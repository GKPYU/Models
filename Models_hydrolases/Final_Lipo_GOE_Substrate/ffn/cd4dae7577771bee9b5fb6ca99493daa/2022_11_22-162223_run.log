2022-11-23 00:33:29,753 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffn/cd4dae7577771bee9b5fb6ca99493daa/2022_11_22-162223",
  "seed": 2,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "cat",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffn/a84e288a23e2297711eccae574abbf00/2021_05_26-165105_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffn",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.85,
  "val_size": 0.15,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.001491528877467142,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 2,
  "hidden_size": 90,
  "model_dropout": 0.13830197814960504,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.00785511672758935,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2022-11-23 00:33:29,765 INFO: Starting stage: BUILD FEATURIZERS
2022-11-23 00:33:29,768 INFO:   Creating esm representation model
2022-11-23 00:33:29,768 INFO:   Done esm representation model
2022-11-23 00:33:29,768 INFO: Done with stage: BUILD FEATURIZERS
2022-11-23 00:33:29,768 INFO: Starting stage: BUILDING DATASET
2022-11-23 00:33:29,827 INFO: Done with stage: BUILDING DATASET
2022-11-23 00:33:29,827 INFO: Starting stage: FEATURIZING DATA
2022-11-23 00:33:29,828 INFO:   Featurizing proteins
2022-11-23 00:33:29,829 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2022-11-23 00:33:29,848 INFO:   Loaded feature cache of size 204
2022-11-23 00:33:29,850 INFO:   Starting to pool ESM Embeddings
2022-11-23 00:33:29,952 INFO:   Featurizing molecules
2022-11-23 00:33:30,339 INFO: Done with stage: FEATURIZING DATA
2022-11-23 00:33:30,339 INFO: Starting stage: RUNNING SPLITS
2022-11-23 00:33:30,348 INFO:   Leaving out SEQ value Fold_0
2022-11-23 00:33:30,362 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-23 00:33:30,363 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:33:31,053 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:33:31,053 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:33:31,122 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:33:31,122 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:33:31,122 INFO:     No hyperparam tuning for this model
2022-11-23 00:33:31,122 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:33:31,122 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:33:31,123 INFO:     None feature selector for col prot
2022-11-23 00:33:31,123 INFO:     None feature selector for col prot
2022-11-23 00:33:31,123 INFO:     None feature selector for col prot
2022-11-23 00:33:31,124 INFO:     None feature selector for col chem
2022-11-23 00:33:31,124 INFO:     None feature selector for col chem
2022-11-23 00:33:31,124 INFO:     None feature selector for col chem
2022-11-23 00:33:31,124 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:33:31,124 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:33:31,126 INFO:     Number of params in model 168571
2022-11-23 00:33:31,126 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:33:31,126 INFO:   Starting stage: TRAINING
2022-11-23 00:33:32,747 INFO:     Val loss before train {'Reaction outcome loss': 1.0160116380037263, 'Total loss': 1.0160116380037263}
2022-11-23 00:33:32,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:32,748 INFO:     Epoch: 0
2022-11-23 00:33:33,542 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8529790362646413, 'Total loss': 0.8529790362646413} | train loss {'Reaction outcome loss': 0.8749035257296484, 'Total loss': 0.8749035257296484}
2022-11-23 00:33:33,542 INFO:     Found new best model at epoch 0
2022-11-23 00:33:33,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:33,543 INFO:     Epoch: 1
2022-11-23 00:33:34,304 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8325662502022677, 'Total loss': 0.8325662502022677} | train loss {'Reaction outcome loss': 0.8462452971544422, 'Total loss': 0.8462452971544422}
2022-11-23 00:33:34,304 INFO:     Found new best model at epoch 1
2022-11-23 00:33:34,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:34,305 INFO:     Epoch: 2
2022-11-23 00:33:35,111 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.870098794615546, 'Total loss': 0.870098794615546} | train loss {'Reaction outcome loss': 0.8424357235675952, 'Total loss': 0.8424357235675952}
2022-11-23 00:33:35,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:35,112 INFO:     Epoch: 3
2022-11-23 00:33:35,869 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8832338660262352, 'Total loss': 0.8832338660262352} | train loss {'Reaction outcome loss': 0.8411802002152459, 'Total loss': 0.8411802002152459}
2022-11-23 00:33:35,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:35,870 INFO:     Epoch: 4
2022-11-23 00:33:36,622 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8415621830973514, 'Total loss': 0.8415621830973514} | train loss {'Reaction outcome loss': 0.8366817206632896, 'Total loss': 0.8366817206632896}
2022-11-23 00:33:36,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:36,622 INFO:     Epoch: 5
2022-11-23 00:33:37,394 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8269857334536176, 'Total loss': 0.8269857334536176} | train loss {'Reaction outcome loss': 0.8369145966211303, 'Total loss': 0.8369145966211303}
2022-11-23 00:33:37,395 INFO:     Found new best model at epoch 5
2022-11-23 00:33:37,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:37,395 INFO:     Epoch: 6
2022-11-23 00:33:38,186 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8138200827809268, 'Total loss': 0.8138200827809268} | train loss {'Reaction outcome loss': 0.8315549334053134, 'Total loss': 0.8315549334053134}
2022-11-23 00:33:38,186 INFO:     Found new best model at epoch 6
2022-11-23 00:33:38,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:38,187 INFO:     Epoch: 7
2022-11-23 00:33:38,940 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8418479735075042, 'Total loss': 0.8418479735075042} | train loss {'Reaction outcome loss': 0.8261897734931258, 'Total loss': 0.8261897734931258}
2022-11-23 00:33:38,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:38,941 INFO:     Epoch: 8
2022-11-23 00:33:39,700 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8173834120118341, 'Total loss': 0.8173834120118341} | train loss {'Reaction outcome loss': 0.8227775135978324, 'Total loss': 0.8227775135978324}
2022-11-23 00:33:39,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:39,701 INFO:     Epoch: 9
2022-11-23 00:33:40,466 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8194913559181746, 'Total loss': 0.8194913559181746} | train loss {'Reaction outcome loss': 0.8248273478668244, 'Total loss': 0.8248273478668244}
2022-11-23 00:33:40,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:40,466 INFO:     Epoch: 10
2022-11-23 00:33:41,212 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8300699355990387, 'Total loss': 0.8300699355990387} | train loss {'Reaction outcome loss': 0.8281428553774709, 'Total loss': 0.8281428553774709}
2022-11-23 00:33:41,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:41,213 INFO:     Epoch: 11
2022-11-23 00:33:41,983 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8297900003056193, 'Total loss': 0.8297900003056193} | train loss {'Reaction outcome loss': 0.8271964676067477, 'Total loss': 0.8271964676067477}
2022-11-23 00:33:41,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:41,984 INFO:     Epoch: 12
2022-11-23 00:33:42,755 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8127155539601348, 'Total loss': 0.8127155539601348} | train loss {'Reaction outcome loss': 0.8240983931988967, 'Total loss': 0.8240983931988967}
2022-11-23 00:33:42,755 INFO:     Found new best model at epoch 12
2022-11-23 00:33:42,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:42,756 INFO:     Epoch: 13
2022-11-23 00:33:43,536 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8647299304951069, 'Total loss': 0.8647299304951069} | train loss {'Reaction outcome loss': 0.8218530197856856, 'Total loss': 0.8218530197856856}
2022-11-23 00:33:43,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:43,537 INFO:     Epoch: 14
2022-11-23 00:33:44,296 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.818041629569475, 'Total loss': 0.818041629569475} | train loss {'Reaction outcome loss': 0.8255142758859962, 'Total loss': 0.8255142758859962}
2022-11-23 00:33:44,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:44,296 INFO:     Epoch: 15
2022-11-23 00:33:45,076 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8312820355559505, 'Total loss': 0.8312820355559505} | train loss {'Reaction outcome loss': 0.8185748979449272, 'Total loss': 0.8185748979449272}
2022-11-23 00:33:45,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:45,077 INFO:     Epoch: 16
2022-11-23 00:33:45,839 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8133724262548048, 'Total loss': 0.8133724262548048} | train loss {'Reaction outcome loss': 0.8246941666622631, 'Total loss': 0.8246941666622631}
2022-11-23 00:33:45,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:45,839 INFO:     Epoch: 17
2022-11-23 00:33:46,598 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8182825654052025, 'Total loss': 0.8182825654052025} | train loss {'Reaction outcome loss': 0.8126489647099229, 'Total loss': 0.8126489647099229}
2022-11-23 00:33:46,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:46,598 INFO:     Epoch: 18
2022-11-23 00:33:47,353 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8159484211788621, 'Total loss': 0.8159484211788621} | train loss {'Reaction outcome loss': 0.816311242761182, 'Total loss': 0.816311242761182}
2022-11-23 00:33:47,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:47,354 INFO:     Epoch: 19
2022-11-23 00:33:48,140 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8295423298381096, 'Total loss': 0.8295423298381096} | train loss {'Reaction outcome loss': 0.8192423020229965, 'Total loss': 0.8192423020229965}
2022-11-23 00:33:48,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:48,140 INFO:     Epoch: 20
2022-11-23 00:33:48,896 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8092600294323855, 'Total loss': 0.8092600294323855} | train loss {'Reaction outcome loss': 0.821546658507136, 'Total loss': 0.821546658507136}
2022-11-23 00:33:48,897 INFO:     Found new best model at epoch 20
2022-11-23 00:33:48,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:48,897 INFO:     Epoch: 21
2022-11-23 00:33:49,681 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.828130210554877, 'Total loss': 0.828130210554877} | train loss {'Reaction outcome loss': 0.8200176988468796, 'Total loss': 0.8200176988468796}
2022-11-23 00:33:49,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:49,682 INFO:     Epoch: 22
2022-11-23 00:33:50,451 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8303542941115624, 'Total loss': 0.8303542941115624} | train loss {'Reaction outcome loss': 0.8154453758577831, 'Total loss': 0.8154453758577831}
2022-11-23 00:33:50,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:50,451 INFO:     Epoch: 23
2022-11-23 00:33:51,218 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8314103290092113, 'Total loss': 0.8314103290092113} | train loss {'Reaction outcome loss': 0.817510757656371, 'Total loss': 0.817510757656371}
2022-11-23 00:33:51,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:51,219 INFO:     Epoch: 24
2022-11-23 00:33:51,968 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8122614275577457, 'Total loss': 0.8122614275577457} | train loss {'Reaction outcome loss': 0.8133526213589262, 'Total loss': 0.8133526213589262}
2022-11-23 00:33:51,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:51,968 INFO:     Epoch: 25
2022-11-23 00:33:52,747 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8164884905482448, 'Total loss': 0.8164884905482448} | train loss {'Reaction outcome loss': 0.8167691911097432, 'Total loss': 0.8167691911097432}
2022-11-23 00:33:52,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:52,748 INFO:     Epoch: 26
2022-11-23 00:33:53,521 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8233755022980446, 'Total loss': 0.8233755022980446} | train loss {'Reaction outcome loss': 0.8140612492551569, 'Total loss': 0.8140612492551569}
2022-11-23 00:33:53,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:53,522 INFO:     Epoch: 27
2022-11-23 00:33:54,277 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8103843338267748, 'Total loss': 0.8103843338267748} | train loss {'Reaction outcome loss': 0.8147705566199099, 'Total loss': 0.8147705566199099}
2022-11-23 00:33:54,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:54,278 INFO:     Epoch: 28
2022-11-23 00:33:55,034 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8126522593720015, 'Total loss': 0.8126522593720015} | train loss {'Reaction outcome loss': 0.8097681762253652, 'Total loss': 0.8097681762253652}
2022-11-23 00:33:55,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:55,034 INFO:     Epoch: 29
2022-11-23 00:33:55,794 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8030883115391398, 'Total loss': 0.8030883115391398} | train loss {'Reaction outcome loss': 0.8204172241394637, 'Total loss': 0.8204172241394637}
2022-11-23 00:33:55,794 INFO:     Found new best model at epoch 29
2022-11-23 00:33:55,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:55,795 INFO:     Epoch: 30
2022-11-23 00:33:56,542 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8071354059285896, 'Total loss': 0.8071354059285896} | train loss {'Reaction outcome loss': 0.8145177306943252, 'Total loss': 0.8145177306943252}
2022-11-23 00:33:56,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:56,543 INFO:     Epoch: 31
2022-11-23 00:33:57,321 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8187297222226165, 'Total loss': 0.8187297222226165} | train loss {'Reaction outcome loss': 0.8212348221511138, 'Total loss': 0.8212348221511138}
2022-11-23 00:33:57,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:57,321 INFO:     Epoch: 32
2022-11-23 00:33:58,092 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8405241287031839, 'Total loss': 0.8405241287031839} | train loss {'Reaction outcome loss': 0.8148515247663514, 'Total loss': 0.8148515247663514}
2022-11-23 00:33:58,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:58,093 INFO:     Epoch: 33
2022-11-23 00:33:58,840 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8063266859498135, 'Total loss': 0.8063266859498135} | train loss {'Reaction outcome loss': 0.8153299811433573, 'Total loss': 0.8153299811433573}
2022-11-23 00:33:58,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:58,840 INFO:     Epoch: 34
2022-11-23 00:33:59,600 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8182653237220853, 'Total loss': 0.8182653237220853} | train loss {'Reaction outcome loss': 0.8187254016272357, 'Total loss': 0.8187254016272357}
2022-11-23 00:33:59,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:33:59,600 INFO:     Epoch: 35
2022-11-23 00:34:00,399 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8132361222145169, 'Total loss': 0.8132361222145169} | train loss {'Reaction outcome loss': 0.8116189447827027, 'Total loss': 0.8116189447827027}
2022-11-23 00:34:00,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:00,399 INFO:     Epoch: 36
2022-11-23 00:34:01,158 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8138316973697307, 'Total loss': 0.8138316973697307} | train loss {'Reaction outcome loss': 0.8136596934961491, 'Total loss': 0.8136596934961491}
2022-11-23 00:34:01,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:01,159 INFO:     Epoch: 37
2022-11-23 00:34:01,964 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8072492106016292, 'Total loss': 0.8072492106016292} | train loss {'Reaction outcome loss': 0.814396079324308, 'Total loss': 0.814396079324308}
2022-11-23 00:34:01,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:01,964 INFO:     Epoch: 38
2022-11-23 00:34:02,816 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8163634510927422, 'Total loss': 0.8163634510927422} | train loss {'Reaction outcome loss': 0.8124482673211176, 'Total loss': 0.8124482673211176}
2022-11-23 00:34:02,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:02,816 INFO:     Epoch: 39
2022-11-23 00:34:03,608 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8126410114210706, 'Total loss': 0.8126410114210706} | train loss {'Reaction outcome loss': 0.8161741661243751, 'Total loss': 0.8161741661243751}
2022-11-23 00:34:03,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:03,608 INFO:     Epoch: 40
2022-11-23 00:34:04,399 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8141463107840959, 'Total loss': 0.8141463107840959} | train loss {'Reaction outcome loss': 0.818048046504865, 'Total loss': 0.818048046504865}
2022-11-23 00:34:04,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:04,399 INFO:     Epoch: 41
2022-11-23 00:34:05,168 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8072060055510942, 'Total loss': 0.8072060055510942} | train loss {'Reaction outcome loss': 0.8156340688955589, 'Total loss': 0.8156340688955589}
2022-11-23 00:34:05,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:05,168 INFO:     Epoch: 42
2022-11-23 00:34:05,959 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8151010877864305, 'Total loss': 0.8151010877864305} | train loss {'Reaction outcome loss': 0.8115747304724865, 'Total loss': 0.8115747304724865}
2022-11-23 00:34:05,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:05,959 INFO:     Epoch: 43
2022-11-23 00:34:06,715 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8204943066419557, 'Total loss': 0.8204943066419557} | train loss {'Reaction outcome loss': 0.8157674763046328, 'Total loss': 0.8157674763046328}
2022-11-23 00:34:06,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:06,715 INFO:     Epoch: 44
2022-11-23 00:34:07,497 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8054347897684851, 'Total loss': 0.8054347897684851} | train loss {'Reaction outcome loss': 0.8163728717653478, 'Total loss': 0.8163728717653478}
2022-11-23 00:34:07,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:07,498 INFO:     Epoch: 45
2022-11-23 00:34:08,314 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8252817787403284, 'Total loss': 0.8252817787403284} | train loss {'Reaction outcome loss': 0.8148115697454233, 'Total loss': 0.8148115697454233}
2022-11-23 00:34:08,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:08,315 INFO:     Epoch: 46
2022-11-23 00:34:09,114 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.815445254015368, 'Total loss': 0.815445254015368} | train loss {'Reaction outcome loss': 0.8097426320929997, 'Total loss': 0.8097426320929997}
2022-11-23 00:34:09,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:09,115 INFO:     Epoch: 47
2022-11-23 00:34:09,950 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8200556608133538, 'Total loss': 0.8200556608133538} | train loss {'Reaction outcome loss': 0.8186971597739907, 'Total loss': 0.8186971597739907}
2022-11-23 00:34:09,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:09,951 INFO:     Epoch: 48
2022-11-23 00:34:10,743 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8109175895535669, 'Total loss': 0.8109175895535669} | train loss {'Reaction outcome loss': 0.8156187147146365, 'Total loss': 0.8156187147146365}
2022-11-23 00:34:10,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:10,743 INFO:     Epoch: 49
2022-11-23 00:34:11,547 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.81621197489805, 'Total loss': 0.81621197489805} | train loss {'Reaction outcome loss': 0.814606597677606, 'Total loss': 0.814606597677606}
2022-11-23 00:34:11,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:11,547 INFO:     Epoch: 50
2022-11-23 00:34:12,342 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8172953336737877, 'Total loss': 0.8172953336737877} | train loss {'Reaction outcome loss': 0.8117727192698933, 'Total loss': 0.8117727192698933}
2022-11-23 00:34:12,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:12,342 INFO:     Epoch: 51
2022-11-23 00:34:13,105 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.805924900049387, 'Total loss': 0.805924900049387} | train loss {'Reaction outcome loss': 0.8158126749464722, 'Total loss': 0.8158126749464722}
2022-11-23 00:34:13,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:13,105 INFO:     Epoch: 52
2022-11-23 00:34:13,915 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8215272537497587, 'Total loss': 0.8215272537497587} | train loss {'Reaction outcome loss': 0.8139387692828648, 'Total loss': 0.8139387692828648}
2022-11-23 00:34:13,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:13,916 INFO:     Epoch: 53
2022-11-23 00:34:14,747 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8088932827461598, 'Total loss': 0.8088932827461598} | train loss {'Reaction outcome loss': 0.8131811453915033, 'Total loss': 0.8131811453915033}
2022-11-23 00:34:14,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:14,748 INFO:     Epoch: 54
2022-11-23 00:34:15,554 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8447265722030817, 'Total loss': 0.8447265722030817} | train loss {'Reaction outcome loss': 0.8149604438269724, 'Total loss': 0.8149604438269724}
2022-11-23 00:34:15,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:15,555 INFO:     Epoch: 55
2022-11-23 00:34:16,351 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8033285120198893, 'Total loss': 0.8033285120198893} | train loss {'Reaction outcome loss': 0.8105619147908493, 'Total loss': 0.8105619147908493}
2022-11-23 00:34:16,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:16,351 INFO:     Epoch: 56
2022-11-23 00:34:17,153 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8026027790335721, 'Total loss': 0.8026027790335721} | train loss {'Reaction outcome loss': 0.8141548660446386, 'Total loss': 0.8141548660446386}
2022-11-23 00:34:17,154 INFO:     Found new best model at epoch 56
2022-11-23 00:34:17,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:17,155 INFO:     Epoch: 57
2022-11-23 00:34:17,961 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8285015017487282, 'Total loss': 0.8285015017487282} | train loss {'Reaction outcome loss': 0.8114442168200602, 'Total loss': 0.8114442168200602}
2022-11-23 00:34:17,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:17,962 INFO:     Epoch: 58
2022-11-23 00:34:18,728 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8017553208872329, 'Total loss': 0.8017553208872329} | train loss {'Reaction outcome loss': 0.8143026561277812, 'Total loss': 0.8143026561277812}
2022-11-23 00:34:18,728 INFO:     Found new best model at epoch 58
2022-11-23 00:34:18,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:18,729 INFO:     Epoch: 59
2022-11-23 00:34:19,524 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8416289867356767, 'Total loss': 0.8416289867356767} | train loss {'Reaction outcome loss': 0.8111213371157646, 'Total loss': 0.8111213371157646}
2022-11-23 00:34:19,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:19,524 INFO:     Epoch: 60
2022-11-23 00:34:20,329 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8228639988012092, 'Total loss': 0.8228639988012092} | train loss {'Reaction outcome loss': 0.808900497853756, 'Total loss': 0.808900497853756}
2022-11-23 00:34:20,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:20,329 INFO:     Epoch: 61
2022-11-23 00:34:21,164 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8166434778723606, 'Total loss': 0.8166434778723606} | train loss {'Reaction outcome loss': 0.8110843911522725, 'Total loss': 0.8110843911522725}
2022-11-23 00:34:21,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:21,164 INFO:     Epoch: 62
2022-11-23 00:34:21,948 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8108813762664795, 'Total loss': 0.8108813762664795} | train loss {'Reaction outcome loss': 0.8198068187129303, 'Total loss': 0.8198068187129303}
2022-11-23 00:34:21,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:21,948 INFO:     Epoch: 63
2022-11-23 00:34:22,747 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8278859243836514, 'Total loss': 0.8278859243836514} | train loss {'Reaction outcome loss': 0.8098722191863372, 'Total loss': 0.8098722191863372}
2022-11-23 00:34:22,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:22,748 INFO:     Epoch: 64
2022-11-23 00:34:23,544 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8086258055165757, 'Total loss': 0.8086258055165757} | train loss {'Reaction outcome loss': 0.8182540094999017, 'Total loss': 0.8182540094999017}
2022-11-23 00:34:23,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:23,544 INFO:     Epoch: 65
2022-11-23 00:34:24,330 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8161979615688324, 'Total loss': 0.8161979615688324} | train loss {'Reaction outcome loss': 0.8105608886871182, 'Total loss': 0.8105608886871182}
2022-11-23 00:34:24,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:24,330 INFO:     Epoch: 66
2022-11-23 00:34:25,087 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8159184081609859, 'Total loss': 0.8159184081609859} | train loss {'Reaction outcome loss': 0.8070230065066306, 'Total loss': 0.8070230065066306}
2022-11-23 00:34:25,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:25,087 INFO:     Epoch: 67
2022-11-23 00:34:25,918 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8142242916794711, 'Total loss': 0.8142242916794711} | train loss {'Reaction outcome loss': 0.8040376581618043, 'Total loss': 0.8040376581618043}
2022-11-23 00:34:25,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:25,920 INFO:     Epoch: 68
2022-11-23 00:34:26,696 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8177057802677155, 'Total loss': 0.8177057802677155} | train loss {'Reaction outcome loss': 0.8090344963015103, 'Total loss': 0.8090344963015103}
2022-11-23 00:34:26,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:26,697 INFO:     Epoch: 69
2022-11-23 00:34:27,509 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8306278087372003, 'Total loss': 0.8306278087372003} | train loss {'Reaction outcome loss': 0.8079957675005569, 'Total loss': 0.8079957675005569}
2022-11-23 00:34:27,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:27,509 INFO:     Epoch: 70
2022-11-23 00:34:28,289 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8276952997196553, 'Total loss': 0.8276952997196553} | train loss {'Reaction outcome loss': 0.8156420407725162, 'Total loss': 0.8156420407725162}
2022-11-23 00:34:28,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:28,289 INFO:     Epoch: 71
2022-11-23 00:34:29,077 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8032346409420634, 'Total loss': 0.8032346409420634} | train loss {'Reaction outcome loss': 0.8092271664836368, 'Total loss': 0.8092271664836368}
2022-11-23 00:34:29,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:29,077 INFO:     Epoch: 72
2022-11-23 00:34:29,881 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8025361160899318, 'Total loss': 0.8025361160899318} | train loss {'Reaction outcome loss': 0.8129499830671998, 'Total loss': 0.8129499830671998}
2022-11-23 00:34:29,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:29,881 INFO:     Epoch: 73
2022-11-23 00:34:30,668 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8186810515647711, 'Total loss': 0.8186810515647711} | train loss {'Reaction outcome loss': 0.8071142143768365, 'Total loss': 0.8071142143768365}
2022-11-23 00:34:30,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:30,668 INFO:     Epoch: 74
2022-11-23 00:34:31,413 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8231498280236887, 'Total loss': 0.8231498280236887} | train loss {'Reaction outcome loss': 0.8067451137744013, 'Total loss': 0.8067451137744013}
2022-11-23 00:34:31,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:31,413 INFO:     Epoch: 75
2022-11-23 00:34:32,192 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8006478769834652, 'Total loss': 0.8006478769834652} | train loss {'Reaction outcome loss': 0.8097176117608782, 'Total loss': 0.8097176117608782}
2022-11-23 00:34:32,193 INFO:     Found new best model at epoch 75
2022-11-23 00:34:32,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:32,193 INFO:     Epoch: 76
2022-11-23 00:34:33,034 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8009294853654019, 'Total loss': 0.8009294853654019} | train loss {'Reaction outcome loss': 0.8042310042703738, 'Total loss': 0.8042310042703738}
2022-11-23 00:34:33,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:33,035 INFO:     Epoch: 77
2022-11-23 00:34:33,834 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8029049011163933, 'Total loss': 0.8029049011163933} | train loss {'Reaction outcome loss': 0.8098148735331707, 'Total loss': 0.8098148735331707}
2022-11-23 00:34:33,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:33,834 INFO:     Epoch: 78
2022-11-23 00:34:34,611 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8349637167398319, 'Total loss': 0.8349637167398319} | train loss {'Reaction outcome loss': 0.8083547170533508, 'Total loss': 0.8083547170533508}
2022-11-23 00:34:34,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:34,611 INFO:     Epoch: 79
2022-11-23 00:34:35,396 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8058912851089655, 'Total loss': 0.8058912851089655} | train loss {'Reaction outcome loss': 0.8058835366954569, 'Total loss': 0.8058835366954569}
2022-11-23 00:34:35,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:35,396 INFO:     Epoch: 80
2022-11-23 00:34:36,192 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8063828584759735, 'Total loss': 0.8063828584759735} | train loss {'Reaction outcome loss': 0.8091756642841902, 'Total loss': 0.8091756642841902}
2022-11-23 00:34:36,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:36,192 INFO:     Epoch: 81
2022-11-23 00:34:36,965 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7925830213136451, 'Total loss': 0.7925830213136451} | train loss {'Reaction outcome loss': 0.8108536710993188, 'Total loss': 0.8108536710993188}
2022-11-23 00:34:36,965 INFO:     Found new best model at epoch 81
2022-11-23 00:34:36,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:36,966 INFO:     Epoch: 82
2022-11-23 00:34:37,725 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8013117271800374, 'Total loss': 0.8013117271800374} | train loss {'Reaction outcome loss': 0.8030145454113601, 'Total loss': 0.8030145454113601}
2022-11-23 00:34:37,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:37,725 INFO:     Epoch: 83
2022-11-23 00:34:38,511 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.824337009773698, 'Total loss': 0.824337009773698} | train loss {'Reaction outcome loss': 0.80622134760755, 'Total loss': 0.80622134760755}
2022-11-23 00:34:38,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:38,513 INFO:     Epoch: 84
2022-11-23 00:34:39,296 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8025951718175134, 'Total loss': 0.8025951718175134} | train loss {'Reaction outcome loss': 0.8067867505501528, 'Total loss': 0.8067867505501528}
2022-11-23 00:34:39,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:39,296 INFO:     Epoch: 85
2022-11-23 00:34:40,062 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8143299014069313, 'Total loss': 0.8143299014069313} | train loss {'Reaction outcome loss': 0.8048251763474746, 'Total loss': 0.8048251763474746}
2022-11-23 00:34:40,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:40,063 INFO:     Epoch: 86
2022-11-23 00:34:40,861 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8270467374213907, 'Total loss': 0.8270467374213907} | train loss {'Reaction outcome loss': 0.8061570747465384, 'Total loss': 0.8061570747465384}
2022-11-23 00:34:40,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:40,861 INFO:     Epoch: 87
2022-11-23 00:34:41,639 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7940287160318952, 'Total loss': 0.7940287160318952} | train loss {'Reaction outcome loss': 0.8078462772193502, 'Total loss': 0.8078462772193502}
2022-11-23 00:34:41,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:41,639 INFO:     Epoch: 88
2022-11-23 00:34:42,439 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8086801843587742, 'Total loss': 0.8086801843587742} | train loss {'Reaction outcome loss': 0.8069230172722066, 'Total loss': 0.8069230172722066}
2022-11-23 00:34:42,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:42,439 INFO:     Epoch: 89
2022-11-23 00:34:43,224 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8019045043823331, 'Total loss': 0.8019045043823331} | train loss {'Reaction outcome loss': 0.8002095596223581, 'Total loss': 0.8002095596223581}
2022-11-23 00:34:43,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:43,224 INFO:     Epoch: 90
2022-11-23 00:34:44,020 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7898743596187857, 'Total loss': 0.7898743596187857} | train loss {'Reaction outcome loss': 0.804213541819424, 'Total loss': 0.804213541819424}
2022-11-23 00:34:44,020 INFO:     Found new best model at epoch 90
2022-11-23 00:34:44,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:44,021 INFO:     Epoch: 91
2022-11-23 00:34:44,779 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8001826169878937, 'Total loss': 0.8001826169878937} | train loss {'Reaction outcome loss': 0.806505275310063, 'Total loss': 0.806505275310063}
2022-11-23 00:34:44,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:44,780 INFO:     Epoch: 92
2022-11-23 00:34:45,555 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7992989656537078, 'Total loss': 0.7992989656537078} | train loss {'Reaction outcome loss': 0.803320473456969, 'Total loss': 0.803320473456969}
2022-11-23 00:34:45,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:45,555 INFO:     Epoch: 93
2022-11-23 00:34:46,375 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8533115172108938, 'Total loss': 0.8533115172108938} | train loss {'Reaction outcome loss': 0.8009131300400515, 'Total loss': 0.8009131300400515}
2022-11-23 00:34:46,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:46,376 INFO:     Epoch: 94
2022-11-23 00:34:47,132 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7935257283754127, 'Total loss': 0.7935257283754127} | train loss {'Reaction outcome loss': 0.8028766747380867, 'Total loss': 0.8028766747380867}
2022-11-23 00:34:47,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:47,132 INFO:     Epoch: 95
2022-11-23 00:34:47,936 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8170388063719106, 'Total loss': 0.8170388063719106} | train loss {'Reaction outcome loss': 0.7995169117558197, 'Total loss': 0.7995169117558197}
2022-11-23 00:34:47,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:47,937 INFO:     Epoch: 96
2022-11-23 00:34:48,733 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7956949382327324, 'Total loss': 0.7956949382327324} | train loss {'Reaction outcome loss': 0.8035594673186052, 'Total loss': 0.8035594673186052}
2022-11-23 00:34:48,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:48,733 INFO:     Epoch: 97
2022-11-23 00:34:49,500 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7996441763500834, 'Total loss': 0.7996441763500834} | train loss {'Reaction outcome loss': 0.800313946653585, 'Total loss': 0.800313946653585}
2022-11-23 00:34:49,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:49,501 INFO:     Epoch: 98
2022-11-23 00:34:50,283 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7905840173710225, 'Total loss': 0.7905840173710225} | train loss {'Reaction outcome loss': 0.7932768824403403, 'Total loss': 0.7932768824403403}
2022-11-23 00:34:50,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:50,284 INFO:     Epoch: 99
2022-11-23 00:34:51,078 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8208021410675936, 'Total loss': 0.8208021410675936} | train loss {'Reaction outcome loss': 0.8019199505692622, 'Total loss': 0.8019199505692622}
2022-11-23 00:34:51,078 INFO:     Best model found after epoch 91 of 100.
2022-11-23 00:34:51,078 INFO:   Done with stage: TRAINING
2022-11-23 00:34:51,078 INFO:   Starting stage: EVALUATION
2022-11-23 00:34:51,217 INFO:   Done with stage: EVALUATION
2022-11-23 00:34:51,217 INFO:   Leaving out SEQ value Fold_1
2022-11-23 00:34:51,230 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 00:34:51,230 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:34:51,913 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:34:51,913 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:34:51,984 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:34:51,984 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:34:51,984 INFO:     No hyperparam tuning for this model
2022-11-23 00:34:51,984 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:34:51,984 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:34:51,985 INFO:     None feature selector for col prot
2022-11-23 00:34:51,985 INFO:     None feature selector for col prot
2022-11-23 00:34:51,985 INFO:     None feature selector for col prot
2022-11-23 00:34:51,986 INFO:     None feature selector for col chem
2022-11-23 00:34:51,986 INFO:     None feature selector for col chem
2022-11-23 00:34:51,986 INFO:     None feature selector for col chem
2022-11-23 00:34:51,986 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:34:51,986 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:34:51,988 INFO:     Number of params in model 168571
2022-11-23 00:34:51,991 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:34:51,991 INFO:   Starting stage: TRAINING
2022-11-23 00:34:52,049 INFO:     Val loss before train {'Reaction outcome loss': 0.9913568943738937, 'Total loss': 0.9913568943738937}
2022-11-23 00:34:52,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:52,049 INFO:     Epoch: 0
2022-11-23 00:34:52,896 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8921186978166754, 'Total loss': 0.8921186978166754} | train loss {'Reaction outcome loss': 0.8755104838595217, 'Total loss': 0.8755104838595217}
2022-11-23 00:34:52,896 INFO:     Found new best model at epoch 0
2022-11-23 00:34:52,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:52,897 INFO:     Epoch: 1
2022-11-23 00:34:53,696 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8607219931754199, 'Total loss': 0.8607219931754199} | train loss {'Reaction outcome loss': 0.8524916654807112, 'Total loss': 0.8524916654807112}
2022-11-23 00:34:53,697 INFO:     Found new best model at epoch 1
2022-11-23 00:34:53,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:53,697 INFO:     Epoch: 2
2022-11-23 00:34:54,526 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8627832125533711, 'Total loss': 0.8627832125533711} | train loss {'Reaction outcome loss': 0.8434452651000699, 'Total loss': 0.8434452651000699}
2022-11-23 00:34:54,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:54,526 INFO:     Epoch: 3
2022-11-23 00:34:55,324 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8632034456188028, 'Total loss': 0.8632034456188028} | train loss {'Reaction outcome loss': 0.8457625590053647, 'Total loss': 0.8457625590053647}
2022-11-23 00:34:55,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:55,324 INFO:     Epoch: 4
2022-11-23 00:34:56,120 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8959994031624361, 'Total loss': 0.8959994031624361} | train loss {'Reaction outcome loss': 0.8436727873709521, 'Total loss': 0.8436727873709521}
2022-11-23 00:34:56,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:56,121 INFO:     Epoch: 5
2022-11-23 00:34:56,922 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8603428040038456, 'Total loss': 0.8603428040038456} | train loss {'Reaction outcome loss': 0.8367281726256073, 'Total loss': 0.8367281726256073}
2022-11-23 00:34:56,923 INFO:     Found new best model at epoch 5
2022-11-23 00:34:56,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:56,924 INFO:     Epoch: 6
2022-11-23 00:34:57,706 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8834971948103472, 'Total loss': 0.8834971948103472} | train loss {'Reaction outcome loss': 0.8321114640366211, 'Total loss': 0.8321114640366211}
2022-11-23 00:34:57,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:57,706 INFO:     Epoch: 7
2022-11-23 00:34:58,483 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8416838652708314, 'Total loss': 0.8416838652708314} | train loss {'Reaction outcome loss': 0.8328923044899698, 'Total loss': 0.8328923044899698}
2022-11-23 00:34:58,483 INFO:     Found new best model at epoch 7
2022-11-23 00:34:58,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:58,484 INFO:     Epoch: 8
2022-11-23 00:34:59,302 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8696919056502256, 'Total loss': 0.8696919056502256} | train loss {'Reaction outcome loss': 0.8298973655893735, 'Total loss': 0.8298973655893735}
2022-11-23 00:34:59,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:34:59,302 INFO:     Epoch: 9
2022-11-23 00:35:00,125 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8462294082749974, 'Total loss': 0.8462294082749974} | train loss {'Reaction outcome loss': 0.8314316054346108, 'Total loss': 0.8314316054346108}
2022-11-23 00:35:00,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:00,125 INFO:     Epoch: 10
2022-11-23 00:35:00,917 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.87377633493055, 'Total loss': 0.87377633493055} | train loss {'Reaction outcome loss': 0.8341089660822139, 'Total loss': 0.8341089660822139}
2022-11-23 00:35:00,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:00,917 INFO:     Epoch: 11
2022-11-23 00:35:01,737 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8699597282843157, 'Total loss': 0.8699597282843157} | train loss {'Reaction outcome loss': 0.8255974171374009, 'Total loss': 0.8255974171374009}
2022-11-23 00:35:01,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:01,737 INFO:     Epoch: 12
2022-11-23 00:35:02,558 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8417533392255957, 'Total loss': 0.8417533392255957} | train loss {'Reaction outcome loss': 0.8314150173654441, 'Total loss': 0.8314150173654441}
2022-11-23 00:35:02,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:02,558 INFO:     Epoch: 13
2022-11-23 00:35:03,377 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8738534071228721, 'Total loss': 0.8738534071228721} | train loss {'Reaction outcome loss': 0.8230244478716059, 'Total loss': 0.8230244478716059}
2022-11-23 00:35:03,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:03,377 INFO:     Epoch: 14
2022-11-23 00:35:04,216 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8448001024397936, 'Total loss': 0.8448001024397936} | train loss {'Reaction outcome loss': 0.8197765711106753, 'Total loss': 0.8197765711106753}
2022-11-23 00:35:04,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:04,216 INFO:     Epoch: 15
2022-11-23 00:35:05,049 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.84618536924774, 'Total loss': 0.84618536924774} | train loss {'Reaction outcome loss': 0.8227749137501967, 'Total loss': 0.8227749137501967}
2022-11-23 00:35:05,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:05,050 INFO:     Epoch: 16
2022-11-23 00:35:05,862 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8505612002177672, 'Total loss': 0.8505612002177672} | train loss {'Reaction outcome loss': 0.8311511124917853, 'Total loss': 0.8311511124917853}
2022-11-23 00:35:05,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:05,863 INFO:     Epoch: 17
2022-11-23 00:35:06,653 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8480337804014032, 'Total loss': 0.8480337804014032} | train loss {'Reaction outcome loss': 0.821051907442842, 'Total loss': 0.821051907442842}
2022-11-23 00:35:06,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:06,653 INFO:     Epoch: 18
2022-11-23 00:35:07,465 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.851926176385446, 'Total loss': 0.851926176385446} | train loss {'Reaction outcome loss': 0.8202985470835497, 'Total loss': 0.8202985470835497}
2022-11-23 00:35:07,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:07,465 INFO:     Epoch: 19
2022-11-23 00:35:08,249 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8603208363056183, 'Total loss': 0.8603208363056183} | train loss {'Reaction outcome loss': 0.8185403075536736, 'Total loss': 0.8185403075536736}
2022-11-23 00:35:08,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:08,250 INFO:     Epoch: 20
2022-11-23 00:35:09,030 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8335721865296364, 'Total loss': 0.8335721865296364} | train loss {'Reaction outcome loss': 0.8230678312450286, 'Total loss': 0.8230678312450286}
2022-11-23 00:35:09,030 INFO:     Found new best model at epoch 20
2022-11-23 00:35:09,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:09,031 INFO:     Epoch: 21
2022-11-23 00:35:09,833 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8511541065844622, 'Total loss': 0.8511541065844622} | train loss {'Reaction outcome loss': 0.8191192807094289, 'Total loss': 0.8191192807094289}
2022-11-23 00:35:09,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:09,835 INFO:     Epoch: 22
2022-11-23 00:35:10,658 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8434187139977108, 'Total loss': 0.8434187139977108} | train loss {'Reaction outcome loss': 0.8188963111354272, 'Total loss': 0.8188963111354272}
2022-11-23 00:35:10,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:10,659 INFO:     Epoch: 23
2022-11-23 00:35:11,506 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.853629706935449, 'Total loss': 0.853629706935449} | train loss {'Reaction outcome loss': 0.8201428949832916, 'Total loss': 0.8201428949832916}
2022-11-23 00:35:11,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:11,507 INFO:     Epoch: 24
2022-11-23 00:35:12,265 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8564064516262575, 'Total loss': 0.8564064516262575} | train loss {'Reaction outcome loss': 0.8248317800311424, 'Total loss': 0.8248317800311424}
2022-11-23 00:35:12,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:12,265 INFO:     Epoch: 25
2022-11-23 00:35:13,101 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8571638546206735, 'Total loss': 0.8571638546206735} | train loss {'Reaction outcome loss': 0.8197507337037369, 'Total loss': 0.8197507337037369}
2022-11-23 00:35:13,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:13,101 INFO:     Epoch: 26
2022-11-23 00:35:13,891 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8381742428649556, 'Total loss': 0.8381742428649556} | train loss {'Reaction outcome loss': 0.8202437914093497, 'Total loss': 0.8202437914093497}
2022-11-23 00:35:13,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:13,892 INFO:     Epoch: 27
2022-11-23 00:35:14,706 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8400535705414686, 'Total loss': 0.8400535705414686} | train loss {'Reaction outcome loss': 0.8214956261368416, 'Total loss': 0.8214956261368416}
2022-11-23 00:35:14,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:14,706 INFO:     Epoch: 28
2022-11-23 00:35:15,512 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8358397761529143, 'Total loss': 0.8358397761529143} | train loss {'Reaction outcome loss': 0.8171625692352109, 'Total loss': 0.8171625692352109}
2022-11-23 00:35:15,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:15,512 INFO:     Epoch: 29
2022-11-23 00:35:16,323 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8538528734987433, 'Total loss': 0.8538528734987433} | train loss {'Reaction outcome loss': 0.8216922230988379, 'Total loss': 0.8216922230988379}
2022-11-23 00:35:16,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:16,324 INFO:     Epoch: 30
2022-11-23 00:35:17,139 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8423330770297484, 'Total loss': 0.8423330770297484} | train loss {'Reaction outcome loss': 0.8125854530315167, 'Total loss': 0.8125854530315167}
2022-11-23 00:35:17,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:17,139 INFO:     Epoch: 31
2022-11-23 00:35:17,943 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8310281851074912, 'Total loss': 0.8310281851074912} | train loss {'Reaction outcome loss': 0.8181126759602473, 'Total loss': 0.8181126759602473}
2022-11-23 00:35:17,943 INFO:     Found new best model at epoch 31
2022-11-23 00:35:17,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:17,944 INFO:     Epoch: 32
2022-11-23 00:35:18,782 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.848231930624355, 'Total loss': 0.848231930624355} | train loss {'Reaction outcome loss': 0.8209451289794706, 'Total loss': 0.8209451289794706}
2022-11-23 00:35:18,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:18,783 INFO:     Epoch: 33
2022-11-23 00:35:19,615 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8326565264300867, 'Total loss': 0.8326565264300867} | train loss {'Reaction outcome loss': 0.8185170263896587, 'Total loss': 0.8185170263896587}
2022-11-23 00:35:19,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:19,615 INFO:     Epoch: 34
2022-11-23 00:35:20,402 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8290763382207263, 'Total loss': 0.8290763382207263} | train loss {'Reaction outcome loss': 0.8211433684777635, 'Total loss': 0.8211433684777635}
2022-11-23 00:35:20,402 INFO:     Found new best model at epoch 34
2022-11-23 00:35:20,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:20,403 INFO:     Epoch: 35
2022-11-23 00:35:21,198 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8404436111450195, 'Total loss': 0.8404436111450195} | train loss {'Reaction outcome loss': 0.8194871532772234, 'Total loss': 0.8194871532772234}
2022-11-23 00:35:21,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:21,198 INFO:     Epoch: 36
2022-11-23 00:35:22,004 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8529874140566046, 'Total loss': 0.8529874140566046} | train loss {'Reaction outcome loss': 0.8181419006364066, 'Total loss': 0.8181419006364066}
2022-11-23 00:35:22,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:22,005 INFO:     Epoch: 37
2022-11-23 00:35:22,812 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.833869684826244, 'Total loss': 0.833869684826244} | train loss {'Reaction outcome loss': 0.8087452267586943, 'Total loss': 0.8087452267586943}
2022-11-23 00:35:22,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:22,812 INFO:     Epoch: 38
2022-11-23 00:35:23,604 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8460025557062842, 'Total loss': 0.8460025557062842} | train loss {'Reaction outcome loss': 0.8197726099959269, 'Total loss': 0.8197726099959269}
2022-11-23 00:35:23,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:23,604 INFO:     Epoch: 39
2022-11-23 00:35:24,423 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8538607223467394, 'Total loss': 0.8538607223467394} | train loss {'Reaction outcome loss': 0.8122894254773252, 'Total loss': 0.8122894254773252}
2022-11-23 00:35:24,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:24,423 INFO:     Epoch: 40
2022-11-23 00:35:25,237 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8303265835751187, 'Total loss': 0.8303265835751187} | train loss {'Reaction outcome loss': 0.8231761309540706, 'Total loss': 0.8231761309540706}
2022-11-23 00:35:25,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:25,237 INFO:     Epoch: 41
2022-11-23 00:35:26,059 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8354120816696774, 'Total loss': 0.8354120816696774} | train loss {'Reaction outcome loss': 0.8185871796086732, 'Total loss': 0.8185871796086732}
2022-11-23 00:35:26,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:26,059 INFO:     Epoch: 42
2022-11-23 00:35:26,898 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.835845406759869, 'Total loss': 0.835845406759869} | train loss {'Reaction outcome loss': 0.8186805113124461, 'Total loss': 0.8186805113124461}
2022-11-23 00:35:26,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:26,898 INFO:     Epoch: 43
2022-11-23 00:35:27,700 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.841546236791394, 'Total loss': 0.841546236791394} | train loss {'Reaction outcome loss': 0.8163888426686106, 'Total loss': 0.8163888426686106}
2022-11-23 00:35:27,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:27,700 INFO:     Epoch: 44
2022-11-23 00:35:28,501 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8508464253761552, 'Total loss': 0.8508464253761552} | train loss {'Reaction outcome loss': 0.81167636950489, 'Total loss': 0.81167636950489}
2022-11-23 00:35:28,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:28,502 INFO:     Epoch: 45
2022-11-23 00:35:29,294 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8423044112595645, 'Total loss': 0.8423044112595645} | train loss {'Reaction outcome loss': 0.8181308941078572, 'Total loss': 0.8181308941078572}
2022-11-23 00:35:29,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:29,294 INFO:     Epoch: 46
2022-11-23 00:35:30,118 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8477351516485214, 'Total loss': 0.8477351516485214} | train loss {'Reaction outcome loss': 0.8147277626914051, 'Total loss': 0.8147277626914051}
2022-11-23 00:35:30,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:30,119 INFO:     Epoch: 47
2022-11-23 00:35:30,941 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8605919012969191, 'Total loss': 0.8605919012969191} | train loss {'Reaction outcome loss': 0.815035323261732, 'Total loss': 0.815035323261732}
2022-11-23 00:35:30,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:30,942 INFO:     Epoch: 48
2022-11-23 00:35:31,747 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8268447755412622, 'Total loss': 0.8268447755412622} | train loss {'Reaction outcome loss': 0.812437243337332, 'Total loss': 0.812437243337332}
2022-11-23 00:35:31,747 INFO:     Found new best model at epoch 48
2022-11-23 00:35:31,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:31,748 INFO:     Epoch: 49
2022-11-23 00:35:32,518 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.83973813327876, 'Total loss': 0.83973813327876} | train loss {'Reaction outcome loss': 0.8132333049648687, 'Total loss': 0.8132333049648687}
2022-11-23 00:35:32,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:32,518 INFO:     Epoch: 50
2022-11-23 00:35:33,348 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8254319070415064, 'Total loss': 0.8254319070415064} | train loss {'Reaction outcome loss': 0.8081959352078225, 'Total loss': 0.8081959352078225}
2022-11-23 00:35:33,348 INFO:     Found new best model at epoch 50
2022-11-23 00:35:33,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:33,349 INFO:     Epoch: 51
2022-11-23 00:35:34,161 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8546419401060451, 'Total loss': 0.8546419401060451} | train loss {'Reaction outcome loss': 0.8164030788881094, 'Total loss': 0.8164030788881094}
2022-11-23 00:35:34,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:34,162 INFO:     Epoch: 52
2022-11-23 00:35:34,971 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8421405039050363, 'Total loss': 0.8421405039050363} | train loss {'Reaction outcome loss': 0.8210149560621393, 'Total loss': 0.8210149560621393}
2022-11-23 00:35:34,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:34,971 INFO:     Epoch: 53
2022-11-23 00:35:35,789 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8499483384869315, 'Total loss': 0.8499483384869315} | train loss {'Reaction outcome loss': 0.8117272084058538, 'Total loss': 0.8117272084058538}
2022-11-23 00:35:35,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:35,790 INFO:     Epoch: 54
2022-11-23 00:35:36,569 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8408849970860914, 'Total loss': 0.8408849970860914} | train loss {'Reaction outcome loss': 0.8076580262135881, 'Total loss': 0.8076580262135881}
2022-11-23 00:35:36,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:36,570 INFO:     Epoch: 55
2022-11-23 00:35:37,354 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8259085565805435, 'Total loss': 0.8259085565805435} | train loss {'Reaction outcome loss': 0.8082559738564588, 'Total loss': 0.8082559738564588}
2022-11-23 00:35:37,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:37,354 INFO:     Epoch: 56
2022-11-23 00:35:38,145 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8254928372123025, 'Total loss': 0.8254928372123025} | train loss {'Reaction outcome loss': 0.8066872659060154, 'Total loss': 0.8066872659060154}
2022-11-23 00:35:38,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:38,145 INFO:     Epoch: 57
2022-11-23 00:35:38,945 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8491645245389505, 'Total loss': 0.8491645245389505} | train loss {'Reaction outcome loss': 0.8100771480485013, 'Total loss': 0.8100771480485013}
2022-11-23 00:35:38,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:38,946 INFO:     Epoch: 58
2022-11-23 00:35:39,765 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.831848449327729, 'Total loss': 0.831848449327729} | train loss {'Reaction outcome loss': 0.8067948750638769, 'Total loss': 0.8067948750638769}
2022-11-23 00:35:39,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:39,765 INFO:     Epoch: 59
2022-11-23 00:35:40,602 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8263786780563268, 'Total loss': 0.8263786780563268} | train loss {'Reaction outcome loss': 0.8111384831942045, 'Total loss': 0.8111384831942045}
2022-11-23 00:35:40,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:40,603 INFO:     Epoch: 60
2022-11-23 00:35:41,444 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8315322697162628, 'Total loss': 0.8315322697162628} | train loss {'Reaction outcome loss': 0.8057730063977029, 'Total loss': 0.8057730063977029}
2022-11-23 00:35:41,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:41,444 INFO:     Epoch: 61
2022-11-23 00:35:42,228 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8321183933453127, 'Total loss': 0.8321183933453127} | train loss {'Reaction outcome loss': 0.8077301986304372, 'Total loss': 0.8077301986304372}
2022-11-23 00:35:42,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:42,229 INFO:     Epoch: 62
2022-11-23 00:35:43,016 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8439618694511327, 'Total loss': 0.8439618694511327} | train loss {'Reaction outcome loss': 0.8176385014645966, 'Total loss': 0.8176385014645966}
2022-11-23 00:35:43,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:43,016 INFO:     Epoch: 63
2022-11-23 00:35:43,786 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8244461037895896, 'Total loss': 0.8244461037895896} | train loss {'Reaction outcome loss': 0.8025500901978508, 'Total loss': 0.8025500901978508}
2022-11-23 00:35:43,787 INFO:     Found new best model at epoch 63
2022-11-23 00:35:43,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:43,788 INFO:     Epoch: 64
2022-11-23 00:35:44,628 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8528099913488735, 'Total loss': 0.8528099913488735} | train loss {'Reaction outcome loss': 0.8070523861328117, 'Total loss': 0.8070523861328117}
2022-11-23 00:35:44,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:44,629 INFO:     Epoch: 65
2022-11-23 00:35:45,460 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8252693143757907, 'Total loss': 0.8252693143757907} | train loss {'Reaction outcome loss': 0.8043633061140655, 'Total loss': 0.8043633061140655}
2022-11-23 00:35:45,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:45,460 INFO:     Epoch: 66
2022-11-23 00:35:46,260 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.841104965318333, 'Total loss': 0.841104965318333} | train loss {'Reaction outcome loss': 0.8056864200333352, 'Total loss': 0.8056864200333352}
2022-11-23 00:35:46,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:46,260 INFO:     Epoch: 67
2022-11-23 00:35:47,050 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8336732665246184, 'Total loss': 0.8336732665246184} | train loss {'Reaction outcome loss': 0.8093219325851332, 'Total loss': 0.8093219325851332}
2022-11-23 00:35:47,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:47,051 INFO:     Epoch: 68
2022-11-23 00:35:47,860 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8263854486021128, 'Total loss': 0.8263854486021128} | train loss {'Reaction outcome loss': 0.8067260020174961, 'Total loss': 0.8067260020174961}
2022-11-23 00:35:47,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:47,861 INFO:     Epoch: 69
2022-11-23 00:35:48,696 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8212240135127847, 'Total loss': 0.8212240135127847} | train loss {'Reaction outcome loss': 0.806638777256012, 'Total loss': 0.806638777256012}
2022-11-23 00:35:48,696 INFO:     Found new best model at epoch 69
2022-11-23 00:35:48,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:48,697 INFO:     Epoch: 70
2022-11-23 00:35:49,515 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8286611370064996, 'Total loss': 0.8286611370064996} | train loss {'Reaction outcome loss': 0.8052681063109564, 'Total loss': 0.8052681063109564}
2022-11-23 00:35:49,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:49,515 INFO:     Epoch: 71
2022-11-23 00:35:50,297 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8090928603302349, 'Total loss': 0.8090928603302349} | train loss {'Reaction outcome loss': 0.8000447705146755, 'Total loss': 0.8000447705146755}
2022-11-23 00:35:50,297 INFO:     Found new best model at epoch 71
2022-11-23 00:35:50,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:50,298 INFO:     Epoch: 72
2022-11-23 00:35:51,106 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8299090625210241, 'Total loss': 0.8299090625210241} | train loss {'Reaction outcome loss': 0.7974444697743003, 'Total loss': 0.7974444697743003}
2022-11-23 00:35:51,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:51,107 INFO:     Epoch: 73
2022-11-23 00:35:51,932 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8501282056624239, 'Total loss': 0.8501282056624239} | train loss {'Reaction outcome loss': 0.806860305037093, 'Total loss': 0.806860305037093}
2022-11-23 00:35:51,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:51,932 INFO:     Epoch: 74
2022-11-23 00:35:52,786 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8183075772090391, 'Total loss': 0.8183075772090391} | train loss {'Reaction outcome loss': 0.7985347730186787, 'Total loss': 0.7985347730186787}
2022-11-23 00:35:52,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:52,787 INFO:     Epoch: 75
2022-11-23 00:35:53,608 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8221038830551234, 'Total loss': 0.8221038830551234} | train loss {'Reaction outcome loss': 0.7895789964478991, 'Total loss': 0.7895789964478991}
2022-11-23 00:35:53,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:53,608 INFO:     Epoch: 76
2022-11-23 00:35:54,437 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8220008394934915, 'Total loss': 0.8220008394934915} | train loss {'Reaction outcome loss': 0.792416434554074, 'Total loss': 0.792416434554074}
2022-11-23 00:35:54,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:54,438 INFO:     Epoch: 77
2022-11-23 00:35:55,205 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.832439083267342, 'Total loss': 0.832439083267342} | train loss {'Reaction outcome loss': 0.7873067975285565, 'Total loss': 0.7873067975285565}
2022-11-23 00:35:55,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:55,206 INFO:     Epoch: 78
2022-11-23 00:35:55,966 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8260387473485686, 'Total loss': 0.8260387473485686} | train loss {'Reaction outcome loss': 0.7869704017031048, 'Total loss': 0.7869704017031048}
2022-11-23 00:35:55,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:55,966 INFO:     Epoch: 79
2022-11-23 00:35:56,764 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7942178723486987, 'Total loss': 0.7942178723486987} | train loss {'Reaction outcome loss': 0.7850679799854031, 'Total loss': 0.7850679799854031}
2022-11-23 00:35:56,764 INFO:     Found new best model at epoch 79
2022-11-23 00:35:56,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:56,765 INFO:     Epoch: 80
2022-11-23 00:35:57,552 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8060441857034509, 'Total loss': 0.8060441857034509} | train loss {'Reaction outcome loss': 0.7880375318922977, 'Total loss': 0.7880375318922977}
2022-11-23 00:35:57,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:57,552 INFO:     Epoch: 81
2022-11-23 00:35:58,375 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7998277287591588, 'Total loss': 0.7998277287591588} | train loss {'Reaction outcome loss': 0.7860874719012846, 'Total loss': 0.7860874719012846}
2022-11-23 00:35:58,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:58,375 INFO:     Epoch: 82
2022-11-23 00:35:59,137 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8141451857306741, 'Total loss': 0.8141451857306741} | train loss {'Reaction outcome loss': 0.7934986045244734, 'Total loss': 0.7934986045244734}
2022-11-23 00:35:59,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:59,138 INFO:     Epoch: 83
2022-11-23 00:35:59,953 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8137922876260497, 'Total loss': 0.8137922876260497} | train loss {'Reaction outcome loss': 0.7906176932910194, 'Total loss': 0.7906176932910194}
2022-11-23 00:35:59,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:35:59,953 INFO:     Epoch: 84
2022-11-23 00:36:00,760 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8221795342185281, 'Total loss': 0.8221795342185281} | train loss {'Reaction outcome loss': 0.7896278556059246, 'Total loss': 0.7896278556059246}
2022-11-23 00:36:00,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:00,761 INFO:     Epoch: 85
2022-11-23 00:36:01,551 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.809353350915692, 'Total loss': 0.809353350915692} | train loss {'Reaction outcome loss': 0.7805363975073162, 'Total loss': 0.7805363975073162}
2022-11-23 00:36:01,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:01,552 INFO:     Epoch: 86
2022-11-23 00:36:02,391 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8327875895933672, 'Total loss': 0.8327875895933672} | train loss {'Reaction outcome loss': 0.7861309746499003, 'Total loss': 0.7861309746499003}
2022-11-23 00:36:02,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:02,391 INFO:     Epoch: 87
2022-11-23 00:36:03,210 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7998440157283436, 'Total loss': 0.7998440157283436} | train loss {'Reaction outcome loss': 0.8011357511586024, 'Total loss': 0.8011357511586024}
2022-11-23 00:36:03,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:03,211 INFO:     Epoch: 88
2022-11-23 00:36:04,031 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8480570600791411, 'Total loss': 0.8480570600791411} | train loss {'Reaction outcome loss': 0.7844101556158258, 'Total loss': 0.7844101556158258}
2022-11-23 00:36:04,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:04,032 INFO:     Epoch: 89
2022-11-23 00:36:04,888 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7884865186431191, 'Total loss': 0.7884865186431191} | train loss {'Reaction outcome loss': 0.7794919519530616, 'Total loss': 0.7794919519530616}
2022-11-23 00:36:04,888 INFO:     Found new best model at epoch 89
2022-11-23 00:36:04,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:04,889 INFO:     Epoch: 90
2022-11-23 00:36:05,694 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8506737337871031, 'Total loss': 0.8506737337871031} | train loss {'Reaction outcome loss': 0.7743055156548979, 'Total loss': 0.7743055156548979}
2022-11-23 00:36:05,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:05,694 INFO:     Epoch: 91
2022-11-23 00:36:06,616 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.777247080071406, 'Total loss': 0.777247080071406} | train loss {'Reaction outcome loss': 0.7719662834999532, 'Total loss': 0.7719662834999532}
2022-11-23 00:36:06,616 INFO:     Found new best model at epoch 91
2022-11-23 00:36:06,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:06,617 INFO:     Epoch: 92
2022-11-23 00:36:07,456 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7834883359345522, 'Total loss': 0.7834883359345522} | train loss {'Reaction outcome loss': 0.7764359543680662, 'Total loss': 0.7764359543680662}
2022-11-23 00:36:07,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:07,456 INFO:     Epoch: 93
2022-11-23 00:36:08,237 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7711255916140296, 'Total loss': 0.7711255916140296} | train loss {'Reaction outcome loss': 0.7542282446072652, 'Total loss': 0.7542282446072652}
2022-11-23 00:36:08,238 INFO:     Found new best model at epoch 93
2022-11-23 00:36:08,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:08,239 INFO:     Epoch: 94
2022-11-23 00:36:09,062 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7733404995365576, 'Total loss': 0.7733404995365576} | train loss {'Reaction outcome loss': 0.763268300999514, 'Total loss': 0.763268300999514}
2022-11-23 00:36:09,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:09,062 INFO:     Epoch: 95
2022-11-23 00:36:09,896 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7836966236883943, 'Total loss': 0.7836966236883943} | train loss {'Reaction outcome loss': 0.7676763067602629, 'Total loss': 0.7676763067602629}
2022-11-23 00:36:09,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:09,897 INFO:     Epoch: 96
2022-11-23 00:36:10,697 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8759172010150823, 'Total loss': 0.8759172010150823} | train loss {'Reaction outcome loss': 0.744966375924315, 'Total loss': 0.744966375924315}
2022-11-23 00:36:10,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:10,697 INFO:     Epoch: 97
2022-11-23 00:36:11,497 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7508949352936312, 'Total loss': 0.7508949352936312} | train loss {'Reaction outcome loss': 0.7470688993631587, 'Total loss': 0.7470688993631587}
2022-11-23 00:36:11,498 INFO:     Found new best model at epoch 97
2022-11-23 00:36:11,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:11,499 INFO:     Epoch: 98
2022-11-23 00:36:12,284 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7354127283800732, 'Total loss': 0.7354127283800732} | train loss {'Reaction outcome loss': 0.741764805818859, 'Total loss': 0.741764805818859}
2022-11-23 00:36:12,284 INFO:     Found new best model at epoch 98
2022-11-23 00:36:12,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:12,285 INFO:     Epoch: 99
2022-11-23 00:36:13,082 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7530659518458627, 'Total loss': 0.7530659518458627} | train loss {'Reaction outcome loss': 0.7388272159977963, 'Total loss': 0.7388272159977963}
2022-11-23 00:36:13,082 INFO:     Best model found after epoch 99 of 100.
2022-11-23 00:36:13,082 INFO:   Done with stage: TRAINING
2022-11-23 00:36:13,082 INFO:   Starting stage: EVALUATION
2022-11-23 00:36:13,206 INFO:   Done with stage: EVALUATION
2022-11-23 00:36:13,206 INFO:   Leaving out SEQ value Fold_2
2022-11-23 00:36:13,219 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-23 00:36:13,220 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:36:13,886 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:36:13,887 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:36:13,957 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:36:13,957 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:36:13,957 INFO:     No hyperparam tuning for this model
2022-11-23 00:36:13,958 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:36:13,958 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:36:13,958 INFO:     None feature selector for col prot
2022-11-23 00:36:13,959 INFO:     None feature selector for col prot
2022-11-23 00:36:13,959 INFO:     None feature selector for col prot
2022-11-23 00:36:13,959 INFO:     None feature selector for col chem
2022-11-23 00:36:13,959 INFO:     None feature selector for col chem
2022-11-23 00:36:13,959 INFO:     None feature selector for col chem
2022-11-23 00:36:13,959 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:36:13,959 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:36:13,961 INFO:     Number of params in model 168571
2022-11-23 00:36:13,964 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:36:13,964 INFO:   Starting stage: TRAINING
2022-11-23 00:36:14,022 INFO:     Val loss before train {'Reaction outcome loss': 0.9492575837807222, 'Total loss': 0.9492575837807222}
2022-11-23 00:36:14,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:14,022 INFO:     Epoch: 0
2022-11-23 00:36:14,816 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8004821931773966, 'Total loss': 0.8004821931773966} | train loss {'Reaction outcome loss': 0.8748633555003575, 'Total loss': 0.8748633555003575}
2022-11-23 00:36:14,817 INFO:     Found new best model at epoch 0
2022-11-23 00:36:14,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:14,817 INFO:     Epoch: 1
2022-11-23 00:36:15,602 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8020193143324419, 'Total loss': 0.8020193143324419} | train loss {'Reaction outcome loss': 0.8522367927492881, 'Total loss': 0.8522367927492881}
2022-11-23 00:36:15,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:15,603 INFO:     Epoch: 2
2022-11-23 00:36:16,378 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7959268506277691, 'Total loss': 0.7959268506277691} | train loss {'Reaction outcome loss': 0.8487156826622632, 'Total loss': 0.8487156826622632}
2022-11-23 00:36:16,378 INFO:     Found new best model at epoch 2
2022-11-23 00:36:16,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:16,379 INFO:     Epoch: 3
2022-11-23 00:36:17,170 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.773889838125218, 'Total loss': 0.773889838125218} | train loss {'Reaction outcome loss': 0.846304124837019, 'Total loss': 0.846304124837019}
2022-11-23 00:36:17,171 INFO:     Found new best model at epoch 3
2022-11-23 00:36:17,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:17,172 INFO:     Epoch: 4
2022-11-23 00:36:17,939 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7814472900195555, 'Total loss': 0.7814472900195555} | train loss {'Reaction outcome loss': 0.8428869085652487, 'Total loss': 0.8428869085652487}
2022-11-23 00:36:17,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:17,940 INFO:     Epoch: 5
2022-11-23 00:36:18,751 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8025794286619533, 'Total loss': 0.8025794286619533} | train loss {'Reaction outcome loss': 0.8384465434721537, 'Total loss': 0.8384465434721537}
2022-11-23 00:36:18,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:18,751 INFO:     Epoch: 6
2022-11-23 00:36:19,521 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7845462553880431, 'Total loss': 0.7845462553880431} | train loss {'Reaction outcome loss': 0.8355480290189081, 'Total loss': 0.8355480290189081}
2022-11-23 00:36:19,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:19,522 INFO:     Epoch: 7
2022-11-23 00:36:20,287 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7703324698589065, 'Total loss': 0.7703324698589065} | train loss {'Reaction outcome loss': 0.828898827883662, 'Total loss': 0.828898827883662}
2022-11-23 00:36:20,288 INFO:     Found new best model at epoch 7
2022-11-23 00:36:20,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:20,289 INFO:     Epoch: 8
2022-11-23 00:36:21,069 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7944060415029526, 'Total loss': 0.7944060415029526} | train loss {'Reaction outcome loss': 0.8310844332587962, 'Total loss': 0.8310844332587962}
2022-11-23 00:36:21,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:21,069 INFO:     Epoch: 9
2022-11-23 00:36:21,868 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7680956267497756, 'Total loss': 0.7680956267497756} | train loss {'Reaction outcome loss': 0.8307268005244586, 'Total loss': 0.8307268005244586}
2022-11-23 00:36:21,868 INFO:     Found new best model at epoch 9
2022-11-23 00:36:21,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:21,869 INFO:     Epoch: 10
2022-11-23 00:36:22,727 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7660873098806902, 'Total loss': 0.7660873098806902} | train loss {'Reaction outcome loss': 0.8279997868197305, 'Total loss': 0.8279997868197305}
2022-11-23 00:36:22,728 INFO:     Found new best model at epoch 10
2022-11-23 00:36:22,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:22,728 INFO:     Epoch: 11
2022-11-23 00:36:23,564 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7802370949224993, 'Total loss': 0.7802370949224993} | train loss {'Reaction outcome loss': 0.8234342126213774, 'Total loss': 0.8234342126213774}
2022-11-23 00:36:23,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:23,565 INFO:     Epoch: 12
2022-11-23 00:36:24,384 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7751220803369175, 'Total loss': 0.7751220803369175} | train loss {'Reaction outcome loss': 0.8211332336980469, 'Total loss': 0.8211332336980469}
2022-11-23 00:36:24,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:24,384 INFO:     Epoch: 13
2022-11-23 00:36:25,189 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8171087266369299, 'Total loss': 0.8171087266369299} | train loss {'Reaction outcome loss': 0.8263158495328864, 'Total loss': 0.8263158495328864}
2022-11-23 00:36:25,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:25,189 INFO:     Epoch: 14
2022-11-23 00:36:25,995 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7862155545841564, 'Total loss': 0.7862155545841564} | train loss {'Reaction outcome loss': 0.8246989365743131, 'Total loss': 0.8246989365743131}
2022-11-23 00:36:25,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:25,996 INFO:     Epoch: 15
2022-11-23 00:36:26,799 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7877248457886956, 'Total loss': 0.7877248457886956} | train loss {'Reaction outcome loss': 0.8182780023740263, 'Total loss': 0.8182780023740263}
2022-11-23 00:36:26,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:26,800 INFO:     Epoch: 16
2022-11-23 00:36:27,646 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7879046201705933, 'Total loss': 0.7879046201705933} | train loss {'Reaction outcome loss': 0.822162743977138, 'Total loss': 0.822162743977138}
2022-11-23 00:36:27,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:27,647 INFO:     Epoch: 17
2022-11-23 00:36:28,459 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7741200944239442, 'Total loss': 0.7741200944239442} | train loss {'Reaction outcome loss': 0.8242652927126203, 'Total loss': 0.8242652927126203}
2022-11-23 00:36:28,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:28,460 INFO:     Epoch: 18
2022-11-23 00:36:29,270 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7734572623263706, 'Total loss': 0.7734572623263706} | train loss {'Reaction outcome loss': 0.8236313905034747, 'Total loss': 0.8236313905034747}
2022-11-23 00:36:29,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:29,270 INFO:     Epoch: 19
2022-11-23 00:36:30,076 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7869397740472447, 'Total loss': 0.7869397740472447} | train loss {'Reaction outcome loss': 0.820736652491044, 'Total loss': 0.820736652491044}
2022-11-23 00:36:30,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:30,077 INFO:     Epoch: 20
2022-11-23 00:36:30,884 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7739461734890938, 'Total loss': 0.7739461734890938} | train loss {'Reaction outcome loss': 0.823046933023297, 'Total loss': 0.823046933023297}
2022-11-23 00:36:30,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:30,884 INFO:     Epoch: 21
2022-11-23 00:36:31,641 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7733173531226136, 'Total loss': 0.7733173531226136} | train loss {'Reaction outcome loss': 0.8207651669881781, 'Total loss': 0.8207651669881781}
2022-11-23 00:36:31,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:31,641 INFO:     Epoch: 22
2022-11-23 00:36:32,452 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.784405220638622, 'Total loss': 0.784405220638622} | train loss {'Reaction outcome loss': 0.8216754016827564, 'Total loss': 0.8216754016827564}
2022-11-23 00:36:32,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:32,452 INFO:     Epoch: 23
2022-11-23 00:36:33,280 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7682259238579057, 'Total loss': 0.7682259238579057} | train loss {'Reaction outcome loss': 0.8177787677365906, 'Total loss': 0.8177787677365906}
2022-11-23 00:36:33,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:33,280 INFO:     Epoch: 24
2022-11-23 00:36:34,082 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7633973759683695, 'Total loss': 0.7633973759683695} | train loss {'Reaction outcome loss': 0.8261542753297455, 'Total loss': 0.8261542753297455}
2022-11-23 00:36:34,082 INFO:     Found new best model at epoch 24
2022-11-23 00:36:34,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:34,083 INFO:     Epoch: 25
2022-11-23 00:36:34,850 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7785767079754309, 'Total loss': 0.7785767079754309} | train loss {'Reaction outcome loss': 0.8241005254035093, 'Total loss': 0.8241005254035093}
2022-11-23 00:36:34,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:34,851 INFO:     Epoch: 26
2022-11-23 00:36:35,672 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7581369402733716, 'Total loss': 0.7581369402733716} | train loss {'Reaction outcome loss': 0.8222627671397462, 'Total loss': 0.8222627671397462}
2022-11-23 00:36:35,673 INFO:     Found new best model at epoch 26
2022-11-23 00:36:35,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:35,673 INFO:     Epoch: 27
2022-11-23 00:36:36,515 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7794208425012502, 'Total loss': 0.7794208425012502} | train loss {'Reaction outcome loss': 0.8194796841971729, 'Total loss': 0.8194796841971729}
2022-11-23 00:36:36,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:36,515 INFO:     Epoch: 28
2022-11-23 00:36:37,270 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.798539518632672, 'Total loss': 0.798539518632672} | train loss {'Reaction outcome loss': 0.8240368144244564, 'Total loss': 0.8240368144244564}
2022-11-23 00:36:37,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:37,270 INFO:     Epoch: 29
2022-11-23 00:36:38,068 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7949850620193915, 'Total loss': 0.7949850620193915} | train loss {'Reaction outcome loss': 0.8203271125044141, 'Total loss': 0.8203271125044141}
2022-11-23 00:36:38,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:38,068 INFO:     Epoch: 30
2022-11-23 00:36:38,877 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7662939822131937, 'Total loss': 0.7662939822131937} | train loss {'Reaction outcome loss': 0.8210685649696662, 'Total loss': 0.8210685649696662}
2022-11-23 00:36:38,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:38,877 INFO:     Epoch: 31
2022-11-23 00:36:39,684 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7930813065984033, 'Total loss': 0.7930813065984033} | train loss {'Reaction outcome loss': 0.8257103879841007, 'Total loss': 0.8257103879841007}
2022-11-23 00:36:39,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:39,684 INFO:     Epoch: 32
2022-11-23 00:36:40,486 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7860343483361331, 'Total loss': 0.7860343483361331} | train loss {'Reaction outcome loss': 0.8217445105922465, 'Total loss': 0.8217445105922465}
2022-11-23 00:36:40,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:40,486 INFO:     Epoch: 33
2022-11-23 00:36:41,262 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7803917703303423, 'Total loss': 0.7803917703303423} | train loss {'Reaction outcome loss': 0.8203946279019726, 'Total loss': 0.8203946279019726}
2022-11-23 00:36:41,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:41,262 INFO:     Epoch: 34
2022-11-23 00:36:42,078 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7799580029465936, 'Total loss': 0.7799580029465936} | train loss {'Reaction outcome loss': 0.8181633074672855, 'Total loss': 0.8181633074672855}
2022-11-23 00:36:42,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:42,079 INFO:     Epoch: 35
2022-11-23 00:36:42,877 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.790566814894026, 'Total loss': 0.790566814894026} | train loss {'Reaction outcome loss': 0.8209632059141081, 'Total loss': 0.8209632059141081}
2022-11-23 00:36:42,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:42,878 INFO:     Epoch: 36
2022-11-23 00:36:43,660 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7630773803049867, 'Total loss': 0.7630773803049867} | train loss {'Reaction outcome loss': 0.8212986840277302, 'Total loss': 0.8212986840277302}
2022-11-23 00:36:43,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:43,660 INFO:     Epoch: 37
2022-11-23 00:36:44,443 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7648664902557026, 'Total loss': 0.7648664902557026} | train loss {'Reaction outcome loss': 0.8196457302083775, 'Total loss': 0.8196457302083775}
2022-11-23 00:36:44,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:44,444 INFO:     Epoch: 38
2022-11-23 00:36:45,239 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7636571391062303, 'Total loss': 0.7636571391062303} | train loss {'Reaction outcome loss': 0.8197181575152339, 'Total loss': 0.8197181575152339}
2022-11-23 00:36:45,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:45,239 INFO:     Epoch: 39
2022-11-23 00:36:46,052 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7952749796889045, 'Total loss': 0.7952749796889045} | train loss {'Reaction outcome loss': 0.8226767861113257, 'Total loss': 0.8226767861113257}
2022-11-23 00:36:46,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:46,053 INFO:     Epoch: 40
2022-11-23 00:36:46,804 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7626865584064614, 'Total loss': 0.7626865584064614} | train loss {'Reaction outcome loss': 0.8225088231417598, 'Total loss': 0.8225088231417598}
2022-11-23 00:36:46,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:46,804 INFO:     Epoch: 41
2022-11-23 00:36:47,574 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7746340083804998, 'Total loss': 0.7746340083804998} | train loss {'Reaction outcome loss': 0.8193206990251736, 'Total loss': 0.8193206990251736}
2022-11-23 00:36:47,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:47,575 INFO:     Epoch: 42
2022-11-23 00:36:48,477 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7738778103481639, 'Total loss': 0.7738778103481639} | train loss {'Reaction outcome loss': 0.8201965566192354, 'Total loss': 0.8201965566192354}
2022-11-23 00:36:48,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:48,478 INFO:     Epoch: 43
2022-11-23 00:36:49,303 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.798643749545921, 'Total loss': 0.798643749545921} | train loss {'Reaction outcome loss': 0.8186488313334329, 'Total loss': 0.8186488313334329}
2022-11-23 00:36:49,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:49,304 INFO:     Epoch: 44
2022-11-23 00:36:50,105 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7819416583939032, 'Total loss': 0.7819416583939032} | train loss {'Reaction outcome loss': 0.8196032903632339, 'Total loss': 0.8196032903632339}
2022-11-23 00:36:50,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:50,105 INFO:     Epoch: 45
2022-11-23 00:36:50,912 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7563199373808774, 'Total loss': 0.7563199373808774} | train loss {'Reaction outcome loss': 0.8232004665598578, 'Total loss': 0.8232004665598578}
2022-11-23 00:36:50,913 INFO:     Found new best model at epoch 45
2022-11-23 00:36:50,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:50,913 INFO:     Epoch: 46
2022-11-23 00:36:51,752 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.762530863454396, 'Total loss': 0.762530863454396} | train loss {'Reaction outcome loss': 0.8192872903784927, 'Total loss': 0.8192872903784927}
2022-11-23 00:36:51,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:51,752 INFO:     Epoch: 47
2022-11-23 00:36:52,553 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7770369587974115, 'Total loss': 0.7770369587974115} | train loss {'Reaction outcome loss': 0.8269167245650778, 'Total loss': 0.8269167245650778}
2022-11-23 00:36:52,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:52,553 INFO:     Epoch: 48
2022-11-23 00:36:53,376 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7690204219384627, 'Total loss': 0.7690204219384627} | train loss {'Reaction outcome loss': 0.8195812552559133, 'Total loss': 0.8195812552559133}
2022-11-23 00:36:53,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:53,377 INFO:     Epoch: 49
2022-11-23 00:36:54,189 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7946984734047543, 'Total loss': 0.7946984734047543} | train loss {'Reaction outcome loss': 0.8192983928991824, 'Total loss': 0.8192983928991824}
2022-11-23 00:36:54,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:54,189 INFO:     Epoch: 50
2022-11-23 00:36:54,950 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7708584395321932, 'Total loss': 0.7708584395321932} | train loss {'Reaction outcome loss': 0.8172672500415724, 'Total loss': 0.8172672500415724}
2022-11-23 00:36:54,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:54,950 INFO:     Epoch: 51
2022-11-23 00:36:55,759 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7696043022654273, 'Total loss': 0.7696043022654273} | train loss {'Reaction outcome loss': 0.8197953876183958, 'Total loss': 0.8197953876183958}
2022-11-23 00:36:55,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:55,760 INFO:     Epoch: 52
2022-11-23 00:36:56,581 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7585410042242571, 'Total loss': 0.7585410042242571} | train loss {'Reaction outcome loss': 0.8186778553894588, 'Total loss': 0.8186778553894588}
2022-11-23 00:36:56,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:56,582 INFO:     Epoch: 53
2022-11-23 00:36:57,426 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7748321288011291, 'Total loss': 0.7748321288011291} | train loss {'Reaction outcome loss': 0.8187902836167082, 'Total loss': 0.8187902836167082}
2022-11-23 00:36:57,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:57,426 INFO:     Epoch: 54
2022-11-23 00:36:58,241 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7722026990218596, 'Total loss': 0.7722026990218596} | train loss {'Reaction outcome loss': 0.8149122811093622, 'Total loss': 0.8149122811093622}
2022-11-23 00:36:58,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:58,241 INFO:     Epoch: 55
2022-11-23 00:36:59,053 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7732279659672217, 'Total loss': 0.7732279659672217} | train loss {'Reaction outcome loss': 0.8157631994510184, 'Total loss': 0.8157631994510184}
2022-11-23 00:36:59,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:59,053 INFO:     Epoch: 56
2022-11-23 00:36:59,851 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7797922756184231, 'Total loss': 0.7797922756184231} | train loss {'Reaction outcome loss': 0.815845979841388, 'Total loss': 0.815845979841388}
2022-11-23 00:36:59,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:36:59,851 INFO:     Epoch: 57
2022-11-23 00:37:00,639 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7684353197162802, 'Total loss': 0.7684353197162802} | train loss {'Reaction outcome loss': 0.8188851750626855, 'Total loss': 0.8188851750626855}
2022-11-23 00:37:00,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:00,640 INFO:     Epoch: 58
2022-11-23 00:37:01,441 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7763223424553871, 'Total loss': 0.7763223424553871} | train loss {'Reaction outcome loss': 0.813376299459107, 'Total loss': 0.813376299459107}
2022-11-23 00:37:01,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:01,441 INFO:     Epoch: 59
2022-11-23 00:37:02,240 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7696230208331888, 'Total loss': 0.7696230208331888} | train loss {'Reaction outcome loss': 0.8173397486307183, 'Total loss': 0.8173397486307183}
2022-11-23 00:37:02,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:02,241 INFO:     Epoch: 60
2022-11-23 00:37:03,018 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7650760290297595, 'Total loss': 0.7650760290297595} | train loss {'Reaction outcome loss': 0.8197430978015977, 'Total loss': 0.8197430978015977}
2022-11-23 00:37:03,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:03,018 INFO:     Epoch: 61
2022-11-23 00:37:03,791 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.772507248277014, 'Total loss': 0.772507248277014} | train loss {'Reaction outcome loss': 0.8198539519796566, 'Total loss': 0.8198539519796566}
2022-11-23 00:37:03,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:03,791 INFO:     Epoch: 62
2022-11-23 00:37:04,546 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7668874351815744, 'Total loss': 0.7668874351815744} | train loss {'Reaction outcome loss': 0.817630829859753, 'Total loss': 0.817630829859753}
2022-11-23 00:37:04,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:04,547 INFO:     Epoch: 63
2022-11-23 00:37:05,324 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7526488385417245, 'Total loss': 0.7526488385417245} | train loss {'Reaction outcome loss': 0.8199100505332557, 'Total loss': 0.8199100505332557}
2022-11-23 00:37:05,324 INFO:     Found new best model at epoch 63
2022-11-23 00:37:05,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:05,325 INFO:     Epoch: 64
2022-11-23 00:37:06,074 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8012895414775069, 'Total loss': 0.8012895414775069} | train loss {'Reaction outcome loss': 0.8188815197166132, 'Total loss': 0.8188815197166132}
2022-11-23 00:37:06,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:06,075 INFO:     Epoch: 65
2022-11-23 00:37:06,853 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7738984437151388, 'Total loss': 0.7738984437151388} | train loss {'Reaction outcome loss': 0.8198987497358906, 'Total loss': 0.8198987497358906}
2022-11-23 00:37:06,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:06,853 INFO:     Epoch: 66
2022-11-23 00:37:07,668 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.79335782406005, 'Total loss': 0.79335782406005} | train loss {'Reaction outcome loss': 0.8202660383010397, 'Total loss': 0.8202660383010397}
2022-11-23 00:37:07,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:07,668 INFO:     Epoch: 67
2022-11-23 00:37:08,443 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7641839723695408, 'Total loss': 0.7641839723695408} | train loss {'Reaction outcome loss': 0.8197474489406663, 'Total loss': 0.8197474489406663}
2022-11-23 00:37:08,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:08,444 INFO:     Epoch: 68
2022-11-23 00:37:09,236 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7722152485088869, 'Total loss': 0.7722152485088869} | train loss {'Reaction outcome loss': 0.818245763803015, 'Total loss': 0.818245763803015}
2022-11-23 00:37:09,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:09,236 INFO:     Epoch: 69
2022-11-23 00:37:10,094 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7660008540207689, 'Total loss': 0.7660008540207689} | train loss {'Reaction outcome loss': 0.820084706252935, 'Total loss': 0.820084706252935}
2022-11-23 00:37:10,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:10,094 INFO:     Epoch: 70
2022-11-23 00:37:10,904 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7727041115814989, 'Total loss': 0.7727041115814989} | train loss {'Reaction outcome loss': 0.8170647905797375, 'Total loss': 0.8170647905797375}
2022-11-23 00:37:10,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:10,905 INFO:     Epoch: 71
2022-11-23 00:37:11,715 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7726174173029986, 'Total loss': 0.7726174173029986} | train loss {'Reaction outcome loss': 0.8197483482409497, 'Total loss': 0.8197483482409497}
2022-11-23 00:37:11,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:11,715 INFO:     Epoch: 72
2022-11-23 00:37:12,593 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7626092332330617, 'Total loss': 0.7626092332330617} | train loss {'Reaction outcome loss': 0.8221704001329383, 'Total loss': 0.8221704001329383}
2022-11-23 00:37:12,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:12,593 INFO:     Epoch: 73
2022-11-23 00:37:13,447 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7681675770066001, 'Total loss': 0.7681675770066001} | train loss {'Reaction outcome loss': 0.8210441442168489, 'Total loss': 0.8210441442168489}
2022-11-23 00:37:13,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:13,448 INFO:     Epoch: 74
2022-11-23 00:37:14,271 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7752115963534876, 'Total loss': 0.7752115963534876} | train loss {'Reaction outcome loss': 0.8162514659823203, 'Total loss': 0.8162514659823203}
2022-11-23 00:37:14,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:14,273 INFO:     Epoch: 75
2022-11-23 00:37:15,151 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7816361195661805, 'Total loss': 0.7816361195661805} | train loss {'Reaction outcome loss': 0.8180351541966808, 'Total loss': 0.8180351541966808}
2022-11-23 00:37:15,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:15,151 INFO:     Epoch: 76
2022-11-23 00:37:16,044 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7768983177163384, 'Total loss': 0.7768983177163384} | train loss {'Reaction outcome loss': 0.816267676377783, 'Total loss': 0.816267676377783}
2022-11-23 00:37:16,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:16,044 INFO:     Epoch: 77
2022-11-23 00:37:16,940 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7929394475438378, 'Total loss': 0.7929394475438378} | train loss {'Reaction outcome loss': 0.8176945665661169, 'Total loss': 0.8176945665661169}
2022-11-23 00:37:16,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:16,940 INFO:     Epoch: 78
2022-11-23 00:37:17,866 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7730432284826582, 'Total loss': 0.7730432284826582} | train loss {'Reaction outcome loss': 0.8207571432298544, 'Total loss': 0.8207571432298544}
2022-11-23 00:37:17,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:17,867 INFO:     Epoch: 79
2022-11-23 00:37:18,795 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7663759406317364, 'Total loss': 0.7663759406317364} | train loss {'Reaction outcome loss': 0.8159211473805564, 'Total loss': 0.8159211473805564}
2022-11-23 00:37:18,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:18,795 INFO:     Epoch: 80
2022-11-23 00:37:19,624 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7758628604086962, 'Total loss': 0.7758628604086962} | train loss {'Reaction outcome loss': 0.8167590900343291, 'Total loss': 0.8167590900343291}
2022-11-23 00:37:19,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:19,624 INFO:     Epoch: 81
2022-11-23 00:37:20,509 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7857595038684931, 'Total loss': 0.7857595038684931} | train loss {'Reaction outcome loss': 0.8128394115944297, 'Total loss': 0.8128394115944297}
2022-11-23 00:37:20,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:20,510 INFO:     Epoch: 82
2022-11-23 00:37:21,340 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7841047549789603, 'Total loss': 0.7841047549789603} | train loss {'Reaction outcome loss': 0.8173938087054662, 'Total loss': 0.8173938087054662}
2022-11-23 00:37:21,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:21,340 INFO:     Epoch: 83
2022-11-23 00:37:22,158 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.787853057411584, 'Total loss': 0.787853057411584} | train loss {'Reaction outcome loss': 0.8177931064245653, 'Total loss': 0.8177931064245653}
2022-11-23 00:37:22,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:22,159 INFO:     Epoch: 84
2022-11-23 00:37:23,005 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7579270418394696, 'Total loss': 0.7579270418394696} | train loss {'Reaction outcome loss': 0.8167932425226484, 'Total loss': 0.8167932425226484}
2022-11-23 00:37:23,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:23,005 INFO:     Epoch: 85
2022-11-23 00:37:23,859 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7797743061726744, 'Total loss': 0.7797743061726744} | train loss {'Reaction outcome loss': 0.8181149493674843, 'Total loss': 0.8181149493674843}
2022-11-23 00:37:23,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:23,859 INFO:     Epoch: 86
2022-11-23 00:37:24,705 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7592356699434194, 'Total loss': 0.7592356699434194} | train loss {'Reaction outcome loss': 0.8153264956814902, 'Total loss': 0.8153264956814902}
2022-11-23 00:37:24,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:24,706 INFO:     Epoch: 87
2022-11-23 00:37:25,556 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7744125371629541, 'Total loss': 0.7744125371629541} | train loss {'Reaction outcome loss': 0.8184608022777402, 'Total loss': 0.8184608022777402}
2022-11-23 00:37:25,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:25,556 INFO:     Epoch: 88
2022-11-23 00:37:26,408 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7760059176520868, 'Total loss': 0.7760059176520868} | train loss {'Reaction outcome loss': 0.816865493326771, 'Total loss': 0.816865493326771}
2022-11-23 00:37:26,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:26,408 INFO:     Epoch: 89
2022-11-23 00:37:27,239 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7742224721746012, 'Total loss': 0.7742224721746012} | train loss {'Reaction outcome loss': 0.816232828461394, 'Total loss': 0.816232828461394}
2022-11-23 00:37:27,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:27,240 INFO:     Epoch: 90
2022-11-23 00:37:28,096 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7800056270577691, 'Total loss': 0.7800056270577691} | train loss {'Reaction outcome loss': 0.8173433674841512, 'Total loss': 0.8173433674841512}
2022-11-23 00:37:28,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:28,096 INFO:     Epoch: 91
2022-11-23 00:37:28,934 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7595849128609354, 'Total loss': 0.7595849128609354} | train loss {'Reaction outcome loss': 0.8190325207248026, 'Total loss': 0.8190325207248026}
2022-11-23 00:37:28,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:28,934 INFO:     Epoch: 92
2022-11-23 00:37:29,771 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7557722546837546, 'Total loss': 0.7557722546837546} | train loss {'Reaction outcome loss': 0.8181544896291226, 'Total loss': 0.8181544896291226}
2022-11-23 00:37:29,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:29,771 INFO:     Epoch: 93
2022-11-23 00:37:30,634 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.772206914018501, 'Total loss': 0.772206914018501} | train loss {'Reaction outcome loss': 0.805183492266402, 'Total loss': 0.805183492266402}
2022-11-23 00:37:30,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:30,634 INFO:     Epoch: 94
2022-11-23 00:37:31,504 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7834659445692193, 'Total loss': 0.7834659445692193} | train loss {'Reaction outcome loss': 0.8150204622015661, 'Total loss': 0.8150204622015661}
2022-11-23 00:37:31,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:31,504 INFO:     Epoch: 95
2022-11-23 00:37:32,366 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7745938761667772, 'Total loss': 0.7745938761667772} | train loss {'Reaction outcome loss': 0.8098145843768606, 'Total loss': 0.8098145843768606}
2022-11-23 00:37:32,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:32,367 INFO:     Epoch: 96
2022-11-23 00:37:33,234 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7485035928812894, 'Total loss': 0.7485035928812894} | train loss {'Reaction outcome loss': 0.8149867140516943, 'Total loss': 0.8149867140516943}
2022-11-23 00:37:33,235 INFO:     Found new best model at epoch 96
2022-11-23 00:37:33,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:33,235 INFO:     Epoch: 97
2022-11-23 00:37:34,087 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7634592869065024, 'Total loss': 0.7634592869065024} | train loss {'Reaction outcome loss': 0.8183717648593747, 'Total loss': 0.8183717648593747}
2022-11-23 00:37:34,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:34,087 INFO:     Epoch: 98
2022-11-23 00:37:35,012 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7656907188621435, 'Total loss': 0.7656907188621435} | train loss {'Reaction outcome loss': 0.8107077852803833, 'Total loss': 0.8107077852803833}
2022-11-23 00:37:35,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:35,012 INFO:     Epoch: 99
2022-11-23 00:37:35,848 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.759381116791205, 'Total loss': 0.759381116791205} | train loss {'Reaction outcome loss': 0.817909875451302, 'Total loss': 0.817909875451302}
2022-11-23 00:37:35,848 INFO:     Best model found after epoch 97 of 100.
2022-11-23 00:37:35,849 INFO:   Done with stage: TRAINING
2022-11-23 00:37:35,849 INFO:   Starting stage: EVALUATION
2022-11-23 00:37:35,979 INFO:   Done with stage: EVALUATION
2022-11-23 00:37:35,979 INFO:   Leaving out SEQ value Fold_3
2022-11-23 00:37:35,993 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-23 00:37:35,993 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:37:36,692 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:37:36,692 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:37:36,764 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:37:36,765 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:37:36,765 INFO:     No hyperparam tuning for this model
2022-11-23 00:37:36,765 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:37:36,765 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:37:36,766 INFO:     None feature selector for col prot
2022-11-23 00:37:36,766 INFO:     None feature selector for col prot
2022-11-23 00:37:36,766 INFO:     None feature selector for col prot
2022-11-23 00:37:36,767 INFO:     None feature selector for col chem
2022-11-23 00:37:36,767 INFO:     None feature selector for col chem
2022-11-23 00:37:36,767 INFO:     None feature selector for col chem
2022-11-23 00:37:36,767 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:37:36,767 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:37:36,768 INFO:     Number of params in model 168571
2022-11-23 00:37:36,772 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:37:36,772 INFO:   Starting stage: TRAINING
2022-11-23 00:37:36,832 INFO:     Val loss before train {'Reaction outcome loss': 0.9970555194588595, 'Total loss': 0.9970555194588595}
2022-11-23 00:37:36,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:36,832 INFO:     Epoch: 0
2022-11-23 00:37:37,707 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8506263522214668, 'Total loss': 0.8506263522214668} | train loss {'Reaction outcome loss': 0.8899412831810655, 'Total loss': 0.8899412831810655}
2022-11-23 00:37:37,707 INFO:     Found new best model at epoch 0
2022-11-23 00:37:37,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:37,708 INFO:     Epoch: 1
2022-11-23 00:37:38,535 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8455031091390655, 'Total loss': 0.8455031091390655} | train loss {'Reaction outcome loss': 0.8627214161831824, 'Total loss': 0.8627214161831824}
2022-11-23 00:37:38,535 INFO:     Found new best model at epoch 1
2022-11-23 00:37:38,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:38,537 INFO:     Epoch: 2
2022-11-23 00:37:39,425 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8335309091002442, 'Total loss': 0.8335309091002442} | train loss {'Reaction outcome loss': 0.8545007203690341, 'Total loss': 0.8545007203690341}
2022-11-23 00:37:39,425 INFO:     Found new best model at epoch 2
2022-11-23 00:37:39,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:39,426 INFO:     Epoch: 3
2022-11-23 00:37:40,250 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8510989394298819, 'Total loss': 0.8510989394298819} | train loss {'Reaction outcome loss': 0.8518279293765787, 'Total loss': 0.8518279293765787}
2022-11-23 00:37:40,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:40,251 INFO:     Epoch: 4
2022-11-23 00:37:41,109 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8313704618187838, 'Total loss': 0.8313704618187838} | train loss {'Reaction outcome loss': 0.8514357473029465, 'Total loss': 0.8514357473029465}
2022-11-23 00:37:41,109 INFO:     Found new best model at epoch 4
2022-11-23 00:37:41,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:41,110 INFO:     Epoch: 5
2022-11-23 00:37:41,972 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8631759507711544, 'Total loss': 0.8631759507711544} | train loss {'Reaction outcome loss': 0.8472433162272953, 'Total loss': 0.8472433162272953}
2022-11-23 00:37:41,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:41,973 INFO:     Epoch: 6
2022-11-23 00:37:42,878 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8288910111715627, 'Total loss': 0.8288910111715627} | train loss {'Reaction outcome loss': 0.8485517120752178, 'Total loss': 0.8485517120752178}
2022-11-23 00:37:42,878 INFO:     Found new best model at epoch 6
2022-11-23 00:37:42,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:42,879 INFO:     Epoch: 7
2022-11-23 00:37:43,691 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8346313051013059, 'Total loss': 0.8346313051013059} | train loss {'Reaction outcome loss': 0.8372017361345838, 'Total loss': 0.8372017361345838}
2022-11-23 00:37:43,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:43,691 INFO:     Epoch: 8
2022-11-23 00:37:44,509 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8199774054593818, 'Total loss': 0.8199774054593818} | train loss {'Reaction outcome loss': 0.8431973787116223, 'Total loss': 0.8431973787116223}
2022-11-23 00:37:44,509 INFO:     Found new best model at epoch 8
2022-11-23 00:37:44,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:44,510 INFO:     Epoch: 9
2022-11-23 00:37:45,386 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8461844033973162, 'Total loss': 0.8461844033973162} | train loss {'Reaction outcome loss': 0.8366925033633826, 'Total loss': 0.8366925033633826}
2022-11-23 00:37:45,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:45,387 INFO:     Epoch: 10
2022-11-23 00:37:46,291 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8169737971106241, 'Total loss': 0.8169737971106241} | train loss {'Reaction outcome loss': 0.8395088782808819, 'Total loss': 0.8395088782808819}
2022-11-23 00:37:46,292 INFO:     Found new best model at epoch 10
2022-11-23 00:37:46,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:46,293 INFO:     Epoch: 11
2022-11-23 00:37:47,161 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8217570199522861, 'Total loss': 0.8217570199522861} | train loss {'Reaction outcome loss': 0.8355367164142796, 'Total loss': 0.8355367164142796}
2022-11-23 00:37:47,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:47,162 INFO:     Epoch: 12
2022-11-23 00:37:48,046 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8111782226451608, 'Total loss': 0.8111782226451608} | train loss {'Reaction outcome loss': 0.8381013297399537, 'Total loss': 0.8381013297399537}
2022-11-23 00:37:48,046 INFO:     Found new best model at epoch 12
2022-11-23 00:37:48,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:48,047 INFO:     Epoch: 13
2022-11-23 00:37:48,892 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8211962213349897, 'Total loss': 0.8211962213349897} | train loss {'Reaction outcome loss': 0.836795554053588, 'Total loss': 0.836795554053588}
2022-11-23 00:37:48,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:48,893 INFO:     Epoch: 14
2022-11-23 00:37:49,731 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.820653521737387, 'Total loss': 0.820653521737387} | train loss {'Reaction outcome loss': 0.835481015507315, 'Total loss': 0.835481015507315}
2022-11-23 00:37:49,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:49,731 INFO:     Epoch: 15
2022-11-23 00:37:50,579 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8246700333994489, 'Total loss': 0.8246700333994489} | train loss {'Reaction outcome loss': 0.8328480854874751, 'Total loss': 0.8328480854874751}
2022-11-23 00:37:50,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:50,579 INFO:     Epoch: 16
2022-11-23 00:37:51,467 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8232276197089705, 'Total loss': 0.8232276197089705} | train loss {'Reaction outcome loss': 0.8324197718843085, 'Total loss': 0.8324197718843085}
2022-11-23 00:37:51,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:51,468 INFO:     Epoch: 17
2022-11-23 00:37:52,309 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8210788091947866, 'Total loss': 0.8210788091947866} | train loss {'Reaction outcome loss': 0.8329412560971057, 'Total loss': 0.8329412560971057}
2022-11-23 00:37:52,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:52,309 INFO:     Epoch: 18
2022-11-23 00:37:53,173 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8358363786409068, 'Total loss': 0.8358363786409068} | train loss {'Reaction outcome loss': 0.831051594531927, 'Total loss': 0.831051594531927}
2022-11-23 00:37:53,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:53,173 INFO:     Epoch: 19
2022-11-23 00:37:54,089 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8261567991833354, 'Total loss': 0.8261567991833354} | train loss {'Reaction outcome loss': 0.8357033567106138, 'Total loss': 0.8357033567106138}
2022-11-23 00:37:54,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:54,090 INFO:     Epoch: 20
2022-11-23 00:37:54,992 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8265662817067878, 'Total loss': 0.8265662817067878} | train loss {'Reaction outcome loss': 0.8298911717338641, 'Total loss': 0.8298911717338641}
2022-11-23 00:37:54,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:54,992 INFO:     Epoch: 21
2022-11-23 00:37:55,879 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8292256399642589, 'Total loss': 0.8292256399642589} | train loss {'Reaction outcome loss': 0.8349847163333267, 'Total loss': 0.8349847163333267}
2022-11-23 00:37:55,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:55,879 INFO:     Epoch: 22
2022-11-23 00:37:56,729 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8087788577689681, 'Total loss': 0.8087788577689681} | train loss {'Reaction outcome loss': 0.8318323772705969, 'Total loss': 0.8318323772705969}
2022-11-23 00:37:56,729 INFO:     Found new best model at epoch 22
2022-11-23 00:37:56,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:56,730 INFO:     Epoch: 23
2022-11-23 00:37:57,597 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.820067411938379, 'Total loss': 0.820067411938379} | train loss {'Reaction outcome loss': 0.8323687573925393, 'Total loss': 0.8323687573925393}
2022-11-23 00:37:57,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:57,598 INFO:     Epoch: 24
2022-11-23 00:37:58,400 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8332430436167606, 'Total loss': 0.8332430436167606} | train loss {'Reaction outcome loss': 0.8348574998681663, 'Total loss': 0.8348574998681663}
2022-11-23 00:37:58,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:58,400 INFO:     Epoch: 25
2022-11-23 00:37:59,280 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8177097966504652, 'Total loss': 0.8177097966504652} | train loss {'Reaction outcome loss': 0.8284708360423807, 'Total loss': 0.8284708360423807}
2022-11-23 00:37:59,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:37:59,280 INFO:     Epoch: 26
2022-11-23 00:38:00,179 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8223518341086632, 'Total loss': 0.8223518341086632} | train loss {'Reaction outcome loss': 0.8326499081048809, 'Total loss': 0.8326499081048809}
2022-11-23 00:38:00,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:00,180 INFO:     Epoch: 27
2022-11-23 00:38:01,042 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8180436949397243, 'Total loss': 0.8180436949397243} | train loss {'Reaction outcome loss': 0.8258720949047902, 'Total loss': 0.8258720949047902}
2022-11-23 00:38:01,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:01,043 INFO:     Epoch: 28
2022-11-23 00:38:01,915 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8161239485407985, 'Total loss': 0.8161239485407985} | train loss {'Reaction outcome loss': 0.8322100947137738, 'Total loss': 0.8322100947137738}
2022-11-23 00:38:01,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:01,915 INFO:     Epoch: 29
2022-11-23 00:38:02,801 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8304911817229071, 'Total loss': 0.8304911817229071} | train loss {'Reaction outcome loss': 0.8291790689356991, 'Total loss': 0.8291790689356991}
2022-11-23 00:38:02,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:02,801 INFO:     Epoch: 30
2022-11-23 00:38:03,631 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8332519198572913, 'Total loss': 0.8332519198572913} | train loss {'Reaction outcome loss': 0.8302822439152686, 'Total loss': 0.8302822439152686}
2022-11-23 00:38:03,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:03,633 INFO:     Epoch: 31
2022-11-23 00:38:04,500 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8245012780954671, 'Total loss': 0.8245012780954671} | train loss {'Reaction outcome loss': 0.8306723173524513, 'Total loss': 0.8306723173524513}
2022-11-23 00:38:04,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:04,500 INFO:     Epoch: 32
2022-11-23 00:38:05,347 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8108047822187113, 'Total loss': 0.8108047822187113} | train loss {'Reaction outcome loss': 0.8288868931961841, 'Total loss': 0.8288868931961841}
2022-11-23 00:38:05,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:05,347 INFO:     Epoch: 33
2022-11-23 00:38:06,216 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8159820097823476, 'Total loss': 0.8159820097823476} | train loss {'Reaction outcome loss': 0.8289827329457783, 'Total loss': 0.8289827329457783}
2022-11-23 00:38:06,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:06,216 INFO:     Epoch: 34
2022-11-23 00:38:07,083 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.817935933900434, 'Total loss': 0.817935933900434} | train loss {'Reaction outcome loss': 0.8298567581127901, 'Total loss': 0.8298567581127901}
2022-11-23 00:38:07,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:07,083 INFO:     Epoch: 35
2022-11-23 00:38:07,939 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.813771337963814, 'Total loss': 0.813771337963814} | train loss {'Reaction outcome loss': 0.8341719608326428, 'Total loss': 0.8341719608326428}
2022-11-23 00:38:07,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:07,939 INFO:     Epoch: 36
2022-11-23 00:38:08,797 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8270029910775119, 'Total loss': 0.8270029910775119} | train loss {'Reaction outcome loss': 0.8298195108282761, 'Total loss': 0.8298195108282761}
2022-11-23 00:38:08,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:08,797 INFO:     Epoch: 37
2022-11-23 00:38:09,660 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8052604004394176, 'Total loss': 0.8052604004394176} | train loss {'Reaction outcome loss': 0.8276203506794132, 'Total loss': 0.8276203506794132}
2022-11-23 00:38:09,660 INFO:     Found new best model at epoch 37
2022-11-23 00:38:09,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:09,661 INFO:     Epoch: 38
2022-11-23 00:38:10,499 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8196729740431142, 'Total loss': 0.8196729740431142} | train loss {'Reaction outcome loss': 0.8259681563396923, 'Total loss': 0.8259681563396923}
2022-11-23 00:38:10,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:10,499 INFO:     Epoch: 39
2022-11-23 00:38:11,354 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8205283679241357, 'Total loss': 0.8205283679241357} | train loss {'Reaction outcome loss': 0.8250818269052467, 'Total loss': 0.8250818269052467}
2022-11-23 00:38:11,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:11,354 INFO:     Epoch: 40
2022-11-23 00:38:12,208 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8269400693649469, 'Total loss': 0.8269400693649469} | train loss {'Reaction outcome loss': 0.830702971972403, 'Total loss': 0.830702971972403}
2022-11-23 00:38:12,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:12,208 INFO:     Epoch: 41
2022-11-23 00:38:13,042 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8118507966052654, 'Total loss': 0.8118507966052654} | train loss {'Reaction outcome loss': 0.8289384221444365, 'Total loss': 0.8289384221444365}
2022-11-23 00:38:13,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:13,043 INFO:     Epoch: 42
2022-11-23 00:38:13,889 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8341414443282194, 'Total loss': 0.8341414443282194} | train loss {'Reaction outcome loss': 0.8239618249115397, 'Total loss': 0.8239618249115397}
2022-11-23 00:38:13,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:13,889 INFO:     Epoch: 43
2022-11-23 00:38:14,747 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8219086188216542, 'Total loss': 0.8219086188216542} | train loss {'Reaction outcome loss': 0.8261701890923938, 'Total loss': 0.8261701890923938}
2022-11-23 00:38:14,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:14,747 INFO:     Epoch: 44
2022-11-23 00:38:15,636 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8280947721281717, 'Total loss': 0.8280947721281717} | train loss {'Reaction outcome loss': 0.8296180576330325, 'Total loss': 0.8296180576330325}
2022-11-23 00:38:15,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:15,637 INFO:     Epoch: 45
2022-11-23 00:38:16,457 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8405225034369979, 'Total loss': 0.8405225034369979} | train loss {'Reaction outcome loss': 0.8270514281313928, 'Total loss': 0.8270514281313928}
2022-11-23 00:38:16,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:16,458 INFO:     Epoch: 46
2022-11-23 00:38:17,320 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.817036849814792, 'Total loss': 0.817036849814792} | train loss {'Reaction outcome loss': 0.826105240671361, 'Total loss': 0.826105240671361}
2022-11-23 00:38:17,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:17,321 INFO:     Epoch: 47
2022-11-23 00:38:18,135 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8090284598428149, 'Total loss': 0.8090284598428149} | train loss {'Reaction outcome loss': 0.8266615822422699, 'Total loss': 0.8266615822422699}
2022-11-23 00:38:18,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:18,136 INFO:     Epoch: 48
2022-11-23 00:38:18,966 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8180414119432139, 'Total loss': 0.8180414119432139} | train loss {'Reaction outcome loss': 0.8301047140457591, 'Total loss': 0.8301047140457591}
2022-11-23 00:38:18,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:18,966 INFO:     Epoch: 49
2022-11-23 00:38:19,768 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8164983114530874, 'Total loss': 0.8164983114530874} | train loss {'Reaction outcome loss': 0.8260487840800989, 'Total loss': 0.8260487840800989}
2022-11-23 00:38:19,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:19,768 INFO:     Epoch: 50
2022-11-23 00:38:20,552 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8173386724882348, 'Total loss': 0.8173386724882348} | train loss {'Reaction outcome loss': 0.8285756273592104, 'Total loss': 0.8285756273592104}
2022-11-23 00:38:20,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:20,552 INFO:     Epoch: 51
2022-11-23 00:38:21,371 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8411252706549889, 'Total loss': 0.8411252706549889} | train loss {'Reaction outcome loss': 0.8292917693491841, 'Total loss': 0.8292917693491841}
2022-11-23 00:38:21,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:21,371 INFO:     Epoch: 52
2022-11-23 00:38:22,137 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8685047480949136, 'Total loss': 0.8685047480949136} | train loss {'Reaction outcome loss': 0.828767009568019, 'Total loss': 0.828767009568019}
2022-11-23 00:38:22,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:22,137 INFO:     Epoch: 53
2022-11-23 00:38:22,969 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8154033457123956, 'Total loss': 0.8154033457123956} | train loss {'Reaction outcome loss': 0.8277723783108054, 'Total loss': 0.8277723783108054}
2022-11-23 00:38:22,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:22,970 INFO:     Epoch: 54
2022-11-23 00:38:23,776 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8070268326027449, 'Total loss': 0.8070268326027449} | train loss {'Reaction outcome loss': 0.8324554525926465, 'Total loss': 0.8324554525926465}
2022-11-23 00:38:23,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:23,776 INFO:     Epoch: 55
2022-11-23 00:38:24,595 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8147009590337443, 'Total loss': 0.8147009590337443} | train loss {'Reaction outcome loss': 0.8324728700958315, 'Total loss': 0.8324728700958315}
2022-11-23 00:38:24,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:24,596 INFO:     Epoch: 56
2022-11-23 00:38:25,414 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8172771369301995, 'Total loss': 0.8172771369301995} | train loss {'Reaction outcome loss': 0.8233977048123469, 'Total loss': 0.8233977048123469}
2022-11-23 00:38:25,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:25,415 INFO:     Epoch: 57
2022-11-23 00:38:26,263 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8199866982393487, 'Total loss': 0.8199866982393487} | train loss {'Reaction outcome loss': 0.8291883418550257, 'Total loss': 0.8291883418550257}
2022-11-23 00:38:26,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:26,263 INFO:     Epoch: 58
2022-11-23 00:38:27,094 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8076215289359869, 'Total loss': 0.8076215289359869} | train loss {'Reaction outcome loss': 0.8288242367447399, 'Total loss': 0.8288242367447399}
2022-11-23 00:38:27,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:27,094 INFO:     Epoch: 59
2022-11-23 00:38:27,884 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8243607913338861, 'Total loss': 0.8243607913338861} | train loss {'Reaction outcome loss': 0.823333953491977, 'Total loss': 0.823333953491977}
2022-11-23 00:38:27,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:27,884 INFO:     Epoch: 60
2022-11-23 00:38:28,679 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8100728025270063, 'Total loss': 0.8100728025270063} | train loss {'Reaction outcome loss': 0.8298619209987218, 'Total loss': 0.8298619209987218}
2022-11-23 00:38:28,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:28,679 INFO:     Epoch: 61
2022-11-23 00:38:29,497 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8194073507952135, 'Total loss': 0.8194073507952135} | train loss {'Reaction outcome loss': 0.8311397981692533, 'Total loss': 0.8311397981692533}
2022-11-23 00:38:29,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:29,497 INFO:     Epoch: 62
2022-11-23 00:38:30,286 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8090205837127774, 'Total loss': 0.8090205837127774} | train loss {'Reaction outcome loss': 0.8324465481717078, 'Total loss': 0.8324465481717078}
2022-11-23 00:38:30,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:30,286 INFO:     Epoch: 63
2022-11-23 00:38:31,024 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.817658030709555, 'Total loss': 0.817658030709555} | train loss {'Reaction outcome loss': 0.8226786592944724, 'Total loss': 0.8226786592944724}
2022-11-23 00:38:31,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:31,025 INFO:     Epoch: 64
2022-11-23 00:38:31,858 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8158499889595564, 'Total loss': 0.8158499889595564} | train loss {'Reaction outcome loss': 0.8245854644013233, 'Total loss': 0.8245854644013233}
2022-11-23 00:38:31,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:31,858 INFO:     Epoch: 65
2022-11-23 00:38:32,677 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.816885000051454, 'Total loss': 0.816885000051454} | train loss {'Reaction outcome loss': 0.8273784254418045, 'Total loss': 0.8273784254418045}
2022-11-23 00:38:32,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:32,677 INFO:     Epoch: 66
2022-11-23 00:38:33,495 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8485497381798056, 'Total loss': 0.8485497381798056} | train loss {'Reaction outcome loss': 0.8251973456535183, 'Total loss': 0.8251973456535183}
2022-11-23 00:38:33,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:33,495 INFO:     Epoch: 67
2022-11-23 00:38:34,334 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8022328379542328, 'Total loss': 0.8022328379542328} | train loss {'Reaction outcome loss': 0.831395111611632, 'Total loss': 0.831395111611632}
2022-11-23 00:38:34,334 INFO:     Found new best model at epoch 67
2022-11-23 00:38:34,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:34,336 INFO:     Epoch: 68
2022-11-23 00:38:35,139 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8045215398766273, 'Total loss': 0.8045215398766273} | train loss {'Reaction outcome loss': 0.8311175394986496, 'Total loss': 0.8311175394986496}
2022-11-23 00:38:35,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:35,140 INFO:     Epoch: 69
2022-11-23 00:38:35,939 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8319495126258495, 'Total loss': 0.8319495126258495} | train loss {'Reaction outcome loss': 0.8244637961758942, 'Total loss': 0.8244637961758942}
2022-11-23 00:38:35,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:35,939 INFO:     Epoch: 70
2022-11-23 00:38:36,739 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.822741046201351, 'Total loss': 0.822741046201351} | train loss {'Reaction outcome loss': 0.8278781902350363, 'Total loss': 0.8278781902350363}
2022-11-23 00:38:36,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:36,739 INFO:     Epoch: 71
2022-11-23 00:38:37,592 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8144969468893006, 'Total loss': 0.8144969468893006} | train loss {'Reaction outcome loss': 0.8233440684490516, 'Total loss': 0.8233440684490516}
2022-11-23 00:38:37,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:37,592 INFO:     Epoch: 72
2022-11-23 00:38:38,393 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8145607730676961, 'Total loss': 0.8145607730676961} | train loss {'Reaction outcome loss': 0.8281545013677879, 'Total loss': 0.8281545013677879}
2022-11-23 00:38:38,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:38,393 INFO:     Epoch: 73
2022-11-23 00:38:39,221 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7994486980660017, 'Total loss': 0.7994486980660017} | train loss {'Reaction outcome loss': 0.8253566726553635, 'Total loss': 0.8253566726553635}
2022-11-23 00:38:39,221 INFO:     Found new best model at epoch 73
2022-11-23 00:38:39,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:39,222 INFO:     Epoch: 74
2022-11-23 00:38:40,039 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.813100746897764, 'Total loss': 0.813100746897764} | train loss {'Reaction outcome loss': 0.8317725917354959, 'Total loss': 0.8317725917354959}
2022-11-23 00:38:40,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:40,039 INFO:     Epoch: 75
2022-11-23 00:38:40,810 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.811032410970954, 'Total loss': 0.811032410970954} | train loss {'Reaction outcome loss': 0.8243303968281043, 'Total loss': 0.8243303968281043}
2022-11-23 00:38:40,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:40,810 INFO:     Epoch: 76
2022-11-23 00:38:41,625 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8084144453669704, 'Total loss': 0.8084144453669704} | train loss {'Reaction outcome loss': 0.8244246989488602, 'Total loss': 0.8244246989488602}
2022-11-23 00:38:41,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:41,625 INFO:     Epoch: 77
2022-11-23 00:38:42,427 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8117835493974908, 'Total loss': 0.8117835493974908} | train loss {'Reaction outcome loss': 0.8264670033679634, 'Total loss': 0.8264670033679634}
2022-11-23 00:38:42,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:42,428 INFO:     Epoch: 78
2022-11-23 00:38:43,235 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8132655183936275, 'Total loss': 0.8132655183936275} | train loss {'Reaction outcome loss': 0.8293383338900863, 'Total loss': 0.8293383338900863}
2022-11-23 00:38:43,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:43,235 INFO:     Epoch: 79
2022-11-23 00:38:44,038 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8203964191813802, 'Total loss': 0.8203964191813802} | train loss {'Reaction outcome loss': 0.8222535180508114, 'Total loss': 0.8222535180508114}
2022-11-23 00:38:44,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:44,039 INFO:     Epoch: 80
2022-11-23 00:38:44,835 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8151288628578186, 'Total loss': 0.8151288628578186} | train loss {'Reaction outcome loss': 0.8275841822633978, 'Total loss': 0.8275841822633978}
2022-11-23 00:38:44,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:44,835 INFO:     Epoch: 81
2022-11-23 00:38:45,624 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8260290116764778, 'Total loss': 0.8260290116764778} | train loss {'Reaction outcome loss': 0.8254418356008217, 'Total loss': 0.8254418356008217}
2022-11-23 00:38:45,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:45,625 INFO:     Epoch: 82
2022-11-23 00:38:46,384 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8113623802051988, 'Total loss': 0.8113623802051988} | train loss {'Reaction outcome loss': 0.8250238735411988, 'Total loss': 0.8250238735411988}
2022-11-23 00:38:46,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:46,384 INFO:     Epoch: 83
2022-11-23 00:38:47,183 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8254121937030969, 'Total loss': 0.8254121937030969} | train loss {'Reaction outcome loss': 0.8264180785808407, 'Total loss': 0.8264180785808407}
2022-11-23 00:38:47,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:47,184 INFO:     Epoch: 84
2022-11-23 00:38:48,012 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.817370823649473, 'Total loss': 0.817370823649473} | train loss {'Reaction outcome loss': 0.8224334481065391, 'Total loss': 0.8224334481065391}
2022-11-23 00:38:48,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:48,012 INFO:     Epoch: 85
2022-11-23 00:38:48,844 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8371213577514471, 'Total loss': 0.8371213577514471} | train loss {'Reaction outcome loss': 0.8275007286765537, 'Total loss': 0.8275007286765537}
2022-11-23 00:38:48,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:48,844 INFO:     Epoch: 86
2022-11-23 00:38:49,607 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8079496012177578, 'Total loss': 0.8079496012177578} | train loss {'Reaction outcome loss': 0.8284421995526454, 'Total loss': 0.8284421995526454}
2022-11-23 00:38:49,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:49,607 INFO:     Epoch: 87
2022-11-23 00:38:50,438 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7960344040116598, 'Total loss': 0.7960344040116598} | train loss {'Reaction outcome loss': 0.8287918101080128, 'Total loss': 0.8287918101080128}
2022-11-23 00:38:50,439 INFO:     Found new best model at epoch 87
2022-11-23 00:38:50,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:50,439 INFO:     Epoch: 88
2022-11-23 00:38:51,206 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8063418359257454, 'Total loss': 0.8063418359257454} | train loss {'Reaction outcome loss': 0.8216985757233667, 'Total loss': 0.8216985757233667}
2022-11-23 00:38:51,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:51,206 INFO:     Epoch: 89
2022-11-23 00:38:51,989 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8146505279596462, 'Total loss': 0.8146505279596462} | train loss {'Reaction outcome loss': 0.8284767673152392, 'Total loss': 0.8284767673152392}
2022-11-23 00:38:51,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:51,989 INFO:     Epoch: 90
2022-11-23 00:38:52,748 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8301905837169913, 'Total loss': 0.8301905837169913} | train loss {'Reaction outcome loss': 0.8260738199851552, 'Total loss': 0.8260738199851552}
2022-11-23 00:38:52,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:52,749 INFO:     Epoch: 91
2022-11-23 00:38:53,540 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.806953115518703, 'Total loss': 0.806953115518703} | train loss {'Reaction outcome loss': 0.8206547325263258, 'Total loss': 0.8206547325263258}
2022-11-23 00:38:53,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:53,541 INFO:     Epoch: 92
2022-11-23 00:38:54,345 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8192790774411933, 'Total loss': 0.8192790774411933} | train loss {'Reaction outcome loss': 0.8275793628370176, 'Total loss': 0.8275793628370176}
2022-11-23 00:38:54,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:54,345 INFO:     Epoch: 93
2022-11-23 00:38:55,173 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8191700161889542, 'Total loss': 0.8191700161889542} | train loss {'Reaction outcome loss': 0.8262671753764153, 'Total loss': 0.8262671753764153}
2022-11-23 00:38:55,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:55,173 INFO:     Epoch: 94
2022-11-23 00:38:55,950 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8092582426791968, 'Total loss': 0.8092582426791968} | train loss {'Reaction outcome loss': 0.8206573040758978, 'Total loss': 0.8206573040758978}
2022-11-23 00:38:55,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:55,950 INFO:     Epoch: 95
2022-11-23 00:38:56,758 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8134256227071895, 'Total loss': 0.8134256227071895} | train loss {'Reaction outcome loss': 0.8244190095145194, 'Total loss': 0.8244190095145194}
2022-11-23 00:38:56,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:56,758 INFO:     Epoch: 96
2022-11-23 00:38:57,545 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8113489934178286, 'Total loss': 0.8113489934178286} | train loss {'Reaction outcome loss': 0.8301690299002851, 'Total loss': 0.8301690299002851}
2022-11-23 00:38:57,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:57,546 INFO:     Epoch: 97
2022-11-23 00:38:58,362 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8062290937401527, 'Total loss': 0.8062290937401527} | train loss {'Reaction outcome loss': 0.8248442470050249, 'Total loss': 0.8248442470050249}
2022-11-23 00:38:58,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:58,363 INFO:     Epoch: 98
2022-11-23 00:38:59,157 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8019004769103472, 'Total loss': 0.8019004769103472} | train loss {'Reaction outcome loss': 0.8248540520912311, 'Total loss': 0.8248540520912311}
2022-11-23 00:38:59,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:38:59,158 INFO:     Epoch: 99
2022-11-23 00:38:59,958 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8065036105555158, 'Total loss': 0.8065036105555158} | train loss {'Reaction outcome loss': 0.8204619422799251, 'Total loss': 0.8204619422799251}
2022-11-23 00:38:59,958 INFO:     Best model found after epoch 88 of 100.
2022-11-23 00:38:59,958 INFO:   Done with stage: TRAINING
2022-11-23 00:38:59,958 INFO:   Starting stage: EVALUATION
2022-11-23 00:39:00,095 INFO:   Done with stage: EVALUATION
2022-11-23 00:39:00,095 INFO:   Leaving out SEQ value Fold_4
2022-11-23 00:39:00,108 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 00:39:00,108 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:39:00,777 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:39:00,777 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:39:00,848 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:39:00,849 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:39:00,849 INFO:     No hyperparam tuning for this model
2022-11-23 00:39:00,849 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:39:00,849 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:39:00,850 INFO:     None feature selector for col prot
2022-11-23 00:39:00,850 INFO:     None feature selector for col prot
2022-11-23 00:39:00,850 INFO:     None feature selector for col prot
2022-11-23 00:39:00,851 INFO:     None feature selector for col chem
2022-11-23 00:39:00,851 INFO:     None feature selector for col chem
2022-11-23 00:39:00,851 INFO:     None feature selector for col chem
2022-11-23 00:39:00,851 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:39:00,851 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:39:00,852 INFO:     Number of params in model 168571
2022-11-23 00:39:00,856 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:39:00,856 INFO:   Starting stage: TRAINING
2022-11-23 00:39:00,914 INFO:     Val loss before train {'Reaction outcome loss': 1.026058092713356, 'Total loss': 1.026058092713356}
2022-11-23 00:39:00,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:00,914 INFO:     Epoch: 0
2022-11-23 00:39:01,737 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8743067180568521, 'Total loss': 0.8743067180568521} | train loss {'Reaction outcome loss': 0.8611658595262035, 'Total loss': 0.8611658595262035}
2022-11-23 00:39:01,737 INFO:     Found new best model at epoch 0
2022-11-23 00:39:01,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:01,738 INFO:     Epoch: 1
2022-11-23 00:39:02,530 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8861533471129157, 'Total loss': 0.8861533471129157} | train loss {'Reaction outcome loss': 0.8361788609575841, 'Total loss': 0.8361788609575841}
2022-11-23 00:39:02,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:02,531 INFO:     Epoch: 2
2022-11-23 00:39:03,353 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8518296060237017, 'Total loss': 0.8518296060237017} | train loss {'Reaction outcome loss': 0.8287736623277587, 'Total loss': 0.8287736623277587}
2022-11-23 00:39:03,353 INFO:     Found new best model at epoch 2
2022-11-23 00:39:03,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:03,354 INFO:     Epoch: 3
2022-11-23 00:39:04,160 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8797291381792589, 'Total loss': 0.8797291381792589} | train loss {'Reaction outcome loss': 0.8252131493101197, 'Total loss': 0.8252131493101197}
2022-11-23 00:39:04,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:04,161 INFO:     Epoch: 4
2022-11-23 00:39:04,968 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8444525856863369, 'Total loss': 0.8444525856863369} | train loss {'Reaction outcome loss': 0.8224188893312409, 'Total loss': 0.8224188893312409}
2022-11-23 00:39:04,968 INFO:     Found new best model at epoch 4
2022-11-23 00:39:04,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:04,969 INFO:     Epoch: 5
2022-11-23 00:39:05,787 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8442227420481768, 'Total loss': 0.8442227420481768} | train loss {'Reaction outcome loss': 0.8186192707188668, 'Total loss': 0.8186192707188668}
2022-11-23 00:39:05,788 INFO:     Found new best model at epoch 5
2022-11-23 00:39:05,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:05,789 INFO:     Epoch: 6
2022-11-23 00:39:06,595 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8515834246169437, 'Total loss': 0.8515834246169437} | train loss {'Reaction outcome loss': 0.8148584161554614, 'Total loss': 0.8148584161554614}
2022-11-23 00:39:06,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:06,596 INFO:     Epoch: 7
2022-11-23 00:39:07,405 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.851242489435456, 'Total loss': 0.851242489435456} | train loss {'Reaction outcome loss': 0.8123391357160383, 'Total loss': 0.8123391357160383}
2022-11-23 00:39:07,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:07,405 INFO:     Epoch: 8
2022-11-23 00:39:08,181 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8410865000703118, 'Total loss': 0.8410865000703118} | train loss {'Reaction outcome loss': 0.8098052708852675, 'Total loss': 0.8098052708852675}
2022-11-23 00:39:08,182 INFO:     Found new best model at epoch 8
2022-11-23 00:39:08,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:08,183 INFO:     Epoch: 9
2022-11-23 00:39:08,982 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8371517766605724, 'Total loss': 0.8371517766605724} | train loss {'Reaction outcome loss': 0.810496143155521, 'Total loss': 0.810496143155521}
2022-11-23 00:39:08,982 INFO:     Found new best model at epoch 9
2022-11-23 00:39:08,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:08,983 INFO:     Epoch: 10
2022-11-23 00:39:09,823 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8361076455224644, 'Total loss': 0.8361076455224644} | train loss {'Reaction outcome loss': 0.805637339670812, 'Total loss': 0.805637339670812}
2022-11-23 00:39:09,823 INFO:     Found new best model at epoch 10
2022-11-23 00:39:09,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:09,824 INFO:     Epoch: 11
2022-11-23 00:39:10,648 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8394401798194105, 'Total loss': 0.8394401798194105} | train loss {'Reaction outcome loss': 0.8053490810336605, 'Total loss': 0.8053490810336605}
2022-11-23 00:39:10,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:10,648 INFO:     Epoch: 12
2022-11-23 00:39:11,439 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8348645994609053, 'Total loss': 0.8348645994609053} | train loss {'Reaction outcome loss': 0.805474471421011, 'Total loss': 0.805474471421011}
2022-11-23 00:39:11,440 INFO:     Found new best model at epoch 12
2022-11-23 00:39:11,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:11,440 INFO:     Epoch: 13
2022-11-23 00:39:12,262 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8617931780490008, 'Total loss': 0.8617931780490008} | train loss {'Reaction outcome loss': 0.8076462456656079, 'Total loss': 0.8076462456656079}
2022-11-23 00:39:12,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:12,263 INFO:     Epoch: 14
2022-11-23 00:39:13,087 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8544314137913964, 'Total loss': 0.8544314137913964} | train loss {'Reaction outcome loss': 0.8011934346249027, 'Total loss': 0.8011934346249027}
2022-11-23 00:39:13,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:13,088 INFO:     Epoch: 15
2022-11-23 00:39:13,861 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.837756869467822, 'Total loss': 0.837756869467822} | train loss {'Reaction outcome loss': 0.809728784426566, 'Total loss': 0.809728784426566}
2022-11-23 00:39:13,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:13,862 INFO:     Epoch: 16
2022-11-23 00:39:14,692 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8692508427934214, 'Total loss': 0.8692508427934214} | train loss {'Reaction outcome loss': 0.8033272782641072, 'Total loss': 0.8033272782641072}
2022-11-23 00:39:14,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:14,692 INFO:     Epoch: 17
2022-11-23 00:39:15,500 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8750642687082291, 'Total loss': 0.8750642687082291} | train loss {'Reaction outcome loss': 0.8001515693481891, 'Total loss': 0.8001515693481891}
2022-11-23 00:39:15,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:15,500 INFO:     Epoch: 18
2022-11-23 00:39:16,279 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8338005197319117, 'Total loss': 0.8338005197319117} | train loss {'Reaction outcome loss': 0.7993810583026179, 'Total loss': 0.7993810583026179}
2022-11-23 00:39:16,279 INFO:     Found new best model at epoch 18
2022-11-23 00:39:16,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:16,280 INFO:     Epoch: 19
2022-11-23 00:39:17,097 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8479392928155985, 'Total loss': 0.8479392928155985} | train loss {'Reaction outcome loss': 0.804057197705392, 'Total loss': 0.804057197705392}
2022-11-23 00:39:17,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:17,097 INFO:     Epoch: 20
2022-11-23 00:39:17,952 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8399058891968294, 'Total loss': 0.8399058891968294} | train loss {'Reaction outcome loss': 0.8023125349033263, 'Total loss': 0.8023125349033263}
2022-11-23 00:39:17,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:17,953 INFO:     Epoch: 21
2022-11-23 00:39:18,776 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.836455446752635, 'Total loss': 0.836455446752635} | train loss {'Reaction outcome loss': 0.8061090719795996, 'Total loss': 0.8061090719795996}
2022-11-23 00:39:18,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:18,776 INFO:     Epoch: 22
2022-11-23 00:39:19,570 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8293121348727833, 'Total loss': 0.8293121348727833} | train loss {'Reaction outcome loss': 0.8006815514977901, 'Total loss': 0.8006815514977901}
2022-11-23 00:39:19,570 INFO:     Found new best model at epoch 22
2022-11-23 00:39:19,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:19,571 INFO:     Epoch: 23
2022-11-23 00:39:20,406 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8308533443645998, 'Total loss': 0.8308533443645998} | train loss {'Reaction outcome loss': 0.7992348374137955, 'Total loss': 0.7992348374137955}
2022-11-23 00:39:20,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:20,406 INFO:     Epoch: 24
2022-11-23 00:39:21,238 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8184279474345121, 'Total loss': 0.8184279474345121} | train loss {'Reaction outcome loss': 0.7986944844165156, 'Total loss': 0.7986944844165156}
2022-11-23 00:39:21,238 INFO:     Found new best model at epoch 24
2022-11-23 00:39:21,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:21,239 INFO:     Epoch: 25
2022-11-23 00:39:22,040 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8284407935359261, 'Total loss': 0.8284407935359261} | train loss {'Reaction outcome loss': 0.8002106039033782, 'Total loss': 0.8002106039033782}
2022-11-23 00:39:22,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:22,040 INFO:     Epoch: 26
2022-11-23 00:39:22,857 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8304664553566412, 'Total loss': 0.8304664553566412} | train loss {'Reaction outcome loss': 0.8028680892480958, 'Total loss': 0.8028680892480958}
2022-11-23 00:39:22,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:22,857 INFO:     Epoch: 27
2022-11-23 00:39:23,667 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8345866020430218, 'Total loss': 0.8345866020430218} | train loss {'Reaction outcome loss': 0.8018509556929911, 'Total loss': 0.8018509556929911}
2022-11-23 00:39:23,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:23,667 INFO:     Epoch: 28
2022-11-23 00:39:24,468 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8490057458931749, 'Total loss': 0.8490057458931749} | train loss {'Reaction outcome loss': 0.798947483541504, 'Total loss': 0.798947483541504}
2022-11-23 00:39:24,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:24,469 INFO:     Epoch: 29
2022-11-23 00:39:25,278 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8299858502366326, 'Total loss': 0.8299858502366326} | train loss {'Reaction outcome loss': 0.7994670607149601, 'Total loss': 0.7994670607149601}
2022-11-23 00:39:25,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:25,279 INFO:     Epoch: 30
2022-11-23 00:39:26,069 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8380128219723701, 'Total loss': 0.8380128219723701} | train loss {'Reaction outcome loss': 0.7957124867506565, 'Total loss': 0.7957124867506565}
2022-11-23 00:39:26,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:26,070 INFO:     Epoch: 31
2022-11-23 00:39:26,885 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8285419744524088, 'Total loss': 0.8285419744524088} | train loss {'Reaction outcome loss': 0.804622201188918, 'Total loss': 0.804622201188918}
2022-11-23 00:39:26,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:26,885 INFO:     Epoch: 32
2022-11-23 00:39:27,673 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8326832340522246, 'Total loss': 0.8326832340522246} | train loss {'Reaction outcome loss': 0.7996887257022243, 'Total loss': 0.7996887257022243}
2022-11-23 00:39:27,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:27,674 INFO:     Epoch: 33
2022-11-23 00:39:28,467 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8710545010187409, 'Total loss': 0.8710545010187409} | train loss {'Reaction outcome loss': 0.7947091088900643, 'Total loss': 0.7947091088900643}
2022-11-23 00:39:28,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:28,467 INFO:     Epoch: 34
2022-11-23 00:39:29,289 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.830151537602598, 'Total loss': 0.830151537602598} | train loss {'Reaction outcome loss': 0.8013679313082849, 'Total loss': 0.8013679313082849}
2022-11-23 00:39:29,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:29,289 INFO:     Epoch: 35
2022-11-23 00:39:30,130 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8420355489308183, 'Total loss': 0.8420355489308183} | train loss {'Reaction outcome loss': 0.7975216197871393, 'Total loss': 0.7975216197871393}
2022-11-23 00:39:30,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:30,130 INFO:     Epoch: 36
2022-11-23 00:39:30,913 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8330850025469606, 'Total loss': 0.8330850025469606} | train loss {'Reaction outcome loss': 0.7987676688259647, 'Total loss': 0.7987676688259647}
2022-11-23 00:39:30,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:30,913 INFO:     Epoch: 37
2022-11-23 00:39:31,729 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.828994784842838, 'Total loss': 0.828994784842838} | train loss {'Reaction outcome loss': 0.7976807377511456, 'Total loss': 0.7976807377511456}
2022-11-23 00:39:31,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:31,729 INFO:     Epoch: 38
2022-11-23 00:39:32,530 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8286231803623113, 'Total loss': 0.8286231803623113} | train loss {'Reaction outcome loss': 0.7979347053314408, 'Total loss': 0.7979347053314408}
2022-11-23 00:39:32,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:32,531 INFO:     Epoch: 39
2022-11-23 00:39:33,309 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.825284634124149, 'Total loss': 0.825284634124149} | train loss {'Reaction outcome loss': 0.7983811730819363, 'Total loss': 0.7983811730819363}
2022-11-23 00:39:33,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:33,309 INFO:     Epoch: 40
2022-11-23 00:39:34,093 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8264761919325049, 'Total loss': 0.8264761919325049} | train loss {'Reaction outcome loss': 0.7998765464271268, 'Total loss': 0.7998765464271268}
2022-11-23 00:39:34,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:34,093 INFO:     Epoch: 41
2022-11-23 00:39:34,933 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.831320119175044, 'Total loss': 0.831320119175044} | train loss {'Reaction outcome loss': 0.7993572148824891, 'Total loss': 0.7993572148824891}
2022-11-23 00:39:34,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:34,934 INFO:     Epoch: 42
2022-11-23 00:39:35,750 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.83336471833966, 'Total loss': 0.83336471833966} | train loss {'Reaction outcome loss': 0.8016455070145668, 'Total loss': 0.8016455070145668}
2022-11-23 00:39:35,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:35,750 INFO:     Epoch: 43
2022-11-23 00:39:36,557 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8218954489989714, 'Total loss': 0.8218954489989714} | train loss {'Reaction outcome loss': 0.7967035543293722, 'Total loss': 0.7967035543293722}
2022-11-23 00:39:36,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:36,558 INFO:     Epoch: 44
2022-11-23 00:39:37,346 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8244103769009764, 'Total loss': 0.8244103769009764} | train loss {'Reaction outcome loss': 0.7960895831065793, 'Total loss': 0.7960895831065793}
2022-11-23 00:39:37,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:37,346 INFO:     Epoch: 45
2022-11-23 00:39:38,141 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8380732197653163, 'Total loss': 0.8380732197653163} | train loss {'Reaction outcome loss': 0.7988008233087678, 'Total loss': 0.7988008233087678}
2022-11-23 00:39:38,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:38,141 INFO:     Epoch: 46
2022-11-23 00:39:38,917 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8790303455157713, 'Total loss': 0.8790303455157713} | train loss {'Reaction outcome loss': 0.7957150864024316, 'Total loss': 0.7957150864024316}
2022-11-23 00:39:38,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:38,917 INFO:     Epoch: 47
2022-11-23 00:39:39,687 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8194893314079805, 'Total loss': 0.8194893314079805} | train loss {'Reaction outcome loss': 0.801572227429959, 'Total loss': 0.801572227429959}
2022-11-23 00:39:39,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:39,687 INFO:     Epoch: 48
2022-11-23 00:39:40,466 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8456245972351595, 'Total loss': 0.8456245972351595} | train loss {'Reaction outcome loss': 0.7991920243347844, 'Total loss': 0.7991920243347844}
2022-11-23 00:39:40,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:40,466 INFO:     Epoch: 49
2022-11-23 00:39:41,255 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.832214662974531, 'Total loss': 0.832214662974531} | train loss {'Reaction outcome loss': 0.7980494683067645, 'Total loss': 0.7980494683067645}
2022-11-23 00:39:41,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:41,255 INFO:     Epoch: 50
2022-11-23 00:39:42,053 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8210726475173776, 'Total loss': 0.8210726475173776} | train loss {'Reaction outcome loss': 0.8002363396508079, 'Total loss': 0.8002363396508079}
2022-11-23 00:39:42,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:42,053 INFO:     Epoch: 51
2022-11-23 00:39:42,870 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8345646072517742, 'Total loss': 0.8345646072517742} | train loss {'Reaction outcome loss': 0.7945120806895918, 'Total loss': 0.7945120806895918}
2022-11-23 00:39:42,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:42,870 INFO:     Epoch: 52
2022-11-23 00:39:43,671 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8467912342060696, 'Total loss': 0.8467912342060696} | train loss {'Reaction outcome loss': 0.798902832091816, 'Total loss': 0.798902832091816}
2022-11-23 00:39:43,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:43,671 INFO:     Epoch: 53
2022-11-23 00:39:44,475 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8294919661500237, 'Total loss': 0.8294919661500237} | train loss {'Reaction outcome loss': 0.8010402808506643, 'Total loss': 0.8010402808506643}
2022-11-23 00:39:44,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:44,475 INFO:     Epoch: 54
2022-11-23 00:39:45,293 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8220208978111093, 'Total loss': 0.8220208978111093} | train loss {'Reaction outcome loss': 0.8030326725734819, 'Total loss': 0.8030326725734819}
2022-11-23 00:39:45,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:45,293 INFO:     Epoch: 55
2022-11-23 00:39:46,095 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8402542946013537, 'Total loss': 0.8402542946013537} | train loss {'Reaction outcome loss': 0.7961130234743318, 'Total loss': 0.7961130234743318}
2022-11-23 00:39:46,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:46,095 INFO:     Epoch: 56
2022-11-23 00:39:46,929 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8248115913434462, 'Total loss': 0.8248115913434462} | train loss {'Reaction outcome loss': 0.7962223987185186, 'Total loss': 0.7962223987185186}
2022-11-23 00:39:46,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:46,930 INFO:     Epoch: 57
2022-11-23 00:39:47,731 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8350048254836689, 'Total loss': 0.8350048254836689} | train loss {'Reaction outcome loss': 0.7938709214570061, 'Total loss': 0.7938709214570061}
2022-11-23 00:39:47,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:47,731 INFO:     Epoch: 58
2022-11-23 00:39:48,556 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8344081586057489, 'Total loss': 0.8344081586057489} | train loss {'Reaction outcome loss': 0.7992602961678659, 'Total loss': 0.7992602961678659}
2022-11-23 00:39:48,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:48,557 INFO:     Epoch: 59
2022-11-23 00:39:49,362 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.853017886931246, 'Total loss': 0.853017886931246} | train loss {'Reaction outcome loss': 0.7955252639949322, 'Total loss': 0.7955252639949322}
2022-11-23 00:39:49,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:49,362 INFO:     Epoch: 60
2022-11-23 00:39:50,142 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8250053118575703, 'Total loss': 0.8250053118575703} | train loss {'Reaction outcome loss': 0.7970180279545246, 'Total loss': 0.7970180279545246}
2022-11-23 00:39:50,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:50,142 INFO:     Epoch: 61
2022-11-23 00:39:50,946 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8297706016085364, 'Total loss': 0.8297706016085364} | train loss {'Reaction outcome loss': 0.7970586056190152, 'Total loss': 0.7970586056190152}
2022-11-23 00:39:50,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:50,946 INFO:     Epoch: 62
2022-11-23 00:39:51,780 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8340971361507069, 'Total loss': 0.8340971361507069} | train loss {'Reaction outcome loss': 0.7950361415503486, 'Total loss': 0.7950361415503486}
2022-11-23 00:39:51,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:51,780 INFO:     Epoch: 63
2022-11-23 00:39:52,636 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8142885132269426, 'Total loss': 0.8142885132269426} | train loss {'Reaction outcome loss': 0.7950552104701919, 'Total loss': 0.7950552104701919}
2022-11-23 00:39:52,636 INFO:     Found new best model at epoch 63
2022-11-23 00:39:52,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:52,637 INFO:     Epoch: 64
2022-11-23 00:39:53,472 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8314983648332682, 'Total loss': 0.8314983648332682} | train loss {'Reaction outcome loss': 0.7960301015165544, 'Total loss': 0.7960301015165544}
2022-11-23 00:39:53,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:53,473 INFO:     Epoch: 65
2022-11-23 00:39:54,269 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8393831015987829, 'Total loss': 0.8393831015987829} | train loss {'Reaction outcome loss': 0.7943243844614875, 'Total loss': 0.7943243844614875}
2022-11-23 00:39:54,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:54,269 INFO:     Epoch: 66
2022-11-23 00:39:55,037 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8272617906332016, 'Total loss': 0.8272617906332016} | train loss {'Reaction outcome loss': 0.7938167111527535, 'Total loss': 0.7938167111527535}
2022-11-23 00:39:55,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:55,038 INFO:     Epoch: 67
2022-11-23 00:39:55,813 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8264590230855074, 'Total loss': 0.8264590230855074} | train loss {'Reaction outcome loss': 0.7951367700532559, 'Total loss': 0.7951367700532559}
2022-11-23 00:39:55,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:55,813 INFO:     Epoch: 68
2022-11-23 00:39:56,576 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8223062293096022, 'Total loss': 0.8223062293096022} | train loss {'Reaction outcome loss': 0.7976186825863777, 'Total loss': 0.7976186825863777}
2022-11-23 00:39:56,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:56,576 INFO:     Epoch: 69
2022-11-23 00:39:57,369 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8200455809181387, 'Total loss': 0.8200455809181387} | train loss {'Reaction outcome loss': 0.7949284412447484, 'Total loss': 0.7949284412447484}
2022-11-23 00:39:57,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:57,369 INFO:     Epoch: 70
2022-11-23 00:39:58,149 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8196456012400714, 'Total loss': 0.8196456012400714} | train loss {'Reaction outcome loss': 0.790628204542783, 'Total loss': 0.790628204542783}
2022-11-23 00:39:58,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:58,150 INFO:     Epoch: 71
2022-11-23 00:39:58,905 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.816463477909565, 'Total loss': 0.816463477909565} | train loss {'Reaction outcome loss': 0.7909267037626235, 'Total loss': 0.7909267037626235}
2022-11-23 00:39:58,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:58,905 INFO:     Epoch: 72
2022-11-23 00:39:59,734 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8287520882758227, 'Total loss': 0.8287520882758227} | train loss {'Reaction outcome loss': 0.7941668809902284, 'Total loss': 0.7941668809902284}
2022-11-23 00:39:59,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:39:59,735 INFO:     Epoch: 73
2022-11-23 00:40:00,520 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8395389684221961, 'Total loss': 0.8395389684221961} | train loss {'Reaction outcome loss': 0.7972394946602083, 'Total loss': 0.7972394946602083}
2022-11-23 00:40:00,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:00,520 INFO:     Epoch: 74
2022-11-23 00:40:01,361 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8690368363803084, 'Total loss': 0.8690368363803084} | train loss {'Reaction outcome loss': 0.7905436822723958, 'Total loss': 0.7905436822723958}
2022-11-23 00:40:01,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:01,362 INFO:     Epoch: 75
2022-11-23 00:40:02,170 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8292627890001644, 'Total loss': 0.8292627890001644} | train loss {'Reaction outcome loss': 0.7944877778570498, 'Total loss': 0.7944877778570498}
2022-11-23 00:40:02,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:02,170 INFO:     Epoch: 76
2022-11-23 00:40:02,984 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8290141705762256, 'Total loss': 0.8290141705762256} | train loss {'Reaction outcome loss': 0.7956240965474036, 'Total loss': 0.7956240965474036}
2022-11-23 00:40:02,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:02,984 INFO:     Epoch: 77
2022-11-23 00:40:03,754 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8144530762325634, 'Total loss': 0.8144530762325634} | train loss {'Reaction outcome loss': 0.7954500786239102, 'Total loss': 0.7954500786239102}
2022-11-23 00:40:03,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:03,754 INFO:     Epoch: 78
2022-11-23 00:40:04,620 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8873877972364426, 'Total loss': 0.8873877972364426} | train loss {'Reaction outcome loss': 0.7943433351334064, 'Total loss': 0.7943433351334064}
2022-11-23 00:40:04,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:04,620 INFO:     Epoch: 79
2022-11-23 00:40:05,418 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8286512304436077, 'Total loss': 0.8286512304436077} | train loss {'Reaction outcome loss': 0.7977186457043693, 'Total loss': 0.7977186457043693}
2022-11-23 00:40:05,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:05,419 INFO:     Epoch: 80
2022-11-23 00:40:06,205 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8236031667752699, 'Total loss': 0.8236031667752699} | train loss {'Reaction outcome loss': 0.8021492727341191, 'Total loss': 0.8021492727341191}
2022-11-23 00:40:06,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:06,205 INFO:     Epoch: 81
2022-11-23 00:40:07,015 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8448512669314038, 'Total loss': 0.8448512669314038} | train loss {'Reaction outcome loss': 0.7960478556492636, 'Total loss': 0.7960478556492636}
2022-11-23 00:40:07,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:07,016 INFO:     Epoch: 82
2022-11-23 00:40:07,873 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8745144361799414, 'Total loss': 0.8745144361799414} | train loss {'Reaction outcome loss': 0.7960996543688159, 'Total loss': 0.7960996543688159}
2022-11-23 00:40:07,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:07,874 INFO:     Epoch: 83
2022-11-23 00:40:08,702 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8328348885882985, 'Total loss': 0.8328348885882985} | train loss {'Reaction outcome loss': 0.7962047903528137, 'Total loss': 0.7962047903528137}
2022-11-23 00:40:08,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:08,702 INFO:     Epoch: 84
2022-11-23 00:40:09,509 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8380657989870418, 'Total loss': 0.8380657989870418} | train loss {'Reaction outcome loss': 0.7945130114113131, 'Total loss': 0.7945130114113131}
2022-11-23 00:40:09,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:09,510 INFO:     Epoch: 85
2022-11-23 00:40:10,325 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8256185054779053, 'Total loss': 0.8256185054779053} | train loss {'Reaction outcome loss': 0.7991596335364927, 'Total loss': 0.7991596335364927}
2022-11-23 00:40:10,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:10,325 INFO:     Epoch: 86
2022-11-23 00:40:11,094 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.835868782617829, 'Total loss': 0.835868782617829} | train loss {'Reaction outcome loss': 0.7966692351525829, 'Total loss': 0.7966692351525829}
2022-11-23 00:40:11,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:11,095 INFO:     Epoch: 87
2022-11-23 00:40:11,872 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8327366879040544, 'Total loss': 0.8327366879040544} | train loss {'Reaction outcome loss': 0.7975894878468206, 'Total loss': 0.7975894878468206}
2022-11-23 00:40:11,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:11,872 INFO:     Epoch: 88
2022-11-23 00:40:12,671 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8405997888608412, 'Total loss': 0.8405997888608412} | train loss {'Reaction outcome loss': 0.7955063696830503, 'Total loss': 0.7955063696830503}
2022-11-23 00:40:12,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:12,671 INFO:     Epoch: 89
2022-11-23 00:40:13,511 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.816976704380729, 'Total loss': 0.816976704380729} | train loss {'Reaction outcome loss': 0.7970672774939768, 'Total loss': 0.7970672774939768}
2022-11-23 00:40:13,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:13,511 INFO:     Epoch: 90
2022-11-23 00:40:14,332 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8307224335995588, 'Total loss': 0.8307224335995588} | train loss {'Reaction outcome loss': 0.7967601593944335, 'Total loss': 0.7967601593944335}
2022-11-23 00:40:14,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:14,332 INFO:     Epoch: 91
2022-11-23 00:40:15,108 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8289756036617539, 'Total loss': 0.8289756036617539} | train loss {'Reaction outcome loss': 0.7988148468636698, 'Total loss': 0.7988148468636698}
2022-11-23 00:40:15,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:15,109 INFO:     Epoch: 92
2022-11-23 00:40:15,911 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8424345207485285, 'Total loss': 0.8424345207485285} | train loss {'Reaction outcome loss': 0.7904179278881319, 'Total loss': 0.7904179278881319}
2022-11-23 00:40:15,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:15,911 INFO:     Epoch: 93
2022-11-23 00:40:16,713 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8236851712519472, 'Total loss': 0.8236851712519472} | train loss {'Reaction outcome loss': 0.7978852689266205, 'Total loss': 0.7978852689266205}
2022-11-23 00:40:16,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:16,714 INFO:     Epoch: 94
2022-11-23 00:40:17,543 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8297150338237936, 'Total loss': 0.8297150338237936} | train loss {'Reaction outcome loss': 0.7936523616794617, 'Total loss': 0.7936523616794617}
2022-11-23 00:40:17,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:17,543 INFO:     Epoch: 95
2022-11-23 00:40:18,337 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8547016009688377, 'Total loss': 0.8547016009688377} | train loss {'Reaction outcome loss': 0.7888065635436966, 'Total loss': 0.7888065635436966}
2022-11-23 00:40:18,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:18,337 INFO:     Epoch: 96
2022-11-23 00:40:19,150 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.842262127860026, 'Total loss': 0.842262127860026} | train loss {'Reaction outcome loss': 0.7919819397070715, 'Total loss': 0.7919819397070715}
2022-11-23 00:40:19,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:19,150 INFO:     Epoch: 97
2022-11-23 00:40:19,978 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.810588926076889, 'Total loss': 0.810588926076889} | train loss {'Reaction outcome loss': 0.7916562491126599, 'Total loss': 0.7916562491126599}
2022-11-23 00:40:19,979 INFO:     Found new best model at epoch 97
2022-11-23 00:40:19,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:19,980 INFO:     Epoch: 98
2022-11-23 00:40:20,797 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8194587291641668, 'Total loss': 0.8194587291641668} | train loss {'Reaction outcome loss': 0.7956028709248189, 'Total loss': 0.7956028709248189}
2022-11-23 00:40:20,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:20,797 INFO:     Epoch: 99
2022-11-23 00:40:21,609 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8462540243159641, 'Total loss': 0.8462540243159641} | train loss {'Reaction outcome loss': 0.7980646369678359, 'Total loss': 0.7980646369678359}
2022-11-23 00:40:21,609 INFO:     Best model found after epoch 98 of 100.
2022-11-23 00:40:21,609 INFO:   Done with stage: TRAINING
2022-11-23 00:40:21,609 INFO:   Starting stage: EVALUATION
2022-11-23 00:40:21,728 INFO:   Done with stage: EVALUATION
2022-11-23 00:40:21,729 INFO:   Leaving out SEQ value Fold_5
2022-11-23 00:40:21,742 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 00:40:21,742 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:40:22,411 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:40:22,412 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:40:22,483 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:40:22,483 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:40:22,483 INFO:     No hyperparam tuning for this model
2022-11-23 00:40:22,483 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:40:22,483 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:40:22,484 INFO:     None feature selector for col prot
2022-11-23 00:40:22,484 INFO:     None feature selector for col prot
2022-11-23 00:40:22,484 INFO:     None feature selector for col prot
2022-11-23 00:40:22,485 INFO:     None feature selector for col chem
2022-11-23 00:40:22,485 INFO:     None feature selector for col chem
2022-11-23 00:40:22,485 INFO:     None feature selector for col chem
2022-11-23 00:40:22,485 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:40:22,485 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:40:22,487 INFO:     Number of params in model 168571
2022-11-23 00:40:22,490 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:40:22,490 INFO:   Starting stage: TRAINING
2022-11-23 00:40:22,548 INFO:     Val loss before train {'Reaction outcome loss': 1.021807373924689, 'Total loss': 1.021807373924689}
2022-11-23 00:40:22,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:22,548 INFO:     Epoch: 0
2022-11-23 00:40:23,334 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8826019696213983, 'Total loss': 0.8826019696213983} | train loss {'Reaction outcome loss': 0.8892395300490241, 'Total loss': 0.8892395300490241}
2022-11-23 00:40:23,334 INFO:     Found new best model at epoch 0
2022-11-23 00:40:23,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:23,335 INFO:     Epoch: 1
2022-11-23 00:40:24,125 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8632206456227736, 'Total loss': 0.8632206456227736} | train loss {'Reaction outcome loss': 0.8524000367089626, 'Total loss': 0.8524000367089626}
2022-11-23 00:40:24,126 INFO:     Found new best model at epoch 1
2022-11-23 00:40:24,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:24,126 INFO:     Epoch: 2
2022-11-23 00:40:24,955 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8435728157108481, 'Total loss': 0.8435728157108481} | train loss {'Reaction outcome loss': 0.8505608511547889, 'Total loss': 0.8505608511547889}
2022-11-23 00:40:24,955 INFO:     Found new best model at epoch 2
2022-11-23 00:40:24,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:24,956 INFO:     Epoch: 3
2022-11-23 00:40:25,747 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8471563770012422, 'Total loss': 0.8471563770012422} | train loss {'Reaction outcome loss': 0.8443592997087587, 'Total loss': 0.8443592997087587}
2022-11-23 00:40:25,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:25,747 INFO:     Epoch: 4
2022-11-23 00:40:26,590 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8550903038545088, 'Total loss': 0.8550903038545088} | train loss {'Reaction outcome loss': 0.842580595444287, 'Total loss': 0.842580595444287}
2022-11-23 00:40:26,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:26,591 INFO:     Epoch: 5
2022-11-23 00:40:27,420 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8487757647579367, 'Total loss': 0.8487757647579367} | train loss {'Reaction outcome loss': 0.8366727532157975, 'Total loss': 0.8366727532157975}
2022-11-23 00:40:27,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:27,420 INFO:     Epoch: 6
2022-11-23 00:40:28,184 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.860888500105251, 'Total loss': 0.860888500105251} | train loss {'Reaction outcome loss': 0.8389942245858331, 'Total loss': 0.8389942245858331}
2022-11-23 00:40:28,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:28,185 INFO:     Epoch: 7
2022-11-23 00:40:28,984 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8771837665276094, 'Total loss': 0.8771837665276094} | train loss {'Reaction outcome loss': 0.8390210881348579, 'Total loss': 0.8390210881348579}
2022-11-23 00:40:28,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:28,985 INFO:     Epoch: 8
2022-11-23 00:40:29,755 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8386030237783085, 'Total loss': 0.8386030237783085} | train loss {'Reaction outcome loss': 0.8334223173799054, 'Total loss': 0.8334223173799054}
2022-11-23 00:40:29,756 INFO:     Found new best model at epoch 8
2022-11-23 00:40:29,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:29,757 INFO:     Epoch: 9
2022-11-23 00:40:30,555 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8550937257029794, 'Total loss': 0.8550937257029794} | train loss {'Reaction outcome loss': 0.8285426702951232, 'Total loss': 0.8285426702951232}
2022-11-23 00:40:30,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:30,555 INFO:     Epoch: 10
2022-11-23 00:40:31,343 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8530184870416467, 'Total loss': 0.8530184870416467} | train loss {'Reaction outcome loss': 0.8288172700953099, 'Total loss': 0.8288172700953099}
2022-11-23 00:40:31,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:31,344 INFO:     Epoch: 11
2022-11-23 00:40:32,130 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8662097345698964, 'Total loss': 0.8662097345698964} | train loss {'Reaction outcome loss': 0.8299972126560826, 'Total loss': 0.8299972126560826}
2022-11-23 00:40:32,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:32,130 INFO:     Epoch: 12
2022-11-23 00:40:32,928 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8894662410020828, 'Total loss': 0.8894662410020828} | train loss {'Reaction outcome loss': 0.827365004127064, 'Total loss': 0.827365004127064}
2022-11-23 00:40:32,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:32,928 INFO:     Epoch: 13
2022-11-23 00:40:33,737 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8452169136567549, 'Total loss': 0.8452169136567549} | train loss {'Reaction outcome loss': 0.8273166996096412, 'Total loss': 0.8273166996096412}
2022-11-23 00:40:33,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:33,737 INFO:     Epoch: 14
2022-11-23 00:40:34,565 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8558280948888172, 'Total loss': 0.8558280948888172} | train loss {'Reaction outcome loss': 0.8210672184584602, 'Total loss': 0.8210672184584602}
2022-11-23 00:40:34,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:34,565 INFO:     Epoch: 15
2022-11-23 00:40:35,351 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8466390283270315, 'Total loss': 0.8466390283270315} | train loss {'Reaction outcome loss': 0.8272646574243423, 'Total loss': 0.8272646574243423}
2022-11-23 00:40:35,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:35,351 INFO:     Epoch: 16
2022-11-23 00:40:36,147 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8403265083378012, 'Total loss': 0.8403265083378012} | train loss {'Reaction outcome loss': 0.8271011823127347, 'Total loss': 0.8271011823127347}
2022-11-23 00:40:36,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:36,148 INFO:     Epoch: 17
2022-11-23 00:40:36,906 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8273632004857063, 'Total loss': 0.8273632004857063} | train loss {'Reaction outcome loss': 0.8259084200666796, 'Total loss': 0.8259084200666796}
2022-11-23 00:40:36,906 INFO:     Found new best model at epoch 17
2022-11-23 00:40:36,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:36,907 INFO:     Epoch: 18
2022-11-23 00:40:37,764 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8258176716891202, 'Total loss': 0.8258176716891202} | train loss {'Reaction outcome loss': 0.8239200565843813, 'Total loss': 0.8239200565843813}
2022-11-23 00:40:37,764 INFO:     Found new best model at epoch 18
2022-11-23 00:40:37,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:37,765 INFO:     Epoch: 19
2022-11-23 00:40:38,625 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8339133702895858, 'Total loss': 0.8339133702895858} | train loss {'Reaction outcome loss': 0.828285908386592, 'Total loss': 0.828285908386592}
2022-11-23 00:40:38,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:38,627 INFO:     Epoch: 20
2022-11-23 00:40:39,438 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8307540565729141, 'Total loss': 0.8307540565729141} | train loss {'Reaction outcome loss': 0.8232795531230588, 'Total loss': 0.8232795531230588}
2022-11-23 00:40:39,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:39,439 INFO:     Epoch: 21
2022-11-23 00:40:40,228 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8283693871714852, 'Total loss': 0.8283693871714852} | train loss {'Reaction outcome loss': 0.8319698518682872, 'Total loss': 0.8319698518682872}
2022-11-23 00:40:40,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:40,228 INFO:     Epoch: 22
2022-11-23 00:40:41,024 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8300912949171934, 'Total loss': 0.8300912949171934} | train loss {'Reaction outcome loss': 0.8231303880531942, 'Total loss': 0.8231303880531942}
2022-11-23 00:40:41,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:41,024 INFO:     Epoch: 23
2022-11-23 00:40:41,798 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8315523117780685, 'Total loss': 0.8315523117780685} | train loss {'Reaction outcome loss': 0.8254281654953957, 'Total loss': 0.8254281654953957}
2022-11-23 00:40:41,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:41,799 INFO:     Epoch: 24
2022-11-23 00:40:42,623 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8387136080048301, 'Total loss': 0.8387136080048301} | train loss {'Reaction outcome loss': 0.8253723754277152, 'Total loss': 0.8253723754277152}
2022-11-23 00:40:42,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:42,623 INFO:     Epoch: 25
2022-11-23 00:40:43,413 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8263659612698988, 'Total loss': 0.8263659612698988} | train loss {'Reaction outcome loss': 0.8246080254114443, 'Total loss': 0.8246080254114443}
2022-11-23 00:40:43,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:43,413 INFO:     Epoch: 26
2022-11-23 00:40:44,175 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8276917812499133, 'Total loss': 0.8276917812499133} | train loss {'Reaction outcome loss': 0.8204519537187391, 'Total loss': 0.8204519537187391}
2022-11-23 00:40:44,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:44,175 INFO:     Epoch: 27
2022-11-23 00:40:44,986 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8440729677677155, 'Total loss': 0.8440729677677155} | train loss {'Reaction outcome loss': 0.8256788461679413, 'Total loss': 0.8256788461679413}
2022-11-23 00:40:44,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:44,986 INFO:     Epoch: 28
2022-11-23 00:40:45,798 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.830677365037528, 'Total loss': 0.830677365037528} | train loss {'Reaction outcome loss': 0.8190552040694221, 'Total loss': 0.8190552040694221}
2022-11-23 00:40:45,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:45,798 INFO:     Epoch: 29
2022-11-23 00:40:46,604 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8304810056632216, 'Total loss': 0.8304810056632216} | train loss {'Reaction outcome loss': 0.8254782383240038, 'Total loss': 0.8254782383240038}
2022-11-23 00:40:46,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:46,605 INFO:     Epoch: 30
2022-11-23 00:40:47,414 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8283686333081939, 'Total loss': 0.8283686333081939} | train loss {'Reaction outcome loss': 0.8211000572529531, 'Total loss': 0.8211000572529531}
2022-11-23 00:40:47,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:47,415 INFO:     Epoch: 31
2022-11-23 00:40:48,221 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8357589827342466, 'Total loss': 0.8357589827342466} | train loss {'Reaction outcome loss': 0.8218164274529103, 'Total loss': 0.8218164274529103}
2022-11-23 00:40:48,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:48,222 INFO:     Epoch: 32
2022-11-23 00:40:49,026 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8238736309788444, 'Total loss': 0.8238736309788444} | train loss {'Reaction outcome loss': 0.8217127898768071, 'Total loss': 0.8217127898768071}
2022-11-23 00:40:49,026 INFO:     Found new best model at epoch 32
2022-11-23 00:40:49,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:49,027 INFO:     Epoch: 33
2022-11-23 00:40:49,839 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8407592285763134, 'Total loss': 0.8407592285763134} | train loss {'Reaction outcome loss': 0.8172206139612582, 'Total loss': 0.8172206139612582}
2022-11-23 00:40:49,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:49,839 INFO:     Epoch: 34
2022-11-23 00:40:50,653 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8244917385957458, 'Total loss': 0.8244917385957458} | train loss {'Reaction outcome loss': 0.819601159903311, 'Total loss': 0.819601159903311}
2022-11-23 00:40:50,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:50,653 INFO:     Epoch: 35
2022-11-23 00:40:51,416 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8213761191476475, 'Total loss': 0.8213761191476475} | train loss {'Reaction outcome loss': 0.8216977811628773, 'Total loss': 0.8216977811628773}
2022-11-23 00:40:51,418 INFO:     Found new best model at epoch 35
2022-11-23 00:40:51,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:51,418 INFO:     Epoch: 36
2022-11-23 00:40:52,189 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8368864885785363, 'Total loss': 0.8368864885785363} | train loss {'Reaction outcome loss': 0.8186292407974121, 'Total loss': 0.8186292407974121}
2022-11-23 00:40:52,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:52,189 INFO:     Epoch: 37
2022-11-23 00:40:52,958 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8196086111393842, 'Total loss': 0.8196086111393842} | train loss {'Reaction outcome loss': 0.820228303151746, 'Total loss': 0.820228303151746}
2022-11-23 00:40:52,958 INFO:     Found new best model at epoch 37
2022-11-23 00:40:52,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:52,959 INFO:     Epoch: 38
2022-11-23 00:40:53,759 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8363974351774562, 'Total loss': 0.8363974351774562} | train loss {'Reaction outcome loss': 0.8178924496375746, 'Total loss': 0.8178924496375746}
2022-11-23 00:40:53,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:53,760 INFO:     Epoch: 39
2022-11-23 00:40:54,545 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8438185974955559, 'Total loss': 0.8438185974955559} | train loss {'Reaction outcome loss': 0.8174358959640226, 'Total loss': 0.8174358959640226}
2022-11-23 00:40:54,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:54,545 INFO:     Epoch: 40
2022-11-23 00:40:55,320 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8136688701131127, 'Total loss': 0.8136688701131127} | train loss {'Reaction outcome loss': 0.8195619794630236, 'Total loss': 0.8195619794630236}
2022-11-23 00:40:55,320 INFO:     Found new best model at epoch 40
2022-11-23 00:40:55,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:55,321 INFO:     Epoch: 41
2022-11-23 00:40:56,127 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8318552225828171, 'Total loss': 0.8318552225828171} | train loss {'Reaction outcome loss': 0.8188724695674835, 'Total loss': 0.8188724695674835}
2022-11-23 00:40:56,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:56,128 INFO:     Epoch: 42
2022-11-23 00:40:56,896 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.825319305062294, 'Total loss': 0.825319305062294} | train loss {'Reaction outcome loss': 0.8234634436666965, 'Total loss': 0.8234634436666965}
2022-11-23 00:40:56,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:56,897 INFO:     Epoch: 43
2022-11-23 00:40:57,660 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8249340253797445, 'Total loss': 0.8249340253797445} | train loss {'Reaction outcome loss': 0.8219476321772221, 'Total loss': 0.8219476321772221}
2022-11-23 00:40:57,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:57,662 INFO:     Epoch: 44
2022-11-23 00:40:58,440 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.819090838459405, 'Total loss': 0.819090838459405} | train loss {'Reaction outcome loss': 0.8220162723333605, 'Total loss': 0.8220162723333605}
2022-11-23 00:40:58,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:58,440 INFO:     Epoch: 45
2022-11-23 00:40:59,235 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8424868150190874, 'Total loss': 0.8424868150190874} | train loss {'Reaction outcome loss': 0.8163392834605709, 'Total loss': 0.8163392834605709}
2022-11-23 00:40:59,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:40:59,235 INFO:     Epoch: 46
2022-11-23 00:41:00,015 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8229429152878848, 'Total loss': 0.8229429152878848} | train loss {'Reaction outcome loss': 0.8207369122293687, 'Total loss': 0.8207369122293687}
2022-11-23 00:41:00,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:00,015 INFO:     Epoch: 47
2022-11-23 00:41:00,787 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8265958672220056, 'Total loss': 0.8265958672220056} | train loss {'Reaction outcome loss': 0.8189404914456029, 'Total loss': 0.8189404914456029}
2022-11-23 00:41:00,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:00,787 INFO:     Epoch: 48
2022-11-23 00:41:01,563 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8393685749985955, 'Total loss': 0.8393685749985955} | train loss {'Reaction outcome loss': 0.8195309568677218, 'Total loss': 0.8195309568677218}
2022-11-23 00:41:01,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:01,563 INFO:     Epoch: 49
2022-11-23 00:41:02,319 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8180630464445461, 'Total loss': 0.8180630464445461} | train loss {'Reaction outcome loss': 0.8196146035146329, 'Total loss': 0.8196146035146329}
2022-11-23 00:41:02,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:02,320 INFO:     Epoch: 50
2022-11-23 00:41:03,105 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8197526328942992, 'Total loss': 0.8197526328942992} | train loss {'Reaction outcome loss': 0.8168915159279301, 'Total loss': 0.8168915159279301}
2022-11-23 00:41:03,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:03,106 INFO:     Epoch: 51
2022-11-23 00:41:03,878 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8265482464974577, 'Total loss': 0.8265482464974577} | train loss {'Reaction outcome loss': 0.8164278625720932, 'Total loss': 0.8164278625720932}
2022-11-23 00:41:03,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:03,878 INFO:     Epoch: 52
2022-11-23 00:41:04,666 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8223289061676372, 'Total loss': 0.8223289061676372} | train loss {'Reaction outcome loss': 0.8235168727415223, 'Total loss': 0.8235168727415223}
2022-11-23 00:41:04,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:04,666 INFO:     Epoch: 53
2022-11-23 00:41:05,451 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8279856863346967, 'Total loss': 0.8279856863346967} | train loss {'Reaction outcome loss': 0.8155745942025415, 'Total loss': 0.8155745942025415}
2022-11-23 00:41:05,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:05,451 INFO:     Epoch: 54
2022-11-23 00:41:06,278 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8353265821933746, 'Total loss': 0.8353265821933746} | train loss {'Reaction outcome loss': 0.8213138335174129, 'Total loss': 0.8213138335174129}
2022-11-23 00:41:06,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:06,279 INFO:     Epoch: 55
2022-11-23 00:41:07,107 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8228112486275759, 'Total loss': 0.8228112486275759} | train loss {'Reaction outcome loss': 0.8208454131118713, 'Total loss': 0.8208454131118713}
2022-11-23 00:41:07,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:07,108 INFO:     Epoch: 56
2022-11-23 00:41:07,942 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8290846605192531, 'Total loss': 0.8290846605192531} | train loss {'Reaction outcome loss': 0.8160564576185518, 'Total loss': 0.8160564576185518}
2022-11-23 00:41:07,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:07,942 INFO:     Epoch: 57
2022-11-23 00:41:08,751 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8737106323242188, 'Total loss': 0.8737106323242188} | train loss {'Reaction outcome loss': 0.8160607145438271, 'Total loss': 0.8160607145438271}
2022-11-23 00:41:08,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:08,751 INFO:     Epoch: 58
2022-11-23 00:41:09,506 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.83768031001091, 'Total loss': 0.83768031001091} | train loss {'Reaction outcome loss': 0.8220595944552652, 'Total loss': 0.8220595944552652}
2022-11-23 00:41:09,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:09,506 INFO:     Epoch: 59
2022-11-23 00:41:10,273 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8485255945812572, 'Total loss': 0.8485255945812572} | train loss {'Reaction outcome loss': 0.8182684059344953, 'Total loss': 0.8182684059344953}
2022-11-23 00:41:10,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:10,274 INFO:     Epoch: 60
2022-11-23 00:41:11,033 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8244148885661905, 'Total loss': 0.8244148885661905} | train loss {'Reaction outcome loss': 0.8177150545581695, 'Total loss': 0.8177150545581695}
2022-11-23 00:41:11,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:11,034 INFO:     Epoch: 61
2022-11-23 00:41:11,810 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8339654898101633, 'Total loss': 0.8339654898101633} | train loss {'Reaction outcome loss': 0.8175811404662747, 'Total loss': 0.8175811404662747}
2022-11-23 00:41:11,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:11,810 INFO:     Epoch: 62
2022-11-23 00:41:12,604 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8496409979733553, 'Total loss': 0.8496409979733553} | train loss {'Reaction outcome loss': 0.8150424813070605, 'Total loss': 0.8150424813070605}
2022-11-23 00:41:12,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:12,604 INFO:     Epoch: 63
2022-11-23 00:41:13,386 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8545490523630922, 'Total loss': 0.8545490523630922} | train loss {'Reaction outcome loss': 0.819146123624617, 'Total loss': 0.819146123624617}
2022-11-23 00:41:13,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:13,386 INFO:     Epoch: 64
2022-11-23 00:41:14,162 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8226244618946855, 'Total loss': 0.8226244618946855} | train loss {'Reaction outcome loss': 0.8182869930901835, 'Total loss': 0.8182869930901835}
2022-11-23 00:41:14,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:14,163 INFO:     Epoch: 65
2022-11-23 00:41:14,953 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8305304897102442, 'Total loss': 0.8305304897102442} | train loss {'Reaction outcome loss': 0.8158920159743678, 'Total loss': 0.8158920159743678}
2022-11-23 00:41:14,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:14,953 INFO:     Epoch: 66
2022-11-23 00:41:15,733 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8559286079623483, 'Total loss': 0.8559286079623483} | train loss {'Reaction outcome loss': 0.8171554052781674, 'Total loss': 0.8171554052781674}
2022-11-23 00:41:15,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:15,733 INFO:     Epoch: 67
2022-11-23 00:41:16,534 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8511278649622743, 'Total loss': 0.8511278649622743} | train loss {'Reaction outcome loss': 0.8188885522465552, 'Total loss': 0.8188885522465552}
2022-11-23 00:41:16,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:16,535 INFO:     Epoch: 68
2022-11-23 00:41:17,291 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8147622455250133, 'Total loss': 0.8147622455250133} | train loss {'Reaction outcome loss': 0.8215452715033486, 'Total loss': 0.8215452715033486}
2022-11-23 00:41:17,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:17,292 INFO:     Epoch: 69
2022-11-23 00:41:18,063 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8291849202730439, 'Total loss': 0.8291849202730439} | train loss {'Reaction outcome loss': 0.8137759895574662, 'Total loss': 0.8137759895574662}
2022-11-23 00:41:18,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:18,063 INFO:     Epoch: 70
2022-11-23 00:41:18,858 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8384642153978348, 'Total loss': 0.8384642153978348} | train loss {'Reaction outcome loss': 0.8209084727831425, 'Total loss': 0.8209084727831425}
2022-11-23 00:41:18,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:18,858 INFO:     Epoch: 71
2022-11-23 00:41:19,691 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8323190232569521, 'Total loss': 0.8323190232569521} | train loss {'Reaction outcome loss': 0.8149215439634938, 'Total loss': 0.8149215439634938}
2022-11-23 00:41:19,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:19,691 INFO:     Epoch: 72
2022-11-23 00:41:20,522 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8264185996218161, 'Total loss': 0.8264185996218161} | train loss {'Reaction outcome loss': 0.8235499415426485, 'Total loss': 0.8235499415426485}
2022-11-23 00:41:20,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:20,522 INFO:     Epoch: 73
2022-11-23 00:41:21,345 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8325947150588036, 'Total loss': 0.8325947150588036} | train loss {'Reaction outcome loss': 0.8174380246670016, 'Total loss': 0.8174380246670016}
2022-11-23 00:41:21,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:21,345 INFO:     Epoch: 74
2022-11-23 00:41:22,133 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8193201266906478, 'Total loss': 0.8193201266906478} | train loss {'Reaction outcome loss': 0.8203547851693246, 'Total loss': 0.8203547851693246}
2022-11-23 00:41:22,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:22,134 INFO:     Epoch: 75
2022-11-23 00:41:22,937 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8142041489481926, 'Total loss': 0.8142041489481926} | train loss {'Reaction outcome loss': 0.8152809683834353, 'Total loss': 0.8152809683834353}
2022-11-23 00:41:22,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:22,938 INFO:     Epoch: 76
2022-11-23 00:41:23,734 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8387177044695074, 'Total loss': 0.8387177044695074} | train loss {'Reaction outcome loss': 0.8197108802776183, 'Total loss': 0.8197108802776183}
2022-11-23 00:41:23,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:23,735 INFO:     Epoch: 77
2022-11-23 00:41:24,494 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8360151465643536, 'Total loss': 0.8360151465643536} | train loss {'Reaction outcome loss': 0.8208160526569812, 'Total loss': 0.8208160526569812}
2022-11-23 00:41:24,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:24,494 INFO:     Epoch: 78
2022-11-23 00:41:25,290 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8353378474712372, 'Total loss': 0.8353378474712372} | train loss {'Reaction outcome loss': 0.8153385735086857, 'Total loss': 0.8153385735086857}
2022-11-23 00:41:25,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:25,290 INFO:     Epoch: 79
2022-11-23 00:41:26,121 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8254260569810867, 'Total loss': 0.8254260569810867} | train loss {'Reaction outcome loss': 0.8206757375549886, 'Total loss': 0.8206757375549886}
2022-11-23 00:41:26,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:26,122 INFO:     Epoch: 80
2022-11-23 00:41:26,951 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8218734555623748, 'Total loss': 0.8218734555623748} | train loss {'Reaction outcome loss': 0.8213056577069144, 'Total loss': 0.8213056577069144}
2022-11-23 00:41:26,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:26,951 INFO:     Epoch: 81
2022-11-23 00:41:27,734 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8403888805346056, 'Total loss': 0.8403888805346056} | train loss {'Reaction outcome loss': 0.8229893077044718, 'Total loss': 0.8229893077044718}
2022-11-23 00:41:27,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:27,735 INFO:     Epoch: 82
2022-11-23 00:41:28,550 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8257306170734492, 'Total loss': 0.8257306170734492} | train loss {'Reaction outcome loss': 0.8211113867019454, 'Total loss': 0.8211113867019454}
2022-11-23 00:41:28,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:28,550 INFO:     Epoch: 83
2022-11-23 00:41:29,372 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8317869264971126, 'Total loss': 0.8317869264971126} | train loss {'Reaction outcome loss': 0.8153289669463711, 'Total loss': 0.8153289669463711}
2022-11-23 00:41:29,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:29,373 INFO:     Epoch: 84
2022-11-23 00:41:30,179 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8210414560003714, 'Total loss': 0.8210414560003714} | train loss {'Reaction outcome loss': 0.8167382177085646, 'Total loss': 0.8167382177085646}
2022-11-23 00:41:30,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:30,180 INFO:     Epoch: 85
2022-11-23 00:41:30,950 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8331687287850813, 'Total loss': 0.8331687287850813} | train loss {'Reaction outcome loss': 0.8193240994887967, 'Total loss': 0.8193240994887967}
2022-11-23 00:41:30,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:30,950 INFO:     Epoch: 86
2022-11-23 00:41:31,766 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8250749463384802, 'Total loss': 0.8250749463384802} | train loss {'Reaction outcome loss': 0.8194227763000996, 'Total loss': 0.8194227763000996}
2022-11-23 00:41:31,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:31,766 INFO:     Epoch: 87
2022-11-23 00:41:32,574 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8263029699975794, 'Total loss': 0.8263029699975794} | train loss {'Reaction outcome loss': 0.8201333501886937, 'Total loss': 0.8201333501886937}
2022-11-23 00:41:32,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:32,574 INFO:     Epoch: 88
2022-11-23 00:41:33,403 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8353211012753573, 'Total loss': 0.8353211012753573} | train loss {'Reaction outcome loss': 0.8195137571423284, 'Total loss': 0.8195137571423284}
2022-11-23 00:41:33,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:33,403 INFO:     Epoch: 89
2022-11-23 00:41:34,252 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8312895839864557, 'Total loss': 0.8312895839864557} | train loss {'Reaction outcome loss': 0.8159188673861565, 'Total loss': 0.8159188673861565}
2022-11-23 00:41:34,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:34,253 INFO:     Epoch: 90
2022-11-23 00:41:35,041 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8239354437047784, 'Total loss': 0.8239354437047784} | train loss {'Reaction outcome loss': 0.8206197726390054, 'Total loss': 0.8206197726390054}
2022-11-23 00:41:35,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:35,041 INFO:     Epoch: 91
2022-11-23 00:41:35,856 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8300449130210009, 'Total loss': 0.8300449130210009} | train loss {'Reaction outcome loss': 0.8206568670368963, 'Total loss': 0.8206568670368963}
2022-11-23 00:41:35,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:35,856 INFO:     Epoch: 92
2022-11-23 00:41:36,644 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8301925604993646, 'Total loss': 0.8301925604993646} | train loss {'Reaction outcome loss': 0.8181508209916853, 'Total loss': 0.8181508209916853}
2022-11-23 00:41:36,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:36,644 INFO:     Epoch: 93
2022-11-23 00:41:37,483 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.828786080533808, 'Total loss': 0.828786080533808} | train loss {'Reaction outcome loss': 0.8203782307044152, 'Total loss': 0.8203782307044152}
2022-11-23 00:41:37,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:37,483 INFO:     Epoch: 94
2022-11-23 00:41:38,306 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8433855514634739, 'Total loss': 0.8433855514634739} | train loss {'Reaction outcome loss': 0.8177245636620829, 'Total loss': 0.8177245636620829}
2022-11-23 00:41:38,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:38,306 INFO:     Epoch: 95
2022-11-23 00:41:39,120 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8416637128049677, 'Total loss': 0.8416637128049677} | train loss {'Reaction outcome loss': 0.8225108258906872, 'Total loss': 0.8225108258906872}
2022-11-23 00:41:39,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:39,120 INFO:     Epoch: 96
2022-11-23 00:41:39,937 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.837744518098506, 'Total loss': 0.837744518098506} | train loss {'Reaction outcome loss': 0.8160361476963566, 'Total loss': 0.8160361476963566}
2022-11-23 00:41:39,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:39,937 INFO:     Epoch: 97
2022-11-23 00:41:40,721 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8268487737937407, 'Total loss': 0.8268487737937407} | train loss {'Reaction outcome loss': 0.8221289552748203, 'Total loss': 0.8221289552748203}
2022-11-23 00:41:40,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:40,721 INFO:     Epoch: 98
2022-11-23 00:41:41,520 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8452985855666074, 'Total loss': 0.8452985855666074} | train loss {'Reaction outcome loss': 0.8159236924782876, 'Total loss': 0.8159236924782876}
2022-11-23 00:41:41,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:41,521 INFO:     Epoch: 99
2022-11-23 00:41:42,301 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8335446586663072, 'Total loss': 0.8335446586663072} | train loss {'Reaction outcome loss': 0.8168708245840764, 'Total loss': 0.8168708245840764}
2022-11-23 00:41:42,301 INFO:     Best model found after epoch 41 of 100.
2022-11-23 00:41:42,301 INFO:   Done with stage: TRAINING
2022-11-23 00:41:42,301 INFO:   Starting stage: EVALUATION
2022-11-23 00:41:42,419 INFO:   Done with stage: EVALUATION
2022-11-23 00:41:42,420 INFO:   Leaving out SEQ value Fold_6
2022-11-23 00:41:42,433 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 00:41:42,433 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:41:43,105 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:41:43,105 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:41:43,176 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:41:43,176 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:41:43,176 INFO:     No hyperparam tuning for this model
2022-11-23 00:41:43,177 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:41:43,177 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:41:43,177 INFO:     None feature selector for col prot
2022-11-23 00:41:43,178 INFO:     None feature selector for col prot
2022-11-23 00:41:43,178 INFO:     None feature selector for col prot
2022-11-23 00:41:43,178 INFO:     None feature selector for col chem
2022-11-23 00:41:43,179 INFO:     None feature selector for col chem
2022-11-23 00:41:43,179 INFO:     None feature selector for col chem
2022-11-23 00:41:43,179 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:41:43,179 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:41:43,180 INFO:     Number of params in model 168571
2022-11-23 00:41:43,183 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:41:43,183 INFO:   Starting stage: TRAINING
2022-11-23 00:41:43,242 INFO:     Val loss before train {'Reaction outcome loss': 0.98691741715778, 'Total loss': 0.98691741715778}
2022-11-23 00:41:43,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:43,242 INFO:     Epoch: 0
2022-11-23 00:41:44,043 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8138414709405466, 'Total loss': 0.8138414709405466} | train loss {'Reaction outcome loss': 0.8825194000476791, 'Total loss': 0.8825194000476791}
2022-11-23 00:41:44,043 INFO:     Found new best model at epoch 0
2022-11-23 00:41:44,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:44,044 INFO:     Epoch: 1
2022-11-23 00:41:44,853 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8033335202119567, 'Total loss': 0.8033335202119567} | train loss {'Reaction outcome loss': 0.8510284415416179, 'Total loss': 0.8510284415416179}
2022-11-23 00:41:44,853 INFO:     Found new best model at epoch 1
2022-11-23 00:41:44,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:44,854 INFO:     Epoch: 2
2022-11-23 00:41:45,653 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7911998683756049, 'Total loss': 0.7911998683756049} | train loss {'Reaction outcome loss': 0.8444939651075871, 'Total loss': 0.8444939651075871}
2022-11-23 00:41:45,654 INFO:     Found new best model at epoch 2
2022-11-23 00:41:45,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:45,654 INFO:     Epoch: 3
2022-11-23 00:41:46,459 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8106992867859927, 'Total loss': 0.8106992867859927} | train loss {'Reaction outcome loss': 0.8390533402562141, 'Total loss': 0.8390533402562141}
2022-11-23 00:41:46,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:46,460 INFO:     Epoch: 4
2022-11-23 00:41:47,286 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8006076684052293, 'Total loss': 0.8006076684052293} | train loss {'Reaction outcome loss': 0.8336047375154111, 'Total loss': 0.8336047375154111}
2022-11-23 00:41:47,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:47,286 INFO:     Epoch: 5
2022-11-23 00:41:48,093 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7842266749251973, 'Total loss': 0.7842266749251973} | train loss {'Reaction outcome loss': 0.8288804124439916, 'Total loss': 0.8288804124439916}
2022-11-23 00:41:48,093 INFO:     Found new best model at epoch 5
2022-11-23 00:41:48,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:48,094 INFO:     Epoch: 6
2022-11-23 00:41:48,882 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7926236181096598, 'Total loss': 0.7926236181096598} | train loss {'Reaction outcome loss': 0.8282274605045395, 'Total loss': 0.8282274605045395}
2022-11-23 00:41:48,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:48,882 INFO:     Epoch: 7
2022-11-23 00:41:49,687 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7922701754353263, 'Total loss': 0.7922701754353263} | train loss {'Reaction outcome loss': 0.8298508575366389, 'Total loss': 0.8298508575366389}
2022-11-23 00:41:49,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:49,687 INFO:     Epoch: 8
2022-11-23 00:41:50,495 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8049499555067583, 'Total loss': 0.8049499555067583} | train loss {'Reaction outcome loss': 0.8277518862197476, 'Total loss': 0.8277518862197476}
2022-11-23 00:41:50,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:50,495 INFO:     Epoch: 9
2022-11-23 00:41:51,314 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7874839488755573, 'Total loss': 0.7874839488755573} | train loss {'Reaction outcome loss': 0.8227727504507187, 'Total loss': 0.8227727504507187}
2022-11-23 00:41:51,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:51,314 INFO:     Epoch: 10
2022-11-23 00:41:52,121 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7831440229307521, 'Total loss': 0.7831440229307521} | train loss {'Reaction outcome loss': 0.822320478457597, 'Total loss': 0.822320478457597}
2022-11-23 00:41:52,121 INFO:     Found new best model at epoch 10
2022-11-23 00:41:52,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:52,122 INFO:     Epoch: 11
2022-11-23 00:41:52,952 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8043423132462935, 'Total loss': 0.8043423132462935} | train loss {'Reaction outcome loss': 0.8239481487581807, 'Total loss': 0.8239481487581807}
2022-11-23 00:41:52,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:52,952 INFO:     Epoch: 12
2022-11-23 00:41:53,747 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7842301286079667, 'Total loss': 0.7842301286079667} | train loss {'Reaction outcome loss': 0.8211650612854189, 'Total loss': 0.8211650612854189}
2022-11-23 00:41:53,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:53,747 INFO:     Epoch: 13
2022-11-23 00:41:54,525 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7928631420839917, 'Total loss': 0.7928631420839917} | train loss {'Reaction outcome loss': 0.8294538791862226, 'Total loss': 0.8294538791862226}
2022-11-23 00:41:54,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:54,526 INFO:     Epoch: 14
2022-11-23 00:41:55,343 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7879472794857892, 'Total loss': 0.7879472794857892} | train loss {'Reaction outcome loss': 0.8229684836922153, 'Total loss': 0.8229684836922153}
2022-11-23 00:41:55,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:55,343 INFO:     Epoch: 15
2022-11-23 00:41:56,195 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7932189730080691, 'Total loss': 0.7932189730080691} | train loss {'Reaction outcome loss': 0.8213287183353978, 'Total loss': 0.8213287183353978}
2022-11-23 00:41:56,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:56,196 INFO:     Epoch: 16
2022-11-23 00:41:57,048 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7840742563659494, 'Total loss': 0.7840742563659494} | train loss {'Reaction outcome loss': 0.8205521939502608, 'Total loss': 0.8205521939502608}
2022-11-23 00:41:57,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:57,049 INFO:     Epoch: 17
2022-11-23 00:41:57,836 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7897995747625828, 'Total loss': 0.7897995747625828} | train loss {'Reaction outcome loss': 0.8234757050391166, 'Total loss': 0.8234757050391166}
2022-11-23 00:41:57,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:57,837 INFO:     Epoch: 18
2022-11-23 00:41:58,632 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7988389581441879, 'Total loss': 0.7988389581441879} | train loss {'Reaction outcome loss': 0.8249879015549537, 'Total loss': 0.8249879015549537}
2022-11-23 00:41:58,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:58,633 INFO:     Epoch: 19
2022-11-23 00:41:59,436 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8179095048796047, 'Total loss': 0.8179095048796047} | train loss {'Reaction outcome loss': 0.8124002918841378, 'Total loss': 0.8124002918841378}
2022-11-23 00:41:59,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:41:59,436 INFO:     Epoch: 20
2022-11-23 00:42:00,268 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7747474719177593, 'Total loss': 0.7747474719177593} | train loss {'Reaction outcome loss': 0.8267904222011566, 'Total loss': 0.8267904222011566}
2022-11-23 00:42:00,268 INFO:     Found new best model at epoch 20
2022-11-23 00:42:00,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:00,269 INFO:     Epoch: 21
2022-11-23 00:42:01,126 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7887067605148662, 'Total loss': 0.7887067605148662} | train loss {'Reaction outcome loss': 0.8170885691238988, 'Total loss': 0.8170885691238988}
2022-11-23 00:42:01,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:01,127 INFO:     Epoch: 22
2022-11-23 00:42:01,894 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7846663756804033, 'Total loss': 0.7846663756804033} | train loss {'Reaction outcome loss': 0.8239238662344794, 'Total loss': 0.8239238662344794}
2022-11-23 00:42:01,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:01,894 INFO:     Epoch: 23
2022-11-23 00:42:02,670 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7921184436841444, 'Total loss': 0.7921184436841444} | train loss {'Reaction outcome loss': 0.8167989117003256, 'Total loss': 0.8167989117003256}
2022-11-23 00:42:02,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:02,671 INFO:     Epoch: 24
2022-11-23 00:42:03,490 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7837646752595901, 'Total loss': 0.7837646752595901} | train loss {'Reaction outcome loss': 0.819054268060192, 'Total loss': 0.819054268060192}
2022-11-23 00:42:03,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:03,491 INFO:     Epoch: 25
2022-11-23 00:42:04,266 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.789583796127276, 'Total loss': 0.789583796127276} | train loss {'Reaction outcome loss': 0.8171933980718735, 'Total loss': 0.8171933980718735}
2022-11-23 00:42:04,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:04,267 INFO:     Epoch: 26
2022-11-23 00:42:05,056 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7716492773457007, 'Total loss': 0.7716492773457007} | train loss {'Reaction outcome loss': 0.8207194717420686, 'Total loss': 0.8207194717420686}
2022-11-23 00:42:05,056 INFO:     Found new best model at epoch 26
2022-11-23 00:42:05,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:05,057 INFO:     Epoch: 27
2022-11-23 00:42:05,913 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7787024392323061, 'Total loss': 0.7787024392323061} | train loss {'Reaction outcome loss': 0.8166907796215627, 'Total loss': 0.8166907796215627}
2022-11-23 00:42:05,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:05,913 INFO:     Epoch: 28
2022-11-23 00:42:06,768 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7803641151298176, 'Total loss': 0.7803641151298176} | train loss {'Reaction outcome loss': 0.808635558812849, 'Total loss': 0.808635558812849}
2022-11-23 00:42:06,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:06,768 INFO:     Epoch: 29
2022-11-23 00:42:07,578 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8044424856250937, 'Total loss': 0.8044424856250937} | train loss {'Reaction outcome loss': 0.8163742334131272, 'Total loss': 0.8163742334131272}
2022-11-23 00:42:07,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:07,578 INFO:     Epoch: 30
2022-11-23 00:42:08,359 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8305734423073855, 'Total loss': 0.8305734423073855} | train loss {'Reaction outcome loss': 0.8223049700740845, 'Total loss': 0.8223049700740845}
2022-11-23 00:42:08,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:08,359 INFO:     Epoch: 31
2022-11-23 00:42:09,199 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7990300059318542, 'Total loss': 0.7990300059318542} | train loss {'Reaction outcome loss': 0.8206627563603462, 'Total loss': 0.8206627563603462}
2022-11-23 00:42:09,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:09,200 INFO:     Epoch: 32
2022-11-23 00:42:10,049 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8021908266977831, 'Total loss': 0.8021908266977831} | train loss {'Reaction outcome loss': 0.8191665723439185, 'Total loss': 0.8191665723439185}
2022-11-23 00:42:10,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:10,050 INFO:     Epoch: 33
2022-11-23 00:42:10,827 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7783070504665375, 'Total loss': 0.7783070504665375} | train loss {'Reaction outcome loss': 0.8232817062206806, 'Total loss': 0.8232817062206806}
2022-11-23 00:42:10,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:10,828 INFO:     Epoch: 34
2022-11-23 00:42:11,599 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.78909932076931, 'Total loss': 0.78909932076931} | train loss {'Reaction outcome loss': 0.8169643004094401, 'Total loss': 0.8169643004094401}
2022-11-23 00:42:11,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:11,600 INFO:     Epoch: 35
2022-11-23 00:42:12,369 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.786028694700111, 'Total loss': 0.786028694700111} | train loss {'Reaction outcome loss': 0.8224630796861264, 'Total loss': 0.8224630796861264}
2022-11-23 00:42:12,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:12,369 INFO:     Epoch: 36
2022-11-23 00:42:13,159 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7945553463968363, 'Total loss': 0.7945553463968363} | train loss {'Reaction outcome loss': 0.8184192298400786, 'Total loss': 0.8184192298400786}
2022-11-23 00:42:13,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:13,160 INFO:     Epoch: 37
2022-11-23 00:42:13,979 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7831466177647765, 'Total loss': 0.7831466177647765} | train loss {'Reaction outcome loss': 0.8189523741002044, 'Total loss': 0.8189523741002044}
2022-11-23 00:42:13,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:13,979 INFO:     Epoch: 38
2022-11-23 00:42:14,813 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7972147586670789, 'Total loss': 0.7972147586670789} | train loss {'Reaction outcome loss': 0.8138432902914863, 'Total loss': 0.8138432902914863}
2022-11-23 00:42:14,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:14,814 INFO:     Epoch: 39
2022-11-23 00:42:15,642 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7800603461536494, 'Total loss': 0.7800603461536494} | train loss {'Reaction outcome loss': 0.8205151417322697, 'Total loss': 0.8205151417322697}
2022-11-23 00:42:15,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:15,643 INFO:     Epoch: 40
2022-11-23 00:42:16,443 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7729515142061494, 'Total loss': 0.7729515142061494} | train loss {'Reaction outcome loss': 0.8214464948302315, 'Total loss': 0.8214464948302315}
2022-11-23 00:42:16,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:16,444 INFO:     Epoch: 41
2022-11-23 00:42:17,273 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7904221374880184, 'Total loss': 0.7904221374880184} | train loss {'Reaction outcome loss': 0.8232951736257922, 'Total loss': 0.8232951736257922}
2022-11-23 00:42:17,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:17,273 INFO:     Epoch: 42
2022-11-23 00:42:18,099 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.77778614515608, 'Total loss': 0.77778614515608} | train loss {'Reaction outcome loss': 0.8187447538779627, 'Total loss': 0.8187447538779627}
2022-11-23 00:42:18,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:18,100 INFO:     Epoch: 43
2022-11-23 00:42:18,909 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.796156992289153, 'Total loss': 0.796156992289153} | train loss {'Reaction outcome loss': 0.819375122266431, 'Total loss': 0.819375122266431}
2022-11-23 00:42:18,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:18,909 INFO:     Epoch: 44
2022-11-23 00:42:19,755 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7820043137127702, 'Total loss': 0.7820043137127702} | train loss {'Reaction outcome loss': 0.8194400648916921, 'Total loss': 0.8194400648916921}
2022-11-23 00:42:19,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:19,756 INFO:     Epoch: 45
2022-11-23 00:42:20,610 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7823348451744426, 'Total loss': 0.7823348451744426} | train loss {'Reaction outcome loss': 0.823569175697142, 'Total loss': 0.823569175697142}
2022-11-23 00:42:20,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:20,611 INFO:     Epoch: 46
2022-11-23 00:42:21,430 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.789157516577027, 'Total loss': 0.789157516577027} | train loss {'Reaction outcome loss': 0.8185476020218865, 'Total loss': 0.8185476020218865}
2022-11-23 00:42:21,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:21,431 INFO:     Epoch: 47
2022-11-23 00:42:22,275 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7900505621324886, 'Total loss': 0.7900505621324886} | train loss {'Reaction outcome loss': 0.8169249946311596, 'Total loss': 0.8169249946311596}
2022-11-23 00:42:22,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:22,276 INFO:     Epoch: 48
2022-11-23 00:42:23,149 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7963866564360532, 'Total loss': 0.7963866564360532} | train loss {'Reaction outcome loss': 0.820293688245358, 'Total loss': 0.820293688245358}
2022-11-23 00:42:23,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:23,150 INFO:     Epoch: 49
2022-11-23 00:42:24,012 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7908021143891595, 'Total loss': 0.7908021143891595} | train loss {'Reaction outcome loss': 0.8167682649387468, 'Total loss': 0.8167682649387468}
2022-11-23 00:42:24,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:24,013 INFO:     Epoch: 50
2022-11-23 00:42:24,887 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7728813554752957, 'Total loss': 0.7728813554752957} | train loss {'Reaction outcome loss': 0.8159378521865414, 'Total loss': 0.8159378521865414}
2022-11-23 00:42:24,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:24,888 INFO:     Epoch: 51
2022-11-23 00:42:25,740 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7863041216676886, 'Total loss': 0.7863041216676886} | train loss {'Reaction outcome loss': 0.8197855018079281, 'Total loss': 0.8197855018079281}
2022-11-23 00:42:25,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:25,741 INFO:     Epoch: 52
2022-11-23 00:42:26,559 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7900125614621423, 'Total loss': 0.7900125614621423} | train loss {'Reaction outcome loss': 0.8110949067819503, 'Total loss': 0.8110949067819503}
2022-11-23 00:42:26,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:26,560 INFO:     Epoch: 53
2022-11-23 00:42:27,429 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.778417778286067, 'Total loss': 0.778417778286067} | train loss {'Reaction outcome loss': 0.8175450801368682, 'Total loss': 0.8175450801368682}
2022-11-23 00:42:27,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:27,429 INFO:     Epoch: 54
2022-11-23 00:42:28,291 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7839275761084123, 'Total loss': 0.7839275761084123} | train loss {'Reaction outcome loss': 0.8159710001801291, 'Total loss': 0.8159710001801291}
2022-11-23 00:42:28,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:28,291 INFO:     Epoch: 55
2022-11-23 00:42:29,155 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7927375002340837, 'Total loss': 0.7927375002340837} | train loss {'Reaction outcome loss': 0.8165622071152733, 'Total loss': 0.8165622071152733}
2022-11-23 00:42:29,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:29,156 INFO:     Epoch: 56
2022-11-23 00:42:29,994 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7963069684126161, 'Total loss': 0.7963069684126161} | train loss {'Reaction outcome loss': 0.8130822882296578, 'Total loss': 0.8130822882296578}
2022-11-23 00:42:29,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:29,994 INFO:     Epoch: 57
2022-11-23 00:42:30,895 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7821879596872763, 'Total loss': 0.7821879596872763} | train loss {'Reaction outcome loss': 0.8203396056928942, 'Total loss': 0.8203396056928942}
2022-11-23 00:42:30,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:30,895 INFO:     Epoch: 58
2022-11-23 00:42:31,738 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7966258932243694, 'Total loss': 0.7966258932243694} | train loss {'Reaction outcome loss': 0.8156320640156346, 'Total loss': 0.8156320640156346}
2022-11-23 00:42:31,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:31,738 INFO:     Epoch: 59
2022-11-23 00:42:32,642 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7963984581557187, 'Total loss': 0.7963984581557187} | train loss {'Reaction outcome loss': 0.8201563865427048, 'Total loss': 0.8201563865427048}
2022-11-23 00:42:32,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:32,643 INFO:     Epoch: 60
2022-11-23 00:42:33,583 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7710216058926149, 'Total loss': 0.7710216058926149} | train loss {'Reaction outcome loss': 0.8145538358198058, 'Total loss': 0.8145538358198058}
2022-11-23 00:42:33,583 INFO:     Found new best model at epoch 60
2022-11-23 00:42:33,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:33,584 INFO:     Epoch: 61
2022-11-23 00:42:34,502 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7986143854531375, 'Total loss': 0.7986143854531375} | train loss {'Reaction outcome loss': 0.8126058918574164, 'Total loss': 0.8126058918574164}
2022-11-23 00:42:34,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:34,502 INFO:     Epoch: 62
2022-11-23 00:42:35,396 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7901844443245367, 'Total loss': 0.7901844443245367} | train loss {'Reaction outcome loss': 0.8132280348049056, 'Total loss': 0.8132280348049056}
2022-11-23 00:42:35,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:35,397 INFO:     Epoch: 63
2022-11-23 00:42:36,255 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7816021245988932, 'Total loss': 0.7816021245988932} | train loss {'Reaction outcome loss': 0.8096886489900851, 'Total loss': 0.8096886489900851}
2022-11-23 00:42:36,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:36,255 INFO:     Epoch: 64
2022-11-23 00:42:37,178 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7988388030366464, 'Total loss': 0.7988388030366464} | train loss {'Reaction outcome loss': 0.8171890307097666, 'Total loss': 0.8171890307097666}
2022-11-23 00:42:37,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:37,178 INFO:     Epoch: 65
2022-11-23 00:42:38,042 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7867090038277886, 'Total loss': 0.7867090038277886} | train loss {'Reaction outcome loss': 0.8174020466544936, 'Total loss': 0.8174020466544936}
2022-11-23 00:42:38,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:38,043 INFO:     Epoch: 66
2022-11-23 00:42:38,885 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8078664432872426, 'Total loss': 0.8078664432872426} | train loss {'Reaction outcome loss': 0.813550379127264, 'Total loss': 0.813550379127264}
2022-11-23 00:42:38,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:38,885 INFO:     Epoch: 67
2022-11-23 00:42:39,791 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8126077929680998, 'Total loss': 0.8126077929680998} | train loss {'Reaction outcome loss': 0.8192147151116402, 'Total loss': 0.8192147151116402}
2022-11-23 00:42:39,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:39,792 INFO:     Epoch: 68
2022-11-23 00:42:40,641 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8048398115418174, 'Total loss': 0.8048398115418174} | train loss {'Reaction outcome loss': 0.8140848265780557, 'Total loss': 0.8140848265780557}
2022-11-23 00:42:40,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:40,642 INFO:     Epoch: 69
2022-11-23 00:42:41,573 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7742475176399405, 'Total loss': 0.7742475176399405} | train loss {'Reaction outcome loss': 0.8104841262102127, 'Total loss': 0.8104841262102127}
2022-11-23 00:42:41,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:41,573 INFO:     Epoch: 70
2022-11-23 00:42:42,495 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7936978089538488, 'Total loss': 0.7936978089538488} | train loss {'Reaction outcome loss': 0.8156200236370487, 'Total loss': 0.8156200236370487}
2022-11-23 00:42:42,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:42,495 INFO:     Epoch: 71
2022-11-23 00:42:43,366 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8120971389792182, 'Total loss': 0.8120971389792182} | train loss {'Reaction outcome loss': 0.8127473773615014, 'Total loss': 0.8127473773615014}
2022-11-23 00:42:43,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:43,367 INFO:     Epoch: 72
2022-11-23 00:42:44,222 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.780854341658679, 'Total loss': 0.780854341658679} | train loss {'Reaction outcome loss': 0.8174999905449729, 'Total loss': 0.8174999905449729}
2022-11-23 00:42:44,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:44,223 INFO:     Epoch: 73
2022-11-23 00:42:45,118 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7778257016431201, 'Total loss': 0.7778257016431201} | train loss {'Reaction outcome loss': 0.8149688523863593, 'Total loss': 0.8149688523863593}
2022-11-23 00:42:45,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:45,119 INFO:     Epoch: 74
2022-11-23 00:42:45,989 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7830482071096246, 'Total loss': 0.7830482071096246} | train loss {'Reaction outcome loss': 0.8149128432475752, 'Total loss': 0.8149128432475752}
2022-11-23 00:42:45,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:45,990 INFO:     Epoch: 75
2022-11-23 00:42:46,873 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7896730134432967, 'Total loss': 0.7896730134432967} | train loss {'Reaction outcome loss': 0.8155703472514306, 'Total loss': 0.8155703472514306}
2022-11-23 00:42:46,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:46,873 INFO:     Epoch: 76
2022-11-23 00:42:47,695 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7922897650436922, 'Total loss': 0.7922897650436922} | train loss {'Reaction outcome loss': 0.8184179642027424, 'Total loss': 0.8184179642027424}
2022-11-23 00:42:47,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:47,695 INFO:     Epoch: 77
2022-11-23 00:42:48,601 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8044970496134325, 'Total loss': 0.8044970496134325} | train loss {'Reaction outcome loss': 0.8124717290122663, 'Total loss': 0.8124717290122663}
2022-11-23 00:42:48,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:48,601 INFO:     Epoch: 78
2022-11-23 00:42:49,410 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7744983007962053, 'Total loss': 0.7744983007962053} | train loss {'Reaction outcome loss': 0.8171149579988372, 'Total loss': 0.8171149579988372}
2022-11-23 00:42:49,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:49,410 INFO:     Epoch: 79
2022-11-23 00:42:50,237 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7807005853815512, 'Total loss': 0.7807005853815512} | train loss {'Reaction outcome loss': 0.8148835315819709, 'Total loss': 0.8148835315819709}
2022-11-23 00:42:50,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:50,238 INFO:     Epoch: 80
2022-11-23 00:42:51,067 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7969010729681362, 'Total loss': 0.7969010729681362} | train loss {'Reaction outcome loss': 0.8128892596690885, 'Total loss': 0.8128892596690885}
2022-11-23 00:42:51,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:51,067 INFO:     Epoch: 81
2022-11-23 00:42:51,888 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7878295162861998, 'Total loss': 0.7878295162861998} | train loss {'Reaction outcome loss': 0.8202664003737511, 'Total loss': 0.8202664003737511}
2022-11-23 00:42:51,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:51,888 INFO:     Epoch: 82
2022-11-23 00:42:52,706 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.781664598394524, 'Total loss': 0.781664598394524} | train loss {'Reaction outcome loss': 0.8147074174015753, 'Total loss': 0.8147074174015753}
2022-11-23 00:42:52,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:52,707 INFO:     Epoch: 83
2022-11-23 00:42:53,524 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7806515768170357, 'Total loss': 0.7806515768170357} | train loss {'Reaction outcome loss': 0.8132040052404327, 'Total loss': 0.8132040052404327}
2022-11-23 00:42:53,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:53,524 INFO:     Epoch: 84
2022-11-23 00:42:54,355 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7743796144019474, 'Total loss': 0.7743796144019474} | train loss {'Reaction outcome loss': 0.8163099124306633, 'Total loss': 0.8163099124306633}
2022-11-23 00:42:54,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:54,356 INFO:     Epoch: 85
2022-11-23 00:42:55,187 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8021148030053485, 'Total loss': 0.8021148030053485} | train loss {'Reaction outcome loss': 0.8179403968876408, 'Total loss': 0.8179403968876408}
2022-11-23 00:42:55,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:55,187 INFO:     Epoch: 86
2022-11-23 00:42:56,041 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7881150272759524, 'Total loss': 0.7881150272759524} | train loss {'Reaction outcome loss': 0.8172168826624271, 'Total loss': 0.8172168826624271}
2022-11-23 00:42:56,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:56,041 INFO:     Epoch: 87
2022-11-23 00:42:56,858 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7886074930429459, 'Total loss': 0.7886074930429459} | train loss {'Reaction outcome loss': 0.8099676900573315, 'Total loss': 0.8099676900573315}
2022-11-23 00:42:56,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:56,859 INFO:     Epoch: 88
2022-11-23 00:42:57,700 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7694001990285787, 'Total loss': 0.7694001990285787} | train loss {'Reaction outcome loss': 0.8118220357404601, 'Total loss': 0.8118220357404601}
2022-11-23 00:42:57,700 INFO:     Found new best model at epoch 88
2022-11-23 00:42:57,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:57,701 INFO:     Epoch: 89
2022-11-23 00:42:58,520 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7846437834880569, 'Total loss': 0.7846437834880569} | train loss {'Reaction outcome loss': 0.8142720714451805, 'Total loss': 0.8142720714451805}
2022-11-23 00:42:58,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:58,520 INFO:     Epoch: 90
2022-11-23 00:42:59,364 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7835095016793772, 'Total loss': 0.7835095016793772} | train loss {'Reaction outcome loss': 0.8206565828332978, 'Total loss': 0.8206565828332978}
2022-11-23 00:42:59,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:42:59,364 INFO:     Epoch: 91
2022-11-23 00:43:00,240 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7850252024152062, 'Total loss': 0.7850252024152062} | train loss {'Reaction outcome loss': 0.8171528810935635, 'Total loss': 0.8171528810935635}
2022-11-23 00:43:00,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:00,241 INFO:     Epoch: 92
2022-11-23 00:43:01,069 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7817341576923024, 'Total loss': 0.7817341576923024} | train loss {'Reaction outcome loss': 0.8125666149200932, 'Total loss': 0.8125666149200932}
2022-11-23 00:43:01,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:01,069 INFO:     Epoch: 93
2022-11-23 00:43:01,886 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7894979986277494, 'Total loss': 0.7894979986277494} | train loss {'Reaction outcome loss': 0.8115779525570331, 'Total loss': 0.8115779525570331}
2022-11-23 00:43:01,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:01,886 INFO:     Epoch: 94
2022-11-23 00:43:02,718 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7859599610621278, 'Total loss': 0.7859599610621278} | train loss {'Reaction outcome loss': 0.817292734019218, 'Total loss': 0.817292734019218}
2022-11-23 00:43:02,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:02,719 INFO:     Epoch: 95
2022-11-23 00:43:03,569 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7774061167782004, 'Total loss': 0.7774061167782004} | train loss {'Reaction outcome loss': 0.81127856828032, 'Total loss': 0.81127856828032}
2022-11-23 00:43:03,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:03,570 INFO:     Epoch: 96
2022-11-23 00:43:04,382 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7852042737332258, 'Total loss': 0.7852042737332258} | train loss {'Reaction outcome loss': 0.8202106188381871, 'Total loss': 0.8202106188381871}
2022-11-23 00:43:04,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:04,382 INFO:     Epoch: 97
2022-11-23 00:43:05,220 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7910674823956056, 'Total loss': 0.7910674823956056} | train loss {'Reaction outcome loss': 0.8167588605034736, 'Total loss': 0.8167588605034736}
2022-11-23 00:43:05,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:05,220 INFO:     Epoch: 98
2022-11-23 00:43:06,023 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7771564600142565, 'Total loss': 0.7771564600142565} | train loss {'Reaction outcome loss': 0.8143789444959932, 'Total loss': 0.8143789444959932}
2022-11-23 00:43:06,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:06,023 INFO:     Epoch: 99
2022-11-23 00:43:06,834 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7768305242061615, 'Total loss': 0.7768305242061615} | train loss {'Reaction outcome loss': 0.8122869072662245, 'Total loss': 0.8122869072662245}
2022-11-23 00:43:06,834 INFO:     Best model found after epoch 89 of 100.
2022-11-23 00:43:06,834 INFO:   Done with stage: TRAINING
2022-11-23 00:43:06,834 INFO:   Starting stage: EVALUATION
2022-11-23 00:43:06,953 INFO:   Done with stage: EVALUATION
2022-11-23 00:43:06,953 INFO:   Leaving out SEQ value Fold_7
2022-11-23 00:43:06,966 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-23 00:43:06,967 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:43:07,638 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:43:07,638 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:43:07,710 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:43:07,710 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:43:07,711 INFO:     No hyperparam tuning for this model
2022-11-23 00:43:07,711 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:43:07,711 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:43:07,712 INFO:     None feature selector for col prot
2022-11-23 00:43:07,712 INFO:     None feature selector for col prot
2022-11-23 00:43:07,712 INFO:     None feature selector for col prot
2022-11-23 00:43:07,712 INFO:     None feature selector for col chem
2022-11-23 00:43:07,713 INFO:     None feature selector for col chem
2022-11-23 00:43:07,713 INFO:     None feature selector for col chem
2022-11-23 00:43:07,713 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:43:07,713 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:43:07,714 INFO:     Number of params in model 168571
2022-11-23 00:43:07,718 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:43:07,718 INFO:   Starting stage: TRAINING
2022-11-23 00:43:07,776 INFO:     Val loss before train {'Reaction outcome loss': 1.0391480132590893, 'Total loss': 1.0391480132590893}
2022-11-23 00:43:07,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:07,776 INFO:     Epoch: 0
2022-11-23 00:43:08,595 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8296488662098729, 'Total loss': 0.8296488662098729} | train loss {'Reaction outcome loss': 0.8654773265856212, 'Total loss': 0.8654773265856212}
2022-11-23 00:43:08,595 INFO:     Found new best model at epoch 0
2022-11-23 00:43:08,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:08,596 INFO:     Epoch: 1
2022-11-23 00:43:09,383 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8649913987448049, 'Total loss': 0.8649913987448049} | train loss {'Reaction outcome loss': 0.8330218995936581, 'Total loss': 0.8330218995936581}
2022-11-23 00:43:09,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:09,384 INFO:     Epoch: 2
2022-11-23 00:43:10,191 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.84967248800189, 'Total loss': 0.84967248800189} | train loss {'Reaction outcome loss': 0.8254488859264577, 'Total loss': 0.8254488859264577}
2022-11-23 00:43:10,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:10,191 INFO:     Epoch: 3
2022-11-23 00:43:11,067 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8312405791393546, 'Total loss': 0.8312405791393546} | train loss {'Reaction outcome loss': 0.8205145174851183, 'Total loss': 0.8205145174851183}
2022-11-23 00:43:11,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:11,067 INFO:     Epoch: 4
2022-11-23 00:43:11,864 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8148753220258758, 'Total loss': 0.8148753220258758} | train loss {'Reaction outcome loss': 0.8185210931496542, 'Total loss': 0.8185210931496542}
2022-11-23 00:43:11,864 INFO:     Found new best model at epoch 4
2022-11-23 00:43:11,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:11,865 INFO:     Epoch: 5
2022-11-23 00:43:12,692 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8233389431654021, 'Total loss': 0.8233389431654021} | train loss {'Reaction outcome loss': 0.8127066445399503, 'Total loss': 0.8127066445399503}
2022-11-23 00:43:12,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:12,693 INFO:     Epoch: 6
2022-11-23 00:43:13,516 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8155861122663631, 'Total loss': 0.8155861122663631} | train loss {'Reaction outcome loss': 0.8124281128898996, 'Total loss': 0.8124281128898996}
2022-11-23 00:43:13,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:13,516 INFO:     Epoch: 7
2022-11-23 00:43:14,329 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8320626540239467, 'Total loss': 0.8320626540239467} | train loss {'Reaction outcome loss': 0.8080267153802465, 'Total loss': 0.8080267153802465}
2022-11-23 00:43:14,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:14,330 INFO:     Epoch: 8
2022-11-23 00:43:15,132 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8107874178609182, 'Total loss': 0.8107874178609182} | train loss {'Reaction outcome loss': 0.8096612009112952, 'Total loss': 0.8096612009112952}
2022-11-23 00:43:15,132 INFO:     Found new best model at epoch 8
2022-11-23 00:43:15,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:15,133 INFO:     Epoch: 9
2022-11-23 00:43:16,022 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8336037300353827, 'Total loss': 0.8336037300353827} | train loss {'Reaction outcome loss': 0.801850645879253, 'Total loss': 0.801850645879253}
2022-11-23 00:43:16,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:16,023 INFO:     Epoch: 10
2022-11-23 00:43:16,824 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8248858049858449, 'Total loss': 0.8248858049858449} | train loss {'Reaction outcome loss': 0.8074163378017848, 'Total loss': 0.8074163378017848}
2022-11-23 00:43:16,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:16,824 INFO:     Epoch: 11
2022-11-23 00:43:17,660 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8437061490014542, 'Total loss': 0.8437061490014542} | train loss {'Reaction outcome loss': 0.8080120522712098, 'Total loss': 0.8080120522712098}
2022-11-23 00:43:17,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:17,660 INFO:     Epoch: 12
2022-11-23 00:43:18,495 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8329266399838203, 'Total loss': 0.8329266399838203} | train loss {'Reaction outcome loss': 0.8067634644322708, 'Total loss': 0.8067634644322708}
2022-11-23 00:43:18,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:18,495 INFO:     Epoch: 13
2022-11-23 00:43:19,367 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8179472608621731, 'Total loss': 0.8179472608621731} | train loss {'Reaction outcome loss': 0.8059622327812382, 'Total loss': 0.8059622327812382}
2022-11-23 00:43:19,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:19,368 INFO:     Epoch: 14
2022-11-23 00:43:20,194 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8202524753504021, 'Total loss': 0.8202524753504021} | train loss {'Reaction outcome loss': 0.8031789808244002, 'Total loss': 0.8031789808244002}
2022-11-23 00:43:20,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:20,195 INFO:     Epoch: 15
2022-11-23 00:43:21,001 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8065391231414883, 'Total loss': 0.8065391231414883} | train loss {'Reaction outcome loss': 0.8085672592774766, 'Total loss': 0.8085672592774766}
2022-11-23 00:43:21,001 INFO:     Found new best model at epoch 15
2022-11-23 00:43:21,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:21,002 INFO:     Epoch: 16
2022-11-23 00:43:21,814 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8371024187221083, 'Total loss': 0.8371024187221083} | train loss {'Reaction outcome loss': 0.795367140383994, 'Total loss': 0.795367140383994}
2022-11-23 00:43:21,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:21,814 INFO:     Epoch: 17
2022-11-23 00:43:22,674 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.800952686126842, 'Total loss': 0.800952686126842} | train loss {'Reaction outcome loss': 0.8068008596291307, 'Total loss': 0.8068008596291307}
2022-11-23 00:43:22,674 INFO:     Found new best model at epoch 17
2022-11-23 00:43:22,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:22,675 INFO:     Epoch: 18
2022-11-23 00:43:23,469 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8079344782718393, 'Total loss': 0.8079344782718393} | train loss {'Reaction outcome loss': 0.800042813063645, 'Total loss': 0.800042813063645}
2022-11-23 00:43:23,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:23,470 INFO:     Epoch: 19
2022-11-23 00:43:24,298 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8092601576516795, 'Total loss': 0.8092601576516795} | train loss {'Reaction outcome loss': 0.8087542105893619, 'Total loss': 0.8087542105893619}
2022-11-23 00:43:24,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:24,298 INFO:     Epoch: 20
2022-11-23 00:43:25,122 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8086728301159171, 'Total loss': 0.8086728301159171} | train loss {'Reaction outcome loss': 0.8041640908503142, 'Total loss': 0.8041640908503142}
2022-11-23 00:43:25,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:25,122 INFO:     Epoch: 21
2022-11-23 00:43:25,985 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8261875676554303, 'Total loss': 0.8261875676554303} | train loss {'Reaction outcome loss': 0.8036699306036605, 'Total loss': 0.8036699306036605}
2022-11-23 00:43:25,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:25,985 INFO:     Epoch: 22
2022-11-23 00:43:26,787 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8172132054040598, 'Total loss': 0.8172132054040598} | train loss {'Reaction outcome loss': 0.805356218433771, 'Total loss': 0.805356218433771}
2022-11-23 00:43:26,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:26,787 INFO:     Epoch: 23
2022-11-23 00:43:27,601 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8001235626464667, 'Total loss': 0.8001235626464667} | train loss {'Reaction outcome loss': 0.803689749270189, 'Total loss': 0.803689749270189}
2022-11-23 00:43:27,601 INFO:     Found new best model at epoch 23
2022-11-23 00:43:27,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:27,602 INFO:     Epoch: 24
2022-11-23 00:43:28,395 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8080827226472456, 'Total loss': 0.8080827226472456} | train loss {'Reaction outcome loss': 0.8029809208189855, 'Total loss': 0.8029809208189855}
2022-11-23 00:43:28,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:28,397 INFO:     Epoch: 25
2022-11-23 00:43:29,163 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8024558508118917, 'Total loss': 0.8024558508118917} | train loss {'Reaction outcome loss': 0.8036835246154519, 'Total loss': 0.8036835246154519}
2022-11-23 00:43:29,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:29,163 INFO:     Epoch: 26
2022-11-23 00:43:29,962 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8241181664688643, 'Total loss': 0.8241181664688643} | train loss {'Reaction outcome loss': 0.7967846505954618, 'Total loss': 0.7967846505954618}
2022-11-23 00:43:29,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:29,962 INFO:     Epoch: 27
2022-11-23 00:43:30,792 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.815291375614876, 'Total loss': 0.815291375614876} | train loss {'Reaction outcome loss': 0.8031958335491477, 'Total loss': 0.8031958335491477}
2022-11-23 00:43:30,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:30,792 INFO:     Epoch: 28
2022-11-23 00:43:31,572 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.800152181192886, 'Total loss': 0.800152181192886} | train loss {'Reaction outcome loss': 0.802438839659339, 'Total loss': 0.802438839659339}
2022-11-23 00:43:31,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:31,572 INFO:     Epoch: 29
2022-11-23 00:43:32,335 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8054325178612111, 'Total loss': 0.8054325178612111} | train loss {'Reaction outcome loss': 0.8025041543802277, 'Total loss': 0.8025041543802277}
2022-11-23 00:43:32,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:32,336 INFO:     Epoch: 30
2022-11-23 00:43:33,084 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8505137881567312, 'Total loss': 0.8505137881567312} | train loss {'Reaction outcome loss': 0.7992966434017557, 'Total loss': 0.7992966434017557}
2022-11-23 00:43:33,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:33,084 INFO:     Epoch: 31
2022-11-23 00:43:33,873 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8244753355203673, 'Total loss': 0.8244753355203673} | train loss {'Reaction outcome loss': 0.8045413143566398, 'Total loss': 0.8045413143566398}
2022-11-23 00:43:33,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:33,873 INFO:     Epoch: 32
2022-11-23 00:43:34,671 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8121602881786435, 'Total loss': 0.8121602881786435} | train loss {'Reaction outcome loss': 0.8022300256568877, 'Total loss': 0.8022300256568877}
2022-11-23 00:43:34,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:34,672 INFO:     Epoch: 33
2022-11-23 00:43:35,445 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.827242793038834, 'Total loss': 0.827242793038834} | train loss {'Reaction outcome loss': 0.7992201073736441, 'Total loss': 0.7992201073736441}
2022-11-23 00:43:35,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:35,445 INFO:     Epoch: 34
2022-11-23 00:43:36,234 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8128211401229681, 'Total loss': 0.8128211401229681} | train loss {'Reaction outcome loss': 0.8017679460224558, 'Total loss': 0.8017679460224558}
2022-11-23 00:43:36,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:36,234 INFO:     Epoch: 35
2022-11-23 00:43:37,037 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8025665484195532, 'Total loss': 0.8025665484195532} | train loss {'Reaction outcome loss': 0.8019090954397545, 'Total loss': 0.8019090954397545}
2022-11-23 00:43:37,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:37,037 INFO:     Epoch: 36
2022-11-23 00:43:37,824 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8379727692105049, 'Total loss': 0.8379727692105049} | train loss {'Reaction outcome loss': 0.7979003430389967, 'Total loss': 0.7979003430389967}
2022-11-23 00:43:37,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:37,824 INFO:     Epoch: 37
2022-11-23 00:43:38,620 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8214913918528446, 'Total loss': 0.8214913918528446} | train loss {'Reaction outcome loss': 0.8019497068446191, 'Total loss': 0.8019497068446191}
2022-11-23 00:43:38,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:38,620 INFO:     Epoch: 38
2022-11-23 00:43:39,438 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8078449222930643, 'Total loss': 0.8078449222930643} | train loss {'Reaction outcome loss': 0.8009011781484378, 'Total loss': 0.8009011781484378}
2022-11-23 00:43:39,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:39,439 INFO:     Epoch: 39
2022-11-23 00:43:40,243 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8040968318318211, 'Total loss': 0.8040968318318211} | train loss {'Reaction outcome loss': 0.8059583380818367, 'Total loss': 0.8059583380818367}
2022-11-23 00:43:40,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:40,244 INFO:     Epoch: 40
2022-11-23 00:43:41,001 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.798070466795633, 'Total loss': 0.798070466795633} | train loss {'Reaction outcome loss': 0.7994470261648053, 'Total loss': 0.7994470261648053}
2022-11-23 00:43:41,002 INFO:     Found new best model at epoch 40
2022-11-23 00:43:41,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:41,002 INFO:     Epoch: 41
2022-11-23 00:43:41,843 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.800534539444502, 'Total loss': 0.800534539444502} | train loss {'Reaction outcome loss': 0.8001710678466031, 'Total loss': 0.8001710678466031}
2022-11-23 00:43:41,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:41,844 INFO:     Epoch: 42
2022-11-23 00:43:42,677 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8252288130826728, 'Total loss': 0.8252288130826728} | train loss {'Reaction outcome loss': 0.7993132762733053, 'Total loss': 0.7993132762733053}
2022-11-23 00:43:42,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:42,677 INFO:     Epoch: 43
2022-11-23 00:43:43,476 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7987400958704394, 'Total loss': 0.7987400958704394} | train loss {'Reaction outcome loss': 0.8025331039164887, 'Total loss': 0.8025331039164887}
2022-11-23 00:43:43,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:43,476 INFO:     Epoch: 44
2022-11-23 00:43:44,261 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8191058413926945, 'Total loss': 0.8191058413926945} | train loss {'Reaction outcome loss': 0.7960071080043668, 'Total loss': 0.7960071080043668}
2022-11-23 00:43:44,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:44,261 INFO:     Epoch: 45
2022-11-23 00:43:45,007 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8188548697981723, 'Total loss': 0.8188548697981723} | train loss {'Reaction outcome loss': 0.8011243629162429, 'Total loss': 0.8011243629162429}
2022-11-23 00:43:45,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:45,007 INFO:     Epoch: 46
2022-11-23 00:43:45,814 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8202145910540293, 'Total loss': 0.8202145910540293} | train loss {'Reaction outcome loss': 0.7997618735325142, 'Total loss': 0.7997618735325142}
2022-11-23 00:43:45,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:45,814 INFO:     Epoch: 47
2022-11-23 00:43:46,624 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8196990379067355, 'Total loss': 0.8196990379067355} | train loss {'Reaction outcome loss': 0.7998552081770585, 'Total loss': 0.7998552081770585}
2022-11-23 00:43:46,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:46,624 INFO:     Epoch: 48
2022-11-23 00:43:47,454 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7975443102592645, 'Total loss': 0.7975443102592645} | train loss {'Reaction outcome loss': 0.7967869865356899, 'Total loss': 0.7967869865356899}
2022-11-23 00:43:47,454 INFO:     Found new best model at epoch 48
2022-11-23 00:43:47,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:47,455 INFO:     Epoch: 49
2022-11-23 00:43:48,251 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.860335857369179, 'Total loss': 0.860335857369179} | train loss {'Reaction outcome loss': 0.8013509371485866, 'Total loss': 0.8013509371485866}
2022-11-23 00:43:48,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:48,251 INFO:     Epoch: 50
2022-11-23 00:43:49,023 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8082218045412108, 'Total loss': 0.8082218045412108} | train loss {'Reaction outcome loss': 0.8014714764278443, 'Total loss': 0.8014714764278443}
2022-11-23 00:43:49,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:49,023 INFO:     Epoch: 51
2022-11-23 00:43:49,826 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7960282598817071, 'Total loss': 0.7960282598817071} | train loss {'Reaction outcome loss': 0.7960430680484069, 'Total loss': 0.7960430680484069}
2022-11-23 00:43:49,826 INFO:     Found new best model at epoch 51
2022-11-23 00:43:49,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:49,827 INFO:     Epoch: 52
2022-11-23 00:43:50,623 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8125465366729471, 'Total loss': 0.8125465366729471} | train loss {'Reaction outcome loss': 0.798087689475935, 'Total loss': 0.798087689475935}
2022-11-23 00:43:50,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:50,623 INFO:     Epoch: 53
2022-11-23 00:43:51,382 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8109479754470116, 'Total loss': 0.8109479754470116} | train loss {'Reaction outcome loss': 0.7973173922691189, 'Total loss': 0.7973173922691189}
2022-11-23 00:43:51,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:51,382 INFO:     Epoch: 54
2022-11-23 00:43:52,187 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8067023865012235, 'Total loss': 0.8067023865012235} | train loss {'Reaction outcome loss': 0.7971584337656615, 'Total loss': 0.7971584337656615}
2022-11-23 00:43:52,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:52,187 INFO:     Epoch: 55
2022-11-23 00:43:52,960 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8223429890566094, 'Total loss': 0.8223429890566094} | train loss {'Reaction outcome loss': 0.7967149498032742, 'Total loss': 0.7967149498032742}
2022-11-23 00:43:52,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:52,960 INFO:     Epoch: 56
2022-11-23 00:43:53,756 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8199873317119687, 'Total loss': 0.8199873317119687} | train loss {'Reaction outcome loss': 0.7998267795707359, 'Total loss': 0.7998267795707359}
2022-11-23 00:43:53,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:53,756 INFO:     Epoch: 57
2022-11-23 00:43:54,520 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7999508367028347, 'Total loss': 0.7999508367028347} | train loss {'Reaction outcome loss': 0.798141891961215, 'Total loss': 0.798141891961215}
2022-11-23 00:43:54,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:54,520 INFO:     Epoch: 58
2022-11-23 00:43:55,343 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8102286832277165, 'Total loss': 0.8102286832277165} | train loss {'Reaction outcome loss': 0.7959408289829238, 'Total loss': 0.7959408289829238}
2022-11-23 00:43:55,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:55,343 INFO:     Epoch: 59
2022-11-23 00:43:56,133 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7916200611480447, 'Total loss': 0.7916200611480447} | train loss {'Reaction outcome loss': 0.7936464561546435, 'Total loss': 0.7936464561546435}
2022-11-23 00:43:56,133 INFO:     Found new best model at epoch 59
2022-11-23 00:43:56,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:56,134 INFO:     Epoch: 60
2022-11-23 00:43:56,927 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.808406145766724, 'Total loss': 0.808406145766724} | train loss {'Reaction outcome loss': 0.7944984956354392, 'Total loss': 0.7944984956354392}
2022-11-23 00:43:56,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:56,927 INFO:     Epoch: 61
2022-11-23 00:43:57,704 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8034919902335765, 'Total loss': 0.8034919902335765} | train loss {'Reaction outcome loss': 0.7949845738342551, 'Total loss': 0.7949845738342551}
2022-11-23 00:43:57,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:57,704 INFO:     Epoch: 62
2022-11-23 00:43:58,498 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8065833934517794, 'Total loss': 0.8065833934517794} | train loss {'Reaction outcome loss': 0.7975088227234903, 'Total loss': 0.7975088227234903}
2022-11-23 00:43:58,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:58,499 INFO:     Epoch: 63
2022-11-23 00:43:59,328 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8083182739657025, 'Total loss': 0.8083182739657025} | train loss {'Reaction outcome loss': 0.7953074986084563, 'Total loss': 0.7953074986084563}
2022-11-23 00:43:59,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:43:59,329 INFO:     Epoch: 64
2022-11-23 00:44:00,126 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8299023023871488, 'Total loss': 0.8299023023871488} | train loss {'Reaction outcome loss': 0.8086581762696876, 'Total loss': 0.8086581762696876}
2022-11-23 00:44:00,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:00,126 INFO:     Epoch: 65
2022-11-23 00:44:00,926 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7953633326430654, 'Total loss': 0.7953633326430654} | train loss {'Reaction outcome loss': 0.7996922255050941, 'Total loss': 0.7996922255050941}
2022-11-23 00:44:00,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:00,926 INFO:     Epoch: 66
2022-11-23 00:44:01,749 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8056737905324891, 'Total loss': 0.8056737905324891} | train loss {'Reaction outcome loss': 0.7957486167061524, 'Total loss': 0.7957486167061524}
2022-11-23 00:44:01,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:01,749 INFO:     Epoch: 67
2022-11-23 00:44:02,552 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7907229661941528, 'Total loss': 0.7907229661941528} | train loss {'Reaction outcome loss': 0.795610811011713, 'Total loss': 0.795610811011713}
2022-11-23 00:44:02,552 INFO:     Found new best model at epoch 67
2022-11-23 00:44:02,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:02,553 INFO:     Epoch: 68
2022-11-23 00:44:03,341 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8223146103149237, 'Total loss': 0.8223146103149237} | train loss {'Reaction outcome loss': 0.7989220240565597, 'Total loss': 0.7989220240565597}
2022-11-23 00:44:03,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:03,341 INFO:     Epoch: 69
2022-11-23 00:44:04,128 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7971374018247738, 'Total loss': 0.7971374018247738} | train loss {'Reaction outcome loss': 0.7945222739802033, 'Total loss': 0.7945222739802033}
2022-11-23 00:44:04,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:04,128 INFO:     Epoch: 70
2022-11-23 00:44:04,925 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7868284139522287, 'Total loss': 0.7868284139522287} | train loss {'Reaction outcome loss': 0.79197118113764, 'Total loss': 0.79197118113764}
2022-11-23 00:44:04,925 INFO:     Found new best model at epoch 70
2022-11-23 00:44:04,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:04,926 INFO:     Epoch: 71
2022-11-23 00:44:05,764 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8055237379184988, 'Total loss': 0.8055237379184988} | train loss {'Reaction outcome loss': 0.7950104660675174, 'Total loss': 0.7950104660675174}
2022-11-23 00:44:05,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:05,765 INFO:     Epoch: 72
2022-11-23 00:44:06,537 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8222466624060343, 'Total loss': 0.8222466624060343} | train loss {'Reaction outcome loss': 0.7925811670109874, 'Total loss': 0.7925811670109874}
2022-11-23 00:44:06,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:06,537 INFO:     Epoch: 73
2022-11-23 00:44:07,298 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8062414651693299, 'Total loss': 0.8062414651693299} | train loss {'Reaction outcome loss': 0.7938164518993409, 'Total loss': 0.7938164518993409}
2022-11-23 00:44:07,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:07,298 INFO:     Epoch: 74
2022-11-23 00:44:08,153 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.806481541589249, 'Total loss': 0.806481541589249} | train loss {'Reaction outcome loss': 0.7885271324241747, 'Total loss': 0.7885271324241747}
2022-11-23 00:44:08,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:08,153 INFO:     Epoch: 75
2022-11-23 00:44:08,943 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7907306794510331, 'Total loss': 0.7907306794510331} | train loss {'Reaction outcome loss': 0.7938599051510702, 'Total loss': 0.7938599051510702}
2022-11-23 00:44:08,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:08,944 INFO:     Epoch: 76
2022-11-23 00:44:09,744 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.800327694693277, 'Total loss': 0.800327694693277} | train loss {'Reaction outcome loss': 0.7918432586994327, 'Total loss': 0.7918432586994327}
2022-11-23 00:44:09,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:09,744 INFO:     Epoch: 77
2022-11-23 00:44:10,561 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8219460512316504, 'Total loss': 0.8219460512316504} | train loss {'Reaction outcome loss': 0.7880500959324055, 'Total loss': 0.7880500959324055}
2022-11-23 00:44:10,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:10,561 INFO:     Epoch: 78
2022-11-23 00:44:11,340 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7830440575300261, 'Total loss': 0.7830440575300261} | train loss {'Reaction outcome loss': 0.787113356419274, 'Total loss': 0.787113356419274}
2022-11-23 00:44:11,340 INFO:     Found new best model at epoch 78
2022-11-23 00:44:11,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:11,341 INFO:     Epoch: 79
2022-11-23 00:44:12,148 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8045549060023108, 'Total loss': 0.8045549060023108} | train loss {'Reaction outcome loss': 0.7960330889117523, 'Total loss': 0.7960330889117523}
2022-11-23 00:44:12,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:12,149 INFO:     Epoch: 80
2022-11-23 00:44:12,973 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8137718522271444, 'Total loss': 0.8137718522271444} | train loss {'Reaction outcome loss': 0.7925387220304521, 'Total loss': 0.7925387220304521}
2022-11-23 00:44:12,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:12,973 INFO:     Epoch: 81
2022-11-23 00:44:13,751 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8056386224059171, 'Total loss': 0.8056386224059171} | train loss {'Reaction outcome loss': 0.7871285322748247, 'Total loss': 0.7871285322748247}
2022-11-23 00:44:13,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:13,751 INFO:     Epoch: 82
2022-11-23 00:44:14,554 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7731141655944115, 'Total loss': 0.7731141655944115} | train loss {'Reaction outcome loss': 0.7911983801693213, 'Total loss': 0.7911983801693213}
2022-11-23 00:44:14,555 INFO:     Found new best model at epoch 82
2022-11-23 00:44:14,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:14,555 INFO:     Epoch: 83
2022-11-23 00:44:15,378 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7914632510307223, 'Total loss': 0.7914632510307223} | train loss {'Reaction outcome loss': 0.7837840969689557, 'Total loss': 0.7837840969689557}
2022-11-23 00:44:15,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:15,379 INFO:     Epoch: 84
2022-11-23 00:44:16,163 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8022416213224101, 'Total loss': 0.8022416213224101} | train loss {'Reaction outcome loss': 0.7880735984835469, 'Total loss': 0.7880735984835469}
2022-11-23 00:44:16,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:16,163 INFO:     Epoch: 85
2022-11-23 00:44:16,943 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7996059572973917, 'Total loss': 0.7996059572973917} | train loss {'Reaction outcome loss': 0.7808324348975401, 'Total loss': 0.7808324348975401}
2022-11-23 00:44:16,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:16,943 INFO:     Epoch: 86
2022-11-23 00:44:17,702 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.805456819922425, 'Total loss': 0.805456819922425} | train loss {'Reaction outcome loss': 0.7852722508985488, 'Total loss': 0.7852722508985488}
2022-11-23 00:44:17,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:17,703 INFO:     Epoch: 87
2022-11-23 00:44:18,496 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7930567333864611, 'Total loss': 0.7930567333864611} | train loss {'Reaction outcome loss': 0.7832276540212944, 'Total loss': 0.7832276540212944}
2022-11-23 00:44:18,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:18,497 INFO:     Epoch: 88
2022-11-23 00:44:19,297 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7805547977602759, 'Total loss': 0.7805547977602759} | train loss {'Reaction outcome loss': 0.7809924695824013, 'Total loss': 0.7809924695824013}
2022-11-23 00:44:19,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:19,297 INFO:     Epoch: 89
2022-11-23 00:44:20,115 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8090666380039481, 'Total loss': 0.8090666380039481} | train loss {'Reaction outcome loss': 0.7850056716897449, 'Total loss': 0.7850056716897449}
2022-11-23 00:44:20,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:20,115 INFO:     Epoch: 90
2022-11-23 00:44:20,892 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7872551346934119, 'Total loss': 0.7872551346934119} | train loss {'Reaction outcome loss': 0.7816803984221865, 'Total loss': 0.7816803984221865}
2022-11-23 00:44:20,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:20,892 INFO:     Epoch: 91
2022-11-23 00:44:21,711 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7750494078148243, 'Total loss': 0.7750494078148243} | train loss {'Reaction outcome loss': 0.7769468021197398, 'Total loss': 0.7769468021197398}
2022-11-23 00:44:21,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:21,711 INFO:     Epoch: 92
2022-11-23 00:44:22,512 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8096169559068458, 'Total loss': 0.8096169559068458} | train loss {'Reaction outcome loss': 0.7728735496763324, 'Total loss': 0.7728735496763324}
2022-11-23 00:44:22,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:22,513 INFO:     Epoch: 93
2022-11-23 00:44:23,294 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8139993853347246, 'Total loss': 0.8139993853347246} | train loss {'Reaction outcome loss': 0.7796857990935201, 'Total loss': 0.7796857990935201}
2022-11-23 00:44:23,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:23,294 INFO:     Epoch: 94
2022-11-23 00:44:24,099 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7609493864137072, 'Total loss': 0.7609493864137072} | train loss {'Reaction outcome loss': 0.7771544676335131, 'Total loss': 0.7771544676335131}
2022-11-23 00:44:24,100 INFO:     Found new best model at epoch 94
2022-11-23 00:44:24,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:24,100 INFO:     Epoch: 95
2022-11-23 00:44:24,899 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8115446969520214, 'Total loss': 0.8115446969520214} | train loss {'Reaction outcome loss': 0.7777172851025081, 'Total loss': 0.7777172851025081}
2022-11-23 00:44:24,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:24,899 INFO:     Epoch: 96
2022-11-23 00:44:25,713 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.764793477779211, 'Total loss': 0.764793477779211} | train loss {'Reaction outcome loss': 0.775648372950124, 'Total loss': 0.775648372950124}
2022-11-23 00:44:25,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:25,714 INFO:     Epoch: 97
2022-11-23 00:44:26,517 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.773617239885552, 'Total loss': 0.773617239885552} | train loss {'Reaction outcome loss': 0.7702155805757789, 'Total loss': 0.7702155805757789}
2022-11-23 00:44:26,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:26,517 INFO:     Epoch: 98
2022-11-23 00:44:27,329 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7769684257895447, 'Total loss': 0.7769684257895447} | train loss {'Reaction outcome loss': 0.773175376604815, 'Total loss': 0.773175376604815}
2022-11-23 00:44:27,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:27,329 INFO:     Epoch: 99
2022-11-23 00:44:28,124 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.790811792362568, 'Total loss': 0.790811792362568} | train loss {'Reaction outcome loss': 0.7752620232154112, 'Total loss': 0.7752620232154112}
2022-11-23 00:44:28,124 INFO:     Best model found after epoch 95 of 100.
2022-11-23 00:44:28,125 INFO:   Done with stage: TRAINING
2022-11-23 00:44:28,125 INFO:   Starting stage: EVALUATION
2022-11-23 00:44:28,262 INFO:   Done with stage: EVALUATION
2022-11-23 00:44:28,262 INFO:   Leaving out SEQ value Fold_8
2022-11-23 00:44:28,275 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 00:44:28,275 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:44:28,942 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:44:28,942 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:44:29,012 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:44:29,012 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:44:29,012 INFO:     No hyperparam tuning for this model
2022-11-23 00:44:29,012 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:44:29,012 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:44:29,013 INFO:     None feature selector for col prot
2022-11-23 00:44:29,013 INFO:     None feature selector for col prot
2022-11-23 00:44:29,013 INFO:     None feature selector for col prot
2022-11-23 00:44:29,014 INFO:     None feature selector for col chem
2022-11-23 00:44:29,014 INFO:     None feature selector for col chem
2022-11-23 00:44:29,014 INFO:     None feature selector for col chem
2022-11-23 00:44:29,014 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:44:29,014 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:44:29,015 INFO:     Number of params in model 168571
2022-11-23 00:44:29,019 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:44:29,019 INFO:   Starting stage: TRAINING
2022-11-23 00:44:29,079 INFO:     Val loss before train {'Reaction outcome loss': 0.9967152808200229, 'Total loss': 0.9967152808200229}
2022-11-23 00:44:29,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:29,080 INFO:     Epoch: 0
2022-11-23 00:44:29,875 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8085954676974904, 'Total loss': 0.8085954676974904} | train loss {'Reaction outcome loss': 0.894774058388795, 'Total loss': 0.894774058388795}
2022-11-23 00:44:29,876 INFO:     Found new best model at epoch 0
2022-11-23 00:44:29,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:29,877 INFO:     Epoch: 1
2022-11-23 00:44:30,649 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8079959872094068, 'Total loss': 0.8079959872094068} | train loss {'Reaction outcome loss': 0.8731335245887277, 'Total loss': 0.8731335245887277}
2022-11-23 00:44:30,649 INFO:     Found new best model at epoch 1
2022-11-23 00:44:30,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:30,650 INFO:     Epoch: 2
2022-11-23 00:44:31,473 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8095567070625045, 'Total loss': 0.8095567070625045} | train loss {'Reaction outcome loss': 0.8586716871512564, 'Total loss': 0.8586716871512564}
2022-11-23 00:44:31,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:31,473 INFO:     Epoch: 3
2022-11-23 00:44:32,292 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8068865009329536, 'Total loss': 0.8068865009329536} | train loss {'Reaction outcome loss': 0.8580892415423143, 'Total loss': 0.8580892415423143}
2022-11-23 00:44:32,292 INFO:     Found new best model at epoch 3
2022-11-23 00:44:32,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:32,293 INFO:     Epoch: 4
2022-11-23 00:44:33,160 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8282088217410174, 'Total loss': 0.8282088217410174} | train loss {'Reaction outcome loss': 0.8569530527360043, 'Total loss': 0.8569530527360043}
2022-11-23 00:44:33,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:33,160 INFO:     Epoch: 5
2022-11-23 00:44:34,003 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8130268176848238, 'Total loss': 0.8130268176848238} | train loss {'Reaction outcome loss': 0.8392910052407608, 'Total loss': 0.8392910052407608}
2022-11-23 00:44:34,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:34,004 INFO:     Epoch: 6
2022-11-23 00:44:34,820 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.799746264110912, 'Total loss': 0.799746264110912} | train loss {'Reaction outcome loss': 0.8448341876147729, 'Total loss': 0.8448341876147729}
2022-11-23 00:44:34,820 INFO:     Found new best model at epoch 6
2022-11-23 00:44:34,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:34,821 INFO:     Epoch: 7
2022-11-23 00:44:35,582 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7913282676176592, 'Total loss': 0.7913282676176592} | train loss {'Reaction outcome loss': 0.8421961943871579, 'Total loss': 0.8421961943871579}
2022-11-23 00:44:35,582 INFO:     Found new best model at epoch 7
2022-11-23 00:44:35,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:35,583 INFO:     Epoch: 8
2022-11-23 00:44:36,374 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7965313467112455, 'Total loss': 0.7965313467112455} | train loss {'Reaction outcome loss': 0.8470110454660679, 'Total loss': 0.8470110454660679}
2022-11-23 00:44:36,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:36,375 INFO:     Epoch: 9
2022-11-23 00:44:37,177 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8227481063116681, 'Total loss': 0.8227481063116681} | train loss {'Reaction outcome loss': 0.8380716082296873, 'Total loss': 0.8380716082296873}
2022-11-23 00:44:37,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:37,177 INFO:     Epoch: 10
2022-11-23 00:44:37,979 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8035373132337224, 'Total loss': 0.8035373132337224} | train loss {'Reaction outcome loss': 0.837720785003442, 'Total loss': 0.837720785003442}
2022-11-23 00:44:37,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:37,980 INFO:     Epoch: 11
2022-11-23 00:44:38,761 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8196649273688142, 'Total loss': 0.8196649273688142} | train loss {'Reaction outcome loss': 0.8392030414540758, 'Total loss': 0.8392030414540758}
2022-11-23 00:44:38,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:38,761 INFO:     Epoch: 12
2022-11-23 00:44:39,576 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7807558686895804, 'Total loss': 0.7807558686895804} | train loss {'Reaction outcome loss': 0.8404401403207046, 'Total loss': 0.8404401403207046}
2022-11-23 00:44:39,577 INFO:     Found new best model at epoch 12
2022-11-23 00:44:39,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:39,577 INFO:     Epoch: 13
2022-11-23 00:44:40,322 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8176408592950214, 'Total loss': 0.8176408592950214} | train loss {'Reaction outcome loss': 0.8304958556993649, 'Total loss': 0.8304958556993649}
2022-11-23 00:44:40,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:40,322 INFO:     Epoch: 14
2022-11-23 00:44:41,173 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7855281017043374, 'Total loss': 0.7855281017043374} | train loss {'Reaction outcome loss': 0.8329183464711495, 'Total loss': 0.8329183464711495}
2022-11-23 00:44:41,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:41,174 INFO:     Epoch: 15
2022-11-23 00:44:42,003 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7916111119768836, 'Total loss': 0.7916111119768836} | train loss {'Reaction outcome loss': 0.8362108881958583, 'Total loss': 0.8362108881958583}
2022-11-23 00:44:42,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:42,003 INFO:     Epoch: 16
2022-11-23 00:44:42,796 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7929459038105878, 'Total loss': 0.7929459038105878} | train loss {'Reaction outcome loss': 0.8332755706812206, 'Total loss': 0.8332755706812206}
2022-11-23 00:44:42,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:42,796 INFO:     Epoch: 17
2022-11-23 00:44:43,559 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7955928512594916, 'Total loss': 0.7955928512594916} | train loss {'Reaction outcome loss': 0.8339172864883293, 'Total loss': 0.8339172864883293}
2022-11-23 00:44:43,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:43,559 INFO:     Epoch: 18
2022-11-23 00:44:44,357 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7755721871825781, 'Total loss': 0.7755721871825781} | train loss {'Reaction outcome loss': 0.8297652230571638, 'Total loss': 0.8297652230571638}
2022-11-23 00:44:44,357 INFO:     Found new best model at epoch 18
2022-11-23 00:44:44,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:44,358 INFO:     Epoch: 19
2022-11-23 00:44:45,205 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7775998088446531, 'Total loss': 0.7775998088446531} | train loss {'Reaction outcome loss': 0.837326870273482, 'Total loss': 0.837326870273482}
2022-11-23 00:44:45,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:45,206 INFO:     Epoch: 20
2022-11-23 00:44:45,982 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7726612091064453, 'Total loss': 0.7726612091064453} | train loss {'Reaction outcome loss': 0.8377785547542186, 'Total loss': 0.8377785547542186}
2022-11-23 00:44:45,982 INFO:     Found new best model at epoch 20
2022-11-23 00:44:45,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:45,983 INFO:     Epoch: 21
2022-11-23 00:44:46,763 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8156598698009144, 'Total loss': 0.8156598698009144} | train loss {'Reaction outcome loss': 0.8312601571080656, 'Total loss': 0.8312601571080656}
2022-11-23 00:44:46,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:46,764 INFO:     Epoch: 22
2022-11-23 00:44:47,604 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7846718254414472, 'Total loss': 0.7846718254414472} | train loss {'Reaction outcome loss': 0.8301528872929604, 'Total loss': 0.8301528872929604}
2022-11-23 00:44:47,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:47,604 INFO:     Epoch: 23
2022-11-23 00:44:48,438 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7861544476314024, 'Total loss': 0.7861544476314024} | train loss {'Reaction outcome loss': 0.8342516465708312, 'Total loss': 0.8342516465708312}
2022-11-23 00:44:48,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:48,439 INFO:     Epoch: 24
2022-11-23 00:44:49,249 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7977848486466841, 'Total loss': 0.7977848486466841} | train loss {'Reaction outcome loss': 0.8417071376734899, 'Total loss': 0.8417071376734899}
2022-11-23 00:44:49,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:49,249 INFO:     Epoch: 25
2022-11-23 00:44:50,051 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7974386018785563, 'Total loss': 0.7974386018785563} | train loss {'Reaction outcome loss': 0.8381303959047264, 'Total loss': 0.8381303959047264}
2022-11-23 00:44:50,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:50,051 INFO:     Epoch: 26
2022-11-23 00:44:50,868 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7841345986182039, 'Total loss': 0.7841345986182039} | train loss {'Reaction outcome loss': 0.8392996886963786, 'Total loss': 0.8392996886963786}
2022-11-23 00:44:50,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:50,868 INFO:     Epoch: 27
2022-11-23 00:44:51,655 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7998335510492325, 'Total loss': 0.7998335510492325} | train loss {'Reaction outcome loss': 0.8349960723869231, 'Total loss': 0.8349960723869231}
2022-11-23 00:44:51,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:51,655 INFO:     Epoch: 28
2022-11-23 00:44:52,492 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7953376221385869, 'Total loss': 0.7953376221385869} | train loss {'Reaction outcome loss': 0.8344788034314569, 'Total loss': 0.8344788034314569}
2022-11-23 00:44:52,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:52,492 INFO:     Epoch: 29
2022-11-23 00:44:53,320 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.804441212253137, 'Total loss': 0.804441212253137} | train loss {'Reaction outcome loss': 0.8309749805854882, 'Total loss': 0.8309749805854882}
2022-11-23 00:44:53,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:53,320 INFO:     Epoch: 30
2022-11-23 00:44:54,125 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7813457399606705, 'Total loss': 0.7813457399606705} | train loss {'Reaction outcome loss': 0.8323548656364201, 'Total loss': 0.8323548656364201}
2022-11-23 00:44:54,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:54,125 INFO:     Epoch: 31
2022-11-23 00:44:54,907 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7834119552915747, 'Total loss': 0.7834119552915747} | train loss {'Reaction outcome loss': 0.8311927297457993, 'Total loss': 0.8311927297457993}
2022-11-23 00:44:54,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:54,907 INFO:     Epoch: 32
2022-11-23 00:44:55,709 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7742330580949783, 'Total loss': 0.7742330580949783} | train loss {'Reaction outcome loss': 0.8365880048226731, 'Total loss': 0.8365880048226731}
2022-11-23 00:44:55,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:55,710 INFO:     Epoch: 33
2022-11-23 00:44:56,534 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7862694412469864, 'Total loss': 0.7862694412469864} | train loss {'Reaction outcome loss': 0.8414669092367535, 'Total loss': 0.8414669092367535}
2022-11-23 00:44:56,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:56,535 INFO:     Epoch: 34
2022-11-23 00:44:57,313 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8021105453372002, 'Total loss': 0.8021105453372002} | train loss {'Reaction outcome loss': 0.8305450329172467, 'Total loss': 0.8305450329172467}
2022-11-23 00:44:57,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:57,313 INFO:     Epoch: 35
2022-11-23 00:44:58,145 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7844595333391969, 'Total loss': 0.7844595333391969} | train loss {'Reaction outcome loss': 0.8426461675871721, 'Total loss': 0.8426461675871721}
2022-11-23 00:44:58,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:58,145 INFO:     Epoch: 36
2022-11-23 00:44:58,968 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7706738331101157, 'Total loss': 0.7706738331101157} | train loss {'Reaction outcome loss': 0.8417540195017208, 'Total loss': 0.8417540195017208}
2022-11-23 00:44:58,969 INFO:     Found new best model at epoch 36
2022-11-23 00:44:58,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:58,970 INFO:     Epoch: 37
2022-11-23 00:44:59,751 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7894526117227294, 'Total loss': 0.7894526117227294} | train loss {'Reaction outcome loss': 0.8316306711932425, 'Total loss': 0.8316306711932425}
2022-11-23 00:44:59,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:44:59,752 INFO:     Epoch: 38
2022-11-23 00:45:00,545 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7959398634054444, 'Total loss': 0.7959398634054444} | train loss {'Reaction outcome loss': 0.8425603392515105, 'Total loss': 0.8425603392515105}
2022-11-23 00:45:00,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:00,546 INFO:     Epoch: 39
2022-11-23 00:45:01,331 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7881344800645654, 'Total loss': 0.7881344800645654} | train loss {'Reaction outcome loss': 0.8356707954575658, 'Total loss': 0.8356707954575658}
2022-11-23 00:45:01,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:01,333 INFO:     Epoch: 40
2022-11-23 00:45:02,188 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7827339382334189, 'Total loss': 0.7827339382334189} | train loss {'Reaction outcome loss': 0.8447707646530167, 'Total loss': 0.8447707646530167}
2022-11-23 00:45:02,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:02,189 INFO:     Epoch: 41
2022-11-23 00:45:02,963 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7874392799355767, 'Total loss': 0.7874392799355767} | train loss {'Reaction outcome loss': 0.8321776557789158, 'Total loss': 0.8321776557789158}
2022-11-23 00:45:02,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:02,963 INFO:     Epoch: 42
2022-11-23 00:45:03,798 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.785004195841876, 'Total loss': 0.785004195841876} | train loss {'Reaction outcome loss': 0.829363551925913, 'Total loss': 0.829363551925913}
2022-11-23 00:45:03,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:03,798 INFO:     Epoch: 43
2022-11-23 00:45:04,560 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8332041129469872, 'Total loss': 0.8332041129469872} | train loss {'Reaction outcome loss': 0.833918887473311, 'Total loss': 0.833918887473311}
2022-11-23 00:45:04,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:04,560 INFO:     Epoch: 44
2022-11-23 00:45:05,380 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7814844474196434, 'Total loss': 0.7814844474196434} | train loss {'Reaction outcome loss': 0.8316531990945097, 'Total loss': 0.8316531990945097}
2022-11-23 00:45:05,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:05,380 INFO:     Epoch: 45
2022-11-23 00:45:06,218 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7948777255686846, 'Total loss': 0.7948777255686846} | train loss {'Reaction outcome loss': 0.8330528749386791, 'Total loss': 0.8330528749386791}
2022-11-23 00:45:06,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:06,218 INFO:     Epoch: 46
2022-11-23 00:45:07,007 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7975544015114958, 'Total loss': 0.7975544015114958} | train loss {'Reaction outcome loss': 0.8327354589092587, 'Total loss': 0.8327354589092587}
2022-11-23 00:45:07,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:07,007 INFO:     Epoch: 47
2022-11-23 00:45:07,804 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.784163275225596, 'Total loss': 0.784163275225596} | train loss {'Reaction outcome loss': 0.840918679830999, 'Total loss': 0.840918679830999}
2022-11-23 00:45:07,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:07,806 INFO:     Epoch: 48
2022-11-23 00:45:08,635 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7985273660583929, 'Total loss': 0.7985273660583929} | train loss {'Reaction outcome loss': 0.8355501966196516, 'Total loss': 0.8355501966196516}
2022-11-23 00:45:08,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:08,635 INFO:     Epoch: 49
2022-11-23 00:45:09,416 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7816057076508348, 'Total loss': 0.7816057076508348} | train loss {'Reaction outcome loss': 0.8317926616562523, 'Total loss': 0.8317926616562523}
2022-11-23 00:45:09,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:09,416 INFO:     Epoch: 50
2022-11-23 00:45:10,231 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7857522090727632, 'Total loss': 0.7857522090727632} | train loss {'Reaction outcome loss': 0.8314735871336238, 'Total loss': 0.8314735871336238}
2022-11-23 00:45:10,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:10,232 INFO:     Epoch: 51
2022-11-23 00:45:11,013 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7864198406988924, 'Total loss': 0.7864198406988924} | train loss {'Reaction outcome loss': 0.8294746184397322, 'Total loss': 0.8294746184397322}
2022-11-23 00:45:11,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:11,013 INFO:     Epoch: 52
2022-11-23 00:45:11,825 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7804713330485604, 'Total loss': 0.7804713330485604} | train loss {'Reaction outcome loss': 0.8357401100488809, 'Total loss': 0.8357401100488809}
2022-11-23 00:45:11,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:11,826 INFO:     Epoch: 53
2022-11-23 00:45:12,665 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8117685886946592, 'Total loss': 0.8117685886946592} | train loss {'Reaction outcome loss': 0.8360475891756143, 'Total loss': 0.8360475891756143}
2022-11-23 00:45:12,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:12,666 INFO:     Epoch: 54
2022-11-23 00:45:13,456 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.798280117186633, 'Total loss': 0.798280117186633} | train loss {'Reaction outcome loss': 0.8322926029743936, 'Total loss': 0.8322926029743936}
2022-11-23 00:45:13,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:13,456 INFO:     Epoch: 55
2022-11-23 00:45:14,258 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7793918231671507, 'Total loss': 0.7793918231671507} | train loss {'Reaction outcome loss': 0.8441359481589514, 'Total loss': 0.8441359481589514}
2022-11-23 00:45:14,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:14,258 INFO:     Epoch: 56
2022-11-23 00:45:15,030 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7862673510204662, 'Total loss': 0.7862673510204662} | train loss {'Reaction outcome loss': 0.8328925353071468, 'Total loss': 0.8328925353071468}
2022-11-23 00:45:15,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:15,030 INFO:     Epoch: 57
2022-11-23 00:45:15,856 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7954961271448568, 'Total loss': 0.7954961271448568} | train loss {'Reaction outcome loss': 0.8328785932498423, 'Total loss': 0.8328785932498423}
2022-11-23 00:45:15,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:15,856 INFO:     Epoch: 58
2022-11-23 00:45:16,638 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7811239382082765, 'Total loss': 0.7811239382082765} | train loss {'Reaction outcome loss': 0.8341100108526979, 'Total loss': 0.8341100108526979}
2022-11-23 00:45:16,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:16,639 INFO:     Epoch: 59
2022-11-23 00:45:17,478 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7744856456463988, 'Total loss': 0.7744856456463988} | train loss {'Reaction outcome loss': 0.8280263750960952, 'Total loss': 0.8280263750960952}
2022-11-23 00:45:17,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:17,478 INFO:     Epoch: 60
2022-11-23 00:45:18,292 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7796561684120785, 'Total loss': 0.7796561684120785} | train loss {'Reaction outcome loss': 0.8298774060721581, 'Total loss': 0.8298774060721581}
2022-11-23 00:45:18,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:18,293 INFO:     Epoch: 61
2022-11-23 00:45:19,080 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7957270924340595, 'Total loss': 0.7957270924340595} | train loss {'Reaction outcome loss': 0.8255545889981363, 'Total loss': 0.8255545889981363}
2022-11-23 00:45:19,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:19,080 INFO:     Epoch: 62
2022-11-23 00:45:19,868 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7791418290951035, 'Total loss': 0.7791418290951035} | train loss {'Reaction outcome loss': 0.8342923483686892, 'Total loss': 0.8342923483686892}
2022-11-23 00:45:19,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:19,869 INFO:     Epoch: 63
2022-11-23 00:45:20,655 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8073496344414625, 'Total loss': 0.8073496344414625} | train loss {'Reaction outcome loss': 0.8329754166968679, 'Total loss': 0.8329754166968679}
2022-11-23 00:45:20,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:20,655 INFO:     Epoch: 64
2022-11-23 00:45:21,485 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7890096076510169, 'Total loss': 0.7890096076510169} | train loss {'Reaction outcome loss': 0.8272820240572879, 'Total loss': 0.8272820240572879}
2022-11-23 00:45:21,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:21,486 INFO:     Epoch: 65
2022-11-23 00:45:22,299 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.779735148630359, 'Total loss': 0.779735148630359} | train loss {'Reaction outcome loss': 0.8280276136118391, 'Total loss': 0.8280276136118391}
2022-11-23 00:45:22,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:22,300 INFO:     Epoch: 66
2022-11-23 00:45:23,110 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.79515221782706, 'Total loss': 0.79515221782706} | train loss {'Reaction outcome loss': 0.838319643909632, 'Total loss': 0.838319643909632}
2022-11-23 00:45:23,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:23,110 INFO:     Epoch: 67
2022-11-23 00:45:23,903 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7819570804184134, 'Total loss': 0.7819570804184134} | train loss {'Reaction outcome loss': 0.8433173858685049, 'Total loss': 0.8433173858685049}
2022-11-23 00:45:23,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:23,903 INFO:     Epoch: 68
2022-11-23 00:45:24,693 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7923922362652692, 'Total loss': 0.7923922362652692} | train loss {'Reaction outcome loss': 0.8341424613587769, 'Total loss': 0.8341424613587769}
2022-11-23 00:45:24,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:24,693 INFO:     Epoch: 69
2022-11-23 00:45:25,489 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7923033095218919, 'Total loss': 0.7923033095218919} | train loss {'Reaction outcome loss': 0.8293859560480003, 'Total loss': 0.8293859560480003}
2022-11-23 00:45:25,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:25,489 INFO:     Epoch: 70
2022-11-23 00:45:26,312 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7789109565994956, 'Total loss': 0.7789109565994956} | train loss {'Reaction outcome loss': 0.8322508384582967, 'Total loss': 0.8322508384582967}
2022-11-23 00:45:26,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:26,313 INFO:     Epoch: 71
2022-11-23 00:45:27,108 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7774115882136605, 'Total loss': 0.7774115882136605} | train loss {'Reaction outcome loss': 0.8363190807311641, 'Total loss': 0.8363190807311641}
2022-11-23 00:45:27,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:27,109 INFO:     Epoch: 72
2022-11-23 00:45:27,903 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8071906607259404, 'Total loss': 0.8071906607259404} | train loss {'Reaction outcome loss': 0.8399466312365976, 'Total loss': 0.8399466312365976}
2022-11-23 00:45:27,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:27,903 INFO:     Epoch: 73
2022-11-23 00:45:28,729 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7858002179048278, 'Total loss': 0.7858002179048278} | train loss {'Reaction outcome loss': 0.8358853875625472, 'Total loss': 0.8358853875625472}
2022-11-23 00:45:28,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:28,729 INFO:     Epoch: 74
2022-11-23 00:45:29,557 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7768744094805284, 'Total loss': 0.7768744094805284} | train loss {'Reaction outcome loss': 0.8385800975054382, 'Total loss': 0.8385800975054382}
2022-11-23 00:45:29,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:29,557 INFO:     Epoch: 75
2022-11-23 00:45:30,315 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7944368679415096, 'Total loss': 0.7944368679415096} | train loss {'Reaction outcome loss': 0.8356446412652128, 'Total loss': 0.8356446412652128}
2022-11-23 00:45:30,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:30,315 INFO:     Epoch: 76
2022-11-23 00:45:31,107 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8001428077166731, 'Total loss': 0.8001428077166731} | train loss {'Reaction outcome loss': 0.8300150807207896, 'Total loss': 0.8300150807207896}
2022-11-23 00:45:31,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:31,107 INFO:     Epoch: 77
2022-11-23 00:45:31,909 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7946636927398768, 'Total loss': 0.7946636927398768} | train loss {'Reaction outcome loss': 0.8353274173823445, 'Total loss': 0.8353274173823445}
2022-11-23 00:45:31,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:31,910 INFO:     Epoch: 78
2022-11-23 00:45:32,707 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7790618400004777, 'Total loss': 0.7790618400004777} | train loss {'Reaction outcome loss': 0.8335188106607329, 'Total loss': 0.8335188106607329}
2022-11-23 00:45:32,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:32,708 INFO:     Epoch: 79
2022-11-23 00:45:33,478 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7820928232236342, 'Total loss': 0.7820928232236342} | train loss {'Reaction outcome loss': 0.8346681265454543, 'Total loss': 0.8346681265454543}
2022-11-23 00:45:33,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:33,479 INFO:     Epoch: 80
2022-11-23 00:45:34,265 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8056896897879514, 'Total loss': 0.8056896897879514} | train loss {'Reaction outcome loss': 0.8291005535119096, 'Total loss': 0.8291005535119096}
2022-11-23 00:45:34,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:34,265 INFO:     Epoch: 81
2022-11-23 00:45:35,108 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8094014836983248, 'Total loss': 0.8094014836983248} | train loss {'Reaction outcome loss': 0.8293321922964413, 'Total loss': 0.8293321922964413}
2022-11-23 00:45:35,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:35,108 INFO:     Epoch: 82
2022-11-23 00:45:35,910 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7836291837421331, 'Total loss': 0.7836291837421331} | train loss {'Reaction outcome loss': 0.830663523452002, 'Total loss': 0.830663523452002}
2022-11-23 00:45:35,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:35,910 INFO:     Epoch: 83
2022-11-23 00:45:36,725 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8024202111092481, 'Total loss': 0.8024202111092481} | train loss {'Reaction outcome loss': 0.8381940557165184, 'Total loss': 0.8381940557165184}
2022-11-23 00:45:36,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:36,725 INFO:     Epoch: 84
2022-11-23 00:45:37,571 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7867187857627869, 'Total loss': 0.7867187857627869} | train loss {'Reaction outcome loss': 0.8374204343629752, 'Total loss': 0.8374204343629752}
2022-11-23 00:45:37,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:37,571 INFO:     Epoch: 85
2022-11-23 00:45:38,383 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8027075380086899, 'Total loss': 0.8027075380086899} | train loss {'Reaction outcome loss': 0.8303914424258205, 'Total loss': 0.8303914424258205}
2022-11-23 00:45:38,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:38,384 INFO:     Epoch: 86
2022-11-23 00:45:39,166 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7789123227650468, 'Total loss': 0.7789123227650468} | train loss {'Reaction outcome loss': 0.8284825104315151, 'Total loss': 0.8284825104315151}
2022-11-23 00:45:39,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:39,167 INFO:     Epoch: 87
2022-11-23 00:45:39,991 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7948695570230484, 'Total loss': 0.7948695570230484} | train loss {'Reaction outcome loss': 0.835443186494503, 'Total loss': 0.835443186494503}
2022-11-23 00:45:39,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:39,992 INFO:     Epoch: 88
2022-11-23 00:45:40,777 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7982616248455915, 'Total loss': 0.7982616248455915} | train loss {'Reaction outcome loss': 0.8441584173001742, 'Total loss': 0.8441584173001742}
2022-11-23 00:45:40,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:40,777 INFO:     Epoch: 89
2022-11-23 00:45:41,564 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7866884801875461, 'Total loss': 0.7866884801875461} | train loss {'Reaction outcome loss': 0.8373419582119838, 'Total loss': 0.8373419582119838}
2022-11-23 00:45:41,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:41,564 INFO:     Epoch: 90
2022-11-23 00:45:42,396 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7962955344807018, 'Total loss': 0.7962955344807018} | train loss {'Reaction outcome loss': 0.8368972967028135, 'Total loss': 0.8368972967028135}
2022-11-23 00:45:42,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:42,396 INFO:     Epoch: 91
2022-11-23 00:45:43,195 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7929189564152197, 'Total loss': 0.7929189564152197} | train loss {'Reaction outcome loss': 0.8379277716040129, 'Total loss': 0.8379277716040129}
2022-11-23 00:45:43,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:43,195 INFO:     Epoch: 92
2022-11-23 00:45:44,032 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7837743014097214, 'Total loss': 0.7837743014097214} | train loss {'Reaction outcome loss': 0.8372380723837416, 'Total loss': 0.8372380723837416}
2022-11-23 00:45:44,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:44,033 INFO:     Epoch: 93
2022-11-23 00:45:44,890 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8240576589649374, 'Total loss': 0.8240576589649374} | train loss {'Reaction outcome loss': 0.8388777045827163, 'Total loss': 0.8388777045827163}
2022-11-23 00:45:44,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:44,890 INFO:     Epoch: 94
2022-11-23 00:45:45,711 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8061412613500248, 'Total loss': 0.8061412613500248} | train loss {'Reaction outcome loss': 0.8454911647296628, 'Total loss': 0.8454911647296628}
2022-11-23 00:45:45,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:45,712 INFO:     Epoch: 95
2022-11-23 00:45:46,510 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7833528417077932, 'Total loss': 0.7833528417077932} | train loss {'Reaction outcome loss': 0.8370836169010232, 'Total loss': 0.8370836169010232}
2022-11-23 00:45:46,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:46,510 INFO:     Epoch: 96
2022-11-23 00:45:47,323 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.805756461891261, 'Total loss': 0.805756461891261} | train loss {'Reaction outcome loss': 0.8275940985332134, 'Total loss': 0.8275940985332134}
2022-11-23 00:45:47,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:47,323 INFO:     Epoch: 97
2022-11-23 00:45:48,146 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7828116261146285, 'Total loss': 0.7828116261146285} | train loss {'Reaction outcome loss': 0.8406553013845977, 'Total loss': 0.8406553013845977}
2022-11-23 00:45:48,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:48,146 INFO:     Epoch: 98
2022-11-23 00:45:48,919 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7839746001091871, 'Total loss': 0.7839746001091871} | train loss {'Reaction outcome loss': 0.832650887881696, 'Total loss': 0.832650887881696}
2022-11-23 00:45:48,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:48,920 INFO:     Epoch: 99
2022-11-23 00:45:49,739 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7884788872166113, 'Total loss': 0.7884788872166113} | train loss {'Reaction outcome loss': 0.8373531058491, 'Total loss': 0.8373531058491}
2022-11-23 00:45:49,739 INFO:     Best model found after epoch 37 of 100.
2022-11-23 00:45:49,739 INFO:   Done with stage: TRAINING
2022-11-23 00:45:49,739 INFO:   Starting stage: EVALUATION
2022-11-23 00:45:49,863 INFO:   Done with stage: EVALUATION
2022-11-23 00:45:49,864 INFO:   Leaving out SEQ value Fold_9
2022-11-23 00:45:49,877 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 00:45:49,877 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:45:50,552 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:45:50,552 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:45:50,624 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:45:50,624 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:45:50,625 INFO:     No hyperparam tuning for this model
2022-11-23 00:45:50,625 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:45:50,625 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:45:50,625 INFO:     None feature selector for col prot
2022-11-23 00:45:50,626 INFO:     None feature selector for col prot
2022-11-23 00:45:50,626 INFO:     None feature selector for col prot
2022-11-23 00:45:50,626 INFO:     None feature selector for col chem
2022-11-23 00:45:50,626 INFO:     None feature selector for col chem
2022-11-23 00:45:50,626 INFO:     None feature selector for col chem
2022-11-23 00:45:50,626 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:45:50,627 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:45:50,628 INFO:     Number of params in model 168571
2022-11-23 00:45:50,631 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:45:50,631 INFO:   Starting stage: TRAINING
2022-11-23 00:45:50,689 INFO:     Val loss before train {'Reaction outcome loss': 1.004592010920698, 'Total loss': 1.004592010920698}
2022-11-23 00:45:50,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:50,689 INFO:     Epoch: 0
2022-11-23 00:45:51,466 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8069281605156985, 'Total loss': 0.8069281605156985} | train loss {'Reaction outcome loss': 0.8658595559326744, 'Total loss': 0.8658595559326744}
2022-11-23 00:45:51,467 INFO:     Found new best model at epoch 0
2022-11-23 00:45:51,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:51,468 INFO:     Epoch: 1
2022-11-23 00:45:52,256 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8077398497949947, 'Total loss': 0.8077398497949947} | train loss {'Reaction outcome loss': 0.8431131577926126, 'Total loss': 0.8431131577926126}
2022-11-23 00:45:52,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:52,257 INFO:     Epoch: 2
2022-11-23 00:45:53,067 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7810891128399156, 'Total loss': 0.7810891128399156} | train loss {'Reaction outcome loss': 0.8307127827695506, 'Total loss': 0.8307127827695506}
2022-11-23 00:45:53,067 INFO:     Found new best model at epoch 2
2022-11-23 00:45:53,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:53,068 INFO:     Epoch: 3
2022-11-23 00:45:53,876 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8210527334700931, 'Total loss': 0.8210527334700931} | train loss {'Reaction outcome loss': 0.826187424286295, 'Total loss': 0.826187424286295}
2022-11-23 00:45:53,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:53,876 INFO:     Epoch: 4
2022-11-23 00:45:54,676 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7769514322280884, 'Total loss': 0.7769514322280884} | train loss {'Reaction outcome loss': 0.8224833617326219, 'Total loss': 0.8224833617326219}
2022-11-23 00:45:54,676 INFO:     Found new best model at epoch 4
2022-11-23 00:45:54,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:54,677 INFO:     Epoch: 5
2022-11-23 00:45:55,500 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7826399525458162, 'Total loss': 0.7826399525458162} | train loss {'Reaction outcome loss': 0.8248595070501088, 'Total loss': 0.8248595070501088}
2022-11-23 00:45:55,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:55,500 INFO:     Epoch: 6
2022-11-23 00:45:56,297 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7708498971028761, 'Total loss': 0.7708498971028761} | train loss {'Reaction outcome loss': 0.8241656504661931, 'Total loss': 0.8241656504661931}
2022-11-23 00:45:56,298 INFO:     Found new best model at epoch 6
2022-11-23 00:45:56,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:56,298 INFO:     Epoch: 7
2022-11-23 00:45:57,099 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7899305021220987, 'Total loss': 0.7899305021220987} | train loss {'Reaction outcome loss': 0.8119384162580436, 'Total loss': 0.8119384162580436}
2022-11-23 00:45:57,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:57,100 INFO:     Epoch: 8
2022-11-23 00:45:57,911 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7900669547644529, 'Total loss': 0.7900669547644529} | train loss {'Reaction outcome loss': 0.8120469407514039, 'Total loss': 0.8120469407514039}
2022-11-23 00:45:57,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:57,911 INFO:     Epoch: 9
2022-11-23 00:45:58,714 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7734182280572978, 'Total loss': 0.7734182280572978} | train loss {'Reaction outcome loss': 0.8134809334268455, 'Total loss': 0.8134809334268455}
2022-11-23 00:45:58,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:58,714 INFO:     Epoch: 10
2022-11-23 00:45:59,529 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7620517089962959, 'Total loss': 0.7620517089962959} | train loss {'Reaction outcome loss': 0.8059330428177528, 'Total loss': 0.8059330428177528}
2022-11-23 00:45:59,529 INFO:     Found new best model at epoch 10
2022-11-23 00:45:59,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:45:59,530 INFO:     Epoch: 11
2022-11-23 00:46:00,379 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7797586999156259, 'Total loss': 0.7797586999156259} | train loss {'Reaction outcome loss': 0.8126442513243872, 'Total loss': 0.8126442513243872}
2022-11-23 00:46:00,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:00,379 INFO:     Epoch: 12
2022-11-23 00:46:01,197 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.803897621279413, 'Total loss': 0.803897621279413} | train loss {'Reaction outcome loss': 0.8065946631827335, 'Total loss': 0.8065946631827335}
2022-11-23 00:46:01,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:01,198 INFO:     Epoch: 13
2022-11-23 00:46:02,109 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7665246975692835, 'Total loss': 0.7665246975692835} | train loss {'Reaction outcome loss': 0.8121853920250286, 'Total loss': 0.8121853920250286}
2022-11-23 00:46:02,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:02,109 INFO:     Epoch: 14
2022-11-23 00:46:03,040 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7622338858517733, 'Total loss': 0.7622338858517733} | train loss {'Reaction outcome loss': 0.8041038927640992, 'Total loss': 0.8041038927640992}
2022-11-23 00:46:03,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:03,040 INFO:     Epoch: 15
2022-11-23 00:46:03,892 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7671236978335814, 'Total loss': 0.7671236978335814} | train loss {'Reaction outcome loss': 0.8062387902727012, 'Total loss': 0.8062387902727012}
2022-11-23 00:46:03,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:03,893 INFO:     Epoch: 16
2022-11-23 00:46:04,729 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8076942400498823, 'Total loss': 0.8076942400498823} | train loss {'Reaction outcome loss': 0.800642292629852, 'Total loss': 0.800642292629852}
2022-11-23 00:46:04,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:04,729 INFO:     Epoch: 17
2022-11-23 00:46:05,558 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7671981650319967, 'Total loss': 0.7671981650319967} | train loss {'Reaction outcome loss': 0.8066855339024231, 'Total loss': 0.8066855339024231}
2022-11-23 00:46:05,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:05,558 INFO:     Epoch: 18
2022-11-23 00:46:06,366 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7893562669103796, 'Total loss': 0.7893562669103796} | train loss {'Reaction outcome loss': 0.8056758774919548, 'Total loss': 0.8056758774919548}
2022-11-23 00:46:06,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:06,366 INFO:     Epoch: 19
2022-11-23 00:46:07,229 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7658682357181202, 'Total loss': 0.7658682357181202} | train loss {'Reaction outcome loss': 0.8072012164573438, 'Total loss': 0.8072012164573438}
2022-11-23 00:46:07,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:07,229 INFO:     Epoch: 20
2022-11-23 00:46:08,024 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7780815776098858, 'Total loss': 0.7780815776098858} | train loss {'Reaction outcome loss': 0.8003562986850739, 'Total loss': 0.8003562986850739}
2022-11-23 00:46:08,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:08,024 INFO:     Epoch: 21
2022-11-23 00:46:08,806 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8351183005354621, 'Total loss': 0.8351183005354621} | train loss {'Reaction outcome loss': 0.8125811046675632, 'Total loss': 0.8125811046675632}
2022-11-23 00:46:08,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:08,806 INFO:     Epoch: 22
2022-11-23 00:46:09,611 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7763687521219254, 'Total loss': 0.7763687521219254} | train loss {'Reaction outcome loss': 0.8311258220238241, 'Total loss': 0.8311258220238241}
2022-11-23 00:46:09,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:09,612 INFO:     Epoch: 23
2022-11-23 00:46:10,425 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7691813944415613, 'Total loss': 0.7691813944415613} | train loss {'Reaction outcome loss': 0.8015735978901628, 'Total loss': 0.8015735978901628}
2022-11-23 00:46:10,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:10,426 INFO:     Epoch: 24
2022-11-23 00:46:11,258 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7882085347717459, 'Total loss': 0.7882085347717459} | train loss {'Reaction outcome loss': 0.8068621729308294, 'Total loss': 0.8068621729308294}
2022-11-23 00:46:11,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:11,259 INFO:     Epoch: 25
2022-11-23 00:46:12,083 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7568271187218752, 'Total loss': 0.7568271187218752} | train loss {'Reaction outcome loss': 0.8055435014881103, 'Total loss': 0.8055435014881103}
2022-11-23 00:46:12,083 INFO:     Found new best model at epoch 25
2022-11-23 00:46:12,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:12,084 INFO:     Epoch: 26
2022-11-23 00:46:12,871 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7783597030422904, 'Total loss': 0.7783597030422904} | train loss {'Reaction outcome loss': 0.8020517593211973, 'Total loss': 0.8020517593211973}
2022-11-23 00:46:12,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:12,872 INFO:     Epoch: 27
2022-11-23 00:46:13,690 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7663420912894335, 'Total loss': 0.7663420912894335} | train loss {'Reaction outcome loss': 0.804648296583278, 'Total loss': 0.804648296583278}
2022-11-23 00:46:13,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:13,691 INFO:     Epoch: 28
2022-11-23 00:46:14,522 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7673372849822044, 'Total loss': 0.7673372849822044} | train loss {'Reaction outcome loss': 0.8013417362442866, 'Total loss': 0.8013417362442866}
2022-11-23 00:46:14,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:14,522 INFO:     Epoch: 29
2022-11-23 00:46:15,347 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7843363420529799, 'Total loss': 0.7843363420529799} | train loss {'Reaction outcome loss': 0.8058059467719152, 'Total loss': 0.8058059467719152}
2022-11-23 00:46:15,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:15,347 INFO:     Epoch: 30
2022-11-23 00:46:16,142 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.781615098091689, 'Total loss': 0.781615098091689} | train loss {'Reaction outcome loss': 0.8003220366321595, 'Total loss': 0.8003220366321595}
2022-11-23 00:46:16,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:16,142 INFO:     Epoch: 31
2022-11-23 00:46:16,921 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7653126432137056, 'Total loss': 0.7653126432137056} | train loss {'Reaction outcome loss': 0.8087705206050564, 'Total loss': 0.8087705206050564}
2022-11-23 00:46:16,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:16,921 INFO:     Epoch: 32
2022-11-23 00:46:17,731 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8014873482964255, 'Total loss': 0.8014873482964255} | train loss {'Reaction outcome loss': 0.8018997369507547, 'Total loss': 0.8018997369507547}
2022-11-23 00:46:17,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:17,731 INFO:     Epoch: 33
2022-11-23 00:46:18,532 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7680354572155259, 'Total loss': 0.7680354572155259} | train loss {'Reaction outcome loss': 0.8141349597498473, 'Total loss': 0.8141349597498473}
2022-11-23 00:46:18,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:18,532 INFO:     Epoch: 34
2022-11-23 00:46:19,341 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7734305838292296, 'Total loss': 0.7734305838292296} | train loss {'Reaction outcome loss': 0.8054929180183874, 'Total loss': 0.8054929180183874}
2022-11-23 00:46:19,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:19,341 INFO:     Epoch: 35
2022-11-23 00:46:20,159 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7613858316432346, 'Total loss': 0.7613858316432346} | train loss {'Reaction outcome loss': 0.8124420179529228, 'Total loss': 0.8124420179529228}
2022-11-23 00:46:20,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:20,159 INFO:     Epoch: 36
2022-11-23 00:46:20,984 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7965231490406123, 'Total loss': 0.7965231490406123} | train loss {'Reaction outcome loss': 0.8062808259054717, 'Total loss': 0.8062808259054717}
2022-11-23 00:46:20,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:20,984 INFO:     Epoch: 37
2022-11-23 00:46:21,768 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7609869952906262, 'Total loss': 0.7609869952906262} | train loss {'Reaction outcome loss': 0.8010617918693103, 'Total loss': 0.8010617918693103}
2022-11-23 00:46:21,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:21,768 INFO:     Epoch: 38
2022-11-23 00:46:22,583 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.757269677113403, 'Total loss': 0.757269677113403} | train loss {'Reaction outcome loss': 0.8043654293183856, 'Total loss': 0.8043654293183856}
2022-11-23 00:46:22,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:22,585 INFO:     Epoch: 39
2022-11-23 00:46:23,377 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7619410360401327, 'Total loss': 0.7619410360401327} | train loss {'Reaction outcome loss': 0.8045560428005482, 'Total loss': 0.8045560428005482}
2022-11-23 00:46:23,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:23,378 INFO:     Epoch: 40
2022-11-23 00:46:24,179 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7783331552689726, 'Total loss': 0.7783331552689726} | train loss {'Reaction outcome loss': 0.7970938294944976, 'Total loss': 0.7970938294944976}
2022-11-23 00:46:24,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:24,179 INFO:     Epoch: 41
2022-11-23 00:46:24,972 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7708255777304823, 'Total loss': 0.7708255777304823} | train loss {'Reaction outcome loss': 0.8026149783600197, 'Total loss': 0.8026149783600197}
2022-11-23 00:46:24,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:24,972 INFO:     Epoch: 42
2022-11-23 00:46:25,794 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.758345284245231, 'Total loss': 0.758345284245231} | train loss {'Reaction outcome loss': 0.8053973451075767, 'Total loss': 0.8053973451075767}
2022-11-23 00:46:25,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:25,794 INFO:     Epoch: 43
2022-11-23 00:46:26,576 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7695985619317401, 'Total loss': 0.7695985619317401} | train loss {'Reaction outcome loss': 0.8067217767841903, 'Total loss': 0.8067217767841903}
2022-11-23 00:46:26,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:26,577 INFO:     Epoch: 44
2022-11-23 00:46:27,371 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7717247652736577, 'Total loss': 0.7717247652736577} | train loss {'Reaction outcome loss': 0.8008663862762664, 'Total loss': 0.8008663862762664}
2022-11-23 00:46:27,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:27,371 INFO:     Epoch: 45
2022-11-23 00:46:28,186 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7895447171547196, 'Total loss': 0.7895447171547196} | train loss {'Reaction outcome loss': 0.8053407225048976, 'Total loss': 0.8053407225048976}
2022-11-23 00:46:28,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:28,187 INFO:     Epoch: 46
2022-11-23 00:46:29,011 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7671377543698658, 'Total loss': 0.7671377543698658} | train loss {'Reaction outcome loss': 0.8125724827471049, 'Total loss': 0.8125724827471049}
2022-11-23 00:46:29,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:29,012 INFO:     Epoch: 47
2022-11-23 00:46:29,812 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7707008333368734, 'Total loss': 0.7707008333368734} | train loss {'Reaction outcome loss': 0.8159362614637444, 'Total loss': 0.8159362614637444}
2022-11-23 00:46:29,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:29,812 INFO:     Epoch: 48
2022-11-23 00:46:30,652 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.774230648170818, 'Total loss': 0.774230648170818} | train loss {'Reaction outcome loss': 0.8073262782231999, 'Total loss': 0.8073262782231999}
2022-11-23 00:46:30,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:30,652 INFO:     Epoch: 49
2022-11-23 00:46:31,455 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.765812558206645, 'Total loss': 0.765812558206645} | train loss {'Reaction outcome loss': 0.8025383963758647, 'Total loss': 0.8025383963758647}
2022-11-23 00:46:31,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:31,455 INFO:     Epoch: 50
2022-11-23 00:46:32,252 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7776795503768054, 'Total loss': 0.7776795503768054} | train loss {'Reaction outcome loss': 0.7989997168180913, 'Total loss': 0.7989997168180913}
2022-11-23 00:46:32,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:32,253 INFO:     Epoch: 51
2022-11-23 00:46:33,051 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7622702284292742, 'Total loss': 0.7622702284292742} | train loss {'Reaction outcome loss': 0.8082564817025111, 'Total loss': 0.8082564817025111}
2022-11-23 00:46:33,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:33,052 INFO:     Epoch: 52
2022-11-23 00:46:33,841 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.764122604646466, 'Total loss': 0.764122604646466} | train loss {'Reaction outcome loss': 0.8048716933138458, 'Total loss': 0.8048716933138458}
2022-11-23 00:46:33,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:33,842 INFO:     Epoch: 53
2022-11-23 00:46:34,666 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7999782738360491, 'Total loss': 0.7999782738360491} | train loss {'Reaction outcome loss': 0.8032847022720677, 'Total loss': 0.8032847022720677}
2022-11-23 00:46:34,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:34,667 INFO:     Epoch: 54
2022-11-23 00:46:35,492 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.765131648291241, 'Total loss': 0.765131648291241} | train loss {'Reaction outcome loss': 0.8007423429022192, 'Total loss': 0.8007423429022192}
2022-11-23 00:46:35,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:35,492 INFO:     Epoch: 55
2022-11-23 00:46:36,273 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7893161286007274, 'Total loss': 0.7893161286007274} | train loss {'Reaction outcome loss': 0.8101554782043102, 'Total loss': 0.8101554782043102}
2022-11-23 00:46:36,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:36,273 INFO:     Epoch: 56
2022-11-23 00:46:37,069 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7825941511175849, 'Total loss': 0.7825941511175849} | train loss {'Reaction outcome loss': 0.8066554168457927, 'Total loss': 0.8066554168457927}
2022-11-23 00:46:37,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:37,069 INFO:     Epoch: 57
2022-11-23 00:46:37,851 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.767049798911268, 'Total loss': 0.767049798911268} | train loss {'Reaction outcome loss': 0.7987505329041346, 'Total loss': 0.7987505329041346}
2022-11-23 00:46:37,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:37,852 INFO:     Epoch: 58
2022-11-23 00:46:38,668 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7795885869047858, 'Total loss': 0.7795885869047858} | train loss {'Reaction outcome loss': 0.8121407653397394, 'Total loss': 0.8121407653397394}
2022-11-23 00:46:38,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:38,668 INFO:     Epoch: 59
2022-11-23 00:46:39,502 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7712016037919305, 'Total loss': 0.7712016037919305} | train loss {'Reaction outcome loss': 0.8082211176876114, 'Total loss': 0.8082211176876114}
2022-11-23 00:46:39,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:39,503 INFO:     Epoch: 60
2022-11-23 00:46:40,310 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7804545292800124, 'Total loss': 0.7804545292800124} | train loss {'Reaction outcome loss': 0.8040023617416259, 'Total loss': 0.8040023617416259}
2022-11-23 00:46:40,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:40,310 INFO:     Epoch: 61
2022-11-23 00:46:41,142 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7834856760772791, 'Total loss': 0.7834856760772791} | train loss {'Reaction outcome loss': 0.8012054561362093, 'Total loss': 0.8012054561362093}
2022-11-23 00:46:41,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:41,142 INFO:     Epoch: 62
2022-11-23 00:46:41,945 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7650322453542189, 'Total loss': 0.7650322453542189} | train loss {'Reaction outcome loss': 0.806560252917561, 'Total loss': 0.806560252917561}
2022-11-23 00:46:41,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:41,946 INFO:     Epoch: 63
2022-11-23 00:46:42,752 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7734702825546265, 'Total loss': 0.7734702825546265} | train loss {'Reaction outcome loss': 0.803981038240286, 'Total loss': 0.803981038240286}
2022-11-23 00:46:42,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:42,752 INFO:     Epoch: 64
2022-11-23 00:46:43,541 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.78330804949457, 'Total loss': 0.78330804949457} | train loss {'Reaction outcome loss': 0.8097937891357824, 'Total loss': 0.8097937891357824}
2022-11-23 00:46:43,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:43,542 INFO:     Epoch: 65
2022-11-23 00:46:44,364 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7641558213667436, 'Total loss': 0.7641558213667436} | train loss {'Reaction outcome loss': 0.8086455400414795, 'Total loss': 0.8086455400414795}
2022-11-23 00:46:44,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:44,364 INFO:     Epoch: 66
2022-11-23 00:46:45,222 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7809351608157158, 'Total loss': 0.7809351608157158} | train loss {'Reaction outcome loss': 0.8055256232317642, 'Total loss': 0.8055256232317642}
2022-11-23 00:46:45,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:45,222 INFO:     Epoch: 67
2022-11-23 00:46:46,080 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7783329209143465, 'Total loss': 0.7783329209143465} | train loss {'Reaction outcome loss': 0.8012892822263694, 'Total loss': 0.8012892822263694}
2022-11-23 00:46:46,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:46,081 INFO:     Epoch: 68
2022-11-23 00:46:46,895 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7709514437751337, 'Total loss': 0.7709514437751337} | train loss {'Reaction outcome loss': 0.804634467068954, 'Total loss': 0.804634467068954}
2022-11-23 00:46:46,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:46,896 INFO:     Epoch: 69
2022-11-23 00:46:47,684 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.79427708549933, 'Total loss': 0.79427708549933} | train loss {'Reaction outcome loss': 0.8110898179322602, 'Total loss': 0.8110898179322602}
2022-11-23 00:46:47,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:47,684 INFO:     Epoch: 70
2022-11-23 00:46:48,531 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7682201997800306, 'Total loss': 0.7682201997800306} | train loss {'Reaction outcome loss': 0.8083559474964374, 'Total loss': 0.8083559474964374}
2022-11-23 00:46:48,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:48,531 INFO:     Epoch: 71
2022-11-23 00:46:49,326 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7709532752633095, 'Total loss': 0.7709532752633095} | train loss {'Reaction outcome loss': 0.8020833900824249, 'Total loss': 0.8020833900824249}
2022-11-23 00:46:49,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:49,326 INFO:     Epoch: 72
2022-11-23 00:46:50,137 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7782435552640394, 'Total loss': 0.7782435552640394} | train loss {'Reaction outcome loss': 0.8013251474511768, 'Total loss': 0.8013251474511768}
2022-11-23 00:46:50,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:50,138 INFO:     Epoch: 73
2022-11-23 00:46:50,971 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7682879208163782, 'Total loss': 0.7682879208163782} | train loss {'Reaction outcome loss': 0.8139959578572015, 'Total loss': 0.8139959578572015}
2022-11-23 00:46:50,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:50,971 INFO:     Epoch: 74
2022-11-23 00:46:51,770 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7553968151861971, 'Total loss': 0.7553968151861971} | train loss {'Reaction outcome loss': 0.8008926720754338, 'Total loss': 0.8008926720754338}
2022-11-23 00:46:51,770 INFO:     Found new best model at epoch 74
2022-11-23 00:46:51,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:51,771 INFO:     Epoch: 75
2022-11-23 00:46:52,574 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7635554163293405, 'Total loss': 0.7635554163293405} | train loss {'Reaction outcome loss': 0.8032203466303436, 'Total loss': 0.8032203466303436}
2022-11-23 00:46:52,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:52,574 INFO:     Epoch: 76
2022-11-23 00:46:53,359 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7744176618077538, 'Total loss': 0.7744176618077538} | train loss {'Reaction outcome loss': 0.8025272830053862, 'Total loss': 0.8025272830053862}
2022-11-23 00:46:53,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:53,360 INFO:     Epoch: 77
2022-11-23 00:46:54,179 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7918508953668855, 'Total loss': 0.7918508953668855} | train loss {'Reaction outcome loss': 0.8053500746425829, 'Total loss': 0.8053500746425829}
2022-11-23 00:46:54,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:54,180 INFO:     Epoch: 78
2022-11-23 00:46:55,019 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8063929047096859, 'Total loss': 0.8063929047096859} | train loss {'Reaction outcome loss': 0.8056073916947794, 'Total loss': 0.8056073916947794}
2022-11-23 00:46:55,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:55,019 INFO:     Epoch: 79
2022-11-23 00:46:55,810 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7769523913210089, 'Total loss': 0.7769523913210089} | train loss {'Reaction outcome loss': 0.8066915314689822, 'Total loss': 0.8066915314689822}
2022-11-23 00:46:55,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:55,810 INFO:     Epoch: 80
2022-11-23 00:46:56,602 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7674431712789969, 'Total loss': 0.7674431712789969} | train loss {'Reaction outcome loss': 0.8026630597317267, 'Total loss': 0.8026630597317267}
2022-11-23 00:46:56,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:56,602 INFO:     Epoch: 81
2022-11-23 00:46:57,469 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8204013298858296, 'Total loss': 0.8204013298858296} | train loss {'Reaction outcome loss': 0.8051668381401402, 'Total loss': 0.8051668381401402}
2022-11-23 00:46:57,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:57,470 INFO:     Epoch: 82
2022-11-23 00:46:58,274 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.762445981529626, 'Total loss': 0.762445981529626} | train loss {'Reaction outcome loss': 0.8113298947029268, 'Total loss': 0.8113298947029268}
2022-11-23 00:46:58,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:58,275 INFO:     Epoch: 83
2022-11-23 00:46:59,059 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7643680829893459, 'Total loss': 0.7643680829893459} | train loss {'Reaction outcome loss': 0.8058901406251467, 'Total loss': 0.8058901406251467}
2022-11-23 00:46:59,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:59,060 INFO:     Epoch: 84
2022-11-23 00:46:59,890 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7820490998300639, 'Total loss': 0.7820490998300639} | train loss {'Reaction outcome loss': 0.8025190988894899, 'Total loss': 0.8025190988894899}
2022-11-23 00:46:59,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:46:59,890 INFO:     Epoch: 85
2022-11-23 00:47:00,695 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7616599906574596, 'Total loss': 0.7616599906574596} | train loss {'Reaction outcome loss': 0.808949145228274, 'Total loss': 0.808949145228274}
2022-11-23 00:47:00,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:00,696 INFO:     Epoch: 86
2022-11-23 00:47:01,482 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7712794461033561, 'Total loss': 0.7712794461033561} | train loss {'Reaction outcome loss': 0.8103481755565535, 'Total loss': 0.8103481755565535}
2022-11-23 00:47:01,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:01,483 INFO:     Epoch: 87
2022-11-23 00:47:02,290 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7677491882985289, 'Total loss': 0.7677491882985289} | train loss {'Reaction outcome loss': 0.8078090175684647, 'Total loss': 0.8078090175684647}
2022-11-23 00:47:02,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:02,290 INFO:     Epoch: 88
2022-11-23 00:47:03,084 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.775475953112949, 'Total loss': 0.775475953112949} | train loss {'Reaction outcome loss': 0.8039860754360554, 'Total loss': 0.8039860754360554}
2022-11-23 00:47:03,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:03,085 INFO:     Epoch: 89
2022-11-23 00:47:03,839 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.778484081002799, 'Total loss': 0.778484081002799} | train loss {'Reaction outcome loss': 0.8085670390351098, 'Total loss': 0.8085670390351098}
2022-11-23 00:47:03,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:03,839 INFO:     Epoch: 90
2022-11-23 00:47:04,610 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7733069908889857, 'Total loss': 0.7733069908889857} | train loss {'Reaction outcome loss': 0.8016410634555073, 'Total loss': 0.8016410634555073}
2022-11-23 00:47:04,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:04,611 INFO:     Epoch: 91
2022-11-23 00:47:05,401 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7574132274497639, 'Total loss': 0.7574132274497639} | train loss {'Reaction outcome loss': 0.8009249216873153, 'Total loss': 0.8009249216873153}
2022-11-23 00:47:05,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:05,403 INFO:     Epoch: 92
2022-11-23 00:47:06,250 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7613925371657718, 'Total loss': 0.7613925371657718} | train loss {'Reaction outcome loss': 0.7976787300546643, 'Total loss': 0.7976787300546643}
2022-11-23 00:47:06,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:06,250 INFO:     Epoch: 93
2022-11-23 00:47:07,061 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7776789455251261, 'Total loss': 0.7776789455251261} | train loss {'Reaction outcome loss': 0.8059307325948105, 'Total loss': 0.8059307325948105}
2022-11-23 00:47:07,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:07,061 INFO:     Epoch: 94
2022-11-23 00:47:07,848 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7787324203686281, 'Total loss': 0.7787324203686281} | train loss {'Reaction outcome loss': 0.8045370418291825, 'Total loss': 0.8045370418291825}
2022-11-23 00:47:07,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:07,849 INFO:     Epoch: 95
2022-11-23 00:47:08,639 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7736284936016257, 'Total loss': 0.7736284936016257} | train loss {'Reaction outcome loss': 0.802181321237734, 'Total loss': 0.802181321237734}
2022-11-23 00:47:08,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:08,639 INFO:     Epoch: 96
2022-11-23 00:47:09,397 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7679063813252882, 'Total loss': 0.7679063813252882} | train loss {'Reaction outcome loss': 0.8040260630339263, 'Total loss': 0.8040260630339263}
2022-11-23 00:47:09,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:09,398 INFO:     Epoch: 97
2022-11-23 00:47:10,207 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7594553916291757, 'Total loss': 0.7594553916291757} | train loss {'Reaction outcome loss': 0.8029145612287135, 'Total loss': 0.8029145612287135}
2022-11-23 00:47:10,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:10,207 INFO:     Epoch: 98
2022-11-23 00:47:11,016 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7867059436711398, 'Total loss': 0.7867059436711398} | train loss {'Reaction outcome loss': 0.8038773285111918, 'Total loss': 0.8038773285111918}
2022-11-23 00:47:11,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:11,016 INFO:     Epoch: 99
2022-11-23 00:47:11,828 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7720687639984217, 'Total loss': 0.7720687639984217} | train loss {'Reaction outcome loss': 0.8034641062652292, 'Total loss': 0.8034641062652292}
2022-11-23 00:47:11,829 INFO:     Best model found after epoch 75 of 100.
2022-11-23 00:47:11,830 INFO:   Done with stage: TRAINING
2022-11-23 00:47:11,830 INFO:   Starting stage: EVALUATION
2022-11-23 00:47:11,958 INFO:   Done with stage: EVALUATION
2022-11-23 00:47:11,966 INFO:   Leaving out SEQ value Fold_0
2022-11-23 00:47:11,980 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 00:47:11,980 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:47:12,656 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:47:12,657 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:47:12,731 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:47:12,731 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:47:12,731 INFO:     No hyperparam tuning for this model
2022-11-23 00:47:12,731 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:47:12,731 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:47:12,732 INFO:     None feature selector for col prot
2022-11-23 00:47:12,732 INFO:     None feature selector for col prot
2022-11-23 00:47:12,732 INFO:     None feature selector for col prot
2022-11-23 00:47:12,733 INFO:     None feature selector for col chem
2022-11-23 00:47:12,733 INFO:     None feature selector for col chem
2022-11-23 00:47:12,733 INFO:     None feature selector for col chem
2022-11-23 00:47:12,733 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:47:12,733 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:47:12,735 INFO:     Number of params in model 168571
2022-11-23 00:47:12,738 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:47:12,738 INFO:   Starting stage: TRAINING
2022-11-23 00:47:12,797 INFO:     Val loss before train {'Reaction outcome loss': 0.9978025203401392, 'Total loss': 0.9978025203401392}
2022-11-23 00:47:12,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:12,797 INFO:     Epoch: 0
2022-11-23 00:47:13,595 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8618659952824766, 'Total loss': 0.8618659952824766} | train loss {'Reaction outcome loss': 0.8718124432602392, 'Total loss': 0.8718124432602392}
2022-11-23 00:47:13,596 INFO:     Found new best model at epoch 0
2022-11-23 00:47:13,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:13,596 INFO:     Epoch: 1
2022-11-23 00:47:14,527 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8537598238749937, 'Total loss': 0.8537598238749937} | train loss {'Reaction outcome loss': 0.8478242466565569, 'Total loss': 0.8478242466565569}
2022-11-23 00:47:14,527 INFO:     Found new best model at epoch 1
2022-11-23 00:47:14,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:14,528 INFO:     Epoch: 2
2022-11-23 00:47:15,376 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8431031263687394, 'Total loss': 0.8431031263687394} | train loss {'Reaction outcome loss': 0.8320326040751538, 'Total loss': 0.8320326040751538}
2022-11-23 00:47:15,377 INFO:     Found new best model at epoch 2
2022-11-23 00:47:15,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:15,377 INFO:     Epoch: 3
2022-11-23 00:47:16,261 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8204804103482853, 'Total loss': 0.8204804103482853} | train loss {'Reaction outcome loss': 0.8336794364307574, 'Total loss': 0.8336794364307574}
2022-11-23 00:47:16,261 INFO:     Found new best model at epoch 3
2022-11-23 00:47:16,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:16,262 INFO:     Epoch: 4
2022-11-23 00:47:17,160 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8263058635321531, 'Total loss': 0.8263058635321531} | train loss {'Reaction outcome loss': 0.8280250498881707, 'Total loss': 0.8280250498881707}
2022-11-23 00:47:17,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:17,160 INFO:     Epoch: 5
2022-11-23 00:47:18,061 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8174602389335632, 'Total loss': 0.8174602389335632} | train loss {'Reaction outcome loss': 0.8237142498616264, 'Total loss': 0.8237142498616264}
2022-11-23 00:47:18,061 INFO:     Found new best model at epoch 5
2022-11-23 00:47:18,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:18,062 INFO:     Epoch: 6
2022-11-23 00:47:18,958 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8116446137428284, 'Total loss': 0.8116446137428284} | train loss {'Reaction outcome loss': 0.8126512262291512, 'Total loss': 0.8126512262291512}
2022-11-23 00:47:18,958 INFO:     Found new best model at epoch 6
2022-11-23 00:47:18,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:18,959 INFO:     Epoch: 7
2022-11-23 00:47:19,896 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8186787339774045, 'Total loss': 0.8186787339774045} | train loss {'Reaction outcome loss': 0.8216667813569428, 'Total loss': 0.8216667813569428}
2022-11-23 00:47:19,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:19,896 INFO:     Epoch: 8
2022-11-23 00:47:20,775 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8118004541505467, 'Total loss': 0.8118004541505467} | train loss {'Reaction outcome loss': 0.8253331702006491, 'Total loss': 0.8253331702006491}
2022-11-23 00:47:20,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:20,775 INFO:     Epoch: 9
2022-11-23 00:47:21,690 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8089763285084204, 'Total loss': 0.8089763285084204} | train loss {'Reaction outcome loss': 0.8182030328613544, 'Total loss': 0.8182030328613544}
2022-11-23 00:47:21,690 INFO:     Found new best model at epoch 9
2022-11-23 00:47:21,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:21,691 INFO:     Epoch: 10
2022-11-23 00:47:22,649 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7894381359219551, 'Total loss': 0.7894381359219551} | train loss {'Reaction outcome loss': 0.8157351702331048, 'Total loss': 0.8157351702331048}
2022-11-23 00:47:22,649 INFO:     Found new best model at epoch 10
2022-11-23 00:47:22,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:22,650 INFO:     Epoch: 11
2022-11-23 00:47:23,529 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8172926591201262, 'Total loss': 0.8172926591201262} | train loss {'Reaction outcome loss': 0.8122708714201383, 'Total loss': 0.8122708714201383}
2022-11-23 00:47:23,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:23,530 INFO:     Epoch: 12
2022-11-23 00:47:24,394 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8485570509325374, 'Total loss': 0.8485570509325374} | train loss {'Reaction outcome loss': 0.8103879859090334, 'Total loss': 0.8103879859090334}
2022-11-23 00:47:24,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:24,395 INFO:     Epoch: 13
2022-11-23 00:47:25,308 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8032898699695413, 'Total loss': 0.8032898699695413} | train loss {'Reaction outcome loss': 0.8112768862652875, 'Total loss': 0.8112768862652875}
2022-11-23 00:47:25,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:25,308 INFO:     Epoch: 14
2022-11-23 00:47:26,190 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8125268796628172, 'Total loss': 0.8125268796628172} | train loss {'Reaction outcome loss': 0.8103714013389247, 'Total loss': 0.8103714013389247}
2022-11-23 00:47:26,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:26,190 INFO:     Epoch: 15
2022-11-23 00:47:27,091 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8055943873795596, 'Total loss': 0.8055943873795596} | train loss {'Reaction outcome loss': 0.8057384191737001, 'Total loss': 0.8057384191737001}
2022-11-23 00:47:27,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:27,091 INFO:     Epoch: 16
2022-11-23 00:47:27,997 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8179375353184614, 'Total loss': 0.8179375353184614} | train loss {'Reaction outcome loss': 0.8205682369861526, 'Total loss': 0.8205682369861526}
2022-11-23 00:47:27,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:27,997 INFO:     Epoch: 17
2022-11-23 00:47:28,861 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7967796879397198, 'Total loss': 0.7967796879397198} | train loss {'Reaction outcome loss': 0.8172725392015356, 'Total loss': 0.8172725392015356}
2022-11-23 00:47:28,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:28,862 INFO:     Epoch: 18
2022-11-23 00:47:29,758 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8050855045968835, 'Total loss': 0.8050855045968835} | train loss {'Reaction outcome loss': 0.8127615279272983, 'Total loss': 0.8127615279272983}
2022-11-23 00:47:29,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:29,758 INFO:     Epoch: 19
2022-11-23 00:47:30,673 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8118136362595991, 'Total loss': 0.8118136362595991} | train loss {'Reaction outcome loss': 0.8091120681299372, 'Total loss': 0.8091120681299372}
2022-11-23 00:47:30,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:30,673 INFO:     Epoch: 20
2022-11-23 00:47:31,541 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8349243551492691, 'Total loss': 0.8349243551492691} | train loss {'Reaction outcome loss': 0.8208046886119765, 'Total loss': 0.8208046886119765}
2022-11-23 00:47:31,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:31,541 INFO:     Epoch: 21
2022-11-23 00:47:32,441 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.808412026275288, 'Total loss': 0.808412026275288} | train loss {'Reaction outcome loss': 0.819975830524074, 'Total loss': 0.819975830524074}
2022-11-23 00:47:32,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:32,441 INFO:     Epoch: 22
2022-11-23 00:47:33,320 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7942490591244264, 'Total loss': 0.7942490591244264} | train loss {'Reaction outcome loss': 0.8073176024896414, 'Total loss': 0.8073176024896414}
2022-11-23 00:47:33,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:33,320 INFO:     Epoch: 23
2022-11-23 00:47:34,171 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8468960963866927, 'Total loss': 0.8468960963866927} | train loss {'Reaction outcome loss': 0.8109415251957742, 'Total loss': 0.8109415251957742}
2022-11-23 00:47:34,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:34,171 INFO:     Epoch: 24
2022-11-23 00:47:35,001 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.799898929216645, 'Total loss': 0.799898929216645} | train loss {'Reaction outcome loss': 0.819541861291839, 'Total loss': 0.819541861291839}
2022-11-23 00:47:35,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:35,001 INFO:     Epoch: 25
2022-11-23 00:47:35,876 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8057884736494585, 'Total loss': 0.8057884736494585} | train loss {'Reaction outcome loss': 0.8110982957880507, 'Total loss': 0.8110982957880507}
2022-11-23 00:47:35,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:35,876 INFO:     Epoch: 26
2022-11-23 00:47:36,786 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8277480758049272, 'Total loss': 0.8277480758049272} | train loss {'Reaction outcome loss': 0.8051660738070967, 'Total loss': 0.8051660738070967}
2022-11-23 00:47:36,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:36,787 INFO:     Epoch: 27
2022-11-23 00:47:37,686 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.811394028365612, 'Total loss': 0.811394028365612} | train loss {'Reaction outcome loss': 0.8055324823810504, 'Total loss': 0.8055324823810504}
2022-11-23 00:47:37,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:37,687 INFO:     Epoch: 28
2022-11-23 00:47:38,585 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8083786761218851, 'Total loss': 0.8083786761218851} | train loss {'Reaction outcome loss': 0.8088107372102468, 'Total loss': 0.8088107372102468}
2022-11-23 00:47:38,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:38,586 INFO:     Epoch: 29
2022-11-23 00:47:39,498 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.808442232283679, 'Total loss': 0.808442232283679} | train loss {'Reaction outcome loss': 0.8142752746338786, 'Total loss': 0.8142752746338786}
2022-11-23 00:47:39,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:39,499 INFO:     Epoch: 30
2022-11-23 00:47:40,370 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8136653459884904, 'Total loss': 0.8136653459884904} | train loss {'Reaction outcome loss': 0.8198112398989288, 'Total loss': 0.8198112398989288}
2022-11-23 00:47:40,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:40,370 INFO:     Epoch: 31
2022-11-23 00:47:41,181 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8111276077953252, 'Total loss': 0.8111276077953252} | train loss {'Reaction outcome loss': 0.8135875387471697, 'Total loss': 0.8135875387471697}
2022-11-23 00:47:41,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:41,181 INFO:     Epoch: 32
2022-11-23 00:47:42,008 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8213793012228879, 'Total loss': 0.8213793012228879} | train loss {'Reaction outcome loss': 0.8052014838527088, 'Total loss': 0.8052014838527088}
2022-11-23 00:47:42,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:42,008 INFO:     Epoch: 33
2022-11-23 00:47:42,914 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8284735679626465, 'Total loss': 0.8284735679626465} | train loss {'Reaction outcome loss': 0.8084945507981034, 'Total loss': 0.8084945507981034}
2022-11-23 00:47:42,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:42,915 INFO:     Epoch: 34
2022-11-23 00:47:43,771 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8058190752159465, 'Total loss': 0.8058190752159465} | train loss {'Reaction outcome loss': 0.8185688508184332, 'Total loss': 0.8185688508184332}
2022-11-23 00:47:43,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:43,772 INFO:     Epoch: 35
2022-11-23 00:47:44,613 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7930151298642159, 'Total loss': 0.7930151298642159} | train loss {'Reaction outcome loss': 0.8077042301898061, 'Total loss': 0.8077042301898061}
2022-11-23 00:47:44,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:44,614 INFO:     Epoch: 36
2022-11-23 00:47:45,469 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8066835362802852, 'Total loss': 0.8066835362802852} | train loss {'Reaction outcome loss': 0.8102634504497775, 'Total loss': 0.8102634504497775}
2022-11-23 00:47:45,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:45,469 INFO:     Epoch: 37
2022-11-23 00:47:46,324 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7972250529988245, 'Total loss': 0.7972250529988245} | train loss {'Reaction outcome loss': 0.8099708576434055, 'Total loss': 0.8099708576434055}
2022-11-23 00:47:46,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:46,324 INFO:     Epoch: 38
2022-11-23 00:47:47,189 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8108906773003665, 'Total loss': 0.8108906773003665} | train loss {'Reaction outcome loss': 0.8190599402435396, 'Total loss': 0.8190599402435396}
2022-11-23 00:47:47,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:47,189 INFO:     Epoch: 39
2022-11-23 00:47:48,073 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.808292028578845, 'Total loss': 0.808292028578845} | train loss {'Reaction outcome loss': 0.8094179572967383, 'Total loss': 0.8094179572967383}
2022-11-23 00:47:48,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:48,074 INFO:     Epoch: 40
2022-11-23 00:47:48,940 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8075720085339113, 'Total loss': 0.8075720085339113} | train loss {'Reaction outcome loss': 0.8096540736765997, 'Total loss': 0.8096540736765997}
2022-11-23 00:47:48,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:48,940 INFO:     Epoch: 41
2022-11-23 00:47:49,800 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8037205216559496, 'Total loss': 0.8037205216559496} | train loss {'Reaction outcome loss': 0.8143320612096594, 'Total loss': 0.8143320612096594}
2022-11-23 00:47:49,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:49,800 INFO:     Epoch: 42
2022-11-23 00:47:50,676 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8176740076054226, 'Total loss': 0.8176740076054226} | train loss {'Reaction outcome loss': 0.8069360518021139, 'Total loss': 0.8069360518021139}
2022-11-23 00:47:50,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:50,677 INFO:     Epoch: 43
2022-11-23 00:47:51,542 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8229070793498646, 'Total loss': 0.8229070793498646} | train loss {'Reaction outcome loss': 0.8107406185706135, 'Total loss': 0.8107406185706135}
2022-11-23 00:47:51,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:51,542 INFO:     Epoch: 44
2022-11-23 00:47:52,398 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8044949648055163, 'Total loss': 0.8044949648055163} | train loss {'Reaction outcome loss': 0.8094773904273385, 'Total loss': 0.8094773904273385}
2022-11-23 00:47:52,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:52,398 INFO:     Epoch: 45
2022-11-23 00:47:53,283 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8127678490497849, 'Total loss': 0.8127678490497849} | train loss {'Reaction outcome loss': 0.8065922254251565, 'Total loss': 0.8065922254251565}
2022-11-23 00:47:53,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:53,283 INFO:     Epoch: 46
2022-11-23 00:47:54,164 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8035152087157423, 'Total loss': 0.8035152087157423} | train loss {'Reaction outcome loss': 0.8111332262817182, 'Total loss': 0.8111332262817182}
2022-11-23 00:47:54,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:54,164 INFO:     Epoch: 47
2022-11-23 00:47:55,076 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8059205663475123, 'Total loss': 0.8059205663475123} | train loss {'Reaction outcome loss': 0.8050638160061258, 'Total loss': 0.8050638160061258}
2022-11-23 00:47:55,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:55,077 INFO:     Epoch: 48
2022-11-23 00:47:55,890 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8067923377860676, 'Total loss': 0.8067923377860676} | train loss {'Reaction outcome loss': 0.807816681033566, 'Total loss': 0.807816681033566}
2022-11-23 00:47:55,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:55,891 INFO:     Epoch: 49
2022-11-23 00:47:56,715 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8281338824467226, 'Total loss': 0.8281338824467226} | train loss {'Reaction outcome loss': 0.8133574702479096, 'Total loss': 0.8133574702479096}
2022-11-23 00:47:56,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:56,715 INFO:     Epoch: 50
2022-11-23 00:47:57,530 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8100964433767579, 'Total loss': 0.8100964433767579} | train loss {'Reaction outcome loss': 0.8105756724894289, 'Total loss': 0.8105756724894289}
2022-11-23 00:47:57,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:57,530 INFO:     Epoch: 51
2022-11-23 00:47:58,336 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.804456198757345, 'Total loss': 0.804456198757345} | train loss {'Reaction outcome loss': 0.8153396794187878, 'Total loss': 0.8153396794187878}
2022-11-23 00:47:58,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:58,336 INFO:     Epoch: 52
2022-11-23 00:47:59,156 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8191080432046544, 'Total loss': 0.8191080432046544} | train loss {'Reaction outcome loss': 0.8148366187506841, 'Total loss': 0.8148366187506841}
2022-11-23 00:47:59,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:47:59,156 INFO:     Epoch: 53
2022-11-23 00:48:00,012 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7999395396221768, 'Total loss': 0.7999395396221768} | train loss {'Reaction outcome loss': 0.809284530489551, 'Total loss': 0.809284530489551}
2022-11-23 00:48:00,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:00,012 INFO:     Epoch: 54
2022-11-23 00:48:00,847 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8310120891440999, 'Total loss': 0.8310120891440999} | train loss {'Reaction outcome loss': 0.8060542839138132, 'Total loss': 0.8060542839138132}
2022-11-23 00:48:00,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:00,847 INFO:     Epoch: 55
2022-11-23 00:48:01,736 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8068917766213417, 'Total loss': 0.8068917766213417} | train loss {'Reaction outcome loss': 0.8120405700525292, 'Total loss': 0.8120405700525292}
2022-11-23 00:48:01,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:01,736 INFO:     Epoch: 56
2022-11-23 00:48:02,620 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8023206066678871, 'Total loss': 0.8023206066678871} | train loss {'Reaction outcome loss': 0.80938507357107, 'Total loss': 0.80938507357107}
2022-11-23 00:48:02,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:02,621 INFO:     Epoch: 57
2022-11-23 00:48:03,504 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8137956356460397, 'Total loss': 0.8137956356460397} | train loss {'Reaction outcome loss': 0.8103373465750382, 'Total loss': 0.8103373465750382}
2022-11-23 00:48:03,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:03,505 INFO:     Epoch: 58
2022-11-23 00:48:04,339 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8149845512075857, 'Total loss': 0.8149845512075857} | train loss {'Reaction outcome loss': 0.8177122063482338, 'Total loss': 0.8177122063482338}
2022-11-23 00:48:04,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:04,339 INFO:     Epoch: 59
2022-11-23 00:48:05,205 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8180106051943519, 'Total loss': 0.8180106051943519} | train loss {'Reaction outcome loss': 0.811220171963155, 'Total loss': 0.811220171963155}
2022-11-23 00:48:05,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:05,206 INFO:     Epoch: 60
2022-11-23 00:48:06,053 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7981338067488237, 'Total loss': 0.7981338067488237} | train loss {'Reaction outcome loss': 0.8087199985498359, 'Total loss': 0.8087199985498359}
2022-11-23 00:48:06,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:06,053 INFO:     Epoch: 61
2022-11-23 00:48:06,876 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8032163855704394, 'Total loss': 0.8032163855704394} | train loss {'Reaction outcome loss': 0.8054488615513693, 'Total loss': 0.8054488615513693}
2022-11-23 00:48:06,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:06,877 INFO:     Epoch: 62
2022-11-23 00:48:07,680 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.817031055688858, 'Total loss': 0.817031055688858} | train loss {'Reaction outcome loss': 0.8021901605824228, 'Total loss': 0.8021901605824228}
2022-11-23 00:48:07,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:07,682 INFO:     Epoch: 63
2022-11-23 00:48:08,507 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8020252666690133, 'Total loss': 0.8020252666690133} | train loss {'Reaction outcome loss': 0.8102029919744986, 'Total loss': 0.8102029919744986}
2022-11-23 00:48:08,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:08,507 INFO:     Epoch: 64
2022-11-23 00:48:09,330 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8073564686558463, 'Total loss': 0.8073564686558463} | train loss {'Reaction outcome loss': 0.8116739867669851, 'Total loss': 0.8116739867669851}
2022-11-23 00:48:09,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:09,330 INFO:     Epoch: 65
2022-11-23 00:48:10,149 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8049655488946221, 'Total loss': 0.8049655488946221} | train loss {'Reaction outcome loss': 0.8114888637896008, 'Total loss': 0.8114888637896008}
2022-11-23 00:48:10,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:10,149 INFO:     Epoch: 66
2022-11-23 00:48:10,948 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8260733207518404, 'Total loss': 0.8260733207518404} | train loss {'Reaction outcome loss': 0.809274459778056, 'Total loss': 0.809274459778056}
2022-11-23 00:48:10,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:10,948 INFO:     Epoch: 67
2022-11-23 00:48:11,765 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.825646928765557, 'Total loss': 0.825646928765557} | train loss {'Reaction outcome loss': 0.8112327248943962, 'Total loss': 0.8112327248943962}
2022-11-23 00:48:11,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:11,765 INFO:     Epoch: 68
2022-11-23 00:48:12,609 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8006897934458472, 'Total loss': 0.8006897934458472} | train loss {'Reaction outcome loss': 0.8179830609545534, 'Total loss': 0.8179830609545534}
2022-11-23 00:48:12,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:12,609 INFO:     Epoch: 69
2022-11-23 00:48:13,431 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8151088539849628, 'Total loss': 0.8151088539849628} | train loss {'Reaction outcome loss': 0.8042262345854088, 'Total loss': 0.8042262345854088}
2022-11-23 00:48:13,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:13,432 INFO:     Epoch: 70
2022-11-23 00:48:14,291 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8015137612819672, 'Total loss': 0.8015137612819672} | train loss {'Reaction outcome loss': 0.8089671994027822, 'Total loss': 0.8089671994027822}
2022-11-23 00:48:14,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:14,292 INFO:     Epoch: 71
2022-11-23 00:48:15,126 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8228125490925529, 'Total loss': 0.8228125490925529} | train loss {'Reaction outcome loss': 0.8103042883187653, 'Total loss': 0.8103042883187653}
2022-11-23 00:48:15,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:15,126 INFO:     Epoch: 72
2022-11-23 00:48:15,932 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8454911072145809, 'Total loss': 0.8454911072145809} | train loss {'Reaction outcome loss': 0.8076789161936957, 'Total loss': 0.8076789161936957}
2022-11-23 00:48:15,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:15,933 INFO:     Epoch: 73
2022-11-23 00:48:16,776 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8244882889769294, 'Total loss': 0.8244882889769294} | train loss {'Reaction outcome loss': 0.8074151224452957, 'Total loss': 0.8074151224452957}
2022-11-23 00:48:16,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:16,777 INFO:     Epoch: 74
2022-11-23 00:48:17,587 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8093792653896592, 'Total loss': 0.8093792653896592} | train loss {'Reaction outcome loss': 0.8134188691252157, 'Total loss': 0.8134188691252157}
2022-11-23 00:48:17,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:17,587 INFO:     Epoch: 75
2022-11-23 00:48:18,393 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8242410103028471, 'Total loss': 0.8242410103028471} | train loss {'Reaction outcome loss': 0.8101242253413568, 'Total loss': 0.8101242253413568}
2022-11-23 00:48:18,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:18,393 INFO:     Epoch: 76
2022-11-23 00:48:19,179 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.806699892336672, 'Total loss': 0.806699892336672} | train loss {'Reaction outcome loss': 0.8122927963974987, 'Total loss': 0.8122927963974987}
2022-11-23 00:48:19,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:19,179 INFO:     Epoch: 77
2022-11-23 00:48:19,962 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8036664541472088, 'Total loss': 0.8036664541472088} | train loss {'Reaction outcome loss': 0.8073133283298508, 'Total loss': 0.8073133283298508}
2022-11-23 00:48:19,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:19,963 INFO:     Epoch: 78
2022-11-23 00:48:20,765 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8234795108437538, 'Total loss': 0.8234795108437538} | train loss {'Reaction outcome loss': 0.8130395265243314, 'Total loss': 0.8130395265243314}
2022-11-23 00:48:20,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:20,765 INFO:     Epoch: 79
2022-11-23 00:48:21,555 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8642380400137468, 'Total loss': 0.8642380400137468} | train loss {'Reaction outcome loss': 0.8079619029996848, 'Total loss': 0.8079619029996848}
2022-11-23 00:48:21,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:21,555 INFO:     Epoch: 80
2022-11-23 00:48:22,357 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8140552599321712, 'Total loss': 0.8140552599321712} | train loss {'Reaction outcome loss': 0.811992729738777, 'Total loss': 0.811992729738777}
2022-11-23 00:48:22,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:22,357 INFO:     Epoch: 81
2022-11-23 00:48:23,139 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.803847839886492, 'Total loss': 0.803847839886492} | train loss {'Reaction outcome loss': 0.8115776555258253, 'Total loss': 0.8115776555258253}
2022-11-23 00:48:23,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:23,139 INFO:     Epoch: 82
2022-11-23 00:48:23,907 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8360648568380963, 'Total loss': 0.8360648568380963} | train loss {'Reaction outcome loss': 0.808168054954243, 'Total loss': 0.808168054954243}
2022-11-23 00:48:23,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:23,907 INFO:     Epoch: 83
2022-11-23 00:48:24,663 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7958402796225115, 'Total loss': 0.7958402796225115} | train loss {'Reaction outcome loss': 0.8151772847542396, 'Total loss': 0.8151772847542396}
2022-11-23 00:48:24,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:24,663 INFO:     Epoch: 84
2022-11-23 00:48:25,441 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8039068566127257, 'Total loss': 0.8039068566127257} | train loss {'Reaction outcome loss': 0.8130433309657371, 'Total loss': 0.8130433309657371}
2022-11-23 00:48:25,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:25,441 INFO:     Epoch: 85
2022-11-23 00:48:26,244 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8045512282035567, 'Total loss': 0.8045512282035567} | train loss {'Reaction outcome loss': 0.809744732439337, 'Total loss': 0.809744732439337}
2022-11-23 00:48:26,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:26,245 INFO:     Epoch: 86
2022-11-23 00:48:27,026 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8300408951260827, 'Total loss': 0.8300408951260827} | train loss {'Reaction outcome loss': 0.808521029558259, 'Total loss': 0.808521029558259}
2022-11-23 00:48:27,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:27,027 INFO:     Epoch: 87
2022-11-23 00:48:27,806 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8167335289445791, 'Total loss': 0.8167335289445791} | train loss {'Reaction outcome loss': 0.8126459860126016, 'Total loss': 0.8126459860126016}
2022-11-23 00:48:27,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:27,807 INFO:     Epoch: 88
2022-11-23 00:48:28,596 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8009577908299186, 'Total loss': 0.8009577908299186} | train loss {'Reaction outcome loss': 0.8102459608301943, 'Total loss': 0.8102459608301943}
2022-11-23 00:48:28,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:28,597 INFO:     Epoch: 89
2022-11-23 00:48:29,353 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8121665661985223, 'Total loss': 0.8121665661985223} | train loss {'Reaction outcome loss': 0.8147014911599487, 'Total loss': 0.8147014911599487}
2022-11-23 00:48:29,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:29,354 INFO:     Epoch: 90
2022-11-23 00:48:30,191 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8060909943147139, 'Total loss': 0.8060909943147139} | train loss {'Reaction outcome loss': 0.8108310426702263, 'Total loss': 0.8108310426702263}
2022-11-23 00:48:30,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:30,191 INFO:     Epoch: 91
2022-11-23 00:48:31,031 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8076026507399299, 'Total loss': 0.8076026507399299} | train loss {'Reaction outcome loss': 0.8129156493706259, 'Total loss': 0.8129156493706259}
2022-11-23 00:48:31,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:31,031 INFO:     Epoch: 92
2022-11-23 00:48:31,854 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8323394195599989, 'Total loss': 0.8323394195599989} | train loss {'Reaction outcome loss': 0.814290253739608, 'Total loss': 0.814290253739608}
2022-11-23 00:48:31,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:31,854 INFO:     Epoch: 93
2022-11-23 00:48:32,661 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8032719215208833, 'Total loss': 0.8032719215208833} | train loss {'Reaction outcome loss': 0.8209917664769207, 'Total loss': 0.8209917664769207}
2022-11-23 00:48:32,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:32,661 INFO:     Epoch: 94
2022-11-23 00:48:33,465 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.803397420455109, 'Total loss': 0.803397420455109} | train loss {'Reaction outcome loss': 0.8085767937756261, 'Total loss': 0.8085767937756261}
2022-11-23 00:48:33,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:33,466 INFO:     Epoch: 95
2022-11-23 00:48:34,273 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.821819510649551, 'Total loss': 0.821819510649551} | train loss {'Reaction outcome loss': 0.8130674905139907, 'Total loss': 0.8130674905139907}
2022-11-23 00:48:34,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:34,274 INFO:     Epoch: 96
2022-11-23 00:48:35,050 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8024535124952142, 'Total loss': 0.8024535124952142} | train loss {'Reaction outcome loss': 0.8139573719337402, 'Total loss': 0.8139573719337402}
2022-11-23 00:48:35,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:35,050 INFO:     Epoch: 97
2022-11-23 00:48:35,901 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8450545208020643, 'Total loss': 0.8450545208020643} | train loss {'Reaction outcome loss': 0.8175581130180282, 'Total loss': 0.8175581130180282}
2022-11-23 00:48:35,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:35,901 INFO:     Epoch: 98
2022-11-23 00:48:36,737 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.799866842275316, 'Total loss': 0.799866842275316} | train loss {'Reaction outcome loss': 0.8139088156252254, 'Total loss': 0.8139088156252254}
2022-11-23 00:48:36,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:36,737 INFO:     Epoch: 99
2022-11-23 00:48:37,618 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7917953688989986, 'Total loss': 0.7917953688989986} | train loss {'Reaction outcome loss': 0.8117997079243061, 'Total loss': 0.8117997079243061}
2022-11-23 00:48:37,619 INFO:     Best model found after epoch 11 of 100.
2022-11-23 00:48:37,619 INFO:   Done with stage: TRAINING
2022-11-23 00:48:37,619 INFO:   Starting stage: EVALUATION
2022-11-23 00:48:37,744 INFO:   Done with stage: EVALUATION
2022-11-23 00:48:37,744 INFO:   Leaving out SEQ value Fold_1
2022-11-23 00:48:37,757 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 00:48:37,757 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:48:38,428 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:48:38,429 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:48:38,514 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:48:38,514 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:48:38,514 INFO:     No hyperparam tuning for this model
2022-11-23 00:48:38,514 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:48:38,514 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:48:38,515 INFO:     None feature selector for col prot
2022-11-23 00:48:38,515 INFO:     None feature selector for col prot
2022-11-23 00:48:38,516 INFO:     None feature selector for col prot
2022-11-23 00:48:38,516 INFO:     None feature selector for col chem
2022-11-23 00:48:38,516 INFO:     None feature selector for col chem
2022-11-23 00:48:38,516 INFO:     None feature selector for col chem
2022-11-23 00:48:38,517 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:48:38,517 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:48:38,518 INFO:     Number of params in model 168571
2022-11-23 00:48:38,521 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:48:38,521 INFO:   Starting stage: TRAINING
2022-11-23 00:48:38,579 INFO:     Val loss before train {'Reaction outcome loss': 0.9971455240791495, 'Total loss': 0.9971455240791495}
2022-11-23 00:48:38,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:38,580 INFO:     Epoch: 0
2022-11-23 00:48:39,371 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8102180937474425, 'Total loss': 0.8102180937474425} | train loss {'Reaction outcome loss': 0.8907011889735696, 'Total loss': 0.8907011889735696}
2022-11-23 00:48:39,371 INFO:     Found new best model at epoch 0
2022-11-23 00:48:39,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:39,372 INFO:     Epoch: 1
2022-11-23 00:48:40,167 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8187631985003297, 'Total loss': 0.8187631985003297} | train loss {'Reaction outcome loss': 0.8513541243638587, 'Total loss': 0.8513541243638587}
2022-11-23 00:48:40,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:40,168 INFO:     Epoch: 2
2022-11-23 00:48:40,960 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8175428482619199, 'Total loss': 0.8175428482619199} | train loss {'Reaction outcome loss': 0.8461548059816785, 'Total loss': 0.8461548059816785}
2022-11-23 00:48:40,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:40,960 INFO:     Epoch: 3
2022-11-23 00:48:41,757 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8085064684802835, 'Total loss': 0.8085064684802835} | train loss {'Reaction outcome loss': 0.8432164213314712, 'Total loss': 0.8432164213314712}
2022-11-23 00:48:41,757 INFO:     Found new best model at epoch 3
2022-11-23 00:48:41,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:41,758 INFO:     Epoch: 4
2022-11-23 00:48:42,553 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.811719382351095, 'Total loss': 0.811719382351095} | train loss {'Reaction outcome loss': 0.834163710897268, 'Total loss': 0.834163710897268}
2022-11-23 00:48:42,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:42,553 INFO:     Epoch: 5
2022-11-23 00:48:43,366 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.824229238385504, 'Total loss': 0.824229238385504} | train loss {'Reaction outcome loss': 0.8404971016080756, 'Total loss': 0.8404971016080756}
2022-11-23 00:48:43,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:43,366 INFO:     Epoch: 6
2022-11-23 00:48:44,140 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8088340813463385, 'Total loss': 0.8088340813463385} | train loss {'Reaction outcome loss': 0.8384470491998108, 'Total loss': 0.8384470491998108}
2022-11-23 00:48:44,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:44,140 INFO:     Epoch: 7
2022-11-23 00:48:44,906 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8091032938523726, 'Total loss': 0.8091032938523726} | train loss {'Reaction outcome loss': 0.8271556124392792, 'Total loss': 0.8271556124392792}
2022-11-23 00:48:44,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:44,908 INFO:     Epoch: 8
2022-11-23 00:48:45,689 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8179369358853861, 'Total loss': 0.8179369358853861} | train loss {'Reaction outcome loss': 0.8274190848172918, 'Total loss': 0.8274190848172918}
2022-11-23 00:48:45,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:45,689 INFO:     Epoch: 9
2022-11-23 00:48:46,445 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7954150790517981, 'Total loss': 0.7954150790517981} | train loss {'Reaction outcome loss': 0.8369895317535169, 'Total loss': 0.8369895317535169}
2022-11-23 00:48:46,445 INFO:     Found new best model at epoch 9
2022-11-23 00:48:46,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:46,446 INFO:     Epoch: 10
2022-11-23 00:48:47,240 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7948098087852652, 'Total loss': 0.7948098087852652} | train loss {'Reaction outcome loss': 0.8275004304372348, 'Total loss': 0.8275004304372348}
2022-11-23 00:48:47,240 INFO:     Found new best model at epoch 10
2022-11-23 00:48:47,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:47,241 INFO:     Epoch: 11
2022-11-23 00:48:48,012 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8072822351347316, 'Total loss': 0.8072822351347316} | train loss {'Reaction outcome loss': 0.8339062315008419, 'Total loss': 0.8339062315008419}
2022-11-23 00:48:48,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:48,013 INFO:     Epoch: 12
2022-11-23 00:48:48,779 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8121941645037044, 'Total loss': 0.8121941645037044} | train loss {'Reaction outcome loss': 0.8305946465445916, 'Total loss': 0.8305946465445916}
2022-11-23 00:48:48,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:48,780 INFO:     Epoch: 13
2022-11-23 00:48:49,556 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7956888458945535, 'Total loss': 0.7956888458945535} | train loss {'Reaction outcome loss': 0.8291024435386967, 'Total loss': 0.8291024435386967}
2022-11-23 00:48:49,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:49,556 INFO:     Epoch: 14
2022-11-23 00:48:50,342 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8028850528326902, 'Total loss': 0.8028850528326902} | train loss {'Reaction outcome loss': 0.8230840053394256, 'Total loss': 0.8230840053394256}
2022-11-23 00:48:50,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:50,343 INFO:     Epoch: 15
2022-11-23 00:48:51,109 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8049208454110406, 'Total loss': 0.8049208454110406} | train loss {'Reaction outcome loss': 0.8261503907833022, 'Total loss': 0.8261503907833022}
2022-11-23 00:48:51,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:51,110 INFO:     Epoch: 16
2022-11-23 00:48:51,880 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8101671080697667, 'Total loss': 0.8101671080697667} | train loss {'Reaction outcome loss': 0.830138919807156, 'Total loss': 0.830138919807156}
2022-11-23 00:48:51,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:51,880 INFO:     Epoch: 17
2022-11-23 00:48:52,669 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8149699121713638, 'Total loss': 0.8149699121713638} | train loss {'Reaction outcome loss': 0.8210202124542915, 'Total loss': 0.8210202124542915}
2022-11-23 00:48:52,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:52,669 INFO:     Epoch: 18
2022-11-23 00:48:53,440 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8205290192907507, 'Total loss': 0.8205290192907507} | train loss {'Reaction outcome loss': 0.8188099233124421, 'Total loss': 0.8188099233124421}
2022-11-23 00:48:53,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:53,440 INFO:     Epoch: 19
2022-11-23 00:48:54,195 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8000997413288463, 'Total loss': 0.8000997413288463} | train loss {'Reaction outcome loss': 0.8266217620130855, 'Total loss': 0.8266217620130855}
2022-11-23 00:48:54,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:54,195 INFO:     Epoch: 20
2022-11-23 00:48:54,945 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8056240481409159, 'Total loss': 0.8056240481409159} | train loss {'Reaction outcome loss': 0.8214198016685995, 'Total loss': 0.8214198016685995}
2022-11-23 00:48:54,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:54,945 INFO:     Epoch: 21
2022-11-23 00:48:55,727 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8121747428720648, 'Total loss': 0.8121747428720648} | train loss {'Reaction outcome loss': 0.8304258387098428, 'Total loss': 0.8304258387098428}
2022-11-23 00:48:55,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:55,727 INFO:     Epoch: 22
2022-11-23 00:48:56,507 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8271370232105255, 'Total loss': 0.8271370232105255} | train loss {'Reaction outcome loss': 0.8442922022178588, 'Total loss': 0.8442922022178588}
2022-11-23 00:48:56,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:56,507 INFO:     Epoch: 23
2022-11-23 00:48:57,304 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7981025041504339, 'Total loss': 0.7981025041504339} | train loss {'Reaction outcome loss': 0.8388236634403106, 'Total loss': 0.8388236634403106}
2022-11-23 00:48:57,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:57,305 INFO:     Epoch: 24
2022-11-23 00:48:58,110 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7843907468698241, 'Total loss': 0.7843907468698241} | train loss {'Reaction outcome loss': 0.8270482802198, 'Total loss': 0.8270482802198}
2022-11-23 00:48:58,110 INFO:     Found new best model at epoch 24
2022-11-23 00:48:58,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:58,111 INFO:     Epoch: 25
2022-11-23 00:48:58,875 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7997691604224119, 'Total loss': 0.7997691604224119} | train loss {'Reaction outcome loss': 0.8266781053321082, 'Total loss': 0.8266781053321082}
2022-11-23 00:48:58,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:58,875 INFO:     Epoch: 26
2022-11-23 00:48:59,669 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8093967126174406, 'Total loss': 0.8093967126174406} | train loss {'Reaction outcome loss': 0.8186445215091049, 'Total loss': 0.8186445215091049}
2022-11-23 00:48:59,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:48:59,669 INFO:     Epoch: 27
2022-11-23 00:49:00,486 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8248109675266526, 'Total loss': 0.8248109675266526} | train loss {'Reaction outcome loss': 0.8167115325628505, 'Total loss': 0.8167115325628505}
2022-11-23 00:49:00,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:00,486 INFO:     Epoch: 28
2022-11-23 00:49:01,271 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7935492829843, 'Total loss': 0.7935492829843} | train loss {'Reaction outcome loss': 0.8248308063277349, 'Total loss': 0.8248308063277349}
2022-11-23 00:49:01,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:01,271 INFO:     Epoch: 29
2022-11-23 00:49:02,108 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8064755018461834, 'Total loss': 0.8064755018461834} | train loss {'Reaction outcome loss': 0.8280790781202586, 'Total loss': 0.8280790781202586}
2022-11-23 00:49:02,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:02,109 INFO:     Epoch: 30
2022-11-23 00:49:02,960 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8055753497914835, 'Total loss': 0.8055753497914835} | train loss {'Reaction outcome loss': 0.8206813854847842, 'Total loss': 0.8206813854847842}
2022-11-23 00:49:02,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:02,960 INFO:     Epoch: 31
2022-11-23 00:49:03,777 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8350059742277319, 'Total loss': 0.8350059742277319} | train loss {'Reaction outcome loss': 0.8235491865318314, 'Total loss': 0.8235491865318314}
2022-11-23 00:49:03,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:03,777 INFO:     Epoch: 32
2022-11-23 00:49:04,605 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8296669938347556, 'Total loss': 0.8296669938347556} | train loss {'Reaction outcome loss': 0.8213261375543077, 'Total loss': 0.8213261375543077}
2022-11-23 00:49:04,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:04,606 INFO:     Epoch: 33
2022-11-23 00:49:05,420 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8005376905202866, 'Total loss': 0.8005376905202866} | train loss {'Reaction outcome loss': 0.8174093220880639, 'Total loss': 0.8174093220880639}
2022-11-23 00:49:05,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:05,420 INFO:     Epoch: 34
2022-11-23 00:49:06,247 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7935463190078735, 'Total loss': 0.7935463190078735} | train loss {'Reaction outcome loss': 0.8139841675547211, 'Total loss': 0.8139841675547211}
2022-11-23 00:49:06,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:06,248 INFO:     Epoch: 35
2022-11-23 00:49:07,077 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8380742235617205, 'Total loss': 0.8380742235617205} | train loss {'Reaction outcome loss': 0.8157137060228751, 'Total loss': 0.8157137060228751}
2022-11-23 00:49:07,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:07,078 INFO:     Epoch: 36
2022-11-23 00:49:07,857 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8006441999565471, 'Total loss': 0.8006441999565471} | train loss {'Reaction outcome loss': 0.8261712083691045, 'Total loss': 0.8261712083691045}
2022-11-23 00:49:07,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:07,857 INFO:     Epoch: 37
2022-11-23 00:49:08,716 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8075933131304655, 'Total loss': 0.8075933131304655} | train loss {'Reaction outcome loss': 0.8144297347015698, 'Total loss': 0.8144297347015698}
2022-11-23 00:49:08,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:08,717 INFO:     Epoch: 38
2022-11-23 00:49:09,518 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8016308254816316, 'Total loss': 0.8016308254816316} | train loss {'Reaction outcome loss': 0.8161393026349998, 'Total loss': 0.8161393026349998}
2022-11-23 00:49:09,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:09,519 INFO:     Epoch: 39
2022-11-23 00:49:10,316 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7967304560271177, 'Total loss': 0.7967304560271177} | train loss {'Reaction outcome loss': 0.8224675394745491, 'Total loss': 0.8224675394745491}
2022-11-23 00:49:10,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:10,317 INFO:     Epoch: 40
2022-11-23 00:49:11,081 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7959489592097022, 'Total loss': 0.7959489592097022} | train loss {'Reaction outcome loss': 0.8179293570489536, 'Total loss': 0.8179293570489536}
2022-11-23 00:49:11,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:11,081 INFO:     Epoch: 41
2022-11-23 00:49:11,857 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7963151288303462, 'Total loss': 0.7963151288303462} | train loss {'Reaction outcome loss': 0.8247806276628363, 'Total loss': 0.8247806276628363}
2022-11-23 00:49:11,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:11,858 INFO:     Epoch: 42
2022-11-23 00:49:12,639 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7883115674961697, 'Total loss': 0.7883115674961697} | train loss {'Reaction outcome loss': 0.8182572621535434, 'Total loss': 0.8182572621535434}
2022-11-23 00:49:12,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:12,640 INFO:     Epoch: 43
2022-11-23 00:49:13,444 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8169173097068613, 'Total loss': 0.8169173097068613} | train loss {'Reaction outcome loss': 0.8118438019684935, 'Total loss': 0.8118438019684935}
2022-11-23 00:49:13,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:13,444 INFO:     Epoch: 44
2022-11-23 00:49:14,266 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7920937958088788, 'Total loss': 0.7920937958088788} | train loss {'Reaction outcome loss': 0.8175275761950836, 'Total loss': 0.8175275761950836}
2022-11-23 00:49:14,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:14,266 INFO:     Epoch: 45
2022-11-23 00:49:15,100 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7940657145597718, 'Total loss': 0.7940657145597718} | train loss {'Reaction outcome loss': 0.8214733866062242, 'Total loss': 0.8214733866062242}
2022-11-23 00:49:15,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:15,100 INFO:     Epoch: 46
2022-11-23 00:49:15,862 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7970537550070069, 'Total loss': 0.7970537550070069} | train loss {'Reaction outcome loss': 0.8101892444165611, 'Total loss': 0.8101892444165611}
2022-11-23 00:49:15,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:15,863 INFO:     Epoch: 47
2022-11-23 00:49:16,637 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7902110239321535, 'Total loss': 0.7902110239321535} | train loss {'Reaction outcome loss': 0.8122460535663342, 'Total loss': 0.8122460535663342}
2022-11-23 00:49:16,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:16,638 INFO:     Epoch: 48
2022-11-23 00:49:17,415 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8013777102936398, 'Total loss': 0.8013777102936398} | train loss {'Reaction outcome loss': 0.8118131867183848, 'Total loss': 0.8118131867183848}
2022-11-23 00:49:17,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:17,415 INFO:     Epoch: 49
2022-11-23 00:49:18,178 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.789031597700986, 'Total loss': 0.789031597700986} | train loss {'Reaction outcome loss': 0.8146573988954547, 'Total loss': 0.8146573988954547}
2022-11-23 00:49:18,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:18,178 INFO:     Epoch: 50
2022-11-23 00:49:18,970 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8012355992739851, 'Total loss': 0.8012355992739851} | train loss {'Reaction outcome loss': 0.8105630891525794, 'Total loss': 0.8105630891525794}
2022-11-23 00:49:18,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:18,970 INFO:     Epoch: 51
2022-11-23 00:49:19,730 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8350981446829709, 'Total loss': 0.8350981446829709} | train loss {'Reaction outcome loss': 0.8149303779428304, 'Total loss': 0.8149303779428304}
2022-11-23 00:49:19,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:19,730 INFO:     Epoch: 52
2022-11-23 00:49:20,516 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8107919483022257, 'Total loss': 0.8107919483022257} | train loss {'Reaction outcome loss': 0.8135916457364434, 'Total loss': 0.8135916457364434}
2022-11-23 00:49:20,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:20,517 INFO:     Epoch: 53
2022-11-23 00:49:21,293 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8011422760107301, 'Total loss': 0.8011422760107301} | train loss {'Reaction outcome loss': 0.8119052977938401, 'Total loss': 0.8119052977938401}
2022-11-23 00:49:21,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:21,293 INFO:     Epoch: 54
2022-11-23 00:49:22,073 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7945758144963871, 'Total loss': 0.7945758144963871} | train loss {'Reaction outcome loss': 0.8168359996094877, 'Total loss': 0.8168359996094877}
2022-11-23 00:49:22,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:22,073 INFO:     Epoch: 55
2022-11-23 00:49:22,860 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7776988270607862, 'Total loss': 0.7776988270607862} | train loss {'Reaction outcome loss': 0.8092020695900869, 'Total loss': 0.8092020695900869}
2022-11-23 00:49:22,861 INFO:     Found new best model at epoch 55
2022-11-23 00:49:22,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:22,862 INFO:     Epoch: 56
2022-11-23 00:49:23,640 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7855328924276612, 'Total loss': 0.7855328924276612} | train loss {'Reaction outcome loss': 0.8097747861132448, 'Total loss': 0.8097747861132448}
2022-11-23 00:49:23,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:23,640 INFO:     Epoch: 57
2022-11-23 00:49:24,403 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7731530449607156, 'Total loss': 0.7731530449607156} | train loss {'Reaction outcome loss': 0.8075966262805317, 'Total loss': 0.8075966262805317}
2022-11-23 00:49:24,403 INFO:     Found new best model at epoch 57
2022-11-23 00:49:24,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:24,404 INFO:     Epoch: 58
2022-11-23 00:49:25,155 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7682930495251309, 'Total loss': 0.7682930495251309} | train loss {'Reaction outcome loss': 0.8105388335612139, 'Total loss': 0.8105388335612139}
2022-11-23 00:49:25,155 INFO:     Found new best model at epoch 58
2022-11-23 00:49:25,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:25,156 INFO:     Epoch: 59
2022-11-23 00:49:25,938 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7790229367938909, 'Total loss': 0.7790229367938909} | train loss {'Reaction outcome loss': 0.8131555266949811, 'Total loss': 0.8131555266949811}
2022-11-23 00:49:25,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:25,939 INFO:     Epoch: 60
2022-11-23 00:49:26,705 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7813521908088163, 'Total loss': 0.7813521908088163} | train loss {'Reaction outcome loss': 0.8218501502203073, 'Total loss': 0.8218501502203073}
2022-11-23 00:49:26,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:26,705 INFO:     Epoch: 61
2022-11-23 00:49:27,473 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7978861799294298, 'Total loss': 0.7978861799294298} | train loss {'Reaction outcome loss': 0.8100689837203817, 'Total loss': 0.8100689837203817}
2022-11-23 00:49:27,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:27,474 INFO:     Epoch: 62
2022-11-23 00:49:28,247 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7787912752140652, 'Total loss': 0.7787912752140652} | train loss {'Reaction outcome loss': 0.8068510300898359, 'Total loss': 0.8068510300898359}
2022-11-23 00:49:28,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:28,247 INFO:     Epoch: 63
2022-11-23 00:49:29,033 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7868270047686317, 'Total loss': 0.7868270047686317} | train loss {'Reaction outcome loss': 0.8159477656428148, 'Total loss': 0.8159477656428148}
2022-11-23 00:49:29,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:29,033 INFO:     Epoch: 64
2022-11-23 00:49:29,821 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7916384508663957, 'Total loss': 0.7916384508663957} | train loss {'Reaction outcome loss': 0.8148768293230158, 'Total loss': 0.8148768293230158}
2022-11-23 00:49:29,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:29,821 INFO:     Epoch: 65
2022-11-23 00:49:30,599 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8007500462911346, 'Total loss': 0.8007500462911346} | train loss {'Reaction outcome loss': 0.80764874297115, 'Total loss': 0.80764874297115}
2022-11-23 00:49:30,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:30,599 INFO:     Epoch: 66
2022-11-23 00:49:31,379 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7707319083538923, 'Total loss': 0.7707319083538923} | train loss {'Reaction outcome loss': 0.8185154858388399, 'Total loss': 0.8185154858388399}
2022-11-23 00:49:31,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:31,381 INFO:     Epoch: 67
2022-11-23 00:49:32,163 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8175876011902635, 'Total loss': 0.8175876011902635} | train loss {'Reaction outcome loss': 0.8044035596252694, 'Total loss': 0.8044035596252694}
2022-11-23 00:49:32,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:32,163 INFO:     Epoch: 68
2022-11-23 00:49:32,968 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.786569050767205, 'Total loss': 0.786569050767205} | train loss {'Reaction outcome loss': 0.8069722941409239, 'Total loss': 0.8069722941409239}
2022-11-23 00:49:32,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:32,968 INFO:     Epoch: 69
2022-11-23 00:49:33,734 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7781175036321987, 'Total loss': 0.7781175036321987} | train loss {'Reaction outcome loss': 0.8060842464086015, 'Total loss': 0.8060842464086015}
2022-11-23 00:49:33,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:33,734 INFO:     Epoch: 70
2022-11-23 00:49:34,507 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7776690247383985, 'Total loss': 0.7776690247383985} | train loss {'Reaction outcome loss': 0.8132180319382594, 'Total loss': 0.8132180319382594}
2022-11-23 00:49:34,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:34,508 INFO:     Epoch: 71
2022-11-23 00:49:35,287 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7997645471583713, 'Total loss': 0.7997645471583713} | train loss {'Reaction outcome loss': 0.8023625670174356, 'Total loss': 0.8023625670174356}
2022-11-23 00:49:35,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:35,287 INFO:     Epoch: 72
2022-11-23 00:49:36,082 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7890969785777006, 'Total loss': 0.7890969785777006} | train loss {'Reaction outcome loss': 0.8106717922185597, 'Total loss': 0.8106717922185597}
2022-11-23 00:49:36,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:36,082 INFO:     Epoch: 73
2022-11-23 00:49:36,856 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7777728844772686, 'Total loss': 0.7777728844772686} | train loss {'Reaction outcome loss': 0.8104771486660729, 'Total loss': 0.8104771486660729}
2022-11-23 00:49:36,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:36,857 INFO:     Epoch: 74
2022-11-23 00:49:37,688 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7769266597249291, 'Total loss': 0.7769266597249291} | train loss {'Reaction outcome loss': 0.8030129989631746, 'Total loss': 0.8030129989631746}
2022-11-23 00:49:37,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:37,689 INFO:     Epoch: 75
2022-11-23 00:49:38,540 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7726562300866301, 'Total loss': 0.7726562300866301} | train loss {'Reaction outcome loss': 0.8107116983728371, 'Total loss': 0.8107116983728371}
2022-11-23 00:49:38,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:38,540 INFO:     Epoch: 76
2022-11-23 00:49:39,336 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7648334570906379, 'Total loss': 0.7648334570906379} | train loss {'Reaction outcome loss': 0.8023326846993404, 'Total loss': 0.8023326846993404}
2022-11-23 00:49:39,336 INFO:     Found new best model at epoch 76
2022-11-23 00:49:39,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:39,337 INFO:     Epoch: 77
2022-11-23 00:49:40,160 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7701352529905059, 'Total loss': 0.7701352529905059} | train loss {'Reaction outcome loss': 0.8061489671589392, 'Total loss': 0.8061489671589392}
2022-11-23 00:49:40,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:40,160 INFO:     Epoch: 78
2022-11-23 00:49:40,948 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7716633907773278, 'Total loss': 0.7716633907773278} | train loss {'Reaction outcome loss': 0.8044469375842014, 'Total loss': 0.8044469375842014}
2022-11-23 00:49:40,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:40,948 INFO:     Epoch: 79
2022-11-23 00:49:41,764 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7720146030187607, 'Total loss': 0.7720146030187607} | train loss {'Reaction outcome loss': 0.8068193998414013, 'Total loss': 0.8068193998414013}
2022-11-23 00:49:41,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:41,764 INFO:     Epoch: 80
2022-11-23 00:49:42,568 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7645642825148322, 'Total loss': 0.7645642825148322} | train loss {'Reaction outcome loss': 0.8041016366559002, 'Total loss': 0.8041016366559002}
2022-11-23 00:49:42,570 INFO:     Found new best model at epoch 80
2022-11-23 00:49:42,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:42,571 INFO:     Epoch: 81
2022-11-23 00:49:43,408 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7483161383054473, 'Total loss': 0.7483161383054473} | train loss {'Reaction outcome loss': 0.7997621849239597, 'Total loss': 0.7997621849239597}
2022-11-23 00:49:43,408 INFO:     Found new best model at epoch 81
2022-11-23 00:49:43,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:43,409 INFO:     Epoch: 82
2022-11-23 00:49:44,204 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7696335810151967, 'Total loss': 0.7696335810151967} | train loss {'Reaction outcome loss': 0.8018204293511657, 'Total loss': 0.8018204293511657}
2022-11-23 00:49:44,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:44,204 INFO:     Epoch: 83
2022-11-23 00:49:45,018 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.766326246613806, 'Total loss': 0.766326246613806} | train loss {'Reaction outcome loss': 0.7935462041422423, 'Total loss': 0.7935462041422423}
2022-11-23 00:49:45,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:45,018 INFO:     Epoch: 84
2022-11-23 00:49:45,857 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.762218442152847, 'Total loss': 0.762218442152847} | train loss {'Reaction outcome loss': 0.7937401492103391, 'Total loss': 0.7937401492103391}
2022-11-23 00:49:45,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:45,857 INFO:     Epoch: 85
2022-11-23 00:49:46,682 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7643415846607902, 'Total loss': 0.7643415846607902} | train loss {'Reaction outcome loss': 0.7906893002781791, 'Total loss': 0.7906893002781791}
2022-11-23 00:49:46,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:46,683 INFO:     Epoch: 86
2022-11-23 00:49:47,481 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7617808472026478, 'Total loss': 0.7617808472026478} | train loss {'Reaction outcome loss': 0.7846297572257548, 'Total loss': 0.7846297572257548}
2022-11-23 00:49:47,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:47,482 INFO:     Epoch: 87
2022-11-23 00:49:48,276 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7772755534811453, 'Total loss': 0.7772755534811453} | train loss {'Reaction outcome loss': 0.7791484350994652, 'Total loss': 0.7791484350994652}
2022-11-23 00:49:48,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:48,276 INFO:     Epoch: 88
2022-11-23 00:49:49,054 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7817505361004309, 'Total loss': 0.7817505361004309} | train loss {'Reaction outcome loss': 0.7808633223176003, 'Total loss': 0.7808633223176003}
2022-11-23 00:49:49,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:49,054 INFO:     Epoch: 89
2022-11-23 00:49:49,844 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7629167904908006, 'Total loss': 0.7629167904908006} | train loss {'Reaction outcome loss': 0.7896828662287368, 'Total loss': 0.7896828662287368}
2022-11-23 00:49:49,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:49,844 INFO:     Epoch: 90
2022-11-23 00:49:50,678 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8048976653001525, 'Total loss': 0.8048976653001525} | train loss {'Reaction outcome loss': 0.7811331534192629, 'Total loss': 0.7811331534192629}
2022-11-23 00:49:50,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:50,678 INFO:     Epoch: 91
2022-11-23 00:49:51,477 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7412267814983021, 'Total loss': 0.7412267814983021} | train loss {'Reaction outcome loss': 0.776484033356794, 'Total loss': 0.776484033356794}
2022-11-23 00:49:51,477 INFO:     Found new best model at epoch 91
2022-11-23 00:49:51,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:51,478 INFO:     Epoch: 92
2022-11-23 00:49:52,304 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7441041327335618, 'Total loss': 0.7441041327335618} | train loss {'Reaction outcome loss': 0.7720523608116968, 'Total loss': 0.7720523608116968}
2022-11-23 00:49:52,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:52,304 INFO:     Epoch: 93
2022-11-23 00:49:53,120 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7654852812940424, 'Total loss': 0.7654852812940424} | train loss {'Reaction outcome loss': 0.7645390831265855, 'Total loss': 0.7645390831265855}
2022-11-23 00:49:53,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:53,121 INFO:     Epoch: 94
2022-11-23 00:49:53,889 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7615449218587442, 'Total loss': 0.7615449218587442} | train loss {'Reaction outcome loss': 0.7616370063320346, 'Total loss': 0.7616370063320346}
2022-11-23 00:49:53,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:53,889 INFO:     Epoch: 95
2022-11-23 00:49:54,708 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7379722940650854, 'Total loss': 0.7379722940650854} | train loss {'Reaction outcome loss': 0.7627042731881021, 'Total loss': 0.7627042731881021}
2022-11-23 00:49:54,709 INFO:     Found new best model at epoch 95
2022-11-23 00:49:54,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:54,709 INFO:     Epoch: 96
2022-11-23 00:49:55,493 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.75351416726004, 'Total loss': 0.75351416726004} | train loss {'Reaction outcome loss': 0.7659322277978364, 'Total loss': 0.7659322277978364}
2022-11-23 00:49:55,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:55,493 INFO:     Epoch: 97
2022-11-23 00:49:56,315 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7060725709254091, 'Total loss': 0.7060725709254091} | train loss {'Reaction outcome loss': 0.7592411096762066, 'Total loss': 0.7592411096762066}
2022-11-23 00:49:56,315 INFO:     Found new best model at epoch 97
2022-11-23 00:49:56,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:56,316 INFO:     Epoch: 98
2022-11-23 00:49:57,150 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.711046005514535, 'Total loss': 0.711046005514535} | train loss {'Reaction outcome loss': 0.740452400947872, 'Total loss': 0.740452400947872}
2022-11-23 00:49:57,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:57,150 INFO:     Epoch: 99
2022-11-23 00:49:57,918 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7604603706435724, 'Total loss': 0.7604603706435724} | train loss {'Reaction outcome loss': 0.732537260542997, 'Total loss': 0.732537260542997}
2022-11-23 00:49:57,918 INFO:     Best model found after epoch 98 of 100.
2022-11-23 00:49:57,918 INFO:   Done with stage: TRAINING
2022-11-23 00:49:57,918 INFO:   Starting stage: EVALUATION
2022-11-23 00:49:58,044 INFO:   Done with stage: EVALUATION
2022-11-23 00:49:58,044 INFO:   Leaving out SEQ value Fold_2
2022-11-23 00:49:58,057 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-23 00:49:58,057 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:49:58,712 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:49:58,713 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:49:58,782 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:49:58,783 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:49:58,783 INFO:     No hyperparam tuning for this model
2022-11-23 00:49:58,783 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:49:58,783 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:49:58,784 INFO:     None feature selector for col prot
2022-11-23 00:49:58,784 INFO:     None feature selector for col prot
2022-11-23 00:49:58,784 INFO:     None feature selector for col prot
2022-11-23 00:49:58,784 INFO:     None feature selector for col chem
2022-11-23 00:49:58,784 INFO:     None feature selector for col chem
2022-11-23 00:49:58,784 INFO:     None feature selector for col chem
2022-11-23 00:49:58,785 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:49:58,785 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:49:58,786 INFO:     Number of params in model 168571
2022-11-23 00:49:58,789 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:49:58,789 INFO:   Starting stage: TRAINING
2022-11-23 00:49:58,846 INFO:     Val loss before train {'Reaction outcome loss': 1.0519494774729707, 'Total loss': 1.0519494774729707}
2022-11-23 00:49:58,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:58,847 INFO:     Epoch: 0
2022-11-23 00:49:59,678 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8648346149644186, 'Total loss': 0.8648346149644186} | train loss {'Reaction outcome loss': 0.864177306533837, 'Total loss': 0.864177306533837}
2022-11-23 00:49:59,678 INFO:     Found new best model at epoch 0
2022-11-23 00:49:59,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:49:59,679 INFO:     Epoch: 1
2022-11-23 00:50:00,499 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8307712999887245, 'Total loss': 0.8307712999887245} | train loss {'Reaction outcome loss': 0.8351741825215152, 'Total loss': 0.8351741825215152}
2022-11-23 00:50:00,499 INFO:     Found new best model at epoch 1
2022-11-23 00:50:00,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:00,500 INFO:     Epoch: 2
2022-11-23 00:50:01,329 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8361681006675543, 'Total loss': 0.8361681006675543} | train loss {'Reaction outcome loss': 0.8265448164988737, 'Total loss': 0.8265448164988737}
2022-11-23 00:50:01,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:01,334 INFO:     Epoch: 3
2022-11-23 00:50:02,123 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.852239264998325, 'Total loss': 0.852239264998325} | train loss {'Reaction outcome loss': 0.8302246350489679, 'Total loss': 0.8302246350489679}
2022-11-23 00:50:02,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:02,124 INFO:     Epoch: 4
2022-11-23 00:50:02,892 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8523548127606858, 'Total loss': 0.8523548127606858} | train loss {'Reaction outcome loss': 0.8208554213652846, 'Total loss': 0.8208554213652846}
2022-11-23 00:50:02,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:02,893 INFO:     Epoch: 5
2022-11-23 00:50:03,696 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8458218789377878, 'Total loss': 0.8458218789377878} | train loss {'Reaction outcome loss': 0.8238889532255345, 'Total loss': 0.8238889532255345}
2022-11-23 00:50:03,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:03,697 INFO:     Epoch: 6
2022-11-23 00:50:04,484 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.831371127172958, 'Total loss': 0.831371127172958} | train loss {'Reaction outcome loss': 0.8148953142713328, 'Total loss': 0.8148953142713328}
2022-11-23 00:50:04,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:04,485 INFO:     Epoch: 7
2022-11-23 00:50:05,293 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8257355544456216, 'Total loss': 0.8257355544456216} | train loss {'Reaction outcome loss': 0.8158297715861289, 'Total loss': 0.8158297715861289}
2022-11-23 00:50:05,293 INFO:     Found new best model at epoch 7
2022-11-23 00:50:05,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:05,294 INFO:     Epoch: 8
2022-11-23 00:50:06,074 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8121965555257575, 'Total loss': 0.8121965555257575} | train loss {'Reaction outcome loss': 0.8144922708390189, 'Total loss': 0.8144922708390189}
2022-11-23 00:50:06,074 INFO:     Found new best model at epoch 8
2022-11-23 00:50:06,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:06,075 INFO:     Epoch: 9
2022-11-23 00:50:06,924 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8175339497799097, 'Total loss': 0.8175339497799097} | train loss {'Reaction outcome loss': 0.8148635456063709, 'Total loss': 0.8148635456063709}
2022-11-23 00:50:06,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:06,924 INFO:     Epoch: 10
2022-11-23 00:50:07,733 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8317938710367957, 'Total loss': 0.8317938710367957} | train loss {'Reaction outcome loss': 0.805607270266189, 'Total loss': 0.805607270266189}
2022-11-23 00:50:07,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:07,733 INFO:     Epoch: 11
2022-11-23 00:50:08,546 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8375849980254506, 'Total loss': 0.8375849980254506} | train loss {'Reaction outcome loss': 0.8129480437177127, 'Total loss': 0.8129480437177127}
2022-11-23 00:50:08,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:08,547 INFO:     Epoch: 12
2022-11-23 00:50:09,376 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8243009288643681, 'Total loss': 0.8243009288643681} | train loss {'Reaction outcome loss': 0.8075894199800296, 'Total loss': 0.8075894199800296}
2022-11-23 00:50:09,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:09,376 INFO:     Epoch: 13
2022-11-23 00:50:10,197 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8234523590220961, 'Total loss': 0.8234523590220961} | train loss {'Reaction outcome loss': 0.8095836731009796, 'Total loss': 0.8095836731009796}
2022-11-23 00:50:10,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:10,198 INFO:     Epoch: 14
2022-11-23 00:50:10,997 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8191211022609888, 'Total loss': 0.8191211022609888} | train loss {'Reaction outcome loss': 0.8073588952910705, 'Total loss': 0.8073588952910705}
2022-11-23 00:50:10,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:10,997 INFO:     Epoch: 15
2022-11-23 00:50:11,782 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8201062693152317, 'Total loss': 0.8201062693152317} | train loss {'Reaction outcome loss': 0.8055979648574454, 'Total loss': 0.8055979648574454}
2022-11-23 00:50:11,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:11,783 INFO:     Epoch: 16
2022-11-23 00:50:12,567 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8465125505314317, 'Total loss': 0.8465125505314317} | train loss {'Reaction outcome loss': 0.8073061124467459, 'Total loss': 0.8073061124467459}
2022-11-23 00:50:12,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:12,567 INFO:     Epoch: 17
2022-11-23 00:50:13,376 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.825541871924733, 'Total loss': 0.825541871924733} | train loss {'Reaction outcome loss': 0.8061784654855728, 'Total loss': 0.8061784654855728}
2022-11-23 00:50:13,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:13,376 INFO:     Epoch: 18
2022-11-23 00:50:14,193 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8140411321506944, 'Total loss': 0.8140411321506944} | train loss {'Reaction outcome loss': 0.8058372590629781, 'Total loss': 0.8058372590629781}
2022-11-23 00:50:14,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:14,194 INFO:     Epoch: 19
2022-11-23 00:50:14,988 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8398349680179773, 'Total loss': 0.8398349680179773} | train loss {'Reaction outcome loss': 0.8042200167403847, 'Total loss': 0.8042200167403847}
2022-11-23 00:50:14,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:14,988 INFO:     Epoch: 20
2022-11-23 00:50:15,770 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8278144729691882, 'Total loss': 0.8278144729691882} | train loss {'Reaction outcome loss': 0.8046037626803898, 'Total loss': 0.8046037626803898}
2022-11-23 00:50:15,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:15,772 INFO:     Epoch: 21
2022-11-23 00:50:16,538 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8167653527370718, 'Total loss': 0.8167653527370718} | train loss {'Reaction outcome loss': 0.8043641128012391, 'Total loss': 0.8043641128012391}
2022-11-23 00:50:16,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:16,539 INFO:     Epoch: 22
2022-11-23 00:50:17,370 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8562962676203528, 'Total loss': 0.8562962676203528} | train loss {'Reaction outcome loss': 0.8053569143912831, 'Total loss': 0.8053569143912831}
2022-11-23 00:50:17,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:17,370 INFO:     Epoch: 23
2022-11-23 00:50:18,195 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8237808416056078, 'Total loss': 0.8237808416056078} | train loss {'Reaction outcome loss': 0.8022720746573855, 'Total loss': 0.8022720746573855}
2022-11-23 00:50:18,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:18,195 INFO:     Epoch: 24
2022-11-23 00:50:18,983 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8088374955709591, 'Total loss': 0.8088374955709591} | train loss {'Reaction outcome loss': 0.799963549023769, 'Total loss': 0.799963549023769}
2022-11-23 00:50:18,983 INFO:     Found new best model at epoch 24
2022-11-23 00:50:18,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:18,984 INFO:     Epoch: 25
2022-11-23 00:50:19,776 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8207017654596374, 'Total loss': 0.8207017654596374} | train loss {'Reaction outcome loss': 0.8039787029389476, 'Total loss': 0.8039787029389476}
2022-11-23 00:50:19,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:19,776 INFO:     Epoch: 26
2022-11-23 00:50:20,566 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8181330783422603, 'Total loss': 0.8181330783422603} | train loss {'Reaction outcome loss': 0.7984925653846537, 'Total loss': 0.7984925653846537}
2022-11-23 00:50:20,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:20,566 INFO:     Epoch: 27
2022-11-23 00:50:21,376 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8382835623829864, 'Total loss': 0.8382835623829864} | train loss {'Reaction outcome loss': 0.7984476994539871, 'Total loss': 0.7984476994539871}
2022-11-23 00:50:21,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:21,377 INFO:     Epoch: 28
2022-11-23 00:50:22,173 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8150088523709497, 'Total loss': 0.8150088523709497} | train loss {'Reaction outcome loss': 0.8037278286990572, 'Total loss': 0.8037278286990572}
2022-11-23 00:50:22,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:22,173 INFO:     Epoch: 29
2022-11-23 00:50:22,966 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.825576105783152, 'Total loss': 0.825576105783152} | train loss {'Reaction outcome loss': 0.7985780859579805, 'Total loss': 0.7985780859579805}
2022-11-23 00:50:22,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:22,966 INFO:     Epoch: 30
2022-11-23 00:50:23,735 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8197116851806641, 'Total loss': 0.8197116851806641} | train loss {'Reaction outcome loss': 0.801444586916048, 'Total loss': 0.801444586916048}
2022-11-23 00:50:23,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:23,735 INFO:     Epoch: 31
2022-11-23 00:50:24,518 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8146254988603814, 'Total loss': 0.8146254988603814} | train loss {'Reaction outcome loss': 0.8063073255976693, 'Total loss': 0.8063073255976693}
2022-11-23 00:50:24,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:24,518 INFO:     Epoch: 32
2022-11-23 00:50:25,321 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.817507253829823, 'Total loss': 0.817507253829823} | train loss {'Reaction outcome loss': 0.8038255836142868, 'Total loss': 0.8038255836142868}
2022-11-23 00:50:25,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:25,321 INFO:     Epoch: 33
2022-11-23 00:50:26,134 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8206828971241795, 'Total loss': 0.8206828971241795} | train loss {'Reaction outcome loss': 0.802087527318079, 'Total loss': 0.802087527318079}
2022-11-23 00:50:26,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:26,135 INFO:     Epoch: 34
2022-11-23 00:50:26,951 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8087549535341041, 'Total loss': 0.8087549535341041} | train loss {'Reaction outcome loss': 0.8046358435368929, 'Total loss': 0.8046358435368929}
2022-11-23 00:50:26,953 INFO:     Found new best model at epoch 34
2022-11-23 00:50:26,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:26,954 INFO:     Epoch: 35
2022-11-23 00:50:27,753 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8139439197473748, 'Total loss': 0.8139439197473748} | train loss {'Reaction outcome loss': 0.8042893545305143, 'Total loss': 0.8042893545305143}
2022-11-23 00:50:27,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:27,754 INFO:     Epoch: 36
2022-11-23 00:50:28,575 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8200234590574752, 'Total loss': 0.8200234590574752} | train loss {'Reaction outcome loss': 0.8008037110576864, 'Total loss': 0.8008037110576864}
2022-11-23 00:50:28,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:28,575 INFO:     Epoch: 37
2022-11-23 00:50:29,375 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8163749582545702, 'Total loss': 0.8163749582545702} | train loss {'Reaction outcome loss': 0.7990537096486717, 'Total loss': 0.7990537096486717}
2022-11-23 00:50:29,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:29,375 INFO:     Epoch: 38
2022-11-23 00:50:30,164 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8161873152089674, 'Total loss': 0.8161873152089674} | train loss {'Reaction outcome loss': 0.8004491671186978, 'Total loss': 0.8004491671186978}
2022-11-23 00:50:30,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:30,165 INFO:     Epoch: 39
2022-11-23 00:50:30,920 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8202518016793007, 'Total loss': 0.8202518016793007} | train loss {'Reaction outcome loss': 0.8026310730664457, 'Total loss': 0.8026310730664457}
2022-11-23 00:50:30,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:30,920 INFO:     Epoch: 40
2022-11-23 00:50:31,719 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8455966336782589, 'Total loss': 0.8455966336782589} | train loss {'Reaction outcome loss': 0.8010586848268744, 'Total loss': 0.8010586848268744}
2022-11-23 00:50:31,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:31,719 INFO:     Epoch: 41
2022-11-23 00:50:32,474 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8296775817871094, 'Total loss': 0.8296775817871094} | train loss {'Reaction outcome loss': 0.8010824592631371, 'Total loss': 0.8010824592631371}
2022-11-23 00:50:32,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:32,476 INFO:     Epoch: 42
2022-11-23 00:50:33,244 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8145874482254649, 'Total loss': 0.8145874482254649} | train loss {'Reaction outcome loss': 0.7954621257596328, 'Total loss': 0.7954621257596328}
2022-11-23 00:50:33,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:33,244 INFO:     Epoch: 43
2022-11-23 00:50:34,006 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8182275031888208, 'Total loss': 0.8182275031888208} | train loss {'Reaction outcome loss': 0.7998136470063788, 'Total loss': 0.7998136470063788}
2022-11-23 00:50:34,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:34,006 INFO:     Epoch: 44
2022-11-23 00:50:34,770 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.816135723923528, 'Total loss': 0.816135723923528} | train loss {'Reaction outcome loss': 0.8009734692387893, 'Total loss': 0.8009734692387893}
2022-11-23 00:50:34,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:34,771 INFO:     Epoch: 45
2022-11-23 00:50:35,516 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8259135567864706, 'Total loss': 0.8259135567864706} | train loss {'Reaction outcome loss': 0.7994808499686054, 'Total loss': 0.7994808499686054}
2022-11-23 00:50:35,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:35,516 INFO:     Epoch: 46
2022-11-23 00:50:36,286 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8163096031477285, 'Total loss': 0.8163096031477285} | train loss {'Reaction outcome loss': 0.797339165430577, 'Total loss': 0.797339165430577}
2022-11-23 00:50:36,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:36,286 INFO:     Epoch: 47
2022-11-23 00:50:37,040 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8099614568921023, 'Total loss': 0.8099614568921023} | train loss {'Reaction outcome loss': 0.7985257792179702, 'Total loss': 0.7985257792179702}
2022-11-23 00:50:37,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:37,040 INFO:     Epoch: 48
2022-11-23 00:50:37,806 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8265066798343215, 'Total loss': 0.8265066798343215} | train loss {'Reaction outcome loss': 0.7973113498482548, 'Total loss': 0.7973113498482548}
2022-11-23 00:50:37,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:37,807 INFO:     Epoch: 49
2022-11-23 00:50:38,585 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8233393971310106, 'Total loss': 0.8233393971310106} | train loss {'Reaction outcome loss': 0.795608506461636, 'Total loss': 0.795608506461636}
2022-11-23 00:50:38,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:38,585 INFO:     Epoch: 50
2022-11-23 00:50:39,376 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8247698240501936, 'Total loss': 0.8247698240501936} | train loss {'Reaction outcome loss': 0.796174951141975, 'Total loss': 0.796174951141975}
2022-11-23 00:50:39,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:39,376 INFO:     Epoch: 51
2022-11-23 00:50:40,195 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8046856584937073, 'Total loss': 0.8046856584937073} | train loss {'Reaction outcome loss': 0.8004168617676516, 'Total loss': 0.8004168617676516}
2022-11-23 00:50:40,195 INFO:     Found new best model at epoch 51
2022-11-23 00:50:40,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:40,196 INFO:     Epoch: 52
2022-11-23 00:50:40,957 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8147007920021234, 'Total loss': 0.8147007920021234} | train loss {'Reaction outcome loss': 0.7985528783231485, 'Total loss': 0.7985528783231485}
2022-11-23 00:50:40,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:40,958 INFO:     Epoch: 53
2022-11-23 00:50:41,722 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8109752300173737, 'Total loss': 0.8109752300173737} | train loss {'Reaction outcome loss': 0.7980044776054679, 'Total loss': 0.7980044776054679}
2022-11-23 00:50:41,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:41,722 INFO:     Epoch: 54
2022-11-23 00:50:42,490 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8178226462630338, 'Total loss': 0.8178226462630338} | train loss {'Reaction outcome loss': 0.7992129141434294, 'Total loss': 0.7992129141434294}
2022-11-23 00:50:42,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:42,490 INFO:     Epoch: 55
2022-11-23 00:50:43,245 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8170215903326522, 'Total loss': 0.8170215903326522} | train loss {'Reaction outcome loss': 0.7940193972870951, 'Total loss': 0.7940193972870951}
2022-11-23 00:50:43,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:43,247 INFO:     Epoch: 56
2022-11-23 00:50:44,035 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8223637051360552, 'Total loss': 0.8223637051360552} | train loss {'Reaction outcome loss': 0.7967871528912763, 'Total loss': 0.7967871528912763}
2022-11-23 00:50:44,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:44,036 INFO:     Epoch: 57
2022-11-23 00:50:44,824 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8174065476240113, 'Total loss': 0.8174065476240113} | train loss {'Reaction outcome loss': 0.7998919250046621, 'Total loss': 0.7998919250046621}
2022-11-23 00:50:44,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:44,825 INFO:     Epoch: 58
2022-11-23 00:50:45,620 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8314197687215583, 'Total loss': 0.8314197687215583} | train loss {'Reaction outcome loss': 0.7978802749612293, 'Total loss': 0.7978802749612293}
2022-11-23 00:50:45,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:45,620 INFO:     Epoch: 59
2022-11-23 00:50:46,426 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8087582823842071, 'Total loss': 0.8087582823842071} | train loss {'Reaction outcome loss': 0.799767436917688, 'Total loss': 0.799767436917688}
2022-11-23 00:50:46,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:46,427 INFO:     Epoch: 60
2022-11-23 00:50:47,207 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.823553073544835, 'Total loss': 0.823553073544835} | train loss {'Reaction outcome loss': 0.7987907427500506, 'Total loss': 0.7987907427500506}
2022-11-23 00:50:47,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:47,208 INFO:     Epoch: 61
2022-11-23 00:50:48,005 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.805659223434537, 'Total loss': 0.805659223434537} | train loss {'Reaction outcome loss': 0.8007164813700269, 'Total loss': 0.8007164813700269}
2022-11-23 00:50:48,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:48,005 INFO:     Epoch: 62
2022-11-23 00:50:48,806 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8105021001294602, 'Total loss': 0.8105021001294602} | train loss {'Reaction outcome loss': 0.7976779518801658, 'Total loss': 0.7976779518801658}
2022-11-23 00:50:48,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:48,807 INFO:     Epoch: 63
2022-11-23 00:50:49,595 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8067993189013282, 'Total loss': 0.8067993189013282} | train loss {'Reaction outcome loss': 0.8018997634043459, 'Total loss': 0.8018997634043459}
2022-11-23 00:50:49,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:49,596 INFO:     Epoch: 64
2022-11-23 00:50:50,372 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8045796821283739, 'Total loss': 0.8045796821283739} | train loss {'Reaction outcome loss': 0.7973283412026577, 'Total loss': 0.7973283412026577}
2022-11-23 00:50:50,373 INFO:     Found new best model at epoch 64
2022-11-23 00:50:50,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:50,374 INFO:     Epoch: 65
2022-11-23 00:50:51,148 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8329530600891557, 'Total loss': 0.8329530600891557} | train loss {'Reaction outcome loss': 0.7947118024601311, 'Total loss': 0.7947118024601311}
2022-11-23 00:50:51,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:51,148 INFO:     Epoch: 66
2022-11-23 00:50:51,950 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8209393149198487, 'Total loss': 0.8209393149198487} | train loss {'Reaction outcome loss': 0.7960374559291074, 'Total loss': 0.7960374559291074}
2022-11-23 00:50:51,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:51,950 INFO:     Epoch: 67
2022-11-23 00:50:52,767 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.820214077483776, 'Total loss': 0.820214077483776} | train loss {'Reaction outcome loss': 0.7981960543843566, 'Total loss': 0.7981960543843566}
2022-11-23 00:50:52,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:52,768 INFO:     Epoch: 68
2022-11-23 00:50:53,577 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8189205056013062, 'Total loss': 0.8189205056013062} | train loss {'Reaction outcome loss': 0.7970901422324728, 'Total loss': 0.7970901422324728}
2022-11-23 00:50:53,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:53,577 INFO:     Epoch: 69
2022-11-23 00:50:54,344 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8291164227696353, 'Total loss': 0.8291164227696353} | train loss {'Reaction outcome loss': 0.7992002815008163, 'Total loss': 0.7992002815008163}
2022-11-23 00:50:54,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:54,346 INFO:     Epoch: 70
2022-11-23 00:50:55,150 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8202122643936512, 'Total loss': 0.8202122643936512} | train loss {'Reaction outcome loss': 0.7938180304453021, 'Total loss': 0.7938180304453021}
2022-11-23 00:50:55,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:55,150 INFO:     Epoch: 71
2022-11-23 00:50:55,923 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8105469415354174, 'Total loss': 0.8105469415354174} | train loss {'Reaction outcome loss': 0.7979914101420856, 'Total loss': 0.7979914101420856}
2022-11-23 00:50:55,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:55,923 INFO:     Epoch: 72
2022-11-23 00:50:56,716 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8079963735369748, 'Total loss': 0.8079963735369748} | train loss {'Reaction outcome loss': 0.7965886399272035, 'Total loss': 0.7965886399272035}
2022-11-23 00:50:56,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:56,717 INFO:     Epoch: 73
2022-11-23 00:50:57,517 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8336435459380926, 'Total loss': 0.8336435459380926} | train loss {'Reaction outcome loss': 0.7914166082857085, 'Total loss': 0.7914166082857085}
2022-11-23 00:50:57,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:57,517 INFO:     Epoch: 74
2022-11-23 00:50:58,305 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8085091765536818, 'Total loss': 0.8085091765536818} | train loss {'Reaction outcome loss': 0.7942468296797549, 'Total loss': 0.7942468296797549}
2022-11-23 00:50:58,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:58,305 INFO:     Epoch: 75
2022-11-23 00:50:59,088 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8267094243404477, 'Total loss': 0.8267094243404477} | train loss {'Reaction outcome loss': 0.7981461574796771, 'Total loss': 0.7981461574796771}
2022-11-23 00:50:59,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:59,088 INFO:     Epoch: 76
2022-11-23 00:50:59,934 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8270754481470862, 'Total loss': 0.8270754481470862} | train loss {'Reaction outcome loss': 0.79878625175992, 'Total loss': 0.79878625175992}
2022-11-23 00:50:59,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:50:59,935 INFO:     Epoch: 77
2022-11-23 00:51:00,825 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8168517794719962, 'Total loss': 0.8168517794719962} | train loss {'Reaction outcome loss': 0.7947314209381088, 'Total loss': 0.7947314209381088}
2022-11-23 00:51:00,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:00,826 INFO:     Epoch: 78
2022-11-23 00:51:01,667 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8111363801845285, 'Total loss': 0.8111363801845285} | train loss {'Reaction outcome loss': 0.795239824374191, 'Total loss': 0.795239824374191}
2022-11-23 00:51:01,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:01,668 INFO:     Epoch: 79
2022-11-23 00:51:02,568 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.813623788051827, 'Total loss': 0.813623788051827} | train loss {'Reaction outcome loss': 0.7976635055708103, 'Total loss': 0.7976635055708103}
2022-11-23 00:51:02,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:02,568 INFO:     Epoch: 80
2022-11-23 00:51:03,443 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.832853052505227, 'Total loss': 0.832853052505227} | train loss {'Reaction outcome loss': 0.7999773498197071, 'Total loss': 0.7999773498197071}
2022-11-23 00:51:03,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:03,443 INFO:     Epoch: 81
2022-11-23 00:51:04,327 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.807442658169325, 'Total loss': 0.807442658169325} | train loss {'Reaction outcome loss': 0.7948633742625596, 'Total loss': 0.7948633742625596}
2022-11-23 00:51:04,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:04,327 INFO:     Epoch: 82
2022-11-23 00:51:05,130 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8079391717910767, 'Total loss': 0.8079391717910767} | train loss {'Reaction outcome loss': 0.793735322527221, 'Total loss': 0.793735322527221}
2022-11-23 00:51:05,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:05,131 INFO:     Epoch: 83
2022-11-23 00:51:05,966 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8375873038935107, 'Total loss': 0.8375873038935107} | train loss {'Reaction outcome loss': 0.7995213862569606, 'Total loss': 0.7995213862569606}
2022-11-23 00:51:05,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:05,967 INFO:     Epoch: 84
2022-11-23 00:51:06,734 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.810992757248324, 'Total loss': 0.810992757248324} | train loss {'Reaction outcome loss': 0.7936769837483031, 'Total loss': 0.7936769837483031}
2022-11-23 00:51:06,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:06,734 INFO:     Epoch: 85
2022-11-23 00:51:07,521 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8023806831171346, 'Total loss': 0.8023806831171346} | train loss {'Reaction outcome loss': 0.7968621186789919, 'Total loss': 0.7968621186789919}
2022-11-23 00:51:07,521 INFO:     Found new best model at epoch 85
2022-11-23 00:51:07,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:07,522 INFO:     Epoch: 86
2022-11-23 00:51:08,334 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8505742161772972, 'Total loss': 0.8505742161772972} | train loss {'Reaction outcome loss': 0.7993790291127612, 'Total loss': 0.7993790291127612}
2022-11-23 00:51:08,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:08,335 INFO:     Epoch: 87
2022-11-23 00:51:09,138 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8053377284560093, 'Total loss': 0.8053377284560093} | train loss {'Reaction outcome loss': 0.7998827667754205, 'Total loss': 0.7998827667754205}
2022-11-23 00:51:09,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:09,139 INFO:     Epoch: 88
2022-11-23 00:51:09,921 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.80685835938121, 'Total loss': 0.80685835938121} | train loss {'Reaction outcome loss': 0.7950404818917884, 'Total loss': 0.7950404818917884}
2022-11-23 00:51:09,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:09,922 INFO:     Epoch: 89
2022-11-23 00:51:10,730 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8153946358104085, 'Total loss': 0.8153946358104085} | train loss {'Reaction outcome loss': 0.8002497135493599, 'Total loss': 0.8002497135493599}
2022-11-23 00:51:10,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:10,731 INFO:     Epoch: 90
2022-11-23 00:51:11,520 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8097900606172029, 'Total loss': 0.8097900606172029} | train loss {'Reaction outcome loss': 0.7938878944174188, 'Total loss': 0.7938878944174188}
2022-11-23 00:51:11,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:11,521 INFO:     Epoch: 91
2022-11-23 00:51:12,280 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8287561092265817, 'Total loss': 0.8287561092265817} | train loss {'Reaction outcome loss': 0.797597977470179, 'Total loss': 0.797597977470179}
2022-11-23 00:51:12,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:12,280 INFO:     Epoch: 92
2022-11-23 00:51:13,073 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8176182258960812, 'Total loss': 0.8176182258960812} | train loss {'Reaction outcome loss': 0.7901696074204366, 'Total loss': 0.7901696074204366}
2022-11-23 00:51:13,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:13,073 INFO:     Epoch: 93
2022-11-23 00:51:13,884 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8406458247539609, 'Total loss': 0.8406458247539609} | train loss {'Reaction outcome loss': 0.800909408780395, 'Total loss': 0.800909408780395}
2022-11-23 00:51:13,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:13,885 INFO:     Epoch: 94
2022-11-23 00:51:14,686 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8290520760902139, 'Total loss': 0.8290520760902139} | train loss {'Reaction outcome loss': 0.7981530714963303, 'Total loss': 0.7981530714963303}
2022-11-23 00:51:14,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:14,687 INFO:     Epoch: 95
2022-11-23 00:51:15,523 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8424142231774885, 'Total loss': 0.8424142231774885} | train loss {'Reaction outcome loss': 0.7978060754840491, 'Total loss': 0.7978060754840491}
2022-11-23 00:51:15,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:15,523 INFO:     Epoch: 96
2022-11-23 00:51:16,345 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.808519974697468, 'Total loss': 0.808519974697468} | train loss {'Reaction outcome loss': 0.7933073365053193, 'Total loss': 0.7933073365053193}
2022-11-23 00:51:16,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:16,345 INFO:     Epoch: 97
2022-11-23 00:51:17,160 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8119849936906681, 'Total loss': 0.8119849936906681} | train loss {'Reaction outcome loss': 0.7958237410324519, 'Total loss': 0.7958237410324519}
2022-11-23 00:51:17,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:17,162 INFO:     Epoch: 98
2022-11-23 00:51:17,971 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8029222315134004, 'Total loss': 0.8029222315134004} | train loss {'Reaction outcome loss': 0.7987234786641403, 'Total loss': 0.7987234786641403}
2022-11-23 00:51:17,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:17,972 INFO:     Epoch: 99
2022-11-23 00:51:18,782 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8079765078633331, 'Total loss': 0.8079765078633331} | train loss {'Reaction outcome loss': 0.7980104976745902, 'Total loss': 0.7980104976745902}
2022-11-23 00:51:18,782 INFO:     Best model found after epoch 86 of 100.
2022-11-23 00:51:18,782 INFO:   Done with stage: TRAINING
2022-11-23 00:51:18,782 INFO:   Starting stage: EVALUATION
2022-11-23 00:51:18,917 INFO:   Done with stage: EVALUATION
2022-11-23 00:51:18,917 INFO:   Leaving out SEQ value Fold_3
2022-11-23 00:51:18,931 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-23 00:51:18,931 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:51:19,594 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:51:19,594 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:51:19,667 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:51:19,667 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:51:19,667 INFO:     No hyperparam tuning for this model
2022-11-23 00:51:19,667 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:51:19,667 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:51:19,668 INFO:     None feature selector for col prot
2022-11-23 00:51:19,668 INFO:     None feature selector for col prot
2022-11-23 00:51:19,668 INFO:     None feature selector for col prot
2022-11-23 00:51:19,669 INFO:     None feature selector for col chem
2022-11-23 00:51:19,669 INFO:     None feature selector for col chem
2022-11-23 00:51:19,669 INFO:     None feature selector for col chem
2022-11-23 00:51:19,669 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:51:19,669 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:51:19,671 INFO:     Number of params in model 168571
2022-11-23 00:51:19,674 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:51:19,674 INFO:   Starting stage: TRAINING
2022-11-23 00:51:19,731 INFO:     Val loss before train {'Reaction outcome loss': 0.9857692071659998, 'Total loss': 0.9857692071659998}
2022-11-23 00:51:19,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:19,732 INFO:     Epoch: 0
2022-11-23 00:51:20,565 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8967614038424059, 'Total loss': 0.8967614038424059} | train loss {'Reaction outcome loss': 0.8905913738571868, 'Total loss': 0.8905913738571868}
2022-11-23 00:51:20,565 INFO:     Found new best model at epoch 0
2022-11-23 00:51:20,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:20,566 INFO:     Epoch: 1
2022-11-23 00:51:21,385 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8310397267341614, 'Total loss': 0.8310397267341614} | train loss {'Reaction outcome loss': 0.8561296844968991, 'Total loss': 0.8561296844968991}
2022-11-23 00:51:21,385 INFO:     Found new best model at epoch 1
2022-11-23 00:51:21,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:21,386 INFO:     Epoch: 2
2022-11-23 00:51:22,199 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8567659868435427, 'Total loss': 0.8567659868435427} | train loss {'Reaction outcome loss': 0.852876553000236, 'Total loss': 0.852876553000236}
2022-11-23 00:51:22,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:22,201 INFO:     Epoch: 3
2022-11-23 00:51:22,987 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8459809097376737, 'Total loss': 0.8459809097376737} | train loss {'Reaction outcome loss': 0.843386487936487, 'Total loss': 0.843386487936487}
2022-11-23 00:51:22,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:22,987 INFO:     Epoch: 4
2022-11-23 00:51:23,800 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8194941343231634, 'Total loss': 0.8194941343231634} | train loss {'Reaction outcome loss': 0.8404107756760656, 'Total loss': 0.8404107756760656}
2022-11-23 00:51:23,800 INFO:     Found new best model at epoch 4
2022-11-23 00:51:23,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:23,801 INFO:     Epoch: 5
2022-11-23 00:51:24,600 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8389283452521671, 'Total loss': 0.8389283452521671} | train loss {'Reaction outcome loss': 0.8338859999666408, 'Total loss': 0.8338859999666408}
2022-11-23 00:51:24,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:24,600 INFO:     Epoch: 6
2022-11-23 00:51:25,399 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8280918110500682, 'Total loss': 0.8280918110500682} | train loss {'Reaction outcome loss': 0.8329456396248875, 'Total loss': 0.8329456396248875}
2022-11-23 00:51:25,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:25,399 INFO:     Epoch: 7
2022-11-23 00:51:26,164 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8121872286904942, 'Total loss': 0.8121872286904942} | train loss {'Reaction outcome loss': 0.8255340636992942, 'Total loss': 0.8255340636992942}
2022-11-23 00:51:26,164 INFO:     Found new best model at epoch 7
2022-11-23 00:51:26,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:26,165 INFO:     Epoch: 8
2022-11-23 00:51:26,984 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8205637085166845, 'Total loss': 0.8205637085166845} | train loss {'Reaction outcome loss': 0.8243088030085272, 'Total loss': 0.8243088030085272}
2022-11-23 00:51:26,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:26,984 INFO:     Epoch: 9
2022-11-23 00:51:27,760 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8213982771743428, 'Total loss': 0.8213982771743428} | train loss {'Reaction outcome loss': 0.8242087972407438, 'Total loss': 0.8242087972407438}
2022-11-23 00:51:27,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:27,762 INFO:     Epoch: 10
2022-11-23 00:51:28,520 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8236112188209187, 'Total loss': 0.8236112188209187} | train loss {'Reaction outcome loss': 0.8225501825614852, 'Total loss': 0.8225501825614852}
2022-11-23 00:51:28,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:28,521 INFO:     Epoch: 11
2022-11-23 00:51:29,373 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8118446130644191, 'Total loss': 0.8118446130644191} | train loss {'Reaction outcome loss': 0.8244508545009457, 'Total loss': 0.8244508545009457}
2022-11-23 00:51:29,373 INFO:     Found new best model at epoch 11
2022-11-23 00:51:29,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:29,374 INFO:     Epoch: 12
2022-11-23 00:51:30,165 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.810971041971987, 'Total loss': 0.810971041971987} | train loss {'Reaction outcome loss': 0.820480002067527, 'Total loss': 0.820480002067527}
2022-11-23 00:51:30,165 INFO:     Found new best model at epoch 12
2022-11-23 00:51:30,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:30,166 INFO:     Epoch: 13
2022-11-23 00:51:30,953 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8285437849434939, 'Total loss': 0.8285437849434939} | train loss {'Reaction outcome loss': 0.8199968494931046, 'Total loss': 0.8199968494931046}
2022-11-23 00:51:30,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:30,953 INFO:     Epoch: 14
2022-11-23 00:51:31,720 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.82061160559004, 'Total loss': 0.82061160559004} | train loss {'Reaction outcome loss': 0.8218632337998371, 'Total loss': 0.8218632337998371}
2022-11-23 00:51:31,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:31,721 INFO:     Epoch: 15
2022-11-23 00:51:32,536 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8221818235787478, 'Total loss': 0.8221818235787478} | train loss {'Reaction outcome loss': 0.8158926533193004, 'Total loss': 0.8158926533193004}
2022-11-23 00:51:32,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:32,537 INFO:     Epoch: 16
2022-11-23 00:51:33,352 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.819632578979839, 'Total loss': 0.819632578979839} | train loss {'Reaction outcome loss': 0.8154160840170724, 'Total loss': 0.8154160840170724}
2022-11-23 00:51:33,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:33,353 INFO:     Epoch: 17
2022-11-23 00:51:34,148 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8317222906784578, 'Total loss': 0.8317222906784578} | train loss {'Reaction outcome loss': 0.8140415735390721, 'Total loss': 0.8140415735390721}
2022-11-23 00:51:34,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:34,149 INFO:     Epoch: 18
2022-11-23 00:51:34,947 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8033961010250178, 'Total loss': 0.8033961010250178} | train loss {'Reaction outcome loss': 0.8146525992422687, 'Total loss': 0.8146525992422687}
2022-11-23 00:51:34,947 INFO:     Found new best model at epoch 18
2022-11-23 00:51:34,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:34,948 INFO:     Epoch: 19
2022-11-23 00:51:35,777 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8153370910070159, 'Total loss': 0.8153370910070159} | train loss {'Reaction outcome loss': 0.8147022784972677, 'Total loss': 0.8147022784972677}
2022-11-23 00:51:35,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:35,778 INFO:     Epoch: 20
2022-11-23 00:51:36,566 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8080479272387244, 'Total loss': 0.8080479272387244} | train loss {'Reaction outcome loss': 0.8097328334438557, 'Total loss': 0.8097328334438557}
2022-11-23 00:51:36,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:36,566 INFO:     Epoch: 21
2022-11-23 00:51:37,332 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7987650294195522, 'Total loss': 0.7987650294195522} | train loss {'Reaction outcome loss': 0.8111182311359717, 'Total loss': 0.8111182311359717}
2022-11-23 00:51:37,333 INFO:     Found new best model at epoch 21
2022-11-23 00:51:37,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:37,334 INFO:     Epoch: 22
2022-11-23 00:51:38,110 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8192168684168295, 'Total loss': 0.8192168684168295} | train loss {'Reaction outcome loss': 0.8152759482665938, 'Total loss': 0.8152759482665938}
2022-11-23 00:51:38,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:38,110 INFO:     Epoch: 23
2022-11-23 00:51:38,883 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8101320706985213, 'Total loss': 0.8101320706985213} | train loss {'Reaction outcome loss': 0.8097110436887157, 'Total loss': 0.8097110436887157}
2022-11-23 00:51:38,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:38,884 INFO:     Epoch: 24
2022-11-23 00:51:39,671 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8013204058462923, 'Total loss': 0.8013204058462923} | train loss {'Reaction outcome loss': 0.8125005528634909, 'Total loss': 0.8125005528634909}
2022-11-23 00:51:39,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:39,672 INFO:     Epoch: 25
2022-11-23 00:51:40,428 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8105827569961548, 'Total loss': 0.8105827569961548} | train loss {'Reaction outcome loss': 0.8101272058730222, 'Total loss': 0.8101272058730222}
2022-11-23 00:51:40,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:40,428 INFO:     Epoch: 26
2022-11-23 00:51:41,217 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8168266544287855, 'Total loss': 0.8168266544287855} | train loss {'Reaction outcome loss': 0.8159374988808924, 'Total loss': 0.8159374988808924}
2022-11-23 00:51:41,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:41,218 INFO:     Epoch: 27
2022-11-23 00:51:42,015 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8221376646648754, 'Total loss': 0.8221376646648754} | train loss {'Reaction outcome loss': 0.8070781312426742, 'Total loss': 0.8070781312426742}
2022-11-23 00:51:42,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:42,015 INFO:     Epoch: 28
2022-11-23 00:51:42,844 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7999352152374658, 'Total loss': 0.7999352152374658} | train loss {'Reaction outcome loss': 0.8072180395223656, 'Total loss': 0.8072180395223656}
2022-11-23 00:51:42,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:42,844 INFO:     Epoch: 29
2022-11-23 00:51:43,613 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.798666471784765, 'Total loss': 0.798666471784765} | train loss {'Reaction outcome loss': 0.8023235574060557, 'Total loss': 0.8023235574060557}
2022-11-23 00:51:43,613 INFO:     Found new best model at epoch 29
2022-11-23 00:51:43,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:43,614 INFO:     Epoch: 30
2022-11-23 00:51:44,378 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8288716186176647, 'Total loss': 0.8288716186176647} | train loss {'Reaction outcome loss': 0.8045540168577311, 'Total loss': 0.8045540168577311}
2022-11-23 00:51:44,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:44,379 INFO:     Epoch: 31
2022-11-23 00:51:45,201 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7812258526682854, 'Total loss': 0.7812258526682854} | train loss {'Reaction outcome loss': 0.8073114510701627, 'Total loss': 0.8073114510701627}
2022-11-23 00:51:45,201 INFO:     Found new best model at epoch 31
2022-11-23 00:51:45,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:45,202 INFO:     Epoch: 32
2022-11-23 00:51:45,995 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8169639977541837, 'Total loss': 0.8169639977541837} | train loss {'Reaction outcome loss': 0.8029712110149617, 'Total loss': 0.8029712110149617}
2022-11-23 00:51:45,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:45,996 INFO:     Epoch: 33
2022-11-23 00:51:46,767 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7929855307394807, 'Total loss': 0.7929855307394807} | train loss {'Reaction outcome loss': 0.8021707469103287, 'Total loss': 0.8021707469103287}
2022-11-23 00:51:46,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:46,768 INFO:     Epoch: 34
2022-11-23 00:51:47,626 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8213277371092276, 'Total loss': 0.8213277371092276} | train loss {'Reaction outcome loss': 0.7992467194187398, 'Total loss': 0.7992467194187398}
2022-11-23 00:51:47,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:47,626 INFO:     Epoch: 35
2022-11-23 00:51:48,453 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8074400343678214, 'Total loss': 0.8074400343678214} | train loss {'Reaction outcome loss': 0.7972700166458986, 'Total loss': 0.7972700166458986}
2022-11-23 00:51:48,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:48,453 INFO:     Epoch: 36
2022-11-23 00:51:49,222 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8170013001019304, 'Total loss': 0.8170013001019304} | train loss {'Reaction outcome loss': 0.8000186139223527, 'Total loss': 0.8000186139223527}
2022-11-23 00:51:49,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:49,223 INFO:     Epoch: 37
2022-11-23 00:51:50,049 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8008102767846801, 'Total loss': 0.8008102767846801} | train loss {'Reaction outcome loss': 0.8014795051545512, 'Total loss': 0.8014795051545512}
2022-11-23 00:51:50,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:50,049 INFO:     Epoch: 38
2022-11-23 00:51:50,827 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.804361102255908, 'Total loss': 0.804361102255908} | train loss {'Reaction outcome loss': 0.7980292166982378, 'Total loss': 0.7980292166982378}
2022-11-23 00:51:50,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:50,827 INFO:     Epoch: 39
2022-11-23 00:51:51,648 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8000496923923492, 'Total loss': 0.8000496923923492} | train loss {'Reaction outcome loss': 0.7980422620870629, 'Total loss': 0.7980422620870629}
2022-11-23 00:51:51,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:51,648 INFO:     Epoch: 40
2022-11-23 00:51:52,487 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8112900067459453, 'Total loss': 0.8112900067459453} | train loss {'Reaction outcome loss': 0.7912641110468884, 'Total loss': 0.7912641110468884}
2022-11-23 00:51:52,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:52,488 INFO:     Epoch: 41
2022-11-23 00:51:53,277 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7754468030550263, 'Total loss': 0.7754468030550263} | train loss {'Reaction outcome loss': 0.8000166733654178, 'Total loss': 0.8000166733654178}
2022-11-23 00:51:53,277 INFO:     Found new best model at epoch 41
2022-11-23 00:51:53,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:53,278 INFO:     Epoch: 42
2022-11-23 00:51:54,096 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7828910195014693, 'Total loss': 0.7828910195014693} | train loss {'Reaction outcome loss': 0.7976957520660088, 'Total loss': 0.7976957520660088}
2022-11-23 00:51:54,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:54,096 INFO:     Epoch: 43
2022-11-23 00:51:54,908 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8022398054599762, 'Total loss': 0.8022398054599762} | train loss {'Reaction outcome loss': 0.7907828674024465, 'Total loss': 0.7907828674024465}
2022-11-23 00:51:54,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:54,908 INFO:     Epoch: 44
2022-11-23 00:51:55,754 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7973900105465542, 'Total loss': 0.7973900105465542} | train loss {'Reaction outcome loss': 0.7896171249905412, 'Total loss': 0.7896171249905412}
2022-11-23 00:51:55,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:55,754 INFO:     Epoch: 45
2022-11-23 00:51:56,608 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7812057042663748, 'Total loss': 0.7812057042663748} | train loss {'Reaction outcome loss': 0.7931709046266517, 'Total loss': 0.7931709046266517}
2022-11-23 00:51:56,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:56,609 INFO:     Epoch: 46
2022-11-23 00:51:57,443 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7906448963013563, 'Total loss': 0.7906448963013563} | train loss {'Reaction outcome loss': 0.7907677767228107, 'Total loss': 0.7907677767228107}
2022-11-23 00:51:57,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:57,443 INFO:     Epoch: 47
2022-11-23 00:51:58,304 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7655913484367457, 'Total loss': 0.7655913484367457} | train loss {'Reaction outcome loss': 0.7903028665756693, 'Total loss': 0.7903028665756693}
2022-11-23 00:51:58,304 INFO:     Found new best model at epoch 47
2022-11-23 00:51:58,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:58,305 INFO:     Epoch: 48
2022-11-23 00:51:59,132 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7927352718331597, 'Total loss': 0.7927352718331597} | train loss {'Reaction outcome loss': 0.7876905667538545, 'Total loss': 0.7876905667538545}
2022-11-23 00:51:59,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:51:59,132 INFO:     Epoch: 49
2022-11-23 00:52:00,037 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7973577928814021, 'Total loss': 0.7973577928814021} | train loss {'Reaction outcome loss': 0.7829680649601684, 'Total loss': 0.7829680649601684}
2022-11-23 00:52:00,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:00,038 INFO:     Epoch: 50
2022-11-23 00:52:00,900 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8055609640750018, 'Total loss': 0.8055609640750018} | train loss {'Reaction outcome loss': 0.7820770310504096, 'Total loss': 0.7820770310504096}
2022-11-23 00:52:00,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:00,900 INFO:     Epoch: 51
2022-11-23 00:52:01,781 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8071053976362402, 'Total loss': 0.8071053976362402} | train loss {'Reaction outcome loss': 0.7818058378842412, 'Total loss': 0.7818058378842412}
2022-11-23 00:52:01,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:01,781 INFO:     Epoch: 52
2022-11-23 00:52:02,668 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8145983124321158, 'Total loss': 0.8145983124321158} | train loss {'Reaction outcome loss': 0.7786780708906602, 'Total loss': 0.7786780708906602}
2022-11-23 00:52:02,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:02,669 INFO:     Epoch: 53
2022-11-23 00:52:03,546 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8156725791367617, 'Total loss': 0.8156725791367617} | train loss {'Reaction outcome loss': 0.7757001938868542, 'Total loss': 0.7757001938868542}
2022-11-23 00:52:03,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:03,547 INFO:     Epoch: 54
2022-11-23 00:52:04,483 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.767659492790699, 'Total loss': 0.767659492790699} | train loss {'Reaction outcome loss': 0.7728465823494658, 'Total loss': 0.7728465823494658}
2022-11-23 00:52:04,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:04,485 INFO:     Epoch: 55
2022-11-23 00:52:05,383 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7840050702745264, 'Total loss': 0.7840050702745264} | train loss {'Reaction outcome loss': 0.7787231135125063, 'Total loss': 0.7787231135125063}
2022-11-23 00:52:05,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:05,384 INFO:     Epoch: 56
2022-11-23 00:52:06,296 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.800843015990474, 'Total loss': 0.800843015990474} | train loss {'Reaction outcome loss': 0.7653112302021104, 'Total loss': 0.7653112302021104}
2022-11-23 00:52:06,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:06,296 INFO:     Epoch: 57
2022-11-23 00:52:07,218 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7862672744826837, 'Total loss': 0.7862672744826837} | train loss {'Reaction outcome loss': 0.7784932995329098, 'Total loss': 0.7784932995329098}
2022-11-23 00:52:07,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:07,219 INFO:     Epoch: 58
2022-11-23 00:52:08,120 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7715934772383083, 'Total loss': 0.7715934772383083} | train loss {'Reaction outcome loss': 0.7650083405630929, 'Total loss': 0.7650083405630929}
2022-11-23 00:52:08,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:08,120 INFO:     Epoch: 59
2022-11-23 00:52:09,004 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7802376543933695, 'Total loss': 0.7802376543933695} | train loss {'Reaction outcome loss': 0.7552361717029493, 'Total loss': 0.7552361717029493}
2022-11-23 00:52:09,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:09,004 INFO:     Epoch: 60
2022-11-23 00:52:09,956 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7492755685340274, 'Total loss': 0.7492755685340274} | train loss {'Reaction outcome loss': 0.7518808423256388, 'Total loss': 0.7518808423256388}
2022-11-23 00:52:09,956 INFO:     Found new best model at epoch 60
2022-11-23 00:52:09,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:09,957 INFO:     Epoch: 61
2022-11-23 00:52:10,824 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7708566276864572, 'Total loss': 0.7708566276864572} | train loss {'Reaction outcome loss': 0.7579496551533135, 'Total loss': 0.7579496551533135}
2022-11-23 00:52:10,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:10,825 INFO:     Epoch: 62
2022-11-23 00:52:11,702 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7397325066002932, 'Total loss': 0.7397325066002932} | train loss {'Reaction outcome loss': 0.7541921639929012, 'Total loss': 0.7541921639929012}
2022-11-23 00:52:11,702 INFO:     Found new best model at epoch 62
2022-11-23 00:52:11,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:11,703 INFO:     Epoch: 63
2022-11-23 00:52:12,513 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7550454525785013, 'Total loss': 0.7550454525785013} | train loss {'Reaction outcome loss': 0.7453673438150056, 'Total loss': 0.7453673438150056}
2022-11-23 00:52:12,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:12,513 INFO:     Epoch: 64
2022-11-23 00:52:13,370 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7286307256330143, 'Total loss': 0.7286307256330143} | train loss {'Reaction outcome loss': 0.7430077363033684, 'Total loss': 0.7430077363033684}
2022-11-23 00:52:13,370 INFO:     Found new best model at epoch 64
2022-11-23 00:52:13,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:13,371 INFO:     Epoch: 65
2022-11-23 00:52:14,243 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7304941429333254, 'Total loss': 0.7304941429333254} | train loss {'Reaction outcome loss': 0.7297544335832401, 'Total loss': 0.7297544335832401}
2022-11-23 00:52:14,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:14,244 INFO:     Epoch: 66
2022-11-23 00:52:15,135 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7112250118093058, 'Total loss': 0.7112250118093058} | train loss {'Reaction outcome loss': 0.7293130782185768, 'Total loss': 0.7293130782185768}
2022-11-23 00:52:15,135 INFO:     Found new best model at epoch 66
2022-11-23 00:52:15,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:15,137 INFO:     Epoch: 67
2022-11-23 00:52:16,040 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7058650261976502, 'Total loss': 0.7058650261976502} | train loss {'Reaction outcome loss': 0.7137891815633189, 'Total loss': 0.7137891815633189}
2022-11-23 00:52:16,040 INFO:     Found new best model at epoch 67
2022-11-23 00:52:16,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:16,041 INFO:     Epoch: 68
2022-11-23 00:52:16,928 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7363726415417411, 'Total loss': 0.7363726415417411} | train loss {'Reaction outcome loss': 0.7022511856896537, 'Total loss': 0.7022511856896537}
2022-11-23 00:52:16,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:16,929 INFO:     Epoch: 69
2022-11-23 00:52:17,811 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7367366599765691, 'Total loss': 0.7367366599765691} | train loss {'Reaction outcome loss': 0.6988977013802041, 'Total loss': 0.6988977013802041}
2022-11-23 00:52:17,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:17,811 INFO:     Epoch: 70
2022-11-23 00:52:18,717 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.6964150281115011, 'Total loss': 0.6964150281115011} | train loss {'Reaction outcome loss': 0.6827830163799986, 'Total loss': 0.6827830163799986}
2022-11-23 00:52:18,717 INFO:     Found new best model at epoch 70
2022-11-23 00:52:18,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:18,718 INFO:     Epoch: 71
2022-11-23 00:52:19,600 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.6717422597787597, 'Total loss': 0.6717422597787597} | train loss {'Reaction outcome loss': 0.6562485898027615, 'Total loss': 0.6562485898027615}
2022-11-23 00:52:19,600 INFO:     Found new best model at epoch 71
2022-11-23 00:52:19,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:19,601 INFO:     Epoch: 72
2022-11-23 00:52:20,459 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.6400327594442801, 'Total loss': 0.6400327594442801} | train loss {'Reaction outcome loss': 0.6565783217245219, 'Total loss': 0.6565783217245219}
2022-11-23 00:52:20,460 INFO:     Found new best model at epoch 72
2022-11-23 00:52:20,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:20,461 INFO:     Epoch: 73
2022-11-23 00:52:21,392 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.6105573441494595, 'Total loss': 0.6105573441494595} | train loss {'Reaction outcome loss': 0.6310795593018435, 'Total loss': 0.6310795593018435}
2022-11-23 00:52:21,392 INFO:     Found new best model at epoch 73
2022-11-23 00:52:21,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:21,393 INFO:     Epoch: 74
2022-11-23 00:52:22,252 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.6161381480368701, 'Total loss': 0.6161381480368701} | train loss {'Reaction outcome loss': 0.6229702687385131, 'Total loss': 0.6229702687385131}
2022-11-23 00:52:22,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:22,252 INFO:     Epoch: 75
2022-11-23 00:52:23,136 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.6095452843741938, 'Total loss': 0.6095452843741938} | train loss {'Reaction outcome loss': 0.6114084002922993, 'Total loss': 0.6114084002922993}
2022-11-23 00:52:23,137 INFO:     Found new best model at epoch 75
2022-11-23 00:52:23,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:23,138 INFO:     Epoch: 76
2022-11-23 00:52:24,019 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.6345029933886095, 'Total loss': 0.6345029933886095} | train loss {'Reaction outcome loss': 0.6122984453123443, 'Total loss': 0.6122984453123443}
2022-11-23 00:52:24,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:24,019 INFO:     Epoch: 77
2022-11-23 00:52:24,893 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5846873093396425, 'Total loss': 0.5846873093396425} | train loss {'Reaction outcome loss': 0.598530908750028, 'Total loss': 0.598530908750028}
2022-11-23 00:52:24,894 INFO:     Found new best model at epoch 77
2022-11-23 00:52:24,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:24,894 INFO:     Epoch: 78
2022-11-23 00:52:25,748 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.602338431911035, 'Total loss': 0.602338431911035} | train loss {'Reaction outcome loss': 0.5921465846956993, 'Total loss': 0.5921465846956993}
2022-11-23 00:52:25,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:25,749 INFO:     Epoch: 79
2022-11-23 00:52:26,559 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5931012081828985, 'Total loss': 0.5931012081828985} | train loss {'Reaction outcome loss': 0.59366069247528, 'Total loss': 0.59366069247528}
2022-11-23 00:52:26,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:26,560 INFO:     Epoch: 80
2022-11-23 00:52:27,383 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.6003562584519386, 'Total loss': 0.6003562584519386} | train loss {'Reaction outcome loss': 0.5756945419068239, 'Total loss': 0.5756945419068239}
2022-11-23 00:52:27,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:27,383 INFO:     Epoch: 81
2022-11-23 00:52:28,253 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5970654985444113, 'Total loss': 0.5970654985444113} | train loss {'Reaction outcome loss': 0.5914670359115212, 'Total loss': 0.5914670359115212}
2022-11-23 00:52:28,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:28,253 INFO:     Epoch: 82
2022-11-23 00:52:29,106 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.548566762696613, 'Total loss': 0.548566762696613} | train loss {'Reaction outcome loss': 0.5980002786431994, 'Total loss': 0.5980002786431994}
2022-11-23 00:52:29,106 INFO:     Found new best model at epoch 82
2022-11-23 00:52:29,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:29,107 INFO:     Epoch: 83
2022-11-23 00:52:29,973 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5957517623901367, 'Total loss': 0.5957517623901367} | train loss {'Reaction outcome loss': 0.577380635117998, 'Total loss': 0.577380635117998}
2022-11-23 00:52:29,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:29,973 INFO:     Epoch: 84
2022-11-23 00:52:30,816 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5667340457439423, 'Total loss': 0.5667340457439423} | train loss {'Reaction outcome loss': 0.5777603418243175, 'Total loss': 0.5777603418243175}
2022-11-23 00:52:30,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:30,816 INFO:     Epoch: 85
2022-11-23 00:52:31,715 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5717223476279866, 'Total loss': 0.5717223476279866} | train loss {'Reaction outcome loss': 0.5914545084140739, 'Total loss': 0.5914545084140739}
2022-11-23 00:52:31,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:31,715 INFO:     Epoch: 86
2022-11-23 00:52:32,558 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5481831922449849, 'Total loss': 0.5481831922449849} | train loss {'Reaction outcome loss': 0.5780292006171479, 'Total loss': 0.5780292006171479}
2022-11-23 00:52:32,558 INFO:     Found new best model at epoch 86
2022-11-23 00:52:32,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:32,559 INFO:     Epoch: 87
2022-11-23 00:52:33,385 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.6819038065997037, 'Total loss': 0.6819038065997037} | train loss {'Reaction outcome loss': 0.6047809158052717, 'Total loss': 0.6047809158052717}
2022-11-23 00:52:33,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:33,386 INFO:     Epoch: 88
2022-11-23 00:52:34,215 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5791902257637545, 'Total loss': 0.5791902257637545} | train loss {'Reaction outcome loss': 0.5969341186844572, 'Total loss': 0.5969341186844572}
2022-11-23 00:52:34,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:34,215 INFO:     Epoch: 89
2022-11-23 00:52:35,109 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5809159559959715, 'Total loss': 0.5809159559959715} | train loss {'Reaction outcome loss': 0.5639804974502447, 'Total loss': 0.5639804974502447}
2022-11-23 00:52:35,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:35,110 INFO:     Epoch: 90
2022-11-23 00:52:35,976 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.6155697744001042, 'Total loss': 0.6155697744001042} | train loss {'Reaction outcome loss': 0.5932533668620246, 'Total loss': 0.5932533668620246}
2022-11-23 00:52:35,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:35,976 INFO:     Epoch: 91
2022-11-23 00:52:36,849 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5508055124770511, 'Total loss': 0.5508055124770511} | train loss {'Reaction outcome loss': 0.5913520540509906, 'Total loss': 0.5913520540509906}
2022-11-23 00:52:36,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:36,849 INFO:     Epoch: 92
2022-11-23 00:52:37,699 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5326081175695766, 'Total loss': 0.5326081175695766} | train loss {'Reaction outcome loss': 0.5836839994605707, 'Total loss': 0.5836839994605707}
2022-11-23 00:52:37,699 INFO:     Found new best model at epoch 92
2022-11-23 00:52:37,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:37,700 INFO:     Epoch: 93
2022-11-23 00:52:38,577 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5988578809933229, 'Total loss': 0.5988578809933229} | train loss {'Reaction outcome loss': 0.574790428487622, 'Total loss': 0.574790428487622}
2022-11-23 00:52:38,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:38,577 INFO:     Epoch: 94
2022-11-23 00:52:39,450 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5530682917345654, 'Total loss': 0.5530682917345654} | train loss {'Reaction outcome loss': 0.5981692714350564, 'Total loss': 0.5981692714350564}
2022-11-23 00:52:39,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:39,451 INFO:     Epoch: 95
2022-11-23 00:52:40,295 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5769844251600179, 'Total loss': 0.5769844251600179} | train loss {'Reaction outcome loss': 0.5758242007420987, 'Total loss': 0.5758242007420987}
2022-11-23 00:52:40,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:40,295 INFO:     Epoch: 96
2022-11-23 00:52:41,184 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5843335891311819, 'Total loss': 0.5843335891311819} | train loss {'Reaction outcome loss': 0.5686904045392056, 'Total loss': 0.5686904045392056}
2022-11-23 00:52:41,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:41,185 INFO:     Epoch: 97
2022-11-23 00:52:42,080 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.6985628882592375, 'Total loss': 0.6985628882592375} | train loss {'Reaction outcome loss': 0.576222924431976, 'Total loss': 0.576222924431976}
2022-11-23 00:52:42,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:42,080 INFO:     Epoch: 98
2022-11-23 00:52:42,918 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5570098276842724, 'Total loss': 0.5570098276842724} | train loss {'Reaction outcome loss': 0.5937189259699412, 'Total loss': 0.5937189259699412}
2022-11-23 00:52:42,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:42,918 INFO:     Epoch: 99
2022-11-23 00:52:43,823 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.6058070354840972, 'Total loss': 0.6058070354840972} | train loss {'Reaction outcome loss': 0.5779714842231907, 'Total loss': 0.5779714842231907}
2022-11-23 00:52:43,823 INFO:     Best model found after epoch 93 of 100.
2022-11-23 00:52:43,823 INFO:   Done with stage: TRAINING
2022-11-23 00:52:43,824 INFO:   Starting stage: EVALUATION
2022-11-23 00:52:43,954 INFO:   Done with stage: EVALUATION
2022-11-23 00:52:43,954 INFO:   Leaving out SEQ value Fold_4
2022-11-23 00:52:43,967 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 00:52:43,968 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:52:44,653 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:52:44,653 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:52:44,727 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:52:44,727 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:52:44,727 INFO:     No hyperparam tuning for this model
2022-11-23 00:52:44,727 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:52:44,727 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:52:44,728 INFO:     None feature selector for col prot
2022-11-23 00:52:44,728 INFO:     None feature selector for col prot
2022-11-23 00:52:44,728 INFO:     None feature selector for col prot
2022-11-23 00:52:44,729 INFO:     None feature selector for col chem
2022-11-23 00:52:44,729 INFO:     None feature selector for col chem
2022-11-23 00:52:44,729 INFO:     None feature selector for col chem
2022-11-23 00:52:44,729 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:52:44,729 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:52:44,731 INFO:     Number of params in model 168571
2022-11-23 00:52:44,734 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:52:44,734 INFO:   Starting stage: TRAINING
2022-11-23 00:52:44,794 INFO:     Val loss before train {'Reaction outcome loss': 1.0285421135750683, 'Total loss': 1.0285421135750683}
2022-11-23 00:52:44,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:44,794 INFO:     Epoch: 0
2022-11-23 00:52:45,694 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8945859264243733, 'Total loss': 0.8945859264243733} | train loss {'Reaction outcome loss': 0.8810937053520187, 'Total loss': 0.8810937053520187}
2022-11-23 00:52:45,694 INFO:     Found new best model at epoch 0
2022-11-23 00:52:45,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:45,695 INFO:     Epoch: 1
2022-11-23 00:52:46,567 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8691035346551375, 'Total loss': 0.8691035346551375} | train loss {'Reaction outcome loss': 0.8443008126155568, 'Total loss': 0.8443008126155568}
2022-11-23 00:52:46,567 INFO:     Found new best model at epoch 1
2022-11-23 00:52:46,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:46,568 INFO:     Epoch: 2
2022-11-23 00:52:47,400 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8994338539513674, 'Total loss': 0.8994338539513674} | train loss {'Reaction outcome loss': 0.8405922744196919, 'Total loss': 0.8405922744196919}
2022-11-23 00:52:47,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:47,400 INFO:     Epoch: 3
2022-11-23 00:52:48,289 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8644463826309551, 'Total loss': 0.8644463826309551} | train loss {'Reaction outcome loss': 0.8354207422463638, 'Total loss': 0.8354207422463638}
2022-11-23 00:52:48,289 INFO:     Found new best model at epoch 3
2022-11-23 00:52:48,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:48,290 INFO:     Epoch: 4
2022-11-23 00:52:49,130 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8877256607467477, 'Total loss': 0.8877256607467477} | train loss {'Reaction outcome loss': 0.8306013783703932, 'Total loss': 0.8306013783703932}
2022-11-23 00:52:49,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:49,131 INFO:     Epoch: 5
2022-11-23 00:52:50,016 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8636028333143755, 'Total loss': 0.8636028333143755} | train loss {'Reaction outcome loss': 0.8251190958959371, 'Total loss': 0.8251190958959371}
2022-11-23 00:52:50,016 INFO:     Found new best model at epoch 5
2022-11-23 00:52:50,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:50,017 INFO:     Epoch: 6
2022-11-23 00:52:50,845 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8382562060247768, 'Total loss': 0.8382562060247768} | train loss {'Reaction outcome loss': 0.8245885884954862, 'Total loss': 0.8245885884954862}
2022-11-23 00:52:50,846 INFO:     Found new best model at epoch 6
2022-11-23 00:52:50,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:50,846 INFO:     Epoch: 7
2022-11-23 00:52:51,687 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8481191511858593, 'Total loss': 0.8481191511858593} | train loss {'Reaction outcome loss': 0.813164220406459, 'Total loss': 0.813164220406459}
2022-11-23 00:52:51,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:51,687 INFO:     Epoch: 8
2022-11-23 00:52:52,553 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8242585902864282, 'Total loss': 0.8242585902864282} | train loss {'Reaction outcome loss': 0.8174319880211401, 'Total loss': 0.8174319880211401}
2022-11-23 00:52:52,553 INFO:     Found new best model at epoch 8
2022-11-23 00:52:52,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:52,554 INFO:     Epoch: 9
2022-11-23 00:52:53,412 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.838118316097693, 'Total loss': 0.838118316097693} | train loss {'Reaction outcome loss': 0.815901618858098, 'Total loss': 0.815901618858098}
2022-11-23 00:52:53,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:53,413 INFO:     Epoch: 10
2022-11-23 00:52:54,239 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8335902230306105, 'Total loss': 0.8335902230306105} | train loss {'Reaction outcome loss': 0.8187465158551328, 'Total loss': 0.8187465158551328}
2022-11-23 00:52:54,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:54,240 INFO:     Epoch: 11
2022-11-23 00:52:55,100 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.845687291838906, 'Total loss': 0.845687291838906} | train loss {'Reaction outcome loss': 0.8207196094970471, 'Total loss': 0.8207196094970471}
2022-11-23 00:52:55,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:55,100 INFO:     Epoch: 12
2022-11-23 00:52:55,921 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8426546935330738, 'Total loss': 0.8426546935330738} | train loss {'Reaction outcome loss': 0.8174083999052704, 'Total loss': 0.8174083999052704}
2022-11-23 00:52:55,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:55,921 INFO:     Epoch: 13
2022-11-23 00:52:56,793 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8424583449959755, 'Total loss': 0.8424583449959755} | train loss {'Reaction outcome loss': 0.8159785623009871, 'Total loss': 0.8159785623009871}
2022-11-23 00:52:56,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:56,793 INFO:     Epoch: 14
2022-11-23 00:52:57,626 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8670347542925314, 'Total loss': 0.8670347542925314} | train loss {'Reaction outcome loss': 0.8216668996009749, 'Total loss': 0.8216668996009749}
2022-11-23 00:52:57,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:57,626 INFO:     Epoch: 15
2022-11-23 00:52:58,478 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8407221775163304, 'Total loss': 0.8407221775163304} | train loss {'Reaction outcome loss': 0.8215109670934407, 'Total loss': 0.8215109670934407}
2022-11-23 00:52:58,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:58,479 INFO:     Epoch: 16
2022-11-23 00:52:59,382 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8726296560330824, 'Total loss': 0.8726296560330824} | train loss {'Reaction outcome loss': 0.8220201803122454, 'Total loss': 0.8220201803122454}
2022-11-23 00:52:59,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:52:59,382 INFO:     Epoch: 17
2022-11-23 00:53:00,223 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8460366177287969, 'Total loss': 0.8460366177287969} | train loss {'Reaction outcome loss': 0.8193768805820449, 'Total loss': 0.8193768805820449}
2022-11-23 00:53:00,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:00,224 INFO:     Epoch: 18
2022-11-23 00:53:01,072 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8396875262260437, 'Total loss': 0.8396875262260437} | train loss {'Reaction outcome loss': 0.8112703163312515, 'Total loss': 0.8112703163312515}
2022-11-23 00:53:01,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:01,073 INFO:     Epoch: 19
2022-11-23 00:53:01,898 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8510565066879446, 'Total loss': 0.8510565066879446} | train loss {'Reaction outcome loss': 0.8127425861081131, 'Total loss': 0.8127425861081131}
2022-11-23 00:53:01,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:01,899 INFO:     Epoch: 20
2022-11-23 00:53:02,729 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8433105688203465, 'Total loss': 0.8433105688203465} | train loss {'Reaction outcome loss': 0.8193279358177532, 'Total loss': 0.8193279358177532}
2022-11-23 00:53:02,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:02,729 INFO:     Epoch: 21
2022-11-23 00:53:03,576 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8403143611821261, 'Total loss': 0.8403143611821261} | train loss {'Reaction outcome loss': 0.8252241629579289, 'Total loss': 0.8252241629579289}
2022-11-23 00:53:03,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:03,576 INFO:     Epoch: 22
2022-11-23 00:53:04,415 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8468647836284204, 'Total loss': 0.8468647836284204} | train loss {'Reaction outcome loss': 0.8157343683153512, 'Total loss': 0.8157343683153512}
2022-11-23 00:53:04,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:04,416 INFO:     Epoch: 23
2022-11-23 00:53:05,248 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8567026284607974, 'Total loss': 0.8567026284607974} | train loss {'Reaction outcome loss': 0.8151075365813637, 'Total loss': 0.8151075365813637}
2022-11-23 00:53:05,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:05,249 INFO:     Epoch: 24
2022-11-23 00:53:06,050 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8567005842924118, 'Total loss': 0.8567005842924118} | train loss {'Reaction outcome loss': 0.8098101094666763, 'Total loss': 0.8098101094666763}
2022-11-23 00:53:06,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:06,051 INFO:     Epoch: 25
2022-11-23 00:53:06,875 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8276127556508238, 'Total loss': 0.8276127556508238} | train loss {'Reaction outcome loss': 0.8124173465769301, 'Total loss': 0.8124173465769301}
2022-11-23 00:53:06,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:06,875 INFO:     Epoch: 26
2022-11-23 00:53:07,663 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8494819660078395, 'Total loss': 0.8494819660078395} | train loss {'Reaction outcome loss': 0.8149726542866664, 'Total loss': 0.8149726542866664}
2022-11-23 00:53:07,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:07,663 INFO:     Epoch: 27
2022-11-23 00:53:08,474 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8463472507216714, 'Total loss': 0.8463472507216714} | train loss {'Reaction outcome loss': 0.8126266011101032, 'Total loss': 0.8126266011101032}
2022-11-23 00:53:08,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:08,474 INFO:     Epoch: 28
2022-11-23 00:53:09,312 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8569572053172372, 'Total loss': 0.8569572053172372} | train loss {'Reaction outcome loss': 0.8170811173162962, 'Total loss': 0.8170811173162962}
2022-11-23 00:53:09,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:09,313 INFO:     Epoch: 29
2022-11-23 00:53:10,129 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8626519089395349, 'Total loss': 0.8626519089395349} | train loss {'Reaction outcome loss': 0.8111372651600162, 'Total loss': 0.8111372651600162}
2022-11-23 00:53:10,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:10,129 INFO:     Epoch: 30
2022-11-23 00:53:10,944 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.870807100426067, 'Total loss': 0.870807100426067} | train loss {'Reaction outcome loss': 0.8148898874458513, 'Total loss': 0.8148898874458513}
2022-11-23 00:53:10,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:10,944 INFO:     Epoch: 31
2022-11-23 00:53:11,789 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8643561445853927, 'Total loss': 0.8643561445853927} | train loss {'Reaction outcome loss': 0.814660518637553, 'Total loss': 0.814660518637553}
2022-11-23 00:53:11,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:11,789 INFO:     Epoch: 32
2022-11-23 00:53:12,572 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8358456682075154, 'Total loss': 0.8358456682075154} | train loss {'Reaction outcome loss': 0.8183109575678945, 'Total loss': 0.8183109575678945}
2022-11-23 00:53:12,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:12,573 INFO:     Epoch: 33
2022-11-23 00:53:13,346 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8352092477408323, 'Total loss': 0.8352092477408323} | train loss {'Reaction outcome loss': 0.8185042022210867, 'Total loss': 0.8185042022210867}
2022-11-23 00:53:13,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:13,347 INFO:     Epoch: 34
2022-11-23 00:53:14,136 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8436458239501173, 'Total loss': 0.8436458239501173} | train loss {'Reaction outcome loss': 0.814719136668603, 'Total loss': 0.814719136668603}
2022-11-23 00:53:14,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:14,136 INFO:     Epoch: 35
2022-11-23 00:53:14,944 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8229527568275278, 'Total loss': 0.8229527568275278} | train loss {'Reaction outcome loss': 0.8192374991019246, 'Total loss': 0.8192374991019246}
2022-11-23 00:53:14,944 INFO:     Found new best model at epoch 35
2022-11-23 00:53:14,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:14,945 INFO:     Epoch: 36
2022-11-23 00:53:15,745 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8317993500015952, 'Total loss': 0.8317993500015952} | train loss {'Reaction outcome loss': 0.8128384338533469, 'Total loss': 0.8128384338533469}
2022-11-23 00:53:15,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:15,745 INFO:     Epoch: 37
2022-11-23 00:53:16,536 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8531547425822779, 'Total loss': 0.8531547425822779} | train loss {'Reaction outcome loss': 0.8140814216272069, 'Total loss': 0.8140814216272069}
2022-11-23 00:53:16,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:16,536 INFO:     Epoch: 38
2022-11-23 00:53:17,334 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8356301581317728, 'Total loss': 0.8356301581317728} | train loss {'Reaction outcome loss': 0.8202300468678416, 'Total loss': 0.8202300468678416}
2022-11-23 00:53:17,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:17,334 INFO:     Epoch: 39
2022-11-23 00:53:18,140 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8585516492074187, 'Total loss': 0.8585516492074187} | train loss {'Reaction outcome loss': 0.8128022585923855, 'Total loss': 0.8128022585923855}
2022-11-23 00:53:18,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:18,140 INFO:     Epoch: 40
2022-11-23 00:53:18,997 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8378648886626417, 'Total loss': 0.8378648886626417} | train loss {'Reaction outcome loss': 0.816069912331307, 'Total loss': 0.816069912331307}
2022-11-23 00:53:18,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:18,997 INFO:     Epoch: 41
2022-11-23 00:53:19,837 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8369659056717699, 'Total loss': 0.8369659056717699} | train loss {'Reaction outcome loss': 0.8091375829900808, 'Total loss': 0.8091375829900808}
2022-11-23 00:53:19,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:19,837 INFO:     Epoch: 42
2022-11-23 00:53:20,678 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8247702690688047, 'Total loss': 0.8247702690688047} | train loss {'Reaction outcome loss': 0.8184932326739617, 'Total loss': 0.8184932326739617}
2022-11-23 00:53:20,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:20,678 INFO:     Epoch: 43
2022-11-23 00:53:21,458 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.827775464816527, 'Total loss': 0.827775464816527} | train loss {'Reaction outcome loss': 0.8115210674310985, 'Total loss': 0.8115210674310985}
2022-11-23 00:53:21,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:21,458 INFO:     Epoch: 44
2022-11-23 00:53:22,260 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8457761244340376, 'Total loss': 0.8457761244340376} | train loss {'Reaction outcome loss': 0.8157326966101824, 'Total loss': 0.8157326966101824}
2022-11-23 00:53:22,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:22,260 INFO:     Epoch: 45
2022-11-23 00:53:23,013 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8260506703095003, 'Total loss': 0.8260506703095003} | train loss {'Reaction outcome loss': 0.8080408568776812, 'Total loss': 0.8080408568776812}
2022-11-23 00:53:23,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:23,014 INFO:     Epoch: 46
2022-11-23 00:53:23,808 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8383685953237794, 'Total loss': 0.8383685953237794} | train loss {'Reaction outcome loss': 0.8150779197090551, 'Total loss': 0.8150779197090551}
2022-11-23 00:53:23,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:23,809 INFO:     Epoch: 47
2022-11-23 00:53:24,631 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8295072649012912, 'Total loss': 0.8295072649012912} | train loss {'Reaction outcome loss': 0.8242764068759887, 'Total loss': 0.8242764068759887}
2022-11-23 00:53:24,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:24,632 INFO:     Epoch: 48
2022-11-23 00:53:25,434 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8463560220870104, 'Total loss': 0.8463560220870104} | train loss {'Reaction outcome loss': 0.8185100895673157, 'Total loss': 0.8185100895673157}
2022-11-23 00:53:25,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:25,434 INFO:     Epoch: 49
2022-11-23 00:53:26,233 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8438254635442387, 'Total loss': 0.8438254635442387} | train loss {'Reaction outcome loss': 0.8143443868227815, 'Total loss': 0.8143443868227815}
2022-11-23 00:53:26,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:26,233 INFO:     Epoch: 50
2022-11-23 00:53:27,068 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.841006182811477, 'Total loss': 0.841006182811477} | train loss {'Reaction outcome loss': 0.8093059667148571, 'Total loss': 0.8093059667148571}
2022-11-23 00:53:27,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:27,068 INFO:     Epoch: 51
2022-11-23 00:53:27,889 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8394420980052515, 'Total loss': 0.8394420980052515} | train loss {'Reaction outcome loss': 0.8144328443386294, 'Total loss': 0.8144328443386294}
2022-11-23 00:53:27,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:27,890 INFO:     Epoch: 52
2022-11-23 00:53:28,668 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8500675186514854, 'Total loss': 0.8500675186514854} | train loss {'Reaction outcome loss': 0.8178024598461414, 'Total loss': 0.8178024598461414}
2022-11-23 00:53:28,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:28,669 INFO:     Epoch: 53
2022-11-23 00:53:29,448 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8303634104403582, 'Total loss': 0.8303634104403582} | train loss {'Reaction outcome loss': 0.8127691292087076, 'Total loss': 0.8127691292087076}
2022-11-23 00:53:29,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:29,449 INFO:     Epoch: 54
2022-11-23 00:53:30,254 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.82722761685198, 'Total loss': 0.82722761685198} | train loss {'Reaction outcome loss': 0.8124131550673048, 'Total loss': 0.8124131550673048}
2022-11-23 00:53:30,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:30,254 INFO:     Epoch: 55
2022-11-23 00:53:31,044 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8426041088320992, 'Total loss': 0.8426041088320992} | train loss {'Reaction outcome loss': 0.8129319819180589, 'Total loss': 0.8129319819180589}
2022-11-23 00:53:31,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:31,045 INFO:     Epoch: 56
2022-11-23 00:53:31,926 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8329973491755399, 'Total loss': 0.8329973491755399} | train loss {'Reaction outcome loss': 0.8101715386396477, 'Total loss': 0.8101715386396477}
2022-11-23 00:53:31,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:31,927 INFO:     Epoch: 57
2022-11-23 00:53:32,727 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8305529809810899, 'Total loss': 0.8305529809810899} | train loss {'Reaction outcome loss': 0.8194858688815885, 'Total loss': 0.8194858688815885}
2022-11-23 00:53:32,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:32,727 INFO:     Epoch: 58
2022-11-23 00:53:33,514 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8397941846739162, 'Total loss': 0.8397941846739162} | train loss {'Reaction outcome loss': 0.8225271966051959, 'Total loss': 0.8225271966051959}
2022-11-23 00:53:33,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:33,515 INFO:     Epoch: 59
2022-11-23 00:53:34,321 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.83184110915119, 'Total loss': 0.83184110915119} | train loss {'Reaction outcome loss': 0.8226382168922347, 'Total loss': 0.8226382168922347}
2022-11-23 00:53:34,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:34,322 INFO:     Epoch: 60
2022-11-23 00:53:35,170 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.835983311588114, 'Total loss': 0.835983311588114} | train loss {'Reaction outcome loss': 0.8329679824804005, 'Total loss': 0.8329679824804005}
2022-11-23 00:53:35,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:35,170 INFO:     Epoch: 61
2022-11-23 00:53:35,970 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.827624574303627, 'Total loss': 0.827624574303627} | train loss {'Reaction outcome loss': 0.8086742678363072, 'Total loss': 0.8086742678363072}
2022-11-23 00:53:35,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:35,971 INFO:     Epoch: 62
2022-11-23 00:53:36,789 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8291935582052578, 'Total loss': 0.8291935582052578} | train loss {'Reaction outcome loss': 0.8080927517853285, 'Total loss': 0.8080927517853285}
2022-11-23 00:53:36,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:36,790 INFO:     Epoch: 63
2022-11-23 00:53:37,580 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8369393714449622, 'Total loss': 0.8369393714449622} | train loss {'Reaction outcome loss': 0.8118622281290742, 'Total loss': 0.8118622281290742}
2022-11-23 00:53:37,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:37,580 INFO:     Epoch: 64
2022-11-23 00:53:38,422 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8875980587168173, 'Total loss': 0.8875980587168173} | train loss {'Reaction outcome loss': 0.8086847769104035, 'Total loss': 0.8086847769104035}
2022-11-23 00:53:38,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:38,422 INFO:     Epoch: 65
2022-11-23 00:53:39,315 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8497077450156212, 'Total loss': 0.8497077450156212} | train loss {'Reaction outcome loss': 0.8109670824970794, 'Total loss': 0.8109670824970794}
2022-11-23 00:53:39,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:39,315 INFO:     Epoch: 66
2022-11-23 00:53:40,133 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8406279764392159, 'Total loss': 0.8406279764392159} | train loss {'Reaction outcome loss': 0.8138960243960623, 'Total loss': 0.8138960243960623}
2022-11-23 00:53:40,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:40,133 INFO:     Epoch: 67
2022-11-23 00:53:40,949 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.82865409553051, 'Total loss': 0.82865409553051} | train loss {'Reaction outcome loss': 0.8211016332813603, 'Total loss': 0.8211016332813603}
2022-11-23 00:53:40,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:40,949 INFO:     Epoch: 68
2022-11-23 00:53:41,731 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.827813249420036, 'Total loss': 0.827813249420036} | train loss {'Reaction outcome loss': 0.8162362979732545, 'Total loss': 0.8162362979732545}
2022-11-23 00:53:41,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:41,731 INFO:     Epoch: 69
2022-11-23 00:53:42,531 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8401520509611476, 'Total loss': 0.8401520509611476} | train loss {'Reaction outcome loss': 0.8037888805272608, 'Total loss': 0.8037888805272608}
2022-11-23 00:53:42,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:42,531 INFO:     Epoch: 70
2022-11-23 00:53:43,344 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8304163041439924, 'Total loss': 0.8304163041439924} | train loss {'Reaction outcome loss': 0.8083174840400094, 'Total loss': 0.8083174840400094}
2022-11-23 00:53:43,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:43,345 INFO:     Epoch: 71
2022-11-23 00:53:44,124 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8348573974587701, 'Total loss': 0.8348573974587701} | train loss {'Reaction outcome loss': 0.8076580595149685, 'Total loss': 0.8076580595149685}
2022-11-23 00:53:44,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:44,124 INFO:     Epoch: 72
2022-11-23 00:53:44,934 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8386129249225963, 'Total loss': 0.8386129249225963} | train loss {'Reaction outcome loss': 0.809237367560265, 'Total loss': 0.809237367560265}
2022-11-23 00:53:44,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:44,935 INFO:     Epoch: 73
2022-11-23 00:53:45,764 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8262508687647906, 'Total loss': 0.8262508687647906} | train loss {'Reaction outcome loss': 0.8128182809603842, 'Total loss': 0.8128182809603842}
2022-11-23 00:53:45,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:45,765 INFO:     Epoch: 74
2022-11-23 00:53:46,581 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8362926786596124, 'Total loss': 0.8362926786596124} | train loss {'Reaction outcome loss': 0.8146474330048812, 'Total loss': 0.8146474330048812}
2022-11-23 00:53:46,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:46,581 INFO:     Epoch: 75
2022-11-23 00:53:47,385 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8568338778885928, 'Total loss': 0.8568338778885928} | train loss {'Reaction outcome loss': 0.807885100484377, 'Total loss': 0.807885100484377}
2022-11-23 00:53:47,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:47,386 INFO:     Epoch: 76
2022-11-23 00:53:48,193 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.820441260933876, 'Total loss': 0.820441260933876} | train loss {'Reaction outcome loss': 0.8161656534382207, 'Total loss': 0.8161656534382207}
2022-11-23 00:53:48,194 INFO:     Found new best model at epoch 76
2022-11-23 00:53:48,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:48,194 INFO:     Epoch: 77
2022-11-23 00:53:49,010 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8155468668450009, 'Total loss': 0.8155468668450009} | train loss {'Reaction outcome loss': 0.8102084025137337, 'Total loss': 0.8102084025137337}
2022-11-23 00:53:49,010 INFO:     Found new best model at epoch 77
2022-11-23 00:53:49,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:49,011 INFO:     Epoch: 78
2022-11-23 00:53:49,816 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8242607787251472, 'Total loss': 0.8242607787251472} | train loss {'Reaction outcome loss': 0.8171664862497615, 'Total loss': 0.8171664862497615}
2022-11-23 00:53:49,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:49,816 INFO:     Epoch: 79
2022-11-23 00:53:50,627 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8548682751980695, 'Total loss': 0.8548682751980695} | train loss {'Reaction outcome loss': 0.8101985623479372, 'Total loss': 0.8101985623479372}
2022-11-23 00:53:50,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:50,628 INFO:     Epoch: 80
2022-11-23 00:53:51,426 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8385669399391521, 'Total loss': 0.8385669399391521} | train loss {'Reaction outcome loss': 0.8142035479246363, 'Total loss': 0.8142035479246363}
2022-11-23 00:53:51,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:51,426 INFO:     Epoch: 81
2022-11-23 00:53:52,264 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8287237564271147, 'Total loss': 0.8287237564271147} | train loss {'Reaction outcome loss': 0.8236470957275345, 'Total loss': 0.8236470957275345}
2022-11-23 00:53:52,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:52,265 INFO:     Epoch: 82
2022-11-23 00:53:53,049 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8444461924108592, 'Total loss': 0.8444461924108592} | train loss {'Reaction outcome loss': 0.8213114259455369, 'Total loss': 0.8213114259455369}
2022-11-23 00:53:53,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:53,049 INFO:     Epoch: 83
2022-11-23 00:53:53,849 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.816824542527849, 'Total loss': 0.816824542527849} | train loss {'Reaction outcome loss': 0.8107271000199955, 'Total loss': 0.8107271000199955}
2022-11-23 00:53:53,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:53,849 INFO:     Epoch: 84
2022-11-23 00:53:54,696 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.835808934813196, 'Total loss': 0.835808934813196} | train loss {'Reaction outcome loss': 0.807904731648171, 'Total loss': 0.807904731648171}
2022-11-23 00:53:54,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:54,696 INFO:     Epoch: 85
2022-11-23 00:53:55,499 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8318552401932803, 'Total loss': 0.8318552401932803} | train loss {'Reaction outcome loss': 0.8142382182814332, 'Total loss': 0.8142382182814332}
2022-11-23 00:53:55,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:55,500 INFO:     Epoch: 86
2022-11-23 00:53:56,353 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8330040099945936, 'Total loss': 0.8330040099945936} | train loss {'Reaction outcome loss': 0.8157761327409552, 'Total loss': 0.8157761327409552}
2022-11-23 00:53:56,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:56,353 INFO:     Epoch: 87
2022-11-23 00:53:57,130 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8244997479698875, 'Total loss': 0.8244997479698875} | train loss {'Reaction outcome loss': 0.8064278390424454, 'Total loss': 0.8064278390424454}
2022-11-23 00:53:57,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:57,131 INFO:     Epoch: 88
2022-11-23 00:53:57,925 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8399487280032851, 'Total loss': 0.8399487280032851} | train loss {'Reaction outcome loss': 0.8104557160906464, 'Total loss': 0.8104557160906464}
2022-11-23 00:53:57,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:57,925 INFO:     Epoch: 89
2022-11-23 00:53:58,701 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8468879366462881, 'Total loss': 0.8468879366462881} | train loss {'Reaction outcome loss': 0.8166945527198344, 'Total loss': 0.8166945527198344}
2022-11-23 00:53:58,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:58,701 INFO:     Epoch: 90
2022-11-23 00:53:59,450 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.840423771603541, 'Total loss': 0.840423771603541} | train loss {'Reaction outcome loss': 0.8104884477128625, 'Total loss': 0.8104884477128625}
2022-11-23 00:53:59,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:53:59,450 INFO:     Epoch: 91
2022-11-23 00:54:00,290 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8272501128641042, 'Total loss': 0.8272501128641042} | train loss {'Reaction outcome loss': 0.816999745393089, 'Total loss': 0.816999745393089}
2022-11-23 00:54:00,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:00,290 INFO:     Epoch: 92
2022-11-23 00:54:01,112 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8691828738559376, 'Total loss': 0.8691828738559376} | train loss {'Reaction outcome loss': 0.820638608594655, 'Total loss': 0.820638608594655}
2022-11-23 00:54:01,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:01,112 INFO:     Epoch: 93
2022-11-23 00:54:01,906 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8315589739517733, 'Total loss': 0.8315589739517733} | train loss {'Reaction outcome loss': 0.8121434135234308, 'Total loss': 0.8121434135234308}
2022-11-23 00:54:01,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:01,906 INFO:     Epoch: 94
2022-11-23 00:54:02,678 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8463334556330334, 'Total loss': 0.8463334556330334} | train loss {'Reaction outcome loss': 0.8104109450390464, 'Total loss': 0.8104109450390464}
2022-11-23 00:54:02,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:02,678 INFO:     Epoch: 95
2022-11-23 00:54:03,515 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8490287268703635, 'Total loss': 0.8490287268703635} | train loss {'Reaction outcome loss': 0.8097528962471224, 'Total loss': 0.8097528962471224}
2022-11-23 00:54:03,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:03,515 INFO:     Epoch: 96
2022-11-23 00:54:04,305 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.871126579967412, 'Total loss': 0.871126579967412} | train loss {'Reaction outcome loss': 0.8087111969708431, 'Total loss': 0.8087111969708431}
2022-11-23 00:54:04,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:04,305 INFO:     Epoch: 97
2022-11-23 00:54:05,109 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.827173380011862, 'Total loss': 0.827173380011862} | train loss {'Reaction outcome loss': 0.8049925203748077, 'Total loss': 0.8049925203748077}
2022-11-23 00:54:05,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:05,109 INFO:     Epoch: 98
2022-11-23 00:54:05,925 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8428568548776887, 'Total loss': 0.8428568548776887} | train loss {'Reaction outcome loss': 0.8095765812435614, 'Total loss': 0.8095765812435614}
2022-11-23 00:54:05,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:05,926 INFO:     Epoch: 99
2022-11-23 00:54:06,726 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.823524876751683, 'Total loss': 0.823524876751683} | train loss {'Reaction outcome loss': 0.8089273273944855, 'Total loss': 0.8089273273944855}
2022-11-23 00:54:06,726 INFO:     Best model found after epoch 78 of 100.
2022-11-23 00:54:06,726 INFO:   Done with stage: TRAINING
2022-11-23 00:54:06,726 INFO:   Starting stage: EVALUATION
2022-11-23 00:54:06,851 INFO:   Done with stage: EVALUATION
2022-11-23 00:54:06,852 INFO:   Leaving out SEQ value Fold_5
2022-11-23 00:54:06,865 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 00:54:06,865 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:54:07,538 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:54:07,538 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:54:07,610 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:54:07,610 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:54:07,610 INFO:     No hyperparam tuning for this model
2022-11-23 00:54:07,611 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:54:07,611 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:54:07,611 INFO:     None feature selector for col prot
2022-11-23 00:54:07,612 INFO:     None feature selector for col prot
2022-11-23 00:54:07,612 INFO:     None feature selector for col prot
2022-11-23 00:54:07,612 INFO:     None feature selector for col chem
2022-11-23 00:54:07,612 INFO:     None feature selector for col chem
2022-11-23 00:54:07,613 INFO:     None feature selector for col chem
2022-11-23 00:54:07,613 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:54:07,613 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:54:07,614 INFO:     Number of params in model 168571
2022-11-23 00:54:07,618 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:54:07,618 INFO:   Starting stage: TRAINING
2022-11-23 00:54:07,676 INFO:     Val loss before train {'Reaction outcome loss': 0.9764663116498427, 'Total loss': 0.9764663116498427}
2022-11-23 00:54:07,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:07,676 INFO:     Epoch: 0
2022-11-23 00:54:08,471 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8546663990074937, 'Total loss': 0.8546663990074937} | train loss {'Reaction outcome loss': 0.8929842656418201, 'Total loss': 0.8929842656418201}
2022-11-23 00:54:08,473 INFO:     Found new best model at epoch 0
2022-11-23 00:54:08,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:08,474 INFO:     Epoch: 1
2022-11-23 00:54:09,291 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8081603199243546, 'Total loss': 0.8081603199243546} | train loss {'Reaction outcome loss': 0.8541233554001777, 'Total loss': 0.8541233554001777}
2022-11-23 00:54:09,292 INFO:     Found new best model at epoch 1
2022-11-23 00:54:09,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:09,293 INFO:     Epoch: 2
2022-11-23 00:54:10,120 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8023785312067379, 'Total loss': 0.8023785312067379} | train loss {'Reaction outcome loss': 0.8513639849280158, 'Total loss': 0.8513639849280158}
2022-11-23 00:54:10,120 INFO:     Found new best model at epoch 2
2022-11-23 00:54:10,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:10,121 INFO:     Epoch: 3
2022-11-23 00:54:10,902 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8138236091895537, 'Total loss': 0.8138236091895537} | train loss {'Reaction outcome loss': 0.8472338769464723, 'Total loss': 0.8472338769464723}
2022-11-23 00:54:10,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:10,902 INFO:     Epoch: 4
2022-11-23 00:54:11,742 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8098239709030498, 'Total loss': 0.8098239709030498} | train loss {'Reaction outcome loss': 0.8372235701930139, 'Total loss': 0.8372235701930139}
2022-11-23 00:54:11,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:11,742 INFO:     Epoch: 5
2022-11-23 00:54:12,571 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7950147959319028, 'Total loss': 0.7950147959319028} | train loss {'Reaction outcome loss': 0.831036540649591, 'Total loss': 0.831036540649591}
2022-11-23 00:54:12,571 INFO:     Found new best model at epoch 5
2022-11-23 00:54:12,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:12,572 INFO:     Epoch: 6
2022-11-23 00:54:13,354 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8235657269304449, 'Total loss': 0.8235657269304449} | train loss {'Reaction outcome loss': 0.8282317927768154, 'Total loss': 0.8282317927768154}
2022-11-23 00:54:13,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:13,354 INFO:     Epoch: 7
2022-11-23 00:54:14,184 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.79805876924233, 'Total loss': 0.79805876924233} | train loss {'Reaction outcome loss': 0.8289753521882719, 'Total loss': 0.8289753521882719}
2022-11-23 00:54:14,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:14,184 INFO:     Epoch: 8
2022-11-23 00:54:14,978 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7779645411805673, 'Total loss': 0.7779645411805673} | train loss {'Reaction outcome loss': 0.8237294885179689, 'Total loss': 0.8237294885179689}
2022-11-23 00:54:14,979 INFO:     Found new best model at epoch 8
2022-11-23 00:54:14,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:14,980 INFO:     Epoch: 9
2022-11-23 00:54:15,751 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.810888333754106, 'Total loss': 0.810888333754106} | train loss {'Reaction outcome loss': 0.8295100917739253, 'Total loss': 0.8295100917739253}
2022-11-23 00:54:15,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:15,751 INFO:     Epoch: 10
2022-11-23 00:54:16,595 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7869546657258814, 'Total loss': 0.7869546657258814} | train loss {'Reaction outcome loss': 0.8268316582806648, 'Total loss': 0.8268316582806648}
2022-11-23 00:54:16,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:16,596 INFO:     Epoch: 11
2022-11-23 00:54:17,367 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7812863120978529, 'Total loss': 0.7812863120978529} | train loss {'Reaction outcome loss': 0.8266907054330072, 'Total loss': 0.8266907054330072}
2022-11-23 00:54:17,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:17,368 INFO:     Epoch: 12
2022-11-23 00:54:18,164 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7882323048331521, 'Total loss': 0.7882323048331521} | train loss {'Reaction outcome loss': 0.8283603782615354, 'Total loss': 0.8283603782615354}
2022-11-23 00:54:18,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:18,164 INFO:     Epoch: 13
2022-11-23 00:54:18,967 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7969733375039968, 'Total loss': 0.7969733375039968} | train loss {'Reaction outcome loss': 0.824006064404403, 'Total loss': 0.824006064404403}
2022-11-23 00:54:18,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:18,968 INFO:     Epoch: 14
2022-11-23 00:54:19,805 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7901541468772021, 'Total loss': 0.7901541468772021} | train loss {'Reaction outcome loss': 0.8236480351657637, 'Total loss': 0.8236480351657637}
2022-11-23 00:54:19,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:19,805 INFO:     Epoch: 15
2022-11-23 00:54:20,626 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7978935492309657, 'Total loss': 0.7978935492309657} | train loss {'Reaction outcome loss': 0.8248128663868673, 'Total loss': 0.8248128663868673}
2022-11-23 00:54:20,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:20,626 INFO:     Epoch: 16
2022-11-23 00:54:21,458 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7770001766356555, 'Total loss': 0.7770001766356555} | train loss {'Reaction outcome loss': 0.8258153994477564, 'Total loss': 0.8258153994477564}
2022-11-23 00:54:21,458 INFO:     Found new best model at epoch 16
2022-11-23 00:54:21,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:21,459 INFO:     Epoch: 17
2022-11-23 00:54:22,270 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7731005535884337, 'Total loss': 0.7731005535884337} | train loss {'Reaction outcome loss': 0.8225096292313068, 'Total loss': 0.8225096292313068}
2022-11-23 00:54:22,270 INFO:     Found new best model at epoch 17
2022-11-23 00:54:22,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:22,271 INFO:     Epoch: 18
2022-11-23 00:54:23,065 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7774392075159333, 'Total loss': 0.7774392075159333} | train loss {'Reaction outcome loss': 0.8198718960967756, 'Total loss': 0.8198718960967756}
2022-11-23 00:54:23,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:23,065 INFO:     Epoch: 19
2022-11-23 00:54:23,840 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7886265414682302, 'Total loss': 0.7886265414682302} | train loss {'Reaction outcome loss': 0.8195634281202671, 'Total loss': 0.8195634281202671}
2022-11-23 00:54:23,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:23,841 INFO:     Epoch: 20
2022-11-23 00:54:24,674 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7909711118448864, 'Total loss': 0.7909711118448864} | train loss {'Reaction outcome loss': 0.8228500901210692, 'Total loss': 0.8228500901210692}
2022-11-23 00:54:24,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:24,675 INFO:     Epoch: 21
2022-11-23 00:54:25,480 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7891167171976783, 'Total loss': 0.7891167171976783} | train loss {'Reaction outcome loss': 0.8149128527410568, 'Total loss': 0.8149128527410568}
2022-11-23 00:54:25,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:25,481 INFO:     Epoch: 22
2022-11-23 00:54:26,323 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7813735956495459, 'Total loss': 0.7813735956495459} | train loss {'Reaction outcome loss': 0.8201653828784343, 'Total loss': 0.8201653828784343}
2022-11-23 00:54:26,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:26,323 INFO:     Epoch: 23
2022-11-23 00:54:27,157 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.774083446372639, 'Total loss': 0.774083446372639} | train loss {'Reaction outcome loss': 0.8201099720693403, 'Total loss': 0.8201099720693403}
2022-11-23 00:54:27,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:27,158 INFO:     Epoch: 24
2022-11-23 00:54:28,009 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7971854602748697, 'Total loss': 0.7971854602748697} | train loss {'Reaction outcome loss': 0.8177358672743843, 'Total loss': 0.8177358672743843}
2022-11-23 00:54:28,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:28,009 INFO:     Epoch: 25
2022-11-23 00:54:28,792 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7992391782728109, 'Total loss': 0.7992391782728109} | train loss {'Reaction outcome loss': 0.823874105729403, 'Total loss': 0.823874105729403}
2022-11-23 00:54:28,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:28,792 INFO:     Epoch: 26
2022-11-23 00:54:29,633 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.788360398601402, 'Total loss': 0.788360398601402} | train loss {'Reaction outcome loss': 0.8208019592829289, 'Total loss': 0.8208019592829289}
2022-11-23 00:54:29,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:29,633 INFO:     Epoch: 27
2022-11-23 00:54:30,499 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7760729586536234, 'Total loss': 0.7760729586536234} | train loss {'Reaction outcome loss': 0.8155197260841247, 'Total loss': 0.8155197260841247}
2022-11-23 00:54:30,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:30,499 INFO:     Epoch: 28
2022-11-23 00:54:31,321 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7780595482750372, 'Total loss': 0.7780595482750372} | train loss {'Reaction outcome loss': 0.8244005082355391, 'Total loss': 0.8244005082355391}
2022-11-23 00:54:31,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:31,322 INFO:     Epoch: 29
2022-11-23 00:54:32,110 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7797940691763704, 'Total loss': 0.7797940691763704} | train loss {'Reaction outcome loss': 0.820208205811439, 'Total loss': 0.820208205811439}
2022-11-23 00:54:32,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:32,110 INFO:     Epoch: 30
2022-11-23 00:54:32,935 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7741905349222097, 'Total loss': 0.7741905349222097} | train loss {'Reaction outcome loss': 0.8225253004460565, 'Total loss': 0.8225253004460565}
2022-11-23 00:54:32,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:32,936 INFO:     Epoch: 31
2022-11-23 00:54:33,725 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7881266339258715, 'Total loss': 0.7881266339258715} | train loss {'Reaction outcome loss': 0.8225874962705758, 'Total loss': 0.8225874962705758}
2022-11-23 00:54:33,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:33,725 INFO:     Epoch: 32
2022-11-23 00:54:34,545 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7752887098626657, 'Total loss': 0.7752887098626657} | train loss {'Reaction outcome loss': 0.82250039664007, 'Total loss': 0.82250039664007}
2022-11-23 00:54:34,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:34,545 INFO:     Epoch: 33
2022-11-23 00:54:35,360 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.787789864296263, 'Total loss': 0.787789864296263} | train loss {'Reaction outcome loss': 0.814539942409723, 'Total loss': 0.814539942409723}
2022-11-23 00:54:35,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:35,360 INFO:     Epoch: 34
2022-11-23 00:54:36,143 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7861143255775626, 'Total loss': 0.7861143255775626} | train loss {'Reaction outcome loss': 0.8202310442443816, 'Total loss': 0.8202310442443816}
2022-11-23 00:54:36,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:36,143 INFO:     Epoch: 35
2022-11-23 00:54:36,966 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7854294797236269, 'Total loss': 0.7854294797236269} | train loss {'Reaction outcome loss': 0.8222883733049515, 'Total loss': 0.8222883733049515}
2022-11-23 00:54:36,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:36,966 INFO:     Epoch: 36
2022-11-23 00:54:37,792 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8143238858743147, 'Total loss': 0.8143238858743147} | train loss {'Reaction outcome loss': 0.8210325195424019, 'Total loss': 0.8210325195424019}
2022-11-23 00:54:37,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:37,793 INFO:     Epoch: 37
2022-11-23 00:54:38,634 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7731503410772844, 'Total loss': 0.7731503410772844} | train loss {'Reaction outcome loss': 0.821047575843911, 'Total loss': 0.821047575843911}
2022-11-23 00:54:38,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:38,635 INFO:     Epoch: 38
2022-11-23 00:54:39,426 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8012481474063613, 'Total loss': 0.8012481474063613} | train loss {'Reaction outcome loss': 0.8164850831512482, 'Total loss': 0.8164850831512482}
2022-11-23 00:54:39,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:39,427 INFO:     Epoch: 39
2022-11-23 00:54:40,250 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7701901732520624, 'Total loss': 0.7701901732520624} | train loss {'Reaction outcome loss': 0.8176949399132882, 'Total loss': 0.8176949399132882}
2022-11-23 00:54:40,251 INFO:     Found new best model at epoch 39
2022-11-23 00:54:40,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:40,251 INFO:     Epoch: 40
2022-11-23 00:54:41,057 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.776065631346269, 'Total loss': 0.776065631346269} | train loss {'Reaction outcome loss': 0.8167396813871399, 'Total loss': 0.8167396813871399}
2022-11-23 00:54:41,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:41,058 INFO:     Epoch: 41
2022-11-23 00:54:41,854 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8004950366236947, 'Total loss': 0.8004950366236947} | train loss {'Reaction outcome loss': 0.8177619348129919, 'Total loss': 0.8177619348129919}
2022-11-23 00:54:41,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:41,854 INFO:     Epoch: 42
2022-11-23 00:54:42,644 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7881022048267451, 'Total loss': 0.7881022048267451} | train loss {'Reaction outcome loss': 0.8177168555557728, 'Total loss': 0.8177168555557728}
2022-11-23 00:54:42,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:42,644 INFO:     Epoch: 43
2022-11-23 00:54:43,474 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7886400290510871, 'Total loss': 0.7886400290510871} | train loss {'Reaction outcome loss': 0.8227439850809113, 'Total loss': 0.8227439850809113}
2022-11-23 00:54:43,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:43,474 INFO:     Epoch: 44
2022-11-23 00:54:44,284 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7892517562616955, 'Total loss': 0.7892517562616955} | train loss {'Reaction outcome loss': 0.8163643049136284, 'Total loss': 0.8163643049136284}
2022-11-23 00:54:44,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:44,284 INFO:     Epoch: 45
2022-11-23 00:54:45,088 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7843335968526927, 'Total loss': 0.7843335968526927} | train loss {'Reaction outcome loss': 0.8132731818383739, 'Total loss': 0.8132731818383739}
2022-11-23 00:54:45,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:45,088 INFO:     Epoch: 46
2022-11-23 00:54:45,902 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7679796625267375, 'Total loss': 0.7679796625267375} | train loss {'Reaction outcome loss': 0.8145262999159675, 'Total loss': 0.8145262999159675}
2022-11-23 00:54:45,903 INFO:     Found new best model at epoch 46
2022-11-23 00:54:45,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:45,904 INFO:     Epoch: 47
2022-11-23 00:54:46,713 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7964254461906173, 'Total loss': 0.7964254461906173} | train loss {'Reaction outcome loss': 0.8211860627897324, 'Total loss': 0.8211860627897324}
2022-11-23 00:54:46,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:46,713 INFO:     Epoch: 48
2022-11-23 00:54:47,528 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7721764154054902, 'Total loss': 0.7721764154054902} | train loss {'Reaction outcome loss': 0.8187117810931898, 'Total loss': 0.8187117810931898}
2022-11-23 00:54:47,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:47,528 INFO:     Epoch: 49
2022-11-23 00:54:48,373 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.833445979790254, 'Total loss': 0.833445979790254} | train loss {'Reaction outcome loss': 0.8170472840147633, 'Total loss': 0.8170472840147633}
2022-11-23 00:54:48,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:48,373 INFO:     Epoch: 50
2022-11-23 00:54:49,189 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7904687334190715, 'Total loss': 0.7904687334190715} | train loss {'Reaction outcome loss': 0.8203708934447458, 'Total loss': 0.8203708934447458}
2022-11-23 00:54:49,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:49,189 INFO:     Epoch: 51
2022-11-23 00:54:49,988 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8032167669047009, 'Total loss': 0.8032167669047009} | train loss {'Reaction outcome loss': 0.8156103448521707, 'Total loss': 0.8156103448521707}
2022-11-23 00:54:49,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:49,988 INFO:     Epoch: 52
2022-11-23 00:54:50,814 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7781921774148941, 'Total loss': 0.7781921774148941} | train loss {'Reaction outcome loss': 0.8152156388086658, 'Total loss': 0.8152156388086658}
2022-11-23 00:54:50,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:50,815 INFO:     Epoch: 53
2022-11-23 00:54:51,607 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7836165353655815, 'Total loss': 0.7836165353655815} | train loss {'Reaction outcome loss': 0.8163180619237884, 'Total loss': 0.8163180619237884}
2022-11-23 00:54:51,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:51,608 INFO:     Epoch: 54
2022-11-23 00:54:52,437 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7750327370383523, 'Total loss': 0.7750327370383523} | train loss {'Reaction outcome loss': 0.818624833778989, 'Total loss': 0.818624833778989}
2022-11-23 00:54:52,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:52,438 INFO:     Epoch: 55
2022-11-23 00:54:53,297 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7854991771958091, 'Total loss': 0.7854991771958091} | train loss {'Reaction outcome loss': 0.8147940447013224, 'Total loss': 0.8147940447013224}
2022-11-23 00:54:53,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:53,297 INFO:     Epoch: 56
2022-11-23 00:54:54,128 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7649361863732338, 'Total loss': 0.7649361863732338} | train loss {'Reaction outcome loss': 0.8185562886778386, 'Total loss': 0.8185562886778386}
2022-11-23 00:54:54,128 INFO:     Found new best model at epoch 56
2022-11-23 00:54:54,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:54,129 INFO:     Epoch: 57
2022-11-23 00:54:54,936 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7797041819854216, 'Total loss': 0.7797041819854216} | train loss {'Reaction outcome loss': 0.8136058452148591, 'Total loss': 0.8136058452148591}
2022-11-23 00:54:54,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:54,936 INFO:     Epoch: 58
2022-11-23 00:54:55,745 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7972093658013777, 'Total loss': 0.7972093658013777} | train loss {'Reaction outcome loss': 0.8172075503295467, 'Total loss': 0.8172075503295467}
2022-11-23 00:54:55,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:55,745 INFO:     Epoch: 59
2022-11-23 00:54:56,555 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7769736349582672, 'Total loss': 0.7769736349582672} | train loss {'Reaction outcome loss': 0.8137553140761391, 'Total loss': 0.8137553140761391}
2022-11-23 00:54:56,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:56,555 INFO:     Epoch: 60
2022-11-23 00:54:57,351 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7824317840012637, 'Total loss': 0.7824317840012637} | train loss {'Reaction outcome loss': 0.8143369365603693, 'Total loss': 0.8143369365603693}
2022-11-23 00:54:57,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:57,351 INFO:     Epoch: 61
2022-11-23 00:54:58,183 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7772914442149076, 'Total loss': 0.7772914442149076} | train loss {'Reaction outcome loss': 0.8124228965851569, 'Total loss': 0.8124228965851569}
2022-11-23 00:54:58,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:58,184 INFO:     Epoch: 62
2022-11-23 00:54:58,979 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7774800698865544, 'Total loss': 0.7774800698865544} | train loss {'Reaction outcome loss': 0.8174197244788369, 'Total loss': 0.8174197244788369}
2022-11-23 00:54:58,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:58,979 INFO:     Epoch: 63
2022-11-23 00:54:59,786 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7836622494188222, 'Total loss': 0.7836622494188222} | train loss {'Reaction outcome loss': 0.8141619977691481, 'Total loss': 0.8141619977691481}
2022-11-23 00:54:59,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:54:59,786 INFO:     Epoch: 64
2022-11-23 00:55:00,597 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7845411124554548, 'Total loss': 0.7845411124554548} | train loss {'Reaction outcome loss': 0.8113462959806765, 'Total loss': 0.8113462959806765}
2022-11-23 00:55:00,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:00,597 INFO:     Epoch: 65
2022-11-23 00:55:01,417 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7717184735970064, 'Total loss': 0.7717184735970064} | train loss {'Reaction outcome loss': 0.8123248090907451, 'Total loss': 0.8123248090907451}
2022-11-23 00:55:01,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:01,417 INFO:     Epoch: 66
2022-11-23 00:55:02,222 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7701397490772334, 'Total loss': 0.7701397490772334} | train loss {'Reaction outcome loss': 0.8186015663368087, 'Total loss': 0.8186015663368087}
2022-11-23 00:55:02,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:02,222 INFO:     Epoch: 67
2022-11-23 00:55:03,046 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7847396914254535, 'Total loss': 0.7847396914254535} | train loss {'Reaction outcome loss': 0.8200132447865701, 'Total loss': 0.8200132447865701}
2022-11-23 00:55:03,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:03,046 INFO:     Epoch: 68
2022-11-23 00:55:03,877 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.770010270178318, 'Total loss': 0.770010270178318} | train loss {'Reaction outcome loss': 0.8195828893972982, 'Total loss': 0.8195828893972982}
2022-11-23 00:55:03,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:03,877 INFO:     Epoch: 69
2022-11-23 00:55:04,731 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7949704690413042, 'Total loss': 0.7949704690413042} | train loss {'Reaction outcome loss': 0.8179205555108285, 'Total loss': 0.8179205555108285}
2022-11-23 00:55:04,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:04,731 INFO:     Epoch: 70
2022-11-23 00:55:05,529 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7736114148389209, 'Total loss': 0.7736114148389209} | train loss {'Reaction outcome loss': 0.8151771820360615, 'Total loss': 0.8151771820360615}
2022-11-23 00:55:05,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:05,530 INFO:     Epoch: 71
2022-11-23 00:55:06,350 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7730987004258416, 'Total loss': 0.7730987004258416} | train loss {'Reaction outcome loss': 0.813001655883366, 'Total loss': 0.813001655883366}
2022-11-23 00:55:06,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:06,350 INFO:     Epoch: 72
2022-11-23 00:55:07,160 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7829553071748127, 'Total loss': 0.7829553071748127} | train loss {'Reaction outcome loss': 0.818181699682628, 'Total loss': 0.818181699682628}
2022-11-23 00:55:07,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:07,161 INFO:     Epoch: 73
2022-11-23 00:55:07,966 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7864746329459277, 'Total loss': 0.7864746329459277} | train loss {'Reaction outcome loss': 0.8108889121682413, 'Total loss': 0.8108889121682413}
2022-11-23 00:55:07,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:07,966 INFO:     Epoch: 74
2022-11-23 00:55:08,804 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7779027609662577, 'Total loss': 0.7779027609662577} | train loss {'Reaction outcome loss': 0.8126185273210849, 'Total loss': 0.8126185273210849}
2022-11-23 00:55:08,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:08,804 INFO:     Epoch: 75
2022-11-23 00:55:09,606 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7768861515955492, 'Total loss': 0.7768861515955492} | train loss {'Reaction outcome loss': 0.8118987712528436, 'Total loss': 0.8118987712528436}
2022-11-23 00:55:09,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:09,606 INFO:     Epoch: 76
2022-11-23 00:55:10,402 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8090437549081716, 'Total loss': 0.8090437549081716} | train loss {'Reaction outcome loss': 0.8122918710352913, 'Total loss': 0.8122918710352913}
2022-11-23 00:55:10,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:10,404 INFO:     Epoch: 77
2022-11-23 00:55:11,267 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.799134303223003, 'Total loss': 0.799134303223003} | train loss {'Reaction outcome loss': 0.8116271771009891, 'Total loss': 0.8116271771009891}
2022-11-23 00:55:11,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:11,267 INFO:     Epoch: 78
2022-11-23 00:55:12,051 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7657526521520182, 'Total loss': 0.7657526521520182} | train loss {'Reaction outcome loss': 0.8183533468794438, 'Total loss': 0.8183533468794438}
2022-11-23 00:55:12,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:12,051 INFO:     Epoch: 79
2022-11-23 00:55:12,840 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7710294628685171, 'Total loss': 0.7710294628685171} | train loss {'Reaction outcome loss': 0.8151234957960344, 'Total loss': 0.8151234957960344}
2022-11-23 00:55:12,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:12,841 INFO:     Epoch: 80
2022-11-23 00:55:13,662 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7897470945661719, 'Total loss': 0.7897470945661719} | train loss {'Reaction outcome loss': 0.814392969853455, 'Total loss': 0.814392969853455}
2022-11-23 00:55:13,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:13,662 INFO:     Epoch: 81
2022-11-23 00:55:14,472 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7749076295982708, 'Total loss': 0.7749076295982708} | train loss {'Reaction outcome loss': 0.8108956407635443, 'Total loss': 0.8108956407635443}
2022-11-23 00:55:14,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:14,472 INFO:     Epoch: 82
2022-11-23 00:55:15,292 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.783411752093922, 'Total loss': 0.783411752093922} | train loss {'Reaction outcome loss': 0.8068267704258042, 'Total loss': 0.8068267704258042}
2022-11-23 00:55:15,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:15,292 INFO:     Epoch: 83
2022-11-23 00:55:16,098 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.802728652276776, 'Total loss': 0.802728652276776} | train loss {'Reaction outcome loss': 0.8132166300089129, 'Total loss': 0.8132166300089129}
2022-11-23 00:55:16,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:16,098 INFO:     Epoch: 84
2022-11-23 00:55:16,932 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7683577727187764, 'Total loss': 0.7683577727187764} | train loss {'Reaction outcome loss': 0.8081401628592322, 'Total loss': 0.8081401628592322}
2022-11-23 00:55:16,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:16,933 INFO:     Epoch: 85
2022-11-23 00:55:17,756 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7951090085235509, 'Total loss': 0.7951090085235509} | train loss {'Reaction outcome loss': 0.8070062642856952, 'Total loss': 0.8070062642856952}
2022-11-23 00:55:17,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:17,756 INFO:     Epoch: 86
2022-11-23 00:55:18,595 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7699876441196962, 'Total loss': 0.7699876441196962} | train loss {'Reaction outcome loss': 0.8131517620096284, 'Total loss': 0.8131517620096284}
2022-11-23 00:55:18,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:18,595 INFO:     Epoch: 87
2022-11-23 00:55:19,410 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7786371213468638, 'Total loss': 0.7786371213468638} | train loss {'Reaction outcome loss': 0.8149562899864489, 'Total loss': 0.8149562899864489}
2022-11-23 00:55:19,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:19,411 INFO:     Epoch: 88
2022-11-23 00:55:20,255 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7734595557505434, 'Total loss': 0.7734595557505434} | train loss {'Reaction outcome loss': 0.8066776483770339, 'Total loss': 0.8066776483770339}
2022-11-23 00:55:20,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:20,255 INFO:     Epoch: 89
2022-11-23 00:55:21,051 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7635842236605558, 'Total loss': 0.7635842236605558} | train loss {'Reaction outcome loss': 0.8107441959361876, 'Total loss': 0.8107441959361876}
2022-11-23 00:55:21,051 INFO:     Found new best model at epoch 89
2022-11-23 00:55:21,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:21,052 INFO:     Epoch: 90
2022-11-23 00:55:21,859 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7688354992053725, 'Total loss': 0.7688354992053725} | train loss {'Reaction outcome loss': 0.8104061665794542, 'Total loss': 0.8104061665794542}
2022-11-23 00:55:21,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:21,859 INFO:     Epoch: 91
2022-11-23 00:55:22,677 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7800758020444349, 'Total loss': 0.7800758020444349} | train loss {'Reaction outcome loss': 0.8146462778170263, 'Total loss': 0.8146462778170263}
2022-11-23 00:55:22,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:22,677 INFO:     Epoch: 92
2022-11-23 00:55:23,472 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7646454030817206, 'Total loss': 0.7646454030817206} | train loss {'Reaction outcome loss': 0.8089676579881099, 'Total loss': 0.8089676579881099}
2022-11-23 00:55:23,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:23,472 INFO:     Epoch: 93
2022-11-23 00:55:24,276 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7773939736864783, 'Total loss': 0.7773939736864783} | train loss {'Reaction outcome loss': 0.814458150296442, 'Total loss': 0.814458150296442}
2022-11-23 00:55:24,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:24,276 INFO:     Epoch: 94
2022-11-23 00:55:25,061 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7737887813286348, 'Total loss': 0.7737887813286348} | train loss {'Reaction outcome loss': 0.8091591212057299, 'Total loss': 0.8091591212057299}
2022-11-23 00:55:25,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:25,062 INFO:     Epoch: 95
2022-11-23 00:55:25,826 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7699498601935126, 'Total loss': 0.7699498601935126} | train loss {'Reaction outcome loss': 0.8064645592483782, 'Total loss': 0.8064645592483782}
2022-11-23 00:55:25,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:25,826 INFO:     Epoch: 96
2022-11-23 00:55:26,649 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7648698328570886, 'Total loss': 0.7648698328570886} | train loss {'Reaction outcome loss': 0.8108475049657207, 'Total loss': 0.8108475049657207}
2022-11-23 00:55:26,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:26,649 INFO:     Epoch: 97
2022-11-23 00:55:27,495 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7731415243311361, 'Total loss': 0.7731415243311361} | train loss {'Reaction outcome loss': 0.8160735521345369, 'Total loss': 0.8160735521345369}
2022-11-23 00:55:27,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:27,495 INFO:     Epoch: 98
2022-11-23 00:55:28,293 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7764070386236365, 'Total loss': 0.7764070386236365} | train loss {'Reaction outcome loss': 0.8072034074894844, 'Total loss': 0.8072034074894844}
2022-11-23 00:55:28,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:28,294 INFO:     Epoch: 99
2022-11-23 00:55:29,124 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7688980840823867, 'Total loss': 0.7688980840823867} | train loss {'Reaction outcome loss': 0.8104049010622886, 'Total loss': 0.8104049010622886}
2022-11-23 00:55:29,124 INFO:     Best model found after epoch 90 of 100.
2022-11-23 00:55:29,125 INFO:   Done with stage: TRAINING
2022-11-23 00:55:29,125 INFO:   Starting stage: EVALUATION
2022-11-23 00:55:29,244 INFO:   Done with stage: EVALUATION
2022-11-23 00:55:29,244 INFO:   Leaving out SEQ value Fold_6
2022-11-23 00:55:29,257 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-23 00:55:29,257 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:55:29,938 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:55:29,938 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:55:30,007 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:55:30,008 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:55:30,008 INFO:     No hyperparam tuning for this model
2022-11-23 00:55:30,008 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:55:30,008 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:55:30,009 INFO:     None feature selector for col prot
2022-11-23 00:55:30,009 INFO:     None feature selector for col prot
2022-11-23 00:55:30,009 INFO:     None feature selector for col prot
2022-11-23 00:55:30,009 INFO:     None feature selector for col chem
2022-11-23 00:55:30,010 INFO:     None feature selector for col chem
2022-11-23 00:55:30,010 INFO:     None feature selector for col chem
2022-11-23 00:55:30,010 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:55:30,010 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:55:30,011 INFO:     Number of params in model 168571
2022-11-23 00:55:30,015 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:55:30,015 INFO:   Starting stage: TRAINING
2022-11-23 00:55:30,074 INFO:     Val loss before train {'Reaction outcome loss': 0.9888219142502005, 'Total loss': 0.9888219142502005}
2022-11-23 00:55:30,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:30,074 INFO:     Epoch: 0
2022-11-23 00:55:30,869 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8529732132499869, 'Total loss': 0.8529732132499869} | train loss {'Reaction outcome loss': 0.8795030340856436, 'Total loss': 0.8795030340856436}
2022-11-23 00:55:30,869 INFO:     Found new best model at epoch 0
2022-11-23 00:55:30,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:30,870 INFO:     Epoch: 1
2022-11-23 00:55:31,654 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8307967226613652, 'Total loss': 0.8307967226613652} | train loss {'Reaction outcome loss': 0.8468110135623387, 'Total loss': 0.8468110135623387}
2022-11-23 00:55:31,654 INFO:     Found new best model at epoch 1
2022-11-23 00:55:31,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:31,655 INFO:     Epoch: 2
2022-11-23 00:55:32,447 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.808822250501676, 'Total loss': 0.808822250501676} | train loss {'Reaction outcome loss': 0.8369344216220233, 'Total loss': 0.8369344216220233}
2022-11-23 00:55:32,447 INFO:     Found new best model at epoch 2
2022-11-23 00:55:32,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:32,448 INFO:     Epoch: 3
2022-11-23 00:55:33,257 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7936261404644359, 'Total loss': 0.7936261404644359} | train loss {'Reaction outcome loss': 0.8395123562034296, 'Total loss': 0.8395123562034296}
2022-11-23 00:55:33,257 INFO:     Found new best model at epoch 3
2022-11-23 00:55:33,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:33,258 INFO:     Epoch: 4
2022-11-23 00:55:34,101 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8177155168219046, 'Total loss': 0.8177155168219046} | train loss {'Reaction outcome loss': 0.8345082151646517, 'Total loss': 0.8345082151646517}
2022-11-23 00:55:34,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:34,101 INFO:     Epoch: 5
2022-11-23 00:55:34,942 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7999385480176319, 'Total loss': 0.7999385480176319} | train loss {'Reaction outcome loss': 0.8305000734572507, 'Total loss': 0.8305000734572507}
2022-11-23 00:55:34,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:34,943 INFO:     Epoch: 6
2022-11-23 00:55:35,722 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.80749281428077, 'Total loss': 0.80749281428077} | train loss {'Reaction outcome loss': 0.8274203524297598, 'Total loss': 0.8274203524297598}
2022-11-23 00:55:35,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:35,722 INFO:     Epoch: 7
2022-11-23 00:55:36,532 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7884085686369375, 'Total loss': 0.7884085686369375} | train loss {'Reaction outcome loss': 0.8242863483574926, 'Total loss': 0.8242863483574926}
2022-11-23 00:55:36,532 INFO:     Found new best model at epoch 7
2022-11-23 00:55:36,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:36,533 INFO:     Epoch: 8
2022-11-23 00:55:37,351 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8128054331649434, 'Total loss': 0.8128054331649434} | train loss {'Reaction outcome loss': 0.8245795579589144, 'Total loss': 0.8245795579589144}
2022-11-23 00:55:37,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:37,351 INFO:     Epoch: 9
2022-11-23 00:55:38,185 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8028437488458373, 'Total loss': 0.8028437488458373} | train loss {'Reaction outcome loss': 0.8260914216236193, 'Total loss': 0.8260914216236193}
2022-11-23 00:55:38,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:38,185 INFO:     Epoch: 10
2022-11-23 00:55:39,023 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8098336837508462, 'Total loss': 0.8098336837508462} | train loss {'Reaction outcome loss': 0.8205605139537734, 'Total loss': 0.8205605139537734}
2022-11-23 00:55:39,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:39,023 INFO:     Epoch: 11
2022-11-23 00:55:39,860 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.807261817834594, 'Total loss': 0.807261817834594} | train loss {'Reaction outcome loss': 0.8223365109793994, 'Total loss': 0.8223365109793994}
2022-11-23 00:55:39,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:39,861 INFO:     Epoch: 12
2022-11-23 00:55:40,638 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7981558713045988, 'Total loss': 0.7981558713045988} | train loss {'Reaction outcome loss': 0.8219493643361695, 'Total loss': 0.8219493643361695}
2022-11-23 00:55:40,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:40,639 INFO:     Epoch: 13
2022-11-23 00:55:41,412 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8173234923319384, 'Total loss': 0.8173234923319384} | train loss {'Reaction outcome loss': 0.8203955478814183, 'Total loss': 0.8203955478814183}
2022-11-23 00:55:41,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:41,413 INFO:     Epoch: 14
2022-11-23 00:55:42,206 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7927737527272918, 'Total loss': 0.7927737527272918} | train loss {'Reaction outcome loss': 0.8216545388406636, 'Total loss': 0.8216545388406636}
2022-11-23 00:55:42,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:42,207 INFO:     Epoch: 15
2022-11-23 00:55:42,988 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8351715647361495, 'Total loss': 0.8351715647361495} | train loss {'Reaction outcome loss': 0.8191486363508264, 'Total loss': 0.8191486363508264}
2022-11-23 00:55:42,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:42,988 INFO:     Epoch: 16
2022-11-23 00:55:43,755 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8029079423709349, 'Total loss': 0.8029079423709349} | train loss {'Reaction outcome loss': 0.8201164012052575, 'Total loss': 0.8201164012052575}
2022-11-23 00:55:43,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:43,756 INFO:     Epoch: 17
2022-11-23 00:55:44,558 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8180914561856877, 'Total loss': 0.8180914561856877} | train loss {'Reaction outcome loss': 0.8156522777615761, 'Total loss': 0.8156522777615761}
2022-11-23 00:55:44,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:44,558 INFO:     Epoch: 18
2022-11-23 00:55:45,395 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7936415719715032, 'Total loss': 0.7936415719715032} | train loss {'Reaction outcome loss': 0.8184700302931727, 'Total loss': 0.8184700302931727}
2022-11-23 00:55:45,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:45,395 INFO:     Epoch: 19
2022-11-23 00:55:46,184 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7846366397359155, 'Total loss': 0.7846366397359155} | train loss {'Reaction outcome loss': 0.8171478452731152, 'Total loss': 0.8171478452731152}
2022-11-23 00:55:46,184 INFO:     Found new best model at epoch 19
2022-11-23 00:55:46,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:46,185 INFO:     Epoch: 20
2022-11-23 00:55:47,039 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8056519708850167, 'Total loss': 0.8056519708850167} | train loss {'Reaction outcome loss': 0.8117316293473147, 'Total loss': 0.8117316293473147}
2022-11-23 00:55:47,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:47,039 INFO:     Epoch: 21
2022-11-23 00:55:47,871 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7825840237465772, 'Total loss': 0.7825840237465772} | train loss {'Reaction outcome loss': 0.8219545404521786, 'Total loss': 0.8219545404521786}
2022-11-23 00:55:47,871 INFO:     Found new best model at epoch 21
2022-11-23 00:55:47,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:47,872 INFO:     Epoch: 22
2022-11-23 00:55:48,658 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7936783534559336, 'Total loss': 0.7936783534559336} | train loss {'Reaction outcome loss': 0.8173092710728548, 'Total loss': 0.8173092710728548}
2022-11-23 00:55:48,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:48,658 INFO:     Epoch: 23
2022-11-23 00:55:49,444 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7950353994965553, 'Total loss': 0.7950353994965553} | train loss {'Reaction outcome loss': 0.811160305446508, 'Total loss': 0.811160305446508}
2022-11-23 00:55:49,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:49,445 INFO:     Epoch: 24
2022-11-23 00:55:50,260 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7820069776339964, 'Total loss': 0.7820069776339964} | train loss {'Reaction outcome loss': 0.8162744946625768, 'Total loss': 0.8162744946625768}
2022-11-23 00:55:50,260 INFO:     Found new best model at epoch 24
2022-11-23 00:55:50,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:50,261 INFO:     Epoch: 25
2022-11-23 00:55:51,031 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7852543423121626, 'Total loss': 0.7852543423121626} | train loss {'Reaction outcome loss': 0.8166661230885253, 'Total loss': 0.8166661230885253}
2022-11-23 00:55:51,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:51,032 INFO:     Epoch: 26
2022-11-23 00:55:51,832 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8031743490560488, 'Total loss': 0.8031743490560488} | train loss {'Reaction outcome loss': 0.8143758545116503, 'Total loss': 0.8143758545116503}
2022-11-23 00:55:51,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:51,832 INFO:     Epoch: 27
2022-11-23 00:55:52,604 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7827683185989206, 'Total loss': 0.7827683185989206} | train loss {'Reaction outcome loss': 0.8158683016592142, 'Total loss': 0.8158683016592142}
2022-11-23 00:55:52,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:52,604 INFO:     Epoch: 28
2022-11-23 00:55:53,461 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7745414132421667, 'Total loss': 0.7745414132421667} | train loss {'Reaction outcome loss': 0.8128189792438429, 'Total loss': 0.8128189792438429}
2022-11-23 00:55:53,461 INFO:     Found new best model at epoch 28
2022-11-23 00:55:53,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:53,462 INFO:     Epoch: 29
2022-11-23 00:55:54,283 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7885200015523217, 'Total loss': 0.7885200015523217} | train loss {'Reaction outcome loss': 0.8140986078855943, 'Total loss': 0.8140986078855943}
2022-11-23 00:55:54,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:54,283 INFO:     Epoch: 30
2022-11-23 00:55:55,134 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7864237454804507, 'Total loss': 0.7864237454804507} | train loss {'Reaction outcome loss': 0.8140129866648693, 'Total loss': 0.8140129866648693}
2022-11-23 00:55:55,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:55,135 INFO:     Epoch: 31
2022-11-23 00:55:55,922 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8142530897801573, 'Total loss': 0.8142530897801573} | train loss {'Reaction outcome loss': 0.8157013637678964, 'Total loss': 0.8157013637678964}
2022-11-23 00:55:55,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:55,922 INFO:     Epoch: 32
2022-11-23 00:55:56,725 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.802944768558849, 'Total loss': 0.802944768558849} | train loss {'Reaction outcome loss': 0.8159302487665293, 'Total loss': 0.8159302487665293}
2022-11-23 00:55:56,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:56,726 INFO:     Epoch: 33
2022-11-23 00:55:57,547 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8384985131296244, 'Total loss': 0.8384985131296244} | train loss {'Reaction outcome loss': 0.8147559982173297, 'Total loss': 0.8147559982173297}
2022-11-23 00:55:57,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:57,548 INFO:     Epoch: 34
2022-11-23 00:55:58,377 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.787746555425904, 'Total loss': 0.787746555425904} | train loss {'Reaction outcome loss': 0.81513564392012, 'Total loss': 0.81513564392012}
2022-11-23 00:55:58,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:58,377 INFO:     Epoch: 35
2022-11-23 00:55:59,271 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.786555254323916, 'Total loss': 0.786555254323916} | train loss {'Reaction outcome loss': 0.8101484279243314, 'Total loss': 0.8101484279243314}
2022-11-23 00:55:59,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:55:59,272 INFO:     Epoch: 36
2022-11-23 00:56:00,157 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8356329817324877, 'Total loss': 0.8356329817324877} | train loss {'Reaction outcome loss': 0.8180889826648089, 'Total loss': 0.8180889826648089}
2022-11-23 00:56:00,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:00,158 INFO:     Epoch: 37
2022-11-23 00:56:01,029 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7841756939888, 'Total loss': 0.7841756939888} | train loss {'Reaction outcome loss': 0.813088900459056, 'Total loss': 0.813088900459056}
2022-11-23 00:56:01,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:01,030 INFO:     Epoch: 38
2022-11-23 00:56:01,893 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8233879669146105, 'Total loss': 0.8233879669146105} | train loss {'Reaction outcome loss': 0.8145214811879762, 'Total loss': 0.8145214811879762}
2022-11-23 00:56:01,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:01,893 INFO:     Epoch: 39
2022-11-23 00:56:02,733 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.778311564756388, 'Total loss': 0.778311564756388} | train loss {'Reaction outcome loss': 0.8176078888834739, 'Total loss': 0.8176078888834739}
2022-11-23 00:56:02,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:02,733 INFO:     Epoch: 40
2022-11-23 00:56:03,607 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7816483629020777, 'Total loss': 0.7816483629020777} | train loss {'Reaction outcome loss': 0.819141030798153, 'Total loss': 0.819141030798153}
2022-11-23 00:56:03,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:03,607 INFO:     Epoch: 41
2022-11-23 00:56:04,418 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7846209068189968, 'Total loss': 0.7846209068189968} | train loss {'Reaction outcome loss': 0.8141132349870643, 'Total loss': 0.8141132349870643}
2022-11-23 00:56:04,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:04,418 INFO:     Epoch: 42
2022-11-23 00:56:05,177 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7993602827191353, 'Total loss': 0.7993602827191353} | train loss {'Reaction outcome loss': 0.8090619722191168, 'Total loss': 0.8090619722191168}
2022-11-23 00:56:05,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:05,177 INFO:     Epoch: 43
2022-11-23 00:56:05,995 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8140591328794305, 'Total loss': 0.8140591328794305} | train loss {'Reaction outcome loss': 0.8159394103653577, 'Total loss': 0.8159394103653577}
2022-11-23 00:56:05,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:05,995 INFO:     Epoch: 44
2022-11-23 00:56:06,845 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7936152341690931, 'Total loss': 0.7936152341690931} | train loss {'Reaction outcome loss': 0.8179312231589336, 'Total loss': 0.8179312231589336}
2022-11-23 00:56:06,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:06,845 INFO:     Epoch: 45
2022-11-23 00:56:07,677 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7789025347341191, 'Total loss': 0.7789025347341191} | train loss {'Reaction outcome loss': 0.8101945840582556, 'Total loss': 0.8101945840582556}
2022-11-23 00:56:07,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:07,677 INFO:     Epoch: 46
2022-11-23 00:56:08,521 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7987236678600311, 'Total loss': 0.7987236678600311} | train loss {'Reaction outcome loss': 0.8154083204512693, 'Total loss': 0.8154083204512693}
2022-11-23 00:56:08,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:08,521 INFO:     Epoch: 47
2022-11-23 00:56:09,314 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.791272602298043, 'Total loss': 0.791272602298043} | train loss {'Reaction outcome loss': 0.8110088956599333, 'Total loss': 0.8110088956599333}
2022-11-23 00:56:09,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:09,314 INFO:     Epoch: 48
2022-11-23 00:56:10,112 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.787884263152426, 'Total loss': 0.787884263152426} | train loss {'Reaction outcome loss': 0.8101101430094972, 'Total loss': 0.8101101430094972}
2022-11-23 00:56:10,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:10,112 INFO:     Epoch: 49
2022-11-23 00:56:10,927 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7959392937746915, 'Total loss': 0.7959392937746915} | train loss {'Reaction outcome loss': 0.8108220105268518, 'Total loss': 0.8108220105268518}
2022-11-23 00:56:10,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:10,927 INFO:     Epoch: 50
2022-11-23 00:56:11,766 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7734261426058683, 'Total loss': 0.7734261426058683} | train loss {'Reaction outcome loss': 0.8110730348801126, 'Total loss': 0.8110730348801126}
2022-11-23 00:56:11,766 INFO:     Found new best model at epoch 50
2022-11-23 00:56:11,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:11,767 INFO:     Epoch: 51
2022-11-23 00:56:12,575 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7873122509230267, 'Total loss': 0.7873122509230267} | train loss {'Reaction outcome loss': 0.8103565688035926, 'Total loss': 0.8103565688035926}
2022-11-23 00:56:12,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:12,577 INFO:     Epoch: 52
2022-11-23 00:56:13,381 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7702506184577942, 'Total loss': 0.7702506184577942} | train loss {'Reaction outcome loss': 0.8142352501956784, 'Total loss': 0.8142352501956784}
2022-11-23 00:56:13,381 INFO:     Found new best model at epoch 52
2022-11-23 00:56:13,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:13,382 INFO:     Epoch: 53
2022-11-23 00:56:14,137 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7892421660098162, 'Total loss': 0.7892421660098162} | train loss {'Reaction outcome loss': 0.8151666376055503, 'Total loss': 0.8151666376055503}
2022-11-23 00:56:14,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:14,137 INFO:     Epoch: 54
2022-11-23 00:56:14,914 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8669581345536492, 'Total loss': 0.8669581345536492} | train loss {'Reaction outcome loss': 0.810415333387803, 'Total loss': 0.810415333387803}
2022-11-23 00:56:14,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:14,915 INFO:     Epoch: 55
2022-11-23 00:56:15,718 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7884453304789283, 'Total loss': 0.7884453304789283} | train loss {'Reaction outcome loss': 0.8153397578365948, 'Total loss': 0.8153397578365948}
2022-11-23 00:56:15,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:15,719 INFO:     Epoch: 56
2022-11-23 00:56:16,494 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.785673858767206, 'Total loss': 0.785673858767206} | train loss {'Reaction outcome loss': 0.8073281185967581, 'Total loss': 0.8073281185967581}
2022-11-23 00:56:16,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:16,495 INFO:     Epoch: 57
2022-11-23 00:56:17,313 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8249997814947908, 'Total loss': 0.8249997814947908} | train loss {'Reaction outcome loss': 0.8110476628858216, 'Total loss': 0.8110476628858216}
2022-11-23 00:56:17,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:17,313 INFO:     Epoch: 58
2022-11-23 00:56:18,150 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7947869802063162, 'Total loss': 0.7947869802063162} | train loss {'Reaction outcome loss': 0.8089360604480821, 'Total loss': 0.8089360604480821}
2022-11-23 00:56:18,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:18,151 INFO:     Epoch: 59
2022-11-23 00:56:18,929 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7879422415386547, 'Total loss': 0.7879422415386547} | train loss {'Reaction outcome loss': 0.8075061612591452, 'Total loss': 0.8075061612591452}
2022-11-23 00:56:18,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:18,930 INFO:     Epoch: 60
2022-11-23 00:56:19,769 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7835107892751694, 'Total loss': 0.7835107892751694} | train loss {'Reaction outcome loss': 0.8105759255740107, 'Total loss': 0.8105759255740107}
2022-11-23 00:56:19,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:19,770 INFO:     Epoch: 61
2022-11-23 00:56:20,568 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7910162196917967, 'Total loss': 0.7910162196917967} | train loss {'Reaction outcome loss': 0.8180403961210835, 'Total loss': 0.8180403961210835}
2022-11-23 00:56:20,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:20,568 INFO:     Epoch: 62
2022-11-23 00:56:21,388 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7811453992670233, 'Total loss': 0.7811453992670233} | train loss {'Reaction outcome loss': 0.8104727578406431, 'Total loss': 0.8104727578406431}
2022-11-23 00:56:21,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:21,388 INFO:     Epoch: 63
2022-11-23 00:56:22,156 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7869840453971516, 'Total loss': 0.7869840453971516} | train loss {'Reaction outcome loss': 0.8088036632051273, 'Total loss': 0.8088036632051273}
2022-11-23 00:56:22,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:22,156 INFO:     Epoch: 64
2022-11-23 00:56:22,917 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7597229785539887, 'Total loss': 0.7597229785539887} | train loss {'Reaction outcome loss': 0.8079616499190427, 'Total loss': 0.8079616499190427}
2022-11-23 00:56:22,917 INFO:     Found new best model at epoch 64
2022-11-23 00:56:22,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:22,918 INFO:     Epoch: 65
2022-11-23 00:56:23,700 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.781407353552905, 'Total loss': 0.781407353552905} | train loss {'Reaction outcome loss': 0.8120427173011157, 'Total loss': 0.8120427173011157}
2022-11-23 00:56:23,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:23,700 INFO:     Epoch: 66
2022-11-23 00:56:24,517 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7837302596731619, 'Total loss': 0.7837302596731619} | train loss {'Reaction outcome loss': 0.8112032186011879, 'Total loss': 0.8112032186011879}
2022-11-23 00:56:24,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:24,517 INFO:     Epoch: 67
2022-11-23 00:56:25,352 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7856835533272136, 'Total loss': 0.7856835533272136} | train loss {'Reaction outcome loss': 0.8120222527153638, 'Total loss': 0.8120222527153638}
2022-11-23 00:56:25,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:25,352 INFO:     Epoch: 68
2022-11-23 00:56:26,114 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7677692967382345, 'Total loss': 0.7677692967382345} | train loss {'Reaction outcome loss': 0.8072766823428018, 'Total loss': 0.8072766823428018}
2022-11-23 00:56:26,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:26,114 INFO:     Epoch: 69
2022-11-23 00:56:26,882 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7917189706455577, 'Total loss': 0.7917189706455577} | train loss {'Reaction outcome loss': 0.8095425997461592, 'Total loss': 0.8095425997461592}
2022-11-23 00:56:26,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:26,882 INFO:     Epoch: 70
2022-11-23 00:56:27,649 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8198526162992824, 'Total loss': 0.8198526162992824} | train loss {'Reaction outcome loss': 0.810102884501827, 'Total loss': 0.810102884501827}
2022-11-23 00:56:27,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:27,649 INFO:     Epoch: 71
2022-11-23 00:56:28,437 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7895983796228062, 'Total loss': 0.7895983796228062} | train loss {'Reaction outcome loss': 0.8124721185285217, 'Total loss': 0.8124721185285217}
2022-11-23 00:56:28,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:28,437 INFO:     Epoch: 72
2022-11-23 00:56:29,242 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.770086214623668, 'Total loss': 0.770086214623668} | train loss {'Reaction outcome loss': 0.814898418528693, 'Total loss': 0.814898418528693}
2022-11-23 00:56:29,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:29,242 INFO:     Epoch: 73
2022-11-23 00:56:30,050 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7876617759466171, 'Total loss': 0.7876617759466171} | train loss {'Reaction outcome loss': 0.8083486930448182, 'Total loss': 0.8083486930448182}
2022-11-23 00:56:30,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:30,050 INFO:     Epoch: 74
2022-11-23 00:56:30,890 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7776599763469263, 'Total loss': 0.7776599763469263} | train loss {'Reaction outcome loss': 0.8098549404922797, 'Total loss': 0.8098549404922797}
2022-11-23 00:56:30,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:30,890 INFO:     Epoch: 75
2022-11-23 00:56:31,726 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7675156241113489, 'Total loss': 0.7675156241113489} | train loss {'Reaction outcome loss': 0.8139746468894336, 'Total loss': 0.8139746468894336}
2022-11-23 00:56:31,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:31,727 INFO:     Epoch: 76
2022-11-23 00:56:32,536 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7854601002552293, 'Total loss': 0.7854601002552293} | train loss {'Reaction outcome loss': 0.8103952877375544, 'Total loss': 0.8103952877375544}
2022-11-23 00:56:32,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:32,536 INFO:     Epoch: 77
2022-11-23 00:56:33,312 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8000501638109033, 'Total loss': 0.8000501638109033} | train loss {'Reaction outcome loss': 0.810434626681464, 'Total loss': 0.810434626681464}
2022-11-23 00:56:33,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:33,313 INFO:     Epoch: 78
2022-11-23 00:56:34,064 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7698631862347777, 'Total loss': 0.7698631862347777} | train loss {'Reaction outcome loss': 0.8113907959996437, 'Total loss': 0.8113907959996437}
2022-11-23 00:56:34,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:34,064 INFO:     Epoch: 79
2022-11-23 00:56:34,837 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8075676919384436, 'Total loss': 0.8075676919384436} | train loss {'Reaction outcome loss': 0.8106053745260045, 'Total loss': 0.8106053745260045}
2022-11-23 00:56:34,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:34,837 INFO:     Epoch: 80
2022-11-23 00:56:35,610 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7840068252249197, 'Total loss': 0.7840068252249197} | train loss {'Reaction outcome loss': 0.8141190264906202, 'Total loss': 0.8141190264906202}
2022-11-23 00:56:35,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:35,611 INFO:     Epoch: 81
2022-11-23 00:56:36,400 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8103640970181335, 'Total loss': 0.8103640970181335} | train loss {'Reaction outcome loss': 0.8102748121534075, 'Total loss': 0.8102748121534075}
2022-11-23 00:56:36,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:36,400 INFO:     Epoch: 82
2022-11-23 00:56:37,184 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8140881434082985, 'Total loss': 0.8140881434082985} | train loss {'Reaction outcome loss': 0.8125840601872425, 'Total loss': 0.8125840601872425}
2022-11-23 00:56:37,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:37,184 INFO:     Epoch: 83
2022-11-23 00:56:37,974 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7735754529183562, 'Total loss': 0.7735754529183562} | train loss {'Reaction outcome loss': 0.8114807564385084, 'Total loss': 0.8114807564385084}
2022-11-23 00:56:37,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:37,974 INFO:     Epoch: 84
2022-11-23 00:56:38,744 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7677078545093536, 'Total loss': 0.7677078545093536} | train loss {'Reaction outcome loss': 0.8128378203936986, 'Total loss': 0.8128378203936986}
2022-11-23 00:56:38,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:38,744 INFO:     Epoch: 85
2022-11-23 00:56:39,527 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7862988195636056, 'Total loss': 0.7862988195636056} | train loss {'Reaction outcome loss': 0.8116389157820721, 'Total loss': 0.8116389157820721}
2022-11-23 00:56:39,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:39,528 INFO:     Epoch: 86
2022-11-23 00:56:40,335 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7977963618256829, 'Total loss': 0.7977963618256829} | train loss {'Reaction outcome loss': 0.8127032228878566, 'Total loss': 0.8127032228878566}
2022-11-23 00:56:40,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:40,335 INFO:     Epoch: 87
2022-11-23 00:56:41,091 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7898795503106985, 'Total loss': 0.7898795503106985} | train loss {'Reaction outcome loss': 0.8084451061122272, 'Total loss': 0.8084451061122272}
2022-11-23 00:56:41,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:41,091 INFO:     Epoch: 88
2022-11-23 00:56:41,868 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8243255628780886, 'Total loss': 0.8243255628780886} | train loss {'Reaction outcome loss': 0.8131579559676502, 'Total loss': 0.8131579559676502}
2022-11-23 00:56:41,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:41,868 INFO:     Epoch: 89
2022-11-23 00:56:42,636 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.785115050998601, 'Total loss': 0.785115050998601} | train loss {'Reaction outcome loss': 0.8089322860143623, 'Total loss': 0.8089322860143623}
2022-11-23 00:56:42,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:42,636 INFO:     Epoch: 90
2022-11-23 00:56:43,423 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7764337184754285, 'Total loss': 0.7764337184754285} | train loss {'Reaction outcome loss': 0.8097686512129647, 'Total loss': 0.8097686512129647}
2022-11-23 00:56:43,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:43,424 INFO:     Epoch: 91
2022-11-23 00:56:44,177 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7772022844715551, 'Total loss': 0.7772022844715551} | train loss {'Reaction outcome loss': 0.8099978487102353, 'Total loss': 0.8099978487102353}
2022-11-23 00:56:44,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:44,177 INFO:     Epoch: 92
2022-11-23 00:56:44,962 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8186414086005904, 'Total loss': 0.8186414086005904} | train loss {'Reaction outcome loss': 0.8116681117184308, 'Total loss': 0.8116681117184308}
2022-11-23 00:56:44,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:44,962 INFO:     Epoch: 93
2022-11-23 00:56:45,744 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7872298793359236, 'Total loss': 0.7872298793359236} | train loss {'Reaction outcome loss': 0.8119605710311811, 'Total loss': 0.8119605710311811}
2022-11-23 00:56:45,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:45,744 INFO:     Epoch: 94
2022-11-23 00:56:46,518 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7917281497608532, 'Total loss': 0.7917281497608532} | train loss {'Reaction outcome loss': 0.8043044915004652, 'Total loss': 0.8043044915004652}
2022-11-23 00:56:46,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:46,518 INFO:     Epoch: 95
2022-11-23 00:56:47,280 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7641923176971349, 'Total loss': 0.7641923176971349} | train loss {'Reaction outcome loss': 0.8116821630876891, 'Total loss': 0.8116821630876891}
2022-11-23 00:56:47,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:47,280 INFO:     Epoch: 96
2022-11-23 00:56:48,066 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7857525910843502, 'Total loss': 0.7857525910843502} | train loss {'Reaction outcome loss': 0.8124430427745897, 'Total loss': 0.8124430427745897}
2022-11-23 00:56:48,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:48,066 INFO:     Epoch: 97
2022-11-23 00:56:48,811 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7916229197924788, 'Total loss': 0.7916229197924788} | train loss {'Reaction outcome loss': 0.808689603635243, 'Total loss': 0.808689603635243}
2022-11-23 00:56:48,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:48,812 INFO:     Epoch: 98
2022-11-23 00:56:49,551 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7755399034781889, 'Total loss': 0.7755399034781889} | train loss {'Reaction outcome loss': 0.8068468506238898, 'Total loss': 0.8068468506238898}
2022-11-23 00:56:49,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:49,552 INFO:     Epoch: 99
2022-11-23 00:56:50,332 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7953713915564797, 'Total loss': 0.7953713915564797} | train loss {'Reaction outcome loss': 0.8107881626304315, 'Total loss': 0.8107881626304315}
2022-11-23 00:56:50,333 INFO:     Best model found after epoch 65 of 100.
2022-11-23 00:56:50,333 INFO:   Done with stage: TRAINING
2022-11-23 00:56:50,333 INFO:   Starting stage: EVALUATION
2022-11-23 00:56:50,463 INFO:   Done with stage: EVALUATION
2022-11-23 00:56:50,464 INFO:   Leaving out SEQ value Fold_7
2022-11-23 00:56:50,477 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-23 00:56:50,477 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:56:51,149 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:56:51,149 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:56:51,219 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:56:51,219 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:56:51,219 INFO:     No hyperparam tuning for this model
2022-11-23 00:56:51,219 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:56:51,219 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:56:51,220 INFO:     None feature selector for col prot
2022-11-23 00:56:51,220 INFO:     None feature selector for col prot
2022-11-23 00:56:51,220 INFO:     None feature selector for col prot
2022-11-23 00:56:51,221 INFO:     None feature selector for col chem
2022-11-23 00:56:51,221 INFO:     None feature selector for col chem
2022-11-23 00:56:51,221 INFO:     None feature selector for col chem
2022-11-23 00:56:51,221 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:56:51,221 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:56:51,223 INFO:     Number of params in model 168571
2022-11-23 00:56:51,226 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:56:51,226 INFO:   Starting stage: TRAINING
2022-11-23 00:56:51,284 INFO:     Val loss before train {'Reaction outcome loss': 1.08320592072877, 'Total loss': 1.08320592072877}
2022-11-23 00:56:51,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:51,284 INFO:     Epoch: 0
2022-11-23 00:56:52,088 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.885926487093622, 'Total loss': 0.885926487093622} | train loss {'Reaction outcome loss': 0.8670625208591928, 'Total loss': 0.8670625208591928}
2022-11-23 00:56:52,089 INFO:     Found new best model at epoch 0
2022-11-23 00:56:52,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:52,089 INFO:     Epoch: 1
2022-11-23 00:56:52,885 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8997825113209811, 'Total loss': 0.8997825113209811} | train loss {'Reaction outcome loss': 0.8389548628914113, 'Total loss': 0.8389548628914113}
2022-11-23 00:56:52,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:52,885 INFO:     Epoch: 2
2022-11-23 00:56:53,708 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.9053781567649408, 'Total loss': 0.9053781567649408} | train loss {'Reaction outcome loss': 0.8354699327021229, 'Total loss': 0.8354699327021229}
2022-11-23 00:56:53,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:53,708 INFO:     Epoch: 3
2022-11-23 00:56:54,483 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8900274336338043, 'Total loss': 0.8900274336338043} | train loss {'Reaction outcome loss': 0.8282985514524032, 'Total loss': 0.8282985514524032}
2022-11-23 00:56:54,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:54,483 INFO:     Epoch: 4
2022-11-23 00:56:55,286 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8723828088153492, 'Total loss': 0.8723828088153492} | train loss {'Reaction outcome loss': 0.8264967905015361, 'Total loss': 0.8264967905015361}
2022-11-23 00:56:55,286 INFO:     Found new best model at epoch 4
2022-11-23 00:56:55,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:55,287 INFO:     Epoch: 5
2022-11-23 00:56:56,114 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8638970059427348, 'Total loss': 0.8638970059427348} | train loss {'Reaction outcome loss': 0.819437544078243, 'Total loss': 0.819437544078243}
2022-11-23 00:56:56,115 INFO:     Found new best model at epoch 5
2022-11-23 00:56:56,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:56,116 INFO:     Epoch: 6
2022-11-23 00:56:56,966 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8634283691644669, 'Total loss': 0.8634283691644669} | train loss {'Reaction outcome loss': 0.8186565745849999, 'Total loss': 0.8186565745849999}
2022-11-23 00:56:56,966 INFO:     Found new best model at epoch 6
2022-11-23 00:56:56,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:56,967 INFO:     Epoch: 7
2022-11-23 00:56:57,823 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8672717755491083, 'Total loss': 0.8672717755491083} | train loss {'Reaction outcome loss': 0.8193499776781822, 'Total loss': 0.8193499776781822}
2022-11-23 00:56:57,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:57,823 INFO:     Epoch: 8
2022-11-23 00:56:58,687 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8803617615591396, 'Total loss': 0.8803617615591396} | train loss {'Reaction outcome loss': 0.81503845149157, 'Total loss': 0.81503845149157}
2022-11-23 00:56:58,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:58,688 INFO:     Epoch: 9
2022-11-23 00:56:59,546 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8736926181749864, 'Total loss': 0.8736926181749864} | train loss {'Reaction outcome loss': 0.8096732268528063, 'Total loss': 0.8096732268528063}
2022-11-23 00:56:59,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:56:59,546 INFO:     Epoch: 10
2022-11-23 00:57:00,365 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8625028350136497, 'Total loss': 0.8625028350136497} | train loss {'Reaction outcome loss': 0.8150609347285057, 'Total loss': 0.8150609347285057}
2022-11-23 00:57:00,365 INFO:     Found new best model at epoch 10
2022-11-23 00:57:00,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:00,366 INFO:     Epoch: 11
2022-11-23 00:57:01,226 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8650686063549735, 'Total loss': 0.8650686063549735} | train loss {'Reaction outcome loss': 0.813334587033914, 'Total loss': 0.813334587033914}
2022-11-23 00:57:01,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:01,227 INFO:     Epoch: 12
2022-11-23 00:57:02,121 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8757424747402017, 'Total loss': 0.8757424747402017} | train loss {'Reaction outcome loss': 0.8116615194447186, 'Total loss': 0.8116615194447186}
2022-11-23 00:57:02,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:02,122 INFO:     Epoch: 13
2022-11-23 00:57:03,024 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8544819199226119, 'Total loss': 0.8544819199226119} | train loss {'Reaction outcome loss': 0.8131961439337049, 'Total loss': 0.8131961439337049}
2022-11-23 00:57:03,024 INFO:     Found new best model at epoch 13
2022-11-23 00:57:03,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:03,025 INFO:     Epoch: 14
2022-11-23 00:57:03,941 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8636281381953846, 'Total loss': 0.8636281381953846} | train loss {'Reaction outcome loss': 0.8122324481302378, 'Total loss': 0.8122324481302378}
2022-11-23 00:57:03,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:03,942 INFO:     Epoch: 15
2022-11-23 00:57:04,808 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8763104392723604, 'Total loss': 0.8763104392723604} | train loss {'Reaction outcome loss': 0.8170028512575188, 'Total loss': 0.8170028512575188}
2022-11-23 00:57:04,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:04,808 INFO:     Epoch: 16
2022-11-23 00:57:05,706 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8608794043009932, 'Total loss': 0.8608794043009932} | train loss {'Reaction outcome loss': 0.8076468685451819, 'Total loss': 0.8076468685451819}
2022-11-23 00:57:05,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:05,707 INFO:     Epoch: 17
2022-11-23 00:57:06,636 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8770904439416799, 'Total loss': 0.8770904439416799} | train loss {'Reaction outcome loss': 0.811329840154064, 'Total loss': 0.811329840154064}
2022-11-23 00:57:06,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:06,636 INFO:     Epoch: 18
2022-11-23 00:57:07,492 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8656434647061608, 'Total loss': 0.8656434647061608} | train loss {'Reaction outcome loss': 0.8096395424434117, 'Total loss': 0.8096395424434117}
2022-11-23 00:57:07,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:07,492 INFO:     Epoch: 19
2022-11-23 00:57:08,427 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8703397316011515, 'Total loss': 0.8703397316011515} | train loss {'Reaction outcome loss': 0.8107431355787783, 'Total loss': 0.8107431355787783}
2022-11-23 00:57:08,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:08,427 INFO:     Epoch: 20
2022-11-23 00:57:09,299 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8608926101164385, 'Total loss': 0.8608926101164385} | train loss {'Reaction outcome loss': 0.8109022936042474, 'Total loss': 0.8109022936042474}
2022-11-23 00:57:09,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:09,299 INFO:     Epoch: 21
2022-11-23 00:57:10,160 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8588272732767191, 'Total loss': 0.8588272732767191} | train loss {'Reaction outcome loss': 0.8098001837730407, 'Total loss': 0.8098001837730407}
2022-11-23 00:57:10,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:10,161 INFO:     Epoch: 22
2022-11-23 00:57:11,036 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8890159231695262, 'Total loss': 0.8890159231695262} | train loss {'Reaction outcome loss': 0.809672063589096, 'Total loss': 0.809672063589096}
2022-11-23 00:57:11,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:11,037 INFO:     Epoch: 23
2022-11-23 00:57:11,885 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8662558963352983, 'Total loss': 0.8662558963352983} | train loss {'Reaction outcome loss': 0.8098443988634616, 'Total loss': 0.8098443988634616}
2022-11-23 00:57:11,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:11,885 INFO:     Epoch: 24
2022-11-23 00:57:12,753 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8728059503165159, 'Total loss': 0.8728059503165159} | train loss {'Reaction outcome loss': 0.8068614439088471, 'Total loss': 0.8068614439088471}
2022-11-23 00:57:12,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:12,753 INFO:     Epoch: 25
2022-11-23 00:57:13,724 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8757806054570458, 'Total loss': 0.8757806054570458} | train loss {'Reaction outcome loss': 0.8084040534739592, 'Total loss': 0.8084040534739592}
2022-11-23 00:57:13,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:13,724 INFO:     Epoch: 26
2022-11-23 00:57:14,678 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8899437087503347, 'Total loss': 0.8899437087503347} | train loss {'Reaction outcome loss': 0.8133587984406219, 'Total loss': 0.8133587984406219}
2022-11-23 00:57:14,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:14,679 INFO:     Epoch: 27
2022-11-23 00:57:15,586 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.851882897994735, 'Total loss': 0.851882897994735} | train loss {'Reaction outcome loss': 0.8108427593902666, 'Total loss': 0.8108427593902666}
2022-11-23 00:57:15,586 INFO:     Found new best model at epoch 27
2022-11-23 00:57:15,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:15,587 INFO:     Epoch: 28
2022-11-23 00:57:16,493 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8643071509220384, 'Total loss': 0.8643071509220384} | train loss {'Reaction outcome loss': 0.8097611803181317, 'Total loss': 0.8097611803181317}
2022-11-23 00:57:16,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:16,493 INFO:     Epoch: 29
2022-11-23 00:57:17,375 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8584519150582227, 'Total loss': 0.8584519150582227} | train loss {'Reaction outcome loss': 0.8072912658963884, 'Total loss': 0.8072912658963884}
2022-11-23 00:57:17,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:17,375 INFO:     Epoch: 30
2022-11-23 00:57:18,221 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8448317999189551, 'Total loss': 0.8448317999189551} | train loss {'Reaction outcome loss': 0.8093677807827385, 'Total loss': 0.8093677807827385}
2022-11-23 00:57:18,221 INFO:     Found new best model at epoch 30
2022-11-23 00:57:18,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:18,222 INFO:     Epoch: 31
2022-11-23 00:57:19,050 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8669857315041802, 'Total loss': 0.8669857315041802} | train loss {'Reaction outcome loss': 0.8051001681357014, 'Total loss': 0.8051001681357014}
2022-11-23 00:57:19,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:19,051 INFO:     Epoch: 32
2022-11-23 00:57:19,916 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8768165321512655, 'Total loss': 0.8768165321512655} | train loss {'Reaction outcome loss': 0.8081868211833798, 'Total loss': 0.8081868211833798}
2022-11-23 00:57:19,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:19,917 INFO:     Epoch: 33
2022-11-23 00:57:20,777 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8542302728376605, 'Total loss': 0.8542302728376605} | train loss {'Reaction outcome loss': 0.8085215344720957, 'Total loss': 0.8085215344720957}
2022-11-23 00:57:20,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:20,778 INFO:     Epoch: 34
2022-11-23 00:57:21,692 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8532292605801062, 'Total loss': 0.8532292605801062} | train loss {'Reaction outcome loss': 0.8123306827885765, 'Total loss': 0.8123306827885765}
2022-11-23 00:57:21,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:21,692 INFO:     Epoch: 35
2022-11-23 00:57:22,607 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8598361245610497, 'Total loss': 0.8598361245610497} | train loss {'Reaction outcome loss': 0.8086119056964407, 'Total loss': 0.8086119056964407}
2022-11-23 00:57:22,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:22,607 INFO:     Epoch: 36
2022-11-23 00:57:23,476 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8698816522955894, 'Total loss': 0.8698816522955894} | train loss {'Reaction outcome loss': 0.8073606105483309, 'Total loss': 0.8073606105483309}
2022-11-23 00:57:23,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:23,477 INFO:     Epoch: 37
2022-11-23 00:57:24,308 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8722455474463376, 'Total loss': 0.8722455474463376} | train loss {'Reaction outcome loss': 0.8076813793912225, 'Total loss': 0.8076813793912225}
2022-11-23 00:57:24,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:24,308 INFO:     Epoch: 38
2022-11-23 00:57:25,139 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8556605645201423, 'Total loss': 0.8556605645201423} | train loss {'Reaction outcome loss': 0.8076877601292669, 'Total loss': 0.8076877601292669}
2022-11-23 00:57:25,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:25,139 INFO:     Epoch: 39
2022-11-23 00:57:26,064 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8690750551494685, 'Total loss': 0.8690750551494685} | train loss {'Reaction outcome loss': 0.8060327823064766, 'Total loss': 0.8060327823064766}
2022-11-23 00:57:26,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:26,064 INFO:     Epoch: 40
2022-11-23 00:57:27,019 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8560558449138295, 'Total loss': 0.8560558449138295} | train loss {'Reaction outcome loss': 0.8092769709168648, 'Total loss': 0.8092769709168648}
2022-11-23 00:57:27,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:27,019 INFO:     Epoch: 41
2022-11-23 00:57:27,879 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8532454466277902, 'Total loss': 0.8532454466277902} | train loss {'Reaction outcome loss': 0.8099644013813564, 'Total loss': 0.8099644013813564}
2022-11-23 00:57:27,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:27,879 INFO:     Epoch: 42
2022-11-23 00:57:28,718 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8467929017814723, 'Total loss': 0.8467929017814723} | train loss {'Reaction outcome loss': 0.8067153086467665, 'Total loss': 0.8067153086467665}
2022-11-23 00:57:28,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:28,719 INFO:     Epoch: 43
2022-11-23 00:57:29,558 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8646458339962092, 'Total loss': 0.8646458339962092} | train loss {'Reaction outcome loss': 0.808775437486415, 'Total loss': 0.808775437486415}
2022-11-23 00:57:29,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:29,559 INFO:     Epoch: 44
2022-11-23 00:57:30,416 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8546528673984788, 'Total loss': 0.8546528673984788} | train loss {'Reaction outcome loss': 0.8111718251997111, 'Total loss': 0.8111718251997111}
2022-11-23 00:57:30,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:30,417 INFO:     Epoch: 45
2022-11-23 00:57:31,283 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8539307781241157, 'Total loss': 0.8539307781241157} | train loss {'Reaction outcome loss': 0.8084804964308836, 'Total loss': 0.8084804964308836}
2022-11-23 00:57:31,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:31,283 INFO:     Epoch: 46
2022-11-23 00:57:32,161 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8578654812140898, 'Total loss': 0.8578654812140898} | train loss {'Reaction outcome loss': 0.8102425106934139, 'Total loss': 0.8102425106934139}
2022-11-23 00:57:32,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:32,161 INFO:     Epoch: 47
2022-11-23 00:57:32,996 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8580655428496274, 'Total loss': 0.8580655428496274} | train loss {'Reaction outcome loss': 0.804984117284113, 'Total loss': 0.804984117284113}
2022-11-23 00:57:32,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:32,997 INFO:     Epoch: 48
2022-11-23 00:57:33,825 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8813927966085348, 'Total loss': 0.8813927966085348} | train loss {'Reaction outcome loss': 0.8061807400109816, 'Total loss': 0.8061807400109816}
2022-11-23 00:57:33,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:33,825 INFO:     Epoch: 49
2022-11-23 00:57:34,725 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8564826128157702, 'Total loss': 0.8564826128157702} | train loss {'Reaction outcome loss': 0.807171185405887, 'Total loss': 0.807171185405887}
2022-11-23 00:57:34,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:34,725 INFO:     Epoch: 50
2022-11-23 00:57:35,572 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8601005307652734, 'Total loss': 0.8601005307652734} | train loss {'Reaction outcome loss': 0.8070811838519817, 'Total loss': 0.8070811838519817}
2022-11-23 00:57:35,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:35,573 INFO:     Epoch: 51
2022-11-23 00:57:36,424 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8812757229263132, 'Total loss': 0.8812757229263132} | train loss {'Reaction outcome loss': 0.807048715863909, 'Total loss': 0.807048715863909}
2022-11-23 00:57:36,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:36,424 INFO:     Epoch: 52
2022-11-23 00:57:37,239 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.859922179105607, 'Total loss': 0.859922179105607} | train loss {'Reaction outcome loss': 0.8086515904689322, 'Total loss': 0.8086515904689322}
2022-11-23 00:57:37,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:37,240 INFO:     Epoch: 53
2022-11-23 00:57:38,053 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8723383796485987, 'Total loss': 0.8723383796485987} | train loss {'Reaction outcome loss': 0.8106139444575018, 'Total loss': 0.8106139444575018}
2022-11-23 00:57:38,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:38,054 INFO:     Epoch: 54
2022-11-23 00:57:38,881 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8506524664434519, 'Total loss': 0.8506524664434519} | train loss {'Reaction outcome loss': 0.8103683099454763, 'Total loss': 0.8103683099454763}
2022-11-23 00:57:38,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:38,882 INFO:     Epoch: 55
2022-11-23 00:57:39,707 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8690611875870011, 'Total loss': 0.8690611875870011} | train loss {'Reaction outcome loss': 0.8072105244714387, 'Total loss': 0.8072105244714387}
2022-11-23 00:57:39,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:39,707 INFO:     Epoch: 56
2022-11-23 00:57:40,520 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8555134263905612, 'Total loss': 0.8555134263905612} | train loss {'Reaction outcome loss': 0.8082694048784217, 'Total loss': 0.8082694048784217}
2022-11-23 00:57:40,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:40,520 INFO:     Epoch: 57
2022-11-23 00:57:41,341 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.870735692706975, 'Total loss': 0.870735692706975} | train loss {'Reaction outcome loss': 0.8092287873735233, 'Total loss': 0.8092287873735233}
2022-11-23 00:57:41,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:41,341 INFO:     Epoch: 58
2022-11-23 00:57:42,154 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8721315745602954, 'Total loss': 0.8721315745602954} | train loss {'Reaction outcome loss': 0.8143112584036224, 'Total loss': 0.8143112584036224}
2022-11-23 00:57:42,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:42,155 INFO:     Epoch: 59
2022-11-23 00:57:42,980 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8764032288031145, 'Total loss': 0.8764032288031145} | train loss {'Reaction outcome loss': 0.8092715763924073, 'Total loss': 0.8092715763924073}
2022-11-23 00:57:42,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:42,981 INFO:     Epoch: 60
2022-11-23 00:57:43,808 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8728647218509153, 'Total loss': 0.8728647218509153} | train loss {'Reaction outcome loss': 0.8123038516969097, 'Total loss': 0.8123038516969097}
2022-11-23 00:57:43,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:43,808 INFO:     Epoch: 61
2022-11-23 00:57:44,626 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8990265638990835, 'Total loss': 0.8990265638990835} | train loss {'Reaction outcome loss': 0.8075354582192946, 'Total loss': 0.8075354582192946}
2022-11-23 00:57:44,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:44,626 INFO:     Epoch: 62
2022-11-23 00:57:45,462 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8593102327801965, 'Total loss': 0.8593102327801965} | train loss {'Reaction outcome loss': 0.811226962902108, 'Total loss': 0.811226962902108}
2022-11-23 00:57:45,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:45,462 INFO:     Epoch: 63
2022-11-23 00:57:46,272 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8669850690798326, 'Total loss': 0.8669850690798326} | train loss {'Reaction outcome loss': 0.8064683117428605, 'Total loss': 0.8064683117428605}
2022-11-23 00:57:46,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:46,273 INFO:     Epoch: 64
2022-11-23 00:57:47,079 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8665756617080081, 'Total loss': 0.8665756617080081} | train loss {'Reaction outcome loss': 0.8097339852732055, 'Total loss': 0.8097339852732055}
2022-11-23 00:57:47,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:47,079 INFO:     Epoch: 65
2022-11-23 00:57:47,909 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8529557633129033, 'Total loss': 0.8529557633129033} | train loss {'Reaction outcome loss': 0.8067580568547151, 'Total loss': 0.8067580568547151}
2022-11-23 00:57:47,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:47,909 INFO:     Epoch: 66
2022-11-23 00:57:48,771 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8593198650262572, 'Total loss': 0.8593198650262572} | train loss {'Reaction outcome loss': 0.8129366130244975, 'Total loss': 0.8129366130244975}
2022-11-23 00:57:48,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:48,772 INFO:     Epoch: 67
2022-11-23 00:57:49,579 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8690242956985127, 'Total loss': 0.8690242956985127} | train loss {'Reaction outcome loss': 0.807646601783986, 'Total loss': 0.807646601783986}
2022-11-23 00:57:49,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:49,580 INFO:     Epoch: 68
2022-11-23 00:57:50,387 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8901982043277133, 'Total loss': 0.8901982043277133} | train loss {'Reaction outcome loss': 0.8088565195093349, 'Total loss': 0.8088565195093349}
2022-11-23 00:57:50,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:50,387 INFO:     Epoch: 69
2022-11-23 00:57:51,216 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.856928943910382, 'Total loss': 0.856928943910382} | train loss {'Reaction outcome loss': 0.8084495093749494, 'Total loss': 0.8084495093749494}
2022-11-23 00:57:51,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:51,216 INFO:     Epoch: 70
2022-11-23 00:57:52,010 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8688814196396958, 'Total loss': 0.8688814196396958} | train loss {'Reaction outcome loss': 0.8056022572274111, 'Total loss': 0.8056022572274111}
2022-11-23 00:57:52,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:52,011 INFO:     Epoch: 71
2022-11-23 00:57:52,829 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8613110293041576, 'Total loss': 0.8613110293041576} | train loss {'Reaction outcome loss': 0.8087561002799443, 'Total loss': 0.8087561002799443}
2022-11-23 00:57:52,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:52,830 INFO:     Epoch: 72
2022-11-23 00:57:53,658 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.870302139358087, 'Total loss': 0.870302139358087} | train loss {'Reaction outcome loss': 0.8114036776581589, 'Total loss': 0.8114036776581589}
2022-11-23 00:57:53,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:53,658 INFO:     Epoch: 73
2022-11-23 00:57:54,495 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8688368716023185, 'Total loss': 0.8688368716023185} | train loss {'Reaction outcome loss': 0.8064261533776108, 'Total loss': 0.8064261533776108}
2022-11-23 00:57:54,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:54,495 INFO:     Epoch: 74
2022-11-23 00:57:55,324 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8596055175770413, 'Total loss': 0.8596055175770413} | train loss {'Reaction outcome loss': 0.8098676821407007, 'Total loss': 0.8098676821407007}
2022-11-23 00:57:55,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:55,325 INFO:     Epoch: 75
2022-11-23 00:57:56,115 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.864119793203744, 'Total loss': 0.864119793203744} | train loss {'Reaction outcome loss': 0.8045147873917404, 'Total loss': 0.8045147873917404}
2022-11-23 00:57:56,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:56,115 INFO:     Epoch: 76
2022-11-23 00:57:56,945 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.856145088645545, 'Total loss': 0.856145088645545} | train loss {'Reaction outcome loss': 0.8101987724401513, 'Total loss': 0.8101987724401513}
2022-11-23 00:57:56,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:56,945 INFO:     Epoch: 77
2022-11-23 00:57:57,769 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.874684832312844, 'Total loss': 0.874684832312844} | train loss {'Reaction outcome loss': 0.8090530413754132, 'Total loss': 0.8090530413754132}
2022-11-23 00:57:57,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:57,769 INFO:     Epoch: 78
2022-11-23 00:57:58,573 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8881498317826878, 'Total loss': 0.8881498317826878} | train loss {'Reaction outcome loss': 0.8071532582750126, 'Total loss': 0.8071532582750126}
2022-11-23 00:57:58,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:58,573 INFO:     Epoch: 79
2022-11-23 00:57:59,416 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8476674414493821, 'Total loss': 0.8476674414493821} | train loss {'Reaction outcome loss': 0.8109129411833627, 'Total loss': 0.8109129411833627}
2022-11-23 00:57:59,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:57:59,416 INFO:     Epoch: 80
2022-11-23 00:58:00,250 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8659025427292694, 'Total loss': 0.8659025427292694} | train loss {'Reaction outcome loss': 0.8093520556177412, 'Total loss': 0.8093520556177412}
2022-11-23 00:58:00,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:00,250 INFO:     Epoch: 81
2022-11-23 00:58:01,061 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8702935535799373, 'Total loss': 0.8702935535799373} | train loss {'Reaction outcome loss': 0.8058145222615223, 'Total loss': 0.8058145222615223}
2022-11-23 00:58:01,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:01,061 INFO:     Epoch: 82
2022-11-23 00:58:01,899 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.85972129621289, 'Total loss': 0.85972129621289} | train loss {'Reaction outcome loss': 0.810266453757578, 'Total loss': 0.810266453757578}
2022-11-23 00:58:01,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:01,899 INFO:     Epoch: 83
2022-11-23 00:58:02,710 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.871186721731316, 'Total loss': 0.871186721731316} | train loss {'Reaction outcome loss': 0.8079862940068148, 'Total loss': 0.8079862940068148}
2022-11-23 00:58:02,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:02,711 INFO:     Epoch: 84
2022-11-23 00:58:03,518 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8799447092142972, 'Total loss': 0.8799447092142972} | train loss {'Reaction outcome loss': 0.8093693753894494, 'Total loss': 0.8093693753894494}
2022-11-23 00:58:03,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:03,518 INFO:     Epoch: 85
2022-11-23 00:58:04,365 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8633027320558374, 'Total loss': 0.8633027320558374} | train loss {'Reaction outcome loss': 0.8126933853236996, 'Total loss': 0.8126933853236996}
2022-11-23 00:58:04,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:04,366 INFO:     Epoch: 86
2022-11-23 00:58:05,173 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8778252262960781, 'Total loss': 0.8778252262960781} | train loss {'Reaction outcome loss': 0.8100777185693079, 'Total loss': 0.8100777185693079}
2022-11-23 00:58:05,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:05,174 INFO:     Epoch: 87
2022-11-23 00:58:05,956 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8672571961175312, 'Total loss': 0.8672571961175312} | train loss {'Reaction outcome loss': 0.8102942058018275, 'Total loss': 0.8102942058018275}
2022-11-23 00:58:05,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:05,956 INFO:     Epoch: 88
2022-11-23 00:58:06,756 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8733863546089693, 'Total loss': 0.8733863546089693} | train loss {'Reaction outcome loss': 0.8056529837603472, 'Total loss': 0.8056529837603472}
2022-11-23 00:58:06,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:06,756 INFO:     Epoch: 89
2022-11-23 00:58:07,527 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8721049800515175, 'Total loss': 0.8721049800515175} | train loss {'Reaction outcome loss': 0.8109163739243332, 'Total loss': 0.8109163739243332}
2022-11-23 00:58:07,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:07,527 INFO:     Epoch: 90
2022-11-23 00:58:08,309 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8502605069767345, 'Total loss': 0.8502605069767345} | train loss {'Reaction outcome loss': 0.8071798044808057, 'Total loss': 0.8071798044808057}
2022-11-23 00:58:08,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:08,309 INFO:     Epoch: 91
2022-11-23 00:58:09,100 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8816041445190256, 'Total loss': 0.8816041445190256} | train loss {'Reaction outcome loss': 0.8074661155136265, 'Total loss': 0.8074661155136265}
2022-11-23 00:58:09,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:09,100 INFO:     Epoch: 92
2022-11-23 00:58:09,909 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8718124120072885, 'Total loss': 0.8718124120072885} | train loss {'Reaction outcome loss': 0.8085519470730607, 'Total loss': 0.8085519470730607}
2022-11-23 00:58:09,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:09,909 INFO:     Epoch: 93
2022-11-23 00:58:10,669 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8484186828136444, 'Total loss': 0.8484186828136444} | train loss {'Reaction outcome loss': 0.8086901726163164, 'Total loss': 0.8086901726163164}
2022-11-23 00:58:10,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:10,669 INFO:     Epoch: 94
2022-11-23 00:58:11,409 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8554121337153695, 'Total loss': 0.8554121337153695} | train loss {'Reaction outcome loss': 0.8036204531484721, 'Total loss': 0.8036204531484721}
2022-11-23 00:58:11,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:11,410 INFO:     Epoch: 95
2022-11-23 00:58:12,160 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8579914989796552, 'Total loss': 0.8579914989796552} | train loss {'Reaction outcome loss': 0.8056266007374744, 'Total loss': 0.8056266007374744}
2022-11-23 00:58:12,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:12,160 INFO:     Epoch: 96
2022-11-23 00:58:12,936 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8600569008426233, 'Total loss': 0.8600569008426233} | train loss {'Reaction outcome loss': 0.8082033176811374, 'Total loss': 0.8082033176811374}
2022-11-23 00:58:12,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:12,936 INFO:     Epoch: 97
2022-11-23 00:58:13,704 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8524178661067378, 'Total loss': 0.8524178661067378} | train loss {'Reaction outcome loss': 0.8088070272791142, 'Total loss': 0.8088070272791142}
2022-11-23 00:58:13,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:13,704 INFO:     Epoch: 98
2022-11-23 00:58:14,473 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8914997008713809, 'Total loss': 0.8914997008713809} | train loss {'Reaction outcome loss': 0.8088358421714938, 'Total loss': 0.8088358421714938}
2022-11-23 00:58:14,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:14,474 INFO:     Epoch: 99
2022-11-23 00:58:15,254 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8569802479310469, 'Total loss': 0.8569802479310469} | train loss {'Reaction outcome loss': 0.8106083008707786, 'Total loss': 0.8106083008707786}
2022-11-23 00:58:15,254 INFO:     Best model found after epoch 31 of 100.
2022-11-23 00:58:15,255 INFO:   Done with stage: TRAINING
2022-11-23 00:58:15,255 INFO:   Starting stage: EVALUATION
2022-11-23 00:58:15,385 INFO:   Done with stage: EVALUATION
2022-11-23 00:58:15,385 INFO:   Leaving out SEQ value Fold_8
2022-11-23 00:58:15,399 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 00:58:15,399 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:58:16,075 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:58:16,076 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:58:16,147 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:58:16,147 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:58:16,147 INFO:     No hyperparam tuning for this model
2022-11-23 00:58:16,148 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:58:16,148 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:58:16,148 INFO:     None feature selector for col prot
2022-11-23 00:58:16,149 INFO:     None feature selector for col prot
2022-11-23 00:58:16,149 INFO:     None feature selector for col prot
2022-11-23 00:58:16,149 INFO:     None feature selector for col chem
2022-11-23 00:58:16,149 INFO:     None feature selector for col chem
2022-11-23 00:58:16,149 INFO:     None feature selector for col chem
2022-11-23 00:58:16,149 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:58:16,149 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:58:16,151 INFO:     Number of params in model 168571
2022-11-23 00:58:16,154 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:58:16,154 INFO:   Starting stage: TRAINING
2022-11-23 00:58:16,213 INFO:     Val loss before train {'Reaction outcome loss': 0.9694693318822167, 'Total loss': 0.9694693318822167}
2022-11-23 00:58:16,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:16,213 INFO:     Epoch: 0
2022-11-23 00:58:17,032 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8429444378072565, 'Total loss': 0.8429444378072565} | train loss {'Reaction outcome loss': 0.8860808029290168, 'Total loss': 0.8860808029290168}
2022-11-23 00:58:17,033 INFO:     Found new best model at epoch 0
2022-11-23 00:58:17,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:17,033 INFO:     Epoch: 1
2022-11-23 00:58:17,814 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8302555328065698, 'Total loss': 0.8302555328065698} | train loss {'Reaction outcome loss': 0.8551074445487992, 'Total loss': 0.8551074445487992}
2022-11-23 00:58:17,814 INFO:     Found new best model at epoch 1
2022-11-23 00:58:17,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:17,815 INFO:     Epoch: 2
2022-11-23 00:58:18,599 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.803740954534574, 'Total loss': 0.803740954534574} | train loss {'Reaction outcome loss': 0.8560522848800305, 'Total loss': 0.8560522848800305}
2022-11-23 00:58:18,599 INFO:     Found new best model at epoch 2
2022-11-23 00:58:18,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:18,600 INFO:     Epoch: 3
2022-11-23 00:58:19,398 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7975798046047037, 'Total loss': 0.7975798046047037} | train loss {'Reaction outcome loss': 0.8453412117256273, 'Total loss': 0.8453412117256273}
2022-11-23 00:58:19,398 INFO:     Found new best model at epoch 3
2022-11-23 00:58:19,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:19,399 INFO:     Epoch: 4
2022-11-23 00:58:20,176 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8288909664208238, 'Total loss': 0.8288909664208238} | train loss {'Reaction outcome loss': 0.8421720343251382, 'Total loss': 0.8421720343251382}
2022-11-23 00:58:20,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:20,177 INFO:     Epoch: 5
2022-11-23 00:58:21,054 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7992854714393616, 'Total loss': 0.7992854714393616} | train loss {'Reaction outcome loss': 0.8433819311040063, 'Total loss': 0.8433819311040063}
2022-11-23 00:58:21,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:21,054 INFO:     Epoch: 6
2022-11-23 00:58:21,893 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.805239012972875, 'Total loss': 0.805239012972875} | train loss {'Reaction outcome loss': 0.8368364990718903, 'Total loss': 0.8368364990718903}
2022-11-23 00:58:21,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:21,893 INFO:     Epoch: 7
2022-11-23 00:58:22,675 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7989097725261342, 'Total loss': 0.7989097725261342} | train loss {'Reaction outcome loss': 0.8378539329935466, 'Total loss': 0.8378539329935466}
2022-11-23 00:58:22,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:22,675 INFO:     Epoch: 8
2022-11-23 00:58:23,515 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8103607622059908, 'Total loss': 0.8103607622059908} | train loss {'Reaction outcome loss': 0.8329089669690978, 'Total loss': 0.8329089669690978}
2022-11-23 00:58:23,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:23,516 INFO:     Epoch: 9
2022-11-23 00:58:24,338 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.790854000909762, 'Total loss': 0.790854000909762} | train loss {'Reaction outcome loss': 0.8310368785694722, 'Total loss': 0.8310368785694722}
2022-11-23 00:58:24,338 INFO:     Found new best model at epoch 9
2022-11-23 00:58:24,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:24,339 INFO:     Epoch: 10
2022-11-23 00:58:25,131 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7917326925830408, 'Total loss': 0.7917326925830408} | train loss {'Reaction outcome loss': 0.8331253568251287, 'Total loss': 0.8331253568251287}
2022-11-23 00:58:25,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:25,131 INFO:     Epoch: 11
2022-11-23 00:58:25,937 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8009315979751673, 'Total loss': 0.8009315979751673} | train loss {'Reaction outcome loss': 0.8275242518753775, 'Total loss': 0.8275242518753775}
2022-11-23 00:58:25,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:25,937 INFO:     Epoch: 12
2022-11-23 00:58:26,735 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8005617877299135, 'Total loss': 0.8005617877299135} | train loss {'Reaction outcome loss': 0.830707149399865, 'Total loss': 0.830707149399865}
2022-11-23 00:58:26,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:26,735 INFO:     Epoch: 13
2022-11-23 00:58:27,550 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7896917746825651, 'Total loss': 0.7896917746825651} | train loss {'Reaction outcome loss': 0.8326544758052595, 'Total loss': 0.8326544758052595}
2022-11-23 00:58:27,550 INFO:     Found new best model at epoch 13
2022-11-23 00:58:27,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:27,551 INFO:     Epoch: 14
2022-11-23 00:58:28,365 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8102485253052278, 'Total loss': 0.8102485253052278} | train loss {'Reaction outcome loss': 0.830025409258181, 'Total loss': 0.830025409258181}
2022-11-23 00:58:28,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:28,366 INFO:     Epoch: 15
2022-11-23 00:58:29,161 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8318036306988109, 'Total loss': 0.8318036306988109} | train loss {'Reaction outcome loss': 0.8302896156186058, 'Total loss': 0.8302896156186058}
2022-11-23 00:58:29,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:29,161 INFO:     Epoch: 16
2022-11-23 00:58:29,976 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.791080809452317, 'Total loss': 0.791080809452317} | train loss {'Reaction outcome loss': 0.8314524774830188, 'Total loss': 0.8314524774830188}
2022-11-23 00:58:29,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:29,976 INFO:     Epoch: 17
2022-11-23 00:58:30,775 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7872724641453136, 'Total loss': 0.7872724641453136} | train loss {'Reaction outcome loss': 0.8324052214382156, 'Total loss': 0.8324052214382156}
2022-11-23 00:58:30,776 INFO:     Found new best model at epoch 17
2022-11-23 00:58:30,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:30,776 INFO:     Epoch: 18
2022-11-23 00:58:31,570 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7992462678389116, 'Total loss': 0.7992462678389116} | train loss {'Reaction outcome loss': 0.8282205844598431, 'Total loss': 0.8282205844598431}
2022-11-23 00:58:31,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:31,570 INFO:     Epoch: 19
2022-11-23 00:58:32,396 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.80397768183188, 'Total loss': 0.80397768183188} | train loss {'Reaction outcome loss': 0.8267907309195688, 'Total loss': 0.8267907309195688}
2022-11-23 00:58:32,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:32,396 INFO:     Epoch: 20
2022-11-23 00:58:33,208 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7924274666742845, 'Total loss': 0.7924274666742845} | train loss {'Reaction outcome loss': 0.829189709718189, 'Total loss': 0.829189709718189}
2022-11-23 00:58:33,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:33,208 INFO:     Epoch: 21
2022-11-23 00:58:34,015 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8121240931478414, 'Total loss': 0.8121240931478414} | train loss {'Reaction outcome loss': 0.8271128023343701, 'Total loss': 0.8271128023343701}
2022-11-23 00:58:34,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:34,016 INFO:     Epoch: 22
2022-11-23 00:58:34,842 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7938112921335481, 'Total loss': 0.7938112921335481} | train loss {'Reaction outcome loss': 0.8260980334974104, 'Total loss': 0.8260980334974104}
2022-11-23 00:58:34,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:34,842 INFO:     Epoch: 23
2022-11-23 00:58:35,629 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7854334332726218, 'Total loss': 0.7854334332726218} | train loss {'Reaction outcome loss': 0.8281894651872497, 'Total loss': 0.8281894651872497}
2022-11-23 00:58:35,630 INFO:     Found new best model at epoch 23
2022-11-23 00:58:35,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:35,631 INFO:     Epoch: 24
2022-11-23 00:58:36,442 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8264613808556036, 'Total loss': 0.8264613808556036} | train loss {'Reaction outcome loss': 0.8252335694288054, 'Total loss': 0.8252335694288054}
2022-11-23 00:58:36,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:36,442 INFO:     Epoch: 25
2022-11-23 00:58:37,242 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7859178158369932, 'Total loss': 0.7859178158369932} | train loss {'Reaction outcome loss': 0.8344021067023277, 'Total loss': 0.8344021067023277}
2022-11-23 00:58:37,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:37,242 INFO:     Epoch: 26
2022-11-23 00:58:38,041 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7851318832148205, 'Total loss': 0.7851318832148205} | train loss {'Reaction outcome loss': 0.8257936211603303, 'Total loss': 0.8257936211603303}
2022-11-23 00:58:38,041 INFO:     Found new best model at epoch 26
2022-11-23 00:58:38,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:38,042 INFO:     Epoch: 27
2022-11-23 00:58:38,840 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7922370095144619, 'Total loss': 0.7922370095144619} | train loss {'Reaction outcome loss': 0.8237136636049517, 'Total loss': 0.8237136636049517}
2022-11-23 00:58:38,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:38,841 INFO:     Epoch: 28
2022-11-23 00:58:39,635 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7929573092948307, 'Total loss': 0.7929573092948307} | train loss {'Reaction outcome loss': 0.8246341567606695, 'Total loss': 0.8246341567606695}
2022-11-23 00:58:39,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:39,635 INFO:     Epoch: 29
2022-11-23 00:58:40,423 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8106953955509446, 'Total loss': 0.8106953955509446} | train loss {'Reaction outcome loss': 0.8283281772127075, 'Total loss': 0.8283281772127075}
2022-11-23 00:58:40,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:40,423 INFO:     Epoch: 30
2022-11-23 00:58:41,222 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7988328012553129, 'Total loss': 0.7988328012553129} | train loss {'Reaction outcome loss': 0.8276230924191975, 'Total loss': 0.8276230924191975}
2022-11-23 00:58:41,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:41,223 INFO:     Epoch: 31
2022-11-23 00:58:42,072 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.798390037634156, 'Total loss': 0.798390037634156} | train loss {'Reaction outcome loss': 0.8261347318128232, 'Total loss': 0.8261347318128232}
2022-11-23 00:58:42,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:42,072 INFO:     Epoch: 32
2022-11-23 00:58:42,877 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7963759851726618, 'Total loss': 0.7963759851726618} | train loss {'Reaction outcome loss': 0.8239965658755072, 'Total loss': 0.8239965658755072}
2022-11-23 00:58:42,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:42,877 INFO:     Epoch: 33
2022-11-23 00:58:43,685 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7992452532052994, 'Total loss': 0.7992452532052994} | train loss {'Reaction outcome loss': 0.827575586135349, 'Total loss': 0.827575586135349}
2022-11-23 00:58:43,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:43,686 INFO:     Epoch: 34
2022-11-23 00:58:44,468 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7868414731188254, 'Total loss': 0.7868414731188254} | train loss {'Reaction outcome loss': 0.8221740073734715, 'Total loss': 0.8221740073734715}
2022-11-23 00:58:44,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:44,469 INFO:     Epoch: 35
2022-11-23 00:58:45,269 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.799460155042735, 'Total loss': 0.799460155042735} | train loss {'Reaction outcome loss': 0.8255142641644324, 'Total loss': 0.8255142641644324}
2022-11-23 00:58:45,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:45,269 INFO:     Epoch: 36
2022-11-23 00:58:46,073 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7962900643998926, 'Total loss': 0.7962900643998926} | train loss {'Reaction outcome loss': 0.827768491160485, 'Total loss': 0.827768491160485}
2022-11-23 00:58:46,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:46,073 INFO:     Epoch: 37
2022-11-23 00:58:46,859 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7925042320381511, 'Total loss': 0.7925042320381511} | train loss {'Reaction outcome loss': 0.8262174813257109, 'Total loss': 0.8262174813257109}
2022-11-23 00:58:46,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:46,859 INFO:     Epoch: 38
2022-11-23 00:58:47,711 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.78799542310563, 'Total loss': 0.78799542310563} | train loss {'Reaction outcome loss': 0.8292357513020115, 'Total loss': 0.8292357513020115}
2022-11-23 00:58:47,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:47,713 INFO:     Epoch: 39
2022-11-23 00:58:48,550 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7964596423235807, 'Total loss': 0.7964596423235807} | train loss {'Reaction outcome loss': 0.8270170640560889, 'Total loss': 0.8270170640560889}
2022-11-23 00:58:48,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:48,551 INFO:     Epoch: 40
2022-11-23 00:58:49,358 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7921315655112267, 'Total loss': 0.7921315655112267} | train loss {'Reaction outcome loss': 0.8287847694610396, 'Total loss': 0.8287847694610396}
2022-11-23 00:58:49,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:49,358 INFO:     Epoch: 41
2022-11-23 00:58:50,190 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7976875420321118, 'Total loss': 0.7976875420321118} | train loss {'Reaction outcome loss': 0.8263535941800764, 'Total loss': 0.8263535941800764}
2022-11-23 00:58:50,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:50,191 INFO:     Epoch: 42
2022-11-23 00:58:51,013 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7995443838563833, 'Total loss': 0.7995443838563833} | train loss {'Reaction outcome loss': 0.8268587124203483, 'Total loss': 0.8268587124203483}
2022-11-23 00:58:51,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:51,013 INFO:     Epoch: 43
2022-11-23 00:58:51,862 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7825885320251639, 'Total loss': 0.7825885320251639} | train loss {'Reaction outcome loss': 0.8229680751119891, 'Total loss': 0.8229680751119891}
2022-11-23 00:58:51,863 INFO:     Found new best model at epoch 43
2022-11-23 00:58:51,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:51,864 INFO:     Epoch: 44
2022-11-23 00:58:52,682 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.812432276931676, 'Total loss': 0.812432276931676} | train loss {'Reaction outcome loss': 0.8261141331205445, 'Total loss': 0.8261141331205445}
2022-11-23 00:58:52,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:52,682 INFO:     Epoch: 45
2022-11-23 00:58:53,458 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8021256320855834, 'Total loss': 0.8021256320855834} | train loss {'Reaction outcome loss': 0.8297856546217396, 'Total loss': 0.8297856546217396}
2022-11-23 00:58:53,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:53,459 INFO:     Epoch: 46
2022-11-23 00:58:54,287 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7972699586640705, 'Total loss': 0.7972699586640705} | train loss {'Reaction outcome loss': 0.8239564931681079, 'Total loss': 0.8239564931681079}
2022-11-23 00:58:54,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:54,288 INFO:     Epoch: 47
2022-11-23 00:58:55,077 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7793594124642286, 'Total loss': 0.7793594124642286} | train loss {'Reaction outcome loss': 0.828418291384174, 'Total loss': 0.828418291384174}
2022-11-23 00:58:55,078 INFO:     Found new best model at epoch 47
2022-11-23 00:58:55,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:55,078 INFO:     Epoch: 48
2022-11-23 00:58:55,927 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7926005260510878, 'Total loss': 0.7926005260510878} | train loss {'Reaction outcome loss': 0.8290890455245972, 'Total loss': 0.8290890455245972}
2022-11-23 00:58:55,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:55,927 INFO:     Epoch: 49
2022-11-23 00:58:56,749 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8003894889896567, 'Total loss': 0.8003894889896567} | train loss {'Reaction outcome loss': 0.8257005730223271, 'Total loss': 0.8257005730223271}
2022-11-23 00:58:56,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:56,749 INFO:     Epoch: 50
2022-11-23 00:58:57,565 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7889858030460097, 'Total loss': 0.7889858030460097} | train loss {'Reaction outcome loss': 0.8226185912686971, 'Total loss': 0.8226185912686971}
2022-11-23 00:58:57,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:57,566 INFO:     Epoch: 51
2022-11-23 00:58:58,382 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7992556244134903, 'Total loss': 0.7992556244134903} | train loss {'Reaction outcome loss': 0.8267367101244388, 'Total loss': 0.8267367101244388}
2022-11-23 00:58:58,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:58,383 INFO:     Epoch: 52
2022-11-23 00:58:59,193 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7949926507743922, 'Total loss': 0.7949926507743922} | train loss {'Reaction outcome loss': 0.8278340775399439, 'Total loss': 0.8278340775399439}
2022-11-23 00:58:59,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:59,193 INFO:     Epoch: 53
2022-11-23 00:58:59,990 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8023434037512, 'Total loss': 0.8023434037512} | train loss {'Reaction outcome loss': 0.8252244976259047, 'Total loss': 0.8252244976259047}
2022-11-23 00:58:59,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:58:59,990 INFO:     Epoch: 54
2022-11-23 00:59:00,782 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7955943779511885, 'Total loss': 0.7955943779511885} | train loss {'Reaction outcome loss': 0.8251718347591739, 'Total loss': 0.8251718347591739}
2022-11-23 00:59:00,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:00,783 INFO:     Epoch: 55
2022-11-23 00:59:01,596 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7968636019663378, 'Total loss': 0.7968636019663378} | train loss {'Reaction outcome loss': 0.826952570388394, 'Total loss': 0.826952570388394}
2022-11-23 00:59:01,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:01,596 INFO:     Epoch: 56
2022-11-23 00:59:02,408 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7937491346489299, 'Total loss': 0.7937491346489299} | train loss {'Reaction outcome loss': 0.8347918527020562, 'Total loss': 0.8347918527020562}
2022-11-23 00:59:02,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:02,408 INFO:     Epoch: 57
2022-11-23 00:59:03,243 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7965067929842256, 'Total loss': 0.7965067929842256} | train loss {'Reaction outcome loss': 0.8230592931710905, 'Total loss': 0.8230592931710905}
2022-11-23 00:59:03,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:03,243 INFO:     Epoch: 58
2022-11-23 00:59:04,077 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7914980013262142, 'Total loss': 0.7914980013262142} | train loss {'Reaction outcome loss': 0.8215213070713705, 'Total loss': 0.8215213070713705}
2022-11-23 00:59:04,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:04,078 INFO:     Epoch: 59
2022-11-23 00:59:04,942 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7901313928040591, 'Total loss': 0.7901313928040591} | train loss {'Reaction outcome loss': 0.8289791489801099, 'Total loss': 0.8289791489801099}
2022-11-23 00:59:04,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:04,943 INFO:     Epoch: 60
2022-11-23 00:59:05,740 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7891330827366222, 'Total loss': 0.7891330827366222} | train loss {'Reaction outcome loss': 0.8281459624488507, 'Total loss': 0.8281459624488507}
2022-11-23 00:59:05,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:05,741 INFO:     Epoch: 61
2022-11-23 00:59:06,572 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7845987447283485, 'Total loss': 0.7845987447283485} | train loss {'Reaction outcome loss': 0.8261180111477452, 'Total loss': 0.8261180111477452}
2022-11-23 00:59:06,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:06,572 INFO:     Epoch: 62
2022-11-23 00:59:07,395 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8021146926012906, 'Total loss': 0.8021146926012906} | train loss {'Reaction outcome loss': 0.8215640808545774, 'Total loss': 0.8215640808545774}
2022-11-23 00:59:07,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:07,396 INFO:     Epoch: 63
2022-11-23 00:59:08,202 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7820687605576082, 'Total loss': 0.7820687605576082} | train loss {'Reaction outcome loss': 0.8247796418445725, 'Total loss': 0.8247796418445725}
2022-11-23 00:59:08,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:08,202 INFO:     Epoch: 64
2022-11-23 00:59:08,988 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7913959500464526, 'Total loss': 0.7913959500464526} | train loss {'Reaction outcome loss': 0.8259943565053325, 'Total loss': 0.8259943565053325}
2022-11-23 00:59:08,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:08,988 INFO:     Epoch: 65
2022-11-23 00:59:09,767 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7940763465382836, 'Total loss': 0.7940763465382836} | train loss {'Reaction outcome loss': 0.8280371212430538, 'Total loss': 0.8280371212430538}
2022-11-23 00:59:09,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:09,768 INFO:     Epoch: 66
2022-11-23 00:59:10,574 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7832102653655139, 'Total loss': 0.7832102653655139} | train loss {'Reaction outcome loss': 0.8283783392079415, 'Total loss': 0.8283783392079415}
2022-11-23 00:59:10,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:10,574 INFO:     Epoch: 67
2022-11-23 00:59:11,396 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7915735563093965, 'Total loss': 0.7915735563093965} | train loss {'Reaction outcome loss': 0.8277744963284461, 'Total loss': 0.8277744963284461}
2022-11-23 00:59:11,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:11,397 INFO:     Epoch: 68
2022-11-23 00:59:12,214 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8041177615523338, 'Total loss': 0.8041177615523338} | train loss {'Reaction outcome loss': 0.8228695559645852, 'Total loss': 0.8228695559645852}
2022-11-23 00:59:12,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:12,214 INFO:     Epoch: 69
2022-11-23 00:59:13,011 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8051432703029026, 'Total loss': 0.8051432703029026} | train loss {'Reaction outcome loss': 0.8279777139184936, 'Total loss': 0.8279777139184936}
2022-11-23 00:59:13,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:13,011 INFO:     Epoch: 70
2022-11-23 00:59:13,804 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7983682968399741, 'Total loss': 0.7983682968399741} | train loss {'Reaction outcome loss': 0.8293296090297161, 'Total loss': 0.8293296090297161}
2022-11-23 00:59:13,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:13,805 INFO:     Epoch: 71
2022-11-23 00:59:14,629 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.782658885825764, 'Total loss': 0.782658885825764} | train loss {'Reaction outcome loss': 0.8283150270581245, 'Total loss': 0.8283150270581245}
2022-11-23 00:59:14,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:14,630 INFO:     Epoch: 72
2022-11-23 00:59:15,456 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8001119209961458, 'Total loss': 0.8001119209961458} | train loss {'Reaction outcome loss': 0.8192680419212387, 'Total loss': 0.8192680419212387}
2022-11-23 00:59:15,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:15,456 INFO:     Epoch: 73
2022-11-23 00:59:16,265 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7946875616908073, 'Total loss': 0.7946875616908073} | train loss {'Reaction outcome loss': 0.8230475247386964, 'Total loss': 0.8230475247386964}
2022-11-23 00:59:16,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:16,267 INFO:     Epoch: 74
2022-11-23 00:59:17,062 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8128303479064595, 'Total loss': 0.8128303479064595} | train loss {'Reaction outcome loss': 0.8250324335550109, 'Total loss': 0.8250324335550109}
2022-11-23 00:59:17,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:17,063 INFO:     Epoch: 75
2022-11-23 00:59:17,860 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8256010270931504, 'Total loss': 0.8256010270931504} | train loss {'Reaction outcome loss': 0.8263179317357079, 'Total loss': 0.8263179317357079}
2022-11-23 00:59:17,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:17,860 INFO:     Epoch: 76
2022-11-23 00:59:18,665 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7847092530944131, 'Total loss': 0.7847092530944131} | train loss {'Reaction outcome loss': 0.8285052266813093, 'Total loss': 0.8285052266813093}
2022-11-23 00:59:18,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:18,665 INFO:     Epoch: 77
2022-11-23 00:59:19,438 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7875134931369261, 'Total loss': 0.7875134931369261} | train loss {'Reaction outcome loss': 0.8271610926716558, 'Total loss': 0.8271610926716558}
2022-11-23 00:59:19,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:19,439 INFO:     Epoch: 78
2022-11-23 00:59:20,293 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8048390095884149, 'Total loss': 0.8048390095884149} | train loss {'Reaction outcome loss': 0.8270820677280426, 'Total loss': 0.8270820677280426}
2022-11-23 00:59:20,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:20,293 INFO:     Epoch: 79
2022-11-23 00:59:21,072 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.788068333810026, 'Total loss': 0.788068333810026} | train loss {'Reaction outcome loss': 0.8285103249213388, 'Total loss': 0.8285103249213388}
2022-11-23 00:59:21,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:21,072 INFO:     Epoch: 80
2022-11-23 00:59:21,887 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7922898381948471, 'Total loss': 0.7922898381948471} | train loss {'Reaction outcome loss': 0.8264870880351912, 'Total loss': 0.8264870880351912}
2022-11-23 00:59:21,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:21,889 INFO:     Epoch: 81
2022-11-23 00:59:22,700 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8102738295089115, 'Total loss': 0.8102738295089115} | train loss {'Reaction outcome loss': 0.8244166321331455, 'Total loss': 0.8244166321331455}
2022-11-23 00:59:22,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:22,700 INFO:     Epoch: 82
2022-11-23 00:59:23,534 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7990684631195936, 'Total loss': 0.7990684631195936} | train loss {'Reaction outcome loss': 0.8307485550401672, 'Total loss': 0.8307485550401672}
2022-11-23 00:59:23,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:23,535 INFO:     Epoch: 83
2022-11-23 00:59:24,357 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8097269914366982, 'Total loss': 0.8097269914366982} | train loss {'Reaction outcome loss': 0.8195997624387664, 'Total loss': 0.8195997624387664}
2022-11-23 00:59:24,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:24,357 INFO:     Epoch: 84
2022-11-23 00:59:25,172 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7829683395949277, 'Total loss': 0.7829683395949277} | train loss {'Reaction outcome loss': 0.8259609678099232, 'Total loss': 0.8259609678099232}
2022-11-23 00:59:25,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:25,172 INFO:     Epoch: 85
2022-11-23 00:59:26,013 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.794490478255532, 'Total loss': 0.794490478255532} | train loss {'Reaction outcome loss': 0.8286428593339459, 'Total loss': 0.8286428593339459}
2022-11-23 00:59:26,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:26,013 INFO:     Epoch: 86
2022-11-23 00:59:26,837 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8123193003914573, 'Total loss': 0.8123193003914573} | train loss {'Reaction outcome loss': 0.8263853054133153, 'Total loss': 0.8263853054133153}
2022-11-23 00:59:26,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:26,838 INFO:     Epoch: 87
2022-11-23 00:59:27,654 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7893019413406198, 'Total loss': 0.7893019413406198} | train loss {'Reaction outcome loss': 0.8271386200381864, 'Total loss': 0.8271386200381864}
2022-11-23 00:59:27,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:27,655 INFO:     Epoch: 88
2022-11-23 00:59:28,489 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7974653095006943, 'Total loss': 0.7974653095006943} | train loss {'Reaction outcome loss': 0.826801463000236, 'Total loss': 0.826801463000236}
2022-11-23 00:59:28,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:28,489 INFO:     Epoch: 89
2022-11-23 00:59:29,281 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7891466461799361, 'Total loss': 0.7891466461799361} | train loss {'Reaction outcome loss': 0.8287890080002046, 'Total loss': 0.8287890080002046}
2022-11-23 00:59:29,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:29,282 INFO:     Epoch: 90
2022-11-23 00:59:30,113 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8173187679865144, 'Total loss': 0.8173187679865144} | train loss {'Reaction outcome loss': 0.8249996773177578, 'Total loss': 0.8249996773177578}
2022-11-23 00:59:30,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:30,114 INFO:     Epoch: 91
2022-11-23 00:59:30,903 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8014235137538477, 'Total loss': 0.8014235137538477} | train loss {'Reaction outcome loss': 0.832367817480718, 'Total loss': 0.832367817480718}
2022-11-23 00:59:30,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:30,903 INFO:     Epoch: 92
2022-11-23 00:59:31,727 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7891847708008506, 'Total loss': 0.7891847708008506} | train loss {'Reaction outcome loss': 0.8272897995287373, 'Total loss': 0.8272897995287373}
2022-11-23 00:59:31,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:31,727 INFO:     Epoch: 93
2022-11-23 00:59:32,544 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.777999071912332, 'Total loss': 0.777999071912332} | train loss {'Reaction outcome loss': 0.828313859359872, 'Total loss': 0.828313859359872}
2022-11-23 00:59:32,545 INFO:     Found new best model at epoch 93
2022-11-23 00:59:32,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:32,546 INFO:     Epoch: 94
2022-11-23 00:59:33,364 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8091993636705659, 'Total loss': 0.8091993636705659} | train loss {'Reaction outcome loss': 0.8275805291148924, 'Total loss': 0.8275805291148924}
2022-11-23 00:59:33,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:33,365 INFO:     Epoch: 95
2022-11-23 00:59:34,210 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7833637229420922, 'Total loss': 0.7833637229420922} | train loss {'Reaction outcome loss': 0.8302065450097283, 'Total loss': 0.8302065450097283}
2022-11-23 00:59:34,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:34,210 INFO:     Epoch: 96
2022-11-23 00:59:35,024 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7814916853200305, 'Total loss': 0.7814916853200305} | train loss {'Reaction outcome loss': 0.826295925364379, 'Total loss': 0.826295925364379}
2022-11-23 00:59:35,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:35,024 INFO:     Epoch: 97
2022-11-23 00:59:35,829 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7901727265932343, 'Total loss': 0.7901727265932343} | train loss {'Reaction outcome loss': 0.8300528950508563, 'Total loss': 0.8300528950508563}
2022-11-23 00:59:35,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:35,829 INFO:     Epoch: 98
2022-11-23 00:59:36,651 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8118041117082943, 'Total loss': 0.8118041117082943} | train loss {'Reaction outcome loss': 0.8276383857573232, 'Total loss': 0.8276383857573232}
2022-11-23 00:59:36,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:36,651 INFO:     Epoch: 99
2022-11-23 00:59:37,468 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8018490265716206, 'Total loss': 0.8018490265716206} | train loss {'Reaction outcome loss': 0.8258684153758711, 'Total loss': 0.8258684153758711}
2022-11-23 00:59:37,468 INFO:     Best model found after epoch 94 of 100.
2022-11-23 00:59:37,469 INFO:   Done with stage: TRAINING
2022-11-23 00:59:37,469 INFO:   Starting stage: EVALUATION
2022-11-23 00:59:37,588 INFO:   Done with stage: EVALUATION
2022-11-23 00:59:37,588 INFO:   Leaving out SEQ value Fold_9
2022-11-23 00:59:37,601 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-23 00:59:37,601 INFO:   Starting stage: FEATURE SCALING
2022-11-23 00:59:38,258 INFO:   Done with stage: FEATURE SCALING
2022-11-23 00:59:38,258 INFO:   Starting stage: SCALING TARGETS
2022-11-23 00:59:38,328 INFO:   Done with stage: SCALING TARGETS
2022-11-23 00:59:38,330 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:59:38,330 INFO:     No hyperparam tuning for this model
2022-11-23 00:59:38,330 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 00:59:38,330 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 00:59:38,331 INFO:     None feature selector for col prot
2022-11-23 00:59:38,331 INFO:     None feature selector for col prot
2022-11-23 00:59:38,331 INFO:     None feature selector for col prot
2022-11-23 00:59:38,332 INFO:     None feature selector for col chem
2022-11-23 00:59:38,332 INFO:     None feature selector for col chem
2022-11-23 00:59:38,332 INFO:     None feature selector for col chem
2022-11-23 00:59:38,332 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 00:59:38,332 INFO:   Starting stage: BUILD MODEL
2022-11-23 00:59:38,334 INFO:     Number of params in model 168571
2022-11-23 00:59:38,337 INFO:   Done with stage: BUILD MODEL
2022-11-23 00:59:38,337 INFO:   Starting stage: TRAINING
2022-11-23 00:59:38,395 INFO:     Val loss before train {'Reaction outcome loss': 1.0240683162754232, 'Total loss': 1.0240683162754232}
2022-11-23 00:59:38,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:38,395 INFO:     Epoch: 0
2022-11-23 00:59:39,167 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8810087659142234, 'Total loss': 0.8810087659142234} | train loss {'Reaction outcome loss': 0.8763015332270642, 'Total loss': 0.8763015332270642}
2022-11-23 00:59:39,167 INFO:     Found new best model at epoch 0
2022-11-23 00:59:39,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:39,168 INFO:     Epoch: 1
2022-11-23 00:59:39,949 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.868998416445472, 'Total loss': 0.868998416445472} | train loss {'Reaction outcome loss': 0.8443504914945485, 'Total loss': 0.8443504914945485}
2022-11-23 00:59:39,949 INFO:     Found new best model at epoch 1
2022-11-23 00:59:39,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:39,950 INFO:     Epoch: 2
2022-11-23 00:59:40,719 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.853014967658303, 'Total loss': 0.853014967658303} | train loss {'Reaction outcome loss': 0.8391363012547396, 'Total loss': 0.8391363012547396}
2022-11-23 00:59:40,719 INFO:     Found new best model at epoch 2
2022-11-23 00:59:40,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:40,720 INFO:     Epoch: 3
2022-11-23 00:59:41,486 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8711844885891135, 'Total loss': 0.8711844885891135} | train loss {'Reaction outcome loss': 0.83771524526635, 'Total loss': 0.83771524526635}
2022-11-23 00:59:41,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:41,486 INFO:     Epoch: 4
2022-11-23 00:59:42,245 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8698056001554836, 'Total loss': 0.8698056001554836} | train loss {'Reaction outcome loss': 0.830692055030745, 'Total loss': 0.830692055030745}
2022-11-23 00:59:42,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:42,245 INFO:     Epoch: 5
2022-11-23 00:59:43,001 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8778671026229858, 'Total loss': 0.8778671026229858} | train loss {'Reaction outcome loss': 0.8255667966239306, 'Total loss': 0.8255667966239306}
2022-11-23 00:59:43,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:43,002 INFO:     Epoch: 6
2022-11-23 00:59:43,779 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.847596479410475, 'Total loss': 0.847596479410475} | train loss {'Reaction outcome loss': 0.8250603337677158, 'Total loss': 0.8250603337677158}
2022-11-23 00:59:43,779 INFO:     Found new best model at epoch 6
2022-11-23 00:59:43,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:43,780 INFO:     Epoch: 7
2022-11-23 00:59:44,564 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8454110886562954, 'Total loss': 0.8454110886562954} | train loss {'Reaction outcome loss': 0.8221687647761131, 'Total loss': 0.8221687647761131}
2022-11-23 00:59:44,565 INFO:     Found new best model at epoch 7
2022-11-23 00:59:44,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:44,566 INFO:     Epoch: 8
2022-11-23 00:59:45,335 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8634733937003396, 'Total loss': 0.8634733937003396} | train loss {'Reaction outcome loss': 0.8257427174217847, 'Total loss': 0.8257427174217847}
2022-11-23 00:59:45,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:45,335 INFO:     Epoch: 9
2022-11-23 00:59:46,088 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8503271138126199, 'Total loss': 0.8503271138126199} | train loss {'Reaction outcome loss': 0.8200784770809875, 'Total loss': 0.8200784770809875}
2022-11-23 00:59:46,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:46,088 INFO:     Epoch: 10
2022-11-23 00:59:46,832 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8483833338726651, 'Total loss': 0.8483833338726651} | train loss {'Reaction outcome loss': 0.8191407984616805, 'Total loss': 0.8191407984616805}
2022-11-23 00:59:46,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:46,832 INFO:     Epoch: 11
2022-11-23 00:59:47,603 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8560593615878712, 'Total loss': 0.8560593615878712} | train loss {'Reaction outcome loss': 0.8214212816588733, 'Total loss': 0.8214212816588733}
2022-11-23 00:59:47,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:47,603 INFO:     Epoch: 12
2022-11-23 00:59:48,378 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.838501825928688, 'Total loss': 0.838501825928688} | train loss {'Reaction outcome loss': 0.8197742423232721, 'Total loss': 0.8197742423232721}
2022-11-23 00:59:48,378 INFO:     Found new best model at epoch 12
2022-11-23 00:59:48,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:48,379 INFO:     Epoch: 13
2022-11-23 00:59:49,169 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8626245382157239, 'Total loss': 0.8626245382157239} | train loss {'Reaction outcome loss': 0.8111057706025182, 'Total loss': 0.8111057706025182}
2022-11-23 00:59:49,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:49,169 INFO:     Epoch: 14
2022-11-23 00:59:49,945 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.851037326184186, 'Total loss': 0.851037326184186} | train loss {'Reaction outcome loss': 0.8204092419877345, 'Total loss': 0.8204092419877345}
2022-11-23 00:59:49,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:49,946 INFO:     Epoch: 15
2022-11-23 00:59:50,695 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8585519628091292, 'Total loss': 0.8585519628091292} | train loss {'Reaction outcome loss': 0.8187573842856348, 'Total loss': 0.8187573842856348}
2022-11-23 00:59:50,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:50,696 INFO:     Epoch: 16
2022-11-23 00:59:51,479 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8333920253948732, 'Total loss': 0.8333920253948732} | train loss {'Reaction outcome loss': 0.8166029347448933, 'Total loss': 0.8166029347448933}
2022-11-23 00:59:51,479 INFO:     Found new best model at epoch 16
2022-11-23 00:59:51,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:51,480 INFO:     Epoch: 17
2022-11-23 00:59:52,261 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8469280546361749, 'Total loss': 0.8469280546361749} | train loss {'Reaction outcome loss': 0.8226868096663027, 'Total loss': 0.8226868096663027}
2022-11-23 00:59:52,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:52,262 INFO:     Epoch: 18
2022-11-23 00:59:53,045 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8379600061611696, 'Total loss': 0.8379600061611696} | train loss {'Reaction outcome loss': 0.8153429224783061, 'Total loss': 0.8153429224783061}
2022-11-23 00:59:53,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:53,046 INFO:     Epoch: 19
2022-11-23 00:59:53,803 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8498928126963702, 'Total loss': 0.8498928126963702} | train loss {'Reaction outcome loss': 0.8161216856265555, 'Total loss': 0.8161216856265555}
2022-11-23 00:59:53,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:53,803 INFO:     Epoch: 20
2022-11-23 00:59:54,630 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.852767365899953, 'Total loss': 0.852767365899953} | train loss {'Reaction outcome loss': 0.8140493448899717, 'Total loss': 0.8140493448899717}
2022-11-23 00:59:54,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:54,630 INFO:     Epoch: 21
2022-11-23 00:59:55,443 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8470421853390607, 'Total loss': 0.8470421853390607} | train loss {'Reaction outcome loss': 0.8181701793962596, 'Total loss': 0.8181701793962596}
2022-11-23 00:59:55,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:55,444 INFO:     Epoch: 22
2022-11-23 00:59:56,262 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8589317561550573, 'Total loss': 0.8589317561550573} | train loss {'Reaction outcome loss': 0.8172043023060779, 'Total loss': 0.8172043023060779}
2022-11-23 00:59:56,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:56,262 INFO:     Epoch: 23
2022-11-23 00:59:57,105 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.839336178519509, 'Total loss': 0.839336178519509} | train loss {'Reaction outcome loss': 0.8178937023999739, 'Total loss': 0.8178937023999739}
2022-11-23 00:59:57,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:57,105 INFO:     Epoch: 24
2022-11-23 00:59:57,888 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8506537567485463, 'Total loss': 0.8506537567485463} | train loss {'Reaction outcome loss': 0.8104340424343032, 'Total loss': 0.8104340424343032}
2022-11-23 00:59:57,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:57,888 INFO:     Epoch: 25
2022-11-23 00:59:58,704 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8685504618016157, 'Total loss': 0.8685504618016157} | train loss {'Reaction outcome loss': 0.8130717919797313, 'Total loss': 0.8130717919797313}
2022-11-23 00:59:58,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:58,705 INFO:     Epoch: 26
2022-11-23 00:59:59,495 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8280220966447484, 'Total loss': 0.8280220966447484} | train loss {'Reaction outcome loss': 0.8138215914064524, 'Total loss': 0.8138215914064524}
2022-11-23 00:59:59,496 INFO:     Found new best model at epoch 26
2022-11-23 00:59:59,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 00:59:59,496 INFO:     Epoch: 27
2022-11-23 01:00:00,302 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.86155051399361, 'Total loss': 0.86155051399361} | train loss {'Reaction outcome loss': 0.8154629814381502, 'Total loss': 0.8154629814381502}
2022-11-23 01:00:00,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:00,303 INFO:     Epoch: 28
2022-11-23 01:00:01,112 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8392676656896417, 'Total loss': 0.8392676656896417} | train loss {'Reaction outcome loss': 0.8150589374863372, 'Total loss': 0.8150589374863372}
2022-11-23 01:00:01,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:01,112 INFO:     Epoch: 29
2022-11-23 01:00:01,910 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8359609002416785, 'Total loss': 0.8359609002416785} | train loss {'Reaction outcome loss': 0.8123158407454588, 'Total loss': 0.8123158407454588}
2022-11-23 01:00:01,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:01,910 INFO:     Epoch: 30
2022-11-23 01:00:02,680 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8674509457566522, 'Total loss': 0.8674509457566522} | train loss {'Reaction outcome loss': 0.8091692350348648, 'Total loss': 0.8091692350348648}
2022-11-23 01:00:02,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:02,680 INFO:     Epoch: 31
2022-11-23 01:00:03,442 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8383796127005056, 'Total loss': 0.8383796127005056} | train loss {'Reaction outcome loss': 0.815984855257735, 'Total loss': 0.815984855257735}
2022-11-23 01:00:03,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:03,442 INFO:     Epoch: 32
2022-11-23 01:00:04,242 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8439668796279214, 'Total loss': 0.8439668796279214} | train loss {'Reaction outcome loss': 0.8082986149252678, 'Total loss': 0.8082986149252678}
2022-11-23 01:00:04,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:04,242 INFO:     Epoch: 33
2022-11-23 01:00:05,029 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8773645027117296, 'Total loss': 0.8773645027117296} | train loss {'Reaction outcome loss': 0.8134821403999718, 'Total loss': 0.8134821403999718}
2022-11-23 01:00:05,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:05,029 INFO:     Epoch: 34
2022-11-23 01:00:05,800 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8453659103675322, 'Total loss': 0.8453659103675322} | train loss {'Reaction outcome loss': 0.816076027130594, 'Total loss': 0.816076027130594}
2022-11-23 01:00:05,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:05,800 INFO:     Epoch: 35
2022-11-23 01:00:06,578 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8396246738054536, 'Total loss': 0.8396246738054536} | train loss {'Reaction outcome loss': 0.810844268847485, 'Total loss': 0.810844268847485}
2022-11-23 01:00:06,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:06,579 INFO:     Epoch: 36
2022-11-23 01:00:07,364 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8333232937888666, 'Total loss': 0.8333232937888666} | train loss {'Reaction outcome loss': 0.8103907047485819, 'Total loss': 0.8103907047485819}
2022-11-23 01:00:07,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:07,364 INFO:     Epoch: 37
2022-11-23 01:00:08,179 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8633073473518545, 'Total loss': 0.8633073473518545} | train loss {'Reaction outcome loss': 0.80771705216291, 'Total loss': 0.80771705216291}
2022-11-23 01:00:08,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:08,180 INFO:     Epoch: 38
2022-11-23 01:00:09,013 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8439088314771652, 'Total loss': 0.8439088314771652} | train loss {'Reaction outcome loss': 0.8105905048701227, 'Total loss': 0.8105905048701227}
2022-11-23 01:00:09,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:09,014 INFO:     Epoch: 39
2022-11-23 01:00:09,804 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8444851982322606, 'Total loss': 0.8444851982322606} | train loss {'Reaction outcome loss': 0.8103118370990364, 'Total loss': 0.8103118370990364}
2022-11-23 01:00:09,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:09,805 INFO:     Epoch: 40
2022-11-23 01:00:10,557 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8596370992335406, 'Total loss': 0.8596370992335406} | train loss {'Reaction outcome loss': 0.809615482967727, 'Total loss': 0.809615482967727}
2022-11-23 01:00:10,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:10,558 INFO:     Epoch: 41
2022-11-23 01:00:11,354 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8361959680914879, 'Total loss': 0.8361959680914879} | train loss {'Reaction outcome loss': 0.8092800585591063, 'Total loss': 0.8092800585591063}
2022-11-23 01:00:11,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:11,354 INFO:     Epoch: 42
2022-11-23 01:00:12,190 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8276261098005555, 'Total loss': 0.8276261098005555} | train loss {'Reaction outcome loss': 0.8087323488021384, 'Total loss': 0.8087323488021384}
2022-11-23 01:00:12,191 INFO:     Found new best model at epoch 42
2022-11-23 01:00:12,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:12,192 INFO:     Epoch: 43
2022-11-23 01:00:13,034 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8358671902255579, 'Total loss': 0.8358671902255579} | train loss {'Reaction outcome loss': 0.8114177671014046, 'Total loss': 0.8114177671014046}
2022-11-23 01:00:13,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:13,035 INFO:     Epoch: 44
2022-11-23 01:00:13,868 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8337800492617217, 'Total loss': 0.8337800492617217} | train loss {'Reaction outcome loss': 0.8048853840146746, 'Total loss': 0.8048853840146746}
2022-11-23 01:00:13,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:13,869 INFO:     Epoch: 45
2022-11-23 01:00:14,696 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8475307822227478, 'Total loss': 0.8475307822227478} | train loss {'Reaction outcome loss': 0.8111108311585018, 'Total loss': 0.8111108311585018}
2022-11-23 01:00:14,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:14,696 INFO:     Epoch: 46
2022-11-23 01:00:15,521 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8362666029821743, 'Total loss': 0.8362666029821743} | train loss {'Reaction outcome loss': 0.8100130707633738, 'Total loss': 0.8100130707633738}
2022-11-23 01:00:15,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:15,522 INFO:     Epoch: 47
2022-11-23 01:00:16,326 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8312618691812862, 'Total loss': 0.8312618691812862} | train loss {'Reaction outcome loss': 0.808408467380368, 'Total loss': 0.808408467380368}
2022-11-23 01:00:16,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:16,326 INFO:     Epoch: 48
2022-11-23 01:00:17,145 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8415603150020946, 'Total loss': 0.8415603150020946} | train loss {'Reaction outcome loss': 0.8117242544281239, 'Total loss': 0.8117242544281239}
2022-11-23 01:00:17,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:17,145 INFO:     Epoch: 49
2022-11-23 01:00:17,915 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8350509052926843, 'Total loss': 0.8350509052926843} | train loss {'Reaction outcome loss': 0.8058459657795575, 'Total loss': 0.8058459657795575}
2022-11-23 01:00:17,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:17,917 INFO:     Epoch: 50
2022-11-23 01:00:18,731 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.832918641242114, 'Total loss': 0.832918641242114} | train loss {'Reaction outcome loss': 0.8100291609764099, 'Total loss': 0.8100291609764099}
2022-11-23 01:00:18,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:18,732 INFO:     Epoch: 51
2022-11-23 01:00:19,516 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8439826477657665, 'Total loss': 0.8439826477657665} | train loss {'Reaction outcome loss': 0.8061952444971824, 'Total loss': 0.8061952444971824}
2022-11-23 01:00:19,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:19,517 INFO:     Epoch: 52
2022-11-23 01:00:20,305 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8562849881974134, 'Total loss': 0.8562849881974134} | train loss {'Reaction outcome loss': 0.8081812292945628, 'Total loss': 0.8081812292945628}
2022-11-23 01:00:20,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:20,306 INFO:     Epoch: 53
2022-11-23 01:00:21,092 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8278832273049788, 'Total loss': 0.8278832273049788} | train loss {'Reaction outcome loss': 0.8133341685849793, 'Total loss': 0.8133341685849793}
2022-11-23 01:00:21,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:21,092 INFO:     Epoch: 54
2022-11-23 01:00:21,861 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8470354608514092, 'Total loss': 0.8470354608514092} | train loss {'Reaction outcome loss': 0.8052578136628988, 'Total loss': 0.8052578136628988}
2022-11-23 01:00:21,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:21,861 INFO:     Epoch: 55
2022-11-23 01:00:22,614 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8305878476663069, 'Total loss': 0.8305878476663069} | train loss {'Reaction outcome loss': 0.8106601469370783, 'Total loss': 0.8106601469370783}
2022-11-23 01:00:22,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:22,614 INFO:     Epoch: 56
2022-11-23 01:00:23,374 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8434774699536237, 'Total loss': 0.8434774699536237} | train loss {'Reaction outcome loss': 0.8117152009691511, 'Total loss': 0.8117152009691511}
2022-11-23 01:00:23,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:23,375 INFO:     Epoch: 57
2022-11-23 01:00:24,174 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.845131067051129, 'Total loss': 0.845131067051129} | train loss {'Reaction outcome loss': 0.8104548431172662, 'Total loss': 0.8104548431172662}
2022-11-23 01:00:24,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:24,174 INFO:     Epoch: 58
2022-11-23 01:00:24,973 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8376788998192007, 'Total loss': 0.8376788998192007} | train loss {'Reaction outcome loss': 0.8075851726288699, 'Total loss': 0.8075851726288699}
2022-11-23 01:00:24,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:24,973 INFO:     Epoch: 59
2022-11-23 01:00:25,774 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.872210069136186, 'Total loss': 0.872210069136186} | train loss {'Reaction outcome loss': 0.8079749699758023, 'Total loss': 0.8079749699758023}
2022-11-23 01:00:25,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:25,774 INFO:     Epoch: 60
2022-11-23 01:00:26,579 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8364184905182231, 'Total loss': 0.8364184905182231} | train loss {'Reaction outcome loss': 0.8070810528434053, 'Total loss': 0.8070810528434053}
2022-11-23 01:00:26,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:26,579 INFO:     Epoch: 61
2022-11-23 01:00:27,366 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8610408753156662, 'Total loss': 0.8610408753156662} | train loss {'Reaction outcome loss': 0.8098776913419061, 'Total loss': 0.8098776913419061}
2022-11-23 01:00:27,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:27,366 INFO:     Epoch: 62
2022-11-23 01:00:28,242 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.82714136893099, 'Total loss': 0.82714136893099} | train loss {'Reaction outcome loss': 0.8064808883229081, 'Total loss': 0.8064808883229081}
2022-11-23 01:00:28,242 INFO:     Found new best model at epoch 62
2022-11-23 01:00:28,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:28,243 INFO:     Epoch: 63
2022-11-23 01:00:29,031 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.854963631792502, 'Total loss': 0.854963631792502} | train loss {'Reaction outcome loss': 0.80681820572639, 'Total loss': 0.80681820572639}
2022-11-23 01:00:29,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:29,032 INFO:     Epoch: 64
2022-11-23 01:00:29,883 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8242334828458049, 'Total loss': 0.8242334828458049} | train loss {'Reaction outcome loss': 0.8103751609520037, 'Total loss': 0.8103751609520037}
2022-11-23 01:00:29,883 INFO:     Found new best model at epoch 64
2022-11-23 01:00:29,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:29,884 INFO:     Epoch: 65
2022-11-23 01:00:30,702 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8430013995278965, 'Total loss': 0.8430013995278965} | train loss {'Reaction outcome loss': 0.8033706537314824, 'Total loss': 0.8033706537314824}
2022-11-23 01:00:30,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:30,703 INFO:     Epoch: 66
2022-11-23 01:00:31,548 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8255652995272116, 'Total loss': 0.8255652995272116} | train loss {'Reaction outcome loss': 0.8092881184451434, 'Total loss': 0.8092881184451434}
2022-11-23 01:00:31,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:31,548 INFO:     Epoch: 67
2022-11-23 01:00:32,379 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8477779735218395, 'Total loss': 0.8477779735218395} | train loss {'Reaction outcome loss': 0.8036262836991525, 'Total loss': 0.8036262836991525}
2022-11-23 01:00:32,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:32,380 INFO:     Epoch: 68
2022-11-23 01:00:33,224 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.848988682708957, 'Total loss': 0.848988682708957} | train loss {'Reaction outcome loss': 0.8114274999316857, 'Total loss': 0.8114274999316857}
2022-11-23 01:00:33,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:33,225 INFO:     Epoch: 69
2022-11-23 01:00:34,059 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8252117268063806, 'Total loss': 0.8252117268063806} | train loss {'Reaction outcome loss': 0.8099869853379775, 'Total loss': 0.8099869853379775}
2022-11-23 01:00:34,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:34,061 INFO:     Epoch: 70
2022-11-23 01:00:34,876 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8472693887623873, 'Total loss': 0.8472693887623873} | train loss {'Reaction outcome loss': 0.8092613608253245, 'Total loss': 0.8092613608253245}
2022-11-23 01:00:34,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:34,876 INFO:     Epoch: 71
2022-11-23 01:00:35,685 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8800784342668273, 'Total loss': 0.8800784342668273} | train loss {'Reaction outcome loss': 0.8050887584686279, 'Total loss': 0.8050887584686279}
2022-11-23 01:00:35,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:35,686 INFO:     Epoch: 72
2022-11-23 01:00:36,498 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.842762449925596, 'Total loss': 0.842762449925596} | train loss {'Reaction outcome loss': 0.8070066720855479, 'Total loss': 0.8070066720855479}
2022-11-23 01:00:36,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:36,498 INFO:     Epoch: 73
2022-11-23 01:00:37,281 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8432237113063986, 'Total loss': 0.8432237113063986} | train loss {'Reaction outcome loss': 0.8077686139515468, 'Total loss': 0.8077686139515468}
2022-11-23 01:00:37,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:37,282 INFO:     Epoch: 74
2022-11-23 01:00:38,078 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8326345898888328, 'Total loss': 0.8326345898888328} | train loss {'Reaction outcome loss': 0.80719481463335, 'Total loss': 0.80719481463335}
2022-11-23 01:00:38,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:38,078 INFO:     Epoch: 75
2022-11-23 01:00:38,895 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8778870796615427, 'Total loss': 0.8778870796615427} | train loss {'Reaction outcome loss': 0.8070536957711589, 'Total loss': 0.8070536957711589}
2022-11-23 01:00:38,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:38,895 INFO:     Epoch: 76
2022-11-23 01:00:39,708 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8697706074877218, 'Total loss': 0.8697706074877218} | train loss {'Reaction outcome loss': 0.808322176154779, 'Total loss': 0.808322176154779}
2022-11-23 01:00:39,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:39,708 INFO:     Epoch: 77
2022-11-23 01:00:40,530 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8438193831931461, 'Total loss': 0.8438193831931461} | train loss {'Reaction outcome loss': 0.8109444474687382, 'Total loss': 0.8109444474687382}
2022-11-23 01:00:40,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:40,531 INFO:     Epoch: 78
2022-11-23 01:00:41,359 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8323177004402335, 'Total loss': 0.8323177004402335} | train loss {'Reaction outcome loss': 0.8084461667099777, 'Total loss': 0.8084461667099777}
2022-11-23 01:00:41,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:41,359 INFO:     Epoch: 79
2022-11-23 01:00:42,170 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8435263098640875, 'Total loss': 0.8435263098640875} | train loss {'Reaction outcome loss': 0.8084720342743154, 'Total loss': 0.8084720342743154}
2022-11-23 01:00:42,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:42,170 INFO:     Epoch: 80
2022-11-23 01:00:42,968 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8527009229768406, 'Total loss': 0.8527009229768406} | train loss {'Reaction outcome loss': 0.8061422048782816, 'Total loss': 0.8061422048782816}
2022-11-23 01:00:42,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:42,968 INFO:     Epoch: 81
2022-11-23 01:00:43,757 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8619751059873537, 'Total loss': 0.8619751059873537} | train loss {'Reaction outcome loss': 0.8110757197652544, 'Total loss': 0.8110757197652544}
2022-11-23 01:00:43,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:43,758 INFO:     Epoch: 82
2022-11-23 01:00:44,557 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8334134254943241, 'Total loss': 0.8334134254943241} | train loss {'Reaction outcome loss': 0.8093674405496948, 'Total loss': 0.8093674405496948}
2022-11-23 01:00:44,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:44,557 INFO:     Epoch: 83
2022-11-23 01:00:45,340 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.836784379048781, 'Total loss': 0.836784379048781} | train loss {'Reaction outcome loss': 0.8064264704986495, 'Total loss': 0.8064264704986495}
2022-11-23 01:00:45,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:45,341 INFO:     Epoch: 84
2022-11-23 01:00:46,128 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8405890925364061, 'Total loss': 0.8405890925364061} | train loss {'Reaction outcome loss': 0.8040735686311916, 'Total loss': 0.8040735686311916}
2022-11-23 01:00:46,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:46,129 INFO:     Epoch: 85
2022-11-23 01:00:46,952 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8447827425870028, 'Total loss': 0.8447827425870028} | train loss {'Reaction outcome loss': 0.8094526761648606, 'Total loss': 0.8094526761648606}
2022-11-23 01:00:46,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:46,953 INFO:     Epoch: 86
2022-11-23 01:00:47,782 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8597132915800269, 'Total loss': 0.8597132915800269} | train loss {'Reaction outcome loss': 0.8057521359044678, 'Total loss': 0.8057521359044678}
2022-11-23 01:00:47,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:47,782 INFO:     Epoch: 87
2022-11-23 01:00:48,617 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8391854695298455, 'Total loss': 0.8391854695298455} | train loss {'Reaction outcome loss': 0.8098958200337936, 'Total loss': 0.8098958200337936}
2022-11-23 01:00:48,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:48,618 INFO:     Epoch: 88
2022-11-23 01:00:49,440 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8345569656653837, 'Total loss': 0.8345569656653837} | train loss {'Reaction outcome loss': 0.8080034112443729, 'Total loss': 0.8080034112443729}
2022-11-23 01:00:49,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:49,440 INFO:     Epoch: 89
2022-11-23 01:00:50,243 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8274878934025764, 'Total loss': 0.8274878934025764} | train loss {'Reaction outcome loss': 0.811736184601881, 'Total loss': 0.811736184601881}
2022-11-23 01:00:50,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:50,243 INFO:     Epoch: 90
2022-11-23 01:00:51,012 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8577686846256256, 'Total loss': 0.8577686846256256} | train loss {'Reaction outcome loss': 0.8062225434244895, 'Total loss': 0.8062225434244895}
2022-11-23 01:00:51,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:51,013 INFO:     Epoch: 91
2022-11-23 01:00:51,783 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8641219762238589, 'Total loss': 0.8641219762238589} | train loss {'Reaction outcome loss': 0.8086337731809032, 'Total loss': 0.8086337731809032}
2022-11-23 01:00:51,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:51,783 INFO:     Epoch: 92
2022-11-23 01:00:52,541 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8484181707555597, 'Total loss': 0.8484181707555597} | train loss {'Reaction outcome loss': 0.806602760723659, 'Total loss': 0.806602760723659}
2022-11-23 01:00:52,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:52,541 INFO:     Epoch: 93
2022-11-23 01:00:53,293 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.837240339002826, 'Total loss': 0.837240339002826} | train loss {'Reaction outcome loss': 0.8047753465418913, 'Total loss': 0.8047753465418913}
2022-11-23 01:00:53,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:53,293 INFO:     Epoch: 94
2022-11-23 01:00:54,075 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8499117866158485, 'Total loss': 0.8499117866158485} | train loss {'Reaction outcome loss': 0.8097021144263599, 'Total loss': 0.8097021144263599}
2022-11-23 01:00:54,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:54,076 INFO:     Epoch: 95
2022-11-23 01:00:54,850 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8751463578505949, 'Total loss': 0.8751463578505949} | train loss {'Reaction outcome loss': 0.8083492015089307, 'Total loss': 0.8083492015089307}
2022-11-23 01:00:54,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:54,850 INFO:     Epoch: 96
2022-11-23 01:00:55,631 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8523572825572707, 'Total loss': 0.8523572825572707} | train loss {'Reaction outcome loss': 0.8079053527238418, 'Total loss': 0.8079053527238418}
2022-11-23 01:00:55,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:55,632 INFO:     Epoch: 97
2022-11-23 01:00:56,407 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8262072991241108, 'Total loss': 0.8262072991241108} | train loss {'Reaction outcome loss': 0.8073926186075016, 'Total loss': 0.8073926186075016}
2022-11-23 01:00:56,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:56,407 INFO:     Epoch: 98
2022-11-23 01:00:57,183 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8415479646487669, 'Total loss': 0.8415479646487669} | train loss {'Reaction outcome loss': 0.810113276024254, 'Total loss': 0.810113276024254}
2022-11-23 01:00:57,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:57,184 INFO:     Epoch: 99
2022-11-23 01:00:57,978 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8302572626959194, 'Total loss': 0.8302572626959194} | train loss {'Reaction outcome loss': 0.8098581054989172, 'Total loss': 0.8098581054989172}
2022-11-23 01:00:57,978 INFO:     Best model found after epoch 65 of 100.
2022-11-23 01:00:57,978 INFO:   Done with stage: TRAINING
2022-11-23 01:00:57,978 INFO:   Starting stage: EVALUATION
2022-11-23 01:00:58,112 INFO:   Done with stage: EVALUATION
2022-11-23 01:00:58,121 INFO:   Leaving out SEQ value Fold_0
2022-11-23 01:00:58,134 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-23 01:00:58,135 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:00:58,797 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:00:58,797 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:00:58,867 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:00:58,867 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:00:58,867 INFO:     No hyperparam tuning for this model
2022-11-23 01:00:58,867 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:00:58,867 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:00:58,868 INFO:     None feature selector for col prot
2022-11-23 01:00:58,868 INFO:     None feature selector for col prot
2022-11-23 01:00:58,868 INFO:     None feature selector for col prot
2022-11-23 01:00:58,869 INFO:     None feature selector for col chem
2022-11-23 01:00:58,869 INFO:     None feature selector for col chem
2022-11-23 01:00:58,869 INFO:     None feature selector for col chem
2022-11-23 01:00:58,869 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:00:58,869 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:00:58,871 INFO:     Number of params in model 168571
2022-11-23 01:00:58,874 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:00:58,874 INFO:   Starting stage: TRAINING
2022-11-23 01:00:58,931 INFO:     Val loss before train {'Reaction outcome loss': 1.0233343007952669, 'Total loss': 1.0233343007952669}
2022-11-23 01:00:58,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:58,931 INFO:     Epoch: 0
2022-11-23 01:00:59,705 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8495485921238743, 'Total loss': 0.8495485921238743} | train loss {'Reaction outcome loss': 0.8832587892891931, 'Total loss': 0.8832587892891931}
2022-11-23 01:00:59,705 INFO:     Found new best model at epoch 0
2022-11-23 01:00:59,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:00:59,706 INFO:     Epoch: 1
2022-11-23 01:01:00,480 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8644530856332113, 'Total loss': 0.8644530856332113} | train loss {'Reaction outcome loss': 0.8490346190137942, 'Total loss': 0.8490346190137942}
2022-11-23 01:01:00,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:00,480 INFO:     Epoch: 2
2022-11-23 01:01:01,277 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8370336411997329, 'Total loss': 0.8370336411997329} | train loss {'Reaction outcome loss': 0.8484414363982248, 'Total loss': 0.8484414363982248}
2022-11-23 01:01:01,278 INFO:     Found new best model at epoch 2
2022-11-23 01:01:01,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:01,279 INFO:     Epoch: 3
2022-11-23 01:01:02,050 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8439713841260865, 'Total loss': 0.8439713841260865} | train loss {'Reaction outcome loss': 0.8414376315767648, 'Total loss': 0.8414376315767648}
2022-11-23 01:01:02,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:02,050 INFO:     Epoch: 4
2022-11-23 01:01:02,837 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8311464426129364, 'Total loss': 0.8311464426129364} | train loss {'Reaction outcome loss': 0.8374156826099411, 'Total loss': 0.8374156826099411}
2022-11-23 01:01:02,838 INFO:     Found new best model at epoch 4
2022-11-23 01:01:02,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:02,839 INFO:     Epoch: 5
2022-11-23 01:01:03,649 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8463663299416386, 'Total loss': 0.8463663299416386} | train loss {'Reaction outcome loss': 0.8333784864574182, 'Total loss': 0.8333784864574182}
2022-11-23 01:01:03,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:03,649 INFO:     Epoch: 6
2022-11-23 01:01:04,486 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8509167515954306, 'Total loss': 0.8509167515954306} | train loss {'Reaction outcome loss': 0.8293028539810025, 'Total loss': 0.8293028539810025}
2022-11-23 01:01:04,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:04,487 INFO:     Epoch: 7
2022-11-23 01:01:05,321 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8195318759873856, 'Total loss': 0.8195318759873856} | train loss {'Reaction outcome loss': 0.8318832096506338, 'Total loss': 0.8318832096506338}
2022-11-23 01:01:05,321 INFO:     Found new best model at epoch 7
2022-11-23 01:01:05,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:05,322 INFO:     Epoch: 8
2022-11-23 01:01:06,114 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8460336715676063, 'Total loss': 0.8460336715676063} | train loss {'Reaction outcome loss': 0.8296891339733953, 'Total loss': 0.8296891339733953}
2022-11-23 01:01:06,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:06,114 INFO:     Epoch: 9
2022-11-23 01:01:06,915 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8426118527734002, 'Total loss': 0.8426118527734002} | train loss {'Reaction outcome loss': 0.8262145127185055, 'Total loss': 0.8262145127185055}
2022-11-23 01:01:06,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:06,915 INFO:     Epoch: 10
2022-11-23 01:01:07,730 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8251337492188742, 'Total loss': 0.8251337492188742} | train loss {'Reaction outcome loss': 0.8211216723821202, 'Total loss': 0.8211216723821202}
2022-11-23 01:01:07,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:07,730 INFO:     Epoch: 11
2022-11-23 01:01:08,499 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8429876593656318, 'Total loss': 0.8429876593656318} | train loss {'Reaction outcome loss': 0.8231821612256472, 'Total loss': 0.8231821612256472}
2022-11-23 01:01:08,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:08,500 INFO:     Epoch: 12
2022-11-23 01:01:09,300 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8497788213020148, 'Total loss': 0.8497788213020148} | train loss {'Reaction outcome loss': 0.8220257876349277, 'Total loss': 0.8220257876349277}
2022-11-23 01:01:09,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:09,300 INFO:     Epoch: 13
2022-11-23 01:01:10,114 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8171813051367915, 'Total loss': 0.8171813051367915} | train loss {'Reaction outcome loss': 0.8256778190614747, 'Total loss': 0.8256778190614747}
2022-11-23 01:01:10,114 INFO:     Found new best model at epoch 13
2022-11-23 01:01:10,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:10,115 INFO:     Epoch: 14
2022-11-23 01:01:10,947 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8179094541904538, 'Total loss': 0.8179094541904538} | train loss {'Reaction outcome loss': 0.8229096182545678, 'Total loss': 0.8229096182545678}
2022-11-23 01:01:10,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:10,947 INFO:     Epoch: 15
2022-11-23 01:01:11,742 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8515905696292256, 'Total loss': 0.8515905696292256} | train loss {'Reaction outcome loss': 0.818257387177866, 'Total loss': 0.818257387177866}
2022-11-23 01:01:11,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:11,742 INFO:     Epoch: 16
2022-11-23 01:01:12,551 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8344217552695163, 'Total loss': 0.8344217552695163} | train loss {'Reaction outcome loss': 0.8263342298689436, 'Total loss': 0.8263342298689436}
2022-11-23 01:01:12,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:12,552 INFO:     Epoch: 17
2022-11-23 01:01:13,340 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8216163751690887, 'Total loss': 0.8216163751690887} | train loss {'Reaction outcome loss': 0.8211620805449173, 'Total loss': 0.8211620805449173}
2022-11-23 01:01:13,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:13,340 INFO:     Epoch: 18
2022-11-23 01:01:14,117 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8425148365109466, 'Total loss': 0.8425148365109466} | train loss {'Reaction outcome loss': 0.8221711642185195, 'Total loss': 0.8221711642185195}
2022-11-23 01:01:14,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:14,118 INFO:     Epoch: 19
2022-11-23 01:01:14,907 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8326316836268403, 'Total loss': 0.8326316836268403} | train loss {'Reaction outcome loss': 0.8181230826456038, 'Total loss': 0.8181230826456038}
2022-11-23 01:01:14,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:14,908 INFO:     Epoch: 20
2022-11-23 01:01:15,692 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8286378660867381, 'Total loss': 0.8286378660867381} | train loss {'Reaction outcome loss': 0.8184286807892752, 'Total loss': 0.8184286807892752}
2022-11-23 01:01:15,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:15,693 INFO:     Epoch: 21
2022-11-23 01:01:16,472 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8196306873199551, 'Total loss': 0.8196306873199551} | train loss {'Reaction outcome loss': 0.8174686431884766, 'Total loss': 0.8174686431884766}
2022-11-23 01:01:16,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:16,472 INFO:     Epoch: 22
2022-11-23 01:01:17,257 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8192814838054568, 'Total loss': 0.8192814838054568} | train loss {'Reaction outcome loss': 0.8203218352110659, 'Total loss': 0.8203218352110659}
2022-11-23 01:01:17,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:17,257 INFO:     Epoch: 23
2022-11-23 01:01:18,045 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8303522550782492, 'Total loss': 0.8303522550782492} | train loss {'Reaction outcome loss': 0.8249803655704514, 'Total loss': 0.8249803655704514}
2022-11-23 01:01:18,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:18,045 INFO:     Epoch: 24
2022-11-23 01:01:18,889 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.836429491985676, 'Total loss': 0.836429491985676} | train loss {'Reaction outcome loss': 0.8168111114961202, 'Total loss': 0.8168111114961202}
2022-11-23 01:01:18,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:18,890 INFO:     Epoch: 25
2022-11-23 01:01:19,679 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8382333024989727, 'Total loss': 0.8382333024989727} | train loss {'Reaction outcome loss': 0.8197592066936805, 'Total loss': 0.8197592066936805}
2022-11-23 01:01:19,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:19,680 INFO:     Epoch: 26
2022-11-23 01:01:20,505 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8379506843034611, 'Total loss': 0.8379506843034611} | train loss {'Reaction outcome loss': 0.8267446813769028, 'Total loss': 0.8267446813769028}
2022-11-23 01:01:20,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:20,506 INFO:     Epoch: 27
2022-11-23 01:01:21,335 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8298062495020933, 'Total loss': 0.8298062495020933} | train loss {'Reaction outcome loss': 0.8179764111266762, 'Total loss': 0.8179764111266762}
2022-11-23 01:01:21,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:21,335 INFO:     Epoch: 28
2022-11-23 01:01:22,151 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8115625492362089, 'Total loss': 0.8115625492362089} | train loss {'Reaction outcome loss': 0.8175871590854692, 'Total loss': 0.8175871590854692}
2022-11-23 01:01:22,151 INFO:     Found new best model at epoch 28
2022-11-23 01:01:22,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:22,152 INFO:     Epoch: 29
2022-11-23 01:01:22,961 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8123052452885827, 'Total loss': 0.8123052452885827} | train loss {'Reaction outcome loss': 0.8185539627905751, 'Total loss': 0.8185539627905751}
2022-11-23 01:01:22,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:22,961 INFO:     Epoch: 30
2022-11-23 01:01:23,766 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8193305890227474, 'Total loss': 0.8193305890227474} | train loss {'Reaction outcome loss': 0.8239251006333554, 'Total loss': 0.8239251006333554}
2022-11-23 01:01:23,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:23,767 INFO:     Epoch: 31
2022-11-23 01:01:24,547 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8338646867940592, 'Total loss': 0.8338646867940592} | train loss {'Reaction outcome loss': 0.8197738218014358, 'Total loss': 0.8197738218014358}
2022-11-23 01:01:24,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:24,548 INFO:     Epoch: 32
2022-11-23 01:01:25,405 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.812308059182278, 'Total loss': 0.812308059182278} | train loss {'Reaction outcome loss': 0.8185835409848417, 'Total loss': 0.8185835409848417}
2022-11-23 01:01:25,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:25,405 INFO:     Epoch: 33
2022-11-23 01:01:26,220 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8241817826448485, 'Total loss': 0.8241817826448485} | train loss {'Reaction outcome loss': 0.8153106292984524, 'Total loss': 0.8153106292984524}
2022-11-23 01:01:26,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:26,220 INFO:     Epoch: 34
2022-11-23 01:01:27,081 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8179721194644307, 'Total loss': 0.8179721194644307} | train loss {'Reaction outcome loss': 0.8167905290840102, 'Total loss': 0.8167905290840102}
2022-11-23 01:01:27,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:27,082 INFO:     Epoch: 35
2022-11-23 01:01:27,862 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.817623247240865, 'Total loss': 0.817623247240865} | train loss {'Reaction outcome loss': 0.8168378477213812, 'Total loss': 0.8168378477213812}
2022-11-23 01:01:27,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:27,863 INFO:     Epoch: 36
2022-11-23 01:01:28,652 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8355344478474107, 'Total loss': 0.8355344478474107} | train loss {'Reaction outcome loss': 0.8223925649386937, 'Total loss': 0.8223925649386937}
2022-11-23 01:01:28,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:28,652 INFO:     Epoch: 37
2022-11-23 01:01:29,436 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8154978093712829, 'Total loss': 0.8154978093712829} | train loss {'Reaction outcome loss': 0.8164750056677177, 'Total loss': 0.8164750056677177}
2022-11-23 01:01:29,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:29,436 INFO:     Epoch: 38
2022-11-23 01:01:30,244 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.833632497593414, 'Total loss': 0.833632497593414} | train loss {'Reaction outcome loss': 0.8150561423819573, 'Total loss': 0.8150561423819573}
2022-11-23 01:01:30,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:30,244 INFO:     Epoch: 39
2022-11-23 01:01:31,026 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8264206412226655, 'Total loss': 0.8264206412226655} | train loss {'Reaction outcome loss': 0.8189628036295782, 'Total loss': 0.8189628036295782}
2022-11-23 01:01:31,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:31,028 INFO:     Epoch: 40
2022-11-23 01:01:31,814 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8343684742617052, 'Total loss': 0.8343684742617052} | train loss {'Reaction outcome loss': 0.8166408610881352, 'Total loss': 0.8166408610881352}
2022-11-23 01:01:31,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:31,814 INFO:     Epoch: 41
2022-11-23 01:01:32,580 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8095667175082273, 'Total loss': 0.8095667175082273} | train loss {'Reaction outcome loss': 0.8189929284033228, 'Total loss': 0.8189929284033228}
2022-11-23 01:01:32,580 INFO:     Found new best model at epoch 41
2022-11-23 01:01:32,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:32,581 INFO:     Epoch: 42
2022-11-23 01:01:33,401 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8341795448646989, 'Total loss': 0.8341795448646989} | train loss {'Reaction outcome loss': 0.8174150173292786, 'Total loss': 0.8174150173292786}
2022-11-23 01:01:33,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:33,401 INFO:     Epoch: 43
2022-11-23 01:01:34,246 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8238547375035841, 'Total loss': 0.8238547375035841} | train loss {'Reaction outcome loss': 0.8155203219808516, 'Total loss': 0.8155203219808516}
2022-11-23 01:01:34,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:34,246 INFO:     Epoch: 44
2022-11-23 01:01:35,028 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8333415486091791, 'Total loss': 0.8333415486091791} | train loss {'Reaction outcome loss': 0.8211628666422406, 'Total loss': 0.8211628666422406}
2022-11-23 01:01:35,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:35,028 INFO:     Epoch: 45
2022-11-23 01:01:35,814 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8220204503037208, 'Total loss': 0.8220204503037208} | train loss {'Reaction outcome loss': 0.8131691476360696, 'Total loss': 0.8131691476360696}
2022-11-23 01:01:35,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:35,814 INFO:     Epoch: 46
2022-11-23 01:01:36,617 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8639943849208743, 'Total loss': 0.8639943849208743} | train loss {'Reaction outcome loss': 0.8153489549629024, 'Total loss': 0.8153489549629024}
2022-11-23 01:01:36,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:36,619 INFO:     Epoch: 47
2022-11-23 01:01:37,387 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.826243807410085, 'Total loss': 0.826243807410085} | train loss {'Reaction outcome loss': 0.818682326523007, 'Total loss': 0.818682326523007}
2022-11-23 01:01:37,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:37,387 INFO:     Epoch: 48
2022-11-23 01:01:38,194 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8138242460960565, 'Total loss': 0.8138242460960565} | train loss {'Reaction outcome loss': 0.8162929022409877, 'Total loss': 0.8162929022409877}
2022-11-23 01:01:38,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:38,195 INFO:     Epoch: 49
2022-11-23 01:01:38,961 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.831220677425695, 'Total loss': 0.831220677425695} | train loss {'Reaction outcome loss': 0.8141159966099457, 'Total loss': 0.8141159966099457}
2022-11-23 01:01:38,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:38,961 INFO:     Epoch: 50
2022-11-23 01:01:39,791 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8282156434170035, 'Total loss': 0.8282156434170035} | train loss {'Reaction outcome loss': 0.8225300856789605, 'Total loss': 0.8225300856789605}
2022-11-23 01:01:39,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:39,791 INFO:     Epoch: 51
2022-11-23 01:01:40,598 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8157287052897519, 'Total loss': 0.8157287052897519} | train loss {'Reaction outcome loss': 0.822046025610361, 'Total loss': 0.822046025610361}
2022-11-23 01:01:40,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:40,598 INFO:     Epoch: 52
2022-11-23 01:01:41,412 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8241359120191529, 'Total loss': 0.8241359120191529} | train loss {'Reaction outcome loss': 0.8159775897616246, 'Total loss': 0.8159775897616246}
2022-11-23 01:01:41,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:41,412 INFO:     Epoch: 53
2022-11-23 01:01:42,234 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8076945515566094, 'Total loss': 0.8076945515566094} | train loss {'Reaction outcome loss': 0.8171726347970181, 'Total loss': 0.8171726347970181}
2022-11-23 01:01:42,235 INFO:     Found new best model at epoch 53
2022-11-23 01:01:42,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:42,236 INFO:     Epoch: 54
2022-11-23 01:01:43,015 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8646947887054709, 'Total loss': 0.8646947887054709} | train loss {'Reaction outcome loss': 0.8161751764719604, 'Total loss': 0.8161751764719604}
2022-11-23 01:01:43,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:43,015 INFO:     Epoch: 55
2022-11-23 01:01:43,798 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.839792900307234, 'Total loss': 0.839792900307234} | train loss {'Reaction outcome loss': 0.8174112064183735, 'Total loss': 0.8174112064183735}
2022-11-23 01:01:43,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:43,799 INFO:     Epoch: 56
2022-11-23 01:01:44,538 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8159340065579082, 'Total loss': 0.8159340065579082} | train loss {'Reaction outcome loss': 0.819038410900069, 'Total loss': 0.819038410900069}
2022-11-23 01:01:44,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:44,539 INFO:     Epoch: 57
2022-11-23 01:01:45,385 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8155014611953912, 'Total loss': 0.8155014611953912} | train loss {'Reaction outcome loss': 0.8143459946894255, 'Total loss': 0.8143459946894255}
2022-11-23 01:01:45,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:45,386 INFO:     Epoch: 58
2022-11-23 01:01:46,220 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8345308040463647, 'Total loss': 0.8345308040463647} | train loss {'Reaction outcome loss': 0.8179005390552224, 'Total loss': 0.8179005390552224}
2022-11-23 01:01:46,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:46,220 INFO:     Epoch: 59
2022-11-23 01:01:47,022 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8138849776844646, 'Total loss': 0.8138849776844646} | train loss {'Reaction outcome loss': 0.8163788983079253, 'Total loss': 0.8163788983079253}
2022-11-23 01:01:47,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:47,023 INFO:     Epoch: 60
2022-11-23 01:01:47,821 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.821885603804921, 'Total loss': 0.821885603804921} | train loss {'Reaction outcome loss': 0.8214994339180774, 'Total loss': 0.8214994339180774}
2022-11-23 01:01:47,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:47,823 INFO:     Epoch: 61
2022-11-23 01:01:48,656 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8263504255649655, 'Total loss': 0.8263504255649655} | train loss {'Reaction outcome loss': 0.8180700285268612, 'Total loss': 0.8180700285268612}
2022-11-23 01:01:48,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:48,656 INFO:     Epoch: 62
2022-11-23 01:01:49,532 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8182060254174609, 'Total loss': 0.8182060254174609} | train loss {'Reaction outcome loss': 0.8124953212796665, 'Total loss': 0.8124953212796665}
2022-11-23 01:01:49,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:49,532 INFO:     Epoch: 63
2022-11-23 01:01:50,376 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8167595031649567, 'Total loss': 0.8167595031649567} | train loss {'Reaction outcome loss': 0.8168627305841837, 'Total loss': 0.8168627305841837}
2022-11-23 01:01:50,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:50,376 INFO:     Epoch: 64
2022-11-23 01:01:51,186 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8252853543259376, 'Total loss': 0.8252853543259376} | train loss {'Reaction outcome loss': 0.8209852786337744, 'Total loss': 0.8209852786337744}
2022-11-23 01:01:51,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:51,186 INFO:     Epoch: 65
2022-11-23 01:01:51,989 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8112301916577095, 'Total loss': 0.8112301916577095} | train loss {'Reaction outcome loss': 0.8154430020539487, 'Total loss': 0.8154430020539487}
2022-11-23 01:01:51,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:51,989 INFO:     Epoch: 66
2022-11-23 01:01:52,776 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.82695487696071, 'Total loss': 0.82695487696071} | train loss {'Reaction outcome loss': 0.8173190263695405, 'Total loss': 0.8173190263695405}
2022-11-23 01:01:52,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:52,778 INFO:     Epoch: 67
2022-11-23 01:01:53,635 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8180092476135077, 'Total loss': 0.8180092476135077} | train loss {'Reaction outcome loss': 0.8146904535347321, 'Total loss': 0.8146904535347321}
2022-11-23 01:01:53,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:53,635 INFO:     Epoch: 68
2022-11-23 01:01:54,441 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8186739738597426, 'Total loss': 0.8186739738597426} | train loss {'Reaction outcome loss': 0.8160677458174893, 'Total loss': 0.8160677458174893}
2022-11-23 01:01:54,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:54,442 INFO:     Epoch: 69
2022-11-23 01:01:55,280 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8383270557536635, 'Total loss': 0.8383270557536635} | train loss {'Reaction outcome loss': 0.8174284973838291, 'Total loss': 0.8174284973838291}
2022-11-23 01:01:55,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:55,281 INFO:     Epoch: 70
2022-11-23 01:01:56,079 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8159881816353909, 'Total loss': 0.8159881816353909} | train loss {'Reaction outcome loss': 0.8179917346502914, 'Total loss': 0.8179917346502914}
2022-11-23 01:01:56,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:56,079 INFO:     Epoch: 71
2022-11-23 01:01:56,860 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8184038359065389, 'Total loss': 0.8184038359065389} | train loss {'Reaction outcome loss': 0.8123484065786737, 'Total loss': 0.8123484065786737}
2022-11-23 01:01:56,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:56,860 INFO:     Epoch: 72
2022-11-23 01:01:57,671 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8254229481830153, 'Total loss': 0.8254229481830153} | train loss {'Reaction outcome loss': 0.8212522291502015, 'Total loss': 0.8212522291502015}
2022-11-23 01:01:57,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:57,672 INFO:     Epoch: 73
2022-11-23 01:01:58,474 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8468917400337929, 'Total loss': 0.8468917400337929} | train loss {'Reaction outcome loss': 0.8132210515561651, 'Total loss': 0.8132210515561651}
2022-11-23 01:01:58,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:58,474 INFO:     Epoch: 74
2022-11-23 01:01:59,271 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8352027507715447, 'Total loss': 0.8352027507715447} | train loss {'Reaction outcome loss': 0.8171563525913191, 'Total loss': 0.8171563525913191}
2022-11-23 01:01:59,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:01:59,273 INFO:     Epoch: 75
2022-11-23 01:02:00,070 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.822813842185708, 'Total loss': 0.822813842185708} | train loss {'Reaction outcome loss': 0.8126734915326853, 'Total loss': 0.8126734915326853}
2022-11-23 01:02:00,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:00,070 INFO:     Epoch: 76
2022-11-23 01:02:00,898 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8598341151725414, 'Total loss': 0.8598341151725414} | train loss {'Reaction outcome loss': 0.8183553017309455, 'Total loss': 0.8183553017309455}
2022-11-23 01:02:00,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:00,898 INFO:     Epoch: 77
2022-11-23 01:02:01,737 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8294812891372415, 'Total loss': 0.8294812891372415} | train loss {'Reaction outcome loss': 0.8162220657848921, 'Total loss': 0.8162220657848921}
2022-11-23 01:02:01,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:01,737 INFO:     Epoch: 78
2022-11-23 01:02:02,554 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8414423382559488, 'Total loss': 0.8414423382559488} | train loss {'Reaction outcome loss': 0.8144896334556283, 'Total loss': 0.8144896334556283}
2022-11-23 01:02:02,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:02,555 INFO:     Epoch: 79
2022-11-23 01:02:03,348 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8229434462480767, 'Total loss': 0.8229434462480767} | train loss {'Reaction outcome loss': 0.8157505957318134, 'Total loss': 0.8157505957318134}
2022-11-23 01:02:03,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:03,348 INFO:     Epoch: 80
2022-11-23 01:02:04,245 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8217683545378751, 'Total loss': 0.8217683545378751} | train loss {'Reaction outcome loss': 0.8177177113343458, 'Total loss': 0.8177177113343458}
2022-11-23 01:02:04,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:04,247 INFO:     Epoch: 81
2022-11-23 01:02:05,155 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.819384646277095, 'Total loss': 0.819384646277095} | train loss {'Reaction outcome loss': 0.8134362993181729, 'Total loss': 0.8134362993181729}
2022-11-23 01:02:05,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:05,155 INFO:     Epoch: 82
2022-11-23 01:02:06,052 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8299129369647004, 'Total loss': 0.8299129369647004} | train loss {'Reaction outcome loss': 0.8199734165043128, 'Total loss': 0.8199734165043128}
2022-11-23 01:02:06,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:06,053 INFO:     Epoch: 83
2022-11-23 01:02:06,895 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8114008390626242, 'Total loss': 0.8114008390626242} | train loss {'Reaction outcome loss': 0.8189781771087256, 'Total loss': 0.8189781771087256}
2022-11-23 01:02:06,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:06,896 INFO:     Epoch: 84
2022-11-23 01:02:07,755 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8378144793732222, 'Total loss': 0.8378144793732222} | train loss {'Reaction outcome loss': 0.8112992967982762, 'Total loss': 0.8112992967982762}
2022-11-23 01:02:07,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:07,755 INFO:     Epoch: 85
2022-11-23 01:02:08,654 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.835048611774001, 'Total loss': 0.835048611774001} | train loss {'Reaction outcome loss': 0.8162444634515731, 'Total loss': 0.8162444634515731}
2022-11-23 01:02:08,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:08,654 INFO:     Epoch: 86
2022-11-23 01:02:09,531 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8449320391167042, 'Total loss': 0.8449320391167042} | train loss {'Reaction outcome loss': 0.8165318899955906, 'Total loss': 0.8165318899955906}
2022-11-23 01:02:09,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:09,531 INFO:     Epoch: 87
2022-11-23 01:02:10,418 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8360536382641903, 'Total loss': 0.8360536382641903} | train loss {'Reaction outcome loss': 0.8151985116180827, 'Total loss': 0.8151985116180827}
2022-11-23 01:02:10,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:10,419 INFO:     Epoch: 88
2022-11-23 01:02:11,320 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8435763335505198, 'Total loss': 0.8435763335505198} | train loss {'Reaction outcome loss': 0.8155492825097725, 'Total loss': 0.8155492825097725}
2022-11-23 01:02:11,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:11,320 INFO:     Epoch: 89
2022-11-23 01:02:12,211 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8266177219013835, 'Total loss': 0.8266177219013835} | train loss {'Reaction outcome loss': 0.8142159237969117, 'Total loss': 0.8142159237969117}
2022-11-23 01:02:12,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:12,211 INFO:     Epoch: 90
2022-11-23 01:02:13,144 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.811001545468042, 'Total loss': 0.811001545468042} | train loss {'Reaction outcome loss': 0.8182966346379186, 'Total loss': 0.8182966346379186}
2022-11-23 01:02:13,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:13,144 INFO:     Epoch: 91
2022-11-23 01:02:14,046 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8208486292251321, 'Total loss': 0.8208486292251321} | train loss {'Reaction outcome loss': 0.8187851337868659, 'Total loss': 0.8187851337868659}
2022-11-23 01:02:14,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:14,047 INFO:     Epoch: 92
2022-11-23 01:02:14,915 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.827972857064979, 'Total loss': 0.827972857064979} | train loss {'Reaction outcome loss': 0.8162873678031515, 'Total loss': 0.8162873678031515}
2022-11-23 01:02:14,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:14,915 INFO:     Epoch: 93
2022-11-23 01:02:15,765 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8219309296718863, 'Total loss': 0.8219309296718863} | train loss {'Reaction outcome loss': 0.8153327694926106, 'Total loss': 0.8153327694926106}
2022-11-23 01:02:15,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:15,766 INFO:     Epoch: 94
2022-11-23 01:02:16,668 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8303906016571577, 'Total loss': 0.8303906016571577} | train loss {'Reaction outcome loss': 0.8180289947595752, 'Total loss': 0.8180289947595752}
2022-11-23 01:02:16,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:16,669 INFO:     Epoch: 95
2022-11-23 01:02:17,594 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8247976788254672, 'Total loss': 0.8247976788254672} | train loss {'Reaction outcome loss': 0.8101314138926443, 'Total loss': 0.8101314138926443}
2022-11-23 01:02:17,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:17,594 INFO:     Epoch: 96
2022-11-23 01:02:18,459 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8322940025218698, 'Total loss': 0.8322940025218698} | train loss {'Reaction outcome loss': 0.8144948172276137, 'Total loss': 0.8144948172276137}
2022-11-23 01:02:18,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:18,459 INFO:     Epoch: 97
2022-11-23 01:02:19,356 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8322789343290551, 'Total loss': 0.8322789343290551} | train loss {'Reaction outcome loss': 0.813417520801552, 'Total loss': 0.813417520801552}
2022-11-23 01:02:19,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:19,356 INFO:     Epoch: 98
2022-11-23 01:02:20,249 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8129328059595685, 'Total loss': 0.8129328059595685} | train loss {'Reaction outcome loss': 0.8166785341550092, 'Total loss': 0.8166785341550092}
2022-11-23 01:02:20,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:20,250 INFO:     Epoch: 99
2022-11-23 01:02:21,079 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8371727071529211, 'Total loss': 0.8371727071529211} | train loss {'Reaction outcome loss': 0.8154025113240617, 'Total loss': 0.8154025113240617}
2022-11-23 01:02:21,080 INFO:     Best model found after epoch 54 of 100.
2022-11-23 01:02:21,080 INFO:   Done with stage: TRAINING
2022-11-23 01:02:21,080 INFO:   Starting stage: EVALUATION
2022-11-23 01:02:21,222 INFO:   Done with stage: EVALUATION
2022-11-23 01:02:21,222 INFO:   Leaving out SEQ value Fold_1
2022-11-23 01:02:21,236 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-23 01:02:21,236 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:02:21,918 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:02:21,918 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:02:21,992 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:02:21,992 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:02:21,992 INFO:     No hyperparam tuning for this model
2022-11-23 01:02:21,992 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:02:21,992 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:02:21,993 INFO:     None feature selector for col prot
2022-11-23 01:02:21,993 INFO:     None feature selector for col prot
2022-11-23 01:02:21,993 INFO:     None feature selector for col prot
2022-11-23 01:02:21,994 INFO:     None feature selector for col chem
2022-11-23 01:02:21,994 INFO:     None feature selector for col chem
2022-11-23 01:02:21,994 INFO:     None feature selector for col chem
2022-11-23 01:02:21,994 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:02:21,994 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:02:21,996 INFO:     Number of params in model 168571
2022-11-23 01:02:21,999 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:02:21,999 INFO:   Starting stage: TRAINING
2022-11-23 01:02:22,059 INFO:     Val loss before train {'Reaction outcome loss': 0.9916230060837485, 'Total loss': 0.9916230060837485}
2022-11-23 01:02:22,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:22,059 INFO:     Epoch: 0
2022-11-23 01:02:22,964 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8337251367894086, 'Total loss': 0.8337251367894086} | train loss {'Reaction outcome loss': 0.8903020001187616, 'Total loss': 0.8903020001187616}
2022-11-23 01:02:22,964 INFO:     Found new best model at epoch 0
2022-11-23 01:02:22,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:22,965 INFO:     Epoch: 1
2022-11-23 01:02:23,805 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8245825720104304, 'Total loss': 0.8245825720104304} | train loss {'Reaction outcome loss': 0.8637599468231201, 'Total loss': 0.8637599468231201}
2022-11-23 01:02:23,805 INFO:     Found new best model at epoch 1
2022-11-23 01:02:23,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:23,806 INFO:     Epoch: 2
2022-11-23 01:02:24,672 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8348521295596253, 'Total loss': 0.8348521295596253} | train loss {'Reaction outcome loss': 0.8620394107030362, 'Total loss': 0.8620394107030362}
2022-11-23 01:02:24,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:24,672 INFO:     Epoch: 3
2022-11-23 01:02:25,517 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8155846260488033, 'Total loss': 0.8155846260488033} | train loss {'Reaction outcome loss': 0.8542697242328099, 'Total loss': 0.8542697242328099}
2022-11-23 01:02:25,517 INFO:     Found new best model at epoch 3
2022-11-23 01:02:25,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:25,518 INFO:     Epoch: 4
2022-11-23 01:02:26,419 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8301991021091287, 'Total loss': 0.8301991021091287} | train loss {'Reaction outcome loss': 0.8528529130682654, 'Total loss': 0.8528529130682654}
2022-11-23 01:02:26,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:26,421 INFO:     Epoch: 5
2022-11-23 01:02:27,245 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8376402827826414, 'Total loss': 0.8376402827826414} | train loss {'Reaction outcome loss': 0.8464643902924596, 'Total loss': 0.8464643902924596}
2022-11-23 01:02:27,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:27,245 INFO:     Epoch: 6
2022-11-23 01:02:28,147 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8320056206800721, 'Total loss': 0.8320056206800721} | train loss {'Reaction outcome loss': 0.8492395424112982, 'Total loss': 0.8492395424112982}
2022-11-23 01:02:28,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:28,147 INFO:     Epoch: 7
2022-11-23 01:02:28,980 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8120281168005683, 'Total loss': 0.8120281168005683} | train loss {'Reaction outcome loss': 0.8412079812312613, 'Total loss': 0.8412079812312613}
2022-11-23 01:02:28,980 INFO:     Found new best model at epoch 7
2022-11-23 01:02:28,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:28,981 INFO:     Epoch: 8
2022-11-23 01:02:29,834 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8230732516808943, 'Total loss': 0.8230732516808943} | train loss {'Reaction outcome loss': 0.8432758642702687, 'Total loss': 0.8432758642702687}
2022-11-23 01:02:29,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:29,834 INFO:     Epoch: 9
2022-11-23 01:02:30,711 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8448344428430904, 'Total loss': 0.8448344428430904} | train loss {'Reaction outcome loss': 0.8471828685731304, 'Total loss': 0.8471828685731304}
2022-11-23 01:02:30,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:30,711 INFO:     Epoch: 10
2022-11-23 01:02:31,568 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8199609612876718, 'Total loss': 0.8199609612876718} | train loss {'Reaction outcome loss': 0.836425763733533, 'Total loss': 0.836425763733533}
2022-11-23 01:02:31,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:31,569 INFO:     Epoch: 11
2022-11-23 01:02:32,425 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8322500870986418, 'Total loss': 0.8322500870986418} | train loss {'Reaction outcome loss': 0.8399516960796045, 'Total loss': 0.8399516960796045}
2022-11-23 01:02:32,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:32,425 INFO:     Epoch: 12
2022-11-23 01:02:33,254 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8251807994463227, 'Total loss': 0.8251807994463227} | train loss {'Reaction outcome loss': 0.8400367369457167, 'Total loss': 0.8400367369457167}
2022-11-23 01:02:33,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:33,255 INFO:     Epoch: 13
2022-11-23 01:02:34,110 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8225231692194939, 'Total loss': 0.8225231692194939} | train loss {'Reaction outcome loss': 0.8381357609009256, 'Total loss': 0.8381357609009256}
2022-11-23 01:02:34,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:34,111 INFO:     Epoch: 14
2022-11-23 01:02:34,978 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.822314823215658, 'Total loss': 0.822314823215658} | train loss {'Reaction outcome loss': 0.8356050362392348, 'Total loss': 0.8356050362392348}
2022-11-23 01:02:34,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:34,979 INFO:     Epoch: 15
2022-11-23 01:02:35,835 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.829671982337128, 'Total loss': 0.829671982337128} | train loss {'Reaction outcome loss': 0.8364745028164922, 'Total loss': 0.8364745028164922}
2022-11-23 01:02:35,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:35,836 INFO:     Epoch: 16
2022-11-23 01:02:36,735 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8348375524986874, 'Total loss': 0.8348375524986874} | train loss {'Reaction outcome loss': 0.8348005819077394, 'Total loss': 0.8348005819077394}
2022-11-23 01:02:36,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:36,736 INFO:     Epoch: 17
2022-11-23 01:02:37,603 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8124681392853911, 'Total loss': 0.8124681392853911} | train loss {'Reaction outcome loss': 0.8350622684371715, 'Total loss': 0.8350622684371715}
2022-11-23 01:02:37,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:37,603 INFO:     Epoch: 18
2022-11-23 01:02:38,460 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8025829981673848, 'Total loss': 0.8025829981673848} | train loss {'Reaction outcome loss': 0.8327748381361669, 'Total loss': 0.8327748381361669}
2022-11-23 01:02:38,460 INFO:     Found new best model at epoch 18
2022-11-23 01:02:38,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:38,461 INFO:     Epoch: 19
2022-11-23 01:02:39,327 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8265679133209315, 'Total loss': 0.8265679133209315} | train loss {'Reaction outcome loss': 0.8332733497327688, 'Total loss': 0.8332733497327688}
2022-11-23 01:02:39,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:39,327 INFO:     Epoch: 20
2022-11-23 01:02:40,171 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.813666699284857, 'Total loss': 0.813666699284857} | train loss {'Reaction outcome loss': 0.8361944489333094, 'Total loss': 0.8361944489333094}
2022-11-23 01:02:40,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:40,172 INFO:     Epoch: 21
2022-11-23 01:02:41,051 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8148467635566538, 'Total loss': 0.8148467635566538} | train loss {'Reaction outcome loss': 0.831939365060962, 'Total loss': 0.831939365060962}
2022-11-23 01:02:41,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:41,051 INFO:     Epoch: 22
2022-11-23 01:02:41,928 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8042832775549456, 'Total loss': 0.8042832775549456} | train loss {'Reaction outcome loss': 0.829070513953968, 'Total loss': 0.829070513953968}
2022-11-23 01:02:41,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:41,930 INFO:     Epoch: 23
2022-11-23 01:02:42,798 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8231290944597938, 'Total loss': 0.8231290944597938} | train loss {'Reaction outcome loss': 0.8331150592589865, 'Total loss': 0.8331150592589865}
2022-11-23 01:02:42,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:42,798 INFO:     Epoch: 24
2022-11-23 01:02:43,687 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8074351691386916, 'Total loss': 0.8074351691386916} | train loss {'Reaction outcome loss': 0.8299339439187731, 'Total loss': 0.8299339439187731}
2022-11-23 01:02:43,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:43,688 INFO:     Epoch: 25
2022-11-23 01:02:44,551 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8202261633493684, 'Total loss': 0.8202261633493684} | train loss {'Reaction outcome loss': 0.8335480286150563, 'Total loss': 0.8335480286150563}
2022-11-23 01:02:44,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:44,551 INFO:     Epoch: 26
2022-11-23 01:02:45,413 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8192541944709691, 'Total loss': 0.8192541944709691} | train loss {'Reaction outcome loss': 0.8297363921087615, 'Total loss': 0.8297363921087615}
2022-11-23 01:02:45,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:45,413 INFO:     Epoch: 27
2022-11-23 01:02:46,266 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8499578325585886, 'Total loss': 0.8499578325585886} | train loss {'Reaction outcome loss': 0.8311923177874818, 'Total loss': 0.8311923177874818}
2022-11-23 01:02:46,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:46,266 INFO:     Epoch: 28
2022-11-23 01:02:47,140 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8459569723768667, 'Total loss': 0.8459569723768667} | train loss {'Reaction outcome loss': 0.8267409204220285, 'Total loss': 0.8267409204220285}
2022-11-23 01:02:47,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:47,141 INFO:     Epoch: 29
2022-11-23 01:02:47,965 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.827193221585317, 'Total loss': 0.827193221585317} | train loss {'Reaction outcome loss': 0.8313950481463451, 'Total loss': 0.8313950481463451}
2022-11-23 01:02:47,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:47,965 INFO:     Epoch: 30
2022-11-23 01:02:48,826 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8097569326108153, 'Total loss': 0.8097569326108153} | train loss {'Reaction outcome loss': 0.8296795871793007, 'Total loss': 0.8296795871793007}
2022-11-23 01:02:48,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:48,826 INFO:     Epoch: 31
2022-11-23 01:02:49,662 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8223918757655404, 'Total loss': 0.8223918757655404} | train loss {'Reaction outcome loss': 0.8283539162606609, 'Total loss': 0.8283539162606609}
2022-11-23 01:02:49,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:49,662 INFO:     Epoch: 32
2022-11-23 01:02:50,481 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8296736397526481, 'Total loss': 0.8296736397526481} | train loss {'Reaction outcome loss': 0.8219826923341167, 'Total loss': 0.8219826923341167}
2022-11-23 01:02:50,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:50,481 INFO:     Epoch: 33
2022-11-23 01:02:51,287 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.79024261507121, 'Total loss': 0.79024261507121} | train loss {'Reaction outcome loss': 0.822457159295374, 'Total loss': 0.822457159295374}
2022-11-23 01:02:51,287 INFO:     Found new best model at epoch 33
2022-11-23 01:02:51,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:51,288 INFO:     Epoch: 34
2022-11-23 01:02:52,136 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7940636920658025, 'Total loss': 0.7940636920658025} | train loss {'Reaction outcome loss': 0.8213896433917843, 'Total loss': 0.8213896433917843}
2022-11-23 01:02:52,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:52,136 INFO:     Epoch: 35
2022-11-23 01:02:52,973 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8318562053821303, 'Total loss': 0.8318562053821303} | train loss {'Reaction outcome loss': 0.8249723832218014, 'Total loss': 0.8249723832218014}
2022-11-23 01:02:52,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:52,974 INFO:     Epoch: 36
2022-11-23 01:02:53,805 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8860366120934486, 'Total loss': 0.8860366120934486} | train loss {'Reaction outcome loss': 0.82281807916505, 'Total loss': 0.82281807916505}
2022-11-23 01:02:53,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:53,806 INFO:     Epoch: 37
2022-11-23 01:02:54,678 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8065912398425016, 'Total loss': 0.8065912398425016} | train loss {'Reaction outcome loss': 0.8247213181184263, 'Total loss': 0.8247213181184263}
2022-11-23 01:02:54,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:54,678 INFO:     Epoch: 38
2022-11-23 01:02:55,561 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8026751584627412, 'Total loss': 0.8026751584627412} | train loss {'Reaction outcome loss': 0.8199052523593513, 'Total loss': 0.8199052523593513}
2022-11-23 01:02:55,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:55,561 INFO:     Epoch: 39
2022-11-23 01:02:56,409 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8099066005511717, 'Total loss': 0.8099066005511717} | train loss {'Reaction outcome loss': 0.8222346987043109, 'Total loss': 0.8222346987043109}
2022-11-23 01:02:56,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:56,409 INFO:     Epoch: 40
2022-11-23 01:02:57,262 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8126930635083806, 'Total loss': 0.8126930635083806} | train loss {'Reaction outcome loss': 0.8236347676539908, 'Total loss': 0.8236347676539908}
2022-11-23 01:02:57,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:57,263 INFO:     Epoch: 41
2022-11-23 01:02:58,083 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8222931393168189, 'Total loss': 0.8222931393168189} | train loss {'Reaction outcome loss': 0.8229892618802129, 'Total loss': 0.8229892618802129}
2022-11-23 01:02:58,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:58,084 INFO:     Epoch: 42
2022-11-23 01:02:58,902 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8230435617945411, 'Total loss': 0.8230435617945411} | train loss {'Reaction outcome loss': 0.8215289765474748, 'Total loss': 0.8215289765474748}
2022-11-23 01:02:58,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:58,902 INFO:     Epoch: 43
2022-11-23 01:02:59,782 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.834621093489907, 'Total loss': 0.834621093489907} | train loss {'Reaction outcome loss': 0.8242311762303722, 'Total loss': 0.8242311762303722}
2022-11-23 01:02:59,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:02:59,783 INFO:     Epoch: 44
2022-11-23 01:03:00,658 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8208879943598401, 'Total loss': 0.8208879943598401} | train loss {'Reaction outcome loss': 0.8197612146941983, 'Total loss': 0.8197612146941983}
2022-11-23 01:03:00,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:00,658 INFO:     Epoch: 45
2022-11-23 01:03:01,492 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8128280294212428, 'Total loss': 0.8128280294212428} | train loss {'Reaction outcome loss': 0.822962274235122, 'Total loss': 0.822962274235122}
2022-11-23 01:03:01,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:01,493 INFO:     Epoch: 46
2022-11-23 01:03:02,326 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8099079206585884, 'Total loss': 0.8099079206585884} | train loss {'Reaction outcome loss': 0.8175301826730066, 'Total loss': 0.8175301826730066}
2022-11-23 01:03:02,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:02,327 INFO:     Epoch: 47
2022-11-23 01:03:03,154 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.833514086224816, 'Total loss': 0.833514086224816} | train loss {'Reaction outcome loss': 0.8188883528417471, 'Total loss': 0.8188883528417471}
2022-11-23 01:03:03,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:03,155 INFO:     Epoch: 48
2022-11-23 01:03:04,004 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7881052441556345, 'Total loss': 0.7881052441556345} | train loss {'Reaction outcome loss': 0.8197367407837692, 'Total loss': 0.8197367407837692}
2022-11-23 01:03:04,005 INFO:     Found new best model at epoch 48
2022-11-23 01:03:04,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:04,006 INFO:     Epoch: 49
2022-11-23 01:03:04,893 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8070709895003926, 'Total loss': 0.8070709895003926} | train loss {'Reaction outcome loss': 0.8218685894596334, 'Total loss': 0.8218685894596334}
2022-11-23 01:03:04,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:04,893 INFO:     Epoch: 50
2022-11-23 01:03:05,727 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8206551941958341, 'Total loss': 0.8206551941958341} | train loss {'Reaction outcome loss': 0.8208023820604596, 'Total loss': 0.8208023820604596}
2022-11-23 01:03:05,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:05,728 INFO:     Epoch: 51
2022-11-23 01:03:06,513 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8120431933890689, 'Total loss': 0.8120431933890689} | train loss {'Reaction outcome loss': 0.8171243882909113, 'Total loss': 0.8171243882909113}
2022-11-23 01:03:06,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:06,514 INFO:     Epoch: 52
2022-11-23 01:03:07,359 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7884025174108419, 'Total loss': 0.7884025174108419} | train loss {'Reaction outcome loss': 0.8171146456076175, 'Total loss': 0.8171146456076175}
2022-11-23 01:03:07,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:07,359 INFO:     Epoch: 53
2022-11-23 01:03:08,213 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7987014976414767, 'Total loss': 0.7987014976414767} | train loss {'Reaction outcome loss': 0.817769100714703, 'Total loss': 0.817769100714703}
2022-11-23 01:03:08,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:08,214 INFO:     Epoch: 54
2022-11-23 01:03:09,055 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.806587120348757, 'Total loss': 0.806587120348757} | train loss {'Reaction outcome loss': 0.8169620196430051, 'Total loss': 0.8169620196430051}
2022-11-23 01:03:09,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:09,056 INFO:     Epoch: 55
2022-11-23 01:03:09,887 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7877933030778711, 'Total loss': 0.7877933030778711} | train loss {'Reaction outcome loss': 0.8198839787317782, 'Total loss': 0.8198839787317782}
2022-11-23 01:03:09,887 INFO:     Found new best model at epoch 55
2022-11-23 01:03:09,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:09,888 INFO:     Epoch: 56
2022-11-23 01:03:10,700 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8273560431870547, 'Total loss': 0.8273560431870547} | train loss {'Reaction outcome loss': 0.8173941000991938, 'Total loss': 0.8173941000991938}
2022-11-23 01:03:10,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:10,701 INFO:     Epoch: 57
2022-11-23 01:03:11,556 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.817791226235303, 'Total loss': 0.817791226235303} | train loss {'Reaction outcome loss': 0.8178826819877235, 'Total loss': 0.8178826819877235}
2022-11-23 01:03:11,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:11,556 INFO:     Epoch: 58
2022-11-23 01:03:12,362 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8350001709027723, 'Total loss': 0.8350001709027723} | train loss {'Reaction outcome loss': 0.8146091421039737, 'Total loss': 0.8146091421039737}
2022-11-23 01:03:12,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:12,362 INFO:     Epoch: 59
2022-11-23 01:03:13,122 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8062783032655716, 'Total loss': 0.8062783032655716} | train loss {'Reaction outcome loss': 0.8229259778042228, 'Total loss': 0.8229259778042228}
2022-11-23 01:03:13,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:13,122 INFO:     Epoch: 60
2022-11-23 01:03:13,926 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7853053103793751, 'Total loss': 0.7853053103793751} | train loss {'Reaction outcome loss': 0.8139011165317224, 'Total loss': 0.8139011165317224}
2022-11-23 01:03:13,927 INFO:     Found new best model at epoch 60
2022-11-23 01:03:13,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:13,928 INFO:     Epoch: 61
2022-11-23 01:03:14,720 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7974058823152022, 'Total loss': 0.7974058823152022} | train loss {'Reaction outcome loss': 0.812096245921388, 'Total loss': 0.812096245921388}
2022-11-23 01:03:14,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:14,721 INFO:     Epoch: 62
2022-11-23 01:03:15,535 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8009441474621947, 'Total loss': 0.8009441474621947} | train loss {'Reaction outcome loss': 0.8153422461480511, 'Total loss': 0.8153422461480511}
2022-11-23 01:03:15,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:15,536 INFO:     Epoch: 63
2022-11-23 01:03:16,327 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8268234892324968, 'Total loss': 0.8268234892324968} | train loss {'Reaction outcome loss': 0.821962489278949, 'Total loss': 0.821962489278949}
2022-11-23 01:03:16,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:16,327 INFO:     Epoch: 64
2022-11-23 01:03:17,163 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8251260126178915, 'Total loss': 0.8251260126178915} | train loss {'Reaction outcome loss': 0.8187260999971506, 'Total loss': 0.8187260999971506}
2022-11-23 01:03:17,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:17,163 INFO:     Epoch: 65
2022-11-23 01:03:17,930 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8107872490178455, 'Total loss': 0.8107872490178455} | train loss {'Reaction outcome loss': 0.8113519487332325, 'Total loss': 0.8113519487332325}
2022-11-23 01:03:17,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:17,930 INFO:     Epoch: 66
2022-11-23 01:03:18,763 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8340371494943445, 'Total loss': 0.8340371494943445} | train loss {'Reaction outcome loss': 0.815765969850579, 'Total loss': 0.815765969850579}
2022-11-23 01:03:18,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:18,763 INFO:     Epoch: 67
2022-11-23 01:03:19,564 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7982556928287853, 'Total loss': 0.7982556928287853} | train loss {'Reaction outcome loss': 0.8123690655036848, 'Total loss': 0.8123690655036848}
2022-11-23 01:03:19,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:19,564 INFO:     Epoch: 68
2022-11-23 01:03:20,397 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8187270665710623, 'Total loss': 0.8187270665710623} | train loss {'Reaction outcome loss': 0.8122181510438724, 'Total loss': 0.8122181510438724}
2022-11-23 01:03:20,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:20,398 INFO:     Epoch: 69
2022-11-23 01:03:21,191 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7920952866023238, 'Total loss': 0.7920952866023238} | train loss {'Reaction outcome loss': 0.8081667463390194, 'Total loss': 0.8081667463390194}
2022-11-23 01:03:21,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:21,191 INFO:     Epoch: 70
2022-11-23 01:03:22,006 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8107276226986538, 'Total loss': 0.8107276226986538} | train loss {'Reaction outcome loss': 0.8146261491337601, 'Total loss': 0.8146261491337601}
2022-11-23 01:03:22,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:22,007 INFO:     Epoch: 71
2022-11-23 01:03:22,776 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7966580634767358, 'Total loss': 0.7966580634767358} | train loss {'Reaction outcome loss': 0.8099623920966168, 'Total loss': 0.8099623920966168}
2022-11-23 01:03:22,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:22,777 INFO:     Epoch: 72
2022-11-23 01:03:23,589 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8163214502009478, 'Total loss': 0.8163214502009478} | train loss {'Reaction outcome loss': 0.8127742409706116, 'Total loss': 0.8127742409706116}
2022-11-23 01:03:23,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:23,590 INFO:     Epoch: 73
2022-11-23 01:03:24,377 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8369131765582345, 'Total loss': 0.8369131765582345} | train loss {'Reaction outcome loss': 0.8084679779957752, 'Total loss': 0.8084679779957752}
2022-11-23 01:03:24,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:24,377 INFO:     Epoch: 74
2022-11-23 01:03:25,170 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8105536509643901, 'Total loss': 0.8105536509643901} | train loss {'Reaction outcome loss': 0.8104502902955425, 'Total loss': 0.8104502902955425}
2022-11-23 01:03:25,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:25,170 INFO:     Epoch: 75
2022-11-23 01:03:26,026 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8170063597234812, 'Total loss': 0.8170063597234812} | train loss {'Reaction outcome loss': 0.8134777610399285, 'Total loss': 0.8134777610399285}
2022-11-23 01:03:26,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:26,027 INFO:     Epoch: 76
2022-11-23 01:03:26,830 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7960369024764408, 'Total loss': 0.7960369024764408} | train loss {'Reaction outcome loss': 0.8102185535187624, 'Total loss': 0.8102185535187624}
2022-11-23 01:03:26,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:26,830 INFO:     Epoch: 77
2022-11-23 01:03:27,568 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8044227104295384, 'Total loss': 0.8044227104295384} | train loss {'Reaction outcome loss': 0.8109136641025543, 'Total loss': 0.8109136641025543}
2022-11-23 01:03:27,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:27,568 INFO:     Epoch: 78
2022-11-23 01:03:28,369 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7882119742306796, 'Total loss': 0.7882119742306796} | train loss {'Reaction outcome loss': 0.8135454453984086, 'Total loss': 0.8135454453984086}
2022-11-23 01:03:28,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:28,369 INFO:     Epoch: 79
2022-11-23 01:03:29,196 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7750698630274697, 'Total loss': 0.7750698630274697} | train loss {'Reaction outcome loss': 0.804643846044735, 'Total loss': 0.804643846044735}
2022-11-23 01:03:29,196 INFO:     Found new best model at epoch 79
2022-11-23 01:03:29,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:29,197 INFO:     Epoch: 80
2022-11-23 01:03:29,965 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8026120784607801, 'Total loss': 0.8026120784607801} | train loss {'Reaction outcome loss': 0.8071199508345857, 'Total loss': 0.8071199508345857}
2022-11-23 01:03:29,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:29,965 INFO:     Epoch: 81
2022-11-23 01:03:30,744 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7874221286990426, 'Total loss': 0.7874221286990426} | train loss {'Reaction outcome loss': 0.8074979789403021, 'Total loss': 0.8074979789403021}
2022-11-23 01:03:30,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:30,744 INFO:     Epoch: 82
2022-11-23 01:03:31,516 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7867410995743491, 'Total loss': 0.7867410995743491} | train loss {'Reaction outcome loss': 0.803592169771389, 'Total loss': 0.803592169771389}
2022-11-23 01:03:31,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:31,517 INFO:     Epoch: 83
2022-11-23 01:03:32,293 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7997014048424634, 'Total loss': 0.7997014048424634} | train loss {'Reaction outcome loss': 0.8006120136805943, 'Total loss': 0.8006120136805943}
2022-11-23 01:03:32,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:32,293 INFO:     Epoch: 84
2022-11-23 01:03:33,065 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7903663628649983, 'Total loss': 0.7903663628649983} | train loss {'Reaction outcome loss': 0.8023822351377837, 'Total loss': 0.8023822351377837}
2022-11-23 01:03:33,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:33,066 INFO:     Epoch: 85
2022-11-23 01:03:33,824 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8012856827540831, 'Total loss': 0.8012856827540831} | train loss {'Reaction outcome loss': 0.8022739268079095, 'Total loss': 0.8022739268079095}
2022-11-23 01:03:33,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:33,825 INFO:     Epoch: 86
2022-11-23 01:03:34,606 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7873330502347513, 'Total loss': 0.7873330502347513} | train loss {'Reaction outcome loss': 0.7987418228266191, 'Total loss': 0.7987418228266191}
2022-11-23 01:03:34,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:34,607 INFO:     Epoch: 87
2022-11-23 01:03:35,388 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7979755686088041, 'Total loss': 0.7979755686088041} | train loss {'Reaction outcome loss': 0.7975242085602818, 'Total loss': 0.7975242085602818}
2022-11-23 01:03:35,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:35,388 INFO:     Epoch: 88
2022-11-23 01:03:36,169 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7832448435100642, 'Total loss': 0.7832448435100642} | train loss {'Reaction outcome loss': 0.7966531730428034, 'Total loss': 0.7966531730428034}
2022-11-23 01:03:36,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:36,169 INFO:     Epoch: 89
2022-11-23 01:03:37,013 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8133061365647749, 'Total loss': 0.8133061365647749} | train loss {'Reaction outcome loss': 0.7930979232398832, 'Total loss': 0.7930979232398832}
2022-11-23 01:03:37,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:37,016 INFO:     Epoch: 90
2022-11-23 01:03:37,813 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7801775857806206, 'Total loss': 0.7801775857806206} | train loss {'Reaction outcome loss': 0.7909971778490106, 'Total loss': 0.7909971778490106}
2022-11-23 01:03:37,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:37,813 INFO:     Epoch: 91
2022-11-23 01:03:38,610 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.77434011481025, 'Total loss': 0.77434011481025} | train loss {'Reaction outcome loss': 0.7860095097094166, 'Total loss': 0.7860095097094166}
2022-11-23 01:03:38,611 INFO:     Found new best model at epoch 91
2022-11-23 01:03:38,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:38,612 INFO:     Epoch: 92
2022-11-23 01:03:39,387 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7799381464719772, 'Total loss': 0.7799381464719772} | train loss {'Reaction outcome loss': 0.7808504071770882, 'Total loss': 0.7808504071770882}
2022-11-23 01:03:39,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:39,387 INFO:     Epoch: 93
2022-11-23 01:03:40,215 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7593075694008307, 'Total loss': 0.7593075694008307} | train loss {'Reaction outcome loss': 0.7824263301430916, 'Total loss': 0.7824263301430916}
2022-11-23 01:03:40,215 INFO:     Found new best model at epoch 93
2022-11-23 01:03:40,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:40,216 INFO:     Epoch: 94
2022-11-23 01:03:41,032 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7732588871466842, 'Total loss': 0.7732588871466842} | train loss {'Reaction outcome loss': 0.7719028607923157, 'Total loss': 0.7719028607923157}
2022-11-23 01:03:41,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:41,032 INFO:     Epoch: 95
2022-11-23 01:03:41,795 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.778719961643219, 'Total loss': 0.778719961643219} | train loss {'Reaction outcome loss': 0.779514729003517, 'Total loss': 0.779514729003517}
2022-11-23 01:03:41,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:41,795 INFO:     Epoch: 96
2022-11-23 01:03:42,568 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7322087599472566, 'Total loss': 0.7322087599472566} | train loss {'Reaction outcome loss': 0.7643902900267621, 'Total loss': 0.7643902900267621}
2022-11-23 01:03:42,569 INFO:     Found new best model at epoch 96
2022-11-23 01:03:42,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:42,570 INFO:     Epoch: 97
2022-11-23 01:03:43,349 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7479584393176165, 'Total loss': 0.7479584393176165} | train loss {'Reaction outcome loss': 0.7555164520837823, 'Total loss': 0.7555164520837823}
2022-11-23 01:03:43,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:43,350 INFO:     Epoch: 98
2022-11-23 01:03:44,139 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7516352182084863, 'Total loss': 0.7516352182084863} | train loss {'Reaction outcome loss': 0.7530583263659963, 'Total loss': 0.7530583263659963}
2022-11-23 01:03:44,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:44,139 INFO:     Epoch: 99
2022-11-23 01:03:44,911 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7028864818540487, 'Total loss': 0.7028864818540487} | train loss {'Reaction outcome loss': 0.7323670831261849, 'Total loss': 0.7323670831261849}
2022-11-23 01:03:44,911 INFO:     Found new best model at epoch 99
2022-11-23 01:03:44,912 INFO:     Best model found after epoch 100 of 100.
2022-11-23 01:03:44,912 INFO:   Done with stage: TRAINING
2022-11-23 01:03:44,912 INFO:   Starting stage: EVALUATION
2022-11-23 01:03:45,042 INFO:   Done with stage: EVALUATION
2022-11-23 01:03:45,042 INFO:   Leaving out SEQ value Fold_2
2022-11-23 01:03:45,055 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-23 01:03:45,056 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:03:45,730 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:03:45,730 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:03:45,801 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:03:45,801 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:03:45,801 INFO:     No hyperparam tuning for this model
2022-11-23 01:03:45,801 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:03:45,801 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:03:45,802 INFO:     None feature selector for col prot
2022-11-23 01:03:45,802 INFO:     None feature selector for col prot
2022-11-23 01:03:45,802 INFO:     None feature selector for col prot
2022-11-23 01:03:45,803 INFO:     None feature selector for col chem
2022-11-23 01:03:45,803 INFO:     None feature selector for col chem
2022-11-23 01:03:45,803 INFO:     None feature selector for col chem
2022-11-23 01:03:45,803 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:03:45,803 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:03:45,805 INFO:     Number of params in model 168571
2022-11-23 01:03:45,808 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:03:45,808 INFO:   Starting stage: TRAINING
2022-11-23 01:03:45,865 INFO:     Val loss before train {'Reaction outcome loss': 0.9736972146256025, 'Total loss': 0.9736972146256025}
2022-11-23 01:03:45,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:45,865 INFO:     Epoch: 0
2022-11-23 01:03:46,643 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8216518856758295, 'Total loss': 0.8216518856758295} | train loss {'Reaction outcome loss': 0.8799369932442415, 'Total loss': 0.8799369932442415}
2022-11-23 01:03:46,644 INFO:     Found new best model at epoch 0
2022-11-23 01:03:46,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:46,644 INFO:     Epoch: 1
2022-11-23 01:03:47,453 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7997674345970154, 'Total loss': 0.7997674345970154} | train loss {'Reaction outcome loss': 0.8504438337976815, 'Total loss': 0.8504438337976815}
2022-11-23 01:03:47,453 INFO:     Found new best model at epoch 1
2022-11-23 01:03:47,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:47,454 INFO:     Epoch: 2
2022-11-23 01:03:48,244 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8029300390287887, 'Total loss': 0.8029300390287887} | train loss {'Reaction outcome loss': 0.8514587754597429, 'Total loss': 0.8514587754597429}
2022-11-23 01:03:48,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:48,245 INFO:     Epoch: 3
2022-11-23 01:03:49,041 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7960643234641053, 'Total loss': 0.7960643234641053} | train loss {'Reaction outcome loss': 0.843472784537761, 'Total loss': 0.843472784537761}
2022-11-23 01:03:49,041 INFO:     Found new best model at epoch 3
2022-11-23 01:03:49,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:49,042 INFO:     Epoch: 4
2022-11-23 01:03:49,813 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8109357731286869, 'Total loss': 0.8109357731286869} | train loss {'Reaction outcome loss': 0.8392908669641761, 'Total loss': 0.8392908669641761}
2022-11-23 01:03:49,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:49,814 INFO:     Epoch: 5
2022-11-23 01:03:50,604 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8013620709264001, 'Total loss': 0.8013620709264001} | train loss {'Reaction outcome loss': 0.833848989156426, 'Total loss': 0.833848989156426}
2022-11-23 01:03:50,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:50,605 INFO:     Epoch: 6
2022-11-23 01:03:51,392 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7947962381118951, 'Total loss': 0.7947962381118951} | train loss {'Reaction outcome loss': 0.8366954230138512, 'Total loss': 0.8366954230138512}
2022-11-23 01:03:51,392 INFO:     Found new best model at epoch 6
2022-11-23 01:03:51,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:51,393 INFO:     Epoch: 7
2022-11-23 01:03:52,151 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7850848214570866, 'Total loss': 0.7850848214570866} | train loss {'Reaction outcome loss': 0.8316330592163274, 'Total loss': 0.8316330592163274}
2022-11-23 01:03:52,151 INFO:     Found new best model at epoch 7
2022-11-23 01:03:52,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:52,152 INFO:     Epoch: 8
2022-11-23 01:03:52,912 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8270457872124606, 'Total loss': 0.8270457872124606} | train loss {'Reaction outcome loss': 0.8256982684624, 'Total loss': 0.8256982684624}
2022-11-23 01:03:52,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:52,912 INFO:     Epoch: 9
2022-11-23 01:03:53,707 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7960577118535375, 'Total loss': 0.7960577118535375} | train loss {'Reaction outcome loss': 0.8292689106014909, 'Total loss': 0.8292689106014909}
2022-11-23 01:03:53,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:53,708 INFO:     Epoch: 10
2022-11-23 01:03:54,486 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8049388798170312, 'Total loss': 0.8049388798170312} | train loss {'Reaction outcome loss': 0.8251229876377544, 'Total loss': 0.8251229876377544}
2022-11-23 01:03:54,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:54,486 INFO:     Epoch: 11
2022-11-23 01:03:55,245 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7967189328615055, 'Total loss': 0.7967189328615055} | train loss {'Reaction outcome loss': 0.8265486176385254, 'Total loss': 0.8265486176385254}
2022-11-23 01:03:55,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:55,245 INFO:     Epoch: 12
2022-11-23 01:03:56,009 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7788735288520192, 'Total loss': 0.7788735288520192} | train loss {'Reaction outcome loss': 0.8258722610160952, 'Total loss': 0.8258722610160952}
2022-11-23 01:03:56,009 INFO:     Found new best model at epoch 12
2022-11-23 01:03:56,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:56,010 INFO:     Epoch: 13
2022-11-23 01:03:56,786 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7947037746739942, 'Total loss': 0.7947037746739942} | train loss {'Reaction outcome loss': 0.8188825842054164, 'Total loss': 0.8188825842054164}
2022-11-23 01:03:56,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:56,786 INFO:     Epoch: 14
2022-11-23 01:03:57,579 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7945627826590871, 'Total loss': 0.7945627826590871} | train loss {'Reaction outcome loss': 0.8279665112495422, 'Total loss': 0.8279665112495422}
2022-11-23 01:03:57,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:57,579 INFO:     Epoch: 15
2022-11-23 01:03:58,361 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7998770378356757, 'Total loss': 0.7998770378356757} | train loss {'Reaction outcome loss': 0.8221045958458401, 'Total loss': 0.8221045958458401}
2022-11-23 01:03:58,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:58,361 INFO:     Epoch: 16
2022-11-23 01:03:59,110 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7952130041843237, 'Total loss': 0.7952130041843237} | train loss {'Reaction outcome loss': 0.8208449241079268, 'Total loss': 0.8208449241079268}
2022-11-23 01:03:59,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:59,111 INFO:     Epoch: 17
2022-11-23 01:03:59,909 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7803747037122416, 'Total loss': 0.7803747037122416} | train loss {'Reaction outcome loss': 0.821468177388926, 'Total loss': 0.821468177388926}
2022-11-23 01:03:59,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:03:59,909 INFO:     Epoch: 18
2022-11-23 01:04:00,699 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7771876142468563, 'Total loss': 0.7771876142468563} | train loss {'Reaction outcome loss': 0.821493787843673, 'Total loss': 0.821493787843673}
2022-11-23 01:04:00,699 INFO:     Found new best model at epoch 18
2022-11-23 01:04:00,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:00,700 INFO:     Epoch: 19
2022-11-23 01:04:01,516 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.784704199364019, 'Total loss': 0.784704199364019} | train loss {'Reaction outcome loss': 0.8199849085973911, 'Total loss': 0.8199849085973911}
2022-11-23 01:04:01,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:01,516 INFO:     Epoch: 20
2022-11-23 01:04:02,319 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7856375769127247, 'Total loss': 0.7856375769127247} | train loss {'Reaction outcome loss': 0.8161968121030292, 'Total loss': 0.8161968121030292}
2022-11-23 01:04:02,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:02,319 INFO:     Epoch: 21
2022-11-23 01:04:03,080 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7923681722130886, 'Total loss': 0.7923681722130886} | train loss {'Reaction outcome loss': 0.8215762699236635, 'Total loss': 0.8215762699236635}
2022-11-23 01:04:03,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:03,081 INFO:     Epoch: 22
2022-11-23 01:04:03,884 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7819699742073236, 'Total loss': 0.7819699742073236} | train loss {'Reaction outcome loss': 0.8220061159036198, 'Total loss': 0.8220061159036198}
2022-11-23 01:04:03,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:03,884 INFO:     Epoch: 23
2022-11-23 01:04:04,735 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.784242355546286, 'Total loss': 0.784242355546286} | train loss {'Reaction outcome loss': 0.8148384560815624, 'Total loss': 0.8148384560815624}
2022-11-23 01:04:04,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:04,736 INFO:     Epoch: 24
2022-11-23 01:04:05,569 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8004967708920323, 'Total loss': 0.8004967708920323} | train loss {'Reaction outcome loss': 0.8183258265012601, 'Total loss': 0.8183258265012601}
2022-11-23 01:04:05,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:05,570 INFO:     Epoch: 25
2022-11-23 01:04:06,360 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7897676478984744, 'Total loss': 0.7897676478984744} | train loss {'Reaction outcome loss': 0.8183178662276659, 'Total loss': 0.8183178662276659}
2022-11-23 01:04:06,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:06,360 INFO:     Epoch: 26
2022-11-23 01:04:07,163 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7795036788596663, 'Total loss': 0.7795036788596663} | train loss {'Reaction outcome loss': 0.8164737420003922, 'Total loss': 0.8164737420003922}
2022-11-23 01:04:07,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:07,163 INFO:     Epoch: 27
2022-11-23 01:04:07,954 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7788798996182376, 'Total loss': 0.7788798996182376} | train loss {'Reaction outcome loss': 0.8190121449163703, 'Total loss': 0.8190121449163703}
2022-11-23 01:04:07,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:07,954 INFO:     Epoch: 28
2022-11-23 01:04:08,756 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7835863315781881, 'Total loss': 0.7835863315781881} | train loss {'Reaction outcome loss': 0.8190250179318131, 'Total loss': 0.8190250179318131}
2022-11-23 01:04:08,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:08,756 INFO:     Epoch: 29
2022-11-23 01:04:09,530 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7734602571919907, 'Total loss': 0.7734602571919907} | train loss {'Reaction outcome loss': 0.8138437429901029, 'Total loss': 0.8138437429901029}
2022-11-23 01:04:09,530 INFO:     Found new best model at epoch 29
2022-11-23 01:04:09,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:09,531 INFO:     Epoch: 30
2022-11-23 01:04:10,318 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7809301767238351, 'Total loss': 0.7809301767238351} | train loss {'Reaction outcome loss': 0.8175209725245101, 'Total loss': 0.8175209725245101}
2022-11-23 01:04:10,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:10,319 INFO:     Epoch: 31
2022-11-23 01:04:11,151 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7900703590969707, 'Total loss': 0.7900703590969707} | train loss {'Reaction outcome loss': 0.8156376358915548, 'Total loss': 0.8156376358915548}
2022-11-23 01:04:11,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:11,151 INFO:     Epoch: 32
2022-11-23 01:04:11,944 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7719544789125753, 'Total loss': 0.7719544789125753} | train loss {'Reaction outcome loss': 0.8143051199492861, 'Total loss': 0.8143051199492861}
2022-11-23 01:04:11,944 INFO:     Found new best model at epoch 32
2022-11-23 01:04:11,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:11,945 INFO:     Epoch: 33
2022-11-23 01:04:12,737 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7805210670759511, 'Total loss': 0.7805210670759511} | train loss {'Reaction outcome loss': 0.8171349271643357, 'Total loss': 0.8171349271643357}
2022-11-23 01:04:12,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:12,737 INFO:     Epoch: 34
2022-11-23 01:04:13,530 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7977971524693245, 'Total loss': 0.7977971524693245} | train loss {'Reaction outcome loss': 0.8182077318674228, 'Total loss': 0.8182077318674228}
2022-11-23 01:04:13,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:13,531 INFO:     Epoch: 35
2022-11-23 01:04:14,354 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7800732837166897, 'Total loss': 0.7800732837166897} | train loss {'Reaction outcome loss': 0.8199750026229953, 'Total loss': 0.8199750026229953}
2022-11-23 01:04:14,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:14,355 INFO:     Epoch: 36
2022-11-23 01:04:15,150 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7909595744554386, 'Total loss': 0.7909595744554386} | train loss {'Reaction outcome loss': 0.8151032996715092, 'Total loss': 0.8151032996715092}
2022-11-23 01:04:15,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:15,151 INFO:     Epoch: 37
2022-11-23 01:04:15,938 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7804617840190267, 'Total loss': 0.7804617840190267} | train loss {'Reaction outcome loss': 0.8162953605661627, 'Total loss': 0.8162953605661627}
2022-11-23 01:04:15,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:15,939 INFO:     Epoch: 38
2022-11-23 01:04:16,740 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7835308722285337, 'Total loss': 0.7835308722285337} | train loss {'Reaction outcome loss': 0.8211006316982332, 'Total loss': 0.8211006316982332}
2022-11-23 01:04:16,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:16,740 INFO:     Epoch: 39
2022-11-23 01:04:17,543 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7796254851097284, 'Total loss': 0.7796254851097284} | train loss {'Reaction outcome loss': 0.8156182886879952, 'Total loss': 0.8156182886879952}
2022-11-23 01:04:17,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:17,544 INFO:     Epoch: 40
2022-11-23 01:04:18,327 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.778229602547579, 'Total loss': 0.778229602547579} | train loss {'Reaction outcome loss': 0.816559550337127, 'Total loss': 0.816559550337127}
2022-11-23 01:04:18,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:18,328 INFO:     Epoch: 41
2022-11-23 01:04:19,137 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7872858726701071, 'Total loss': 0.7872858726701071} | train loss {'Reaction outcome loss': 0.8139333413516889, 'Total loss': 0.8139333413516889}
2022-11-23 01:04:19,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:19,138 INFO:     Epoch: 42
2022-11-23 01:04:20,031 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7924696886262228, 'Total loss': 0.7924696886262228} | train loss {'Reaction outcome loss': 0.8146984567407702, 'Total loss': 0.8146984567407702}
2022-11-23 01:04:20,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:20,031 INFO:     Epoch: 43
2022-11-23 01:04:20,864 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7948097524254821, 'Total loss': 0.7948097524254821} | train loss {'Reaction outcome loss': 0.8166313405896797, 'Total loss': 0.8166313405896797}
2022-11-23 01:04:20,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:20,865 INFO:     Epoch: 44
2022-11-23 01:04:21,723 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7772644508716672, 'Total loss': 0.7772644508716672} | train loss {'Reaction outcome loss': 0.8147139378258439, 'Total loss': 0.8147139378258439}
2022-11-23 01:04:21,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:21,725 INFO:     Epoch: 45
2022-11-23 01:04:22,483 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7784246947876242, 'Total loss': 0.7784246947876242} | train loss {'Reaction outcome loss': 0.8171968864368611, 'Total loss': 0.8171968864368611}
2022-11-23 01:04:22,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:22,483 INFO:     Epoch: 46
2022-11-23 01:04:23,257 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7814093800478203, 'Total loss': 0.7814093800478203} | train loss {'Reaction outcome loss': 0.8197098611319651, 'Total loss': 0.8197098611319651}
2022-11-23 01:04:23,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:23,257 INFO:     Epoch: 47
2022-11-23 01:04:24,057 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.784643753323444, 'Total loss': 0.784643753323444} | train loss {'Reaction outcome loss': 0.8167605466041409, 'Total loss': 0.8167605466041409}
2022-11-23 01:04:24,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:24,058 INFO:     Epoch: 48
2022-11-23 01:04:24,854 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7834552124489186, 'Total loss': 0.7834552124489186} | train loss {'Reaction outcome loss': 0.8158235242132281, 'Total loss': 0.8158235242132281}
2022-11-23 01:04:24,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:24,855 INFO:     Epoch: 49
2022-11-23 01:04:25,685 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.785866824693458, 'Total loss': 0.785866824693458} | train loss {'Reaction outcome loss': 0.8161252204511986, 'Total loss': 0.8161252204511986}
2022-11-23 01:04:25,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:25,685 INFO:     Epoch: 50
2022-11-23 01:04:26,454 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7855776430562486, 'Total loss': 0.7855776430562486} | train loss {'Reaction outcome loss': 0.8106797431580356, 'Total loss': 0.8106797431580356}
2022-11-23 01:04:26,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:26,455 INFO:     Epoch: 51
2022-11-23 01:04:27,270 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7761084679947343, 'Total loss': 0.7761084679947343} | train loss {'Reaction outcome loss': 0.8145440628782648, 'Total loss': 0.8145440628782648}
2022-11-23 01:04:27,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:27,272 INFO:     Epoch: 52
2022-11-23 01:04:28,088 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7950168182683546, 'Total loss': 0.7950168182683546} | train loss {'Reaction outcome loss': 0.81394874854166, 'Total loss': 0.81394874854166}
2022-11-23 01:04:28,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:28,088 INFO:     Epoch: 53
2022-11-23 01:04:28,846 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7797016591526741, 'Total loss': 0.7797016591526741} | train loss {'Reaction outcome loss': 0.8140025218246413, 'Total loss': 0.8140025218246413}
2022-11-23 01:04:28,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:28,846 INFO:     Epoch: 54
2022-11-23 01:04:29,608 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7735076754592186, 'Total loss': 0.7735076754592186} | train loss {'Reaction outcome loss': 0.8161941654369479, 'Total loss': 0.8161941654369479}
2022-11-23 01:04:29,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:29,608 INFO:     Epoch: 55
2022-11-23 01:04:30,403 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7921413820843364, 'Total loss': 0.7921413820843364} | train loss {'Reaction outcome loss': 0.8192263346959333, 'Total loss': 0.8192263346959333}
2022-11-23 01:04:30,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:30,404 INFO:     Epoch: 56
2022-11-23 01:04:31,191 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7970088463883067, 'Total loss': 0.7970088463883067} | train loss {'Reaction outcome loss': 0.8174172890235166, 'Total loss': 0.8174172890235166}
2022-11-23 01:04:31,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:31,191 INFO:     Epoch: 57
2022-11-23 01:04:31,988 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.787545139706412, 'Total loss': 0.787545139706412} | train loss {'Reaction outcome loss': 0.8196211392517949, 'Total loss': 0.8196211392517949}
2022-11-23 01:04:31,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:31,988 INFO:     Epoch: 58
2022-11-23 01:04:32,791 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7779835386331692, 'Total loss': 0.7779835386331692} | train loss {'Reaction outcome loss': 0.8126870158021567, 'Total loss': 0.8126870158021567}
2022-11-23 01:04:32,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:32,793 INFO:     Epoch: 59
2022-11-23 01:04:33,570 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7869205939215284, 'Total loss': 0.7869205939215284} | train loss {'Reaction outcome loss': 0.8104852122850106, 'Total loss': 0.8104852122850106}
2022-11-23 01:04:33,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:33,570 INFO:     Epoch: 60
2022-11-23 01:04:34,398 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8097097166748934, 'Total loss': 0.8097097166748934} | train loss {'Reaction outcome loss': 0.8133480871309999, 'Total loss': 0.8133480871309999}
2022-11-23 01:04:34,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:34,398 INFO:     Epoch: 61
2022-11-23 01:04:35,184 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7787793202455654, 'Total loss': 0.7787793202455654} | train loss {'Reaction outcome loss': 0.814304918417188, 'Total loss': 0.814304918417188}
2022-11-23 01:04:35,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:35,184 INFO:     Epoch: 62
2022-11-23 01:04:35,967 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8267493552939836, 'Total loss': 0.8267493552939836} | train loss {'Reaction outcome loss': 0.818953887360995, 'Total loss': 0.818953887360995}
2022-11-23 01:04:35,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:35,968 INFO:     Epoch: 63
2022-11-23 01:04:36,792 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7820135978765266, 'Total loss': 0.7820135978765266} | train loss {'Reaction outcome loss': 0.8124565109610558, 'Total loss': 0.8124565109610558}
2022-11-23 01:04:36,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:36,792 INFO:     Epoch: 64
2022-11-23 01:04:37,567 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7859497049520182, 'Total loss': 0.7859497049520182} | train loss {'Reaction outcome loss': 0.810279442760788, 'Total loss': 0.810279442760788}
2022-11-23 01:04:37,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:37,568 INFO:     Epoch: 65
2022-11-23 01:04:38,370 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8004247511542121, 'Total loss': 0.8004247511542121} | train loss {'Reaction outcome loss': 0.8155621452653994, 'Total loss': 0.8155621452653994}
2022-11-23 01:04:38,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:38,372 INFO:     Epoch: 66
2022-11-23 01:04:39,159 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7922992276590924, 'Total loss': 0.7922992276590924} | train loss {'Reaction outcome loss': 0.813144502214721, 'Total loss': 0.813144502214721}
2022-11-23 01:04:39,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:39,159 INFO:     Epoch: 67
2022-11-23 01:04:39,959 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7877422460289889, 'Total loss': 0.7877422460289889} | train loss {'Reaction outcome loss': 0.8163622258628, 'Total loss': 0.8163622258628}
2022-11-23 01:04:39,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:39,959 INFO:     Epoch: 68
2022-11-23 01:04:40,772 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7879044670005177, 'Total loss': 0.7879044670005177} | train loss {'Reaction outcome loss': 0.816177249321195, 'Total loss': 0.816177249321195}
2022-11-23 01:04:40,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:40,773 INFO:     Epoch: 69
2022-11-23 01:04:41,619 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7963580981243489, 'Total loss': 0.7963580981243489} | train loss {'Reaction outcome loss': 0.8148952197344577, 'Total loss': 0.8148952197344577}
2022-11-23 01:04:41,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:41,619 INFO:     Epoch: 70
2022-11-23 01:04:42,471 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7752325659574464, 'Total loss': 0.7752325659574464} | train loss {'Reaction outcome loss': 0.8168973226527698, 'Total loss': 0.8168973226527698}
2022-11-23 01:04:42,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:42,471 INFO:     Epoch: 71
2022-11-23 01:04:43,226 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7727394748565762, 'Total loss': 0.7727394748565762} | train loss {'Reaction outcome loss': 0.8175634642849203, 'Total loss': 0.8175634642849203}
2022-11-23 01:04:43,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:43,226 INFO:     Epoch: 72
2022-11-23 01:04:43,989 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7846992258415666, 'Total loss': 0.7846992258415666} | train loss {'Reaction outcome loss': 0.8173929246478393, 'Total loss': 0.8173929246478393}
2022-11-23 01:04:43,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:43,990 INFO:     Epoch: 73
2022-11-23 01:04:44,790 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7720898438331693, 'Total loss': 0.7720898438331693} | train loss {'Reaction outcome loss': 0.8106711751124898, 'Total loss': 0.8106711751124898}
2022-11-23 01:04:44,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:44,790 INFO:     Epoch: 74
2022-11-23 01:04:45,595 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7820565603500189, 'Total loss': 0.7820565603500189} | train loss {'Reaction outcome loss': 0.8137613587447854, 'Total loss': 0.8137613587447854}
2022-11-23 01:04:45,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:45,595 INFO:     Epoch: 75
2022-11-23 01:04:46,387 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7736603853314422, 'Total loss': 0.7736603853314422} | train loss {'Reaction outcome loss': 0.8144115953416121, 'Total loss': 0.8144115953416121}
2022-11-23 01:04:46,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:46,387 INFO:     Epoch: 76
2022-11-23 01:04:47,169 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7872824765915094, 'Total loss': 0.7872824765915094} | train loss {'Reaction outcome loss': 0.8126213920653843, 'Total loss': 0.8126213920653843}
2022-11-23 01:04:47,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:47,169 INFO:     Epoch: 77
2022-11-23 01:04:47,993 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7900047302246094, 'Total loss': 0.7900047302246094} | train loss {'Reaction outcome loss': 0.8145889281982281, 'Total loss': 0.8145889281982281}
2022-11-23 01:04:47,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:47,993 INFO:     Epoch: 78
2022-11-23 01:04:48,774 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7827710225138553, 'Total loss': 0.7827710225138553} | train loss {'Reaction outcome loss': 0.8163228573613479, 'Total loss': 0.8163228573613479}
2022-11-23 01:04:48,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:48,774 INFO:     Epoch: 79
2022-11-23 01:04:49,579 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7862140286800473, 'Total loss': 0.7862140286800473} | train loss {'Reaction outcome loss': 0.8169551385474987, 'Total loss': 0.8169551385474987}
2022-11-23 01:04:49,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:49,581 INFO:     Epoch: 80
2022-11-23 01:04:50,398 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7735647372035093, 'Total loss': 0.7735647372035093} | train loss {'Reaction outcome loss': 0.8141015383308051, 'Total loss': 0.8141015383308051}
2022-11-23 01:04:50,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:50,398 INFO:     Epoch: 81
2022-11-23 01:04:51,248 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7962287186190139, 'Total loss': 0.7962287186190139} | train loss {'Reaction outcome loss': 0.8187898818830974, 'Total loss': 0.8187898818830974}
2022-11-23 01:04:51,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:51,249 INFO:     Epoch: 82
2022-11-23 01:04:52,084 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7785761397938396, 'Total loss': 0.7785761397938396} | train loss {'Reaction outcome loss': 0.8163888883150991, 'Total loss': 0.8163888883150991}
2022-11-23 01:04:52,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:52,084 INFO:     Epoch: 83
2022-11-23 01:04:52,860 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.793808366670165, 'Total loss': 0.793808366670165} | train loss {'Reaction outcome loss': 0.8168692342082008, 'Total loss': 0.8168692342082008}
2022-11-23 01:04:52,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:52,860 INFO:     Epoch: 84
2022-11-23 01:04:53,659 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7907526479210965, 'Total loss': 0.7907526479210965} | train loss {'Reaction outcome loss': 0.8159204965732136, 'Total loss': 0.8159204965732136}
2022-11-23 01:04:53,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:53,659 INFO:     Epoch: 85
2022-11-23 01:04:54,507 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7859230776165806, 'Total loss': 0.7859230776165806} | train loss {'Reaction outcome loss': 0.8158593490475514, 'Total loss': 0.8158593490475514}
2022-11-23 01:04:54,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:54,509 INFO:     Epoch: 86
2022-11-23 01:04:55,292 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8003458602483883, 'Total loss': 0.8003458602483883} | train loss {'Reaction outcome loss': 0.8160312156208226, 'Total loss': 0.8160312156208226}
2022-11-23 01:04:55,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:55,292 INFO:     Epoch: 87
2022-11-23 01:04:56,089 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7879453294498976, 'Total loss': 0.7879453294498976} | train loss {'Reaction outcome loss': 0.8174566718154266, 'Total loss': 0.8174566718154266}
2022-11-23 01:04:56,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:56,090 INFO:     Epoch: 88
2022-11-23 01:04:56,857 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7802871105282806, 'Total loss': 0.7802871105282806} | train loss {'Reaction outcome loss': 0.8130721973835445, 'Total loss': 0.8130721973835445}
2022-11-23 01:04:56,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:56,858 INFO:     Epoch: 89
2022-11-23 01:04:57,676 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7788894315098607, 'Total loss': 0.7788894315098607} | train loss {'Reaction outcome loss': 0.8164655678584928, 'Total loss': 0.8164655678584928}
2022-11-23 01:04:57,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:57,676 INFO:     Epoch: 90
2022-11-23 01:04:58,485 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7960582292357157, 'Total loss': 0.7960582292357157} | train loss {'Reaction outcome loss': 0.8172891108227558, 'Total loss': 0.8172891108227558}
2022-11-23 01:04:58,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:58,485 INFO:     Epoch: 91
2022-11-23 01:04:59,340 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8066628187201744, 'Total loss': 0.8066628187201744} | train loss {'Reaction outcome loss': 0.815752235470248, 'Total loss': 0.815752235470248}
2022-11-23 01:04:59,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:04:59,340 INFO:     Epoch: 92
2022-11-23 01:05:00,152 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7898653669412746, 'Total loss': 0.7898653669412746} | train loss {'Reaction outcome loss': 0.8170500431881577, 'Total loss': 0.8170500431881577}
2022-11-23 01:05:00,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:00,153 INFO:     Epoch: 93
2022-11-23 01:05:00,974 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7815987308358037, 'Total loss': 0.7815987308358037} | train loss {'Reaction outcome loss': 0.813615749727507, 'Total loss': 0.813615749727507}
2022-11-23 01:05:00,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:00,975 INFO:     Epoch: 94
2022-11-23 01:05:01,763 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7813737995402757, 'Total loss': 0.7813737995402757} | train loss {'Reaction outcome loss': 0.8186636717348802, 'Total loss': 0.8186636717348802}
2022-11-23 01:05:01,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:01,763 INFO:     Epoch: 95
2022-11-23 01:05:02,564 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8004735652790513, 'Total loss': 0.8004735652790513} | train loss {'Reaction outcome loss': 0.8146991734621954, 'Total loss': 0.8146991734621954}
2022-11-23 01:05:02,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:02,564 INFO:     Epoch: 96
2022-11-23 01:05:03,341 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7950151250805966, 'Total loss': 0.7950151250805966} | train loss {'Reaction outcome loss': 0.8214600491719167, 'Total loss': 0.8214600491719167}
2022-11-23 01:05:03,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:03,341 INFO:     Epoch: 97
2022-11-23 01:05:04,192 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7709934753040935, 'Total loss': 0.7709934753040935} | train loss {'Reaction outcome loss': 0.815088931410039, 'Total loss': 0.815088931410039}
2022-11-23 01:05:04,192 INFO:     Found new best model at epoch 97
2022-11-23 01:05:04,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:04,193 INFO:     Epoch: 98
2022-11-23 01:05:05,008 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7915131144745405, 'Total loss': 0.7915131144745405} | train loss {'Reaction outcome loss': 0.8145997673273087, 'Total loss': 0.8145997673273087}
2022-11-23 01:05:05,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:05,008 INFO:     Epoch: 99
2022-11-23 01:05:05,789 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7840566662854926, 'Total loss': 0.7840566662854926} | train loss {'Reaction outcome loss': 0.812447441161656, 'Total loss': 0.812447441161656}
2022-11-23 01:05:05,790 INFO:     Best model found after epoch 98 of 100.
2022-11-23 01:05:05,790 INFO:   Done with stage: TRAINING
2022-11-23 01:05:05,790 INFO:   Starting stage: EVALUATION
2022-11-23 01:05:05,926 INFO:   Done with stage: EVALUATION
2022-11-23 01:05:05,927 INFO:   Leaving out SEQ value Fold_3
2022-11-23 01:05:05,940 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-23 01:05:05,940 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:05:06,615 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:05:06,615 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:05:06,685 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:05:06,685 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:05:06,686 INFO:     No hyperparam tuning for this model
2022-11-23 01:05:06,686 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:05:06,686 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:05:06,687 INFO:     None feature selector for col prot
2022-11-23 01:05:06,687 INFO:     None feature selector for col prot
2022-11-23 01:05:06,687 INFO:     None feature selector for col prot
2022-11-23 01:05:06,687 INFO:     None feature selector for col chem
2022-11-23 01:05:06,688 INFO:     None feature selector for col chem
2022-11-23 01:05:06,688 INFO:     None feature selector for col chem
2022-11-23 01:05:06,688 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:05:06,688 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:05:06,689 INFO:     Number of params in model 168571
2022-11-23 01:05:06,693 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:05:06,693 INFO:   Starting stage: TRAINING
2022-11-23 01:05:06,750 INFO:     Val loss before train {'Reaction outcome loss': 1.0004720972342924, 'Total loss': 1.0004720972342924}
2022-11-23 01:05:06,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:06,750 INFO:     Epoch: 0
2022-11-23 01:05:07,539 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8425628156824545, 'Total loss': 0.8425628156824545} | train loss {'Reaction outcome loss': 0.8855428313722415, 'Total loss': 0.8855428313722415}
2022-11-23 01:05:07,539 INFO:     Found new best model at epoch 0
2022-11-23 01:05:07,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:07,540 INFO:     Epoch: 1
2022-11-23 01:05:08,330 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8375191912055016, 'Total loss': 0.8375191912055016} | train loss {'Reaction outcome loss': 0.8463027304532577, 'Total loss': 0.8463027304532577}
2022-11-23 01:05:08,331 INFO:     Found new best model at epoch 1
2022-11-23 01:05:08,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:08,331 INFO:     Epoch: 2
2022-11-23 01:05:09,127 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.822360175577077, 'Total loss': 0.822360175577077} | train loss {'Reaction outcome loss': 0.8407682989324842, 'Total loss': 0.8407682989324842}
2022-11-23 01:05:09,127 INFO:     Found new best model at epoch 2
2022-11-23 01:05:09,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:09,128 INFO:     Epoch: 3
2022-11-23 01:05:09,922 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8386633572253314, 'Total loss': 0.8386633572253314} | train loss {'Reaction outcome loss': 0.8387525402769751, 'Total loss': 0.8387525402769751}
2022-11-23 01:05:09,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:09,923 INFO:     Epoch: 4
2022-11-23 01:05:10,749 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8082160749896006, 'Total loss': 0.8082160749896006} | train loss {'Reaction outcome loss': 0.8372822073041176, 'Total loss': 0.8372822073041176}
2022-11-23 01:05:10,749 INFO:     Found new best model at epoch 4
2022-11-23 01:05:10,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:10,750 INFO:     Epoch: 5
2022-11-23 01:05:11,528 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8370282433249734, 'Total loss': 0.8370282433249734} | train loss {'Reaction outcome loss': 0.8303914865668939, 'Total loss': 0.8303914865668939}
2022-11-23 01:05:11,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:11,528 INFO:     Epoch: 6
2022-11-23 01:05:12,342 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8204874064434658, 'Total loss': 0.8204874064434658} | train loss {'Reaction outcome loss': 0.8258180664510143, 'Total loss': 0.8258180664510143}
2022-11-23 01:05:12,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:12,344 INFO:     Epoch: 7
2022-11-23 01:05:13,131 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8335088444027033, 'Total loss': 0.8335088444027033} | train loss {'Reaction outcome loss': 0.8335159526795757, 'Total loss': 0.8335159526795757}
2022-11-23 01:05:13,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:13,131 INFO:     Epoch: 8
2022-11-23 01:05:13,918 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8240904171358455, 'Total loss': 0.8240904171358455} | train loss {'Reaction outcome loss': 0.8251914462264703, 'Total loss': 0.8251914462264703}
2022-11-23 01:05:13,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:13,919 INFO:     Epoch: 9
2022-11-23 01:05:14,671 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8139540742744099, 'Total loss': 0.8139540742744099} | train loss {'Reaction outcome loss': 0.8225292970939558, 'Total loss': 0.8225292970939558}
2022-11-23 01:05:14,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:14,672 INFO:     Epoch: 10
2022-11-23 01:05:15,427 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8108556798913262, 'Total loss': 0.8108556798913262} | train loss {'Reaction outcome loss': 0.83057783112234, 'Total loss': 0.83057783112234}
2022-11-23 01:05:15,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:15,427 INFO:     Epoch: 11
2022-11-23 01:05:16,205 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8334516808390617, 'Total loss': 0.8334516808390617} | train loss {'Reaction outcome loss': 0.8243822489465986, 'Total loss': 0.8243822489465986}
2022-11-23 01:05:16,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:16,206 INFO:     Epoch: 12
2022-11-23 01:05:17,006 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8138356073336168, 'Total loss': 0.8138356073336168} | train loss {'Reaction outcome loss': 0.8259849805004743, 'Total loss': 0.8259849805004743}
2022-11-23 01:05:17,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:17,007 INFO:     Epoch: 13
2022-11-23 01:05:17,808 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8074024373834784, 'Total loss': 0.8074024373834784} | train loss {'Reaction outcome loss': 0.8213694086488412, 'Total loss': 0.8213694086488412}
2022-11-23 01:05:17,812 INFO:     Found new best model at epoch 13
2022-11-23 01:05:17,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:17,813 INFO:     Epoch: 14
2022-11-23 01:05:18,666 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8142378892410885, 'Total loss': 0.8142378892410885} | train loss {'Reaction outcome loss': 0.8217082737659921, 'Total loss': 0.8217082737659921}
2022-11-23 01:05:18,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:18,666 INFO:     Epoch: 15
2022-11-23 01:05:19,482 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8131846223365177, 'Total loss': 0.8131846223365177} | train loss {'Reaction outcome loss': 0.8212053933922125, 'Total loss': 0.8212053933922125}
2022-11-23 01:05:19,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:19,482 INFO:     Epoch: 16
2022-11-23 01:05:20,325 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8110042905265634, 'Total loss': 0.8110042905265634} | train loss {'Reaction outcome loss': 0.8222044124895213, 'Total loss': 0.8222044124895213}
2022-11-23 01:05:20,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:20,326 INFO:     Epoch: 17
2022-11-23 01:05:21,134 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8122356256300752, 'Total loss': 0.8122356256300752} | train loss {'Reaction outcome loss': 0.8221149657453809, 'Total loss': 0.8221149657453809}
2022-11-23 01:05:21,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:21,134 INFO:     Epoch: 18
2022-11-23 01:05:21,918 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8408540649847551, 'Total loss': 0.8408540649847551} | train loss {'Reaction outcome loss': 0.82344751516167, 'Total loss': 0.82344751516167}
2022-11-23 01:05:21,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:21,918 INFO:     Epoch: 19
2022-11-23 01:05:22,722 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8194268616763029, 'Total loss': 0.8194268616763029} | train loss {'Reaction outcome loss': 0.817789316055726, 'Total loss': 0.817789316055726}
2022-11-23 01:05:22,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:22,722 INFO:     Epoch: 20
2022-11-23 01:05:23,536 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8113072302869775, 'Total loss': 0.8113072302869775} | train loss {'Reaction outcome loss': 0.8207640118744909, 'Total loss': 0.8207640118744909}
2022-11-23 01:05:23,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:23,536 INFO:     Epoch: 21
2022-11-23 01:05:24,323 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8230875425718047, 'Total loss': 0.8230875425718047} | train loss {'Reaction outcome loss': 0.820211831039312, 'Total loss': 0.820211831039312}
2022-11-23 01:05:24,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:24,324 INFO:     Epoch: 22
2022-11-23 01:05:25,127 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8214406587860801, 'Total loss': 0.8214406587860801} | train loss {'Reaction outcome loss': 0.8215105756204956, 'Total loss': 0.8215105756204956}
2022-11-23 01:05:25,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:25,127 INFO:     Epoch: 23
2022-11-23 01:05:25,924 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8153570741415024, 'Total loss': 0.8153570741415024} | train loss {'Reaction outcome loss': 0.8272734740558936, 'Total loss': 0.8272734740558936}
2022-11-23 01:05:25,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:25,924 INFO:     Epoch: 24
2022-11-23 01:05:26,720 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8101597008380023, 'Total loss': 0.8101597008380023} | train loss {'Reaction outcome loss': 0.8212336515893741, 'Total loss': 0.8212336515893741}
2022-11-23 01:05:26,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:26,720 INFO:     Epoch: 25
2022-11-23 01:05:27,542 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8195373172109778, 'Total loss': 0.8195373172109778} | train loss {'Reaction outcome loss': 0.8198424816131592, 'Total loss': 0.8198424816131592}
2022-11-23 01:05:27,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:27,542 INFO:     Epoch: 26
2022-11-23 01:05:28,383 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8102522600780834, 'Total loss': 0.8102522600780834} | train loss {'Reaction outcome loss': 0.821143477060357, 'Total loss': 0.821143477060357}
2022-11-23 01:05:28,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:28,383 INFO:     Epoch: 27
2022-11-23 01:05:29,180 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.800806390968236, 'Total loss': 0.800806390968236} | train loss {'Reaction outcome loss': 0.8206585052062054, 'Total loss': 0.8206585052062054}
2022-11-23 01:05:29,180 INFO:     Found new best model at epoch 27
2022-11-23 01:05:29,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:29,181 INFO:     Epoch: 28
2022-11-23 01:05:29,972 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.829740235074, 'Total loss': 0.829740235074} | train loss {'Reaction outcome loss': 0.8208141135926149, 'Total loss': 0.8208141135926149}
2022-11-23 01:05:29,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:29,972 INFO:     Epoch: 29
2022-11-23 01:05:30,783 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.816363512115045, 'Total loss': 0.816363512115045} | train loss {'Reaction outcome loss': 0.8193060256996934, 'Total loss': 0.8193060256996934}
2022-11-23 01:05:30,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:30,783 INFO:     Epoch: 30
2022-11-23 01:05:31,547 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8000338118184697, 'Total loss': 0.8000338118184697} | train loss {'Reaction outcome loss': 0.8204617668171318, 'Total loss': 0.8204617668171318}
2022-11-23 01:05:31,547 INFO:     Found new best model at epoch 30
2022-11-23 01:05:31,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:31,548 INFO:     Epoch: 31
2022-11-23 01:05:32,336 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8232519464059309, 'Total loss': 0.8232519464059309} | train loss {'Reaction outcome loss': 0.8201811429189176, 'Total loss': 0.8201811429189176}
2022-11-23 01:05:32,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:32,337 INFO:     Epoch: 32
2022-11-23 01:05:33,110 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.838407118212093, 'Total loss': 0.838407118212093} | train loss {'Reaction outcome loss': 0.8180245719393905, 'Total loss': 0.8180245719393905}
2022-11-23 01:05:33,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:33,110 INFO:     Epoch: 33
2022-11-23 01:05:33,885 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8004710423675451, 'Total loss': 0.8004710423675451} | train loss {'Reaction outcome loss': 0.8196352410073183, 'Total loss': 0.8196352410073183}
2022-11-23 01:05:33,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:33,885 INFO:     Epoch: 34
2022-11-23 01:05:34,691 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8032966882667758, 'Total loss': 0.8032966882667758} | train loss {'Reaction outcome loss': 0.8193897300836991, 'Total loss': 0.8193897300836991}
2022-11-23 01:05:34,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:34,691 INFO:     Epoch: 35
2022-11-23 01:05:35,549 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8177162612026388, 'Total loss': 0.8177162612026388} | train loss {'Reaction outcome loss': 0.8142268501982397, 'Total loss': 0.8142268501982397}
2022-11-23 01:05:35,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:35,550 INFO:     Epoch: 36
2022-11-23 01:05:36,336 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8280167281627655, 'Total loss': 0.8280167281627655} | train loss {'Reaction outcome loss': 0.817473777216308, 'Total loss': 0.817473777216308}
2022-11-23 01:05:36,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:36,337 INFO:     Epoch: 37
2022-11-23 01:05:37,136 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8120622472329573, 'Total loss': 0.8120622472329573} | train loss {'Reaction outcome loss': 0.8179834471673382, 'Total loss': 0.8179834471673382}
2022-11-23 01:05:37,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:37,136 INFO:     Epoch: 38
2022-11-23 01:05:37,906 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8132590001279657, 'Total loss': 0.8132590001279657} | train loss {'Reaction outcome loss': 0.8190137524994052, 'Total loss': 0.8190137524994052}
2022-11-23 01:05:37,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:37,906 INFO:     Epoch: 39
2022-11-23 01:05:38,674 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8276628594506871, 'Total loss': 0.8276628594506871} | train loss {'Reaction outcome loss': 0.8171858844708423, 'Total loss': 0.8171858844708423}
2022-11-23 01:05:38,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:38,674 INFO:     Epoch: 40
2022-11-23 01:05:39,443 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8222608864307404, 'Total loss': 0.8222608864307404} | train loss {'Reaction outcome loss': 0.8200925971780505, 'Total loss': 0.8200925971780505}
2022-11-23 01:05:39,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:39,443 INFO:     Epoch: 41
2022-11-23 01:05:40,207 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8135909133336761, 'Total loss': 0.8135909133336761} | train loss {'Reaction outcome loss': 0.817743011883327, 'Total loss': 0.817743011883327}
2022-11-23 01:05:40,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:40,208 INFO:     Epoch: 42
2022-11-23 01:05:41,014 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8378914540464227, 'Total loss': 0.8378914540464227} | train loss {'Reaction outcome loss': 0.8184394128468572, 'Total loss': 0.8184394128468572}
2022-11-23 01:05:41,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:41,014 INFO:     Epoch: 43
2022-11-23 01:05:41,823 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7909597937356342, 'Total loss': 0.7909597937356342} | train loss {'Reaction outcome loss': 0.8169125556945801, 'Total loss': 0.8169125556945801}
2022-11-23 01:05:41,823 INFO:     Found new best model at epoch 43
2022-11-23 01:05:41,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:41,824 INFO:     Epoch: 44
2022-11-23 01:05:42,605 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8042012337933887, 'Total loss': 0.8042012337933887} | train loss {'Reaction outcome loss': 0.8191233849038884, 'Total loss': 0.8191233849038884}
2022-11-23 01:05:42,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:42,605 INFO:     Epoch: 45
2022-11-23 01:05:43,429 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8048401806842197, 'Total loss': 0.8048401806842197} | train loss {'Reaction outcome loss': 0.8166051486316992, 'Total loss': 0.8166051486316992}
2022-11-23 01:05:43,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:43,429 INFO:     Epoch: 46
2022-11-23 01:05:44,229 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7953873991288922, 'Total loss': 0.7953873991288922} | train loss {'Reaction outcome loss': 0.8192565391258317, 'Total loss': 0.8192565391258317}
2022-11-23 01:05:44,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:44,229 INFO:     Epoch: 47
2022-11-23 01:05:45,045 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8216269544579766, 'Total loss': 0.8216269544579766} | train loss {'Reaction outcome loss': 0.8194291702338627, 'Total loss': 0.8194291702338627}
2022-11-23 01:05:45,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:45,046 INFO:     Epoch: 48
2022-11-23 01:05:45,846 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.806157720359889, 'Total loss': 0.806157720359889} | train loss {'Reaction outcome loss': 0.8210468896797725, 'Total loss': 0.8210468896797725}
2022-11-23 01:05:45,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:45,847 INFO:     Epoch: 49
2022-11-23 01:05:46,688 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8526860787109896, 'Total loss': 0.8526860787109896} | train loss {'Reaction outcome loss': 0.8177671459256386, 'Total loss': 0.8177671459256386}
2022-11-23 01:05:46,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:46,688 INFO:     Epoch: 50
2022-11-23 01:05:47,499 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.830826610326767, 'Total loss': 0.830826610326767} | train loss {'Reaction outcome loss': 0.8197219617512761, 'Total loss': 0.8197219617512761}
2022-11-23 01:05:47,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:47,500 INFO:     Epoch: 51
2022-11-23 01:05:48,295 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8134397126056931, 'Total loss': 0.8134397126056931} | train loss {'Reaction outcome loss': 0.8217941970241313, 'Total loss': 0.8217941970241313}
2022-11-23 01:05:48,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:48,295 INFO:     Epoch: 52
2022-11-23 01:05:49,091 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7980846430767666, 'Total loss': 0.7980846430767666} | train loss {'Reaction outcome loss': 0.817429493884651, 'Total loss': 0.817429493884651}
2022-11-23 01:05:49,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:49,093 INFO:     Epoch: 53
2022-11-23 01:05:49,920 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.833657989447767, 'Total loss': 0.833657989447767} | train loss {'Reaction outcome loss': 0.81730733337451, 'Total loss': 0.81730733337451}
2022-11-23 01:05:49,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:49,921 INFO:     Epoch: 54
2022-11-23 01:05:50,714 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7937549217180773, 'Total loss': 0.7937549217180773} | train loss {'Reaction outcome loss': 0.8161466233584346, 'Total loss': 0.8161466233584346}
2022-11-23 01:05:50,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:50,714 INFO:     Epoch: 55
2022-11-23 01:05:51,512 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8107654696161096, 'Total loss': 0.8107654696161096} | train loss {'Reaction outcome loss': 0.8180898980218537, 'Total loss': 0.8180898980218537}
2022-11-23 01:05:51,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:51,513 INFO:     Epoch: 56
2022-11-23 01:05:52,340 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8350271413272078, 'Total loss': 0.8350271413272078} | train loss {'Reaction outcome loss': 0.8173053512767869, 'Total loss': 0.8173053512767869}
2022-11-23 01:05:52,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:52,340 INFO:     Epoch: 57
2022-11-23 01:05:53,124 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8338033604350957, 'Total loss': 0.8338033604350957} | train loss {'Reaction outcome loss': 0.8199601438580727, 'Total loss': 0.8199601438580727}
2022-11-23 01:05:53,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:53,124 INFO:     Epoch: 58
2022-11-23 01:05:53,911 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8455761156298898, 'Total loss': 0.8455761156298898} | train loss {'Reaction outcome loss': 0.8207420755405815, 'Total loss': 0.8207420755405815}
2022-11-23 01:05:53,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:53,912 INFO:     Epoch: 59
2022-11-23 01:05:54,725 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8176366165280342, 'Total loss': 0.8176366165280342} | train loss {'Reaction outcome loss': 0.8166071352910023, 'Total loss': 0.8166071352910023}
2022-11-23 01:05:54,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:54,725 INFO:     Epoch: 60
2022-11-23 01:05:55,515 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8269458148967136, 'Total loss': 0.8269458148967136} | train loss {'Reaction outcome loss': 0.8164813741129272, 'Total loss': 0.8164813741129272}
2022-11-23 01:05:55,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:55,517 INFO:     Epoch: 61
2022-11-23 01:05:56,346 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8409216180443764, 'Total loss': 0.8409216180443764} | train loss {'Reaction outcome loss': 0.8225136613359256, 'Total loss': 0.8225136613359256}
2022-11-23 01:05:56,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:56,346 INFO:     Epoch: 62
2022-11-23 01:05:57,158 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8232277577573602, 'Total loss': 0.8232277577573602} | train loss {'Reaction outcome loss': 0.8164735968015632, 'Total loss': 0.8164735968015632}
2022-11-23 01:05:57,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:57,158 INFO:     Epoch: 63
2022-11-23 01:05:57,967 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8048402206464247, 'Total loss': 0.8048402206464247} | train loss {'Reaction outcome loss': 0.8134379225117819, 'Total loss': 0.8134379225117819}
2022-11-23 01:05:57,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:57,967 INFO:     Epoch: 64
2022-11-23 01:05:58,782 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.824200225147334, 'Total loss': 0.824200225147334} | train loss {'Reaction outcome loss': 0.8167609566328476, 'Total loss': 0.8167609566328476}
2022-11-23 01:05:58,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:58,783 INFO:     Epoch: 65
2022-11-23 01:05:59,632 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8084936981851404, 'Total loss': 0.8084936981851404} | train loss {'Reaction outcome loss': 0.8231387044702257, 'Total loss': 0.8231387044702257}
2022-11-23 01:05:59,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:05:59,632 INFO:     Epoch: 66
2022-11-23 01:06:00,507 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8300657042048194, 'Total loss': 0.8300657042048194} | train loss {'Reaction outcome loss': 0.8192348702829712, 'Total loss': 0.8192348702829712}
2022-11-23 01:06:00,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:00,508 INFO:     Epoch: 67
2022-11-23 01:06:01,355 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8055591515519402, 'Total loss': 0.8055591515519402} | train loss {'Reaction outcome loss': 0.8208344066629605, 'Total loss': 0.8208344066629605}
2022-11-23 01:06:01,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:01,355 INFO:     Epoch: 68
2022-11-23 01:06:02,253 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8412539823488756, 'Total loss': 0.8412539823488756} | train loss {'Reaction outcome loss': 0.8202806304912178, 'Total loss': 0.8202806304912178}
2022-11-23 01:06:02,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:02,253 INFO:     Epoch: 69
2022-11-23 01:06:03,119 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8265452303669669, 'Total loss': 0.8265452303669669} | train loss {'Reaction outcome loss': 0.8171297583044792, 'Total loss': 0.8171297583044792}
2022-11-23 01:06:03,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:03,119 INFO:     Epoch: 70
2022-11-23 01:06:03,982 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8068354339762167, 'Total loss': 0.8068354339762167} | train loss {'Reaction outcome loss': 0.8197115778923034, 'Total loss': 0.8197115778923034}
2022-11-23 01:06:03,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:03,983 INFO:     Epoch: 71
2022-11-23 01:06:04,856 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8175151998346503, 'Total loss': 0.8175151998346503} | train loss {'Reaction outcome loss': 0.8214676775494401, 'Total loss': 0.8214676775494401}
2022-11-23 01:06:04,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:04,856 INFO:     Epoch: 72
2022-11-23 01:06:05,687 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8301482850855048, 'Total loss': 0.8301482850855048} | train loss {'Reaction outcome loss': 0.8191342164059074, 'Total loss': 0.8191342164059074}
2022-11-23 01:06:05,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:05,687 INFO:     Epoch: 73
2022-11-23 01:06:06,491 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8150185969742861, 'Total loss': 0.8150185969742861} | train loss {'Reaction outcome loss': 0.822592283146722, 'Total loss': 0.822592283146722}
2022-11-23 01:06:06,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:06,491 INFO:     Epoch: 74
2022-11-23 01:06:07,302 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8162061809138819, 'Total loss': 0.8162061809138819} | train loss {'Reaction outcome loss': 0.8194032423350276, 'Total loss': 0.8194032423350276}
2022-11-23 01:06:07,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:07,303 INFO:     Epoch: 75
2022-11-23 01:06:08,147 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8056722337549383, 'Total loss': 0.8056722337549383} | train loss {'Reaction outcome loss': 0.8183126667324377, 'Total loss': 0.8183126667324377}
2022-11-23 01:06:08,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:08,148 INFO:     Epoch: 76
2022-11-23 01:06:08,966 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8092841197821227, 'Total loss': 0.8092841197821227} | train loss {'Reaction outcome loss': 0.8165236603240578, 'Total loss': 0.8165236603240578}
2022-11-23 01:06:08,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:08,967 INFO:     Epoch: 77
2022-11-23 01:06:09,781 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8264974179593, 'Total loss': 0.8264974179593} | train loss {'Reaction outcome loss': 0.8202533646505706, 'Total loss': 0.8202533646505706}
2022-11-23 01:06:09,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:09,781 INFO:     Epoch: 78
2022-11-23 01:06:10,578 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8023525124246423, 'Total loss': 0.8023525124246423} | train loss {'Reaction outcome loss': 0.8196652912363714, 'Total loss': 0.8196652912363714}
2022-11-23 01:06:10,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:10,578 INFO:     Epoch: 79
2022-11-23 01:06:11,383 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8242472782731056, 'Total loss': 0.8242472782731056} | train loss {'Reaction outcome loss': 0.8193319253775538, 'Total loss': 0.8193319253775538}
2022-11-23 01:06:11,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:11,383 INFO:     Epoch: 80
2022-11-23 01:06:12,249 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8095629939978773, 'Total loss': 0.8095629939978773} | train loss {'Reaction outcome loss': 0.8217851704480696, 'Total loss': 0.8217851704480696}
2022-11-23 01:06:12,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:12,249 INFO:     Epoch: 81
2022-11-23 01:06:13,090 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8162819025191393, 'Total loss': 0.8162819025191393} | train loss {'Reaction outcome loss': 0.818982707480995, 'Total loss': 0.818982707480995}
2022-11-23 01:06:13,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:13,090 INFO:     Epoch: 82
2022-11-23 01:06:13,922 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8114961358633909, 'Total loss': 0.8114961358633909} | train loss {'Reaction outcome loss': 0.8186971337211375, 'Total loss': 0.8186971337211375}
2022-11-23 01:06:13,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:13,922 INFO:     Epoch: 83
2022-11-23 01:06:14,749 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8274274190718477, 'Total loss': 0.8274274190718477} | train loss {'Reaction outcome loss': 0.825281305580723, 'Total loss': 0.825281305580723}
2022-11-23 01:06:14,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:14,749 INFO:     Epoch: 84
2022-11-23 01:06:15,547 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8031415810639208, 'Total loss': 0.8031415810639208} | train loss {'Reaction outcome loss': 0.8177561857262436, 'Total loss': 0.8177561857262436}
2022-11-23 01:06:15,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:15,548 INFO:     Epoch: 85
2022-11-23 01:06:16,371 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8262432366609573, 'Total loss': 0.8262432366609573} | train loss {'Reaction outcome loss': 0.8213765426557891, 'Total loss': 0.8213765426557891}
2022-11-23 01:06:16,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:16,372 INFO:     Epoch: 86
2022-11-23 01:06:17,176 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8299427576024424, 'Total loss': 0.8299427576024424} | train loss {'Reaction outcome loss': 0.8198759133718452, 'Total loss': 0.8198759133718452}
2022-11-23 01:06:17,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:17,176 INFO:     Epoch: 87
2022-11-23 01:06:17,984 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8212172253565355, 'Total loss': 0.8212172253565355} | train loss {'Reaction outcome loss': 0.8173915382550687, 'Total loss': 0.8173915382550687}
2022-11-23 01:06:17,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:17,984 INFO:     Epoch: 88
2022-11-23 01:06:18,836 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8228584236719392, 'Total loss': 0.8228584236719392} | train loss {'Reaction outcome loss': 0.8202604571775515, 'Total loss': 0.8202604571775515}
2022-11-23 01:06:18,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:18,836 INFO:     Epoch: 89
2022-11-23 01:06:19,637 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8025071289051663, 'Total loss': 0.8025071289051663} | train loss {'Reaction outcome loss': 0.8205284690370365, 'Total loss': 0.8205284690370365}
2022-11-23 01:06:19,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:19,637 INFO:     Epoch: 90
2022-11-23 01:06:20,446 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8033989498561079, 'Total loss': 0.8033989498561079} | train loss {'Reaction outcome loss': 0.8188516655746771, 'Total loss': 0.8188516655746771}
2022-11-23 01:06:20,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:20,447 INFO:     Epoch: 91
2022-11-23 01:06:21,304 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8074667196382176, 'Total loss': 0.8074667196382176} | train loss {'Reaction outcome loss': 0.8187076560088566, 'Total loss': 0.8187076560088566}
2022-11-23 01:06:21,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:21,304 INFO:     Epoch: 92
2022-11-23 01:06:22,086 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.807116298512979, 'Total loss': 0.807116298512979} | train loss {'Reaction outcome loss': 0.8176660461085183, 'Total loss': 0.8176660461085183}
2022-11-23 01:06:22,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:22,086 INFO:     Epoch: 93
2022-11-23 01:06:22,911 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8243165862831202, 'Total loss': 0.8243165862831202} | train loss {'Reaction outcome loss': 0.8208590637056195, 'Total loss': 0.8208590637056195}
2022-11-23 01:06:22,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:22,912 INFO:     Epoch: 94
2022-11-23 01:06:23,689 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8378759161992506, 'Total loss': 0.8378759161992506} | train loss {'Reaction outcome loss': 0.819766966420777, 'Total loss': 0.819766966420777}
2022-11-23 01:06:23,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:23,690 INFO:     Epoch: 95
2022-11-23 01:06:24,502 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8127674406225031, 'Total loss': 0.8127674406225031} | train loss {'Reaction outcome loss': 0.8164624032925586, 'Total loss': 0.8164624032925586}
2022-11-23 01:06:24,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:24,502 INFO:     Epoch: 96
2022-11-23 01:06:25,302 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8178093765269626, 'Total loss': 0.8178093765269626} | train loss {'Reaction outcome loss': 0.8189317052461663, 'Total loss': 0.8189317052461663}
2022-11-23 01:06:25,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:25,302 INFO:     Epoch: 97
2022-11-23 01:06:26,059 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7984459450976416, 'Total loss': 0.7984459450976416} | train loss {'Reaction outcome loss': 0.8205716856888362, 'Total loss': 0.8205716856888362}
2022-11-23 01:06:26,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:26,059 INFO:     Epoch: 98
2022-11-23 01:06:26,842 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8154176981611685, 'Total loss': 0.8154176981611685} | train loss {'Reaction outcome loss': 0.8139321082708787, 'Total loss': 0.8139321082708787}
2022-11-23 01:06:26,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:26,844 INFO:     Epoch: 99
2022-11-23 01:06:27,633 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8328368149020455, 'Total loss': 0.8328368149020455} | train loss {'Reaction outcome loss': 0.8233385340291627, 'Total loss': 0.8233385340291627}
2022-11-23 01:06:27,633 INFO:     Best model found after epoch 44 of 100.
2022-11-23 01:06:27,634 INFO:   Done with stage: TRAINING
2022-11-23 01:06:27,634 INFO:   Starting stage: EVALUATION
2022-11-23 01:06:27,765 INFO:   Done with stage: EVALUATION
2022-11-23 01:06:27,765 INFO:   Leaving out SEQ value Fold_4
2022-11-23 01:06:27,778 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 01:06:27,778 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:06:28,457 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:06:28,457 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:06:28,528 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:06:28,528 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:06:28,528 INFO:     No hyperparam tuning for this model
2022-11-23 01:06:28,528 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:06:28,528 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:06:28,529 INFO:     None feature selector for col prot
2022-11-23 01:06:28,529 INFO:     None feature selector for col prot
2022-11-23 01:06:28,529 INFO:     None feature selector for col prot
2022-11-23 01:06:28,530 INFO:     None feature selector for col chem
2022-11-23 01:06:28,530 INFO:     None feature selector for col chem
2022-11-23 01:06:28,530 INFO:     None feature selector for col chem
2022-11-23 01:06:28,530 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:06:28,530 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:06:28,532 INFO:     Number of params in model 168571
2022-11-23 01:06:28,535 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:06:28,535 INFO:   Starting stage: TRAINING
2022-11-23 01:06:28,593 INFO:     Val loss before train {'Reaction outcome loss': 0.9945605045015161, 'Total loss': 0.9945605045015161}
2022-11-23 01:06:28,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:28,594 INFO:     Epoch: 0
2022-11-23 01:06:29,405 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8450638638301329, 'Total loss': 0.8450638638301329} | train loss {'Reaction outcome loss': 0.8845714777104767, 'Total loss': 0.8845714777104767}
2022-11-23 01:06:29,405 INFO:     Found new best model at epoch 0
2022-11-23 01:06:29,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:29,406 INFO:     Epoch: 1
2022-11-23 01:06:30,178 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8256456953558055, 'Total loss': 0.8256456953558055} | train loss {'Reaction outcome loss': 0.8576984816958547, 'Total loss': 0.8576984816958547}
2022-11-23 01:06:30,178 INFO:     Found new best model at epoch 1
2022-11-23 01:06:30,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:30,179 INFO:     Epoch: 2
2022-11-23 01:06:30,964 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8199086135083978, 'Total loss': 0.8199086135083978} | train loss {'Reaction outcome loss': 0.8494066281719246, 'Total loss': 0.8494066281719246}
2022-11-23 01:06:30,964 INFO:     Found new best model at epoch 2
2022-11-23 01:06:30,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:30,965 INFO:     Epoch: 3
2022-11-23 01:06:31,755 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8282004039395939, 'Total loss': 0.8282004039395939} | train loss {'Reaction outcome loss': 0.8558287129469728, 'Total loss': 0.8558287129469728}
2022-11-23 01:06:31,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:31,756 INFO:     Epoch: 4
2022-11-23 01:06:32,528 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8331119472330267, 'Total loss': 0.8331119472330267} | train loss {'Reaction outcome loss': 0.8367553897473493, 'Total loss': 0.8367553897473493}
2022-11-23 01:06:32,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:32,528 INFO:     Epoch: 5
2022-11-23 01:06:33,305 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8122645020484924, 'Total loss': 0.8122645020484924} | train loss {'Reaction outcome loss': 0.8412301967501158, 'Total loss': 0.8412301967501158}
2022-11-23 01:06:33,305 INFO:     Found new best model at epoch 5
2022-11-23 01:06:33,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:33,306 INFO:     Epoch: 6
2022-11-23 01:06:34,101 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8070308125831864, 'Total loss': 0.8070308125831864} | train loss {'Reaction outcome loss': 0.8345392370362755, 'Total loss': 0.8345392370362755}
2022-11-23 01:06:34,101 INFO:     Found new best model at epoch 6
2022-11-23 01:06:34,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:34,102 INFO:     Epoch: 7
2022-11-23 01:06:34,886 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8360479372468862, 'Total loss': 0.8360479372468862} | train loss {'Reaction outcome loss': 0.8327185033786635, 'Total loss': 0.8327185033786635}
2022-11-23 01:06:34,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:34,886 INFO:     Epoch: 8
2022-11-23 01:06:35,699 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8177946237000552, 'Total loss': 0.8177946237000552} | train loss {'Reaction outcome loss': 0.8342354070802449, 'Total loss': 0.8342354070802449}
2022-11-23 01:06:35,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:35,699 INFO:     Epoch: 9
2022-11-23 01:06:36,498 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7956682707775723, 'Total loss': 0.7956682707775723} | train loss {'Reaction outcome loss': 0.8322818822223648, 'Total loss': 0.8322818822223648}
2022-11-23 01:06:36,498 INFO:     Found new best model at epoch 9
2022-11-23 01:06:36,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:36,499 INFO:     Epoch: 10
2022-11-23 01:06:37,312 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8089036934755065, 'Total loss': 0.8089036934755065} | train loss {'Reaction outcome loss': 0.830372899288108, 'Total loss': 0.830372899288108}
2022-11-23 01:06:37,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:37,312 INFO:     Epoch: 11
2022-11-23 01:06:38,141 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8236470981077715, 'Total loss': 0.8236470981077715} | train loss {'Reaction outcome loss': 0.8344266342248029, 'Total loss': 0.8344266342248029}
2022-11-23 01:06:38,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:38,141 INFO:     Epoch: 12
2022-11-23 01:06:38,974 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8036144294522025, 'Total loss': 0.8036144294522025} | train loss {'Reaction outcome loss': 0.8292166457364434, 'Total loss': 0.8292166457364434}
2022-11-23 01:06:38,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:38,975 INFO:     Epoch: 13
2022-11-23 01:06:39,820 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.808876400644129, 'Total loss': 0.808876400644129} | train loss {'Reaction outcome loss': 0.8235347523139074, 'Total loss': 0.8235347523139074}
2022-11-23 01:06:39,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:39,820 INFO:     Epoch: 14
2022-11-23 01:06:40,593 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8260986865921454, 'Total loss': 0.8260986865921454} | train loss {'Reaction outcome loss': 0.8337894015707951, 'Total loss': 0.8337894015707951}
2022-11-23 01:06:40,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:40,594 INFO:     Epoch: 15
2022-11-23 01:06:41,402 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8187331448901783, 'Total loss': 0.8187331448901783} | train loss {'Reaction outcome loss': 0.842435574965921, 'Total loss': 0.842435574965921}
2022-11-23 01:06:41,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:41,402 INFO:     Epoch: 16
2022-11-23 01:06:42,223 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8195026693019, 'Total loss': 0.8195026693019} | train loss {'Reaction outcome loss': 0.8254089924970619, 'Total loss': 0.8254089924970619}
2022-11-23 01:06:42,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:42,223 INFO:     Epoch: 17
2022-11-23 01:06:43,045 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8166549822146242, 'Total loss': 0.8166549822146242} | train loss {'Reaction outcome loss': 0.8294914851063176, 'Total loss': 0.8294914851063176}
2022-11-23 01:06:43,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:43,046 INFO:     Epoch: 18
2022-11-23 01:06:43,869 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8078419132666155, 'Total loss': 0.8078419132666155} | train loss {'Reaction outcome loss': 0.8235283158568718, 'Total loss': 0.8235283158568718}
2022-11-23 01:06:43,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:43,869 INFO:     Epoch: 19
2022-11-23 01:06:44,674 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8197359124367888, 'Total loss': 0.8197359124367888} | train loss {'Reaction outcome loss': 0.8298931624966595, 'Total loss': 0.8298931624966595}
2022-11-23 01:06:44,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:44,674 INFO:     Epoch: 20
2022-11-23 01:06:45,477 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8175763094967062, 'Total loss': 0.8175763094967062} | train loss {'Reaction outcome loss': 0.8314189733522623, 'Total loss': 0.8314189733522623}
2022-11-23 01:06:45,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:45,478 INFO:     Epoch: 21
2022-11-23 01:06:46,294 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8426987610080026, 'Total loss': 0.8426987610080026} | train loss {'Reaction outcome loss': 0.8280442960349171, 'Total loss': 0.8280442960349171}
2022-11-23 01:06:46,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:46,294 INFO:     Epoch: 22
2022-11-23 01:06:47,107 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8139052025296472, 'Total loss': 0.8139052025296472} | train loss {'Reaction outcome loss': 0.8285872329343186, 'Total loss': 0.8285872329343186}
2022-11-23 01:06:47,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:47,108 INFO:     Epoch: 23
2022-11-23 01:06:48,007 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7972534156658433, 'Total loss': 0.7972534156658433} | train loss {'Reaction outcome loss': 0.8227088670981558, 'Total loss': 0.8227088670981558}
2022-11-23 01:06:48,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:48,008 INFO:     Epoch: 24
2022-11-23 01:06:48,850 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8102973672476682, 'Total loss': 0.8102973672476682} | train loss {'Reaction outcome loss': 0.8220096271530337, 'Total loss': 0.8220096271530337}
2022-11-23 01:06:48,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:48,851 INFO:     Epoch: 25
2022-11-23 01:06:49,689 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8365006650036032, 'Total loss': 0.8365006650036032} | train loss {'Reaction outcome loss': 0.8211863025238639, 'Total loss': 0.8211863025238639}
2022-11-23 01:06:49,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:49,689 INFO:     Epoch: 26
2022-11-23 01:06:50,522 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8052112026648088, 'Total loss': 0.8052112026648088} | train loss {'Reaction outcome loss': 0.8306856887784564, 'Total loss': 0.8306856887784564}
2022-11-23 01:06:50,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:50,522 INFO:     Epoch: 27
2022-11-23 01:06:51,373 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8125670491294428, 'Total loss': 0.8125670491294428} | train loss {'Reaction outcome loss': 0.8263564919864359, 'Total loss': 0.8263564919864359}
2022-11-23 01:06:51,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:51,374 INFO:     Epoch: 28
2022-11-23 01:06:52,199 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8123037557710301, 'Total loss': 0.8123037557710301} | train loss {'Reaction outcome loss': 0.8247065674438168, 'Total loss': 0.8247065674438168}
2022-11-23 01:06:52,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:52,199 INFO:     Epoch: 29
2022-11-23 01:06:53,018 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8143252703276548, 'Total loss': 0.8143252703276548} | train loss {'Reaction outcome loss': 0.8232956377842165, 'Total loss': 0.8232956377842165}
2022-11-23 01:06:53,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:53,019 INFO:     Epoch: 30
2022-11-23 01:06:53,801 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8191459808837284, 'Total loss': 0.8191459808837284} | train loss {'Reaction outcome loss': 0.8261867730241073, 'Total loss': 0.8261867730241073}
2022-11-23 01:06:53,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:53,801 INFO:     Epoch: 31
2022-11-23 01:06:54,607 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7869413488290526, 'Total loss': 0.7869413488290526} | train loss {'Reaction outcome loss': 0.8199449307040164, 'Total loss': 0.8199449307040164}
2022-11-23 01:06:54,607 INFO:     Found new best model at epoch 31
2022-11-23 01:06:54,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:54,608 INFO:     Epoch: 32
2022-11-23 01:06:55,435 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8185131874951449, 'Total loss': 0.8185131874951449} | train loss {'Reaction outcome loss': 0.8332191826360911, 'Total loss': 0.8332191826360911}
2022-11-23 01:06:55,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:55,436 INFO:     Epoch: 33
2022-11-23 01:06:56,276 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8135471791028976, 'Total loss': 0.8135471791028976} | train loss {'Reaction outcome loss': 0.8197661351699096, 'Total loss': 0.8197661351699096}
2022-11-23 01:06:56,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:56,277 INFO:     Epoch: 34
2022-11-23 01:06:57,091 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7908709834922444, 'Total loss': 0.7908709834922444} | train loss {'Reaction outcome loss': 0.8213676029612661, 'Total loss': 0.8213676029612661}
2022-11-23 01:06:57,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:57,092 INFO:     Epoch: 35
2022-11-23 01:06:57,922 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8105586489493196, 'Total loss': 0.8105586489493196} | train loss {'Reaction outcome loss': 0.8198921696135872, 'Total loss': 0.8198921696135872}
2022-11-23 01:06:57,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:57,924 INFO:     Epoch: 36
2022-11-23 01:06:58,854 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8119436414404348, 'Total loss': 0.8119436414404348} | train loss {'Reaction outcome loss': 0.8236961199445763, 'Total loss': 0.8236961199445763}
2022-11-23 01:06:58,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:58,855 INFO:     Epoch: 37
2022-11-23 01:06:59,775 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7906746159900319, 'Total loss': 0.7906746159900319} | train loss {'Reaction outcome loss': 0.8167387368647676, 'Total loss': 0.8167387368647676}
2022-11-23 01:06:59,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:06:59,775 INFO:     Epoch: 38
2022-11-23 01:07:00,606 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7873749692331661, 'Total loss': 0.7873749692331661} | train loss {'Reaction outcome loss': 0.8193670827367527, 'Total loss': 0.8193670827367527}
2022-11-23 01:07:00,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:00,607 INFO:     Epoch: 39
2022-11-23 01:07:01,400 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8125949772921476, 'Total loss': 0.8125949772921476} | train loss {'Reaction outcome loss': 0.8242497189566191, 'Total loss': 0.8242497189566191}
2022-11-23 01:07:01,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:01,401 INFO:     Epoch: 40
2022-11-23 01:07:02,270 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8067244284532287, 'Total loss': 0.8067244284532287} | train loss {'Reaction outcome loss': 0.8259926572261069, 'Total loss': 0.8259926572261069}
2022-11-23 01:07:02,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:02,270 INFO:     Epoch: 41
2022-11-23 01:07:03,172 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8071857914328575, 'Total loss': 0.8071857914328575} | train loss {'Reaction outcome loss': 0.8192120186215349, 'Total loss': 0.8192120186215349}
2022-11-23 01:07:03,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:03,172 INFO:     Epoch: 42
2022-11-23 01:07:04,039 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7978736412796107, 'Total loss': 0.7978736412796107} | train loss {'Reaction outcome loss': 0.8194523000041483, 'Total loss': 0.8194523000041483}
2022-11-23 01:07:04,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:04,040 INFO:     Epoch: 43
2022-11-23 01:07:04,920 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.802585093812509, 'Total loss': 0.802585093812509} | train loss {'Reaction outcome loss': 0.8190904216245118, 'Total loss': 0.8190904216245118}
2022-11-23 01:07:04,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:04,921 INFO:     Epoch: 44
2022-11-23 01:07:05,805 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8027824827215888, 'Total loss': 0.8027824827215888} | train loss {'Reaction outcome loss': 0.8255235194435969, 'Total loss': 0.8255235194435969}
2022-11-23 01:07:05,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:05,806 INFO:     Epoch: 45
2022-11-23 01:07:06,679 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7990216992118142, 'Total loss': 0.7990216992118142} | train loss {'Reaction outcome loss': 0.829954201815582, 'Total loss': 0.829954201815582}
2022-11-23 01:07:06,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:06,680 INFO:     Epoch: 46
2022-11-23 01:07:07,589 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8008964115923102, 'Total loss': 0.8008964115923102} | train loss {'Reaction outcome loss': 0.8171167099690028, 'Total loss': 0.8171167099690028}
2022-11-23 01:07:07,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:07,589 INFO:     Epoch: 47
2022-11-23 01:07:08,451 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8007457655939189, 'Total loss': 0.8007457655939189} | train loss {'Reaction outcome loss': 0.8187197706236048, 'Total loss': 0.8187197706236048}
2022-11-23 01:07:08,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:08,451 INFO:     Epoch: 48
2022-11-23 01:07:09,344 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7941355491903695, 'Total loss': 0.7941355491903695} | train loss {'Reaction outcome loss': 0.8175661346690375, 'Total loss': 0.8175661346690375}
2022-11-23 01:07:09,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:09,345 INFO:     Epoch: 49
2022-11-23 01:07:10,260 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.794838935136795, 'Total loss': 0.794838935136795} | train loss {'Reaction outcome loss': 0.8203074454295973, 'Total loss': 0.8203074454295973}
2022-11-23 01:07:10,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:10,261 INFO:     Epoch: 50
2022-11-23 01:07:11,177 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8483234989372167, 'Total loss': 0.8483234989372167} | train loss {'Reaction outcome loss': 0.8172972157657871, 'Total loss': 0.8172972157657871}
2022-11-23 01:07:11,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:11,177 INFO:     Epoch: 51
2022-11-23 01:07:12,074 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7964148236946627, 'Total loss': 0.7964148236946627} | train loss {'Reaction outcome loss': 0.8223832984443619, 'Total loss': 0.8223832984443619}
2022-11-23 01:07:12,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:12,075 INFO:     Epoch: 52
2022-11-23 01:07:12,984 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7950540909712965, 'Total loss': 0.7950540909712965} | train loss {'Reaction outcome loss': 0.8278766662968315, 'Total loss': 0.8278766662968315}
2022-11-23 01:07:12,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:12,984 INFO:     Epoch: 53
2022-11-23 01:07:13,866 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8123686625198885, 'Total loss': 0.8123686625198885} | train loss {'Reaction outcome loss': 0.8163742395306406, 'Total loss': 0.8163742395306406}
2022-11-23 01:07:13,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:13,866 INFO:     Epoch: 54
2022-11-23 01:07:14,768 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7847194353287871, 'Total loss': 0.7847194353287871} | train loss {'Reaction outcome loss': 0.8266130496374509, 'Total loss': 0.8266130496374509}
2022-11-23 01:07:14,768 INFO:     Found new best model at epoch 54
2022-11-23 01:07:14,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:14,769 INFO:     Epoch: 55
2022-11-23 01:07:15,739 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7959361340511929, 'Total loss': 0.7959361340511929} | train loss {'Reaction outcome loss': 0.8243838726026327, 'Total loss': 0.8243838726026327}
2022-11-23 01:07:15,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:15,739 INFO:     Epoch: 56
2022-11-23 01:07:16,637 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8094974722374569, 'Total loss': 0.8094974722374569} | train loss {'Reaction outcome loss': 0.8200590215955186, 'Total loss': 0.8200590215955186}
2022-11-23 01:07:16,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:16,637 INFO:     Epoch: 57
2022-11-23 01:07:17,518 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8031495443799279, 'Total loss': 0.8031495443799279} | train loss {'Reaction outcome loss': 0.8164043863292648, 'Total loss': 0.8164043863292648}
2022-11-23 01:07:17,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:17,519 INFO:     Epoch: 58
2022-11-23 01:07:18,412 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7922434596852823, 'Total loss': 0.7922434596852823} | train loss {'Reaction outcome loss': 0.8209281550486561, 'Total loss': 0.8209281550486561}
2022-11-23 01:07:18,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:18,413 INFO:     Epoch: 59
2022-11-23 01:07:19,288 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7879043895412575, 'Total loss': 0.7879043895412575} | train loss {'Reaction outcome loss': 0.8278629847383692, 'Total loss': 0.8278629847383692}
2022-11-23 01:07:19,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:19,288 INFO:     Epoch: 60
2022-11-23 01:07:20,157 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8020762543786656, 'Total loss': 0.8020762543786656} | train loss {'Reaction outcome loss': 0.8255175825072686, 'Total loss': 0.8255175825072686}
2022-11-23 01:07:20,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:20,157 INFO:     Epoch: 61
2022-11-23 01:07:21,055 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8027082498777997, 'Total loss': 0.8027082498777997} | train loss {'Reaction outcome loss': 0.8182676016439793, 'Total loss': 0.8182676016439793}
2022-11-23 01:07:21,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:21,055 INFO:     Epoch: 62
2022-11-23 01:07:21,952 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8044756393540989, 'Total loss': 0.8044756393540989} | train loss {'Reaction outcome loss': 0.8164118722624142, 'Total loss': 0.8164118722624142}
2022-11-23 01:07:21,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:21,953 INFO:     Epoch: 63
2022-11-23 01:07:22,840 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7902228798378598, 'Total loss': 0.7902228798378598} | train loss {'Reaction outcome loss': 0.8130867621194013, 'Total loss': 0.8130867621194013}
2022-11-23 01:07:22,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:22,840 INFO:     Epoch: 64
2022-11-23 01:07:23,689 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8124214593659748, 'Total loss': 0.8124214593659748} | train loss {'Reaction outcome loss': 0.8214868019949569, 'Total loss': 0.8214868019949569}
2022-11-23 01:07:23,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:23,689 INFO:     Epoch: 65
2022-11-23 01:07:24,585 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7820744006471201, 'Total loss': 0.7820744006471201} | train loss {'Reaction outcome loss': 0.8186564461784325, 'Total loss': 0.8186564461784325}
2022-11-23 01:07:24,585 INFO:     Found new best model at epoch 65
2022-11-23 01:07:24,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:24,586 INFO:     Epoch: 66
2022-11-23 01:07:25,447 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7972346672957594, 'Total loss': 0.7972346672957594} | train loss {'Reaction outcome loss': 0.825385630251425, 'Total loss': 0.825385630251425}
2022-11-23 01:07:25,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:25,447 INFO:     Epoch: 67
2022-11-23 01:07:26,340 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7884740619496866, 'Total loss': 0.7884740619496866} | train loss {'Reaction outcome loss': 0.8215463184393369, 'Total loss': 0.8215463184393369}
2022-11-23 01:07:26,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:26,340 INFO:     Epoch: 68
2022-11-23 01:07:27,248 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.807149975137277, 'Total loss': 0.807149975137277} | train loss {'Reaction outcome loss': 0.8173925832577562, 'Total loss': 0.8173925832577562}
2022-11-23 01:07:27,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:27,248 INFO:     Epoch: 69
2022-11-23 01:07:28,159 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8549710579893806, 'Total loss': 0.8549710579893806} | train loss {'Reaction outcome loss': 0.8149314496198646, 'Total loss': 0.8149314496198646}
2022-11-23 01:07:28,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:28,160 INFO:     Epoch: 70
2022-11-23 01:07:28,989 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.800686544992707, 'Total loss': 0.800686544992707} | train loss {'Reaction outcome loss': 0.8192697220485703, 'Total loss': 0.8192697220485703}
2022-11-23 01:07:28,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:28,990 INFO:     Epoch: 71
2022-11-23 01:07:29,840 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7881585623730313, 'Total loss': 0.7881585623730313} | train loss {'Reaction outcome loss': 0.8201059847466858, 'Total loss': 0.8201059847466858}
2022-11-23 01:07:29,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:29,840 INFO:     Epoch: 72
2022-11-23 01:07:30,721 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7775882401249625, 'Total loss': 0.7775882401249625} | train loss {'Reaction outcome loss': 0.8223559000955419, 'Total loss': 0.8223559000955419}
2022-11-23 01:07:30,721 INFO:     Found new best model at epoch 72
2022-11-23 01:07:30,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:30,722 INFO:     Epoch: 73
2022-11-23 01:07:31,629 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7888349789110097, 'Total loss': 0.7888349789110097} | train loss {'Reaction outcome loss': 0.8191308184915226, 'Total loss': 0.8191308184915226}
2022-11-23 01:07:31,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:31,629 INFO:     Epoch: 74
2022-11-23 01:07:32,466 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7919291440736164, 'Total loss': 0.7919291440736164} | train loss {'Reaction outcome loss': 0.8132963250523154, 'Total loss': 0.8132963250523154}
2022-11-23 01:07:32,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:32,467 INFO:     Epoch: 75
2022-11-23 01:07:33,335 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7858475663445212, 'Total loss': 0.7858475663445212} | train loss {'Reaction outcome loss': 0.8172853845605242, 'Total loss': 0.8172853845605242}
2022-11-23 01:07:33,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:33,335 INFO:     Epoch: 76
2022-11-23 01:07:34,212 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7953568730841983, 'Total loss': 0.7953568730841983} | train loss {'Reaction outcome loss': 0.8163596981389802, 'Total loss': 0.8163596981389802}
2022-11-23 01:07:34,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:34,213 INFO:     Epoch: 77
2022-11-23 01:07:35,096 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7871578593145717, 'Total loss': 0.7871578593145717} | train loss {'Reaction outcome loss': 0.8221003450604103, 'Total loss': 0.8221003450604103}
2022-11-23 01:07:35,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:35,097 INFO:     Epoch: 78
2022-11-23 01:07:36,007 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8014025722037662, 'Total loss': 0.8014025722037662} | train loss {'Reaction outcome loss': 0.8176295377223598, 'Total loss': 0.8176295377223598}
2022-11-23 01:07:36,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:36,008 INFO:     Epoch: 79
2022-11-23 01:07:36,867 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8132775127887726, 'Total loss': 0.8132775127887726} | train loss {'Reaction outcome loss': 0.8242377274432163, 'Total loss': 0.8242377274432163}
2022-11-23 01:07:36,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:36,868 INFO:     Epoch: 80
2022-11-23 01:07:37,783 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7868943918835033, 'Total loss': 0.7868943918835033} | train loss {'Reaction outcome loss': 0.8180754249877775, 'Total loss': 0.8180754249877775}
2022-11-23 01:07:37,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:37,783 INFO:     Epoch: 81
2022-11-23 01:07:38,647 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7934069714762948, 'Total loss': 0.7934069714762948} | train loss {'Reaction outcome loss': 0.81286565941355, 'Total loss': 0.81286565941355}
2022-11-23 01:07:38,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:38,647 INFO:     Epoch: 82
2022-11-23 01:07:39,543 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8146615915677764, 'Total loss': 0.8146615915677764} | train loss {'Reaction outcome loss': 0.8190250110771009, 'Total loss': 0.8190250110771009}
2022-11-23 01:07:39,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:39,543 INFO:     Epoch: 83
2022-11-23 01:07:40,384 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7998909245837819, 'Total loss': 0.7998909245837819} | train loss {'Reaction outcome loss': 0.8145390073297477, 'Total loss': 0.8145390073297477}
2022-11-23 01:07:40,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:40,385 INFO:     Epoch: 84
2022-11-23 01:07:41,305 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7816304137760942, 'Total loss': 0.7816304137760942} | train loss {'Reaction outcome loss': 0.8145480338419949, 'Total loss': 0.8145480338419949}
2022-11-23 01:07:41,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:41,306 INFO:     Epoch: 85
2022-11-23 01:07:42,142 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7891885218295184, 'Total loss': 0.7891885218295184} | train loss {'Reaction outcome loss': 0.8197229032212423, 'Total loss': 0.8197229032212423}
2022-11-23 01:07:42,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:42,143 INFO:     Epoch: 86
2022-11-23 01:07:43,002 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7888117622245442, 'Total loss': 0.7888117622245442} | train loss {'Reaction outcome loss': 0.8207134250928516, 'Total loss': 0.8207134250928516}
2022-11-23 01:07:43,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:43,003 INFO:     Epoch: 87
2022-11-23 01:07:43,880 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8037717884237116, 'Total loss': 0.8037717884237116} | train loss {'Reaction outcome loss': 0.8243197165278771, 'Total loss': 0.8243197165278771}
2022-11-23 01:07:43,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:43,880 INFO:     Epoch: 88
2022-11-23 01:07:44,743 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7796965851025148, 'Total loss': 0.7796965851025148} | train loss {'Reaction outcome loss': 0.8183155080326173, 'Total loss': 0.8183155080326173}
2022-11-23 01:07:44,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:44,743 INFO:     Epoch: 89
2022-11-23 01:07:45,621 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8093035715547475, 'Total loss': 0.8093035715547475} | train loss {'Reaction outcome loss': 0.8159922174355279, 'Total loss': 0.8159922174355279}
2022-11-23 01:07:45,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:45,622 INFO:     Epoch: 90
2022-11-23 01:07:46,471 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7880662009119987, 'Total loss': 0.7880662009119987} | train loss {'Reaction outcome loss': 0.8189200878384625, 'Total loss': 0.8189200878384625}
2022-11-23 01:07:46,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:46,472 INFO:     Epoch: 91
2022-11-23 01:07:47,375 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.807469333437356, 'Total loss': 0.807469333437356} | train loss {'Reaction outcome loss': 0.8162518066433277, 'Total loss': 0.8162518066433277}
2022-11-23 01:07:47,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:47,376 INFO:     Epoch: 92
2022-11-23 01:07:48,235 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7903862297534943, 'Total loss': 0.7903862297534943} | train loss {'Reaction outcome loss': 0.8148964596723738, 'Total loss': 0.8148964596723738}
2022-11-23 01:07:48,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:48,236 INFO:     Epoch: 93
2022-11-23 01:07:49,090 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7830475812608545, 'Total loss': 0.7830475812608545} | train loss {'Reaction outcome loss': 0.8238994807366901, 'Total loss': 0.8238994807366901}
2022-11-23 01:07:49,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:49,091 INFO:     Epoch: 94
2022-11-23 01:07:49,936 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8080147355794907, 'Total loss': 0.8080147355794907} | train loss {'Reaction outcome loss': 0.8149682329854502, 'Total loss': 0.8149682329854502}
2022-11-23 01:07:49,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:49,937 INFO:     Epoch: 95
2022-11-23 01:07:50,792 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7922786548733711, 'Total loss': 0.7922786548733711} | train loss {'Reaction outcome loss': 0.8189094654220318, 'Total loss': 0.8189094654220318}
2022-11-23 01:07:50,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:50,792 INFO:     Epoch: 96
2022-11-23 01:07:51,637 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7954736785455183, 'Total loss': 0.7954736785455183} | train loss {'Reaction outcome loss': 0.8180530014549673, 'Total loss': 0.8180530014549673}
2022-11-23 01:07:51,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:51,637 INFO:     Epoch: 97
2022-11-23 01:07:52,475 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7885833924466913, 'Total loss': 0.7885833924466913} | train loss {'Reaction outcome loss': 0.8173365416797066, 'Total loss': 0.8173365416797066}
2022-11-23 01:07:52,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:52,476 INFO:     Epoch: 98
2022-11-23 01:07:53,306 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7936735627326098, 'Total loss': 0.7936735627326098} | train loss {'Reaction outcome loss': 0.8178357042764363, 'Total loss': 0.8178357042764363}
2022-11-23 01:07:53,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:53,308 INFO:     Epoch: 99
2022-11-23 01:07:54,149 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.790758690373464, 'Total loss': 0.790758690373464} | train loss {'Reaction outcome loss': 0.817950060010439, 'Total loss': 0.817950060010439}
2022-11-23 01:07:54,149 INFO:     Best model found after epoch 73 of 100.
2022-11-23 01:07:54,149 INFO:   Done with stage: TRAINING
2022-11-23 01:07:54,149 INFO:   Starting stage: EVALUATION
2022-11-23 01:07:54,274 INFO:   Done with stage: EVALUATION
2022-11-23 01:07:54,274 INFO:   Leaving out SEQ value Fold_5
2022-11-23 01:07:54,288 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 01:07:54,288 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:07:54,977 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:07:54,977 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:07:55,052 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:07:55,052 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:07:55,052 INFO:     No hyperparam tuning for this model
2022-11-23 01:07:55,052 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:07:55,052 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:07:55,053 INFO:     None feature selector for col prot
2022-11-23 01:07:55,053 INFO:     None feature selector for col prot
2022-11-23 01:07:55,053 INFO:     None feature selector for col prot
2022-11-23 01:07:55,054 INFO:     None feature selector for col chem
2022-11-23 01:07:55,054 INFO:     None feature selector for col chem
2022-11-23 01:07:55,054 INFO:     None feature selector for col chem
2022-11-23 01:07:55,054 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:07:55,054 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:07:55,056 INFO:     Number of params in model 168571
2022-11-23 01:07:55,059 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:07:55,059 INFO:   Starting stage: TRAINING
2022-11-23 01:07:55,119 INFO:     Val loss before train {'Reaction outcome loss': 1.0000699677250602, 'Total loss': 1.0000699677250602}
2022-11-23 01:07:55,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:55,120 INFO:     Epoch: 0
2022-11-23 01:07:55,977 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8619257590987466, 'Total loss': 0.8619257590987466} | train loss {'Reaction outcome loss': 0.8673064162434354, 'Total loss': 0.8673064162434354}
2022-11-23 01:07:55,978 INFO:     Found new best model at epoch 0
2022-11-23 01:07:55,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:55,978 INFO:     Epoch: 1
2022-11-23 01:07:56,868 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8433969169855118, 'Total loss': 0.8433969169855118} | train loss {'Reaction outcome loss': 0.8374832051877792, 'Total loss': 0.8374832051877792}
2022-11-23 01:07:56,868 INFO:     Found new best model at epoch 1
2022-11-23 01:07:56,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:56,869 INFO:     Epoch: 2
2022-11-23 01:07:57,710 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8357867043126713, 'Total loss': 0.8357867043126713} | train loss {'Reaction outcome loss': 0.8344216325022431, 'Total loss': 0.8344216325022431}
2022-11-23 01:07:57,711 INFO:     Found new best model at epoch 2
2022-11-23 01:07:57,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:57,712 INFO:     Epoch: 3
2022-11-23 01:07:58,548 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8281153277917341, 'Total loss': 0.8281153277917341} | train loss {'Reaction outcome loss': 0.83168750874668, 'Total loss': 0.83168750874668}
2022-11-23 01:07:58,548 INFO:     Found new best model at epoch 3
2022-11-23 01:07:58,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:58,549 INFO:     Epoch: 4
2022-11-23 01:07:59,417 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8444382507692684, 'Total loss': 0.8444382507692684} | train loss {'Reaction outcome loss': 0.8292701655795217, 'Total loss': 0.8292701655795217}
2022-11-23 01:07:59,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:07:59,418 INFO:     Epoch: 5
2022-11-23 01:08:00,286 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8614778234200045, 'Total loss': 0.8614778234200045} | train loss {'Reaction outcome loss': 0.8295186287478397, 'Total loss': 0.8295186287478397}
2022-11-23 01:08:00,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:00,286 INFO:     Epoch: 6
2022-11-23 01:08:01,163 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8505637300285426, 'Total loss': 0.8505637300285426} | train loss {'Reaction outcome loss': 0.8306922271908054, 'Total loss': 0.8306922271908054}
2022-11-23 01:08:01,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:01,163 INFO:     Epoch: 7
2022-11-23 01:08:01,992 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8413808386434208, 'Total loss': 0.8413808386434208} | train loss {'Reaction outcome loss': 0.8284892380720208, 'Total loss': 0.8284892380720208}
2022-11-23 01:08:01,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:01,992 INFO:     Epoch: 8
2022-11-23 01:08:02,826 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8414135345003821, 'Total loss': 0.8414135345003821} | train loss {'Reaction outcome loss': 0.8205245903387726, 'Total loss': 0.8205245903387726}
2022-11-23 01:08:02,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:02,827 INFO:     Epoch: 9
2022-11-23 01:08:03,664 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8273472345688127, 'Total loss': 0.8273472345688127} | train loss {'Reaction outcome loss': 0.8205362495321494, 'Total loss': 0.8205362495321494}
2022-11-23 01:08:03,664 INFO:     Found new best model at epoch 9
2022-11-23 01:08:03,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:03,665 INFO:     Epoch: 10
2022-11-23 01:08:04,503 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8236142153089697, 'Total loss': 0.8236142153089697} | train loss {'Reaction outcome loss': 0.8149354395716779, 'Total loss': 0.8149354395716779}
2022-11-23 01:08:04,503 INFO:     Found new best model at epoch 10
2022-11-23 01:08:04,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:04,504 INFO:     Epoch: 11
2022-11-23 01:08:05,384 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.839321877468716, 'Total loss': 0.839321877468716} | train loss {'Reaction outcome loss': 0.8154148050708326, 'Total loss': 0.8154148050708326}
2022-11-23 01:08:05,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:05,385 INFO:     Epoch: 12
2022-11-23 01:08:06,221 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8206959854472767, 'Total loss': 0.8206959854472767} | train loss {'Reaction outcome loss': 0.8170011838981015, 'Total loss': 0.8170011838981015}
2022-11-23 01:08:06,221 INFO:     Found new best model at epoch 12
2022-11-23 01:08:06,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:06,222 INFO:     Epoch: 13
2022-11-23 01:08:07,083 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.822881315919486, 'Total loss': 0.822881315919486} | train loss {'Reaction outcome loss': 0.8174248838472945, 'Total loss': 0.8174248838472945}
2022-11-23 01:08:07,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:07,084 INFO:     Epoch: 14
2022-11-23 01:08:07,889 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8265504769303582, 'Total loss': 0.8265504769303582} | train loss {'Reaction outcome loss': 0.815404479350397, 'Total loss': 0.815404479350397}
2022-11-23 01:08:07,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:07,889 INFO:     Epoch: 15
2022-11-23 01:08:08,739 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8421944562684406, 'Total loss': 0.8421944562684406} | train loss {'Reaction outcome loss': 0.8190696849996745, 'Total loss': 0.8190696849996745}
2022-11-23 01:08:08,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:08,739 INFO:     Epoch: 16
2022-11-23 01:08:09,598 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8296865231611512, 'Total loss': 0.8296865231611512} | train loss {'Reaction outcome loss': 0.815530226056875, 'Total loss': 0.815530226056875}
2022-11-23 01:08:09,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:09,598 INFO:     Epoch: 17
2022-11-23 01:08:10,409 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8366476534442469, 'Total loss': 0.8366476534442469} | train loss {'Reaction outcome loss': 0.809595104171197, 'Total loss': 0.809595104171197}
2022-11-23 01:08:10,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:10,409 INFO:     Epoch: 18
2022-11-23 01:08:11,206 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8162849396467209, 'Total loss': 0.8162849396467209} | train loss {'Reaction outcome loss': 0.8086322290212037, 'Total loss': 0.8086322290212037}
2022-11-23 01:08:11,206 INFO:     Found new best model at epoch 18
2022-11-23 01:08:11,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:11,207 INFO:     Epoch: 19
2022-11-23 01:08:12,019 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8324236422777176, 'Total loss': 0.8324236422777176} | train loss {'Reaction outcome loss': 0.8080644374675596, 'Total loss': 0.8080644374675596}
2022-11-23 01:08:12,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:12,020 INFO:     Epoch: 20
2022-11-23 01:08:12,849 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8303164121779528, 'Total loss': 0.8303164121779528} | train loss {'Reaction outcome loss': 0.8137550431224498, 'Total loss': 0.8137550431224498}
2022-11-23 01:08:12,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:12,849 INFO:     Epoch: 21
2022-11-23 01:08:13,712 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8406366279179399, 'Total loss': 0.8406366279179399} | train loss {'Reaction outcome loss': 0.8115520219088566, 'Total loss': 0.8115520219088566}
2022-11-23 01:08:13,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:13,712 INFO:     Epoch: 22
2022-11-23 01:08:14,512 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8170932368798689, 'Total loss': 0.8170932368798689} | train loss {'Reaction outcome loss': 0.8092944988234323, 'Total loss': 0.8092944988234323}
2022-11-23 01:08:14,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:14,512 INFO:     Epoch: 23
2022-11-23 01:08:15,350 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8322418264367364, 'Total loss': 0.8322418264367364} | train loss {'Reaction outcome loss': 0.814048619526118, 'Total loss': 0.814048619526118}
2022-11-23 01:08:15,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:15,350 INFO:     Epoch: 24
2022-11-23 01:08:16,185 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8378095084970648, 'Total loss': 0.8378095084970648} | train loss {'Reaction outcome loss': 0.808768852941903, 'Total loss': 0.808768852941903}
2022-11-23 01:08:16,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:16,186 INFO:     Epoch: 25
2022-11-23 01:08:17,003 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8428218181837689, 'Total loss': 0.8428218181837689} | train loss {'Reaction outcome loss': 0.8120465782670839, 'Total loss': 0.8120465782670839}
2022-11-23 01:08:17,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:17,004 INFO:     Epoch: 26
2022-11-23 01:08:17,823 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8444901406764984, 'Total loss': 0.8444901406764984} | train loss {'Reaction outcome loss': 0.8114948247367071, 'Total loss': 0.8114948247367071}
2022-11-23 01:08:17,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:17,824 INFO:     Epoch: 27
2022-11-23 01:08:18,626 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.84845677560026, 'Total loss': 0.84845677560026} | train loss {'Reaction outcome loss': 0.8136569652480152, 'Total loss': 0.8136569652480152}
2022-11-23 01:08:18,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:18,626 INFO:     Epoch: 28
2022-11-23 01:08:19,434 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8619022288105704, 'Total loss': 0.8619022288105704} | train loss {'Reaction outcome loss': 0.8169333083547561, 'Total loss': 0.8169333083547561}
2022-11-23 01:08:19,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:19,434 INFO:     Epoch: 29
2022-11-23 01:08:20,254 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8414726704359055, 'Total loss': 0.8414726704359055} | train loss {'Reaction outcome loss': 0.8120793005232869, 'Total loss': 0.8120793005232869}
2022-11-23 01:08:20,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:20,255 INFO:     Epoch: 30
2022-11-23 01:08:21,058 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8311912742528048, 'Total loss': 0.8311912742528048} | train loss {'Reaction outcome loss': 0.8160197528508993, 'Total loss': 0.8160197528508993}
2022-11-23 01:08:21,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:21,059 INFO:     Epoch: 31
2022-11-23 01:08:21,862 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8344956988638098, 'Total loss': 0.8344956988638098} | train loss {'Reaction outcome loss': 0.8078633464782344, 'Total loss': 0.8078633464782344}
2022-11-23 01:08:21,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:21,862 INFO:     Epoch: 32
2022-11-23 01:08:22,678 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8261809525164691, 'Total loss': 0.8261809525164691} | train loss {'Reaction outcome loss': 0.8115746109833119, 'Total loss': 0.8115746109833119}
2022-11-23 01:08:22,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:22,678 INFO:     Epoch: 33
2022-11-23 01:08:23,496 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8271705359220505, 'Total loss': 0.8271705359220505} | train loss {'Reaction outcome loss': 0.8184914140083529, 'Total loss': 0.8184914140083529}
2022-11-23 01:08:23,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:23,497 INFO:     Epoch: 34
2022-11-23 01:08:24,315 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.82539287480441, 'Total loss': 0.82539287480441} | train loss {'Reaction outcome loss': 0.8105077895558315, 'Total loss': 0.8105077895558315}
2022-11-23 01:08:24,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:24,315 INFO:     Epoch: 35
2022-11-23 01:08:25,093 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.816400134427981, 'Total loss': 0.816400134427981} | train loss {'Reaction outcome loss': 0.8137215880850549, 'Total loss': 0.8137215880850549}
2022-11-23 01:08:25,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:25,095 INFO:     Epoch: 36
2022-11-23 01:08:25,930 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8351509652354501, 'Total loss': 0.8351509652354501} | train loss {'Reaction outcome loss': 0.8180563043244937, 'Total loss': 0.8180563043244937}
2022-11-23 01:08:25,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:25,930 INFO:     Epoch: 37
2022-11-23 01:08:26,742 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8166264891624451, 'Total loss': 0.8166264891624451} | train loss {'Reaction outcome loss': 0.8159836463117407, 'Total loss': 0.8159836463117407}
2022-11-23 01:08:26,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:26,742 INFO:     Epoch: 38
2022-11-23 01:08:27,529 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8482419699430466, 'Total loss': 0.8482419699430466} | train loss {'Reaction outcome loss': 0.815808846777388, 'Total loss': 0.815808846777388}
2022-11-23 01:08:27,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:27,529 INFO:     Epoch: 39
2022-11-23 01:08:28,354 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8353926796804775, 'Total loss': 0.8353926796804775} | train loss {'Reaction outcome loss': 0.8076356467809754, 'Total loss': 0.8076356467809754}
2022-11-23 01:08:28,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:28,354 INFO:     Epoch: 40
2022-11-23 01:08:29,175 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8487746200778268, 'Total loss': 0.8487746200778268} | train loss {'Reaction outcome loss': 0.8088402317361794, 'Total loss': 0.8088402317361794}
2022-11-23 01:08:29,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:29,175 INFO:     Epoch: 41
2022-11-23 01:08:30,006 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.828111698681658, 'Total loss': 0.828111698681658} | train loss {'Reaction outcome loss': 0.8110199061482541, 'Total loss': 0.8110199061482541}
2022-11-23 01:08:30,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:30,007 INFO:     Epoch: 42
2022-11-23 01:08:30,778 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8403473841873083, 'Total loss': 0.8403473841873083} | train loss {'Reaction outcome loss': 0.8155627429244007, 'Total loss': 0.8155627429244007}
2022-11-23 01:08:30,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:30,778 INFO:     Epoch: 43
2022-11-23 01:08:31,592 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8338297957723791, 'Total loss': 0.8338297957723791} | train loss {'Reaction outcome loss': 0.8100172084594063, 'Total loss': 0.8100172084594063}
2022-11-23 01:08:31,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:31,594 INFO:     Epoch: 44
2022-11-23 01:08:32,434 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8228778168559074, 'Total loss': 0.8228778168559074} | train loss {'Reaction outcome loss': 0.8155639738689068, 'Total loss': 0.8155639738689068}
2022-11-23 01:08:32,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:32,434 INFO:     Epoch: 45
2022-11-23 01:08:33,264 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8101533034985716, 'Total loss': 0.8101533034985716} | train loss {'Reaction outcome loss': 0.8069813162435283, 'Total loss': 0.8069813162435283}
2022-11-23 01:08:33,264 INFO:     Found new best model at epoch 45
2022-11-23 01:08:33,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:33,265 INFO:     Epoch: 46
2022-11-23 01:08:34,077 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8229614794254303, 'Total loss': 0.8229614794254303} | train loss {'Reaction outcome loss': 0.8089352017230833, 'Total loss': 0.8089352017230833}
2022-11-23 01:08:34,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:34,078 INFO:     Epoch: 47
2022-11-23 01:08:34,907 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8886453116481955, 'Total loss': 0.8886453116481955} | train loss {'Reaction outcome loss': 0.8087191931631884, 'Total loss': 0.8087191931631884}
2022-11-23 01:08:34,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:34,907 INFO:     Epoch: 48
2022-11-23 01:08:35,703 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8250089355490424, 'Total loss': 0.8250089355490424} | train loss {'Reaction outcome loss': 0.81397904232446, 'Total loss': 0.81397904232446}
2022-11-23 01:08:35,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:35,704 INFO:     Epoch: 49
2022-11-23 01:08:36,531 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8326160257512872, 'Total loss': 0.8326160257512872} | train loss {'Reaction outcome loss': 0.8144263616698956, 'Total loss': 0.8144263616698956}
2022-11-23 01:08:36,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:36,531 INFO:     Epoch: 50
2022-11-23 01:08:37,381 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.828915761275725, 'Total loss': 0.828915761275725} | train loss {'Reaction outcome loss': 0.8138545696069355, 'Total loss': 0.8138545696069355}
2022-11-23 01:08:37,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:37,381 INFO:     Epoch: 51
2022-11-23 01:08:38,143 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8212500661611557, 'Total loss': 0.8212500661611557} | train loss {'Reaction outcome loss': 0.8108559326845625, 'Total loss': 0.8108559326845625}
2022-11-23 01:08:38,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:38,143 INFO:     Epoch: 52
2022-11-23 01:08:38,943 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8311623477123, 'Total loss': 0.8311623477123} | train loss {'Reaction outcome loss': 0.809225664206362, 'Total loss': 0.809225664206362}
2022-11-23 01:08:38,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:38,944 INFO:     Epoch: 53
2022-11-23 01:08:39,781 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8269836841659113, 'Total loss': 0.8269836841659113} | train loss {'Reaction outcome loss': 0.8192975693627408, 'Total loss': 0.8192975693627408}
2022-11-23 01:08:39,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:39,781 INFO:     Epoch: 54
2022-11-23 01:08:40,644 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8155779459259727, 'Total loss': 0.8155779459259727} | train loss {'Reaction outcome loss': 0.8172950024305567, 'Total loss': 0.8172950024305567}
2022-11-23 01:08:40,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:40,645 INFO:     Epoch: 55
2022-11-23 01:08:41,437 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8523756238547239, 'Total loss': 0.8523756238547239} | train loss {'Reaction outcome loss': 0.8084895318818961, 'Total loss': 0.8084895318818961}
2022-11-23 01:08:41,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:41,438 INFO:     Epoch: 56
2022-11-23 01:08:42,269 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8274303437633947, 'Total loss': 0.8274303437633947} | train loss {'Reaction outcome loss': 0.8105576999998285, 'Total loss': 0.8105576999998285}
2022-11-23 01:08:42,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:42,269 INFO:     Epoch: 57
2022-11-23 01:08:43,118 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8334738530895927, 'Total loss': 0.8334738530895927} | train loss {'Reaction outcome loss': 0.804877517978672, 'Total loss': 0.804877517978672}
2022-11-23 01:08:43,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:43,119 INFO:     Epoch: 58
2022-11-23 01:08:43,933 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.832771741531112, 'Total loss': 0.832771741531112} | train loss {'Reaction outcome loss': 0.806135618433296, 'Total loss': 0.806135618433296}
2022-11-23 01:08:43,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:43,934 INFO:     Epoch: 59
2022-11-23 01:08:44,758 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8237163966352289, 'Total loss': 0.8237163966352289} | train loss {'Reaction outcome loss': 0.8072059032646751, 'Total loss': 0.8072059032646751}
2022-11-23 01:08:44,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:44,758 INFO:     Epoch: 60
2022-11-23 01:08:45,622 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8219739158045162, 'Total loss': 0.8219739158045162} | train loss {'Reaction outcome loss': 0.8125918354341376, 'Total loss': 0.8125918354341376}
2022-11-23 01:08:45,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:45,622 INFO:     Epoch: 61
2022-11-23 01:08:46,439 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8333642956885424, 'Total loss': 0.8333642956885424} | train loss {'Reaction outcome loss': 0.8155698043856061, 'Total loss': 0.8155698043856061}
2022-11-23 01:08:46,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:46,440 INFO:     Epoch: 62
2022-11-23 01:08:47,342 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8625045581297441, 'Total loss': 0.8625045581297441} | train loss {'Reaction outcome loss': 0.8133157833143767, 'Total loss': 0.8133157833143767}
2022-11-23 01:08:47,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:47,342 INFO:     Epoch: 63
2022-11-23 01:08:48,260 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8192833946509794, 'Total loss': 0.8192833946509794} | train loss {'Reaction outcome loss': 0.8107562405377747, 'Total loss': 0.8107562405377747}
2022-11-23 01:08:48,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:48,260 INFO:     Epoch: 64
2022-11-23 01:08:49,147 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8509184596213427, 'Total loss': 0.8509184596213427} | train loss {'Reaction outcome loss': 0.8114898025024275, 'Total loss': 0.8114898025024275}
2022-11-23 01:08:49,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:49,148 INFO:     Epoch: 65
2022-11-23 01:08:50,017 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8412641503594138, 'Total loss': 0.8412641503594138} | train loss {'Reaction outcome loss': 0.8114105986680097, 'Total loss': 0.8114105986680097}
2022-11-23 01:08:50,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:50,017 INFO:     Epoch: 66
2022-11-23 01:08:50,831 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8350161388516426, 'Total loss': 0.8350161388516426} | train loss {'Reaction outcome loss': 0.8079411669781333, 'Total loss': 0.8079411669781333}
2022-11-23 01:08:50,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:50,832 INFO:     Epoch: 67
2022-11-23 01:08:51,684 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8191732472994111, 'Total loss': 0.8191732472994111} | train loss {'Reaction outcome loss': 0.8105994936546334, 'Total loss': 0.8105994936546334}
2022-11-23 01:08:51,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:51,685 INFO:     Epoch: 68
2022-11-23 01:08:52,500 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8220761255784468, 'Total loss': 0.8220761255784468} | train loss {'Reaction outcome loss': 0.8053135151865511, 'Total loss': 0.8053135151865511}
2022-11-23 01:08:52,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:52,501 INFO:     Epoch: 69
2022-11-23 01:08:53,310 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8300585502927954, 'Total loss': 0.8300585502927954} | train loss {'Reaction outcome loss': 0.8089229030165113, 'Total loss': 0.8089229030165113}
2022-11-23 01:08:53,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:53,311 INFO:     Epoch: 70
2022-11-23 01:08:54,139 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8204128024252978, 'Total loss': 0.8204128024252978} | train loss {'Reaction outcome loss': 0.8098782787197515, 'Total loss': 0.8098782787197515}
2022-11-23 01:08:54,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:54,139 INFO:     Epoch: 71
2022-11-23 01:08:54,948 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8216698257760569, 'Total loss': 0.8216698257760569} | train loss {'Reaction outcome loss': 0.810623490843575, 'Total loss': 0.810623490843575}
2022-11-23 01:08:54,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:54,948 INFO:     Epoch: 72
2022-11-23 01:08:55,827 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8200225532054901, 'Total loss': 0.8200225532054901} | train loss {'Reaction outcome loss': 0.815580536238095, 'Total loss': 0.815580536238095}
2022-11-23 01:08:55,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:55,829 INFO:     Epoch: 73
2022-11-23 01:08:56,624 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8412958844141527, 'Total loss': 0.8412958844141527} | train loss {'Reaction outcome loss': 0.8216822131683952, 'Total loss': 0.8216822131683952}
2022-11-23 01:08:56,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:56,625 INFO:     Epoch: 74
2022-11-23 01:08:57,464 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.829179816625335, 'Total loss': 0.829179816625335} | train loss {'Reaction outcome loss': 0.8091400767627516, 'Total loss': 0.8091400767627516}
2022-11-23 01:08:57,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:57,465 INFO:     Epoch: 75
2022-11-23 01:08:58,308 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8206727518276735, 'Total loss': 0.8206727518276735} | train loss {'Reaction outcome loss': 0.8113589338686785, 'Total loss': 0.8113589338686785}
2022-11-23 01:08:58,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:58,308 INFO:     Epoch: 76
2022-11-23 01:08:59,188 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8293982717123899, 'Total loss': 0.8293982717123899} | train loss {'Reaction outcome loss': 0.8171742486085004, 'Total loss': 0.8171742486085004}
2022-11-23 01:08:59,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:08:59,188 INFO:     Epoch: 77
2022-11-23 01:09:00,041 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8177219412543557, 'Total loss': 0.8177219412543557} | train loss {'Reaction outcome loss': 0.8098035434238341, 'Total loss': 0.8098035434238341}
2022-11-23 01:09:00,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:00,041 INFO:     Epoch: 78
2022-11-23 01:09:00,970 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8204374238848686, 'Total loss': 0.8204374238848686} | train loss {'Reaction outcome loss': 0.8090373078579844, 'Total loss': 0.8090373078579844}
2022-11-23 01:09:00,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:00,970 INFO:     Epoch: 79
2022-11-23 01:09:01,807 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8543775542215868, 'Total loss': 0.8543775542215868} | train loss {'Reaction outcome loss': 0.8101943801289145, 'Total loss': 0.8101943801289145}
2022-11-23 01:09:01,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:01,807 INFO:     Epoch: 80
2022-11-23 01:09:02,742 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8332457264715974, 'Total loss': 0.8332457264715974} | train loss {'Reaction outcome loss': 0.8056889443775179, 'Total loss': 0.8056889443775179}
2022-11-23 01:09:02,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:02,744 INFO:     Epoch: 81
2022-11-23 01:09:03,630 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8312927254221656, 'Total loss': 0.8312927254221656} | train loss {'Reaction outcome loss': 0.8104190160388406, 'Total loss': 0.8104190160388406}
2022-11-23 01:09:03,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:03,630 INFO:     Epoch: 82
2022-11-23 01:09:04,446 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8541441688483412, 'Total loss': 0.8541441688483412} | train loss {'Reaction outcome loss': 0.8118643923568339, 'Total loss': 0.8118643923568339}
2022-11-23 01:09:04,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:04,446 INFO:     Epoch: 83
2022-11-23 01:09:05,288 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8274749287150123, 'Total loss': 0.8274749287150123} | train loss {'Reaction outcome loss': 0.8156175004084584, 'Total loss': 0.8156175004084584}
2022-11-23 01:09:05,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:05,288 INFO:     Epoch: 84
2022-11-23 01:09:06,075 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.837768396193331, 'Total loss': 0.837768396193331} | train loss {'Reaction outcome loss': 0.8090258736299117, 'Total loss': 0.8090258736299117}
2022-11-23 01:09:06,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:06,075 INFO:     Epoch: 85
2022-11-23 01:09:06,900 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8527935513041236, 'Total loss': 0.8527935513041236} | train loss {'Reaction outcome loss': 0.8155962490601095, 'Total loss': 0.8155962490601095}
2022-11-23 01:09:06,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:06,900 INFO:     Epoch: 86
2022-11-23 01:09:07,740 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.830490923740647, 'Total loss': 0.830490923740647} | train loss {'Reaction outcome loss': 0.8115821562797917, 'Total loss': 0.8115821562797917}
2022-11-23 01:09:07,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:07,741 INFO:     Epoch: 87
2022-11-23 01:09:08,565 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8376861058852889, 'Total loss': 0.8376861058852889} | train loss {'Reaction outcome loss': 0.8081812117746484, 'Total loss': 0.8081812117746484}
2022-11-23 01:09:08,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:08,566 INFO:     Epoch: 88
2022-11-23 01:09:09,356 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.825934225185351, 'Total loss': 0.825934225185351} | train loss {'Reaction outcome loss': 0.8079951234192018, 'Total loss': 0.8079951234192018}
2022-11-23 01:09:09,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:09,356 INFO:     Epoch: 89
2022-11-23 01:09:10,140 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8417860858819701, 'Total loss': 0.8417860858819701} | train loss {'Reaction outcome loss': 0.8080291391957385, 'Total loss': 0.8080291391957385}
2022-11-23 01:09:10,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:10,140 INFO:     Epoch: 90
2022-11-23 01:09:10,976 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8171723694963888, 'Total loss': 0.8171723694963888} | train loss {'Reaction outcome loss': 0.8080794379597733, 'Total loss': 0.8080794379597733}
2022-11-23 01:09:10,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:10,977 INFO:     Epoch: 91
2022-11-23 01:09:11,824 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8327698003162037, 'Total loss': 0.8327698003162037} | train loss {'Reaction outcome loss': 0.8111917961705551, 'Total loss': 0.8111917961705551}
2022-11-23 01:09:11,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:11,824 INFO:     Epoch: 92
2022-11-23 01:09:12,744 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8193609870292924, 'Total loss': 0.8193609870292924} | train loss {'Reaction outcome loss': 0.8084994372327318, 'Total loss': 0.8084994372327318}
2022-11-23 01:09:12,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:12,745 INFO:     Epoch: 93
2022-11-23 01:09:13,586 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8231434930454601, 'Total loss': 0.8231434930454601} | train loss {'Reaction outcome loss': 0.8124293181818989, 'Total loss': 0.8124293181818989}
2022-11-23 01:09:13,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:13,586 INFO:     Epoch: 94
2022-11-23 01:09:14,455 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8501942211931403, 'Total loss': 0.8501942211931403} | train loss {'Reaction outcome loss': 0.8128052439525543, 'Total loss': 0.8128052439525543}
2022-11-23 01:09:14,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:14,455 INFO:     Epoch: 95
2022-11-23 01:09:15,307 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8341794068163092, 'Total loss': 0.8341794068163092} | train loss {'Reaction outcome loss': 0.8047313094591564, 'Total loss': 0.8047313094591564}
2022-11-23 01:09:15,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:15,308 INFO:     Epoch: 96
2022-11-23 01:09:16,180 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8633395731449127, 'Total loss': 0.8633395731449127} | train loss {'Reaction outcome loss': 0.8058919759414457, 'Total loss': 0.8058919759414457}
2022-11-23 01:09:16,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:16,180 INFO:     Epoch: 97
2022-11-23 01:09:17,093 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8287203156135299, 'Total loss': 0.8287203156135299} | train loss {'Reaction outcome loss': 0.8091228236312326, 'Total loss': 0.8091228236312326}
2022-11-23 01:09:17,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:17,093 INFO:     Epoch: 98
2022-11-23 01:09:17,942 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8606140898032622, 'Total loss': 0.8606140898032622} | train loss {'Reaction outcome loss': 0.8107332221650885, 'Total loss': 0.8107332221650885}
2022-11-23 01:09:17,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:17,942 INFO:     Epoch: 99
2022-11-23 01:09:18,785 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8286032771522348, 'Total loss': 0.8286032771522348} | train loss {'Reaction outcome loss': 0.8078909259183928, 'Total loss': 0.8078909259183928}
2022-11-23 01:09:18,785 INFO:     Best model found after epoch 46 of 100.
2022-11-23 01:09:18,785 INFO:   Done with stage: TRAINING
2022-11-23 01:09:18,785 INFO:   Starting stage: EVALUATION
2022-11-23 01:09:18,915 INFO:   Done with stage: EVALUATION
2022-11-23 01:09:18,916 INFO:   Leaving out SEQ value Fold_6
2022-11-23 01:09:18,929 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 01:09:18,929 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:09:19,613 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:09:19,613 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:09:19,688 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:09:19,688 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:09:19,688 INFO:     No hyperparam tuning for this model
2022-11-23 01:09:19,688 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:09:19,688 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:09:19,689 INFO:     None feature selector for col prot
2022-11-23 01:09:19,689 INFO:     None feature selector for col prot
2022-11-23 01:09:19,689 INFO:     None feature selector for col prot
2022-11-23 01:09:19,690 INFO:     None feature selector for col chem
2022-11-23 01:09:19,690 INFO:     None feature selector for col chem
2022-11-23 01:09:19,690 INFO:     None feature selector for col chem
2022-11-23 01:09:19,690 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:09:19,690 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:09:19,692 INFO:     Number of params in model 168571
2022-11-23 01:09:19,695 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:09:19,696 INFO:   Starting stage: TRAINING
2022-11-23 01:09:19,754 INFO:     Val loss before train {'Reaction outcome loss': 0.9880882162939418, 'Total loss': 0.9880882162939418}
2022-11-23 01:09:19,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:19,755 INFO:     Epoch: 0
2022-11-23 01:09:20,654 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8475623381408778, 'Total loss': 0.8475623381408778} | train loss {'Reaction outcome loss': 0.8765502025283152, 'Total loss': 0.8765502025283152}
2022-11-23 01:09:20,655 INFO:     Found new best model at epoch 0
2022-11-23 01:09:20,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:20,656 INFO:     Epoch: 1
2022-11-23 01:09:21,512 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8701095418496565, 'Total loss': 0.8701095418496565} | train loss {'Reaction outcome loss': 0.8433819399966348, 'Total loss': 0.8433819399966348}
2022-11-23 01:09:21,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:21,512 INFO:     Epoch: 2
2022-11-23 01:09:22,388 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8434308516708288, 'Total loss': 0.8434308516708288} | train loss {'Reaction outcome loss': 0.8396117246199039, 'Total loss': 0.8396117246199039}
2022-11-23 01:09:22,389 INFO:     Found new best model at epoch 2
2022-11-23 01:09:22,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:22,390 INFO:     Epoch: 3
2022-11-23 01:09:23,232 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8396338908509775, 'Total loss': 0.8396338908509775} | train loss {'Reaction outcome loss': 0.8338589217033117, 'Total loss': 0.8338589217033117}
2022-11-23 01:09:23,232 INFO:     Found new best model at epoch 3
2022-11-23 01:09:23,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:23,233 INFO:     Epoch: 4
2022-11-23 01:09:24,080 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8098062473264608, 'Total loss': 0.8098062473264608} | train loss {'Reaction outcome loss': 0.8340881383947788, 'Total loss': 0.8340881383947788}
2022-11-23 01:09:24,088 INFO:     Found new best model at epoch 4
2022-11-23 01:09:24,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:24,089 INFO:     Epoch: 5
2022-11-23 01:09:24,974 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8205855827439915, 'Total loss': 0.8205855827439915} | train loss {'Reaction outcome loss': 0.8309393271563514, 'Total loss': 0.8309393271563514}
2022-11-23 01:09:24,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:24,974 INFO:     Epoch: 6
2022-11-23 01:09:25,791 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8412908532402732, 'Total loss': 0.8412908532402732} | train loss {'Reaction outcome loss': 0.8278168176691378, 'Total loss': 0.8278168176691378}
2022-11-23 01:09:25,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:25,791 INFO:     Epoch: 7
2022-11-23 01:09:26,655 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8103288452733647, 'Total loss': 0.8103288452733647} | train loss {'Reaction outcome loss': 0.8241138679365958, 'Total loss': 0.8241138679365958}
2022-11-23 01:09:26,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:26,655 INFO:     Epoch: 8
2022-11-23 01:09:27,497 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8278039422902194, 'Total loss': 0.8278039422902194} | train loss {'Reaction outcome loss': 0.8292739820336142, 'Total loss': 0.8292739820336142}
2022-11-23 01:09:27,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:27,498 INFO:     Epoch: 9
2022-11-23 01:09:28,369 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8478257683190432, 'Total loss': 0.8478257683190432} | train loss {'Reaction outcome loss': 0.8225731568471077, 'Total loss': 0.8225731568471077}
2022-11-23 01:09:28,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:28,369 INFO:     Epoch: 10
2022-11-23 01:09:29,239 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.827724701301618, 'Total loss': 0.827724701301618} | train loss {'Reaction outcome loss': 0.824447178432057, 'Total loss': 0.824447178432057}
2022-11-23 01:09:29,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:29,239 INFO:     Epoch: 11
2022-11-23 01:09:30,113 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8307072452523492, 'Total loss': 0.8307072452523492} | train loss {'Reaction outcome loss': 0.8233832126903918, 'Total loss': 0.8233832126903918}
2022-11-23 01:09:30,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:30,114 INFO:     Epoch: 12
2022-11-23 01:09:30,979 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8249989226460457, 'Total loss': 0.8249989226460457} | train loss {'Reaction outcome loss': 0.8225829077343787, 'Total loss': 0.8225829077343787}
2022-11-23 01:09:30,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:30,979 INFO:     Epoch: 13
2022-11-23 01:09:31,833 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8109035444530573, 'Total loss': 0.8109035444530573} | train loss {'Reaction outcome loss': 0.8229020217493657, 'Total loss': 0.8229020217493657}
2022-11-23 01:09:31,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:31,833 INFO:     Epoch: 14
2022-11-23 01:09:32,677 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8097633909095417, 'Total loss': 0.8097633909095417} | train loss {'Reaction outcome loss': 0.8226628090825773, 'Total loss': 0.8226628090825773}
2022-11-23 01:09:32,677 INFO:     Found new best model at epoch 14
2022-11-23 01:09:32,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:32,678 INFO:     Epoch: 15
2022-11-23 01:09:33,499 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8347231054847891, 'Total loss': 0.8347231054847891} | train loss {'Reaction outcome loss': 0.8236043793299506, 'Total loss': 0.8236043793299506}
2022-11-23 01:09:33,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:33,500 INFO:     Epoch: 16
2022-11-23 01:09:34,343 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.81411051614718, 'Total loss': 0.81411051614718} | train loss {'Reaction outcome loss': 0.8156960016537097, 'Total loss': 0.8156960016537097}
2022-11-23 01:09:34,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:34,344 INFO:     Epoch: 17
2022-11-23 01:09:35,183 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8268629854375665, 'Total loss': 0.8268629854375665} | train loss {'Reaction outcome loss': 0.8183962560949787, 'Total loss': 0.8183962560949787}
2022-11-23 01:09:35,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:35,183 INFO:     Epoch: 18
2022-11-23 01:09:36,041 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7944565571167252, 'Total loss': 0.7944565571167252} | train loss {'Reaction outcome loss': 0.8208237983767064, 'Total loss': 0.8208237983767064}
2022-11-23 01:09:36,041 INFO:     Found new best model at epoch 18
2022-11-23 01:09:36,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:36,042 INFO:     Epoch: 19
2022-11-23 01:09:36,901 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8288345844908194, 'Total loss': 0.8288345844908194} | train loss {'Reaction outcome loss': 0.8149339720126121, 'Total loss': 0.8149339720126121}
2022-11-23 01:09:36,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:36,901 INFO:     Epoch: 20
2022-11-23 01:09:37,738 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8229395279830153, 'Total loss': 0.8229395279830153} | train loss {'Reaction outcome loss': 0.819929109946374, 'Total loss': 0.819929109946374}
2022-11-23 01:09:37,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:37,738 INFO:     Epoch: 21
2022-11-23 01:09:38,553 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8342918408187953, 'Total loss': 0.8342918408187953} | train loss {'Reaction outcome loss': 0.8208131191711272, 'Total loss': 0.8208131191711272}
2022-11-23 01:09:38,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:38,554 INFO:     Epoch: 22
2022-11-23 01:09:39,421 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8260536397045309, 'Total loss': 0.8260536397045309} | train loss {'Reaction outcome loss': 0.8166361513637728, 'Total loss': 0.8166361513637728}
2022-11-23 01:09:39,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:39,421 INFO:     Epoch: 23
2022-11-23 01:09:40,233 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7994349070570685, 'Total loss': 0.7994349070570685} | train loss {'Reaction outcome loss': 0.8199972130598561, 'Total loss': 0.8199972130598561}
2022-11-23 01:09:40,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:40,233 INFO:     Epoch: 24
2022-11-23 01:09:41,130 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8095237104730173, 'Total loss': 0.8095237104730173} | train loss {'Reaction outcome loss': 0.8165451296635212, 'Total loss': 0.8165451296635212}
2022-11-23 01:09:41,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:41,131 INFO:     Epoch: 25
2022-11-23 01:09:41,941 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8237365795807405, 'Total loss': 0.8237365795807405} | train loss {'Reaction outcome loss': 0.8122607912988432, 'Total loss': 0.8122607912988432}
2022-11-23 01:09:41,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:41,942 INFO:     Epoch: 26
2022-11-23 01:09:42,816 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8041325597600504, 'Total loss': 0.8041325597600504} | train loss {'Reaction outcome loss': 0.8234938795287763, 'Total loss': 0.8234938795287763}
2022-11-23 01:09:42,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:42,816 INFO:     Epoch: 27
2022-11-23 01:09:43,660 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8308195959437977, 'Total loss': 0.8308195959437977} | train loss {'Reaction outcome loss': 0.8169292955388946, 'Total loss': 0.8169292955388946}
2022-11-23 01:09:43,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:43,661 INFO:     Epoch: 28
2022-11-23 01:09:44,535 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8329290002584457, 'Total loss': 0.8329290002584457} | train loss {'Reaction outcome loss': 0.8186146332131278, 'Total loss': 0.8186146332131278}
2022-11-23 01:09:44,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:44,535 INFO:     Epoch: 29
2022-11-23 01:09:45,390 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8113025806166909, 'Total loss': 0.8113025806166909} | train loss {'Reaction outcome loss': 0.8200751344763464, 'Total loss': 0.8200751344763464}
2022-11-23 01:09:45,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:45,390 INFO:     Epoch: 30
2022-11-23 01:09:46,272 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8114547004753893, 'Total loss': 0.8114547004753893} | train loss {'Reaction outcome loss': 0.818443137070825, 'Total loss': 0.818443137070825}
2022-11-23 01:09:46,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:46,273 INFO:     Epoch: 31
2022-11-23 01:09:47,157 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8218432170423594, 'Total loss': 0.8218432170423594} | train loss {'Reaction outcome loss': 0.8197663143998192, 'Total loss': 0.8197663143998192}
2022-11-23 01:09:47,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:47,157 INFO:     Epoch: 32
2022-11-23 01:09:48,015 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8303925408558412, 'Total loss': 0.8303925408558412} | train loss {'Reaction outcome loss': 0.8190954581143395, 'Total loss': 0.8190954581143395}
2022-11-23 01:09:48,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:48,016 INFO:     Epoch: 33
2022-11-23 01:09:48,841 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8205405839464881, 'Total loss': 0.8205405839464881} | train loss {'Reaction outcome loss': 0.8198962359418792, 'Total loss': 0.8198962359418792}
2022-11-23 01:09:48,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:48,841 INFO:     Epoch: 34
2022-11-23 01:09:49,669 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8298753080042925, 'Total loss': 0.8298753080042925} | train loss {'Reaction outcome loss': 0.8204806168233195, 'Total loss': 0.8204806168233195}
2022-11-23 01:09:49,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:49,669 INFO:     Epoch: 35
2022-11-23 01:09:50,509 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8637573813850229, 'Total loss': 0.8637573813850229} | train loss {'Reaction outcome loss': 0.8147589511448338, 'Total loss': 0.8147589511448338}
2022-11-23 01:09:50,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:50,509 INFO:     Epoch: 36
2022-11-23 01:09:51,306 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8146635754541918, 'Total loss': 0.8146635754541918} | train loss {'Reaction outcome loss': 0.8139005653079479, 'Total loss': 0.8139005653079479}
2022-11-23 01:09:51,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:51,307 INFO:     Epoch: 37
2022-11-23 01:09:52,109 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8127110146663405, 'Total loss': 0.8127110146663405} | train loss {'Reaction outcome loss': 0.8162015682506946, 'Total loss': 0.8162015682506946}
2022-11-23 01:09:52,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:52,110 INFO:     Epoch: 38
2022-11-23 01:09:52,933 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8200638910586183, 'Total loss': 0.8200638910586183} | train loss {'Reaction outcome loss': 0.8189764196473744, 'Total loss': 0.8189764196473744}
2022-11-23 01:09:52,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:52,934 INFO:     Epoch: 39
2022-11-23 01:09:53,791 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8259103501384909, 'Total loss': 0.8259103501384909} | train loss {'Reaction outcome loss': 0.8109013504318653, 'Total loss': 0.8109013504318653}
2022-11-23 01:09:53,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:53,791 INFO:     Epoch: 40
2022-11-23 01:09:54,610 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8225659050724723, 'Total loss': 0.8225659050724723} | train loss {'Reaction outcome loss': 0.8158228946549277, 'Total loss': 0.8158228946549277}
2022-11-23 01:09:54,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:54,611 INFO:     Epoch: 41
2022-11-23 01:09:55,431 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.821544080295346, 'Total loss': 0.821544080295346} | train loss {'Reaction outcome loss': 0.8145726362784063, 'Total loss': 0.8145726362784063}
2022-11-23 01:09:55,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:55,431 INFO:     Epoch: 42
2022-11-23 01:09:56,291 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8299906091256575, 'Total loss': 0.8299906091256575} | train loss {'Reaction outcome loss': 0.8194521213731458, 'Total loss': 0.8194521213731458}
2022-11-23 01:09:56,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:56,292 INFO:     Epoch: 43
2022-11-23 01:09:57,115 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8190577693960883, 'Total loss': 0.8190577693960883} | train loss {'Reaction outcome loss': 0.8157885885767399, 'Total loss': 0.8157885885767399}
2022-11-23 01:09:57,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:57,115 INFO:     Epoch: 44
2022-11-23 01:09:57,951 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.812418981031938, 'Total loss': 0.812418981031938} | train loss {'Reaction outcome loss': 0.8163397266499458, 'Total loss': 0.8163397266499458}
2022-11-23 01:09:57,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:57,953 INFO:     Epoch: 45
2022-11-23 01:09:58,782 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8331261331384833, 'Total loss': 0.8331261331384833} | train loss {'Reaction outcome loss': 0.8217908599443974, 'Total loss': 0.8217908599443974}
2022-11-23 01:09:58,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:58,782 INFO:     Epoch: 46
2022-11-23 01:09:59,648 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8344950039278377, 'Total loss': 0.8344950039278377} | train loss {'Reaction outcome loss': 0.8189611330388054, 'Total loss': 0.8189611330388054}
2022-11-23 01:09:59,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:09:59,649 INFO:     Epoch: 47
2022-11-23 01:10:00,461 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.798459222370928, 'Total loss': 0.798459222370928} | train loss {'Reaction outcome loss': 0.8169416670477198, 'Total loss': 0.8169416670477198}
2022-11-23 01:10:00,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:00,461 INFO:     Epoch: 48
2022-11-23 01:10:01,301 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8142122240229086, 'Total loss': 0.8142122240229086} | train loss {'Reaction outcome loss': 0.8178927564332562, 'Total loss': 0.8178927564332562}
2022-11-23 01:10:01,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:01,302 INFO:     Epoch: 49
2022-11-23 01:10:02,110 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8227079652927138, 'Total loss': 0.8227079652927138} | train loss {'Reaction outcome loss': 0.8182792849838734, 'Total loss': 0.8182792849838734}
2022-11-23 01:10:02,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:02,110 INFO:     Epoch: 50
2022-11-23 01:10:02,893 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8273853632536802, 'Total loss': 0.8273853632536802} | train loss {'Reaction outcome loss': 0.8184501708995912, 'Total loss': 0.8184501708995912}
2022-11-23 01:10:02,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:02,893 INFO:     Epoch: 51
2022-11-23 01:10:03,710 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8369398807937448, 'Total loss': 0.8369398807937448} | train loss {'Reaction outcome loss': 0.818644352858105, 'Total loss': 0.818644352858105}
2022-11-23 01:10:03,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:03,711 INFO:     Epoch: 52
2022-11-23 01:10:04,539 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8202055259184404, 'Total loss': 0.8202055259184404} | train loss {'Reaction outcome loss': 0.8210495719986577, 'Total loss': 0.8210495719986577}
2022-11-23 01:10:04,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:04,540 INFO:     Epoch: 53
2022-11-23 01:10:05,327 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8151852894913066, 'Total loss': 0.8151852894913066} | train loss {'Reaction outcome loss': 0.8153788929264392, 'Total loss': 0.8153788929264392}
2022-11-23 01:10:05,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:05,328 INFO:     Epoch: 54
2022-11-23 01:10:06,151 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8062220269983466, 'Total loss': 0.8062220269983466} | train loss {'Reaction outcome loss': 0.8199334749050678, 'Total loss': 0.8199334749050678}
2022-11-23 01:10:06,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:06,152 INFO:     Epoch: 55
2022-11-23 01:10:06,922 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8186854652383111, 'Total loss': 0.8186854652383111} | train loss {'Reaction outcome loss': 0.8145332046814503, 'Total loss': 0.8145332046814503}
2022-11-23 01:10:06,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:06,922 INFO:     Epoch: 56
2022-11-23 01:10:07,719 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8001814382997426, 'Total loss': 0.8001814382997426} | train loss {'Reaction outcome loss': 0.8190861522190033, 'Total loss': 0.8190861522190033}
2022-11-23 01:10:07,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:07,720 INFO:     Epoch: 57
2022-11-23 01:10:08,544 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8114565082571723, 'Total loss': 0.8114565082571723} | train loss {'Reaction outcome loss': 0.8195100487960923, 'Total loss': 0.8195100487960923}
2022-11-23 01:10:08,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:08,544 INFO:     Epoch: 58
2022-11-23 01:10:09,375 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8078537420793013, 'Total loss': 0.8078537420793013} | train loss {'Reaction outcome loss': 0.8173162152449931, 'Total loss': 0.8173162152449931}
2022-11-23 01:10:09,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:09,375 INFO:     Epoch: 59
2022-11-23 01:10:10,150 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8031001036817377, 'Total loss': 0.8031001036817377} | train loss {'Reaction outcome loss': 0.8181856322673059, 'Total loss': 0.8181856322673059}
2022-11-23 01:10:10,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:10,150 INFO:     Epoch: 60
2022-11-23 01:10:10,921 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8098890307274732, 'Total loss': 0.8098890307274732} | train loss {'Reaction outcome loss': 0.815036716480409, 'Total loss': 0.815036716480409}
2022-11-23 01:10:10,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:10,922 INFO:     Epoch: 61
2022-11-23 01:10:11,773 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8237855922092091, 'Total loss': 0.8237855922092091} | train loss {'Reaction outcome loss': 0.8186921432854668, 'Total loss': 0.8186921432854668}
2022-11-23 01:10:11,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:11,774 INFO:     Epoch: 62
2022-11-23 01:10:12,600 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8109806396744468, 'Total loss': 0.8109806396744468} | train loss {'Reaction outcome loss': 0.8181936106374187, 'Total loss': 0.8181936106374187}
2022-11-23 01:10:12,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:12,601 INFO:     Epoch: 63
2022-11-23 01:10:13,399 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8158933838660066, 'Total loss': 0.8158933838660066} | train loss {'Reaction outcome loss': 0.8153564005849823, 'Total loss': 0.8153564005849823}
2022-11-23 01:10:13,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:13,399 INFO:     Epoch: 64
2022-11-23 01:10:14,254 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7994576828046278, 'Total loss': 0.7994576828046278} | train loss {'Reaction outcome loss': 0.8196533649198471, 'Total loss': 0.8196533649198471}
2022-11-23 01:10:14,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:14,254 INFO:     Epoch: 65
2022-11-23 01:10:15,060 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8192280138080771, 'Total loss': 0.8192280138080771} | train loss {'Reaction outcome loss': 0.8167597566160464, 'Total loss': 0.8167597566160464}
2022-11-23 01:10:15,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:15,060 INFO:     Epoch: 66
2022-11-23 01:10:15,897 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.819043555720286, 'Total loss': 0.819043555720286} | train loss {'Reaction outcome loss': 0.8178654334718182, 'Total loss': 0.8178654334718182}
2022-11-23 01:10:15,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:15,897 INFO:     Epoch: 67
2022-11-23 01:10:16,737 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8202591389417648, 'Total loss': 0.8202591389417648} | train loss {'Reaction outcome loss': 0.8219040053025368, 'Total loss': 0.8219040053025368}
2022-11-23 01:10:16,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:16,738 INFO:     Epoch: 68
2022-11-23 01:10:17,579 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.808710862967101, 'Total loss': 0.808710862967101} | train loss {'Reaction outcome loss': 0.8141555858235205, 'Total loss': 0.8141555858235205}
2022-11-23 01:10:17,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:17,579 INFO:     Epoch: 69
2022-11-23 01:10:18,355 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8128833662379872, 'Total loss': 0.8128833662379872} | train loss {'Reaction outcome loss': 0.8206001798952779, 'Total loss': 0.8206001798952779}
2022-11-23 01:10:18,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:18,356 INFO:     Epoch: 70
2022-11-23 01:10:19,196 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8102180009538477, 'Total loss': 0.8102180009538477} | train loss {'Reaction outcome loss': 0.8151739407931605, 'Total loss': 0.8151739407931605}
2022-11-23 01:10:19,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:19,197 INFO:     Epoch: 71
2022-11-23 01:10:20,028 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.806884378194809, 'Total loss': 0.806884378194809} | train loss {'Reaction outcome loss': 0.8162466835591101, 'Total loss': 0.8162466835591101}
2022-11-23 01:10:20,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:20,029 INFO:     Epoch: 72
2022-11-23 01:10:20,864 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8013406897133047, 'Total loss': 0.8013406897133047} | train loss {'Reaction outcome loss': 0.8153779944104533, 'Total loss': 0.8153779944104533}
2022-11-23 01:10:20,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:20,864 INFO:     Epoch: 73
2022-11-23 01:10:21,636 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8141625659032301, 'Total loss': 0.8141625659032301} | train loss {'Reaction outcome loss': 0.8133140599295017, 'Total loss': 0.8133140599295017}
2022-11-23 01:10:21,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:21,636 INFO:     Epoch: 74
2022-11-23 01:10:22,412 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8038586262952198, 'Total loss': 0.8038586262952198} | train loss {'Reaction outcome loss': 0.8138065404228626, 'Total loss': 0.8138065404228626}
2022-11-23 01:10:22,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:22,412 INFO:     Epoch: 75
2022-11-23 01:10:23,236 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8167724866758693, 'Total loss': 0.8167724866758693} | train loss {'Reaction outcome loss': 0.8161443595684343, 'Total loss': 0.8161443595684343}
2022-11-23 01:10:23,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:23,236 INFO:     Epoch: 76
2022-11-23 01:10:24,022 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8134872398593209, 'Total loss': 0.8134872398593209} | train loss {'Reaction outcome loss': 0.8175997553813842, 'Total loss': 0.8175997553813842}
2022-11-23 01:10:24,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:24,022 INFO:     Epoch: 77
2022-11-23 01:10:24,845 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8095430284738541, 'Total loss': 0.8095430284738541} | train loss {'Reaction outcome loss': 0.8159415839660552, 'Total loss': 0.8159415839660552}
2022-11-23 01:10:24,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:24,845 INFO:     Epoch: 78
2022-11-23 01:10:25,632 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8141629865223711, 'Total loss': 0.8141629865223711} | train loss {'Reaction outcome loss': 0.8158647529780865, 'Total loss': 0.8158647529780865}
2022-11-23 01:10:25,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:25,632 INFO:     Epoch: 79
2022-11-23 01:10:26,420 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8110588477416472, 'Total loss': 0.8110588477416472} | train loss {'Reaction outcome loss': 0.8148798324888752, 'Total loss': 0.8148798324888752}
2022-11-23 01:10:26,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:26,420 INFO:     Epoch: 80
2022-11-23 01:10:27,224 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8093411150303754, 'Total loss': 0.8093411150303754} | train loss {'Reaction outcome loss': 0.8218710427322695, 'Total loss': 0.8218710427322695}
2022-11-23 01:10:27,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:27,224 INFO:     Epoch: 81
2022-11-23 01:10:28,054 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8167462017048489, 'Total loss': 0.8167462017048489} | train loss {'Reaction outcome loss': 0.8134230571168084, 'Total loss': 0.8134230571168084}
2022-11-23 01:10:28,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:28,054 INFO:     Epoch: 82
2022-11-23 01:10:28,836 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8113207342949781, 'Total loss': 0.8113207342949781} | train loss {'Reaction outcome loss': 0.8151428606962005, 'Total loss': 0.8151428606962005}
2022-11-23 01:10:28,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:28,836 INFO:     Epoch: 83
2022-11-23 01:10:29,639 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8091702962463553, 'Total loss': 0.8091702962463553} | train loss {'Reaction outcome loss': 0.8150506054441775, 'Total loss': 0.8150506054441775}
2022-11-23 01:10:29,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:29,640 INFO:     Epoch: 84
2022-11-23 01:10:30,474 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8201770199970766, 'Total loss': 0.8201770199970766} | train loss {'Reaction outcome loss': 0.8229380439846746, 'Total loss': 0.8229380439846746}
2022-11-23 01:10:30,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:30,474 INFO:     Epoch: 85
2022-11-23 01:10:31,308 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.837417640469291, 'Total loss': 0.837417640469291} | train loss {'Reaction outcome loss': 0.8148111839207911, 'Total loss': 0.8148111839207911}
2022-11-23 01:10:31,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:31,308 INFO:     Epoch: 86
2022-11-23 01:10:32,104 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8309237801215865, 'Total loss': 0.8309237801215865} | train loss {'Reaction outcome loss': 0.8161619559170739, 'Total loss': 0.8161619559170739}
2022-11-23 01:10:32,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:32,104 INFO:     Epoch: 87
2022-11-23 01:10:32,903 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8154309168457985, 'Total loss': 0.8154309168457985} | train loss {'Reaction outcome loss': 0.8089245077102415, 'Total loss': 0.8089245077102415}
2022-11-23 01:10:32,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:32,903 INFO:     Epoch: 88
2022-11-23 01:10:33,725 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8183129355311394, 'Total loss': 0.8183129355311394} | train loss {'Reaction outcome loss': 0.8128338446540218, 'Total loss': 0.8128338446540218}
2022-11-23 01:10:33,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:33,725 INFO:     Epoch: 89
2022-11-23 01:10:34,596 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.811171487651088, 'Total loss': 0.811171487651088} | train loss {'Reaction outcome loss': 0.8113902193163672, 'Total loss': 0.8113902193163672}
2022-11-23 01:10:34,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:34,597 INFO:     Epoch: 90
2022-11-23 01:10:35,407 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8056757985190912, 'Total loss': 0.8056757985190912} | train loss {'Reaction outcome loss': 0.8155330015767005, 'Total loss': 0.8155330015767005}
2022-11-23 01:10:35,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:35,407 INFO:     Epoch: 91
2022-11-23 01:10:36,193 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8096314953132109, 'Total loss': 0.8096314953132109} | train loss {'Reaction outcome loss': 0.8161873240624705, 'Total loss': 0.8161873240624705}
2022-11-23 01:10:36,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:36,194 INFO:     Epoch: 92
2022-11-23 01:10:36,977 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8188567649234425, 'Total loss': 0.8188567649234425} | train loss {'Reaction outcome loss': 0.8123948636554903, 'Total loss': 0.8123948636554903}
2022-11-23 01:10:36,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:36,978 INFO:     Epoch: 93
2022-11-23 01:10:37,780 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8149370761080221, 'Total loss': 0.8149370761080221} | train loss {'Reaction outcome loss': 0.8110315317828809, 'Total loss': 0.8110315317828809}
2022-11-23 01:10:37,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:37,780 INFO:     Epoch: 94
2022-11-23 01:10:38,589 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8077455433932218, 'Total loss': 0.8077455433932218} | train loss {'Reaction outcome loss': 0.8136331221509364, 'Total loss': 0.8136331221509364}
2022-11-23 01:10:38,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:38,589 INFO:     Epoch: 95
2022-11-23 01:10:39,382 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8042540245435454, 'Total loss': 0.8042540245435454} | train loss {'Reaction outcome loss': 0.8113351562811483, 'Total loss': 0.8113351562811483}
2022-11-23 01:10:39,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:39,383 INFO:     Epoch: 96
2022-11-23 01:10:40,201 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8411001116037369, 'Total loss': 0.8411001116037369} | train loss {'Reaction outcome loss': 0.8160848351976564, 'Total loss': 0.8160848351976564}
2022-11-23 01:10:40,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:40,201 INFO:     Epoch: 97
2022-11-23 01:10:40,977 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8308616429567337, 'Total loss': 0.8308616429567337} | train loss {'Reaction outcome loss': 0.817543298246399, 'Total loss': 0.817543298246399}
2022-11-23 01:10:40,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:40,977 INFO:     Epoch: 98
2022-11-23 01:10:41,819 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8294856439937245, 'Total loss': 0.8294856439937245} | train loss {'Reaction outcome loss': 0.8151121806473501, 'Total loss': 0.8151121806473501}
2022-11-23 01:10:41,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:41,819 INFO:     Epoch: 99
2022-11-23 01:10:42,646 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8130944262851368, 'Total loss': 0.8130944262851368} | train loss {'Reaction outcome loss': 0.8143829811484583, 'Total loss': 0.8143829811484583}
2022-11-23 01:10:42,646 INFO:     Best model found after epoch 19 of 100.
2022-11-23 01:10:42,646 INFO:   Done with stage: TRAINING
2022-11-23 01:10:42,646 INFO:   Starting stage: EVALUATION
2022-11-23 01:10:42,766 INFO:   Done with stage: EVALUATION
2022-11-23 01:10:42,766 INFO:   Leaving out SEQ value Fold_7
2022-11-23 01:10:42,779 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 01:10:42,780 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:10:43,443 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:10:43,443 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:10:43,514 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:10:43,514 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:10:43,514 INFO:     No hyperparam tuning for this model
2022-11-23 01:10:43,514 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:10:43,514 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:10:43,515 INFO:     None feature selector for col prot
2022-11-23 01:10:43,515 INFO:     None feature selector for col prot
2022-11-23 01:10:43,515 INFO:     None feature selector for col prot
2022-11-23 01:10:43,516 INFO:     None feature selector for col chem
2022-11-23 01:10:43,516 INFO:     None feature selector for col chem
2022-11-23 01:10:43,516 INFO:     None feature selector for col chem
2022-11-23 01:10:43,516 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:10:43,516 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:10:43,517 INFO:     Number of params in model 168571
2022-11-23 01:10:43,521 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:10:43,521 INFO:   Starting stage: TRAINING
2022-11-23 01:10:43,579 INFO:     Val loss before train {'Reaction outcome loss': 1.0463224297220057, 'Total loss': 1.0463224297220057}
2022-11-23 01:10:43,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:43,579 INFO:     Epoch: 0
2022-11-23 01:10:44,413 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8446788002144207, 'Total loss': 0.8446788002144207} | train loss {'Reaction outcome loss': 0.8689222388690517, 'Total loss': 0.8689222388690517}
2022-11-23 01:10:44,413 INFO:     Found new best model at epoch 0
2022-11-23 01:10:44,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:44,414 INFO:     Epoch: 1
2022-11-23 01:10:45,255 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8737880126996473, 'Total loss': 0.8737880126996473} | train loss {'Reaction outcome loss': 0.8445858872465549, 'Total loss': 0.8445858872465549}
2022-11-23 01:10:45,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:45,256 INFO:     Epoch: 2
2022-11-23 01:10:46,042 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8473267846486785, 'Total loss': 0.8473267846486785} | train loss {'Reaction outcome loss': 0.832642930109174, 'Total loss': 0.832642930109174}
2022-11-23 01:10:46,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:46,042 INFO:     Epoch: 3
2022-11-23 01:10:46,817 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8375151313164018, 'Total loss': 0.8375151313164018} | train loss {'Reaction outcome loss': 0.8288675468535193, 'Total loss': 0.8288675468535193}
2022-11-23 01:10:46,817 INFO:     Found new best model at epoch 3
2022-11-23 01:10:46,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:46,818 INFO:     Epoch: 4
2022-11-23 01:10:47,582 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8292632685466246, 'Total loss': 0.8292632685466246} | train loss {'Reaction outcome loss': 0.8177693539088772, 'Total loss': 0.8177693539088772}
2022-11-23 01:10:47,582 INFO:     Found new best model at epoch 4
2022-11-23 01:10:47,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:47,583 INFO:     Epoch: 5
2022-11-23 01:10:48,457 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8222159269181165, 'Total loss': 0.8222159269181165} | train loss {'Reaction outcome loss': 0.8169502341939557, 'Total loss': 0.8169502341939557}
2022-11-23 01:10:48,458 INFO:     Found new best model at epoch 5
2022-11-23 01:10:48,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:48,459 INFO:     Epoch: 6
2022-11-23 01:10:49,258 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8399825380607084, 'Total loss': 0.8399825380607084} | train loss {'Reaction outcome loss': 0.8166990560148993, 'Total loss': 0.8166990560148993}
2022-11-23 01:10:49,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:49,258 INFO:     Epoch: 7
2022-11-23 01:10:50,063 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8273546519604597, 'Total loss': 0.8273546519604597} | train loss {'Reaction outcome loss': 0.8061952947849228, 'Total loss': 0.8061952947849228}
2022-11-23 01:10:50,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:50,063 INFO:     Epoch: 8
2022-11-23 01:10:50,876 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8484128930351951, 'Total loss': 0.8484128930351951} | train loss {'Reaction outcome loss': 0.8109068267287747, 'Total loss': 0.8109068267287747}
2022-11-23 01:10:50,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:50,876 INFO:     Epoch: 9
2022-11-23 01:10:51,688 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8394094163721258, 'Total loss': 0.8394094163721258} | train loss {'Reaction outcome loss': 0.8096476888224002, 'Total loss': 0.8096476888224002}
2022-11-23 01:10:51,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:51,688 INFO:     Epoch: 10
2022-11-23 01:10:52,513 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8312363990328528, 'Total loss': 0.8312363990328528} | train loss {'Reaction outcome loss': 0.8067868393996069, 'Total loss': 0.8067868393996069}
2022-11-23 01:10:52,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:52,513 INFO:     Epoch: 11
2022-11-23 01:10:53,362 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8385993364182386, 'Total loss': 0.8385993364182386} | train loss {'Reaction outcome loss': 0.8032817093114699, 'Total loss': 0.8032817093114699}
2022-11-23 01:10:53,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:53,362 INFO:     Epoch: 12
2022-11-23 01:10:54,192 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8350454751740802, 'Total loss': 0.8350454751740802} | train loss {'Reaction outcome loss': 0.8078484646975994, 'Total loss': 0.8078484646975994}
2022-11-23 01:10:54,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:54,192 INFO:     Epoch: 13
2022-11-23 01:10:55,029 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.843737168745561, 'Total loss': 0.843737168745561} | train loss {'Reaction outcome loss': 0.80790620934098, 'Total loss': 0.80790620934098}
2022-11-23 01:10:55,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:55,029 INFO:     Epoch: 14
2022-11-23 01:10:55,816 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8246013589880683, 'Total loss': 0.8246013589880683} | train loss {'Reaction outcome loss': 0.8087006171624507, 'Total loss': 0.8087006171624507}
2022-11-23 01:10:55,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:55,816 INFO:     Epoch: 15
2022-11-23 01:10:56,622 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8131683231754736, 'Total loss': 0.8131683231754736} | train loss {'Reaction outcome loss': 0.8013307560355433, 'Total loss': 0.8013307560355433}
2022-11-23 01:10:56,622 INFO:     Found new best model at epoch 15
2022-11-23 01:10:56,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:56,623 INFO:     Epoch: 16
2022-11-23 01:10:57,425 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.839982891624624, 'Total loss': 0.839982891624624} | train loss {'Reaction outcome loss': 0.802472376775357, 'Total loss': 0.802472376775357}
2022-11-23 01:10:57,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:57,426 INFO:     Epoch: 17
2022-11-23 01:10:58,220 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8337851173498414, 'Total loss': 0.8337851173498414} | train loss {'Reaction outcome loss': 0.8086900426255118, 'Total loss': 0.8086900426255118}
2022-11-23 01:10:58,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:58,220 INFO:     Epoch: 18
2022-11-23 01:10:59,069 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.835702130740339, 'Total loss': 0.835702130740339} | train loss {'Reaction outcome loss': 0.7996476258962385, 'Total loss': 0.7996476258962385}
2022-11-23 01:10:59,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:59,069 INFO:     Epoch: 19
2022-11-23 01:10:59,912 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8303576450456273, 'Total loss': 0.8303576450456273} | train loss {'Reaction outcome loss': 0.8113395274887162, 'Total loss': 0.8113395274887162}
2022-11-23 01:10:59,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:10:59,912 INFO:     Epoch: 20
2022-11-23 01:11:00,769 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.829666951840574, 'Total loss': 0.829666951840574} | train loss {'Reaction outcome loss': 0.8049323043275264, 'Total loss': 0.8049323043275264}
2022-11-23 01:11:00,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:00,770 INFO:     Epoch: 21
2022-11-23 01:11:01,707 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8360741991888393, 'Total loss': 0.8360741991888393} | train loss {'Reaction outcome loss': 0.8058564179847317, 'Total loss': 0.8058564179847317}
2022-11-23 01:11:01,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:01,707 INFO:     Epoch: 22
2022-11-23 01:11:02,579 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8216089037331668, 'Total loss': 0.8216089037331668} | train loss {'Reaction outcome loss': 0.8035324962148743, 'Total loss': 0.8035324962148743}
2022-11-23 01:11:02,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:02,580 INFO:     Epoch: 23
2022-11-23 01:11:03,526 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8349385830489072, 'Total loss': 0.8349385830489072} | train loss {'Reaction outcome loss': 0.8057455794224816, 'Total loss': 0.8057455794224816}
2022-11-23 01:11:03,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:03,526 INFO:     Epoch: 24
2022-11-23 01:11:04,379 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8184853832830082, 'Total loss': 0.8184853832830082} | train loss {'Reaction outcome loss': 0.8067403686863761, 'Total loss': 0.8067403686863761}
2022-11-23 01:11:04,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:04,379 INFO:     Epoch: 25
2022-11-23 01:11:05,169 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8296427184885199, 'Total loss': 0.8296427184885199} | train loss {'Reaction outcome loss': 0.8049622673180795, 'Total loss': 0.8049622673180795}
2022-11-23 01:11:05,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:05,169 INFO:     Epoch: 26
2022-11-23 01:11:06,004 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8242037215016105, 'Total loss': 0.8242037215016105} | train loss {'Reaction outcome loss': 0.8024101065051171, 'Total loss': 0.8024101065051171}
2022-11-23 01:11:06,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:06,004 INFO:     Epoch: 27
2022-11-23 01:11:06,845 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8271436203609813, 'Total loss': 0.8271436203609813} | train loss {'Reaction outcome loss': 0.803122086510543, 'Total loss': 0.803122086510543}
2022-11-23 01:11:06,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:06,846 INFO:     Epoch: 28
2022-11-23 01:11:07,654 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8228568969802423, 'Total loss': 0.8228568969802423} | train loss {'Reaction outcome loss': 0.806274215300237, 'Total loss': 0.806274215300237}
2022-11-23 01:11:07,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:07,655 INFO:     Epoch: 29
2022-11-23 01:11:08,517 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8278367939320478, 'Total loss': 0.8278367939320478} | train loss {'Reaction outcome loss': 0.8013377802506569, 'Total loss': 0.8013377802506569}
2022-11-23 01:11:08,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:08,517 INFO:     Epoch: 30
2022-11-23 01:11:09,334 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8303956917741082, 'Total loss': 0.8303956917741082} | train loss {'Reaction outcome loss': 0.7981313820327481, 'Total loss': 0.7981313820327481}
2022-11-23 01:11:09,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:09,334 INFO:     Epoch: 31
2022-11-23 01:11:10,159 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8251141567121852, 'Total loss': 0.8251141567121852} | train loss {'Reaction outcome loss': 0.8004156274180259, 'Total loss': 0.8004156274180259}
2022-11-23 01:11:10,159 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:10,159 INFO:     Epoch: 32
2022-11-23 01:11:10,971 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8948737274516713, 'Total loss': 0.8948737274516713} | train loss {'Reaction outcome loss': 0.8007151939936222, 'Total loss': 0.8007151939936222}
2022-11-23 01:11:10,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:10,971 INFO:     Epoch: 33
2022-11-23 01:11:11,772 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8238267336379398, 'Total loss': 0.8238267336379398} | train loss {'Reaction outcome loss': 0.8032882455135545, 'Total loss': 0.8032882455135545}
2022-11-23 01:11:11,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:11,772 INFO:     Epoch: 34
2022-11-23 01:11:12,562 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8490523987195708, 'Total loss': 0.8490523987195708} | train loss {'Reaction outcome loss': 0.8010311985929166, 'Total loss': 0.8010311985929166}
2022-11-23 01:11:12,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:12,562 INFO:     Epoch: 35
2022-11-23 01:11:13,412 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8499377058310942, 'Total loss': 0.8499377058310942} | train loss {'Reaction outcome loss': 0.7970946985146692, 'Total loss': 0.7970946985146692}
2022-11-23 01:11:13,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:13,412 INFO:     Epoch: 36
2022-11-23 01:11:14,250 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8277938745238564, 'Total loss': 0.8277938745238564} | train loss {'Reaction outcome loss': 0.8062203140148232, 'Total loss': 0.8062203140148232}
2022-11-23 01:11:14,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:14,250 INFO:     Epoch: 37
2022-11-23 01:11:15,077 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8147334984757684, 'Total loss': 0.8147334984757684} | train loss {'Reaction outcome loss': 0.8030189300977415, 'Total loss': 0.8030189300977415}
2022-11-23 01:11:15,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:15,077 INFO:     Epoch: 38
2022-11-23 01:11:15,879 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8512813557278026, 'Total loss': 0.8512813557278026} | train loss {'Reaction outcome loss': 0.8011857154628923, 'Total loss': 0.8011857154628923}
2022-11-23 01:11:15,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:15,879 INFO:     Epoch: 39
2022-11-23 01:11:16,732 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8300369700247591, 'Total loss': 0.8300369700247591} | train loss {'Reaction outcome loss': 0.8039971010819558, 'Total loss': 0.8039971010819558}
2022-11-23 01:11:16,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:16,732 INFO:     Epoch: 40
2022-11-23 01:11:17,557 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8446337675506418, 'Total loss': 0.8446337675506418} | train loss {'Reaction outcome loss': 0.8026908515922485, 'Total loss': 0.8026908515922485}
2022-11-23 01:11:17,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:17,557 INFO:     Epoch: 41
2022-11-23 01:11:18,383 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8317787464369427, 'Total loss': 0.8317787464369427} | train loss {'Reaction outcome loss': 0.8007999560044657, 'Total loss': 0.8007999560044657}
2022-11-23 01:11:18,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:18,384 INFO:     Epoch: 42
2022-11-23 01:11:19,204 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8273679370229895, 'Total loss': 0.8273679370229895} | train loss {'Reaction outcome loss': 0.7996069907901748, 'Total loss': 0.7996069907901748}
2022-11-23 01:11:19,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:19,206 INFO:     Epoch: 43
2022-11-23 01:11:20,026 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8255741081454537, 'Total loss': 0.8255741081454537} | train loss {'Reaction outcome loss': 0.8029599494991764, 'Total loss': 0.8029599494991764}
2022-11-23 01:11:20,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:20,027 INFO:     Epoch: 44
2022-11-23 01:11:20,825 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8215638995170593, 'Total loss': 0.8215638995170593} | train loss {'Reaction outcome loss': 0.8004595906503739, 'Total loss': 0.8004595906503739}
2022-11-23 01:11:20,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:20,826 INFO:     Epoch: 45
2022-11-23 01:11:21,677 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8191654377362945, 'Total loss': 0.8191654377362945} | train loss {'Reaction outcome loss': 0.8026170036004435, 'Total loss': 0.8026170036004435}
2022-11-23 01:11:21,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:21,677 INFO:     Epoch: 46
2022-11-23 01:11:22,512 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8418784127994017, 'Total loss': 0.8418784127994017} | train loss {'Reaction outcome loss': 0.7974103827389979, 'Total loss': 0.7974103827389979}
2022-11-23 01:11:22,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:22,512 INFO:     Epoch: 47
2022-11-23 01:11:23,278 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8365497562018308, 'Total loss': 0.8365497562018308} | train loss {'Reaction outcome loss': 0.8067095243642407, 'Total loss': 0.8067095243642407}
2022-11-23 01:11:23,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:23,278 INFO:     Epoch: 48
2022-11-23 01:11:24,072 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8227360153740103, 'Total loss': 0.8227360153740103} | train loss {'Reaction outcome loss': 0.8053818617857271, 'Total loss': 0.8053818617857271}
2022-11-23 01:11:24,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:24,072 INFO:     Epoch: 49
2022-11-23 01:11:24,904 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8245910555124283, 'Total loss': 0.8245910555124283} | train loss {'Reaction outcome loss': 0.7986688984017218, 'Total loss': 0.7986688984017218}
2022-11-23 01:11:24,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:24,905 INFO:     Epoch: 50
2022-11-23 01:11:25,734 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8191951967098496, 'Total loss': 0.8191951967098496} | train loss {'Reaction outcome loss': 0.8020606481980893, 'Total loss': 0.8020606481980893}
2022-11-23 01:11:25,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:25,734 INFO:     Epoch: 51
2022-11-23 01:11:26,560 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8307355669411746, 'Total loss': 0.8307355669411746} | train loss {'Reaction outcome loss': 0.8003114304475246, 'Total loss': 0.8003114304475246}
2022-11-23 01:11:26,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:26,561 INFO:     Epoch: 52
2022-11-23 01:11:27,399 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8273445286534049, 'Total loss': 0.8273445286534049} | train loss {'Reaction outcome loss': 0.8007337744197538, 'Total loss': 0.8007337744197538}
2022-11-23 01:11:27,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:27,399 INFO:     Epoch: 53
2022-11-23 01:11:28,189 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.821946501054547, 'Total loss': 0.821946501054547} | train loss {'Reaction outcome loss': 0.8008293945702815, 'Total loss': 0.8008293945702815}
2022-11-23 01:11:28,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:28,190 INFO:     Epoch: 54
2022-11-23 01:11:29,011 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8269799128174782, 'Total loss': 0.8269799128174782} | train loss {'Reaction outcome loss': 0.7991452658128354, 'Total loss': 0.7991452658128354}
2022-11-23 01:11:29,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:29,011 INFO:     Epoch: 55
2022-11-23 01:11:29,806 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.82237539508126, 'Total loss': 0.82237539508126} | train loss {'Reaction outcome loss': 0.7965280863065873, 'Total loss': 0.7965280863065873}
2022-11-23 01:11:29,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:29,806 INFO:     Epoch: 56
2022-11-23 01:11:30,619 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.824666174297983, 'Total loss': 0.824666174297983} | train loss {'Reaction outcome loss': 0.8033314693358636, 'Total loss': 0.8033314693358636}
2022-11-23 01:11:30,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:30,619 INFO:     Epoch: 57
2022-11-23 01:11:31,446 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8194164051250978, 'Total loss': 0.8194164051250978} | train loss {'Reaction outcome loss': 0.798875566211439, 'Total loss': 0.798875566211439}
2022-11-23 01:11:31,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:31,448 INFO:     Epoch: 58
2022-11-23 01:11:32,266 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8220830011096868, 'Total loss': 0.8220830011096868} | train loss {'Reaction outcome loss': 0.8000115581577824, 'Total loss': 0.8000115581577824}
2022-11-23 01:11:32,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:32,266 INFO:     Epoch: 59
2022-11-23 01:11:33,105 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8479955494403839, 'Total loss': 0.8479955494403839} | train loss {'Reaction outcome loss': 0.7967377660735961, 'Total loss': 0.7967377660735961}
2022-11-23 01:11:33,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:33,105 INFO:     Epoch: 60
2022-11-23 01:11:33,936 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.821525024419481, 'Total loss': 0.821525024419481} | train loss {'Reaction outcome loss': 0.8067421555038421, 'Total loss': 0.8067421555038421}
2022-11-23 01:11:33,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:33,936 INFO:     Epoch: 61
2022-11-23 01:11:34,802 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8185191852125254, 'Total loss': 0.8185191852125254} | train loss {'Reaction outcome loss': 0.8001094962800702, 'Total loss': 0.8001094962800702}
2022-11-23 01:11:34,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:34,802 INFO:     Epoch: 62
2022-11-23 01:11:35,607 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8196793008934368, 'Total loss': 0.8196793008934368} | train loss {'Reaction outcome loss': 0.8002969001329714, 'Total loss': 0.8002969001329714}
2022-11-23 01:11:35,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:35,608 INFO:     Epoch: 63
2022-11-23 01:11:36,481 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8264350789514455, 'Total loss': 0.8264350789514455} | train loss {'Reaction outcome loss': 0.7990095072215603, 'Total loss': 0.7990095072215603}
2022-11-23 01:11:36,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:36,481 INFO:     Epoch: 64
2022-11-23 01:11:37,255 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8479591249064966, 'Total loss': 0.8479591249064966} | train loss {'Reaction outcome loss': 0.8001237977896968, 'Total loss': 0.8001237977896968}
2022-11-23 01:11:37,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:37,256 INFO:     Epoch: 65
2022-11-23 01:11:38,087 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8455871099775488, 'Total loss': 0.8455871099775488} | train loss {'Reaction outcome loss': 0.8044325551919399, 'Total loss': 0.8044325551919399}
2022-11-23 01:11:38,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:38,088 INFO:     Epoch: 66
2022-11-23 01:11:38,881 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8259183696725152, 'Total loss': 0.8259183696725152} | train loss {'Reaction outcome loss': 0.7979628541056187, 'Total loss': 0.7979628541056187}
2022-11-23 01:11:38,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:38,881 INFO:     Epoch: 67
2022-11-23 01:11:39,695 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8233740912242369, 'Total loss': 0.8233740912242369} | train loss {'Reaction outcome loss': 0.7998403638841645, 'Total loss': 0.7998403638841645}
2022-11-23 01:11:39,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:39,696 INFO:     Epoch: 68
2022-11-23 01:11:40,526 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8120056045326319, 'Total loss': 0.8120056045326319} | train loss {'Reaction outcome loss': 0.8032556757811578, 'Total loss': 0.8032556757811578}
2022-11-23 01:11:40,526 INFO:     Found new best model at epoch 68
2022-11-23 01:11:40,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:40,527 INFO:     Epoch: 69
2022-11-23 01:11:41,351 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8243669745596972, 'Total loss': 0.8243669745596972} | train loss {'Reaction outcome loss': 0.7965665048649234, 'Total loss': 0.7965665048649234}
2022-11-23 01:11:41,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:41,351 INFO:     Epoch: 70
2022-11-23 01:11:42,153 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8440572064031254, 'Total loss': 0.8440572064031254} | train loss {'Reaction outcome loss': 0.7984810613336102, 'Total loss': 0.7984810613336102}
2022-11-23 01:11:42,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:42,154 INFO:     Epoch: 71
2022-11-23 01:11:42,937 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.820506173778664, 'Total loss': 0.820506173778664} | train loss {'Reaction outcome loss': 0.8028942049751359, 'Total loss': 0.8028942049751359}
2022-11-23 01:11:42,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:42,937 INFO:     Epoch: 72
2022-11-23 01:11:43,753 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8392559303478762, 'Total loss': 0.8392559303478762} | train loss {'Reaction outcome loss': 0.7942916841035889, 'Total loss': 0.7942916841035889}
2022-11-23 01:11:43,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:43,753 INFO:     Epoch: 73
2022-11-23 01:11:44,581 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8271421363407915, 'Total loss': 0.8271421363407915} | train loss {'Reaction outcome loss': 0.8005648809334924, 'Total loss': 0.8005648809334924}
2022-11-23 01:11:44,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:44,581 INFO:     Epoch: 74
2022-11-23 01:11:45,412 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8131085444580425, 'Total loss': 0.8131085444580425} | train loss {'Reaction outcome loss': 0.7983309429499411, 'Total loss': 0.7983309429499411}
2022-11-23 01:11:45,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:45,413 INFO:     Epoch: 75
2022-11-23 01:11:46,260 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8220705620267175, 'Total loss': 0.8220705620267175} | train loss {'Reaction outcome loss': 0.7914420902248351, 'Total loss': 0.7914420902248351}
2022-11-23 01:11:46,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:46,260 INFO:     Epoch: 76
2022-11-23 01:11:47,066 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.825852713801644, 'Total loss': 0.825852713801644} | train loss {'Reaction outcome loss': 0.7961902015151516, 'Total loss': 0.7961902015151516}
2022-11-23 01:11:47,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:47,066 INFO:     Epoch: 77
2022-11-23 01:11:47,907 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.809953130104325, 'Total loss': 0.809953130104325} | train loss {'Reaction outcome loss': 0.8040553145110607, 'Total loss': 0.8040553145110607}
2022-11-23 01:11:47,907 INFO:     Found new best model at epoch 77
2022-11-23 01:11:47,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:47,908 INFO:     Epoch: 78
2022-11-23 01:11:48,718 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8289122080261057, 'Total loss': 0.8289122080261057} | train loss {'Reaction outcome loss': 0.8005367543908858, 'Total loss': 0.8005367543908858}
2022-11-23 01:11:48,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:48,718 INFO:     Epoch: 79
2022-11-23 01:11:49,569 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8433445163748481, 'Total loss': 0.8433445163748481} | train loss {'Reaction outcome loss': 0.7930232759925627, 'Total loss': 0.7930232759925627}
2022-11-23 01:11:49,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:49,569 INFO:     Epoch: 80
2022-11-23 01:11:50,359 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8214687237685377, 'Total loss': 0.8214687237685377} | train loss {'Reaction outcome loss': 0.7949092734244562, 'Total loss': 0.7949092734244562}
2022-11-23 01:11:50,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:50,360 INFO:     Epoch: 81
2022-11-23 01:11:51,179 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8135595951567997, 'Total loss': 0.8135595951567997} | train loss {'Reaction outcome loss': 0.7951728887856007, 'Total loss': 0.7951728887856007}
2022-11-23 01:11:51,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:51,180 INFO:     Epoch: 82
2022-11-23 01:11:52,030 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8305689259008928, 'Total loss': 0.8305689259008928} | train loss {'Reaction outcome loss': 0.7982991198378224, 'Total loss': 0.7982991198378224}
2022-11-23 01:11:52,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:52,030 INFO:     Epoch: 83
2022-11-23 01:11:52,859 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8199216493151404, 'Total loss': 0.8199216493151404} | train loss {'Reaction outcome loss': 0.793946218947249, 'Total loss': 0.793946218947249}
2022-11-23 01:11:52,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:52,860 INFO:     Epoch: 84
2022-11-23 01:11:53,689 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8215530047362501, 'Total loss': 0.8215530047362501} | train loss {'Reaction outcome loss': 0.7948270478556233, 'Total loss': 0.7948270478556233}
2022-11-23 01:11:53,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:53,689 INFO:     Epoch: 85
2022-11-23 01:11:54,570 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.813067077235742, 'Total loss': 0.813067077235742} | train loss {'Reaction outcome loss': 0.7966945996928599, 'Total loss': 0.7966945996928599}
2022-11-23 01:11:54,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:54,570 INFO:     Epoch: 86
2022-11-23 01:11:55,395 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8275849941101941, 'Total loss': 0.8275849941101941} | train loss {'Reaction outcome loss': 0.7941136106608375, 'Total loss': 0.7941136106608375}
2022-11-23 01:11:55,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:55,395 INFO:     Epoch: 87
2022-11-23 01:11:56,170 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8374131945046511, 'Total loss': 0.8374131945046511} | train loss {'Reaction outcome loss': 0.7917692888407938, 'Total loss': 0.7917692888407938}
2022-11-23 01:11:56,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:56,170 INFO:     Epoch: 88
2022-11-23 01:11:56,946 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8117278631437909, 'Total loss': 0.8117278631437909} | train loss {'Reaction outcome loss': 0.7925777901564875, 'Total loss': 0.7925777901564875}
2022-11-23 01:11:56,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:56,946 INFO:     Epoch: 89
2022-11-23 01:11:57,723 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8167548707940362, 'Total loss': 0.8167548707940362} | train loss {'Reaction outcome loss': 0.7979206596651385, 'Total loss': 0.7979206596651385}
2022-11-23 01:11:57,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:57,723 INFO:     Epoch: 90
2022-11-23 01:11:58,505 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8057863766496832, 'Total loss': 0.8057863766496832} | train loss {'Reaction outcome loss': 0.7936919070780277, 'Total loss': 0.7936919070780277}
2022-11-23 01:11:58,506 INFO:     Found new best model at epoch 90
2022-11-23 01:11:58,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:58,506 INFO:     Epoch: 91
2022-11-23 01:11:59,312 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8433837375857614, 'Total loss': 0.8433837375857614} | train loss {'Reaction outcome loss': 0.7918511917514186, 'Total loss': 0.7918511917514186}
2022-11-23 01:11:59,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:11:59,312 INFO:     Epoch: 92
2022-11-23 01:12:00,123 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8104461241852153, 'Total loss': 0.8104461241852153} | train loss {'Reaction outcome loss': 0.7931602986589554, 'Total loss': 0.7931602986589554}
2022-11-23 01:12:00,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:00,123 INFO:     Epoch: 93
2022-11-23 01:12:00,975 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8370141712102023, 'Total loss': 0.8370141712102023} | train loss {'Reaction outcome loss': 0.7933692247156174, 'Total loss': 0.7933692247156174}
2022-11-23 01:12:00,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:00,975 INFO:     Epoch: 94
2022-11-23 01:12:01,863 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8285564577037637, 'Total loss': 0.8285564577037637} | train loss {'Reaction outcome loss': 0.7874456638049695, 'Total loss': 0.7874456638049695}
2022-11-23 01:12:01,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:01,864 INFO:     Epoch: 95
2022-11-23 01:12:02,692 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8179465769366785, 'Total loss': 0.8179465769366785} | train loss {'Reaction outcome loss': 0.7915422287919829, 'Total loss': 0.7915422287919829}
2022-11-23 01:12:02,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:02,692 INFO:     Epoch: 96
2022-11-23 01:12:03,519 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8141129680655219, 'Total loss': 0.8141129680655219} | train loss {'Reaction outcome loss': 0.7856553929948038, 'Total loss': 0.7856553929948038}
2022-11-23 01:12:03,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:03,520 INFO:     Epoch: 97
2022-11-23 01:12:04,356 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8258392810821533, 'Total loss': 0.8258392810821533} | train loss {'Reaction outcome loss': 0.7880838875088, 'Total loss': 0.7880838875088}
2022-11-23 01:12:04,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:04,356 INFO:     Epoch: 98
2022-11-23 01:12:05,228 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8093964416872371, 'Total loss': 0.8093964416872371} | train loss {'Reaction outcome loss': 0.7985641235305417, 'Total loss': 0.7985641235305417}
2022-11-23 01:12:05,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:05,228 INFO:     Epoch: 99
2022-11-23 01:12:06,071 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8000824708830226, 'Total loss': 0.8000824708830226} | train loss {'Reaction outcome loss': 0.7861906467906891, 'Total loss': 0.7861906467906891}
2022-11-23 01:12:06,071 INFO:     Found new best model at epoch 99
2022-11-23 01:12:06,072 INFO:     Best model found after epoch 100 of 100.
2022-11-23 01:12:06,072 INFO:   Done with stage: TRAINING
2022-11-23 01:12:06,072 INFO:   Starting stage: EVALUATION
2022-11-23 01:12:06,193 INFO:   Done with stage: EVALUATION
2022-11-23 01:12:06,194 INFO:   Leaving out SEQ value Fold_8
2022-11-23 01:12:06,207 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 01:12:06,207 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:12:06,894 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:12:06,894 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:12:06,968 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:12:06,968 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:12:06,968 INFO:     No hyperparam tuning for this model
2022-11-23 01:12:06,968 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:12:06,968 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:12:06,969 INFO:     None feature selector for col prot
2022-11-23 01:12:06,969 INFO:     None feature selector for col prot
2022-11-23 01:12:06,969 INFO:     None feature selector for col prot
2022-11-23 01:12:06,970 INFO:     None feature selector for col chem
2022-11-23 01:12:06,970 INFO:     None feature selector for col chem
2022-11-23 01:12:06,970 INFO:     None feature selector for col chem
2022-11-23 01:12:06,970 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:12:06,971 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:12:06,972 INFO:     Number of params in model 168571
2022-11-23 01:12:06,976 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:12:06,976 INFO:   Starting stage: TRAINING
2022-11-23 01:12:07,036 INFO:     Val loss before train {'Reaction outcome loss': 0.977520537647334, 'Total loss': 0.977520537647334}
2022-11-23 01:12:07,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:07,036 INFO:     Epoch: 0
2022-11-23 01:12:07,901 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8350982835347002, 'Total loss': 0.8350982835347002} | train loss {'Reaction outcome loss': 0.8853575488732707, 'Total loss': 0.8853575488732707}
2022-11-23 01:12:07,901 INFO:     Found new best model at epoch 0
2022-11-23 01:12:07,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:07,902 INFO:     Epoch: 1
2022-11-23 01:12:08,748 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8480574190616608, 'Total loss': 0.8480574190616608} | train loss {'Reaction outcome loss': 0.8500603260772843, 'Total loss': 0.8500603260772843}
2022-11-23 01:12:08,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:08,748 INFO:     Epoch: 2
2022-11-23 01:12:09,646 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8339357755400918, 'Total loss': 0.8339357755400918} | train loss {'Reaction outcome loss': 0.8385818665546756, 'Total loss': 0.8385818665546756}
2022-11-23 01:12:09,647 INFO:     Found new best model at epoch 2
2022-11-23 01:12:09,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:09,648 INFO:     Epoch: 3
2022-11-23 01:12:10,590 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8253213532946326, 'Total loss': 0.8253213532946326} | train loss {'Reaction outcome loss': 0.8391956153415865, 'Total loss': 0.8391956153415865}
2022-11-23 01:12:10,591 INFO:     Found new best model at epoch 3
2022-11-23 01:12:10,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:10,592 INFO:     Epoch: 4
2022-11-23 01:12:11,515 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8183825219219382, 'Total loss': 0.8183825219219382} | train loss {'Reaction outcome loss': 0.828161665508824, 'Total loss': 0.828161665508824}
2022-11-23 01:12:11,515 INFO:     Found new best model at epoch 4
2022-11-23 01:12:11,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:11,516 INFO:     Epoch: 5
2022-11-23 01:12:12,428 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8263501931320537, 'Total loss': 0.8263501931320537} | train loss {'Reaction outcome loss': 0.8302402207928319, 'Total loss': 0.8302402207928319}
2022-11-23 01:12:12,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:12,429 INFO:     Epoch: 6
2022-11-23 01:12:13,295 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.813861292871562, 'Total loss': 0.813861292871562} | train loss {'Reaction outcome loss': 0.8215188465772136, 'Total loss': 0.8215188465772136}
2022-11-23 01:12:13,295 INFO:     Found new best model at epoch 6
2022-11-23 01:12:13,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:13,296 INFO:     Epoch: 7
2022-11-23 01:12:14,242 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8143571771003983, 'Total loss': 0.8143571771003983} | train loss {'Reaction outcome loss': 0.8247339404638736, 'Total loss': 0.8247339404638736}
2022-11-23 01:12:14,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:14,242 INFO:     Epoch: 8
2022-11-23 01:12:15,172 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8137464916164224, 'Total loss': 0.8137464916164224} | train loss {'Reaction outcome loss': 0.8180157198540626, 'Total loss': 0.8180157198540626}
2022-11-23 01:12:15,172 INFO:     Found new best model at epoch 8
2022-11-23 01:12:15,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:15,173 INFO:     Epoch: 9
2022-11-23 01:12:16,122 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8202731236815453, 'Total loss': 0.8202731236815453} | train loss {'Reaction outcome loss': 0.8218940576959041, 'Total loss': 0.8218940576959041}
2022-11-23 01:12:16,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:16,122 INFO:     Epoch: 10
2022-11-23 01:12:17,000 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8124977519566362, 'Total loss': 0.8124977519566362} | train loss {'Reaction outcome loss': 0.8206920030136262, 'Total loss': 0.8206920030136262}
2022-11-23 01:12:17,000 INFO:     Found new best model at epoch 10
2022-11-23 01:12:17,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:17,001 INFO:     Epoch: 11
2022-11-23 01:12:17,947 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8220871382138946, 'Total loss': 0.8220871382138946} | train loss {'Reaction outcome loss': 0.8171567201854721, 'Total loss': 0.8171567201854721}
2022-11-23 01:12:17,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:17,947 INFO:     Epoch: 12
2022-11-23 01:12:18,791 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8185859816995534, 'Total loss': 0.8185859816995534} | train loss {'Reaction outcome loss': 0.8212402934028257, 'Total loss': 0.8212402934028257}
2022-11-23 01:12:18,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:18,791 INFO:     Epoch: 13
2022-11-23 01:12:19,649 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8060272010889921, 'Total loss': 0.8060272010889921} | train loss {'Reaction outcome loss': 0.8226646388009671, 'Total loss': 0.8226646388009671}
2022-11-23 01:12:19,649 INFO:     Found new best model at epoch 13
2022-11-23 01:12:19,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:19,650 INFO:     Epoch: 14
2022-11-23 01:12:20,559 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8100542764772068, 'Total loss': 0.8100542764772068} | train loss {'Reaction outcome loss': 0.8207099206985966, 'Total loss': 0.8207099206985966}
2022-11-23 01:12:20,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:20,559 INFO:     Epoch: 15
2022-11-23 01:12:21,426 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8149196322668683, 'Total loss': 0.8149196322668683} | train loss {'Reaction outcome loss': 0.8225822853705576, 'Total loss': 0.8225822853705576}
2022-11-23 01:12:21,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:21,427 INFO:     Epoch: 16
2022-11-23 01:12:22,312 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8005589531226591, 'Total loss': 0.8005589531226591} | train loss {'Reaction outcome loss': 0.8223567054637017, 'Total loss': 0.8223567054637017}
2022-11-23 01:12:22,313 INFO:     Found new best model at epoch 16
2022-11-23 01:12:22,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:22,314 INFO:     Epoch: 17
2022-11-23 01:12:23,212 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8237606740810655, 'Total loss': 0.8237606740810655} | train loss {'Reaction outcome loss': 0.8178871783518022, 'Total loss': 0.8178871783518022}
2022-11-23 01:12:23,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:23,212 INFO:     Epoch: 18
2022-11-23 01:12:24,079 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8147633888504722, 'Total loss': 0.8147633888504722} | train loss {'Reaction outcome loss': 0.8216025900215872, 'Total loss': 0.8216025900215872}
2022-11-23 01:12:24,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:24,079 INFO:     Epoch: 19
2022-11-23 01:12:24,939 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8264066251841459, 'Total loss': 0.8264066251841459} | train loss {'Reaction outcome loss': 0.8208251317902919, 'Total loss': 0.8208251317902919}
2022-11-23 01:12:24,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:24,940 INFO:     Epoch: 20
2022-11-23 01:12:25,797 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8166266957467253, 'Total loss': 0.8166266957467253} | train loss {'Reaction outcome loss': 0.8210273758778649, 'Total loss': 0.8210273758778649}
2022-11-23 01:12:25,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:25,797 INFO:     Epoch: 21
2022-11-23 01:12:26,663 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8155468912287192, 'Total loss': 0.8155468912287192} | train loss {'Reaction outcome loss': 0.8178187651980308, 'Total loss': 0.8178187651980308}
2022-11-23 01:12:26,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:26,663 INFO:     Epoch: 22
2022-11-23 01:12:27,533 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8218504827130925, 'Total loss': 0.8218504827130925} | train loss {'Reaction outcome loss': 0.8152649131032729, 'Total loss': 0.8152649131032729}
2022-11-23 01:12:27,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:27,534 INFO:     Epoch: 23
2022-11-23 01:12:28,421 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8101092251864347, 'Total loss': 0.8101092251864347} | train loss {'Reaction outcome loss': 0.8233959969253309, 'Total loss': 0.8233959969253309}
2022-11-23 01:12:28,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:28,422 INFO:     Epoch: 24
2022-11-23 01:12:29,287 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8060638051141392, 'Total loss': 0.8060638051141392} | train loss {'Reaction outcome loss': 0.8199256360530853, 'Total loss': 0.8199256360530853}
2022-11-23 01:12:29,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:29,288 INFO:     Epoch: 25
2022-11-23 01:12:30,169 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8359841677275571, 'Total loss': 0.8359841677275571} | train loss {'Reaction outcome loss': 0.8211821506340657, 'Total loss': 0.8211821506340657}
2022-11-23 01:12:30,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:30,170 INFO:     Epoch: 26
2022-11-23 01:12:31,064 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8262237920002504, 'Total loss': 0.8262237920002504} | train loss {'Reaction outcome loss': 0.8193016345462492, 'Total loss': 0.8193016345462492}
2022-11-23 01:12:31,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:31,064 INFO:     Epoch: 27
2022-11-23 01:12:31,927 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8114460808309641, 'Total loss': 0.8114460808309641} | train loss {'Reaction outcome loss': 0.8185371533036232, 'Total loss': 0.8185371533036232}
2022-11-23 01:12:31,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:31,928 INFO:     Epoch: 28
2022-11-23 01:12:32,796 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8051685162565925, 'Total loss': 0.8051685162565925} | train loss {'Reaction outcome loss': 0.8156702924639948, 'Total loss': 0.8156702924639948}
2022-11-23 01:12:32,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:32,796 INFO:     Epoch: 29
2022-11-23 01:12:33,642 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8237750855359164, 'Total loss': 0.8237750855359164} | train loss {'Reaction outcome loss': 0.8254117310768173, 'Total loss': 0.8254117310768173}
2022-11-23 01:12:33,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:33,642 INFO:     Epoch: 30
2022-11-23 01:12:34,505 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8421686691316691, 'Total loss': 0.8421686691316691} | train loss {'Reaction outcome loss': 0.8192220589206103, 'Total loss': 0.8192220589206103}
2022-11-23 01:12:34,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:34,507 INFO:     Epoch: 31
2022-11-23 01:12:35,390 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8056477287953551, 'Total loss': 0.8056477287953551} | train loss {'Reaction outcome loss': 0.820681736353905, 'Total loss': 0.820681736353905}
2022-11-23 01:12:35,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:35,390 INFO:     Epoch: 32
2022-11-23 01:12:36,250 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8240347037261183, 'Total loss': 0.8240347037261183} | train loss {'Reaction outcome loss': 0.8178556758549905, 'Total loss': 0.8178556758549905}
2022-11-23 01:12:36,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:36,250 INFO:     Epoch: 33
2022-11-23 01:12:37,069 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8330294367941943, 'Total loss': 0.8330294367941943} | train loss {'Reaction outcome loss': 0.8176881476275383, 'Total loss': 0.8176881476275383}
2022-11-23 01:12:37,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:37,069 INFO:     Epoch: 34
2022-11-23 01:12:37,943 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8108266287229278, 'Total loss': 0.8108266287229278} | train loss {'Reaction outcome loss': 0.8215670871638483, 'Total loss': 0.8215670871638483}
2022-11-23 01:12:37,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:37,943 INFO:     Epoch: 35
2022-11-23 01:12:38,798 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8125808117064562, 'Total loss': 0.8125808117064562} | train loss {'Reaction outcome loss': 0.8165479714591657, 'Total loss': 0.8165479714591657}
2022-11-23 01:12:38,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:38,798 INFO:     Epoch: 36
2022-11-23 01:12:39,713 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8193051130934195, 'Total loss': 0.8193051130934195} | train loss {'Reaction outcome loss': 0.8177873113703343, 'Total loss': 0.8177873113703343}
2022-11-23 01:12:39,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:39,714 INFO:     Epoch: 37
2022-11-23 01:12:40,606 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8123407905752008, 'Total loss': 0.8123407905752008} | train loss {'Reaction outcome loss': 0.8198811426278083, 'Total loss': 0.8198811426278083}
2022-11-23 01:12:40,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:40,607 INFO:     Epoch: 38
2022-11-23 01:12:41,478 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8080743036486886, 'Total loss': 0.8080743036486886} | train loss {'Reaction outcome loss': 0.8175171580045454, 'Total loss': 0.8175171580045454}
2022-11-23 01:12:41,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:41,478 INFO:     Epoch: 39
2022-11-23 01:12:42,387 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8033500516956503, 'Total loss': 0.8033500516956503} | train loss {'Reaction outcome loss': 0.8177327582192037, 'Total loss': 0.8177327582192037}
2022-11-23 01:12:42,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:42,388 INFO:     Epoch: 40
2022-11-23 01:12:43,249 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8131129734895446, 'Total loss': 0.8131129734895446} | train loss {'Reaction outcome loss': 0.8170031780196775, 'Total loss': 0.8170031780196775}
2022-11-23 01:12:43,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:43,250 INFO:     Epoch: 41
2022-11-23 01:12:44,058 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.810950517654419, 'Total loss': 0.810950517654419} | train loss {'Reaction outcome loss': 0.8162151876716844, 'Total loss': 0.8162151876716844}
2022-11-23 01:12:44,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:44,058 INFO:     Epoch: 42
2022-11-23 01:12:44,946 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8125465011054819, 'Total loss': 0.8125465011054819} | train loss {'Reaction outcome loss': 0.8187506299826407, 'Total loss': 0.8187506299826407}
2022-11-23 01:12:44,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:44,946 INFO:     Epoch: 43
2022-11-23 01:12:45,791 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8096331263130362, 'Total loss': 0.8096331263130362} | train loss {'Reaction outcome loss': 0.8201707940428488, 'Total loss': 0.8201707940428488}
2022-11-23 01:12:45,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:45,791 INFO:     Epoch: 44
2022-11-23 01:12:46,631 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.81224175542593, 'Total loss': 0.81224175542593} | train loss {'Reaction outcome loss': 0.8130344877079609, 'Total loss': 0.8130344877079609}
2022-11-23 01:12:46,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:46,631 INFO:     Epoch: 45
2022-11-23 01:12:47,493 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8051095279780301, 'Total loss': 0.8051095279780301} | train loss {'Reaction outcome loss': 0.8190681928348157, 'Total loss': 0.8190681928348157}
2022-11-23 01:12:47,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:47,493 INFO:     Epoch: 46
2022-11-23 01:12:48,408 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8143332675099373, 'Total loss': 0.8143332675099373} | train loss {'Reaction outcome loss': 0.8180621905672935, 'Total loss': 0.8180621905672935}
2022-11-23 01:12:48,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:48,409 INFO:     Epoch: 47
2022-11-23 01:12:49,232 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8154913932085037, 'Total loss': 0.8154913932085037} | train loss {'Reaction outcome loss': 0.8170803433224079, 'Total loss': 0.8170803433224079}
2022-11-23 01:12:49,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:49,232 INFO:     Epoch: 48
2022-11-23 01:12:50,081 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8130573467774824, 'Total loss': 0.8130573467774824} | train loss {'Reaction outcome loss': 0.8147712561392015, 'Total loss': 0.8147712561392015}
2022-11-23 01:12:50,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:50,081 INFO:     Epoch: 49
2022-11-23 01:12:50,897 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7959716435183178, 'Total loss': 0.7959716435183178} | train loss {'Reaction outcome loss': 0.8173381278832113, 'Total loss': 0.8173381278832113}
2022-11-23 01:12:50,897 INFO:     Found new best model at epoch 49
2022-11-23 01:12:50,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:50,898 INFO:     Epoch: 50
2022-11-23 01:12:51,793 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8240199224515394, 'Total loss': 0.8240199224515394} | train loss {'Reaction outcome loss': 0.8147121380654073, 'Total loss': 0.8147121380654073}
2022-11-23 01:12:51,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:51,794 INFO:     Epoch: 51
2022-11-23 01:12:52,725 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8201783753254197, 'Total loss': 0.8201783753254197} | train loss {'Reaction outcome loss': 0.8196410351703244, 'Total loss': 0.8196410351703244}
2022-11-23 01:12:52,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:52,726 INFO:     Epoch: 52
2022-11-23 01:12:53,582 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8437438302419402, 'Total loss': 0.8437438302419402} | train loss {'Reaction outcome loss': 0.8136301408371618, 'Total loss': 0.8136301408371618}
2022-11-23 01:12:53,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:53,582 INFO:     Epoch: 53
2022-11-23 01:12:54,453 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8038409508087418, 'Total loss': 0.8038409508087418} | train loss {'Reaction outcome loss': 0.8152389748682899, 'Total loss': 0.8152389748682899}
2022-11-23 01:12:54,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:54,453 INFO:     Epoch: 54
2022-11-23 01:12:55,311 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7947692769494924, 'Total loss': 0.7947692769494924} | train loss {'Reaction outcome loss': 0.8174686276864621, 'Total loss': 0.8174686276864621}
2022-11-23 01:12:55,311 INFO:     Found new best model at epoch 54
2022-11-23 01:12:55,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:55,312 INFO:     Epoch: 55
2022-11-23 01:12:56,157 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8066951673139225, 'Total loss': 0.8066951673139225} | train loss {'Reaction outcome loss': 0.8094479077525677, 'Total loss': 0.8094479077525677}
2022-11-23 01:12:56,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:56,157 INFO:     Epoch: 56
2022-11-23 01:12:57,001 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8374967832456935, 'Total loss': 0.8374967832456935} | train loss {'Reaction outcome loss': 0.8148441970829041, 'Total loss': 0.8148441970829041}
2022-11-23 01:12:57,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:57,001 INFO:     Epoch: 57
2022-11-23 01:12:57,844 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8105086860331622, 'Total loss': 0.8105086860331622} | train loss {'Reaction outcome loss': 0.8146384674454888, 'Total loss': 0.8146384674454888}
2022-11-23 01:12:57,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:57,844 INFO:     Epoch: 58
2022-11-23 01:12:58,727 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8052193522453308, 'Total loss': 0.8052193522453308} | train loss {'Reaction outcome loss': 0.8103912713066224, 'Total loss': 0.8103912713066224}
2022-11-23 01:12:58,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:58,727 INFO:     Epoch: 59
2022-11-23 01:12:59,539 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8243839117613706, 'Total loss': 0.8243839117613706} | train loss {'Reaction outcome loss': 0.8110948811856008, 'Total loss': 0.8110948811856008}
2022-11-23 01:12:59,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:12:59,539 INFO:     Epoch: 60
2022-11-23 01:13:00,373 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.813625882295045, 'Total loss': 0.813625882295045} | train loss {'Reaction outcome loss': 0.8151085982399602, 'Total loss': 0.8151085982399602}
2022-11-23 01:13:00,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:00,374 INFO:     Epoch: 61
2022-11-23 01:13:01,206 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8296104283495382, 'Total loss': 0.8296104283495382} | train loss {'Reaction outcome loss': 0.8159185891910907, 'Total loss': 0.8159185891910907}
2022-11-23 01:13:01,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:01,207 INFO:     Epoch: 62
2022-11-23 01:13:02,101 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8087048381567001, 'Total loss': 0.8087048381567001} | train loss {'Reaction outcome loss': 0.8197446518367336, 'Total loss': 0.8197446518367336}
2022-11-23 01:13:02,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:02,101 INFO:     Epoch: 63
2022-11-23 01:13:03,007 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8021418736739592, 'Total loss': 0.8021418736739592} | train loss {'Reaction outcome loss': 0.813801925749548, 'Total loss': 0.813801925749548}
2022-11-23 01:13:03,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:03,007 INFO:     Epoch: 64
2022-11-23 01:13:03,898 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8067148280414668, 'Total loss': 0.8067148280414668} | train loss {'Reaction outcome loss': 0.815547451376915, 'Total loss': 0.815547451376915}
2022-11-23 01:13:03,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:03,899 INFO:     Epoch: 65
2022-11-23 01:13:04,767 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8092316822572188, 'Total loss': 0.8092316822572188} | train loss {'Reaction outcome loss': 0.8124961767706179, 'Total loss': 0.8124961767706179}
2022-11-23 01:13:04,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:04,768 INFO:     Epoch: 66
2022-11-23 01:13:05,672 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.797437609596686, 'Total loss': 0.797437609596686} | train loss {'Reaction outcome loss': 0.8130663943386847, 'Total loss': 0.8130663943386847}
2022-11-23 01:13:05,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:05,672 INFO:     Epoch: 67
2022-11-23 01:13:06,545 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.807344051585956, 'Total loss': 0.807344051585956} | train loss {'Reaction outcome loss': 0.8148347325623035, 'Total loss': 0.8148347325623035}
2022-11-23 01:13:06,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:06,545 INFO:     Epoch: 68
2022-11-23 01:13:07,434 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8049207580360499, 'Total loss': 0.8049207580360499} | train loss {'Reaction outcome loss': 0.8151244118569358, 'Total loss': 0.8151244118569358}
2022-11-23 01:13:07,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:07,434 INFO:     Epoch: 69
2022-11-23 01:13:08,245 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7997376268560236, 'Total loss': 0.7997376268560236} | train loss {'Reaction outcome loss': 0.8165359138961761, 'Total loss': 0.8165359138961761}
2022-11-23 01:13:08,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:08,246 INFO:     Epoch: 70
2022-11-23 01:13:09,042 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7997099594636397, 'Total loss': 0.7997099594636397} | train loss {'Reaction outcome loss': 0.8128491903264676, 'Total loss': 0.8128491903264676}
2022-11-23 01:13:09,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:09,043 INFO:     Epoch: 71
2022-11-23 01:13:09,876 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8105886619199406, 'Total loss': 0.8105886619199406} | train loss {'Reaction outcome loss': 0.8139125552148588, 'Total loss': 0.8139125552148588}
2022-11-23 01:13:09,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:09,876 INFO:     Epoch: 72
2022-11-23 01:13:10,698 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8198757564479654, 'Total loss': 0.8198757564479654} | train loss {'Reaction outcome loss': 0.814090997701691, 'Total loss': 0.814090997701691}
2022-11-23 01:13:10,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:10,699 INFO:     Epoch: 73
2022-11-23 01:13:11,514 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8124801326881755, 'Total loss': 0.8124801326881755} | train loss {'Reaction outcome loss': 0.8103015588656548, 'Total loss': 0.8103015588656548}
2022-11-23 01:13:11,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:11,515 INFO:     Epoch: 74
2022-11-23 01:13:12,272 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8181093809279528, 'Total loss': 0.8181093809279528} | train loss {'Reaction outcome loss': 0.8134652818402937, 'Total loss': 0.8134652818402937}
2022-11-23 01:13:12,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:12,272 INFO:     Epoch: 75
2022-11-23 01:13:13,063 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8043033426458185, 'Total loss': 0.8043033426458185} | train loss {'Reaction outcome loss': 0.8102959973677513, 'Total loss': 0.8102959973677513}
2022-11-23 01:13:13,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:13,063 INFO:     Epoch: 76
2022-11-23 01:13:13,861 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8058273873545907, 'Total loss': 0.8058273873545907} | train loss {'Reaction outcome loss': 0.8164808852297645, 'Total loss': 0.8164808852297645}
2022-11-23 01:13:13,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:13,861 INFO:     Epoch: 77
2022-11-23 01:13:14,626 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8145120177756656, 'Total loss': 0.8145120177756656} | train loss {'Reaction outcome loss': 0.8137953703201586, 'Total loss': 0.8137953703201586}
2022-11-23 01:13:14,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:14,626 INFO:     Epoch: 78
2022-11-23 01:13:15,376 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8071274357763204, 'Total loss': 0.8071274357763204} | train loss {'Reaction outcome loss': 0.8094341049511586, 'Total loss': 0.8094341049511586}
2022-11-23 01:13:15,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:15,376 INFO:     Epoch: 79
2022-11-23 01:13:16,165 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8191377026113597, 'Total loss': 0.8191377026113597} | train loss {'Reaction outcome loss': 0.8149988046817241, 'Total loss': 0.8149988046817241}
2022-11-23 01:13:16,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:16,165 INFO:     Epoch: 80
2022-11-23 01:13:16,950 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8060698441483758, 'Total loss': 0.8060698441483758} | train loss {'Reaction outcome loss': 0.8155190460383892, 'Total loss': 0.8155190460383892}
2022-11-23 01:13:16,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:16,950 INFO:     Epoch: 81
2022-11-23 01:13:17,728 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.836260436610742, 'Total loss': 0.836260436610742} | train loss {'Reaction outcome loss': 0.8177224350792747, 'Total loss': 0.8177224350792747}
2022-11-23 01:13:17,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:17,728 INFO:     Epoch: 82
2022-11-23 01:13:18,489 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8253170231526549, 'Total loss': 0.8253170231526549} | train loss {'Reaction outcome loss': 0.8155977894221583, 'Total loss': 0.8155977894221583}
2022-11-23 01:13:18,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:18,489 INFO:     Epoch: 83
2022-11-23 01:13:19,282 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.818071037530899, 'Total loss': 0.818071037530899} | train loss {'Reaction outcome loss': 0.8171304269062896, 'Total loss': 0.8171304269062896}
2022-11-23 01:13:19,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:19,282 INFO:     Epoch: 84
2022-11-23 01:13:20,066 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8119103874672543, 'Total loss': 0.8119103874672543} | train loss {'Reaction outcome loss': 0.815078136781531, 'Total loss': 0.815078136781531}
2022-11-23 01:13:20,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:20,066 INFO:     Epoch: 85
2022-11-23 01:13:20,866 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8131627995859493, 'Total loss': 0.8131627995859493} | train loss {'Reaction outcome loss': 0.8107401600047466, 'Total loss': 0.8107401600047466}
2022-11-23 01:13:20,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:20,866 INFO:     Epoch: 86
2022-11-23 01:13:21,655 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8032712482593276, 'Total loss': 0.8032712482593276} | train loss {'Reaction outcome loss': 0.8148196112484701, 'Total loss': 0.8148196112484701}
2022-11-23 01:13:21,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:21,656 INFO:     Epoch: 87
2022-11-23 01:13:22,443 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8086784373630177, 'Total loss': 0.8086784373630177} | train loss {'Reaction outcome loss': 0.8094192203735152, 'Total loss': 0.8094192203735152}
2022-11-23 01:13:22,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:22,443 INFO:     Epoch: 88
2022-11-23 01:13:23,221 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8051656755534086, 'Total loss': 0.8051656755534086} | train loss {'Reaction outcome loss': 0.8147130473967521, 'Total loss': 0.8147130473967521}
2022-11-23 01:13:23,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:23,221 INFO:     Epoch: 89
2022-11-23 01:13:24,011 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8506549136205153, 'Total loss': 0.8506549136205153} | train loss {'Reaction outcome loss': 0.8143701083477466, 'Total loss': 0.8143701083477466}
2022-11-23 01:13:24,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:24,012 INFO:     Epoch: 90
2022-11-23 01:13:24,789 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8180041963403876, 'Total loss': 0.8180041963403876} | train loss {'Reaction outcome loss': 0.8148435390283985, 'Total loss': 0.8148435390283985}
2022-11-23 01:13:24,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:24,789 INFO:     Epoch: 91
2022-11-23 01:13:25,563 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8140643056143414, 'Total loss': 0.8140643056143414} | train loss {'Reaction outcome loss': 0.8140553953426499, 'Total loss': 0.8140553953426499}
2022-11-23 01:13:25,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:25,564 INFO:     Epoch: 92
2022-11-23 01:13:26,353 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8203607113523916, 'Total loss': 0.8203607113523916} | train loss {'Reaction outcome loss': 0.816293120504387, 'Total loss': 0.816293120504387}
2022-11-23 01:13:26,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:26,353 INFO:     Epoch: 93
2022-11-23 01:13:27,197 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8189977285536852, 'Total loss': 0.8189977285536852} | train loss {'Reaction outcome loss': 0.8142805558539206, 'Total loss': 0.8142805558539206}
2022-11-23 01:13:27,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:27,197 INFO:     Epoch: 94
2022-11-23 01:13:27,982 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8054480200464075, 'Total loss': 0.8054480200464075} | train loss {'Reaction outcome loss': 0.8133323926839137, 'Total loss': 0.8133323926839137}
2022-11-23 01:13:27,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:27,982 INFO:     Epoch: 95
2022-11-23 01:13:28,757 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8046952343799851, 'Total loss': 0.8046952343799851} | train loss {'Reaction outcome loss': 0.8101611720217813, 'Total loss': 0.8101611720217813}
2022-11-23 01:13:28,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:28,758 INFO:     Epoch: 96
2022-11-23 01:13:29,571 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8258066576990214, 'Total loss': 0.8258066576990214} | train loss {'Reaction outcome loss': 0.8146053744900611, 'Total loss': 0.8146053744900611}
2022-11-23 01:13:29,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:29,571 INFO:     Epoch: 97
2022-11-23 01:13:30,409 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8004773232069883, 'Total loss': 0.8004773232069883} | train loss {'Reaction outcome loss': 0.8132434913948658, 'Total loss': 0.8132434913948658}
2022-11-23 01:13:30,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:30,409 INFO:     Epoch: 98
2022-11-23 01:13:31,213 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.813292455944148, 'Total loss': 0.813292455944148} | train loss {'Reaction outcome loss': 0.8088168515072715, 'Total loss': 0.8088168515072715}
2022-11-23 01:13:31,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:31,213 INFO:     Epoch: 99
2022-11-23 01:13:32,018 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8033167963678186, 'Total loss': 0.8033167963678186} | train loss {'Reaction outcome loss': 0.8130177410860215, 'Total loss': 0.8130177410860215}
2022-11-23 01:13:32,018 INFO:     Best model found after epoch 55 of 100.
2022-11-23 01:13:32,018 INFO:   Done with stage: TRAINING
2022-11-23 01:13:32,019 INFO:   Starting stage: EVALUATION
2022-11-23 01:13:32,138 INFO:   Done with stage: EVALUATION
2022-11-23 01:13:32,138 INFO:   Leaving out SEQ value Fold_9
2022-11-23 01:13:32,151 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-23 01:13:32,151 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:13:32,824 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:13:32,824 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:13:32,894 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:13:32,895 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:13:32,895 INFO:     No hyperparam tuning for this model
2022-11-23 01:13:32,895 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:13:32,895 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:13:32,896 INFO:     None feature selector for col prot
2022-11-23 01:13:32,896 INFO:     None feature selector for col prot
2022-11-23 01:13:32,896 INFO:     None feature selector for col prot
2022-11-23 01:13:32,896 INFO:     None feature selector for col chem
2022-11-23 01:13:32,896 INFO:     None feature selector for col chem
2022-11-23 01:13:32,897 INFO:     None feature selector for col chem
2022-11-23 01:13:32,897 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:13:32,897 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:13:32,898 INFO:     Number of params in model 168571
2022-11-23 01:13:32,901 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:13:32,902 INFO:   Starting stage: TRAINING
2022-11-23 01:13:32,959 INFO:     Val loss before train {'Reaction outcome loss': 1.0434975800189106, 'Total loss': 1.0434975800189106}
2022-11-23 01:13:32,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:32,960 INFO:     Epoch: 0
2022-11-23 01:13:33,755 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8708079132166776, 'Total loss': 0.8708079132166776} | train loss {'Reaction outcome loss': 0.8691681190412872, 'Total loss': 0.8691681190412872}
2022-11-23 01:13:33,755 INFO:     Found new best model at epoch 0
2022-11-23 01:13:33,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:33,756 INFO:     Epoch: 1
2022-11-23 01:13:34,602 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8431651463562791, 'Total loss': 0.8431651463562791} | train loss {'Reaction outcome loss': 0.8352635603778217, 'Total loss': 0.8352635603778217}
2022-11-23 01:13:34,602 INFO:     Found new best model at epoch 1
2022-11-23 01:13:34,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:34,603 INFO:     Epoch: 2
2022-11-23 01:13:35,389 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8499319052154367, 'Total loss': 0.8499319052154367} | train loss {'Reaction outcome loss': 0.8296896641351739, 'Total loss': 0.8296896641351739}
2022-11-23 01:13:35,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:35,389 INFO:     Epoch: 3
2022-11-23 01:13:36,204 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8448672213337638, 'Total loss': 0.8448672213337638} | train loss {'Reaction outcome loss': 0.8238230946112652, 'Total loss': 0.8238230946112652}
2022-11-23 01:13:36,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:36,206 INFO:     Epoch: 4
2022-11-23 01:13:36,967 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8399516987529668, 'Total loss': 0.8399516987529668} | train loss {'Reaction outcome loss': 0.8200460368273209, 'Total loss': 0.8200460368273209}
2022-11-23 01:13:36,967 INFO:     Found new best model at epoch 4
2022-11-23 01:13:36,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:36,968 INFO:     Epoch: 5
2022-11-23 01:13:37,780 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8834982636300001, 'Total loss': 0.8834982636300001} | train loss {'Reaction outcome loss': 0.8192776026774425, 'Total loss': 0.8192776026774425}
2022-11-23 01:13:37,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:37,780 INFO:     Epoch: 6
2022-11-23 01:13:38,568 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8401215293190696, 'Total loss': 0.8401215293190696} | train loss {'Reaction outcome loss': 0.8134848850114005, 'Total loss': 0.8134848850114005}
2022-11-23 01:13:38,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:38,569 INFO:     Epoch: 7
2022-11-23 01:13:39,348 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8350483802231875, 'Total loss': 0.8350483802231875} | train loss {'Reaction outcome loss': 0.811849222377855, 'Total loss': 0.811849222377855}
2022-11-23 01:13:39,348 INFO:     Found new best model at epoch 7
2022-11-23 01:13:39,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:39,349 INFO:     Epoch: 8
2022-11-23 01:13:40,160 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8512962297959761, 'Total loss': 0.8512962297959761} | train loss {'Reaction outcome loss': 0.8058868767047415, 'Total loss': 0.8058868767047415}
2022-11-23 01:13:40,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:40,161 INFO:     Epoch: 9
2022-11-23 01:13:40,953 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8389411297711459, 'Total loss': 0.8389411297711459} | train loss {'Reaction outcome loss': 0.800779621333492, 'Total loss': 0.800779621333492}
2022-11-23 01:13:40,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:40,954 INFO:     Epoch: 10
2022-11-23 01:13:41,710 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8503596836870367, 'Total loss': 0.8503596836870367} | train loss {'Reaction outcome loss': 0.8050824476748096, 'Total loss': 0.8050824476748096}
2022-11-23 01:13:41,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:41,711 INFO:     Epoch: 11
2022-11-23 01:13:42,495 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8708445910703052, 'Total loss': 0.8708445910703052} | train loss {'Reaction outcome loss': 0.8030750325747898, 'Total loss': 0.8030750325747898}
2022-11-23 01:13:42,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:42,496 INFO:     Epoch: 12
2022-11-23 01:13:43,263 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8596189523285086, 'Total loss': 0.8596189523285086} | train loss {'Reaction outcome loss': 0.7976377748713201, 'Total loss': 0.7976377748713201}
2022-11-23 01:13:43,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:43,263 INFO:     Epoch: 13
2022-11-23 01:13:44,022 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8630070374770598, 'Total loss': 0.8630070374770598} | train loss {'Reaction outcome loss': 0.8008514875051926, 'Total loss': 0.8008514875051926}
2022-11-23 01:13:44,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:44,022 INFO:     Epoch: 14
2022-11-23 01:13:44,797 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8389735438606956, 'Total loss': 0.8389735438606956} | train loss {'Reaction outcome loss': 0.8014348054418758, 'Total loss': 0.8014348054418758}
2022-11-23 01:13:44,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:44,797 INFO:     Epoch: 15
2022-11-23 01:13:45,570 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8674038987268101, 'Total loss': 0.8674038987268101} | train loss {'Reaction outcome loss': 0.8012718290698772, 'Total loss': 0.8012718290698772}
2022-11-23 01:13:45,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:45,570 INFO:     Epoch: 16
2022-11-23 01:13:46,352 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8360887847163461, 'Total loss': 0.8360887847163461} | train loss {'Reaction outcome loss': 0.8004020135013424, 'Total loss': 0.8004020135013424}
2022-11-23 01:13:46,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:46,352 INFO:     Epoch: 17
2022-11-23 01:13:47,167 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8516861755739559, 'Total loss': 0.8516861755739559} | train loss {'Reaction outcome loss': 0.7997780892313743, 'Total loss': 0.7997780892313743}
2022-11-23 01:13:47,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:47,167 INFO:     Epoch: 18
2022-11-23 01:13:48,003 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8532171445814046, 'Total loss': 0.8532171445814046} | train loss {'Reaction outcome loss': 0.8013818333343584, 'Total loss': 0.8013818333343584}
2022-11-23 01:13:48,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:48,004 INFO:     Epoch: 19
2022-11-23 01:13:48,752 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8394034152681177, 'Total loss': 0.8394034152681177} | train loss {'Reaction outcome loss': 0.7968514056838288, 'Total loss': 0.7968514056838288}
2022-11-23 01:13:48,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:48,752 INFO:     Epoch: 20
2022-11-23 01:13:49,544 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8632951080799103, 'Total loss': 0.8632951080799103} | train loss {'Reaction outcome loss': 0.7993245752490297, 'Total loss': 0.7993245752490297}
2022-11-23 01:13:49,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:49,545 INFO:     Epoch: 21
2022-11-23 01:13:50,392 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8249248780987479, 'Total loss': 0.8249248780987479} | train loss {'Reaction outcome loss': 0.7994424048735171, 'Total loss': 0.7994424048735171}
2022-11-23 01:13:50,392 INFO:     Found new best model at epoch 21
2022-11-23 01:13:50,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:50,393 INFO:     Epoch: 22
2022-11-23 01:13:51,207 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8567545034668662, 'Total loss': 0.8567545034668662} | train loss {'Reaction outcome loss': 0.7994960326321271, 'Total loss': 0.7994960326321271}
2022-11-23 01:13:51,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:51,207 INFO:     Epoch: 23
2022-11-23 01:13:52,042 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8338000307028944, 'Total loss': 0.8338000307028944} | train loss {'Reaction outcome loss': 0.7972013854250616, 'Total loss': 0.7972013854250616}
2022-11-23 01:13:52,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:52,043 INFO:     Epoch: 24
2022-11-23 01:13:52,834 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8668114407496019, 'Total loss': 0.8668114407496019} | train loss {'Reaction outcome loss': 0.7963777711196821, 'Total loss': 0.7963777711196821}
2022-11-23 01:13:52,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:52,834 INFO:     Epoch: 25
2022-11-23 01:13:53,632 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8229426646774466, 'Total loss': 0.8229426646774466} | train loss {'Reaction outcome loss': 0.7968871768640012, 'Total loss': 0.7968871768640012}
2022-11-23 01:13:53,632 INFO:     Found new best model at epoch 25
2022-11-23 01:13:53,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:53,633 INFO:     Epoch: 26
2022-11-23 01:13:54,412 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8297802717848257, 'Total loss': 0.8297802717848257} | train loss {'Reaction outcome loss': 0.7985504433816794, 'Total loss': 0.7985504433816794}
2022-11-23 01:13:54,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:54,413 INFO:     Epoch: 27
2022-11-23 01:13:55,215 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8350496928800236, 'Total loss': 0.8350496928800236} | train loss {'Reaction outcome loss': 0.7961044798091966, 'Total loss': 0.7961044798091966}
2022-11-23 01:13:55,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:55,216 INFO:     Epoch: 28
2022-11-23 01:13:56,037 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8369272513823076, 'Total loss': 0.8369272513823076} | train loss {'Reaction outcome loss': 0.8008743288565655, 'Total loss': 0.8008743288565655}
2022-11-23 01:13:56,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:56,038 INFO:     Epoch: 29
2022-11-23 01:13:56,819 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8350024331699718, 'Total loss': 0.8350024331699718} | train loss {'Reaction outcome loss': 0.7989277343360746, 'Total loss': 0.7989277343360746}
2022-11-23 01:13:56,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:56,820 INFO:     Epoch: 30
2022-11-23 01:13:57,606 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8359326435761019, 'Total loss': 0.8359326435761019} | train loss {'Reaction outcome loss': 0.7979922232579212, 'Total loss': 0.7979922232579212}
2022-11-23 01:13:57,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:57,606 INFO:     Epoch: 31
2022-11-23 01:13:58,366 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8614461679350246, 'Total loss': 0.8614461679350246} | train loss {'Reaction outcome loss': 0.796938501207196, 'Total loss': 0.796938501207196}
2022-11-23 01:13:58,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:58,367 INFO:     Epoch: 32
2022-11-23 01:13:59,156 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8337296321988106, 'Total loss': 0.8337296321988106} | train loss {'Reaction outcome loss': 0.7963161050056925, 'Total loss': 0.7963161050056925}
2022-11-23 01:13:59,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:59,156 INFO:     Epoch: 33
2022-11-23 01:13:59,945 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8531335944479163, 'Total loss': 0.8531335944479163} | train loss {'Reaction outcome loss': 0.7940622677608412, 'Total loss': 0.7940622677608412}
2022-11-23 01:13:59,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:13:59,946 INFO:     Epoch: 34
2022-11-23 01:14:00,797 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8477743897925724, 'Total loss': 0.8477743897925724} | train loss {'Reaction outcome loss': 0.8007973837609194, 'Total loss': 0.8007973837609194}
2022-11-23 01:14:00,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:00,797 INFO:     Epoch: 35
2022-11-23 01:14:01,608 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8330181633884256, 'Total loss': 0.8330181633884256} | train loss {'Reaction outcome loss': 0.8003727678133516, 'Total loss': 0.8003727678133516}
2022-11-23 01:14:01,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:01,609 INFO:     Epoch: 36
2022-11-23 01:14:02,444 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8798458339138464, 'Total loss': 0.8798458339138464} | train loss {'Reaction outcome loss': 0.7978850729611455, 'Total loss': 0.7978850729611455}
2022-11-23 01:14:02,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:02,444 INFO:     Epoch: 37
2022-11-23 01:14:03,234 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.833006123250181, 'Total loss': 0.833006123250181} | train loss {'Reaction outcome loss': 0.8001482733658382, 'Total loss': 0.8001482733658382}
2022-11-23 01:14:03,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:03,234 INFO:     Epoch: 38
2022-11-23 01:14:04,049 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8468950472094796, 'Total loss': 0.8468950472094796} | train loss {'Reaction outcome loss': 0.7986494021756309, 'Total loss': 0.7986494021756309}
2022-11-23 01:14:04,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:04,050 INFO:     Epoch: 39
2022-11-23 01:14:04,892 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8782913969321684, 'Total loss': 0.8782913969321684} | train loss {'Reaction outcome loss': 0.7963205212233018, 'Total loss': 0.7963205212233018}
2022-11-23 01:14:04,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:04,893 INFO:     Epoch: 40
2022-11-23 01:14:05,728 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8664693331176584, 'Total loss': 0.8664693331176584} | train loss {'Reaction outcome loss': 0.794782390399855, 'Total loss': 0.794782390399855}
2022-11-23 01:14:05,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:05,728 INFO:     Epoch: 41
2022-11-23 01:14:06,509 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8519512293013659, 'Total loss': 0.8519512293013659} | train loss {'Reaction outcome loss': 0.7985439040222947, 'Total loss': 0.7985439040222947}
2022-11-23 01:14:06,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:06,510 INFO:     Epoch: 42
2022-11-23 01:14:07,284 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8493999879468571, 'Total loss': 0.8493999879468571} | train loss {'Reaction outcome loss': 0.8000995745464247, 'Total loss': 0.8000995745464247}
2022-11-23 01:14:07,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:07,285 INFO:     Epoch: 43
2022-11-23 01:14:08,070 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8597185760736465, 'Total loss': 0.8597185760736465} | train loss {'Reaction outcome loss': 0.7928511325193911, 'Total loss': 0.7928511325193911}
2022-11-23 01:14:08,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:08,070 INFO:     Epoch: 44
2022-11-23 01:14:08,854 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8509953672235663, 'Total loss': 0.8509953672235663} | train loss {'Reaction outcome loss': 0.7934906719898691, 'Total loss': 0.7934906719898691}
2022-11-23 01:14:08,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:08,854 INFO:     Epoch: 45
2022-11-23 01:14:09,639 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8279223160987551, 'Total loss': 0.8279223160987551} | train loss {'Reaction outcome loss': 0.8025212565246893, 'Total loss': 0.8025212565246893}
2022-11-23 01:14:09,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:09,639 INFO:     Epoch: 46
2022-11-23 01:14:10,436 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8414678295904939, 'Total loss': 0.8414678295904939} | train loss {'Reaction outcome loss': 0.7952837830903579, 'Total loss': 0.7952837830903579}
2022-11-23 01:14:10,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:10,436 INFO:     Epoch: 47
2022-11-23 01:14:11,209 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8489620685577393, 'Total loss': 0.8489620685577393} | train loss {'Reaction outcome loss': 0.7953664898872376, 'Total loss': 0.7953664898872376}
2022-11-23 01:14:11,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:11,209 INFO:     Epoch: 48
2022-11-23 01:14:12,004 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.844954096458175, 'Total loss': 0.844954096458175} | train loss {'Reaction outcome loss': 0.7988744699225134, 'Total loss': 0.7988744699225134}
2022-11-23 01:14:12,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:12,005 INFO:     Epoch: 49
2022-11-23 01:14:12,814 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8524620167233727, 'Total loss': 0.8524620167233727} | train loss {'Reaction outcome loss': 0.795129276781666, 'Total loss': 0.795129276781666}
2022-11-23 01:14:12,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:12,814 INFO:     Epoch: 50
2022-11-23 01:14:13,662 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8257763209668073, 'Total loss': 0.8257763209668073} | train loss {'Reaction outcome loss': 0.7932413131606822, 'Total loss': 0.7932413131606822}
2022-11-23 01:14:13,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:13,663 INFO:     Epoch: 51
2022-11-23 01:14:14,465 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8233968154950575, 'Total loss': 0.8233968154950575} | train loss {'Reaction outcome loss': 0.7916577764919825, 'Total loss': 0.7916577764919825}
2022-11-23 01:14:14,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:14,465 INFO:     Epoch: 52
2022-11-23 01:14:15,286 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.839584159580144, 'Total loss': 0.839584159580144} | train loss {'Reaction outcome loss': 0.7924160552268126, 'Total loss': 0.7924160552268126}
2022-11-23 01:14:15,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:15,286 INFO:     Epoch: 53
2022-11-23 01:14:16,073 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.838439130647616, 'Total loss': 0.838439130647616} | train loss {'Reaction outcome loss': 0.7968157678234334, 'Total loss': 0.7968157678234334}
2022-11-23 01:14:16,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:16,073 INFO:     Epoch: 54
2022-11-23 01:14:16,864 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8306126113642346, 'Total loss': 0.8306126113642346} | train loss {'Reaction outcome loss': 0.7964196728200329, 'Total loss': 0.7964196728200329}
2022-11-23 01:14:16,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:16,864 INFO:     Epoch: 55
2022-11-23 01:14:17,650 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.841035564176061, 'Total loss': 0.841035564176061} | train loss {'Reaction outcome loss': 0.7922125468448716, 'Total loss': 0.7922125468448716}
2022-11-23 01:14:17,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:17,651 INFO:     Epoch: 56
2022-11-23 01:14:18,463 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8356285379691557, 'Total loss': 0.8356285379691557} | train loss {'Reaction outcome loss': 0.7938285142791515, 'Total loss': 0.7938285142791515}
2022-11-23 01:14:18,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:18,463 INFO:     Epoch: 57
2022-11-23 01:14:19,264 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8290340277281675, 'Total loss': 0.8290340277281675} | train loss {'Reaction outcome loss': 0.7978204094633764, 'Total loss': 0.7978204094633764}
2022-11-23 01:14:19,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:19,265 INFO:     Epoch: 58
2022-11-23 01:14:20,140 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8744218715212562, 'Total loss': 0.8744218715212562} | train loss {'Reaction outcome loss': 0.7959019250407511, 'Total loss': 0.7959019250407511}
2022-11-23 01:14:20,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:20,140 INFO:     Epoch: 59
2022-11-23 01:14:20,906 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8400445621122014, 'Total loss': 0.8400445621122014} | train loss {'Reaction outcome loss': 0.7929978547047596, 'Total loss': 0.7929978547047596}
2022-11-23 01:14:20,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:20,906 INFO:     Epoch: 60
2022-11-23 01:14:21,686 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8287174735556949, 'Total loss': 0.8287174735556949} | train loss {'Reaction outcome loss': 0.7988275542551158, 'Total loss': 0.7988275542551158}
2022-11-23 01:14:21,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:21,686 INFO:     Epoch: 61
2022-11-23 01:14:22,463 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8372610414570029, 'Total loss': 0.8372610414570029} | train loss {'Reaction outcome loss': 0.7930661608978193, 'Total loss': 0.7930661608978193}
2022-11-23 01:14:22,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:22,464 INFO:     Epoch: 62
2022-11-23 01:14:23,292 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8790626972913742, 'Total loss': 0.8790626972913742} | train loss {'Reaction outcome loss': 0.7898280913732489, 'Total loss': 0.7898280913732489}
2022-11-23 01:14:23,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:23,293 INFO:     Epoch: 63
2022-11-23 01:14:24,065 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.820522125471722, 'Total loss': 0.820522125471722} | train loss {'Reaction outcome loss': 0.7954324300191841, 'Total loss': 0.7954324300191841}
2022-11-23 01:14:24,065 INFO:     Found new best model at epoch 63
2022-11-23 01:14:24,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:24,066 INFO:     Epoch: 64
2022-11-23 01:14:24,879 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8191150216893717, 'Total loss': 0.8191150216893717} | train loss {'Reaction outcome loss': 0.7943692871502468, 'Total loss': 0.7943692871502468}
2022-11-23 01:14:24,879 INFO:     Found new best model at epoch 64
2022-11-23 01:14:24,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:24,880 INFO:     Epoch: 65
2022-11-23 01:14:25,727 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8161313730207357, 'Total loss': 0.8161313730207357} | train loss {'Reaction outcome loss': 0.793370786978274, 'Total loss': 0.793370786978274}
2022-11-23 01:14:25,728 INFO:     Found new best model at epoch 65
2022-11-23 01:14:25,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:25,729 INFO:     Epoch: 66
2022-11-23 01:14:26,532 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8262444328178059, 'Total loss': 0.8262444328178059} | train loss {'Reaction outcome loss': 0.795101467200688, 'Total loss': 0.795101467200688}
2022-11-23 01:14:26,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:26,532 INFO:     Epoch: 67
2022-11-23 01:14:27,371 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.815917812965133, 'Total loss': 0.815917812965133} | train loss {'Reaction outcome loss': 0.7957981232477694, 'Total loss': 0.7957981232477694}
2022-11-23 01:14:27,371 INFO:     Found new best model at epoch 67
2022-11-23 01:14:27,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:27,372 INFO:     Epoch: 68
2022-11-23 01:14:28,170 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8575483438643542, 'Total loss': 0.8575483438643542} | train loss {'Reaction outcome loss': 0.793160383616175, 'Total loss': 0.793160383616175}
2022-11-23 01:14:28,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:28,171 INFO:     Epoch: 69
2022-11-23 01:14:28,977 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.849675403399901, 'Total loss': 0.849675403399901} | train loss {'Reaction outcome loss': 0.7922342565594888, 'Total loss': 0.7922342565594888}
2022-11-23 01:14:28,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:28,977 INFO:     Epoch: 70
2022-11-23 01:14:29,778 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8363844935189594, 'Total loss': 0.8363844935189594} | train loss {'Reaction outcome loss': 0.7924201854637691, 'Total loss': 0.7924201854637691}
2022-11-23 01:14:29,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:29,778 INFO:     Epoch: 71
2022-11-23 01:14:30,601 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8365355005318468, 'Total loss': 0.8365355005318468} | train loss {'Reaction outcome loss': 0.7969074181147984, 'Total loss': 0.7969074181147984}
2022-11-23 01:14:30,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:30,601 INFO:     Epoch: 72
2022-11-23 01:14:31,376 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8333074355667288, 'Total loss': 0.8333074355667288} | train loss {'Reaction outcome loss': 0.7891529620910177, 'Total loss': 0.7891529620910177}
2022-11-23 01:14:31,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:31,377 INFO:     Epoch: 73
2022-11-23 01:14:32,181 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8158658790317449, 'Total loss': 0.8158658790317449} | train loss {'Reaction outcome loss': 0.8002217982496534, 'Total loss': 0.8002217982496534}
2022-11-23 01:14:32,181 INFO:     Found new best model at epoch 73
2022-11-23 01:14:32,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:32,182 INFO:     Epoch: 74
2022-11-23 01:14:32,989 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8508888496593996, 'Total loss': 0.8508888496593996} | train loss {'Reaction outcome loss': 0.7926810638028748, 'Total loss': 0.7926810638028748}
2022-11-23 01:14:32,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:32,989 INFO:     Epoch: 75
2022-11-23 01:14:33,800 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8450099575248632, 'Total loss': 0.8450099575248632} | train loss {'Reaction outcome loss': 0.7942749517304557, 'Total loss': 0.7942749517304557}
2022-11-23 01:14:33,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:33,800 INFO:     Epoch: 76
2022-11-23 01:14:34,630 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.82322212647308, 'Total loss': 0.82322212647308} | train loss {'Reaction outcome loss': 0.7906310827148204, 'Total loss': 0.7906310827148204}
2022-11-23 01:14:34,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:34,630 INFO:     Epoch: 77
2022-11-23 01:14:35,427 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8133007125421003, 'Total loss': 0.8133007125421003} | train loss {'Reaction outcome loss': 0.7933346252052151, 'Total loss': 0.7933346252052151}
2022-11-23 01:14:35,427 INFO:     Found new best model at epoch 77
2022-11-23 01:14:35,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:35,428 INFO:     Epoch: 78
2022-11-23 01:14:36,222 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8480648039416834, 'Total loss': 0.8480648039416834} | train loss {'Reaction outcome loss': 0.7914798814423231, 'Total loss': 0.7914798814423231}
2022-11-23 01:14:36,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:36,223 INFO:     Epoch: 79
2022-11-23 01:14:37,002 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8479808433489366, 'Total loss': 0.8479808433489366} | train loss {'Reaction outcome loss': 0.7885573725311124, 'Total loss': 0.7885573725311124}
2022-11-23 01:14:37,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:37,003 INFO:     Epoch: 80
2022-11-23 01:14:37,804 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8253036520697854, 'Total loss': 0.8253036520697854} | train loss {'Reaction outcome loss': 0.7961384426574318, 'Total loss': 0.7961384426574318}
2022-11-23 01:14:37,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:37,804 INFO:     Epoch: 81
2022-11-23 01:14:38,593 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8299410228024829, 'Total loss': 0.8299410228024829} | train loss {'Reaction outcome loss': 0.7896567323986365, 'Total loss': 0.7896567323986365}
2022-11-23 01:14:38,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:38,594 INFO:     Epoch: 82
2022-11-23 01:14:39,416 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.844395408576185, 'Total loss': 0.844395408576185} | train loss {'Reaction outcome loss': 0.789074256103866, 'Total loss': 0.789074256103866}
2022-11-23 01:14:39,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:39,416 INFO:     Epoch: 83
2022-11-23 01:14:40,239 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8396654535423625, 'Total loss': 0.8396654535423625} | train loss {'Reaction outcome loss': 0.7925849009533318, 'Total loss': 0.7925849009533318}
2022-11-23 01:14:40,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:40,239 INFO:     Epoch: 84
2022-11-23 01:14:41,037 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8272194726900621, 'Total loss': 0.8272194726900621} | train loss {'Reaction outcome loss': 0.7920121071289997, 'Total loss': 0.7920121071289997}
2022-11-23 01:14:41,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:41,038 INFO:     Epoch: 85
2022-11-23 01:14:41,817 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8348617404699326, 'Total loss': 0.8348617404699326} | train loss {'Reaction outcome loss': 0.7884277194130177, 'Total loss': 0.7884277194130177}
2022-11-23 01:14:41,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:41,818 INFO:     Epoch: 86
2022-11-23 01:14:42,580 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.895751332694834, 'Total loss': 0.895751332694834} | train loss {'Reaction outcome loss': 0.7864606145693331, 'Total loss': 0.7864606145693331}
2022-11-23 01:14:42,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:42,580 INFO:     Epoch: 87
2022-11-23 01:14:43,356 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8193554309281436, 'Total loss': 0.8193554309281436} | train loss {'Reaction outcome loss': 0.7901812698768109, 'Total loss': 0.7901812698768109}
2022-11-23 01:14:43,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:43,357 INFO:     Epoch: 88
2022-11-23 01:14:44,142 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8451735715974461, 'Total loss': 0.8451735715974461} | train loss {'Reaction outcome loss': 0.7906841981167696, 'Total loss': 0.7906841981167696}
2022-11-23 01:14:44,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:44,142 INFO:     Epoch: 89
2022-11-23 01:14:44,933 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8444566821510141, 'Total loss': 0.8444566821510141} | train loss {'Reaction outcome loss': 0.7857099518483999, 'Total loss': 0.7857099518483999}
2022-11-23 01:14:44,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:44,934 INFO:     Epoch: 90
2022-11-23 01:14:45,720 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8340199318799105, 'Total loss': 0.8340199318799105} | train loss {'Reaction outcome loss': 0.7816304420938297, 'Total loss': 0.7816304420938297}
2022-11-23 01:14:45,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:45,720 INFO:     Epoch: 91
2022-11-23 01:14:46,492 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8206516165624965, 'Total loss': 0.8206516165624965} | train loss {'Reaction outcome loss': 0.7836263840295831, 'Total loss': 0.7836263840295831}
2022-11-23 01:14:46,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:46,492 INFO:     Epoch: 92
2022-11-23 01:14:47,322 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8186561742966826, 'Total loss': 0.8186561742966826} | train loss {'Reaction outcome loss': 0.782098076781448, 'Total loss': 0.782098076781448}
2022-11-23 01:14:47,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:47,322 INFO:     Epoch: 93
2022-11-23 01:14:48,166 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8196016428145495, 'Total loss': 0.8196016428145495} | train loss {'Reaction outcome loss': 0.7846757472777853, 'Total loss': 0.7846757472777853}
2022-11-23 01:14:48,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:48,166 INFO:     Epoch: 94
2022-11-23 01:14:48,962 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8254029740664092, 'Total loss': 0.8254029740664092} | train loss {'Reaction outcome loss': 0.7814801742835921, 'Total loss': 0.7814801742835921}
2022-11-23 01:14:48,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:48,962 INFO:     Epoch: 95
2022-11-23 01:14:49,719 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8378709893334996, 'Total loss': 0.8378709893334996} | train loss {'Reaction outcome loss': 0.781530054126467, 'Total loss': 0.781530054126467}
2022-11-23 01:14:49,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:49,719 INFO:     Epoch: 96
2022-11-23 01:14:50,517 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8443299972198226, 'Total loss': 0.8443299972198226} | train loss {'Reaction outcome loss': 0.779479322628099, 'Total loss': 0.779479322628099}
2022-11-23 01:14:50,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:50,517 INFO:     Epoch: 97
2022-11-23 01:14:51,323 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8120732828974724, 'Total loss': 0.8120732828974724} | train loss {'Reaction outcome loss': 0.772359838899301, 'Total loss': 0.772359838899301}
2022-11-23 01:14:51,323 INFO:     Found new best model at epoch 97
2022-11-23 01:14:51,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:51,324 INFO:     Epoch: 98
2022-11-23 01:14:52,150 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8318994411013343, 'Total loss': 0.8318994411013343} | train loss {'Reaction outcome loss': 0.7826784547494382, 'Total loss': 0.7826784547494382}
2022-11-23 01:14:52,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:52,150 INFO:     Epoch: 99
2022-11-23 01:14:52,918 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8134298290718686, 'Total loss': 0.8134298290718686} | train loss {'Reaction outcome loss': 0.7747651631734809, 'Total loss': 0.7747651631734809}
2022-11-23 01:14:52,918 INFO:     Best model found after epoch 98 of 100.
2022-11-23 01:14:52,918 INFO:   Done with stage: TRAINING
2022-11-23 01:14:52,918 INFO:   Starting stage: EVALUATION
2022-11-23 01:14:53,051 INFO:   Done with stage: EVALUATION
2022-11-23 01:14:53,060 INFO:   Leaving out SEQ value Fold_0
2022-11-23 01:14:53,073 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-23 01:14:53,073 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:14:53,733 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:14:53,733 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:14:53,803 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:14:53,803 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:14:53,803 INFO:     No hyperparam tuning for this model
2022-11-23 01:14:53,803 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:14:53,803 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:14:53,804 INFO:     None feature selector for col prot
2022-11-23 01:14:53,804 INFO:     None feature selector for col prot
2022-11-23 01:14:53,805 INFO:     None feature selector for col prot
2022-11-23 01:14:53,805 INFO:     None feature selector for col chem
2022-11-23 01:14:53,805 INFO:     None feature selector for col chem
2022-11-23 01:14:53,805 INFO:     None feature selector for col chem
2022-11-23 01:14:53,805 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:14:53,805 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:14:53,807 INFO:     Number of params in model 168571
2022-11-23 01:14:53,810 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:14:53,810 INFO:   Starting stage: TRAINING
2022-11-23 01:14:53,868 INFO:     Val loss before train {'Reaction outcome loss': 0.9836149276657538, 'Total loss': 0.9836149276657538}
2022-11-23 01:14:53,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:53,868 INFO:     Epoch: 0
2022-11-23 01:14:54,647 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8198641978881576, 'Total loss': 0.8198641978881576} | train loss {'Reaction outcome loss': 0.886605435974744, 'Total loss': 0.886605435974744}
2022-11-23 01:14:54,647 INFO:     Found new best model at epoch 0
2022-11-23 01:14:54,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:54,648 INFO:     Epoch: 1
2022-11-23 01:14:55,403 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8003889999606393, 'Total loss': 0.8003889999606393} | train loss {'Reaction outcome loss': 0.8499086226735796, 'Total loss': 0.8499086226735796}
2022-11-23 01:14:55,404 INFO:     Found new best model at epoch 1
2022-11-23 01:14:55,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:55,404 INFO:     Epoch: 2
2022-11-23 01:14:56,186 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.792727415534583, 'Total loss': 0.792727415534583} | train loss {'Reaction outcome loss': 0.8399163341035648, 'Total loss': 0.8399163341035648}
2022-11-23 01:14:56,186 INFO:     Found new best model at epoch 2
2022-11-23 01:14:56,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:56,186 INFO:     Epoch: 3
2022-11-23 01:14:56,978 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7791881832209501, 'Total loss': 0.7791881832209501} | train loss {'Reaction outcome loss': 0.8324054808032756, 'Total loss': 0.8324054808032756}
2022-11-23 01:14:56,979 INFO:     Found new best model at epoch 3
2022-11-23 01:14:56,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:56,980 INFO:     Epoch: 4
2022-11-23 01:14:57,767 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7953751581636342, 'Total loss': 0.7953751581636342} | train loss {'Reaction outcome loss': 0.8297477725817233, 'Total loss': 0.8297477725817233}
2022-11-23 01:14:57,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:57,768 INFO:     Epoch: 5
2022-11-23 01:14:58,555 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.790832633999261, 'Total loss': 0.790832633999261} | train loss {'Reaction outcome loss': 0.8276535778629537, 'Total loss': 0.8276535778629537}
2022-11-23 01:14:58,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:58,556 INFO:     Epoch: 6
2022-11-23 01:14:59,343 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7921394170685248, 'Total loss': 0.7921394170685248} | train loss {'Reaction outcome loss': 0.8218854737525083, 'Total loss': 0.8218854737525083}
2022-11-23 01:14:59,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:14:59,343 INFO:     Epoch: 7
2022-11-23 01:15:00,158 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8046506548469717, 'Total loss': 0.8046506548469717} | train loss {'Reaction outcome loss': 0.8265265464782715, 'Total loss': 0.8265265464782715}
2022-11-23 01:15:00,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:00,158 INFO:     Epoch: 8
2022-11-23 01:15:00,948 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7906874066049402, 'Total loss': 0.7906874066049402} | train loss {'Reaction outcome loss': 0.8233074403538996, 'Total loss': 0.8233074403538996}
2022-11-23 01:15:00,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:00,948 INFO:     Epoch: 9
2022-11-23 01:15:01,768 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7893892032178965, 'Total loss': 0.7893892032178965} | train loss {'Reaction outcome loss': 0.8196821297918048, 'Total loss': 0.8196821297918048}
2022-11-23 01:15:01,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:01,769 INFO:     Epoch: 10
2022-11-23 01:15:02,608 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7567749511111866, 'Total loss': 0.7567749511111866} | train loss {'Reaction outcome loss': 0.8185447782886272, 'Total loss': 0.8185447782886272}
2022-11-23 01:15:02,608 INFO:     Found new best model at epoch 10
2022-11-23 01:15:02,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:02,609 INFO:     Epoch: 11
2022-11-23 01:15:03,378 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7724137191068042, 'Total loss': 0.7724137191068042} | train loss {'Reaction outcome loss': 0.8201906895150943, 'Total loss': 0.8201906895150943}
2022-11-23 01:15:03,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:03,379 INFO:     Epoch: 12
2022-11-23 01:15:04,151 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7538495625961911, 'Total loss': 0.7538495625961911} | train loss {'Reaction outcome loss': 0.8226645243411161, 'Total loss': 0.8226645243411161}
2022-11-23 01:15:04,151 INFO:     Found new best model at epoch 12
2022-11-23 01:15:04,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:04,152 INFO:     Epoch: 13
2022-11-23 01:15:04,947 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8063739138570699, 'Total loss': 0.8063739138570699} | train loss {'Reaction outcome loss': 0.8199362791314417, 'Total loss': 0.8199362791314417}
2022-11-23 01:15:04,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:04,948 INFO:     Epoch: 14
2022-11-23 01:15:05,754 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7739520750262521, 'Total loss': 0.7739520750262521} | train loss {'Reaction outcome loss': 0.8146696645386365, 'Total loss': 0.8146696645386365}
2022-11-23 01:15:05,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:05,755 INFO:     Epoch: 15
2022-11-23 01:15:06,543 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7932241626761176, 'Total loss': 0.7932241626761176} | train loss {'Reaction outcome loss': 0.8155263169687621, 'Total loss': 0.8155263169687621}
2022-11-23 01:15:06,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:06,543 INFO:     Epoch: 16
2022-11-23 01:15:07,369 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7724195935509421, 'Total loss': 0.7724195935509421} | train loss {'Reaction outcome loss': 0.8187172875112417, 'Total loss': 0.8187172875112417}
2022-11-23 01:15:07,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:07,369 INFO:     Epoch: 17
2022-11-23 01:15:08,161 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7738229212435809, 'Total loss': 0.7738229212435809} | train loss {'Reaction outcome loss': 0.8179949262920692, 'Total loss': 0.8179949262920692}
2022-11-23 01:15:08,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:08,161 INFO:     Epoch: 18
2022-11-23 01:15:08,959 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7909168059175665, 'Total loss': 0.7909168059175665} | train loss {'Reaction outcome loss': 0.8165644015584673, 'Total loss': 0.8165644015584673}
2022-11-23 01:15:08,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:08,959 INFO:     Epoch: 19
2022-11-23 01:15:09,795 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7783292528580535, 'Total loss': 0.7783292528580535} | train loss {'Reaction outcome loss': 0.8140187349854683, 'Total loss': 0.8140187349854683}
2022-11-23 01:15:09,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:09,796 INFO:     Epoch: 20
2022-11-23 01:15:10,613 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8017789464105259, 'Total loss': 0.8017789464105259} | train loss {'Reaction outcome loss': 0.8186375236024662, 'Total loss': 0.8186375236024662}
2022-11-23 01:15:10,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:10,613 INFO:     Epoch: 21
2022-11-23 01:15:11,391 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7541365352543917, 'Total loss': 0.7541365352543917} | train loss {'Reaction outcome loss': 0.8138826517426238, 'Total loss': 0.8138826517426238}
2022-11-23 01:15:11,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:11,392 INFO:     Epoch: 22
2022-11-23 01:15:12,196 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.765265820378607, 'Total loss': 0.765265820378607} | train loss {'Reaction outcome loss': 0.8139423386174806, 'Total loss': 0.8139423386174806}
2022-11-23 01:15:12,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:12,196 INFO:     Epoch: 23
2022-11-23 01:15:13,042 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7685584913600575, 'Total loss': 0.7685584913600575} | train loss {'Reaction outcome loss': 0.816525743810498, 'Total loss': 0.816525743810498}
2022-11-23 01:15:13,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:13,043 INFO:     Epoch: 24
2022-11-23 01:15:13,867 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7744594995271076, 'Total loss': 0.7744594995271076} | train loss {'Reaction outcome loss': 0.8172651080452666, 'Total loss': 0.8172651080452666}
2022-11-23 01:15:13,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:13,868 INFO:     Epoch: 25
2022-11-23 01:15:14,670 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7663791105151176, 'Total loss': 0.7663791105151176} | train loss {'Reaction outcome loss': 0.8174740232983414, 'Total loss': 0.8174740232983414}
2022-11-23 01:15:14,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:14,670 INFO:     Epoch: 26
2022-11-23 01:15:15,445 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7814185273918238, 'Total loss': 0.7814185273918238} | train loss {'Reaction outcome loss': 0.8090667818273817, 'Total loss': 0.8090667818273817}
2022-11-23 01:15:15,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:15,446 INFO:     Epoch: 27
2022-11-23 01:15:16,251 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7618431570855054, 'Total loss': 0.7618431570855054} | train loss {'Reaction outcome loss': 0.818324021903836, 'Total loss': 0.818324021903836}
2022-11-23 01:15:16,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:16,252 INFO:     Epoch: 28
2022-11-23 01:15:17,038 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7736687314781275, 'Total loss': 0.7736687314781275} | train loss {'Reaction outcome loss': 0.8128621283842593, 'Total loss': 0.8128621283842593}
2022-11-23 01:15:17,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:17,038 INFO:     Epoch: 29
2022-11-23 01:15:17,824 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7790091464465315, 'Total loss': 0.7790091464465315} | train loss {'Reaction outcome loss': 0.8166029005634542, 'Total loss': 0.8166029005634542}
2022-11-23 01:15:17,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:17,824 INFO:     Epoch: 30
2022-11-23 01:15:18,603 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7666467324915257, 'Total loss': 0.7666467324915257} | train loss {'Reaction outcome loss': 0.8093472018533824, 'Total loss': 0.8093472018533824}
2022-11-23 01:15:18,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:18,603 INFO:     Epoch: 31
2022-11-23 01:15:19,370 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7694821974093263, 'Total loss': 0.7694821974093263} | train loss {'Reaction outcome loss': 0.8132091021051212, 'Total loss': 0.8132091021051212}
2022-11-23 01:15:19,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:19,370 INFO:     Epoch: 32
2022-11-23 01:15:20,182 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7739600349556316, 'Total loss': 0.7739600349556316} | train loss {'Reaction outcome loss': 0.8210044928959438, 'Total loss': 0.8210044928959438}
2022-11-23 01:15:20,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:20,182 INFO:     Epoch: 33
2022-11-23 01:15:20,976 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7817810530012305, 'Total loss': 0.7817810530012305} | train loss {'Reaction outcome loss': 0.8174860468932561, 'Total loss': 0.8174860468932561}
2022-11-23 01:15:20,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:20,976 INFO:     Epoch: 34
2022-11-23 01:15:21,771 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7792664116079157, 'Total loss': 0.7792664116079157} | train loss {'Reaction outcome loss': 0.8109690117592714, 'Total loss': 0.8109690117592714}
2022-11-23 01:15:21,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:21,772 INFO:     Epoch: 35
2022-11-23 01:15:22,536 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7668433798985048, 'Total loss': 0.7668433798985048} | train loss {'Reaction outcome loss': 0.8191654160314676, 'Total loss': 0.8191654160314676}
2022-11-23 01:15:22,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:22,536 INFO:     Epoch: 36
2022-11-23 01:15:23,323 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8075673343105749, 'Total loss': 0.8075673343105749} | train loss {'Reaction outcome loss': 0.8122771601287686, 'Total loss': 0.8122771601287686}
2022-11-23 01:15:23,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:23,323 INFO:     Epoch: 37
2022-11-23 01:15:24,095 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7679978866468776, 'Total loss': 0.7679978866468776} | train loss {'Reaction outcome loss': 0.8167499742945846, 'Total loss': 0.8167499742945846}
2022-11-23 01:15:24,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:24,096 INFO:     Epoch: 38
2022-11-23 01:15:24,925 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7646251510490071, 'Total loss': 0.7646251510490071} | train loss {'Reaction outcome loss': 0.8143160557260318, 'Total loss': 0.8143160557260318}
2022-11-23 01:15:24,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:24,925 INFO:     Epoch: 39
2022-11-23 01:15:25,726 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7874117798425935, 'Total loss': 0.7874117798425935} | train loss {'Reaction outcome loss': 0.8101765917271984, 'Total loss': 0.8101765917271984}
2022-11-23 01:15:25,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:25,726 INFO:     Epoch: 40
2022-11-23 01:15:26,531 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7921310378746553, 'Total loss': 0.7921310378746553} | train loss {'Reaction outcome loss': 0.8163863571322694, 'Total loss': 0.8163863571322694}
2022-11-23 01:15:26,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:26,531 INFO:     Epoch: 41
2022-11-23 01:15:27,322 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7642225284468044, 'Total loss': 0.7642225284468044} | train loss {'Reaction outcome loss': 0.8174521564220896, 'Total loss': 0.8174521564220896}
2022-11-23 01:15:27,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:27,323 INFO:     Epoch: 42
2022-11-23 01:15:28,122 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7719923454252157, 'Total loss': 0.7719923454252157} | train loss {'Reaction outcome loss': 0.8124089778686057, 'Total loss': 0.8124089778686057}
2022-11-23 01:15:28,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:28,122 INFO:     Epoch: 43
2022-11-23 01:15:28,858 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7763869159600951, 'Total loss': 0.7763869159600951} | train loss {'Reaction outcome loss': 0.8131244242191314, 'Total loss': 0.8131244242191314}
2022-11-23 01:15:28,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:28,859 INFO:     Epoch: 44
2022-11-23 01:15:29,665 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8094939332116734, 'Total loss': 0.8094939332116734} | train loss {'Reaction outcome loss': 0.8175917620561561, 'Total loss': 0.8175917620561561}
2022-11-23 01:15:29,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:29,665 INFO:     Epoch: 45
2022-11-23 01:15:30,487 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7673133127391338, 'Total loss': 0.7673133127391338} | train loss {'Reaction outcome loss': 0.8115119469409087, 'Total loss': 0.8115119469409087}
2022-11-23 01:15:30,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:30,487 INFO:     Epoch: 46
2022-11-23 01:15:31,323 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7849154350432482, 'Total loss': 0.7849154350432482} | train loss {'Reaction outcome loss': 0.8180204424322868, 'Total loss': 0.8180204424322868}
2022-11-23 01:15:31,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:31,323 INFO:     Epoch: 47
2022-11-23 01:15:32,142 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7771597917784344, 'Total loss': 0.7771597917784344} | train loss {'Reaction outcome loss': 0.8157316237079854, 'Total loss': 0.8157316237079854}
2022-11-23 01:15:32,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:32,142 INFO:     Epoch: 48
2022-11-23 01:15:32,937 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.76549027656967, 'Total loss': 0.76549027656967} | train loss {'Reaction outcome loss': 0.8132506740336516, 'Total loss': 0.8132506740336516}
2022-11-23 01:15:32,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:32,937 INFO:     Epoch: 49
2022-11-23 01:15:33,740 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7713797261769121, 'Total loss': 0.7713797261769121} | train loss {'Reaction outcome loss': 0.8152313920916343, 'Total loss': 0.8152313920916343}
2022-11-23 01:15:33,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:33,740 INFO:     Epoch: 50
2022-11-23 01:15:34,545 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7698026712645184, 'Total loss': 0.7698026712645184} | train loss {'Reaction outcome loss': 0.8156631776264736, 'Total loss': 0.8156631776264736}
2022-11-23 01:15:34,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:34,545 INFO:     Epoch: 51
2022-11-23 01:15:35,347 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7885911986231804, 'Total loss': 0.7885911986231804} | train loss {'Reaction outcome loss': 0.8149048704273847, 'Total loss': 0.8149048704273847}
2022-11-23 01:15:35,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:35,347 INFO:     Epoch: 52
2022-11-23 01:15:36,150 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7703311531381174, 'Total loss': 0.7703311531381174} | train loss {'Reaction outcome loss': 0.8087865751616808, 'Total loss': 0.8087865751616808}
2022-11-23 01:15:36,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:36,150 INFO:     Epoch: 53
2022-11-23 01:15:36,975 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7746948423710737, 'Total loss': 0.7746948423710737} | train loss {'Reaction outcome loss': 0.8123636931789164, 'Total loss': 0.8123636931789164}
2022-11-23 01:15:36,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:36,976 INFO:     Epoch: 54
2022-11-23 01:15:37,784 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7780760824680328, 'Total loss': 0.7780760824680328} | train loss {'Reaction outcome loss': 0.810996175907096, 'Total loss': 0.810996175907096}
2022-11-23 01:15:37,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:37,784 INFO:     Epoch: 55
2022-11-23 01:15:38,597 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7579472683031451, 'Total loss': 0.7579472683031451} | train loss {'Reaction outcome loss': 0.8197684846362289, 'Total loss': 0.8197684846362289}
2022-11-23 01:15:38,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:38,597 INFO:     Epoch: 56
2022-11-23 01:15:39,383 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7860129441727292, 'Total loss': 0.7860129441727292} | train loss {'Reaction outcome loss': 0.8100323903317355, 'Total loss': 0.8100323903317355}
2022-11-23 01:15:39,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:39,383 INFO:     Epoch: 57
2022-11-23 01:15:40,187 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.79013522782109, 'Total loss': 0.79013522782109} | train loss {'Reaction outcome loss': 0.8185363899688332, 'Total loss': 0.8185363899688332}
2022-11-23 01:15:40,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:40,187 INFO:     Epoch: 58
2022-11-23 01:15:40,981 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7805878330360759, 'Total loss': 0.7805878330360759} | train loss {'Reaction outcome loss': 0.8106885520779357, 'Total loss': 0.8106885520779357}
2022-11-23 01:15:40,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:40,982 INFO:     Epoch: 59
2022-11-23 01:15:41,802 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7739840197292241, 'Total loss': 0.7739840197292241} | train loss {'Reaction outcome loss': 0.8177380536283766, 'Total loss': 0.8177380536283766}
2022-11-23 01:15:41,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:41,802 INFO:     Epoch: 60
2022-11-23 01:15:42,600 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7800263058055531, 'Total loss': 0.7800263058055531} | train loss {'Reaction outcome loss': 0.8144375662414395, 'Total loss': 0.8144375662414395}
2022-11-23 01:15:42,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:42,600 INFO:     Epoch: 61
2022-11-23 01:15:43,371 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7857522998343814, 'Total loss': 0.7857522998343814} | train loss {'Reaction outcome loss': 0.8148139406223687, 'Total loss': 0.8148139406223687}
2022-11-23 01:15:43,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:43,372 INFO:     Epoch: 62
2022-11-23 01:15:44,207 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7692257294600661, 'Total loss': 0.7692257294600661} | train loss {'Reaction outcome loss': 0.8169110757963998, 'Total loss': 0.8169110757963998}
2022-11-23 01:15:44,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:44,208 INFO:     Epoch: 63
2022-11-23 01:15:44,991 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7744002958590334, 'Total loss': 0.7744002958590334} | train loss {'Reaction outcome loss': 0.815253024198571, 'Total loss': 0.815253024198571}
2022-11-23 01:15:44,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:44,991 INFO:     Epoch: 64
2022-11-23 01:15:45,817 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8107215111905878, 'Total loss': 0.8107215111905878} | train loss {'Reaction outcome loss': 0.815435957543704, 'Total loss': 0.815435957543704}
2022-11-23 01:15:45,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:45,817 INFO:     Epoch: 65
2022-11-23 01:15:46,650 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7658134224739942, 'Total loss': 0.7658134224739942} | train loss {'Reaction outcome loss': 0.8120232549248909, 'Total loss': 0.8120232549248909}
2022-11-23 01:15:46,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:46,650 INFO:     Epoch: 66
2022-11-23 01:15:47,455 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7798169851303101, 'Total loss': 0.7798169851303101} | train loss {'Reaction outcome loss': 0.811537218093872, 'Total loss': 0.811537218093872}
2022-11-23 01:15:47,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:47,456 INFO:     Epoch: 67
2022-11-23 01:15:48,245 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7770397839221087, 'Total loss': 0.7770397839221087} | train loss {'Reaction outcome loss': 0.8105895449920576, 'Total loss': 0.8105895449920576}
2022-11-23 01:15:48,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:48,245 INFO:     Epoch: 68
2022-11-23 01:15:49,084 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7832681814377959, 'Total loss': 0.7832681814377959} | train loss {'Reaction outcome loss': 0.8196732389683626, 'Total loss': 0.8196732389683626}
2022-11-23 01:15:49,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:49,084 INFO:     Epoch: 69
2022-11-23 01:15:49,894 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7784263884479349, 'Total loss': 0.7784263884479349} | train loss {'Reaction outcome loss': 0.8102950504847936, 'Total loss': 0.8102950504847936}
2022-11-23 01:15:49,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:49,895 INFO:     Epoch: 70
2022-11-23 01:15:50,647 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7991657209667292, 'Total loss': 0.7991657209667292} | train loss {'Reaction outcome loss': 0.8168224299440578, 'Total loss': 0.8168224299440578}
2022-11-23 01:15:50,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:50,648 INFO:     Epoch: 71
2022-11-23 01:15:51,450 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7776623828844591, 'Total loss': 0.7776623828844591} | train loss {'Reaction outcome loss': 0.8141993382755591, 'Total loss': 0.8141993382755591}
2022-11-23 01:15:51,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:51,451 INFO:     Epoch: 72
2022-11-23 01:15:52,282 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8010129109025002, 'Total loss': 0.8010129109025002} | train loss {'Reaction outcome loss': 0.8140602695698641, 'Total loss': 0.8140602695698641}
2022-11-23 01:15:52,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:52,282 INFO:     Epoch: 73
2022-11-23 01:15:53,121 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7997545105489817, 'Total loss': 0.7997545105489817} | train loss {'Reaction outcome loss': 0.8138537589384585, 'Total loss': 0.8138537589384585}
2022-11-23 01:15:53,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:53,121 INFO:     Epoch: 74
2022-11-23 01:15:53,928 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7758465138348666, 'Total loss': 0.7758465138348666} | train loss {'Reaction outcome loss': 0.8115742606776101, 'Total loss': 0.8115742606776101}
2022-11-23 01:15:53,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:53,928 INFO:     Epoch: 75
2022-11-23 01:15:54,743 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.77941334112124, 'Total loss': 0.77941334112124} | train loss {'Reaction outcome loss': 0.816105348479991, 'Total loss': 0.816105348479991}
2022-11-23 01:15:54,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:54,743 INFO:     Epoch: 76
2022-11-23 01:15:55,534 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7560826533220031, 'Total loss': 0.7560826533220031} | train loss {'Reaction outcome loss': 0.8148998902768505, 'Total loss': 0.8148998902768505}
2022-11-23 01:15:55,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:55,534 INFO:     Epoch: 77
2022-11-23 01:15:56,326 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7614213726059957, 'Total loss': 0.7614213726059957} | train loss {'Reaction outcome loss': 0.8133274241369598, 'Total loss': 0.8133274241369598}
2022-11-23 01:15:56,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:56,326 INFO:     Epoch: 78
2022-11-23 01:15:57,100 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7847055156122554, 'Total loss': 0.7847055156122554} | train loss {'Reaction outcome loss': 0.8122444562766017, 'Total loss': 0.8122444562766017}
2022-11-23 01:15:57,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:57,100 INFO:     Epoch: 79
2022-11-23 01:15:57,886 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7829966667023572, 'Total loss': 0.7829966667023572} | train loss {'Reaction outcome loss': 0.8128758058256033, 'Total loss': 0.8128758058256033}
2022-11-23 01:15:57,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:57,886 INFO:     Epoch: 80
2022-11-23 01:15:58,687 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7789720662615516, 'Total loss': 0.7789720662615516} | train loss {'Reaction outcome loss': 0.8106313060741035, 'Total loss': 0.8106313060741035}
2022-11-23 01:15:58,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:58,688 INFO:     Epoch: 81
2022-11-23 01:15:59,497 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7728304632685401, 'Total loss': 0.7728304632685401} | train loss {'Reaction outcome loss': 0.8144249565747319, 'Total loss': 0.8144249565747319}
2022-11-23 01:15:59,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:15:59,498 INFO:     Epoch: 82
2022-11-23 01:16:00,349 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7638118382204663, 'Total loss': 0.7638118382204663} | train loss {'Reaction outcome loss': 0.8146807725332221, 'Total loss': 0.8146807725332221}
2022-11-23 01:16:00,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:00,349 INFO:     Epoch: 83
2022-11-23 01:16:01,204 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7672886834903196, 'Total loss': 0.7672886834903196} | train loss {'Reaction outcome loss': 0.8097229146227545, 'Total loss': 0.8097229146227545}
2022-11-23 01:16:01,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:01,205 INFO:     Epoch: 84
2022-11-23 01:16:02,096 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.789840165187012, 'Total loss': 0.789840165187012} | train loss {'Reaction outcome loss': 0.8126603113145244, 'Total loss': 0.8126603113145244}
2022-11-23 01:16:02,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:02,096 INFO:     Epoch: 85
2022-11-23 01:16:02,981 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7752772488377311, 'Total loss': 0.7752772488377311} | train loss {'Reaction outcome loss': 0.8106001107060179, 'Total loss': 0.8106001107060179}
2022-11-23 01:16:02,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:02,981 INFO:     Epoch: 86
2022-11-23 01:16:03,881 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7640468063340946, 'Total loss': 0.7640468063340946} | train loss {'Reaction outcome loss': 0.8081621020424122, 'Total loss': 0.8081621020424122}
2022-11-23 01:16:03,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:03,881 INFO:     Epoch: 87
2022-11-23 01:16:04,797 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7747823629866947, 'Total loss': 0.7747823629866947} | train loss {'Reaction outcome loss': 0.8154131380879149, 'Total loss': 0.8154131380879149}
2022-11-23 01:16:04,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:04,797 INFO:     Epoch: 88
2022-11-23 01:16:05,600 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7585532739758492, 'Total loss': 0.7585532739758492} | train loss {'Reaction outcome loss': 0.8121929834083635, 'Total loss': 0.8121929834083635}
2022-11-23 01:16:05,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:05,600 INFO:     Epoch: 89
2022-11-23 01:16:06,425 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7942090061577883, 'Total loss': 0.7942090061577883} | train loss {'Reaction outcome loss': 0.8138335349608441, 'Total loss': 0.8138335349608441}
2022-11-23 01:16:06,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:06,426 INFO:     Epoch: 90
2022-11-23 01:16:07,194 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7592993649569425, 'Total loss': 0.7592993649569425} | train loss {'Reaction outcome loss': 0.8049667598033438, 'Total loss': 0.8049667598033438}
2022-11-23 01:16:07,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:07,194 INFO:     Epoch: 91
2022-11-23 01:16:07,990 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7826998220248655, 'Total loss': 0.7826998220248655} | train loss {'Reaction outcome loss': 0.8162401084997216, 'Total loss': 0.8162401084997216}
2022-11-23 01:16:07,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:07,990 INFO:     Epoch: 92
2022-11-23 01:16:08,809 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7614552216096357, 'Total loss': 0.7614552216096357} | train loss {'Reaction outcome loss': 0.8143859885176834, 'Total loss': 0.8143859885176834}
2022-11-23 01:16:08,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:08,809 INFO:     Epoch: 93
2022-11-23 01:16:09,674 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7682881023396145, 'Total loss': 0.7682881023396145} | train loss {'Reaction outcome loss': 0.8125748788823887, 'Total loss': 0.8125748788823887}
2022-11-23 01:16:09,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:09,674 INFO:     Epoch: 94
2022-11-23 01:16:10,446 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7806507992473516, 'Total loss': 0.7806507992473516} | train loss {'Reaction outcome loss': 0.8124019312615297, 'Total loss': 0.8124019312615297}
2022-11-23 01:16:10,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:10,446 INFO:     Epoch: 95
2022-11-23 01:16:11,238 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7707446664571762, 'Total loss': 0.7707446664571762} | train loss {'Reaction outcome loss': 0.8150554430728056, 'Total loss': 0.8150554430728056}
2022-11-23 01:16:11,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:11,238 INFO:     Epoch: 96
2022-11-23 01:16:12,071 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7807635732672431, 'Total loss': 0.7807635732672431} | train loss {'Reaction outcome loss': 0.8173359778462624, 'Total loss': 0.8173359778462624}
2022-11-23 01:16:12,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:12,073 INFO:     Epoch: 97
2022-11-23 01:16:12,856 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.758655458688736, 'Total loss': 0.758655458688736} | train loss {'Reaction outcome loss': 0.8125499123213242, 'Total loss': 0.8125499123213242}
2022-11-23 01:16:12,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:12,856 INFO:     Epoch: 98
2022-11-23 01:16:13,643 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.77801109647209, 'Total loss': 0.77801109647209} | train loss {'Reaction outcome loss': 0.8100599156350505, 'Total loss': 0.8100599156350505}
2022-11-23 01:16:13,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:13,643 INFO:     Epoch: 99
2022-11-23 01:16:14,459 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7751424075527624, 'Total loss': 0.7751424075527624} | train loss {'Reaction outcome loss': 0.8116276703318771, 'Total loss': 0.8116276703318771}
2022-11-23 01:16:14,460 INFO:     Best model found after epoch 13 of 100.
2022-11-23 01:16:14,460 INFO:   Done with stage: TRAINING
2022-11-23 01:16:14,460 INFO:   Starting stage: EVALUATION
2022-11-23 01:16:14,590 INFO:   Done with stage: EVALUATION
2022-11-23 01:16:14,591 INFO:   Leaving out SEQ value Fold_1
2022-11-23 01:16:14,604 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 01:16:14,604 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:16:15,278 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:16:15,278 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:16:15,350 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:16:15,350 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:16:15,350 INFO:     No hyperparam tuning for this model
2022-11-23 01:16:15,351 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:16:15,351 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:16:15,351 INFO:     None feature selector for col prot
2022-11-23 01:16:15,352 INFO:     None feature selector for col prot
2022-11-23 01:16:15,352 INFO:     None feature selector for col prot
2022-11-23 01:16:15,352 INFO:     None feature selector for col chem
2022-11-23 01:16:15,352 INFO:     None feature selector for col chem
2022-11-23 01:16:15,352 INFO:     None feature selector for col chem
2022-11-23 01:16:15,352 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:16:15,352 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:16:15,354 INFO:     Number of params in model 168571
2022-11-23 01:16:15,357 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:16:15,357 INFO:   Starting stage: TRAINING
2022-11-23 01:16:15,415 INFO:     Val loss before train {'Reaction outcome loss': 1.0357957536523992, 'Total loss': 1.0357957536523992}
2022-11-23 01:16:15,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:15,415 INFO:     Epoch: 0
2022-11-23 01:16:16,288 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8820574649355628, 'Total loss': 0.8820574649355628} | train loss {'Reaction outcome loss': 0.8846222129669267, 'Total loss': 0.8846222129669267}
2022-11-23 01:16:16,288 INFO:     Found new best model at epoch 0
2022-11-23 01:16:16,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:16,289 INFO:     Epoch: 1
2022-11-23 01:16:17,093 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8585404076359489, 'Total loss': 0.8585404076359489} | train loss {'Reaction outcome loss': 0.856945229566049, 'Total loss': 0.856945229566049}
2022-11-23 01:16:17,093 INFO:     Found new best model at epoch 1
2022-11-23 01:16:17,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:17,094 INFO:     Epoch: 2
2022-11-23 01:16:17,913 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8629498888145793, 'Total loss': 0.8629498888145793} | train loss {'Reaction outcome loss': 0.8593032046368247, 'Total loss': 0.8593032046368247}
2022-11-23 01:16:17,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:17,913 INFO:     Epoch: 3
2022-11-23 01:16:18,723 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8852632750164379, 'Total loss': 0.8852632750164379} | train loss {'Reaction outcome loss': 0.8462639403970618, 'Total loss': 0.8462639403970618}
2022-11-23 01:16:18,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:18,724 INFO:     Epoch: 4
2022-11-23 01:16:19,542 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8619933019984852, 'Total loss': 0.8619933019984852} | train loss {'Reaction outcome loss': 0.8369687403503218, 'Total loss': 0.8369687403503218}
2022-11-23 01:16:19,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:19,542 INFO:     Epoch: 5
2022-11-23 01:16:20,356 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.853224630382928, 'Total loss': 0.853224630382928} | train loss {'Reaction outcome loss': 0.8408749084240994, 'Total loss': 0.8408749084240994}
2022-11-23 01:16:20,357 INFO:     Found new best model at epoch 5
2022-11-23 01:16:20,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:20,358 INFO:     Epoch: 6
2022-11-23 01:16:21,212 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.867403663017533, 'Total loss': 0.867403663017533} | train loss {'Reaction outcome loss': 0.838489752489063, 'Total loss': 0.838489752489063}
2022-11-23 01:16:21,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:21,212 INFO:     Epoch: 7
2022-11-23 01:16:22,006 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.866865252906626, 'Total loss': 0.866865252906626} | train loss {'Reaction outcome loss': 0.8253728265493263, 'Total loss': 0.8253728265493263}
2022-11-23 01:16:22,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:22,006 INFO:     Epoch: 8
2022-11-23 01:16:22,771 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8582404404878616, 'Total loss': 0.8582404404878616} | train loss {'Reaction outcome loss': 0.8257951618507806, 'Total loss': 0.8257951618507806}
2022-11-23 01:16:22,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:22,771 INFO:     Epoch: 9
2022-11-23 01:16:23,606 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8834202072837136, 'Total loss': 0.8834202072837136} | train loss {'Reaction outcome loss': 0.8263059667488823, 'Total loss': 0.8263059667488823}
2022-11-23 01:16:23,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:23,606 INFO:     Epoch: 10
2022-11-23 01:16:24,449 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8450011401013895, 'Total loss': 0.8450011401013895} | train loss {'Reaction outcome loss': 0.8335152613489252, 'Total loss': 0.8335152613489252}
2022-11-23 01:16:24,449 INFO:     Found new best model at epoch 10
2022-11-23 01:16:24,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:24,450 INFO:     Epoch: 11
2022-11-23 01:16:25,252 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8457120643420653, 'Total loss': 0.8457120643420653} | train loss {'Reaction outcome loss': 0.827277663341056, 'Total loss': 0.827277663341056}
2022-11-23 01:16:25,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:25,252 INFO:     Epoch: 12
2022-11-23 01:16:26,035 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.84489445252852, 'Total loss': 0.84489445252852} | train loss {'Reaction outcome loss': 0.8334482773112865, 'Total loss': 0.8334482773112865}
2022-11-23 01:16:26,035 INFO:     Found new best model at epoch 12
2022-11-23 01:16:26,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:26,036 INFO:     Epoch: 13
2022-11-23 01:16:26,844 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8545789576389573, 'Total loss': 0.8545789576389573} | train loss {'Reaction outcome loss': 0.8314526205362096, 'Total loss': 0.8314526205362096}
2022-11-23 01:16:26,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:26,844 INFO:     Epoch: 14
2022-11-23 01:16:27,653 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8548072251406583, 'Total loss': 0.8548072251406583} | train loss {'Reaction outcome loss': 0.82401353754254, 'Total loss': 0.82401353754254}
2022-11-23 01:16:27,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:27,654 INFO:     Epoch: 15
2022-11-23 01:16:28,465 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8659269999374043, 'Total loss': 0.8659269999374043} | train loss {'Reaction outcome loss': 0.8281590423361975, 'Total loss': 0.8281590423361975}
2022-11-23 01:16:28,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:28,466 INFO:     Epoch: 16
2022-11-23 01:16:29,288 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8537044260989536, 'Total loss': 0.8537044260989536} | train loss {'Reaction outcome loss': 0.8396611458618148, 'Total loss': 0.8396611458618148}
2022-11-23 01:16:29,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:29,288 INFO:     Epoch: 17
2022-11-23 01:16:30,104 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8506154668602076, 'Total loss': 0.8506154668602076} | train loss {'Reaction outcome loss': 0.8255561815823621, 'Total loss': 0.8255561815823621}
2022-11-23 01:16:30,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:30,105 INFO:     Epoch: 18
2022-11-23 01:16:30,928 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8665764460509474, 'Total loss': 0.8665764460509474} | train loss {'Reaction outcome loss': 0.8236532722890135, 'Total loss': 0.8236532722890135}
2022-11-23 01:16:30,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:30,929 INFO:     Epoch: 19
2022-11-23 01:16:31,739 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8485452675006606, 'Total loss': 0.8485452675006606} | train loss {'Reaction outcome loss': 0.8391294248914911, 'Total loss': 0.8391294248914911}
2022-11-23 01:16:31,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:31,739 INFO:     Epoch: 20
2022-11-23 01:16:32,580 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8652145551009611, 'Total loss': 0.8652145551009611} | train loss {'Reaction outcome loss': 0.8349666365908708, 'Total loss': 0.8349666365908708}
2022-11-23 01:16:32,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:32,580 INFO:     Epoch: 21
2022-11-23 01:16:33,422 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8646501736207441, 'Total loss': 0.8646501736207441} | train loss {'Reaction outcome loss': 0.830040602548885, 'Total loss': 0.830040602548885}
2022-11-23 01:16:33,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:33,422 INFO:     Epoch: 22
2022-11-23 01:16:34,210 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8858521668748423, 'Total loss': 0.8858521668748423} | train loss {'Reaction outcome loss': 0.8316330763733821, 'Total loss': 0.8316330763733821}
2022-11-23 01:16:34,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:34,211 INFO:     Epoch: 23
2022-11-23 01:16:35,036 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8757740326903083, 'Total loss': 0.8757740326903083} | train loss {'Reaction outcome loss': 0.8247605910607678, 'Total loss': 0.8247605910607678}
2022-11-23 01:16:35,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:35,036 INFO:     Epoch: 24
2022-11-23 01:16:35,849 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8588086265054616, 'Total loss': 0.8588086265054616} | train loss {'Reaction outcome loss': 0.8289992265735078, 'Total loss': 0.8289992265735078}
2022-11-23 01:16:35,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:35,849 INFO:     Epoch: 25
2022-11-23 01:16:36,665 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8433331847190857, 'Total loss': 0.8433331847190857} | train loss {'Reaction outcome loss': 0.8217979398092278, 'Total loss': 0.8217979398092278}
2022-11-23 01:16:36,665 INFO:     Found new best model at epoch 25
2022-11-23 01:16:36,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:36,666 INFO:     Epoch: 26
2022-11-23 01:16:37,476 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8462739613923159, 'Total loss': 0.8462739613923159} | train loss {'Reaction outcome loss': 0.8252386736121737, 'Total loss': 0.8252386736121737}
2022-11-23 01:16:37,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:37,476 INFO:     Epoch: 27
2022-11-23 01:16:38,266 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8456115045330741, 'Total loss': 0.8456115045330741} | train loss {'Reaction outcome loss': 0.83030155602737, 'Total loss': 0.83030155602737}
2022-11-23 01:16:38,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:38,266 INFO:     Epoch: 28
2022-11-23 01:16:39,070 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8582655394619162, 'Total loss': 0.8582655394619162} | train loss {'Reaction outcome loss': 0.8177048547970138, 'Total loss': 0.8177048547970138}
2022-11-23 01:16:39,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:39,070 INFO:     Epoch: 29
2022-11-23 01:16:39,872 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8433689271861856, 'Total loss': 0.8433689271861856} | train loss {'Reaction outcome loss': 0.8328858015508305, 'Total loss': 0.8328858015508305}
2022-11-23 01:16:39,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:39,872 INFO:     Epoch: 30
2022-11-23 01:16:40,713 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8440688225356016, 'Total loss': 0.8440688225356016} | train loss {'Reaction outcome loss': 0.832375289698844, 'Total loss': 0.832375289698844}
2022-11-23 01:16:40,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:40,713 INFO:     Epoch: 31
2022-11-23 01:16:41,493 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8455418253486807, 'Total loss': 0.8455418253486807} | train loss {'Reaction outcome loss': 0.8256011325338108, 'Total loss': 0.8256011325338108}
2022-11-23 01:16:41,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:41,493 INFO:     Epoch: 32
2022-11-23 01:16:42,294 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8566925518892028, 'Total loss': 0.8566925518892028} | train loss {'Reaction outcome loss': 0.8300491921332201, 'Total loss': 0.8300491921332201}
2022-11-23 01:16:42,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:42,295 INFO:     Epoch: 33
2022-11-23 01:16:43,132 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8476303341713819, 'Total loss': 0.8476303341713819} | train loss {'Reaction outcome loss': 0.8322053418950996, 'Total loss': 0.8322053418950996}
2022-11-23 01:16:43,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:43,133 INFO:     Epoch: 34
2022-11-23 01:16:43,979 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8459569906646555, 'Total loss': 0.8459569906646555} | train loss {'Reaction outcome loss': 0.8242286654558741, 'Total loss': 0.8242286654558741}
2022-11-23 01:16:43,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:43,979 INFO:     Epoch: 35
2022-11-23 01:16:44,752 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8723371489481493, 'Total loss': 0.8723371489481493} | train loss {'Reaction outcome loss': 0.8231413524884444, 'Total loss': 0.8231413524884444}
2022-11-23 01:16:44,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:44,752 INFO:     Epoch: 36
2022-11-23 01:16:45,563 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8485650406642393, 'Total loss': 0.8485650406642393} | train loss {'Reaction outcome loss': 0.8220483552408122, 'Total loss': 0.8220483552408122}
2022-11-23 01:16:45,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:45,563 INFO:     Epoch: 37
2022-11-23 01:16:46,374 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8387596627528017, 'Total loss': 0.8387596627528017} | train loss {'Reaction outcome loss': 0.8178386807381383, 'Total loss': 0.8178386807381383}
2022-11-23 01:16:46,374 INFO:     Found new best model at epoch 37
2022-11-23 01:16:46,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:46,375 INFO:     Epoch: 38
2022-11-23 01:16:47,185 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8676619245247408, 'Total loss': 0.8676619245247408} | train loss {'Reaction outcome loss': 0.823385038839178, 'Total loss': 0.823385038839178}
2022-11-23 01:16:47,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:47,186 INFO:     Epoch: 39
2022-11-23 01:16:47,974 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8541124706918543, 'Total loss': 0.8541124706918543} | train loss {'Reaction outcome loss': 0.8221634486577047, 'Total loss': 0.8221634486577047}
2022-11-23 01:16:47,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:47,975 INFO:     Epoch: 40
2022-11-23 01:16:48,809 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8438085927204653, 'Total loss': 0.8438085927204653} | train loss {'Reaction outcome loss': 0.8199903673005973, 'Total loss': 0.8199903673005973}
2022-11-23 01:16:48,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:48,809 INFO:     Epoch: 41
2022-11-23 01:16:49,578 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8542590263214979, 'Total loss': 0.8542590263214979} | train loss {'Reaction outcome loss': 0.8228876150330069, 'Total loss': 0.8228876150330069}
2022-11-23 01:16:49,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:49,579 INFO:     Epoch: 42
2022-11-23 01:16:50,405 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8621437644416635, 'Total loss': 0.8621437644416635} | train loss {'Reaction outcome loss': 0.8296005862203204, 'Total loss': 0.8296005862203204}
2022-11-23 01:16:50,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:50,405 INFO:     Epoch: 43
2022-11-23 01:16:51,193 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.863462817939845, 'Total loss': 0.863462817939845} | train loss {'Reaction outcome loss': 0.8255799562342254, 'Total loss': 0.8255799562342254}
2022-11-23 01:16:51,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:51,194 INFO:     Epoch: 44
2022-11-23 01:16:52,017 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8517549146305431, 'Total loss': 0.8517549146305431} | train loss {'Reaction outcome loss': 0.8294719774954715, 'Total loss': 0.8294719774954715}
2022-11-23 01:16:52,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:52,017 INFO:     Epoch: 45
2022-11-23 01:16:52,810 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8563347458839417, 'Total loss': 0.8563347458839417} | train loss {'Reaction outcome loss': 0.8325508921011257, 'Total loss': 0.8325508921011257}
2022-11-23 01:16:52,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:52,810 INFO:     Epoch: 46
2022-11-23 01:16:53,595 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8477750278332017, 'Total loss': 0.8477750278332017} | train loss {'Reaction outcome loss': 0.8280688091237777, 'Total loss': 0.8280688091237777}
2022-11-23 01:16:53,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:53,595 INFO:     Epoch: 47
2022-11-23 01:16:54,396 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8445227742195129, 'Total loss': 0.8445227742195129} | train loss {'Reaction outcome loss': 0.8286542029757249, 'Total loss': 0.8286542029757249}
2022-11-23 01:16:54,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:54,396 INFO:     Epoch: 48
2022-11-23 01:16:55,189 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8495417779142206, 'Total loss': 0.8495417779142206} | train loss {'Reaction outcome loss': 0.8337763984676315, 'Total loss': 0.8337763984676315}
2022-11-23 01:16:55,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:55,190 INFO:     Epoch: 49
2022-11-23 01:16:56,005 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.855716733769937, 'Total loss': 0.855716733769937} | train loss {'Reaction outcome loss': 0.8244590309226079, 'Total loss': 0.8244590309226079}
2022-11-23 01:16:56,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:56,005 INFO:     Epoch: 50
2022-11-23 01:16:56,802 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8542690967971628, 'Total loss': 0.8542690967971628} | train loss {'Reaction outcome loss': 0.8210684495416247, 'Total loss': 0.8210684495416247}
2022-11-23 01:16:56,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:56,802 INFO:     Epoch: 51
2022-11-23 01:16:57,651 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8514709432016719, 'Total loss': 0.8514709432016719} | train loss {'Reaction outcome loss': 0.8342686890349215, 'Total loss': 0.8342686890349215}
2022-11-23 01:16:57,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:57,651 INFO:     Epoch: 52
2022-11-23 01:16:58,464 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8498413616960699, 'Total loss': 0.8498413616960699} | train loss {'Reaction outcome loss': 0.8278952183028464, 'Total loss': 0.8278952183028464}
2022-11-23 01:16:58,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:58,464 INFO:     Epoch: 53
2022-11-23 01:16:59,239 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8723888173699379, 'Total loss': 0.8723888173699379} | train loss {'Reaction outcome loss': 0.8230454144086915, 'Total loss': 0.8230454144086915}
2022-11-23 01:16:59,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:16:59,239 INFO:     Epoch: 54
2022-11-23 01:17:00,146 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8423641093752601, 'Total loss': 0.8423641093752601} | train loss {'Reaction outcome loss': 0.8207594900116747, 'Total loss': 0.8207594900116747}
2022-11-23 01:17:00,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:00,147 INFO:     Epoch: 55
2022-11-23 01:17:01,045 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8475543612783606, 'Total loss': 0.8475543612783606} | train loss {'Reaction outcome loss': 0.8207056024055249, 'Total loss': 0.8207056024055249}
2022-11-23 01:17:01,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:01,045 INFO:     Epoch: 56
2022-11-23 01:17:01,880 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8468184010549025, 'Total loss': 0.8468184010549025} | train loss {'Reaction outcome loss': 0.8171477146476869, 'Total loss': 0.8171477146476869}
2022-11-23 01:17:01,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:01,881 INFO:     Epoch: 57
2022-11-23 01:17:02,714 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8331867812032049, 'Total loss': 0.8331867812032049} | train loss {'Reaction outcome loss': 0.8203084251130761, 'Total loss': 0.8203084251130761}
2022-11-23 01:17:02,714 INFO:     Found new best model at epoch 57
2022-11-23 01:17:02,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:02,715 INFO:     Epoch: 58
2022-11-23 01:17:03,606 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8355971832167018, 'Total loss': 0.8355971832167018} | train loss {'Reaction outcome loss': 0.8291706780673038, 'Total loss': 0.8291706780673038}
2022-11-23 01:17:03,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:03,606 INFO:     Epoch: 59
2022-11-23 01:17:04,422 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8508801331574266, 'Total loss': 0.8508801331574266} | train loss {'Reaction outcome loss': 0.8239707373655759, 'Total loss': 0.8239707373655759}
2022-11-23 01:17:04,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:04,423 INFO:     Epoch: 60
2022-11-23 01:17:05,301 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8563914847644892, 'Total loss': 0.8563914847644892} | train loss {'Reaction outcome loss': 0.8232407458880653, 'Total loss': 0.8232407458880653}
2022-11-23 01:17:05,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:05,302 INFO:     Epoch: 61
2022-11-23 01:17:06,200 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8464671766216104, 'Total loss': 0.8464671766216104} | train loss {'Reaction outcome loss': 0.8276251116503588, 'Total loss': 0.8276251116503588}
2022-11-23 01:17:06,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:06,200 INFO:     Epoch: 62
2022-11-23 01:17:07,110 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8448065018112009, 'Total loss': 0.8448065018112009} | train loss {'Reaction outcome loss': 0.8219718889668886, 'Total loss': 0.8219718889668886}
2022-11-23 01:17:07,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:07,110 INFO:     Epoch: 63
2022-11-23 01:17:08,030 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8595800399780273, 'Total loss': 0.8595800399780273} | train loss {'Reaction outcome loss': 0.8215130487313638, 'Total loss': 0.8215130487313638}
2022-11-23 01:17:08,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:08,030 INFO:     Epoch: 64
2022-11-23 01:17:08,966 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8413943309675563, 'Total loss': 0.8413943309675563} | train loss {'Reaction outcome loss': 0.8187076930816357, 'Total loss': 0.8187076930816357}
2022-11-23 01:17:08,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:08,966 INFO:     Epoch: 65
2022-11-23 01:17:09,870 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8581614711067893, 'Total loss': 0.8581614711067893} | train loss {'Reaction outcome loss': 0.8196992118831589, 'Total loss': 0.8196992118831589}
2022-11-23 01:17:09,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:09,870 INFO:     Epoch: 66
2022-11-23 01:17:10,838 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8484159606424245, 'Total loss': 0.8484159606424245} | train loss {'Reaction outcome loss': 0.8246623336786201, 'Total loss': 0.8246623336786201}
2022-11-23 01:17:10,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:10,838 INFO:     Epoch: 67
2022-11-23 01:17:11,784 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8368141881444238, 'Total loss': 0.8368141881444238} | train loss {'Reaction outcome loss': 0.8225137938854665, 'Total loss': 0.8225137938854665}
2022-11-23 01:17:11,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:11,784 INFO:     Epoch: 68
2022-11-23 01:17:12,736 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8645865266973322, 'Total loss': 0.8645865266973322} | train loss {'Reaction outcome loss': 0.8318092966610603, 'Total loss': 0.8318092966610603}
2022-11-23 01:17:12,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:12,736 INFO:     Epoch: 69
2022-11-23 01:17:13,688 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8380553851073439, 'Total loss': 0.8380553851073439} | train loss {'Reaction outcome loss': 0.8250117263330622, 'Total loss': 0.8250117263330622}
2022-11-23 01:17:13,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:13,689 INFO:     Epoch: 70
2022-11-23 01:17:14,667 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8397455804727294, 'Total loss': 0.8397455804727294} | train loss {'Reaction outcome loss': 0.8161331156668393, 'Total loss': 0.8161331156668393}
2022-11-23 01:17:14,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:14,667 INFO:     Epoch: 71
2022-11-23 01:17:15,574 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8353491632098501, 'Total loss': 0.8353491632098501} | train loss {'Reaction outcome loss': 0.8226820366826617, 'Total loss': 0.8226820366826617}
2022-11-23 01:17:15,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:15,575 INFO:     Epoch: 72
2022-11-23 01:17:16,502 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8453924208879471, 'Total loss': 0.8453924208879471} | train loss {'Reaction outcome loss': 0.8246644900636635, 'Total loss': 0.8246644900636635}
2022-11-23 01:17:16,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:16,502 INFO:     Epoch: 73
2022-11-23 01:17:17,439 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8479677032340657, 'Total loss': 0.8479677032340657} | train loss {'Reaction outcome loss': 0.8209464723161357, 'Total loss': 0.8209464723161357}
2022-11-23 01:17:17,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:17,440 INFO:     Epoch: 74
2022-11-23 01:17:18,319 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8383864557201212, 'Total loss': 0.8383864557201212} | train loss {'Reaction outcome loss': 0.8251030277988689, 'Total loss': 0.8251030277988689}
2022-11-23 01:17:18,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:18,320 INFO:     Epoch: 75
2022-11-23 01:17:19,237 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8360822566530921, 'Total loss': 0.8360822566530921} | train loss {'Reaction outcome loss': 0.8228629213354366, 'Total loss': 0.8228629213354366}
2022-11-23 01:17:19,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:19,237 INFO:     Epoch: 76
2022-11-23 01:17:20,125 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.844563873654062, 'Total loss': 0.844563873654062} | train loss {'Reaction outcome loss': 0.8245696229068374, 'Total loss': 0.8245696229068374}
2022-11-23 01:17:20,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:20,126 INFO:     Epoch: 77
2022-11-23 01:17:21,021 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8444597057320855, 'Total loss': 0.8444597057320855} | train loss {'Reaction outcome loss': 0.8190696644879546, 'Total loss': 0.8190696644879546}
2022-11-23 01:17:21,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:21,022 INFO:     Epoch: 78
2022-11-23 01:17:21,927 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8493731258945032, 'Total loss': 0.8493731258945032} | train loss {'Reaction outcome loss': 0.8224031810577099, 'Total loss': 0.8224031810577099}
2022-11-23 01:17:21,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:21,927 INFO:     Epoch: 79
2022-11-23 01:17:22,813 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8528984412550926, 'Total loss': 0.8528984412550926} | train loss {'Reaction outcome loss': 0.8246024563486277, 'Total loss': 0.8246024563486277}
2022-11-23 01:17:22,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:22,813 INFO:     Epoch: 80
2022-11-23 01:17:23,711 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8360055840828202, 'Total loss': 0.8360055840828202} | train loss {'Reaction outcome loss': 0.8296952120929595, 'Total loss': 0.8296952120929595}
2022-11-23 01:17:23,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:23,712 INFO:     Epoch: 81
2022-11-23 01:17:24,583 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8486163697459481, 'Total loss': 0.8486163697459481} | train loss {'Reaction outcome loss': 0.829566632567147, 'Total loss': 0.829566632567147}
2022-11-23 01:17:24,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:24,584 INFO:     Epoch: 82
2022-11-23 01:17:25,475 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8577401380647313, 'Total loss': 0.8577401380647313} | train loss {'Reaction outcome loss': 0.8241141344371595, 'Total loss': 0.8241141344371595}
2022-11-23 01:17:25,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:25,475 INFO:     Epoch: 83
2022-11-23 01:17:26,354 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8436304412104867, 'Total loss': 0.8436304412104867} | train loss {'Reaction outcome loss': 0.8232435158148468, 'Total loss': 0.8232435158148468}
2022-11-23 01:17:26,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:26,354 INFO:     Epoch: 84
2022-11-23 01:17:27,270 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8327697603539987, 'Total loss': 0.8327697603539987} | train loss {'Reaction outcome loss': 0.8239144938677428, 'Total loss': 0.8239144938677428}
2022-11-23 01:17:27,270 INFO:     Found new best model at epoch 84
2022-11-23 01:17:27,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:27,271 INFO:     Epoch: 85
2022-11-23 01:17:28,199 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8350518515164201, 'Total loss': 0.8350518515164201} | train loss {'Reaction outcome loss': 0.8256818637674154, 'Total loss': 0.8256818637674154}
2022-11-23 01:17:28,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:28,200 INFO:     Epoch: 86
2022-11-23 01:17:29,096 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8475724824450233, 'Total loss': 0.8475724824450233} | train loss {'Reaction outcome loss': 0.8216757559583254, 'Total loss': 0.8216757559583254}
2022-11-23 01:17:29,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:29,096 INFO:     Epoch: 87
2022-11-23 01:17:29,954 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.897590855305845, 'Total loss': 0.897590855305845} | train loss {'Reaction outcome loss': 0.826415402927862, 'Total loss': 0.826415402927862}
2022-11-23 01:17:29,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:29,954 INFO:     Epoch: 88
2022-11-23 01:17:30,812 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8541005470535972, 'Total loss': 0.8541005470535972} | train loss {'Reaction outcome loss': 0.8262451245234563, 'Total loss': 0.8262451245234563}
2022-11-23 01:17:30,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:30,812 INFO:     Epoch: 89
2022-11-23 01:17:31,699 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8458409830927849, 'Total loss': 0.8458409830927849} | train loss {'Reaction outcome loss': 0.8305795379737129, 'Total loss': 0.8305795379737129}
2022-11-23 01:17:31,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:31,699 INFO:     Epoch: 90
2022-11-23 01:17:32,577 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8597583364356648, 'Total loss': 0.8597583364356648} | train loss {'Reaction outcome loss': 0.8194154014411242, 'Total loss': 0.8194154014411242}
2022-11-23 01:17:32,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:32,578 INFO:     Epoch: 91
2022-11-23 01:17:33,448 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.842703942548145, 'Total loss': 0.842703942548145} | train loss {'Reaction outcome loss': 0.8214351996960427, 'Total loss': 0.8214351996960427}
2022-11-23 01:17:33,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:33,449 INFO:     Epoch: 92
2022-11-23 01:17:34,308 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8462802476503632, 'Total loss': 0.8462802476503632} | train loss {'Reaction outcome loss': 0.8241030657701647, 'Total loss': 0.8241030657701647}
2022-11-23 01:17:34,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:34,308 INFO:     Epoch: 93
2022-11-23 01:17:35,212 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8518702949989926, 'Total loss': 0.8518702949989926} | train loss {'Reaction outcome loss': 0.8231945092137526, 'Total loss': 0.8231945092137526}
2022-11-23 01:17:35,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:35,212 INFO:     Epoch: 94
2022-11-23 01:17:36,046 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8443029861558567, 'Total loss': 0.8443029861558567} | train loss {'Reaction outcome loss': 0.817238694712942, 'Total loss': 0.817238694712942}
2022-11-23 01:17:36,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:36,046 INFO:     Epoch: 95
2022-11-23 01:17:36,941 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8562663278796456, 'Total loss': 0.8562663278796456} | train loss {'Reaction outcome loss': 0.8219040399379576, 'Total loss': 0.8219040399379576}
2022-11-23 01:17:36,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:36,941 INFO:     Epoch: 96
2022-11-23 01:17:37,800 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8494665609164671, 'Total loss': 0.8494665609164671} | train loss {'Reaction outcome loss': 0.8225668724249249, 'Total loss': 0.8225668724249249}
2022-11-23 01:17:37,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:37,800 INFO:     Epoch: 97
2022-11-23 01:17:38,645 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8653492893684994, 'Total loss': 0.8653492893684994} | train loss {'Reaction outcome loss': 0.8247325170619285, 'Total loss': 0.8247325170619285}
2022-11-23 01:17:38,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:38,645 INFO:     Epoch: 98
2022-11-23 01:17:39,524 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8508133793419058, 'Total loss': 0.8508133793419058} | train loss {'Reaction outcome loss': 0.8253028207582983, 'Total loss': 0.8253028207582983}
2022-11-23 01:17:39,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:39,525 INFO:     Epoch: 99
2022-11-23 01:17:40,425 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8503809517080133, 'Total loss': 0.8503809517080133} | train loss {'Reaction outcome loss': 0.8191296168667103, 'Total loss': 0.8191296168667103}
2022-11-23 01:17:40,425 INFO:     Best model found after epoch 85 of 100.
2022-11-23 01:17:40,425 INFO:   Done with stage: TRAINING
2022-11-23 01:17:40,426 INFO:   Starting stage: EVALUATION
2022-11-23 01:17:40,552 INFO:   Done with stage: EVALUATION
2022-11-23 01:17:40,552 INFO:   Leaving out SEQ value Fold_2
2022-11-23 01:17:40,566 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-23 01:17:40,566 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:17:41,243 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:17:41,243 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:17:41,317 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:17:41,317 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:17:41,317 INFO:     No hyperparam tuning for this model
2022-11-23 01:17:41,317 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:17:41,317 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:17:41,318 INFO:     None feature selector for col prot
2022-11-23 01:17:41,318 INFO:     None feature selector for col prot
2022-11-23 01:17:41,318 INFO:     None feature selector for col prot
2022-11-23 01:17:41,319 INFO:     None feature selector for col chem
2022-11-23 01:17:41,319 INFO:     None feature selector for col chem
2022-11-23 01:17:41,319 INFO:     None feature selector for col chem
2022-11-23 01:17:41,319 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:17:41,319 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:17:41,321 INFO:     Number of params in model 168571
2022-11-23 01:17:41,324 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:17:41,325 INFO:   Starting stage: TRAINING
2022-11-23 01:17:41,385 INFO:     Val loss before train {'Reaction outcome loss': 0.9871408356861635, 'Total loss': 0.9871408356861635}
2022-11-23 01:17:41,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:41,386 INFO:     Epoch: 0
2022-11-23 01:17:42,320 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8265600922432813, 'Total loss': 0.8265600922432813} | train loss {'Reaction outcome loss': 0.8742281535450294, 'Total loss': 0.8742281535450294}
2022-11-23 01:17:42,320 INFO:     Found new best model at epoch 0
2022-11-23 01:17:42,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:42,321 INFO:     Epoch: 1
2022-11-23 01:17:43,156 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8430600139227781, 'Total loss': 0.8430600139227781} | train loss {'Reaction outcome loss': 0.8431525036996724, 'Total loss': 0.8431525036996724}
2022-11-23 01:17:43,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:43,156 INFO:     Epoch: 2
2022-11-23 01:17:44,008 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.817271769724109, 'Total loss': 0.817271769724109} | train loss {'Reaction outcome loss': 0.8421835237619828, 'Total loss': 0.8421835237619828}
2022-11-23 01:17:44,009 INFO:     Found new best model at epoch 2
2022-11-23 01:17:44,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:44,009 INFO:     Epoch: 3
2022-11-23 01:17:44,838 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8073313263329592, 'Total loss': 0.8073313263329592} | train loss {'Reaction outcome loss': 0.8362276790093403, 'Total loss': 0.8362276790093403}
2022-11-23 01:17:44,839 INFO:     Found new best model at epoch 3
2022-11-23 01:17:44,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:44,840 INFO:     Epoch: 4
2022-11-23 01:17:45,745 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8079740337350152, 'Total loss': 0.8079740337350152} | train loss {'Reaction outcome loss': 0.8264456693007022, 'Total loss': 0.8264456693007022}
2022-11-23 01:17:45,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:45,745 INFO:     Epoch: 5
2022-11-23 01:17:46,620 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8157160674983804, 'Total loss': 0.8157160674983804} | train loss {'Reaction outcome loss': 0.8227412773638355, 'Total loss': 0.8227412773638355}
2022-11-23 01:17:46,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:46,621 INFO:     Epoch: 6
2022-11-23 01:17:47,484 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8426355943083763, 'Total loss': 0.8426355943083763} | train loss {'Reaction outcome loss': 0.8191568527902876, 'Total loss': 0.8191568527902876}
2022-11-23 01:17:47,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:47,484 INFO:     Epoch: 7
2022-11-23 01:17:48,376 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.806763347576965, 'Total loss': 0.806763347576965} | train loss {'Reaction outcome loss': 0.8222710958548954, 'Total loss': 0.8222710958548954}
2022-11-23 01:17:48,377 INFO:     Found new best model at epoch 7
2022-11-23 01:17:48,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:48,378 INFO:     Epoch: 8
2022-11-23 01:17:49,246 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7850633148442615, 'Total loss': 0.7850633148442615} | train loss {'Reaction outcome loss': 0.8176634916237422, 'Total loss': 0.8176634916237422}
2022-11-23 01:17:49,246 INFO:     Found new best model at epoch 8
2022-11-23 01:17:49,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:49,247 INFO:     Epoch: 9
2022-11-23 01:17:50,085 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7844118990681388, 'Total loss': 0.7844118990681388} | train loss {'Reaction outcome loss': 0.8205589152112299, 'Total loss': 0.8205589152112299}
2022-11-23 01:17:50,085 INFO:     Found new best model at epoch 9
2022-11-23 01:17:50,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:50,086 INFO:     Epoch: 10
2022-11-23 01:17:50,951 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8410927111452277, 'Total loss': 0.8410927111452277} | train loss {'Reaction outcome loss': 0.8175961526072755, 'Total loss': 0.8175961526072755}
2022-11-23 01:17:50,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:50,952 INFO:     Epoch: 11
2022-11-23 01:17:51,788 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7942768863656304, 'Total loss': 0.7942768863656304} | train loss {'Reaction outcome loss': 0.8150694731546908, 'Total loss': 0.8150694731546908}
2022-11-23 01:17:51,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:51,789 INFO:     Epoch: 12
2022-11-23 01:17:52,670 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7840755168687213, 'Total loss': 0.7840755168687213} | train loss {'Reaction outcome loss': 0.8178209646623962, 'Total loss': 0.8178209646623962}
2022-11-23 01:17:52,671 INFO:     Found new best model at epoch 12
2022-11-23 01:17:52,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:52,671 INFO:     Epoch: 13
2022-11-23 01:17:53,538 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7923816740512848, 'Total loss': 0.7923816740512848} | train loss {'Reaction outcome loss': 0.8133384061102964, 'Total loss': 0.8133384061102964}
2022-11-23 01:17:53,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:53,538 INFO:     Epoch: 14
2022-11-23 01:17:54,386 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7923635813322935, 'Total loss': 0.7923635813322935} | train loss {'Reaction outcome loss': 0.8142691474788043, 'Total loss': 0.8142691474788043}
2022-11-23 01:17:54,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:54,386 INFO:     Epoch: 15
2022-11-23 01:17:55,240 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7831957069310275, 'Total loss': 0.7831957069310275} | train loss {'Reaction outcome loss': 0.8136680505713638, 'Total loss': 0.8136680505713638}
2022-11-23 01:17:55,240 INFO:     Found new best model at epoch 15
2022-11-23 01:17:55,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:55,241 INFO:     Epoch: 16
2022-11-23 01:17:56,105 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7736834822730585, 'Total loss': 0.7736834822730585} | train loss {'Reaction outcome loss': 0.8112993498237766, 'Total loss': 0.8112993498237766}
2022-11-23 01:17:56,105 INFO:     Found new best model at epoch 16
2022-11-23 01:17:56,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:56,106 INFO:     Epoch: 17
2022-11-23 01:17:56,959 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7852975685488094, 'Total loss': 0.7852975685488094} | train loss {'Reaction outcome loss': 0.8134977895386365, 'Total loss': 0.8134977895386365}
2022-11-23 01:17:56,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:56,960 INFO:     Epoch: 18
2022-11-23 01:17:57,798 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7840085395357825, 'Total loss': 0.7840085395357825} | train loss {'Reaction outcome loss': 0.8135577645837044, 'Total loss': 0.8135577645837044}
2022-11-23 01:17:57,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:57,799 INFO:     Epoch: 19
2022-11-23 01:17:58,683 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8195656314492226, 'Total loss': 0.8195656314492226} | train loss {'Reaction outcome loss': 0.8139908148317921, 'Total loss': 0.8139908148317921}
2022-11-23 01:17:58,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:58,683 INFO:     Epoch: 20
2022-11-23 01:17:59,564 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7913009029897776, 'Total loss': 0.7913009029897776} | train loss {'Reaction outcome loss': 0.8109100233535378, 'Total loss': 0.8109100233535378}
2022-11-23 01:17:59,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:17:59,564 INFO:     Epoch: 21
2022-11-23 01:18:00,444 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.778752095320008, 'Total loss': 0.778752095320008} | train loss {'Reaction outcome loss': 0.8088987054873485, 'Total loss': 0.8088987054873485}
2022-11-23 01:18:00,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:00,444 INFO:     Epoch: 22
2022-11-23 01:18:01,355 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7727912481535565, 'Total loss': 0.7727912481535565} | train loss {'Reaction outcome loss': 0.8162425885395128, 'Total loss': 0.8162425885395128}
2022-11-23 01:18:01,356 INFO:     Found new best model at epoch 22
2022-11-23 01:18:01,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:01,356 INFO:     Epoch: 23
2022-11-23 01:18:02,180 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7936345365914431, 'Total loss': 0.7936345365914431} | train loss {'Reaction outcome loss': 0.8098215842733578, 'Total loss': 0.8098215842733578}
2022-11-23 01:18:02,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:02,180 INFO:     Epoch: 24
2022-11-23 01:18:03,006 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8059632263400338, 'Total loss': 0.8059632263400338} | train loss {'Reaction outcome loss': 0.8085221086229597, 'Total loss': 0.8085221086229597}
2022-11-23 01:18:03,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:03,007 INFO:     Epoch: 25
2022-11-23 01:18:03,849 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7941596684130755, 'Total loss': 0.7941596684130755} | train loss {'Reaction outcome loss': 0.8088425035379371, 'Total loss': 0.8088425035379371}
2022-11-23 01:18:03,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:03,850 INFO:     Epoch: 26
2022-11-23 01:18:04,694 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7947980707341974, 'Total loss': 0.7947980707341974} | train loss {'Reaction outcome loss': 0.810455454855549, 'Total loss': 0.810455454855549}
2022-11-23 01:18:04,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:04,694 INFO:     Epoch: 27
2022-11-23 01:18:05,563 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7794609144330025, 'Total loss': 0.7794609144330025} | train loss {'Reaction outcome loss': 0.811324997337497, 'Total loss': 0.811324997337497}
2022-11-23 01:18:05,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:05,563 INFO:     Epoch: 28
2022-11-23 01:18:06,411 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7810218611901457, 'Total loss': 0.7810218611901457} | train loss {'Reaction outcome loss': 0.8119269071793069, 'Total loss': 0.8119269071793069}
2022-11-23 01:18:06,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:06,411 INFO:     Epoch: 29
2022-11-23 01:18:07,238 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8033189312978224, 'Total loss': 0.8033189312978224} | train loss {'Reaction outcome loss': 0.8087444765227182, 'Total loss': 0.8087444765227182}
2022-11-23 01:18:07,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:07,238 INFO:     Epoch: 30
2022-11-23 01:18:08,051 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8014067262411118, 'Total loss': 0.8014067262411118} | train loss {'Reaction outcome loss': 0.8056799936051271, 'Total loss': 0.8056799936051271}
2022-11-23 01:18:08,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:08,051 INFO:     Epoch: 31
2022-11-23 01:18:08,909 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7959851548075676, 'Total loss': 0.7959851548075676} | train loss {'Reaction outcome loss': 0.8076862044480382, 'Total loss': 0.8076862044480382}
2022-11-23 01:18:08,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:08,909 INFO:     Epoch: 32
2022-11-23 01:18:09,750 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7801023491404273, 'Total loss': 0.7801023491404273} | train loss {'Reaction outcome loss': 0.8123397336930644, 'Total loss': 0.8123397336930644}
2022-11-23 01:18:09,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:09,750 INFO:     Epoch: 33
2022-11-23 01:18:10,569 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.803165351125327, 'Total loss': 0.803165351125327} | train loss {'Reaction outcome loss': 0.8099604314687301, 'Total loss': 0.8099604314687301}
2022-11-23 01:18:10,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:10,569 INFO:     Epoch: 34
2022-11-23 01:18:11,362 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7819640152156353, 'Total loss': 0.7819640152156353} | train loss {'Reaction outcome loss': 0.8052894851382898, 'Total loss': 0.8052894851382898}
2022-11-23 01:18:11,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:11,362 INFO:     Epoch: 35
2022-11-23 01:18:12,180 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.797992545095357, 'Total loss': 0.797992545095357} | train loss {'Reaction outcome loss': 0.8137557675643843, 'Total loss': 0.8137557675643843}
2022-11-23 01:18:12,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:12,180 INFO:     Epoch: 36
2022-11-23 01:18:12,971 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.804807260632515, 'Total loss': 0.804807260632515} | train loss {'Reaction outcome loss': 0.8155014100123424, 'Total loss': 0.8155014100123424}
2022-11-23 01:18:12,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:12,971 INFO:     Epoch: 37
2022-11-23 01:18:13,768 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7818504795432091, 'Total loss': 0.7818504795432091} | train loss {'Reaction outcome loss': 0.81107727070244, 'Total loss': 0.81107727070244}
2022-11-23 01:18:13,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:13,768 INFO:     Epoch: 38
2022-11-23 01:18:14,561 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7872800650921735, 'Total loss': 0.7872800650921735} | train loss {'Reaction outcome loss': 0.8081835872056533, 'Total loss': 0.8081835872056533}
2022-11-23 01:18:14,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:14,562 INFO:     Epoch: 39
2022-11-23 01:18:15,366 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7753040302883495, 'Total loss': 0.7753040302883495} | train loss {'Reaction outcome loss': 0.8117096806059079, 'Total loss': 0.8117096806059079}
2022-11-23 01:18:15,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:15,366 INFO:     Epoch: 40
2022-11-23 01:18:16,189 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7745455056428909, 'Total loss': 0.7745455056428909} | train loss {'Reaction outcome loss': 0.8097540726467055, 'Total loss': 0.8097540726467055}
2022-11-23 01:18:16,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:16,191 INFO:     Epoch: 41
2022-11-23 01:18:17,023 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7858506061814048, 'Total loss': 0.7858506061814048} | train loss {'Reaction outcome loss': 0.8115995459410609, 'Total loss': 0.8115995459410609}
2022-11-23 01:18:17,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:17,023 INFO:     Epoch: 42
2022-11-23 01:18:17,826 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7705479243939574, 'Total loss': 0.7705479243939574} | train loss {'Reaction outcome loss': 0.808504079920905, 'Total loss': 0.808504079920905}
2022-11-23 01:18:17,826 INFO:     Found new best model at epoch 42
2022-11-23 01:18:17,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:17,827 INFO:     Epoch: 43
2022-11-23 01:18:18,654 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7634826885028319, 'Total loss': 0.7634826885028319} | train loss {'Reaction outcome loss': 0.814819723367691, 'Total loss': 0.814819723367691}
2022-11-23 01:18:18,654 INFO:     Found new best model at epoch 43
2022-11-23 01:18:18,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:18,655 INFO:     Epoch: 44
2022-11-23 01:18:19,463 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7733501446518031, 'Total loss': 0.7733501446518031} | train loss {'Reaction outcome loss': 0.8104563597513705, 'Total loss': 0.8104563597513705}
2022-11-23 01:18:19,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:19,463 INFO:     Epoch: 45
2022-11-23 01:18:20,260 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7888128845529123, 'Total loss': 0.7888128845529123} | train loss {'Reaction outcome loss': 0.8066745777519382, 'Total loss': 0.8066745777519382}
2022-11-23 01:18:20,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:20,261 INFO:     Epoch: 46
2022-11-23 01:18:21,105 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7817922789942134, 'Total loss': 0.7817922789942134} | train loss {'Reaction outcome loss': 0.8099620873830756, 'Total loss': 0.8099620873830756}
2022-11-23 01:18:21,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:21,105 INFO:     Epoch: 47
2022-11-23 01:18:21,873 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7706430107355118, 'Total loss': 0.7706430107355118} | train loss {'Reaction outcome loss': 0.8089118405264251, 'Total loss': 0.8089118405264251}
2022-11-23 01:18:21,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:21,873 INFO:     Epoch: 48
2022-11-23 01:18:22,655 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7762723924084143, 'Total loss': 0.7762723924084143} | train loss {'Reaction outcome loss': 0.8097170911273178, 'Total loss': 0.8097170911273178}
2022-11-23 01:18:22,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:22,656 INFO:     Epoch: 49
2022-11-23 01:18:23,502 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7853059870275584, 'Total loss': 0.7853059870275584} | train loss {'Reaction outcome loss': 0.811335833340275, 'Total loss': 0.811335833340275}
2022-11-23 01:18:23,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:23,502 INFO:     Epoch: 50
2022-11-23 01:18:24,311 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7830520069057291, 'Total loss': 0.7830520069057291} | train loss {'Reaction outcome loss': 0.8102086612156459, 'Total loss': 0.8102086612156459}
2022-11-23 01:18:24,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:24,312 INFO:     Epoch: 51
2022-11-23 01:18:25,113 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7763549055565487, 'Total loss': 0.7763549055565487} | train loss {'Reaction outcome loss': 0.8046648473155742, 'Total loss': 0.8046648473155742}
2022-11-23 01:18:25,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:25,114 INFO:     Epoch: 52
2022-11-23 01:18:25,893 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7848014777356928, 'Total loss': 0.7848014777356928} | train loss {'Reaction outcome loss': 0.8102375656974559, 'Total loss': 0.8102375656974559}
2022-11-23 01:18:25,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:25,893 INFO:     Epoch: 53
2022-11-23 01:18:26,736 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7704816006801345, 'Total loss': 0.7704816006801345} | train loss {'Reaction outcome loss': 0.8095431505417338, 'Total loss': 0.8095431505417338}
2022-11-23 01:18:26,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:26,736 INFO:     Epoch: 54
2022-11-23 01:18:27,533 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7905195660211823, 'Total loss': 0.7905195660211823} | train loss {'Reaction outcome loss': 0.8085178468908583, 'Total loss': 0.8085178468908583}
2022-11-23 01:18:27,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:27,533 INFO:     Epoch: 55
2022-11-23 01:18:28,356 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7767120857130397, 'Total loss': 0.7767120857130397} | train loss {'Reaction outcome loss': 0.8115451716646856, 'Total loss': 0.8115451716646856}
2022-11-23 01:18:28,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:28,357 INFO:     Epoch: 56
2022-11-23 01:18:29,207 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7794479246843945, 'Total loss': 0.7794479246843945} | train loss {'Reaction outcome loss': 0.8095944686811798, 'Total loss': 0.8095944686811798}
2022-11-23 01:18:29,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:29,208 INFO:     Epoch: 57
2022-11-23 01:18:30,032 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8068485679951581, 'Total loss': 0.8068485679951581} | train loss {'Reaction outcome loss': 0.8090596495842447, 'Total loss': 0.8090596495842447}
2022-11-23 01:18:30,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:30,033 INFO:     Epoch: 58
2022-11-23 01:18:30,802 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7632632810961116, 'Total loss': 0.7632632810961116} | train loss {'Reaction outcome loss': 0.8097154113711144, 'Total loss': 0.8097154113711144}
2022-11-23 01:18:30,802 INFO:     Found new best model at epoch 58
2022-11-23 01:18:30,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:30,803 INFO:     Epoch: 59
2022-11-23 01:18:31,636 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7772232165390794, 'Total loss': 0.7772232165390794} | train loss {'Reaction outcome loss': 0.8076074479794015, 'Total loss': 0.8076074479794015}
2022-11-23 01:18:31,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:31,636 INFO:     Epoch: 60
2022-11-23 01:18:32,433 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7728842124342918, 'Total loss': 0.7728842124342918} | train loss {'Reaction outcome loss': 0.809410395427626, 'Total loss': 0.809410395427626}
2022-11-23 01:18:32,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:32,433 INFO:     Epoch: 61
2022-11-23 01:18:33,231 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7811914194713939, 'Total loss': 0.7811914194713939} | train loss {'Reaction outcome loss': 0.8069147708464642, 'Total loss': 0.8069147708464642}
2022-11-23 01:18:33,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:33,231 INFO:     Epoch: 62
2022-11-23 01:18:34,058 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7708258947188203, 'Total loss': 0.7708258947188203} | train loss {'Reaction outcome loss': 0.8060640399553338, 'Total loss': 0.8060640399553338}
2022-11-23 01:18:34,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:34,058 INFO:     Epoch: 63
2022-11-23 01:18:34,851 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.771021310578693, 'Total loss': 0.771021310578693} | train loss {'Reaction outcome loss': 0.8065399456997306, 'Total loss': 0.8065399456997306}
2022-11-23 01:18:34,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:34,852 INFO:     Epoch: 64
2022-11-23 01:18:35,686 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7661766342141412, 'Total loss': 0.7661766342141412} | train loss {'Reaction outcome loss': 0.8056413390198532, 'Total loss': 0.8056413390198532}
2022-11-23 01:18:35,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:35,686 INFO:     Epoch: 65
2022-11-23 01:18:36,458 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7673525911840525, 'Total loss': 0.7673525911840525} | train loss {'Reaction outcome loss': 0.803252500295639, 'Total loss': 0.803252500295639}
2022-11-23 01:18:36,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:36,458 INFO:     Epoch: 66
2022-11-23 01:18:37,254 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7976124279878356, 'Total loss': 0.7976124279878356} | train loss {'Reaction outcome loss': 0.8109237532226407, 'Total loss': 0.8109237532226407}
2022-11-23 01:18:37,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:37,255 INFO:     Epoch: 67
2022-11-23 01:18:38,026 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7793834873221137, 'Total loss': 0.7793834873221137} | train loss {'Reaction outcome loss': 0.8163130136168733, 'Total loss': 0.8163130136168733}
2022-11-23 01:18:38,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:38,026 INFO:     Epoch: 68
2022-11-23 01:18:38,833 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7784838087179444, 'Total loss': 0.7784838087179444} | train loss {'Reaction outcome loss': 0.8032700030171142, 'Total loss': 0.8032700030171142}
2022-11-23 01:18:38,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:38,833 INFO:     Epoch: 69
2022-11-23 01:18:39,663 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8131345551122319, 'Total loss': 0.8131345551122319} | train loss {'Reaction outcome loss': 0.808830853141084, 'Total loss': 0.808830853141084}
2022-11-23 01:18:39,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:39,663 INFO:     Epoch: 70
2022-11-23 01:18:40,451 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.767855482514609, 'Total loss': 0.767855482514609} | train loss {'Reaction outcome loss': 0.8123643558852527, 'Total loss': 0.8123643558852527}
2022-11-23 01:18:40,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:40,452 INFO:     Epoch: 71
2022-11-23 01:18:41,274 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.794180038977753, 'Total loss': 0.794180038977753} | train loss {'Reaction outcome loss': 0.810600855155867, 'Total loss': 0.810600855155867}
2022-11-23 01:18:41,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:41,275 INFO:     Epoch: 72
2022-11-23 01:18:42,066 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.76174892146479, 'Total loss': 0.76174892146479} | train loss {'Reaction outcome loss': 0.8128276674114928, 'Total loss': 0.8128276674114928}
2022-11-23 01:18:42,066 INFO:     Found new best model at epoch 72
2022-11-23 01:18:42,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:42,067 INFO:     Epoch: 73
2022-11-23 01:18:42,840 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7713789337060668, 'Total loss': 0.7713789337060668} | train loss {'Reaction outcome loss': 0.8086096750230205, 'Total loss': 0.8086096750230205}
2022-11-23 01:18:42,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:42,841 INFO:     Epoch: 74
2022-11-23 01:18:43,609 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7763283984227614, 'Total loss': 0.7763283984227614} | train loss {'Reaction outcome loss': 0.8141425410095526, 'Total loss': 0.8141425410095526}
2022-11-23 01:18:43,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:43,609 INFO:     Epoch: 75
2022-11-23 01:18:44,383 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7907130406661467, 'Total loss': 0.7907130406661467} | train loss {'Reaction outcome loss': 0.8106242907290556, 'Total loss': 0.8106242907290556}
2022-11-23 01:18:44,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:44,384 INFO:     Epoch: 76
2022-11-23 01:18:45,184 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7918137833476067, 'Total loss': 0.7918137833476067} | train loss {'Reaction outcome loss': 0.807206562465551, 'Total loss': 0.807206562465551}
2022-11-23 01:18:45,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:45,184 INFO:     Epoch: 77
2022-11-23 01:18:45,979 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7805013737895272, 'Total loss': 0.7805013737895272} | train loss {'Reaction outcome loss': 0.8081479876625295, 'Total loss': 0.8081479876625295}
2022-11-23 01:18:45,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:45,979 INFO:     Epoch: 78
2022-11-23 01:18:46,754 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7920645333149217, 'Total loss': 0.7920645333149217} | train loss {'Reaction outcome loss': 0.8087195159221182, 'Total loss': 0.8087195159221182}
2022-11-23 01:18:46,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:46,755 INFO:     Epoch: 79
2022-11-23 01:18:47,555 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7730847969651222, 'Total loss': 0.7730847969651222} | train loss {'Reaction outcome loss': 0.8077378274226675, 'Total loss': 0.8077378274226675}
2022-11-23 01:18:47,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:47,556 INFO:     Epoch: 80
2022-11-23 01:18:48,366 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7868979092348706, 'Total loss': 0.7868979092348706} | train loss {'Reaction outcome loss': 0.8087937519258382, 'Total loss': 0.8087937519258382}
2022-11-23 01:18:48,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:48,366 INFO:     Epoch: 81
2022-11-23 01:18:49,194 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7735429629683495, 'Total loss': 0.7735429629683495} | train loss {'Reaction outcome loss': 0.810142790541357, 'Total loss': 0.810142790541357}
2022-11-23 01:18:49,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:49,194 INFO:     Epoch: 82
2022-11-23 01:18:49,987 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7779541916467927, 'Total loss': 0.7779541916467927} | train loss {'Reaction outcome loss': 0.808521959854632, 'Total loss': 0.808521959854632}
2022-11-23 01:18:49,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:49,987 INFO:     Epoch: 83
2022-11-23 01:18:50,801 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7992079860784791, 'Total loss': 0.7992079860784791} | train loss {'Reaction outcome loss': 0.8078912508730985, 'Total loss': 0.8078912508730985}
2022-11-23 01:18:50,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:50,802 INFO:     Epoch: 84
2022-11-23 01:18:51,618 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7714005193927072, 'Total loss': 0.7714005193927072} | train loss {'Reaction outcome loss': 0.8090564147550232, 'Total loss': 0.8090564147550232}
2022-11-23 01:18:51,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:51,618 INFO:     Epoch: 85
2022-11-23 01:18:52,459 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7949451650069519, 'Total loss': 0.7949451650069519} | train loss {'Reaction outcome loss': 0.8098723426157114, 'Total loss': 0.8098723426157114}
2022-11-23 01:18:52,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:52,459 INFO:     Epoch: 86
2022-11-23 01:18:53,254 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7840551076964899, 'Total loss': 0.7840551076964899} | train loss {'Reaction outcome loss': 0.8084181885330044, 'Total loss': 0.8084181885330044}
2022-11-23 01:18:53,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:53,254 INFO:     Epoch: 87
2022-11-23 01:18:54,030 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7828486656600778, 'Total loss': 0.7828486656600778} | train loss {'Reaction outcome loss': 0.8069803198989557, 'Total loss': 0.8069803198989557}
2022-11-23 01:18:54,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:54,031 INFO:     Epoch: 88
2022-11-23 01:18:54,802 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7976611906831915, 'Total loss': 0.7976611906831915} | train loss {'Reaction outcome loss': 0.8090699560788213, 'Total loss': 0.8090699560788213}
2022-11-23 01:18:54,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:54,802 INFO:     Epoch: 89
2022-11-23 01:18:55,646 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.793409602208571, 'Total loss': 0.793409602208571} | train loss {'Reaction outcome loss': 0.809550524122861, 'Total loss': 0.809550524122861}
2022-11-23 01:18:55,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:55,646 INFO:     Epoch: 90
2022-11-23 01:18:56,422 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7734318009831689, 'Total loss': 0.7734318009831689} | train loss {'Reaction outcome loss': 0.8087330004390405, 'Total loss': 0.8087330004390405}
2022-11-23 01:18:56,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:56,422 INFO:     Epoch: 91
2022-11-23 01:18:57,202 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7684739340435375, 'Total loss': 0.7684739340435375} | train loss {'Reaction outcome loss': 0.8099866150593271, 'Total loss': 0.8099866150593271}
2022-11-23 01:18:57,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:57,203 INFO:     Epoch: 92
2022-11-23 01:18:57,990 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7853177453983914, 'Total loss': 0.7853177453983914} | train loss {'Reaction outcome loss': 0.8079256594181061, 'Total loss': 0.8079256594181061}
2022-11-23 01:18:57,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:57,991 INFO:     Epoch: 93
2022-11-23 01:18:58,782 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.798487854952162, 'Total loss': 0.798487854952162} | train loss {'Reaction outcome loss': 0.8079967282256302, 'Total loss': 0.8079967282256302}
2022-11-23 01:18:58,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:58,782 INFO:     Epoch: 94
2022-11-23 01:18:59,543 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7975761544975367, 'Total loss': 0.7975761544975367} | train loss {'Reaction outcome loss': 0.8116538775210478, 'Total loss': 0.8116538775210478}
2022-11-23 01:18:59,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:18:59,543 INFO:     Epoch: 95
2022-11-23 01:19:00,314 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7651724171909419, 'Total loss': 0.7651724171909419} | train loss {'Reaction outcome loss': 0.8032480689944054, 'Total loss': 0.8032480689944054}
2022-11-23 01:19:00,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:00,314 INFO:     Epoch: 96
2022-11-23 01:19:01,116 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7830921560525894, 'Total loss': 0.7830921560525894} | train loss {'Reaction outcome loss': 0.8094449236684916, 'Total loss': 0.8094449236684916}
2022-11-23 01:19:01,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:01,116 INFO:     Epoch: 97
2022-11-23 01:19:01,906 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7826391729441556, 'Total loss': 0.7826391729441556} | train loss {'Reaction outcome loss': 0.8056139618766551, 'Total loss': 0.8056139618766551}
2022-11-23 01:19:01,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:01,906 INFO:     Epoch: 98
2022-11-23 01:19:02,697 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7882294268770651, 'Total loss': 0.7882294268770651} | train loss {'Reaction outcome loss': 0.8051727103943728, 'Total loss': 0.8051727103943728}
2022-11-23 01:19:02,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:02,697 INFO:     Epoch: 99
2022-11-23 01:19:03,458 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7644962959668853, 'Total loss': 0.7644962959668853} | train loss {'Reaction outcome loss': 0.8061828389459726, 'Total loss': 0.8061828389459726}
2022-11-23 01:19:03,458 INFO:     Best model found after epoch 73 of 100.
2022-11-23 01:19:03,458 INFO:   Done with stage: TRAINING
2022-11-23 01:19:03,458 INFO:   Starting stage: EVALUATION
2022-11-23 01:19:03,589 INFO:   Done with stage: EVALUATION
2022-11-23 01:19:03,589 INFO:   Leaving out SEQ value Fold_3
2022-11-23 01:19:03,604 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-23 01:19:03,605 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:19:04,264 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:19:04,264 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:19:04,336 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:19:04,336 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:19:04,336 INFO:     No hyperparam tuning for this model
2022-11-23 01:19:04,336 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:19:04,336 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:19:04,337 INFO:     None feature selector for col prot
2022-11-23 01:19:04,337 INFO:     None feature selector for col prot
2022-11-23 01:19:04,337 INFO:     None feature selector for col prot
2022-11-23 01:19:04,338 INFO:     None feature selector for col chem
2022-11-23 01:19:04,338 INFO:     None feature selector for col chem
2022-11-23 01:19:04,338 INFO:     None feature selector for col chem
2022-11-23 01:19:04,338 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:19:04,338 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:19:04,340 INFO:     Number of params in model 168571
2022-11-23 01:19:04,343 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:19:04,343 INFO:   Starting stage: TRAINING
2022-11-23 01:19:04,401 INFO:     Val loss before train {'Reaction outcome loss': 1.0226526246514431, 'Total loss': 1.0226526246514431}
2022-11-23 01:19:04,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:04,401 INFO:     Epoch: 0
2022-11-23 01:19:05,170 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8533532349176185, 'Total loss': 0.8533532349176185} | train loss {'Reaction outcome loss': 0.876089983787693, 'Total loss': 0.876089983787693}
2022-11-23 01:19:05,170 INFO:     Found new best model at epoch 0
2022-11-23 01:19:05,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:05,171 INFO:     Epoch: 1
2022-11-23 01:19:05,940 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8586158045502597, 'Total loss': 0.8586158045502597} | train loss {'Reaction outcome loss': 0.8449068468857984, 'Total loss': 0.8449068468857984}
2022-11-23 01:19:05,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:05,941 INFO:     Epoch: 2
2022-11-23 01:19:06,704 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8303774664568346, 'Total loss': 0.8303774664568346} | train loss {'Reaction outcome loss': 0.8324605204531403, 'Total loss': 0.8324605204531403}
2022-11-23 01:19:06,705 INFO:     Found new best model at epoch 2
2022-11-23 01:19:06,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:06,706 INFO:     Epoch: 3
2022-11-23 01:19:07,472 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8471537273983623, 'Total loss': 0.8471537273983623} | train loss {'Reaction outcome loss': 0.8317394417817475, 'Total loss': 0.8317394417817475}
2022-11-23 01:19:07,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:07,472 INFO:     Epoch: 4
2022-11-23 01:19:08,245 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8338451191436412, 'Total loss': 0.8338451191436412} | train loss {'Reaction outcome loss': 0.8288294368835746, 'Total loss': 0.8288294368835746}
2022-11-23 01:19:08,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:08,245 INFO:     Epoch: 5
2022-11-23 01:19:09,000 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8310552786949069, 'Total loss': 0.8310552786949069} | train loss {'Reaction outcome loss': 0.8219452499121916, 'Total loss': 0.8219452499121916}
2022-11-23 01:19:09,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:09,001 INFO:     Epoch: 6
2022-11-23 01:19:09,743 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8348601869372434, 'Total loss': 0.8348601869372434} | train loss {'Reaction outcome loss': 0.8198370720397253, 'Total loss': 0.8198370720397253}
2022-11-23 01:19:09,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:09,743 INFO:     Epoch: 7
2022-11-23 01:19:10,509 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8785379681476327, 'Total loss': 0.8785379681476327} | train loss {'Reaction outcome loss': 0.8172200219553025, 'Total loss': 0.8172200219553025}
2022-11-23 01:19:10,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:10,509 INFO:     Epoch: 8
2022-11-23 01:19:11,294 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8264242909675421, 'Total loss': 0.8264242909675421} | train loss {'Reaction outcome loss': 0.8218191590954046, 'Total loss': 0.8218191590954046}
2022-11-23 01:19:11,295 INFO:     Found new best model at epoch 8
2022-11-23 01:19:11,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:11,295 INFO:     Epoch: 9
2022-11-23 01:19:12,096 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8186581231826959, 'Total loss': 0.8186581231826959} | train loss {'Reaction outcome loss': 0.8166468635690017, 'Total loss': 0.8166468635690017}
2022-11-23 01:19:12,096 INFO:     Found new best model at epoch 9
2022-11-23 01:19:12,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:12,097 INFO:     Epoch: 10
2022-11-23 01:19:12,906 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8225623625655507, 'Total loss': 0.8225623625655507} | train loss {'Reaction outcome loss': 0.811024578746225, 'Total loss': 0.811024578746225}
2022-11-23 01:19:12,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:12,907 INFO:     Epoch: 11
2022-11-23 01:19:13,703 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.826918366343476, 'Total loss': 0.826918366343476} | train loss {'Reaction outcome loss': 0.8139983178650747, 'Total loss': 0.8139983178650747}
2022-11-23 01:19:13,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:13,703 INFO:     Epoch: 12
2022-11-23 01:19:14,475 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.818265977293946, 'Total loss': 0.818265977293946} | train loss {'Reaction outcome loss': 0.8136296390754277, 'Total loss': 0.8136296390754277}
2022-11-23 01:19:14,475 INFO:     Found new best model at epoch 12
2022-11-23 01:19:14,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:14,476 INFO:     Epoch: 13
2022-11-23 01:19:15,246 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8204857589200486, 'Total loss': 0.8204857589200486} | train loss {'Reaction outcome loss': 0.814180353625876, 'Total loss': 0.814180353625876}
2022-11-23 01:19:15,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:15,246 INFO:     Epoch: 14
2022-11-23 01:19:16,071 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8244136481784111, 'Total loss': 0.8244136481784111} | train loss {'Reaction outcome loss': 0.8190481232815101, 'Total loss': 0.8190481232815101}
2022-11-23 01:19:16,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:16,071 INFO:     Epoch: 15
2022-11-23 01:19:16,870 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8201382638410081, 'Total loss': 0.8201382638410081} | train loss {'Reaction outcome loss': 0.8075477142558724, 'Total loss': 0.8075477142558724}
2022-11-23 01:19:16,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:16,871 INFO:     Epoch: 16
2022-11-23 01:19:17,702 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8231748987075894, 'Total loss': 0.8231748987075894} | train loss {'Reaction outcome loss': 0.8130287364369533, 'Total loss': 0.8130287364369533}
2022-11-23 01:19:17,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:17,702 INFO:     Epoch: 17
2022-11-23 01:19:18,491 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8356566429138184, 'Total loss': 0.8356566429138184} | train loss {'Reaction outcome loss': 0.8111142982713512, 'Total loss': 0.8111142982713512}
2022-11-23 01:19:18,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:18,491 INFO:     Epoch: 18
2022-11-23 01:19:19,305 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.821981152822805, 'Total loss': 0.821981152822805} | train loss {'Reaction outcome loss': 0.8125152298417248, 'Total loss': 0.8125152298417248}
2022-11-23 01:19:19,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:19,306 INFO:     Epoch: 19
2022-11-23 01:19:20,107 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8114571086196012, 'Total loss': 0.8114571086196012} | train loss {'Reaction outcome loss': 0.8138107204290687, 'Total loss': 0.8138107204290687}
2022-11-23 01:19:20,107 INFO:     Found new best model at epoch 19
2022-11-23 01:19:20,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:20,108 INFO:     Epoch: 20
2022-11-23 01:19:20,888 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8477124599523322, 'Total loss': 0.8477124599523322} | train loss {'Reaction outcome loss': 0.8101368528164801, 'Total loss': 0.8101368528164801}
2022-11-23 01:19:20,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:20,889 INFO:     Epoch: 21
2022-11-23 01:19:21,685 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8259190265522447, 'Total loss': 0.8259190265522447} | train loss {'Reaction outcome loss': 0.8163050338625908, 'Total loss': 0.8163050338625908}
2022-11-23 01:19:21,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:21,685 INFO:     Epoch: 22
2022-11-23 01:19:22,465 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8266659226528433, 'Total loss': 0.8266659226528433} | train loss {'Reaction outcome loss': 0.8118016092015095, 'Total loss': 0.8118016092015095}
2022-11-23 01:19:22,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:22,466 INFO:     Epoch: 23
2022-11-23 01:19:23,289 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.815094766228698, 'Total loss': 0.815094766228698} | train loss {'Reaction outcome loss': 0.8135555557540206, 'Total loss': 0.8135555557540206}
2022-11-23 01:19:23,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:23,289 INFO:     Epoch: 24
2022-11-23 01:19:24,088 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8204200149968613, 'Total loss': 0.8204200149968613} | train loss {'Reaction outcome loss': 0.8098613776144434, 'Total loss': 0.8098613776144434}
2022-11-23 01:19:24,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:24,088 INFO:     Epoch: 25
2022-11-23 01:19:24,899 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8149839473325152, 'Total loss': 0.8149839473325152} | train loss {'Reaction outcome loss': 0.8065783488945882, 'Total loss': 0.8065783488945882}
2022-11-23 01:19:24,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:24,899 INFO:     Epoch: 26
2022-11-23 01:19:25,676 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8305392916812453, 'Total loss': 0.8305392916812453} | train loss {'Reaction outcome loss': 0.8109156021573505, 'Total loss': 0.8109156021573505}
2022-11-23 01:19:25,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:25,677 INFO:     Epoch: 27
2022-11-23 01:19:26,523 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8122436078481896, 'Total loss': 0.8122436078481896} | train loss {'Reaction outcome loss': 0.8113292152764368, 'Total loss': 0.8113292152764368}
2022-11-23 01:19:26,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:26,523 INFO:     Epoch: 28
2022-11-23 01:19:27,296 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8208107560179955, 'Total loss': 0.8208107560179955} | train loss {'Reaction outcome loss': 0.8079367035725078, 'Total loss': 0.8079367035725078}
2022-11-23 01:19:27,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:27,296 INFO:     Epoch: 29
2022-11-23 01:19:28,098 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8060410993043766, 'Total loss': 0.8060410993043766} | train loss {'Reaction outcome loss': 0.8113705995874326, 'Total loss': 0.8113705995874326}
2022-11-23 01:19:28,098 INFO:     Found new best model at epoch 29
2022-11-23 01:19:28,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:28,099 INFO:     Epoch: 30
2022-11-23 01:19:28,913 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8174558933391127, 'Total loss': 0.8174558933391127} | train loss {'Reaction outcome loss': 0.8071686737850065, 'Total loss': 0.8071686737850065}
2022-11-23 01:19:28,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:28,913 INFO:     Epoch: 31
2022-11-23 01:19:29,728 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8109218450479729, 'Total loss': 0.8109218450479729} | train loss {'Reaction outcome loss': 0.8111751957750711, 'Total loss': 0.8111751957750711}
2022-11-23 01:19:29,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:29,728 INFO:     Epoch: 32
2022-11-23 01:19:30,517 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8232959384141967, 'Total loss': 0.8232959384141967} | train loss {'Reaction outcome loss': 0.8092259979638897, 'Total loss': 0.8092259979638897}
2022-11-23 01:19:30,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:30,518 INFO:     Epoch: 33
2022-11-23 01:19:31,305 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8331198553706325, 'Total loss': 0.8331198553706325} | train loss {'Reaction outcome loss': 0.810976035648682, 'Total loss': 0.810976035648682}
2022-11-23 01:19:31,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:31,305 INFO:     Epoch: 34
2022-11-23 01:19:32,109 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8347350386686103, 'Total loss': 0.8347350386686103} | train loss {'Reaction outcome loss': 0.8062424751334503, 'Total loss': 0.8062424751334503}
2022-11-23 01:19:32,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:32,110 INFO:     Epoch: 35
2022-11-23 01:19:32,931 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8113993184511051, 'Total loss': 0.8113993184511051} | train loss {'Reaction outcome loss': 0.8058400681761445, 'Total loss': 0.8058400681761445}
2022-11-23 01:19:32,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:32,931 INFO:     Epoch: 36
2022-11-23 01:19:33,716 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8242039891869523, 'Total loss': 0.8242039891869523} | train loss {'Reaction outcome loss': 0.8052900639958069, 'Total loss': 0.8052900639958069}
2022-11-23 01:19:33,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:33,716 INFO:     Epoch: 37
2022-11-23 01:19:34,544 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8184787852819576, 'Total loss': 0.8184787852819576} | train loss {'Reaction outcome loss': 0.8088266779897643, 'Total loss': 0.8088266779897643}
2022-11-23 01:19:34,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:34,544 INFO:     Epoch: 38
2022-11-23 01:19:35,354 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8132620640965396, 'Total loss': 0.8132620640965396} | train loss {'Reaction outcome loss': 0.8077752487581285, 'Total loss': 0.8077752487581285}
2022-11-23 01:19:35,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:35,355 INFO:     Epoch: 39
2022-11-23 01:19:36,168 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.805857413729956, 'Total loss': 0.805857413729956} | train loss {'Reaction outcome loss': 0.8102075990106239, 'Total loss': 0.8102075990106239}
2022-11-23 01:19:36,168 INFO:     Found new best model at epoch 39
2022-11-23 01:19:36,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:36,169 INFO:     Epoch: 40
2022-11-23 01:19:36,947 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8237659057905508, 'Total loss': 0.8237659057905508} | train loss {'Reaction outcome loss': 0.8101644630803436, 'Total loss': 0.8101644630803436}
2022-11-23 01:19:36,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:36,948 INFO:     Epoch: 41
2022-11-23 01:19:37,769 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8177797073541686, 'Total loss': 0.8177797073541686} | train loss {'Reaction outcome loss': 0.8083751189415572, 'Total loss': 0.8083751189415572}
2022-11-23 01:19:37,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:37,771 INFO:     Epoch: 42
2022-11-23 01:19:38,555 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8186384813730107, 'Total loss': 0.8186384813730107} | train loss {'Reaction outcome loss': 0.810754162183062, 'Total loss': 0.810754162183062}
2022-11-23 01:19:38,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:38,555 INFO:     Epoch: 43
2022-11-23 01:19:39,365 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8235508744106737, 'Total loss': 0.8235508744106737} | train loss {'Reaction outcome loss': 0.8074405741740446, 'Total loss': 0.8074405741740446}
2022-11-23 01:19:39,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:39,365 INFO:     Epoch: 44
2022-11-23 01:19:40,160 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8162215733250906, 'Total loss': 0.8162215733250906} | train loss {'Reaction outcome loss': 0.8042678592390702, 'Total loss': 0.8042678592390702}
2022-11-23 01:19:40,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:40,161 INFO:     Epoch: 45
2022-11-23 01:19:40,971 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.819342689458714, 'Total loss': 0.819342689458714} | train loss {'Reaction outcome loss': 0.8005000031629547, 'Total loss': 0.8005000031629547}
2022-11-23 01:19:40,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:40,971 INFO:     Epoch: 46
2022-11-23 01:19:41,755 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.820021158040956, 'Total loss': 0.820021158040956} | train loss {'Reaction outcome loss': 0.8078275611166095, 'Total loss': 0.8078275611166095}
2022-11-23 01:19:41,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:41,756 INFO:     Epoch: 47
2022-11-23 01:19:42,572 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8189999883951142, 'Total loss': 0.8189999883951142} | train loss {'Reaction outcome loss': 0.808714260148709, 'Total loss': 0.808714260148709}
2022-11-23 01:19:42,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:42,572 INFO:     Epoch: 48
2022-11-23 01:19:43,361 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8154239016909932, 'Total loss': 0.8154239016909932} | train loss {'Reaction outcome loss': 0.8047855973976558, 'Total loss': 0.8047855973976558}
2022-11-23 01:19:43,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:43,361 INFO:     Epoch: 49
2022-11-23 01:19:44,128 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8186668005100516, 'Total loss': 0.8186668005100516} | train loss {'Reaction outcome loss': 0.8071946281878675, 'Total loss': 0.8071946281878675}
2022-11-23 01:19:44,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:44,128 INFO:     Epoch: 50
2022-11-23 01:19:44,937 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8418865397919056, 'Total loss': 0.8418865397919056} | train loss {'Reaction outcome loss': 0.8021698010260941, 'Total loss': 0.8021698010260941}
2022-11-23 01:19:44,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:44,937 INFO:     Epoch: 51
2022-11-23 01:19:45,740 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8415843913721484, 'Total loss': 0.8415843913721484} | train loss {'Reaction outcome loss': 0.8028538213645826, 'Total loss': 0.8028538213645826}
2022-11-23 01:19:45,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:45,740 INFO:     Epoch: 52
2022-11-23 01:19:46,608 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8217139833195265, 'Total loss': 0.8217139833195265} | train loss {'Reaction outcome loss': 0.8050953396519677, 'Total loss': 0.8050953396519677}
2022-11-23 01:19:46,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:46,608 INFO:     Epoch: 53
2022-11-23 01:19:47,418 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8059691419435102, 'Total loss': 0.8059691419435102} | train loss {'Reaction outcome loss': 0.800556164295947, 'Total loss': 0.800556164295947}
2022-11-23 01:19:47,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:47,419 INFO:     Epoch: 54
2022-11-23 01:19:48,204 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8113850029402001, 'Total loss': 0.8113850029402001} | train loss {'Reaction outcome loss': 0.8058004049492664, 'Total loss': 0.8058004049492664}
2022-11-23 01:19:48,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:48,204 INFO:     Epoch: 55
2022-11-23 01:19:49,011 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.819508166507233, 'Total loss': 0.819508166507233} | train loss {'Reaction outcome loss': 0.8080596161670373, 'Total loss': 0.8080596161670373}
2022-11-23 01:19:49,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:49,012 INFO:     Epoch: 56
2022-11-23 01:19:49,834 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8288784727107646, 'Total loss': 0.8288784727107646} | train loss {'Reaction outcome loss': 0.8078794330358505, 'Total loss': 0.8078794330358505}
2022-11-23 01:19:49,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:49,834 INFO:     Epoch: 57
2022-11-23 01:19:50,618 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8035560818605645, 'Total loss': 0.8035560818605645} | train loss {'Reaction outcome loss': 0.8039524668797118, 'Total loss': 0.8039524668797118}
2022-11-23 01:19:50,619 INFO:     Found new best model at epoch 57
2022-11-23 01:19:50,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:50,620 INFO:     Epoch: 58
2022-11-23 01:19:51,388 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8251061009806256, 'Total loss': 0.8251061009806256} | train loss {'Reaction outcome loss': 0.8016986503708557, 'Total loss': 0.8016986503708557}
2022-11-23 01:19:51,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:51,388 INFO:     Epoch: 59
2022-11-23 01:19:52,187 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8003175307151883, 'Total loss': 0.8003175307151883} | train loss {'Reaction outcome loss': 0.7996545098111277, 'Total loss': 0.7996545098111277}
2022-11-23 01:19:52,187 INFO:     Found new best model at epoch 59
2022-11-23 01:19:52,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:52,188 INFO:     Epoch: 60
2022-11-23 01:19:53,012 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8153858642245448, 'Total loss': 0.8153858642245448} | train loss {'Reaction outcome loss': 0.8065888595874192, 'Total loss': 0.8065888595874192}
2022-11-23 01:19:53,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:53,012 INFO:     Epoch: 61
2022-11-23 01:19:53,795 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8132654359174329, 'Total loss': 0.8132654359174329} | train loss {'Reaction outcome loss': 0.8077524827152002, 'Total loss': 0.8077524827152002}
2022-11-23 01:19:53,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:53,795 INFO:     Epoch: 62
2022-11-23 01:19:54,601 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8412487583104954, 'Total loss': 0.8412487583104954} | train loss {'Reaction outcome loss': 0.800035692629267, 'Total loss': 0.800035692629267}
2022-11-23 01:19:54,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:54,602 INFO:     Epoch: 63
2022-11-23 01:19:55,404 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8156910933727441, 'Total loss': 0.8156910933727441} | train loss {'Reaction outcome loss': 0.8043299521334836, 'Total loss': 0.8043299521334836}
2022-11-23 01:19:55,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:55,404 INFO:     Epoch: 64
2022-11-23 01:19:56,232 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.809803539930388, 'Total loss': 0.809803539930388} | train loss {'Reaction outcome loss': 0.8065869583458197, 'Total loss': 0.8065869583458197}
2022-11-23 01:19:56,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:56,232 INFO:     Epoch: 65
2022-11-23 01:19:57,066 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8157667982023816, 'Total loss': 0.8157667982023816} | train loss {'Reaction outcome loss': 0.8028717117964245, 'Total loss': 0.8028717117964245}
2022-11-23 01:19:57,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:57,067 INFO:     Epoch: 66
2022-11-23 01:19:57,877 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8138144141019776, 'Total loss': 0.8138144141019776} | train loss {'Reaction outcome loss': 0.7979471930226342, 'Total loss': 0.7979471930226342}
2022-11-23 01:19:57,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:57,877 INFO:     Epoch: 67
2022-11-23 01:19:58,622 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7984992182532022, 'Total loss': 0.7984992182532022} | train loss {'Reaction outcome loss': 0.8051234361578207, 'Total loss': 0.8051234361578207}
2022-11-23 01:19:58,623 INFO:     Found new best model at epoch 67
2022-11-23 01:19:58,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:58,623 INFO:     Epoch: 68
2022-11-23 01:19:59,404 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.822119229061659, 'Total loss': 0.822119229061659} | train loss {'Reaction outcome loss': 0.8022808353187608, 'Total loss': 0.8022808353187608}
2022-11-23 01:19:59,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:19:59,404 INFO:     Epoch: 69
2022-11-23 01:20:00,182 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.815406089605287, 'Total loss': 0.815406089605287} | train loss {'Reaction outcome loss': 0.7995031830228743, 'Total loss': 0.7995031830228743}
2022-11-23 01:20:00,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:00,182 INFO:     Epoch: 70
2022-11-23 01:20:00,943 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8199304577916168, 'Total loss': 0.8199304577916168} | train loss {'Reaction outcome loss': 0.8046490220261402, 'Total loss': 0.8046490220261402}
2022-11-23 01:20:00,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:00,943 INFO:     Epoch: 71
2022-11-23 01:20:01,730 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8040708469790082, 'Total loss': 0.8040708469790082} | train loss {'Reaction outcome loss': 0.8029023182929539, 'Total loss': 0.8029023182929539}
2022-11-23 01:20:01,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:01,731 INFO:     Epoch: 72
2022-11-23 01:20:02,497 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8018282866755198, 'Total loss': 0.8018282866755198} | train loss {'Reaction outcome loss': 0.7969319278099498, 'Total loss': 0.7969319278099498}
2022-11-23 01:20:02,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:02,498 INFO:     Epoch: 73
2022-11-23 01:20:03,247 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7932504803635353, 'Total loss': 0.7932504803635353} | train loss {'Reaction outcome loss': 0.798879901649522, 'Total loss': 0.798879901649522}
2022-11-23 01:20:03,247 INFO:     Found new best model at epoch 73
2022-11-23 01:20:03,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:03,248 INFO:     Epoch: 74
2022-11-23 01:20:04,022 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8109436645064243, 'Total loss': 0.8109436645064243} | train loss {'Reaction outcome loss': 0.795742579170915, 'Total loss': 0.795742579170915}
2022-11-23 01:20:04,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:04,022 INFO:     Epoch: 75
2022-11-23 01:20:04,799 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8175739410311677, 'Total loss': 0.8175739410311677} | train loss {'Reaction outcome loss': 0.7968110009783604, 'Total loss': 0.7968110009783604}
2022-11-23 01:20:04,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:04,799 INFO:     Epoch: 76
2022-11-23 01:20:05,571 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7903869470884634, 'Total loss': 0.7903869470884634} | train loss {'Reaction outcome loss': 0.7947151659697783, 'Total loss': 0.7947151659697783}
2022-11-23 01:20:05,571 INFO:     Found new best model at epoch 76
2022-11-23 01:20:05,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:05,572 INFO:     Epoch: 77
2022-11-23 01:20:06,335 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7954208386498828, 'Total loss': 0.7954208386498828} | train loss {'Reaction outcome loss': 0.7970028054274496, 'Total loss': 0.7970028054274496}
2022-11-23 01:20:06,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:06,335 INFO:     Epoch: 78
2022-11-23 01:20:07,140 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7960339133129564, 'Total loss': 0.7960339133129564} | train loss {'Reaction outcome loss': 0.8038690424844867, 'Total loss': 0.8038690424844867}
2022-11-23 01:20:07,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:07,140 INFO:     Epoch: 79
2022-11-23 01:20:07,939 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8218394372352334, 'Total loss': 0.8218394372352334} | train loss {'Reaction outcome loss': 0.7958335358588422, 'Total loss': 0.7958335358588422}
2022-11-23 01:20:07,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:07,939 INFO:     Epoch: 80
2022-11-23 01:20:08,705 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8002057726993117, 'Total loss': 0.8002057726993117} | train loss {'Reaction outcome loss': 0.797950056732678, 'Total loss': 0.797950056732678}
2022-11-23 01:20:08,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:08,705 INFO:     Epoch: 81
2022-11-23 01:20:09,482 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8011526409969774, 'Total loss': 0.8011526409969774} | train loss {'Reaction outcome loss': 0.7945463698906977, 'Total loss': 0.7945463698906977}
2022-11-23 01:20:09,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:09,482 INFO:     Epoch: 82
2022-11-23 01:20:10,279 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8062892597775126, 'Total loss': 0.8062892597775126} | train loss {'Reaction outcome loss': 0.7945035685037003, 'Total loss': 0.7945035685037003}
2022-11-23 01:20:10,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:10,279 INFO:     Epoch: 83
2022-11-23 01:20:11,039 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.805610268615013, 'Total loss': 0.805610268615013} | train loss {'Reaction outcome loss': 0.7896351475940376, 'Total loss': 0.7896351475940376}
2022-11-23 01:20:11,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:11,039 INFO:     Epoch: 84
2022-11-23 01:20:11,834 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.809823008470757, 'Total loss': 0.809823008470757} | train loss {'Reaction outcome loss': 0.7911975094285167, 'Total loss': 0.7911975094285167}
2022-11-23 01:20:11,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:11,834 INFO:     Epoch: 85
2022-11-23 01:20:12,605 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8237709409968798, 'Total loss': 0.8237709409968798} | train loss {'Reaction outcome loss': 0.7971664703771716, 'Total loss': 0.7971664703771716}
2022-11-23 01:20:12,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:12,605 INFO:     Epoch: 86
2022-11-23 01:20:13,379 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8052890016589054, 'Total loss': 0.8052890016589054} | train loss {'Reaction outcome loss': 0.7916013863487322, 'Total loss': 0.7916013863487322}
2022-11-23 01:20:13,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:13,379 INFO:     Epoch: 87
2022-11-23 01:20:14,154 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8061817475529605, 'Total loss': 0.8061817475529605} | train loss {'Reaction outcome loss': 0.7937111562637033, 'Total loss': 0.7937111562637033}
2022-11-23 01:20:14,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:14,155 INFO:     Epoch: 88
2022-11-23 01:20:14,920 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7998020039048306, 'Total loss': 0.7998020039048306} | train loss {'Reaction outcome loss': 0.7973857048105021, 'Total loss': 0.7973857048105021}
2022-11-23 01:20:14,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:14,920 INFO:     Epoch: 89
2022-11-23 01:20:15,681 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8537586102651995, 'Total loss': 0.8537586102651995} | train loss {'Reaction outcome loss': 0.7881408658672552, 'Total loss': 0.7881408658672552}
2022-11-23 01:20:15,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:15,682 INFO:     Epoch: 90
2022-11-23 01:20:16,435 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7871205598808998, 'Total loss': 0.7871205598808998} | train loss {'Reaction outcome loss': 0.7972399278498087, 'Total loss': 0.7972399278498087}
2022-11-23 01:20:16,435 INFO:     Found new best model at epoch 90
2022-11-23 01:20:16,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:16,436 INFO:     Epoch: 91
2022-11-23 01:20:17,208 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.800161270208137, 'Total loss': 0.800161270208137} | train loss {'Reaction outcome loss': 0.7904476817758357, 'Total loss': 0.7904476817758357}
2022-11-23 01:20:17,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:17,209 INFO:     Epoch: 92
2022-11-23 01:20:17,972 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8322616538336111, 'Total loss': 0.8322616538336111} | train loss {'Reaction outcome loss': 0.7977388528038244, 'Total loss': 0.7977388528038244}
2022-11-23 01:20:17,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:17,973 INFO:     Epoch: 93
2022-11-23 01:20:18,750 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.801406414009804, 'Total loss': 0.801406414009804} | train loss {'Reaction outcome loss': 0.7849711926012742, 'Total loss': 0.7849711926012742}
2022-11-23 01:20:18,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:18,750 INFO:     Epoch: 94
2022-11-23 01:20:19,504 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8009926863881045, 'Total loss': 0.8009926863881045} | train loss {'Reaction outcome loss': 0.7886161509840215, 'Total loss': 0.7886161509840215}
2022-11-23 01:20:19,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:19,505 INFO:     Epoch: 95
2022-11-23 01:20:20,295 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7982126730819081, 'Total loss': 0.7982126730819081} | train loss {'Reaction outcome loss': 0.7867951322285855, 'Total loss': 0.7867951322285855}
2022-11-23 01:20:20,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:20,296 INFO:     Epoch: 96
2022-11-23 01:20:21,060 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7945377785106038, 'Total loss': 0.7945377785106038} | train loss {'Reaction outcome loss': 0.7832384855165834, 'Total loss': 0.7832384855165834}
2022-11-23 01:20:21,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:21,060 INFO:     Epoch: 97
2022-11-23 01:20:21,835 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7990492415982623, 'Total loss': 0.7990492415982623} | train loss {'Reaction outcome loss': 0.7825602164766827, 'Total loss': 0.7825602164766827}
2022-11-23 01:20:21,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:21,836 INFO:     Epoch: 98
2022-11-23 01:20:22,612 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8048654683800631, 'Total loss': 0.8048654683800631} | train loss {'Reaction outcome loss': 0.7858237360344559, 'Total loss': 0.7858237360344559}
2022-11-23 01:20:22,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:22,612 INFO:     Epoch: 99
2022-11-23 01:20:23,390 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7858147745908692, 'Total loss': 0.7858147745908692} | train loss {'Reaction outcome loss': 0.7856729906357702, 'Total loss': 0.7856729906357702}
2022-11-23 01:20:23,390 INFO:     Found new best model at epoch 99
2022-11-23 01:20:23,391 INFO:     Best model found after epoch 100 of 100.
2022-11-23 01:20:23,391 INFO:   Done with stage: TRAINING
2022-11-23 01:20:23,391 INFO:   Starting stage: EVALUATION
2022-11-23 01:20:23,528 INFO:   Done with stage: EVALUATION
2022-11-23 01:20:23,528 INFO:   Leaving out SEQ value Fold_4
2022-11-23 01:20:23,541 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 01:20:23,541 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:20:24,204 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:20:24,205 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:20:24,280 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:20:24,280 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:20:24,280 INFO:     No hyperparam tuning for this model
2022-11-23 01:20:24,281 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:20:24,281 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:20:24,281 INFO:     None feature selector for col prot
2022-11-23 01:20:24,282 INFO:     None feature selector for col prot
2022-11-23 01:20:24,282 INFO:     None feature selector for col prot
2022-11-23 01:20:24,282 INFO:     None feature selector for col chem
2022-11-23 01:20:24,282 INFO:     None feature selector for col chem
2022-11-23 01:20:24,283 INFO:     None feature selector for col chem
2022-11-23 01:20:24,283 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:20:24,283 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:20:24,284 INFO:     Number of params in model 168571
2022-11-23 01:20:24,287 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:20:24,288 INFO:   Starting stage: TRAINING
2022-11-23 01:20:24,345 INFO:     Val loss before train {'Reaction outcome loss': 1.1004230244593187, 'Total loss': 1.1004230244593187}
2022-11-23 01:20:24,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:24,345 INFO:     Epoch: 0
2022-11-23 01:20:25,128 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9432285712523893, 'Total loss': 0.9432285712523893} | train loss {'Reaction outcome loss': 0.8726330915322671, 'Total loss': 0.8726330915322671}
2022-11-23 01:20:25,128 INFO:     Found new best model at epoch 0
2022-11-23 01:20:25,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:25,129 INFO:     Epoch: 1
2022-11-23 01:20:25,926 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.9270282658663663, 'Total loss': 0.9270282658663663} | train loss {'Reaction outcome loss': 0.833653198562653, 'Total loss': 0.833653198562653}
2022-11-23 01:20:25,926 INFO:     Found new best model at epoch 1
2022-11-23 01:20:25,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:25,927 INFO:     Epoch: 2
2022-11-23 01:20:26,723 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.916213562542742, 'Total loss': 0.916213562542742} | train loss {'Reaction outcome loss': 0.8336815899803571, 'Total loss': 0.8336815899803571}
2022-11-23 01:20:26,723 INFO:     Found new best model at epoch 2
2022-11-23 01:20:26,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:26,724 INFO:     Epoch: 3
2022-11-23 01:20:27,492 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.9362136315215718, 'Total loss': 0.9362136315215718} | train loss {'Reaction outcome loss': 0.8328419583529113, 'Total loss': 0.8328419583529113}
2022-11-23 01:20:27,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:27,492 INFO:     Epoch: 4
2022-11-23 01:20:28,315 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.9173527617346157, 'Total loss': 0.9173527617346157} | train loss {'Reaction outcome loss': 0.8281949679348392, 'Total loss': 0.8281949679348392}
2022-11-23 01:20:28,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:28,316 INFO:     Epoch: 5
2022-11-23 01:20:29,141 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.909849073399197, 'Total loss': 0.909849073399197} | train loss {'Reaction outcome loss': 0.8211600934928246, 'Total loss': 0.8211600934928246}
2022-11-23 01:20:29,141 INFO:     Found new best model at epoch 5
2022-11-23 01:20:29,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:29,142 INFO:     Epoch: 6
2022-11-23 01:20:29,966 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.9072420800274069, 'Total loss': 0.9072420800274069} | train loss {'Reaction outcome loss': 0.829621318139528, 'Total loss': 0.829621318139528}
2022-11-23 01:20:29,966 INFO:     Found new best model at epoch 6
2022-11-23 01:20:29,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:29,967 INFO:     Epoch: 7
2022-11-23 01:20:30,781 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.9059199758551337, 'Total loss': 0.9059199758551337} | train loss {'Reaction outcome loss': 0.8192066592484833, 'Total loss': 0.8192066592484833}
2022-11-23 01:20:30,781 INFO:     Found new best model at epoch 7
2022-11-23 01:20:30,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:30,782 INFO:     Epoch: 8
2022-11-23 01:20:31,602 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.9028540334918282, 'Total loss': 0.9028540334918282} | train loss {'Reaction outcome loss': 0.8190342093768873, 'Total loss': 0.8190342093768873}
2022-11-23 01:20:31,602 INFO:     Found new best model at epoch 8
2022-11-23 01:20:31,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:31,603 INFO:     Epoch: 9
2022-11-23 01:20:32,408 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.895195718516003, 'Total loss': 0.895195718516003} | train loss {'Reaction outcome loss': 0.8160806130240803, 'Total loss': 0.8160806130240803}
2022-11-23 01:20:32,408 INFO:     Found new best model at epoch 9
2022-11-23 01:20:32,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:32,409 INFO:     Epoch: 10
2022-11-23 01:20:33,232 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8992764299566095, 'Total loss': 0.8992764299566095} | train loss {'Reaction outcome loss': 0.8257817225417627, 'Total loss': 0.8257817225417627}
2022-11-23 01:20:33,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:33,232 INFO:     Epoch: 11
2022-11-23 01:20:34,038 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8994835845448754, 'Total loss': 0.8994835845448754} | train loss {'Reaction outcome loss': 0.8159967226387277, 'Total loss': 0.8159967226387277}
2022-11-23 01:20:34,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:34,038 INFO:     Epoch: 12
2022-11-23 01:20:34,820 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8966167284683748, 'Total loss': 0.8966167284683748} | train loss {'Reaction outcome loss': 0.812791887323866, 'Total loss': 0.812791887323866}
2022-11-23 01:20:34,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:34,821 INFO:     Epoch: 13
2022-11-23 01:20:35,634 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.9011844979091124, 'Total loss': 0.9011844979091124} | train loss {'Reaction outcome loss': 0.8130725511549576, 'Total loss': 0.8130725511549576}
2022-11-23 01:20:35,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:35,634 INFO:     Epoch: 14
2022-11-23 01:20:36,467 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.9016245271671902, 'Total loss': 0.9016245271671902} | train loss {'Reaction outcome loss': 0.8062355596768228, 'Total loss': 0.8062355596768228}
2022-11-23 01:20:36,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:36,467 INFO:     Epoch: 15
2022-11-23 01:20:37,282 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.9400334507226944, 'Total loss': 0.9400334507226944} | train loss {'Reaction outcome loss': 0.8055045732300774, 'Total loss': 0.8055045732300774}
2022-11-23 01:20:37,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:37,282 INFO:     Epoch: 16
2022-11-23 01:20:38,131 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8881253437562422, 'Total loss': 0.8881253437562422} | train loss {'Reaction outcome loss': 0.8095687285276801, 'Total loss': 0.8095687285276801}
2022-11-23 01:20:38,131 INFO:     Found new best model at epoch 16
2022-11-23 01:20:38,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:38,132 INFO:     Epoch: 17
2022-11-23 01:20:38,913 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8916219798001376, 'Total loss': 0.8916219798001376} | train loss {'Reaction outcome loss': 0.8051489613769267, 'Total loss': 0.8051489613769267}
2022-11-23 01:20:38,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:38,914 INFO:     Epoch: 18
2022-11-23 01:20:39,698 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.9378582293337042, 'Total loss': 0.9378582293337042} | train loss {'Reaction outcome loss': 0.805253751591029, 'Total loss': 0.805253751591029}
2022-11-23 01:20:39,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:39,698 INFO:     Epoch: 19
2022-11-23 01:20:40,495 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.913605503060601, 'Total loss': 0.913605503060601} | train loss {'Reaction outcome loss': 0.821791365803012, 'Total loss': 0.821791365803012}
2022-11-23 01:20:40,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:40,496 INFO:     Epoch: 20
2022-11-23 01:20:41,349 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8977735462513837, 'Total loss': 0.8977735462513837} | train loss {'Reaction outcome loss': 0.8114627430494498, 'Total loss': 0.8114627430494498}
2022-11-23 01:20:41,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:41,350 INFO:     Epoch: 21
2022-11-23 01:20:42,113 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8815847865559838, 'Total loss': 0.8815847865559838} | train loss {'Reaction outcome loss': 0.8180711720636499, 'Total loss': 0.8180711720636499}
2022-11-23 01:20:42,113 INFO:     Found new best model at epoch 21
2022-11-23 01:20:42,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:42,114 INFO:     Epoch: 22
2022-11-23 01:20:42,904 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.9186421490528367, 'Total loss': 0.9186421490528367} | train loss {'Reaction outcome loss': 0.8164962497558671, 'Total loss': 0.8164962497558671}
2022-11-23 01:20:42,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:42,905 INFO:     Epoch: 23
2022-11-23 01:20:43,701 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.9035784602165222, 'Total loss': 0.9035784602165222} | train loss {'Reaction outcome loss': 0.8142373970886956, 'Total loss': 0.8142373970886956}
2022-11-23 01:20:43,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:43,702 INFO:     Epoch: 24
2022-11-23 01:20:44,473 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8848332457921722, 'Total loss': 0.8848332457921722} | train loss {'Reaction outcome loss': 0.8109389062111194, 'Total loss': 0.8109389062111194}
2022-11-23 01:20:44,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:44,473 INFO:     Epoch: 25
2022-11-23 01:20:45,278 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8949451107870449, 'Total loss': 0.8949451107870449} | train loss {'Reaction outcome loss': 0.8075853962044002, 'Total loss': 0.8075853962044002}
2022-11-23 01:20:45,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:45,278 INFO:     Epoch: 26
2022-11-23 01:20:46,096 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8931864906441082, 'Total loss': 0.8931864906441082} | train loss {'Reaction outcome loss': 0.8040804808077059, 'Total loss': 0.8040804808077059}
2022-11-23 01:20:46,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:46,096 INFO:     Epoch: 27
2022-11-23 01:20:46,891 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8850703625516458, 'Total loss': 0.8850703625516458} | train loss {'Reaction outcome loss': 0.8094617476468144, 'Total loss': 0.8094617476468144}
2022-11-23 01:20:46,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:46,891 INFO:     Epoch: 28
2022-11-23 01:20:47,704 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8893007392233069, 'Total loss': 0.8893007392233069} | train loss {'Reaction outcome loss': 0.8067731487183918, 'Total loss': 0.8067731487183918}
2022-11-23 01:20:47,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:47,704 INFO:     Epoch: 29
2022-11-23 01:20:48,506 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.9135637202046134, 'Total loss': 0.9135637202046134} | train loss {'Reaction outcome loss': 0.8050467615064821, 'Total loss': 0.8050467615064821}
2022-11-23 01:20:48,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:48,506 INFO:     Epoch: 30
2022-11-23 01:20:49,285 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8889140303839337, 'Total loss': 0.8889140303839337} | train loss {'Reaction outcome loss': 0.8096383000433687, 'Total loss': 0.8096383000433687}
2022-11-23 01:20:49,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:49,285 INFO:     Epoch: 31
2022-11-23 01:20:50,080 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.9019452252171256, 'Total loss': 0.9019452252171256} | train loss {'Reaction outcome loss': 0.8121100344397278, 'Total loss': 0.8121100344397278}
2022-11-23 01:20:50,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:50,080 INFO:     Epoch: 32
2022-11-23 01:20:50,913 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.9197397922927683, 'Total loss': 0.9197397922927683} | train loss {'Reaction outcome loss': 0.8052112704768837, 'Total loss': 0.8052112704768837}
2022-11-23 01:20:50,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:50,914 INFO:     Epoch: 33
2022-11-23 01:20:51,718 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8922343870455568, 'Total loss': 0.8922343870455568} | train loss {'Reaction outcome loss': 0.8090148253238153, 'Total loss': 0.8090148253238153}
2022-11-23 01:20:51,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:51,718 INFO:     Epoch: 34
2022-11-23 01:20:52,498 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8954558399590579, 'Total loss': 0.8954558399590579} | train loss {'Reaction outcome loss': 0.8142217911689388, 'Total loss': 0.8142217911689388}
2022-11-23 01:20:52,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:52,499 INFO:     Epoch: 35
2022-11-23 01:20:53,292 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.89377342232249, 'Total loss': 0.89377342232249} | train loss {'Reaction outcome loss': 0.8198248436938413, 'Total loss': 0.8198248436938413}
2022-11-23 01:20:53,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:53,292 INFO:     Epoch: 36
2022-11-23 01:20:54,120 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8967737765474753, 'Total loss': 0.8967737765474753} | train loss {'Reaction outcome loss': 0.8134288786635225, 'Total loss': 0.8134288786635225}
2022-11-23 01:20:54,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:54,120 INFO:     Epoch: 37
2022-11-23 01:20:54,939 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.9163698736916889, 'Total loss': 0.9163698736916889} | train loss {'Reaction outcome loss': 0.8096031699827325, 'Total loss': 0.8096031699827325}
2022-11-23 01:20:54,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:54,939 INFO:     Epoch: 38
2022-11-23 01:20:55,751 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8852188302712007, 'Total loss': 0.8852188302712007} | train loss {'Reaction outcome loss': 0.8154186605200594, 'Total loss': 0.8154186605200594}
2022-11-23 01:20:55,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:55,751 INFO:     Epoch: 39
2022-11-23 01:20:56,556 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8948105038567022, 'Total loss': 0.8948105038567022} | train loss {'Reaction outcome loss': 0.8099899343874774, 'Total loss': 0.8099899343874774}
2022-11-23 01:20:56,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:56,556 INFO:     Epoch: 40
2022-11-23 01:20:57,363 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.914527572014115, 'Total loss': 0.914527572014115} | train loss {'Reaction outcome loss': 0.8016771867509312, 'Total loss': 0.8016771867509312}
2022-11-23 01:20:57,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:57,363 INFO:     Epoch: 41
2022-11-23 01:20:58,215 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.896297578107227, 'Total loss': 0.896297578107227} | train loss {'Reaction outcome loss': 0.804012337857895, 'Total loss': 0.804012337857895}
2022-11-23 01:20:58,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:58,216 INFO:     Epoch: 42
2022-11-23 01:20:59,021 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8910657438364896, 'Total loss': 0.8910657438364896} | train loss {'Reaction outcome loss': 0.8061910167125313, 'Total loss': 0.8061910167125313}
2022-11-23 01:20:59,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:59,022 INFO:     Epoch: 43
2022-11-23 01:20:59,793 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.9165579967878081, 'Total loss': 0.9165579967878081} | train loss {'Reaction outcome loss': 0.8036806340883618, 'Total loss': 0.8036806340883618}
2022-11-23 01:20:59,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:20:59,794 INFO:     Epoch: 44
2022-11-23 01:21:00,630 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.890591328794306, 'Total loss': 0.890591328794306} | train loss {'Reaction outcome loss': 0.8067234192299939, 'Total loss': 0.8067234192299939}
2022-11-23 01:21:00,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:00,630 INFO:     Epoch: 45
2022-11-23 01:21:01,408 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8899548507549546, 'Total loss': 0.8899548507549546} | train loss {'Reaction outcome loss': 0.8027215569396975, 'Total loss': 0.8027215569396975}
2022-11-23 01:21:01,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:01,408 INFO:     Epoch: 46
2022-11-23 01:21:02,201 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8934681849046187, 'Total loss': 0.8934681849046187} | train loss {'Reaction outcome loss': 0.7977509150198596, 'Total loss': 0.7977509150198596}
2022-11-23 01:21:02,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:02,201 INFO:     Epoch: 47
2022-11-23 01:21:03,012 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.9379073584621603, 'Total loss': 0.9379073584621603} | train loss {'Reaction outcome loss': 0.8077849982238492, 'Total loss': 0.8077849982238492}
2022-11-23 01:21:03,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:03,012 INFO:     Epoch: 48
2022-11-23 01:21:03,848 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8979673351753842, 'Total loss': 0.8979673351753842} | train loss {'Reaction outcome loss': 0.8129197305995925, 'Total loss': 0.8129197305995925}
2022-11-23 01:21:03,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:03,849 INFO:     Epoch: 49
2022-11-23 01:21:04,700 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.9063342674212023, 'Total loss': 0.9063342674212023} | train loss {'Reaction outcome loss': 0.8120681706227755, 'Total loss': 0.8120681706227755}
2022-11-23 01:21:04,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:04,700 INFO:     Epoch: 50
2022-11-23 01:21:05,521 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8994290496815335, 'Total loss': 0.8994290496815335} | train loss {'Reaction outcome loss': 0.8234454872395828, 'Total loss': 0.8234454872395828}
2022-11-23 01:21:05,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:05,521 INFO:     Epoch: 51
2022-11-23 01:21:06,347 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.898545422337272, 'Total loss': 0.898545422337272} | train loss {'Reaction outcome loss': 0.8029697195962373, 'Total loss': 0.8029697195962373}
2022-11-23 01:21:06,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:06,348 INFO:     Epoch: 52
2022-11-23 01:21:07,182 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8900357972491871, 'Total loss': 0.8900357972491871} | train loss {'Reaction outcome loss': 0.8010678801097368, 'Total loss': 0.8010678801097368}
2022-11-23 01:21:07,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:07,182 INFO:     Epoch: 53
2022-11-23 01:21:07,965 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.9017289253798398, 'Total loss': 0.9017289253798398} | train loss {'Reaction outcome loss': 0.7972449485272893, 'Total loss': 0.7972449485272893}
2022-11-23 01:21:07,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:07,965 INFO:     Epoch: 54
2022-11-23 01:21:08,741 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8854902183467691, 'Total loss': 0.8854902183467691} | train loss {'Reaction outcome loss': 0.800504710389535, 'Total loss': 0.800504710389535}
2022-11-23 01:21:08,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:08,742 INFO:     Epoch: 55
2022-11-23 01:21:09,520 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8885296203873374, 'Total loss': 0.8885296203873374} | train loss {'Reaction outcome loss': 0.8075645914685871, 'Total loss': 0.8075645914685871}
2022-11-23 01:21:09,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:09,520 INFO:     Epoch: 56
2022-11-23 01:21:10,301 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8957110833037983, 'Total loss': 0.8957110833037983} | train loss {'Reaction outcome loss': 0.8025297030565227, 'Total loss': 0.8025297030565227}
2022-11-23 01:21:10,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:10,301 INFO:     Epoch: 57
2022-11-23 01:21:11,114 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8777151107788086, 'Total loss': 0.8777151107788086} | train loss {'Reaction outcome loss': 0.8045706470244327, 'Total loss': 0.8045706470244327}
2022-11-23 01:21:11,115 INFO:     Found new best model at epoch 57
2022-11-23 01:21:11,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:11,116 INFO:     Epoch: 58
2022-11-23 01:21:11,956 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8921343345533718, 'Total loss': 0.8921343345533718} | train loss {'Reaction outcome loss': 0.8075071585323164, 'Total loss': 0.8075071585323164}
2022-11-23 01:21:11,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:11,956 INFO:     Epoch: 59
2022-11-23 01:21:12,744 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.9145440581169996, 'Total loss': 0.9145440581169996} | train loss {'Reaction outcome loss': 0.8045599131207717, 'Total loss': 0.8045599131207717}
2022-11-23 01:21:12,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:12,744 INFO:     Epoch: 60
2022-11-23 01:21:13,540 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8814904005690054, 'Total loss': 0.8814904005690054} | train loss {'Reaction outcome loss': 0.804776925533286, 'Total loss': 0.804776925533286}
2022-11-23 01:21:13,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:13,540 INFO:     Epoch: 61
2022-11-23 01:21:14,342 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8834087042645975, 'Total loss': 0.8834087042645975} | train loss {'Reaction outcome loss': 0.8012511276523111, 'Total loss': 0.8012511276523111}
2022-11-23 01:21:14,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:14,342 INFO:     Epoch: 62
2022-11-23 01:21:15,165 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.9037308090112426, 'Total loss': 0.9037308090112426} | train loss {'Reaction outcome loss': 0.8012868851302606, 'Total loss': 0.8012868851302606}
2022-11-23 01:21:15,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:15,165 INFO:     Epoch: 63
2022-11-23 01:21:15,984 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8856196755712683, 'Total loss': 0.8856196755712683} | train loss {'Reaction outcome loss': 0.8009907863883354, 'Total loss': 0.8009907863883354}
2022-11-23 01:21:15,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:15,984 INFO:     Epoch: 64
2022-11-23 01:21:16,801 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8846755115823313, 'Total loss': 0.8846755115823313} | train loss {'Reaction outcome loss': 0.8078202161229091, 'Total loss': 0.8078202161229091}
2022-11-23 01:21:16,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:16,801 INFO:     Epoch: 65
2022-11-23 01:21:17,652 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8853266347538341, 'Total loss': 0.8853266347538341} | train loss {'Reaction outcome loss': 0.8119955644433797, 'Total loss': 0.8119955644433797}
2022-11-23 01:21:17,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:17,652 INFO:     Epoch: 66
2022-11-23 01:21:18,494 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8848198638720945, 'Total loss': 0.8848198638720945} | train loss {'Reaction outcome loss': 0.8060399697497789, 'Total loss': 0.8060399697497789}
2022-11-23 01:21:18,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:18,494 INFO:     Epoch: 67
2022-11-23 01:21:19,302 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.9017278335311196, 'Total loss': 0.9017278335311196} | train loss {'Reaction outcome loss': 0.806822377298525, 'Total loss': 0.806822377298525}
2022-11-23 01:21:19,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:19,302 INFO:     Epoch: 68
2022-11-23 01:21:20,116 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8905416334217245, 'Total loss': 0.8905416334217245} | train loss {'Reaction outcome loss': 0.8014829064670362, 'Total loss': 0.8014829064670362}
2022-11-23 01:21:20,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:20,116 INFO:     Epoch: 69
2022-11-23 01:21:20,935 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8828482275659387, 'Total loss': 0.8828482275659387} | train loss {'Reaction outcome loss': 0.7988848252606536, 'Total loss': 0.7988848252606536}
2022-11-23 01:21:20,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:20,935 INFO:     Epoch: 70
2022-11-23 01:21:21,721 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8802081630988554, 'Total loss': 0.8802081630988554} | train loss {'Reaction outcome loss': 0.8172233432893329, 'Total loss': 0.8172233432893329}
2022-11-23 01:21:21,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:21,722 INFO:     Epoch: 71
2022-11-23 01:21:22,523 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.9031651765108109, 'Total loss': 0.9031651765108109} | train loss {'Reaction outcome loss': 0.8082379636011625, 'Total loss': 0.8082379636011625}
2022-11-23 01:21:22,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:22,524 INFO:     Epoch: 72
2022-11-23 01:21:23,380 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8920197263360023, 'Total loss': 0.8920197263360023} | train loss {'Reaction outcome loss': 0.8042758225429396, 'Total loss': 0.8042758225429396}
2022-11-23 01:21:23,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:23,380 INFO:     Epoch: 73
2022-11-23 01:21:24,228 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8830243863842704, 'Total loss': 0.8830243863842704} | train loss {'Reaction outcome loss': 0.8025045205465695, 'Total loss': 0.8025045205465695}
2022-11-23 01:21:24,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:24,229 INFO:     Epoch: 74
2022-11-23 01:21:25,099 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8985716646367853, 'Total loss': 0.8985716646367853} | train loss {'Reaction outcome loss': 0.8059824300922362, 'Total loss': 0.8059824300922362}
2022-11-23 01:21:25,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:25,100 INFO:     Epoch: 75
2022-11-23 01:21:25,900 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.9042291397398169, 'Total loss': 0.9042291397398169} | train loss {'Reaction outcome loss': 0.813090140640977, 'Total loss': 0.813090140640977}
2022-11-23 01:21:25,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:25,901 INFO:     Epoch: 76
2022-11-23 01:21:26,698 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8841265243562785, 'Total loss': 0.8841265243562785} | train loss {'Reaction outcome loss': 0.8030826848769478, 'Total loss': 0.8030826848769478}
2022-11-23 01:21:26,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:26,699 INFO:     Epoch: 77
2022-11-23 01:21:27,522 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8925810388543389, 'Total loss': 0.8925810388543389} | train loss {'Reaction outcome loss': 0.799522297192923, 'Total loss': 0.799522297192923}
2022-11-23 01:21:27,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:27,522 INFO:     Epoch: 78
2022-11-23 01:21:28,331 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.9018053182146766, 'Total loss': 0.9018053182146766} | train loss {'Reaction outcome loss': 0.802576717215511, 'Total loss': 0.802576717215511}
2022-11-23 01:21:28,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:28,331 INFO:     Epoch: 79
2022-11-23 01:21:29,143 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8785790337080305, 'Total loss': 0.8785790337080305} | train loss {'Reaction outcome loss': 0.8037960974552371, 'Total loss': 0.8037960974552371}
2022-11-23 01:21:29,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:29,143 INFO:     Epoch: 80
2022-11-23 01:21:29,943 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.887911821630868, 'Total loss': 0.887911821630868} | train loss {'Reaction outcome loss': 0.8028293241132126, 'Total loss': 0.8028293241132126}
2022-11-23 01:21:29,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:29,943 INFO:     Epoch: 81
2022-11-23 01:21:30,766 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.889623453671282, 'Total loss': 0.889623453671282} | train loss {'Reaction outcome loss': 0.8001789910952571, 'Total loss': 0.8001789910952571}
2022-11-23 01:21:30,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:30,767 INFO:     Epoch: 82
2022-11-23 01:21:31,584 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.9085571860725229, 'Total loss': 0.9085571860725229} | train loss {'Reaction outcome loss': 0.7996073111831418, 'Total loss': 0.7996073111831418}
2022-11-23 01:21:31,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:31,584 INFO:     Epoch: 83
2022-11-23 01:21:32,424 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.888537616214969, 'Total loss': 0.888537616214969} | train loss {'Reaction outcome loss': 0.8018610851484754, 'Total loss': 0.8018610851484754}
2022-11-23 01:21:32,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:32,424 INFO:     Epoch: 84
2022-11-23 01:21:33,209 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8967126567255367, 'Total loss': 0.8967126567255367} | train loss {'Reaction outcome loss': 0.8010417231422687, 'Total loss': 0.8010417231422687}
2022-11-23 01:21:33,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:33,209 INFO:     Epoch: 85
2022-11-23 01:21:33,998 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8891875865784559, 'Total loss': 0.8891875865784559} | train loss {'Reaction outcome loss': 0.8012207214407593, 'Total loss': 0.8012207214407593}
2022-11-23 01:21:33,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:33,998 INFO:     Epoch: 86
2022-11-23 01:21:34,804 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.892802978103811, 'Total loss': 0.892802978103811} | train loss {'Reaction outcome loss': 0.8021274229534242, 'Total loss': 0.8021274229534242}
2022-11-23 01:21:34,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:34,804 INFO:     Epoch: 87
2022-11-23 01:21:35,586 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.9002829478545622, 'Total loss': 0.9002829478545622} | train loss {'Reaction outcome loss': 0.8047078807464978, 'Total loss': 0.8047078807464978}
2022-11-23 01:21:35,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:35,586 INFO:     Epoch: 88
2022-11-23 01:21:36,423 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.9001304940743879, 'Total loss': 0.9001304940743879} | train loss {'Reaction outcome loss': 0.7995293452913462, 'Total loss': 0.7995293452913462}
2022-11-23 01:21:36,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:36,423 INFO:     Epoch: 89
2022-11-23 01:21:37,238 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8849590732292696, 'Total loss': 0.8849590732292696} | train loss {'Reaction outcome loss': 0.798805417319541, 'Total loss': 0.798805417319541}
2022-11-23 01:21:37,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:37,238 INFO:     Epoch: 90
2022-11-23 01:21:38,049 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.9428333111784675, 'Total loss': 0.9428333111784675} | train loss {'Reaction outcome loss': 0.7994633729641254, 'Total loss': 0.7994633729641254}
2022-11-23 01:21:38,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:38,049 INFO:     Epoch: 91
2022-11-23 01:21:38,828 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8797532645138827, 'Total loss': 0.8797532645138827} | train loss {'Reaction outcome loss': 0.8030586806144792, 'Total loss': 0.8030586806144792}
2022-11-23 01:21:38,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:38,828 INFO:     Epoch: 92
2022-11-23 01:21:39,659 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.874297326261347, 'Total loss': 0.874297326261347} | train loss {'Reaction outcome loss': 0.804636319518572, 'Total loss': 0.804636319518572}
2022-11-23 01:21:39,659 INFO:     Found new best model at epoch 92
2022-11-23 01:21:39,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:39,660 INFO:     Epoch: 93
2022-11-23 01:21:40,483 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8902304037050768, 'Total loss': 0.8902304037050768} | train loss {'Reaction outcome loss': 0.8002225977447834, 'Total loss': 0.8002225977447834}
2022-11-23 01:21:40,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:40,483 INFO:     Epoch: 94
2022-11-23 01:21:41,288 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.899219998581843, 'Total loss': 0.899219998581843} | train loss {'Reaction outcome loss': 0.799914534124527, 'Total loss': 0.799914534124527}
2022-11-23 01:21:41,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:41,288 INFO:     Epoch: 95
2022-11-23 01:21:42,135 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8838699175552889, 'Total loss': 0.8838699175552889} | train loss {'Reaction outcome loss': 0.7929414160821119, 'Total loss': 0.7929414160821119}
2022-11-23 01:21:42,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:42,135 INFO:     Epoch: 96
2022-11-23 01:21:42,973 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.9007398865439675, 'Total loss': 0.9007398865439675} | train loss {'Reaction outcome loss': 0.7980461042479947, 'Total loss': 0.7980461042479947}
2022-11-23 01:21:42,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:42,974 INFO:     Epoch: 97
2022-11-23 01:21:43,794 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8958463736555793, 'Total loss': 0.8958463736555793} | train loss {'Reaction outcome loss': 0.8035939485437957, 'Total loss': 0.8035939485437957}
2022-11-23 01:21:43,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:43,794 INFO:     Epoch: 98
2022-11-23 01:21:44,606 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8850320943377235, 'Total loss': 0.8850320943377235} | train loss {'Reaction outcome loss': 0.8006008710214484, 'Total loss': 0.8006008710214484}
2022-11-23 01:21:44,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:44,606 INFO:     Epoch: 99
2022-11-23 01:21:45,389 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8966540856794878, 'Total loss': 0.8966540856794878} | train loss {'Reaction outcome loss': 0.8001003439730479, 'Total loss': 0.8001003439730479}
2022-11-23 01:21:45,389 INFO:     Best model found after epoch 93 of 100.
2022-11-23 01:21:45,389 INFO:   Done with stage: TRAINING
2022-11-23 01:21:45,389 INFO:   Starting stage: EVALUATION
2022-11-23 01:21:45,514 INFO:   Done with stage: EVALUATION
2022-11-23 01:21:45,514 INFO:   Leaving out SEQ value Fold_5
2022-11-23 01:21:45,527 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 01:21:45,527 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:21:46,203 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:21:46,203 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:21:46,275 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:21:46,275 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:21:46,275 INFO:     No hyperparam tuning for this model
2022-11-23 01:21:46,275 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:21:46,275 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:21:46,276 INFO:     None feature selector for col prot
2022-11-23 01:21:46,276 INFO:     None feature selector for col prot
2022-11-23 01:21:46,276 INFO:     None feature selector for col prot
2022-11-23 01:21:46,276 INFO:     None feature selector for col chem
2022-11-23 01:21:46,277 INFO:     None feature selector for col chem
2022-11-23 01:21:46,277 INFO:     None feature selector for col chem
2022-11-23 01:21:46,277 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:21:46,277 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:21:46,278 INFO:     Number of params in model 168571
2022-11-23 01:21:46,282 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:21:46,282 INFO:   Starting stage: TRAINING
2022-11-23 01:21:46,340 INFO:     Val loss before train {'Reaction outcome loss': 1.0157085724852302, 'Total loss': 1.0157085724852302}
2022-11-23 01:21:46,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:46,340 INFO:     Epoch: 0
2022-11-23 01:21:47,132 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8449440402063456, 'Total loss': 0.8449440402063456} | train loss {'Reaction outcome loss': 0.8736802772109807, 'Total loss': 0.8736802772109807}
2022-11-23 01:21:47,132 INFO:     Found new best model at epoch 0
2022-11-23 01:21:47,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:47,134 INFO:     Epoch: 1
2022-11-23 01:21:47,930 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8107800558209419, 'Total loss': 0.8107800558209419} | train loss {'Reaction outcome loss': 0.8391268363124446, 'Total loss': 0.8391268363124446}
2022-11-23 01:21:47,930 INFO:     Found new best model at epoch 1
2022-11-23 01:21:47,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:47,934 INFO:     Epoch: 2
2022-11-23 01:21:48,751 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8356389064680446, 'Total loss': 0.8356389064680446} | train loss {'Reaction outcome loss': 0.8377545507330644, 'Total loss': 0.8377545507330644}
2022-11-23 01:21:48,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:48,751 INFO:     Epoch: 3
2022-11-23 01:21:49,612 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8033630922436714, 'Total loss': 0.8033630922436714} | train loss {'Reaction outcome loss': 0.8347066538295282, 'Total loss': 0.8347066538295282}
2022-11-23 01:21:49,613 INFO:     Found new best model at epoch 3
2022-11-23 01:21:49,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:49,613 INFO:     Epoch: 4
2022-11-23 01:21:50,459 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8243948851119388, 'Total loss': 0.8243948851119388} | train loss {'Reaction outcome loss': 0.8357230784439365, 'Total loss': 0.8357230784439365}
2022-11-23 01:21:50,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:50,460 INFO:     Epoch: 5
2022-11-23 01:21:51,285 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8050030422481623, 'Total loss': 0.8050030422481623} | train loss {'Reaction outcome loss': 0.8263626408721754, 'Total loss': 0.8263626408721754}
2022-11-23 01:21:51,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:51,285 INFO:     Epoch: 6
2022-11-23 01:21:52,106 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8287789875810797, 'Total loss': 0.8287789875810797} | train loss {'Reaction outcome loss': 0.8207218288048076, 'Total loss': 0.8207218288048076}
2022-11-23 01:21:52,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:52,106 INFO:     Epoch: 7
2022-11-23 01:21:52,933 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8177637566219677, 'Total loss': 0.8177637566219677} | train loss {'Reaction outcome loss': 0.8260381360526993, 'Total loss': 0.8260381360526993}
2022-11-23 01:21:52,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:52,933 INFO:     Epoch: 8
2022-11-23 01:21:53,771 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8036394586617296, 'Total loss': 0.8036394586617296} | train loss {'Reaction outcome loss': 0.8212430683466104, 'Total loss': 0.8212430683466104}
2022-11-23 01:21:53,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:53,771 INFO:     Epoch: 9
2022-11-23 01:21:54,582 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8043478442863985, 'Total loss': 0.8043478442863985} | train loss {'Reaction outcome loss': 0.8336104122009355, 'Total loss': 0.8336104122009355}
2022-11-23 01:21:54,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:54,582 INFO:     Epoch: 10
2022-11-23 01:21:55,394 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8057048740712079, 'Total loss': 0.8057048740712079} | train loss {'Reaction outcome loss': 0.816425729377067, 'Total loss': 0.816425729377067}
2022-11-23 01:21:55,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:55,396 INFO:     Epoch: 11
2022-11-23 01:21:56,199 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7949309274554253, 'Total loss': 0.7949309274554253} | train loss {'Reaction outcome loss': 0.8241117532677978, 'Total loss': 0.8241117532677978}
2022-11-23 01:21:56,199 INFO:     Found new best model at epoch 11
2022-11-23 01:21:56,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:56,200 INFO:     Epoch: 12
2022-11-23 01:21:57,053 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8154090399091894, 'Total loss': 0.8154090399091894} | train loss {'Reaction outcome loss': 0.8175973328742904, 'Total loss': 0.8175973328742904}
2022-11-23 01:21:57,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:57,054 INFO:     Epoch: 13
2022-11-23 01:21:57,870 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8019428625702858, 'Total loss': 0.8019428625702858} | train loss {'Reaction outcome loss': 0.8206280641227599, 'Total loss': 0.8206280641227599}
2022-11-23 01:21:57,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:57,871 INFO:     Epoch: 14
2022-11-23 01:21:58,673 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8039491522041234, 'Total loss': 0.8039491522041234} | train loss {'Reaction outcome loss': 0.8232224379413524, 'Total loss': 0.8232224379413524}
2022-11-23 01:21:58,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:58,673 INFO:     Epoch: 15
2022-11-23 01:21:59,455 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7923210236159238, 'Total loss': 0.7923210236159238} | train loss {'Reaction outcome loss': 0.8208808789127752, 'Total loss': 0.8208808789127752}
2022-11-23 01:21:59,456 INFO:     Found new best model at epoch 15
2022-11-23 01:21:59,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:21:59,456 INFO:     Epoch: 16
2022-11-23 01:22:00,240 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7958193611014973, 'Total loss': 0.7958193611014973} | train loss {'Reaction outcome loss': 0.8131373321961778, 'Total loss': 0.8131373321961778}
2022-11-23 01:22:00,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:00,240 INFO:     Epoch: 17
2022-11-23 01:22:01,084 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.79998452487317, 'Total loss': 0.79998452487317} | train loss {'Reaction outcome loss': 0.8161963824077174, 'Total loss': 0.8161963824077174}
2022-11-23 01:22:01,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:01,085 INFO:     Epoch: 18
2022-11-23 01:22:01,867 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7912018956108526, 'Total loss': 0.7912018956108526} | train loss {'Reaction outcome loss': 0.8148876830392521, 'Total loss': 0.8148876830392521}
2022-11-23 01:22:01,867 INFO:     Found new best model at epoch 18
2022-11-23 01:22:01,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:01,868 INFO:     Epoch: 19
2022-11-23 01:22:02,682 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8022527566010301, 'Total loss': 0.8022527566010301} | train loss {'Reaction outcome loss': 0.8199206860924539, 'Total loss': 0.8199206860924539}
2022-11-23 01:22:02,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:02,682 INFO:     Epoch: 20
2022-11-23 01:22:03,489 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8294962326234038, 'Total loss': 0.8294962326234038} | train loss {'Reaction outcome loss': 0.820111021097855, 'Total loss': 0.820111021097855}
2022-11-23 01:22:03,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:03,489 INFO:     Epoch: 21
2022-11-23 01:22:04,449 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8140126310966231, 'Total loss': 0.8140126310966231} | train loss {'Reaction outcome loss': 0.8159540931464206, 'Total loss': 0.8159540931464206}
2022-11-23 01:22:04,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:04,449 INFO:     Epoch: 22
2022-11-23 01:22:05,334 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8287200412966989, 'Total loss': 0.8287200412966989} | train loss {'Reaction outcome loss': 0.8159205417642709, 'Total loss': 0.8159205417642709}
2022-11-23 01:22:05,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:05,334 INFO:     Epoch: 23
2022-11-23 01:22:06,227 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7896873984824527, 'Total loss': 0.7896873984824527} | train loss {'Reaction outcome loss': 0.8145572995910277, 'Total loss': 0.8145572995910277}
2022-11-23 01:22:06,227 INFO:     Found new best model at epoch 23
2022-11-23 01:22:06,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:06,228 INFO:     Epoch: 24
2022-11-23 01:22:07,131 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8035823540254072, 'Total loss': 0.8035823540254072} | train loss {'Reaction outcome loss': 0.8181951757867326, 'Total loss': 0.8181951757867326}
2022-11-23 01:22:07,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:07,131 INFO:     Epoch: 25
2022-11-23 01:22:07,981 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7951338677243753, 'Total loss': 0.7951338677243753} | train loss {'Reaction outcome loss': 0.8202701984388143, 'Total loss': 0.8202701984388143}
2022-11-23 01:22:07,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:07,981 INFO:     Epoch: 26
2022-11-23 01:22:08,910 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8014193935827776, 'Total loss': 0.8014193935827776} | train loss {'Reaction outcome loss': 0.8185639755445936, 'Total loss': 0.8185639755445936}
2022-11-23 01:22:08,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:08,910 INFO:     Epoch: 27
2022-11-23 01:22:09,827 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7827655971050262, 'Total loss': 0.7827655971050262} | train loss {'Reaction outcome loss': 0.8148795386195665, 'Total loss': 0.8148795386195665}
2022-11-23 01:22:09,827 INFO:     Found new best model at epoch 27
2022-11-23 01:22:09,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:09,828 INFO:     Epoch: 28
2022-11-23 01:22:10,714 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8246333253654566, 'Total loss': 0.8246333253654566} | train loss {'Reaction outcome loss': 0.8084854346658537, 'Total loss': 0.8084854346658537}
2022-11-23 01:22:10,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:10,715 INFO:     Epoch: 29
2022-11-23 01:22:11,598 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7807827232913538, 'Total loss': 0.7807827232913538} | train loss {'Reaction outcome loss': 0.8111408714823395, 'Total loss': 0.8111408714823395}
2022-11-23 01:22:11,598 INFO:     Found new best model at epoch 29
2022-11-23 01:22:11,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:11,599 INFO:     Epoch: 30
2022-11-23 01:22:12,536 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8007942519404672, 'Total loss': 0.8007942519404672} | train loss {'Reaction outcome loss': 0.8127271506467811, 'Total loss': 0.8127271506467811}
2022-11-23 01:22:12,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:12,537 INFO:     Epoch: 31
2022-11-23 01:22:13,409 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7924759902737357, 'Total loss': 0.7924759902737357} | train loss {'Reaction outcome loss': 0.8104278652774177, 'Total loss': 0.8104278652774177}
2022-11-23 01:22:13,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:13,409 INFO:     Epoch: 32
2022-11-23 01:22:14,274 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.813051390376958, 'Total loss': 0.813051390376958} | train loss {'Reaction outcome loss': 0.8156575081560776, 'Total loss': 0.8156575081560776}
2022-11-23 01:22:14,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:14,275 INFO:     Epoch: 33
2022-11-23 01:22:15,176 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.797112456776879, 'Total loss': 0.797112456776879} | train loss {'Reaction outcome loss': 0.8128597600016034, 'Total loss': 0.8128597600016034}
2022-11-23 01:22:15,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:15,177 INFO:     Epoch: 34
2022-11-23 01:22:16,130 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8026324327696454, 'Total loss': 0.8026324327696454} | train loss {'Reaction outcome loss': 0.8246036311875471, 'Total loss': 0.8246036311875471}
2022-11-23 01:22:16,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:16,130 INFO:     Epoch: 35
2022-11-23 01:22:17,003 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7958376678553495, 'Total loss': 0.7958376678553495} | train loss {'Reaction outcome loss': 0.8156047787079926, 'Total loss': 0.8156047787079926}
2022-11-23 01:22:17,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:17,003 INFO:     Epoch: 36
2022-11-23 01:22:17,900 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7917740094390783, 'Total loss': 0.7917740094390783} | train loss {'Reaction outcome loss': 0.8134376752955711, 'Total loss': 0.8134376752955711}
2022-11-23 01:22:17,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:17,900 INFO:     Epoch: 37
2022-11-23 01:22:18,766 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7988165339285677, 'Total loss': 0.7988165339285677} | train loss {'Reaction outcome loss': 0.8115229260342324, 'Total loss': 0.8115229260342324}
2022-11-23 01:22:18,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:18,766 INFO:     Epoch: 38
2022-11-23 01:22:19,613 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8029031990603968, 'Total loss': 0.8029031990603968} | train loss {'Reaction outcome loss': 0.8174141909670734, 'Total loss': 0.8174141909670734}
2022-11-23 01:22:19,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:19,613 INFO:     Epoch: 39
2022-11-23 01:22:20,496 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7805260345339775, 'Total loss': 0.7805260345339775} | train loss {'Reaction outcome loss': 0.8099692455428814, 'Total loss': 0.8099692455428814}
2022-11-23 01:22:20,496 INFO:     Found new best model at epoch 39
2022-11-23 01:22:20,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:20,497 INFO:     Epoch: 40
2022-11-23 01:22:21,395 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7820566228844903, 'Total loss': 0.7820566228844903} | train loss {'Reaction outcome loss': 0.8127724476430097, 'Total loss': 0.8127724476430097}
2022-11-23 01:22:21,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:21,395 INFO:     Epoch: 41
2022-11-23 01:22:22,294 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7930094904520295, 'Total loss': 0.7930094904520295} | train loss {'Reaction outcome loss': 0.8142625924788023, 'Total loss': 0.8142625924788023}
2022-11-23 01:22:22,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:22,294 INFO:     Epoch: 42
2022-11-23 01:22:23,156 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8058784780177203, 'Total loss': 0.8058784780177203} | train loss {'Reaction outcome loss': 0.810582330080903, 'Total loss': 0.810582330080903}
2022-11-23 01:22:23,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:23,156 INFO:     Epoch: 43
2022-11-23 01:22:24,128 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7948008572513406, 'Total loss': 0.7948008572513406} | train loss {'Reaction outcome loss': 0.8124516473607979, 'Total loss': 0.8124516473607979}
2022-11-23 01:22:24,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:24,129 INFO:     Epoch: 44
2022-11-23 01:22:25,009 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8001869788224046, 'Total loss': 0.8001869788224046} | train loss {'Reaction outcome loss': 0.8107809162574259, 'Total loss': 0.8107809162574259}
2022-11-23 01:22:25,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:25,009 INFO:     Epoch: 45
2022-11-23 01:22:25,901 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8011349859562787, 'Total loss': 0.8011349859562787} | train loss {'Reaction outcome loss': 0.8149945941048595, 'Total loss': 0.8149945941048595}
2022-11-23 01:22:25,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:25,903 INFO:     Epoch: 46
2022-11-23 01:22:26,813 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7809995629570701, 'Total loss': 0.7809995629570701} | train loss {'Reaction outcome loss': 0.8098385779239871, 'Total loss': 0.8098385779239871}
2022-11-23 01:22:26,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:26,813 INFO:     Epoch: 47
2022-11-23 01:22:27,696 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7903618067502975, 'Total loss': 0.7903618067502975} | train loss {'Reaction outcome loss': 0.8117237469927985, 'Total loss': 0.8117237469927985}
2022-11-23 01:22:27,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:27,696 INFO:     Epoch: 48
2022-11-23 01:22:28,562 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7843926603143866, 'Total loss': 0.7843926603143866} | train loss {'Reaction outcome loss': 0.8238540426922231, 'Total loss': 0.8238540426922231}
2022-11-23 01:22:28,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:28,562 INFO:     Epoch: 49
2022-11-23 01:22:29,447 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7946017174558206, 'Total loss': 0.7946017174558206} | train loss {'Reaction outcome loss': 0.8164497724911461, 'Total loss': 0.8164497724911461}
2022-11-23 01:22:29,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:29,448 INFO:     Epoch: 50
2022-11-23 01:22:30,327 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7867362174120817, 'Total loss': 0.7867362174120817} | train loss {'Reaction outcome loss': 0.8115526092679877, 'Total loss': 0.8115526092679877}
2022-11-23 01:22:30,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:30,328 INFO:     Epoch: 51
2022-11-23 01:22:31,237 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7781270512125709, 'Total loss': 0.7781270512125709} | train loss {'Reaction outcome loss': 0.8176930164277312, 'Total loss': 0.8176930164277312}
2022-11-23 01:22:31,237 INFO:     Found new best model at epoch 51
2022-11-23 01:22:31,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:31,238 INFO:     Epoch: 52
2022-11-23 01:22:32,129 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7922631434418939, 'Total loss': 0.7922631434418939} | train loss {'Reaction outcome loss': 0.8123530556074521, 'Total loss': 0.8123530556074521}
2022-11-23 01:22:32,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:32,130 INFO:     Epoch: 53
2022-11-23 01:22:33,002 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8091110214591026, 'Total loss': 0.8091110214591026} | train loss {'Reaction outcome loss': 0.8103054133262712, 'Total loss': 0.8103054133262712}
2022-11-23 01:22:33,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:33,003 INFO:     Epoch: 54
2022-11-23 01:22:33,914 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8121521459384398, 'Total loss': 0.8121521459384398} | train loss {'Reaction outcome loss': 0.8110298999709639, 'Total loss': 0.8110298999709639}
2022-11-23 01:22:33,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:33,914 INFO:     Epoch: 55
2022-11-23 01:22:34,785 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7870094857432626, 'Total loss': 0.7870094857432626} | train loss {'Reaction outcome loss': 0.8125577504456285, 'Total loss': 0.8125577504456285}
2022-11-23 01:22:34,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:34,785 INFO:     Epoch: 56
2022-11-23 01:22:35,611 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8056820759719069, 'Total loss': 0.8056820759719069} | train loss {'Reaction outcome loss': 0.8065151005742038, 'Total loss': 0.8065151005742038}
2022-11-23 01:22:35,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:35,611 INFO:     Epoch: 57
2022-11-23 01:22:36,534 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8034778101877733, 'Total loss': 0.8034778101877733} | train loss {'Reaction outcome loss': 0.8135903870407869, 'Total loss': 0.8135903870407869}
2022-11-23 01:22:36,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:36,535 INFO:     Epoch: 58
2022-11-23 01:22:37,444 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7888723523779348, 'Total loss': 0.7888723523779348} | train loss {'Reaction outcome loss': 0.8226039097135366, 'Total loss': 0.8226039097135366}
2022-11-23 01:22:37,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:37,444 INFO:     Epoch: 59
2022-11-23 01:22:38,337 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7958408614451234, 'Total loss': 0.7958408614451234} | train loss {'Reaction outcome loss': 0.8133520305398022, 'Total loss': 0.8133520305398022}
2022-11-23 01:22:38,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:38,337 INFO:     Epoch: 60
2022-11-23 01:22:39,208 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7976743321527134, 'Total loss': 0.7976743321527134} | train loss {'Reaction outcome loss': 0.814701608076752, 'Total loss': 0.814701608076752}
2022-11-23 01:22:39,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:39,208 INFO:     Epoch: 61
2022-11-23 01:22:40,081 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7973310432650826, 'Total loss': 0.7973310432650826} | train loss {'Reaction outcome loss': 0.8065355273514141, 'Total loss': 0.8065355273514141}
2022-11-23 01:22:40,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:40,081 INFO:     Epoch: 62
2022-11-23 01:22:40,962 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8198514960028909, 'Total loss': 0.8198514960028909} | train loss {'Reaction outcome loss': 0.8117229258000609, 'Total loss': 0.8117229258000609}
2022-11-23 01:22:40,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:40,962 INFO:     Epoch: 63
2022-11-23 01:22:41,858 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8101284395564686, 'Total loss': 0.8101284395564686} | train loss {'Reaction outcome loss': 0.8209347975881476, 'Total loss': 0.8209347975881476}
2022-11-23 01:22:41,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:41,858 INFO:     Epoch: 64
2022-11-23 01:22:42,720 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7888522500341589, 'Total loss': 0.7888522500341589} | train loss {'Reaction outcome loss': 0.8315456170543485, 'Total loss': 0.8315456170543485}
2022-11-23 01:22:42,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:42,720 INFO:     Epoch: 65
2022-11-23 01:22:43,627 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8006584583358332, 'Total loss': 0.8006584583358332} | train loss {'Reaction outcome loss': 0.8113743311721786, 'Total loss': 0.8113743311721786}
2022-11-23 01:22:43,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:43,628 INFO:     Epoch: 66
2022-11-23 01:22:44,508 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7850894237106497, 'Total loss': 0.7850894237106497} | train loss {'Reaction outcome loss': 0.8135706349181743, 'Total loss': 0.8135706349181743}
2022-11-23 01:22:44,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:44,509 INFO:     Epoch: 67
2022-11-23 01:22:45,364 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.800936182114211, 'Total loss': 0.800936182114211} | train loss {'Reaction outcome loss': 0.8219562384039767, 'Total loss': 0.8219562384039767}
2022-11-23 01:22:45,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:45,364 INFO:     Epoch: 68
2022-11-23 01:22:46,250 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8041690804741599, 'Total loss': 0.8041690804741599} | train loss {'Reaction outcome loss': 0.8084931858638038, 'Total loss': 0.8084931858638038}
2022-11-23 01:22:46,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:46,251 INFO:     Epoch: 69
2022-11-23 01:22:47,150 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7954564548351548, 'Total loss': 0.7954564548351548} | train loss {'Reaction outcome loss': 0.8160306707567532, 'Total loss': 0.8160306707567532}
2022-11-23 01:22:47,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:47,150 INFO:     Epoch: 70
2022-11-23 01:22:48,043 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7798713858832013, 'Total loss': 0.7798713858832013} | train loss {'Reaction outcome loss': 0.8131160765644992, 'Total loss': 0.8131160765644992}
2022-11-23 01:22:48,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:48,043 INFO:     Epoch: 71
2022-11-23 01:22:48,950 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8020700263706121, 'Total loss': 0.8020700263706121} | train loss {'Reaction outcome loss': 0.8119205602026178, 'Total loss': 0.8119205602026178}
2022-11-23 01:22:48,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:48,950 INFO:     Epoch: 72
2022-11-23 01:22:49,819 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7942472445693883, 'Total loss': 0.7942472445693883} | train loss {'Reaction outcome loss': 0.8142752086344035, 'Total loss': 0.8142752086344035}
2022-11-23 01:22:49,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:49,819 INFO:     Epoch: 73
2022-11-23 01:22:50,670 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.790050402960994, 'Total loss': 0.790050402960994} | train loss {'Reaction outcome loss': 0.8162230110844138, 'Total loss': 0.8162230110844138}
2022-11-23 01:22:50,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:50,671 INFO:     Epoch: 74
2022-11-23 01:22:51,532 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8073003732345321, 'Total loss': 0.8073003732345321} | train loss {'Reaction outcome loss': 0.8138046694187983, 'Total loss': 0.8138046694187983}
2022-11-23 01:22:51,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:51,532 INFO:     Epoch: 75
2022-11-23 01:22:52,437 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8388151892206885, 'Total loss': 0.8388151892206885} | train loss {'Reaction outcome loss': 0.8093467442854213, 'Total loss': 0.8093467442854213}
2022-11-23 01:22:52,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:52,438 INFO:     Epoch: 76
2022-11-23 01:22:53,280 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7986251007426869, 'Total loss': 0.7986251007426869} | train loss {'Reaction outcome loss': 0.8148561078406539, 'Total loss': 0.8148561078406539}
2022-11-23 01:22:53,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:53,280 INFO:     Epoch: 77
2022-11-23 01:22:54,158 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7785155942494218, 'Total loss': 0.7785155942494218} | train loss {'Reaction outcome loss': 0.8087100608628771, 'Total loss': 0.8087100608628771}
2022-11-23 01:22:54,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:54,159 INFO:     Epoch: 78
2022-11-23 01:22:55,038 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8051161271604624, 'Total loss': 0.8051161271604624} | train loss {'Reaction outcome loss': 0.8170160102216821, 'Total loss': 0.8170160102216821}
2022-11-23 01:22:55,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:55,039 INFO:     Epoch: 79
2022-11-23 01:22:55,902 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8140906766057014, 'Total loss': 0.8140906766057014} | train loss {'Reaction outcome loss': 0.8175589081488157, 'Total loss': 0.8175589081488157}
2022-11-23 01:22:55,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:55,902 INFO:     Epoch: 80
2022-11-23 01:22:56,769 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7864239608699625, 'Total loss': 0.7864239608699625} | train loss {'Reaction outcome loss': 0.819713468252406, 'Total loss': 0.819713468252406}
2022-11-23 01:22:56,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:56,769 INFO:     Epoch: 81
2022-11-23 01:22:57,633 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.804492321881381, 'Total loss': 0.804492321881381} | train loss {'Reaction outcome loss': 0.8205125527343287, 'Total loss': 0.8205125527343287}
2022-11-23 01:22:57,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:57,635 INFO:     Epoch: 82
2022-11-23 01:22:58,489 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7938611446456476, 'Total loss': 0.7938611446456476} | train loss {'Reaction outcome loss': 0.8221175340023118, 'Total loss': 0.8221175340023118}
2022-11-23 01:22:58,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:58,490 INFO:     Epoch: 83
2022-11-23 01:22:59,362 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7909784100272439, 'Total loss': 0.7909784100272439} | train loss {'Reaction outcome loss': 0.820420353880778, 'Total loss': 0.820420353880778}
2022-11-23 01:22:59,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:22:59,362 INFO:     Epoch: 84
2022-11-23 01:23:00,236 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7958909496665001, 'Total loss': 0.7958909496665001} | train loss {'Reaction outcome loss': 0.811913708262598, 'Total loss': 0.811913708262598}
2022-11-23 01:23:00,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:00,236 INFO:     Epoch: 85
2022-11-23 01:23:01,071 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8102100484750487, 'Total loss': 0.8102100484750487} | train loss {'Reaction outcome loss': 0.813404991921143, 'Total loss': 0.813404991921143}
2022-11-23 01:23:01,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:01,071 INFO:     Epoch: 86
2022-11-23 01:23:01,928 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8094151230020956, 'Total loss': 0.8094151230020956} | train loss {'Reaction outcome loss': 0.8248839909248507, 'Total loss': 0.8248839909248507}
2022-11-23 01:23:01,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:01,928 INFO:     Epoch: 87
2022-11-23 01:23:02,764 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7935889674858614, 'Total loss': 0.7935889674858614} | train loss {'Reaction outcome loss': 0.8125744423402949, 'Total loss': 0.8125744423402949}
2022-11-23 01:23:02,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:02,765 INFO:     Epoch: 88
2022-11-23 01:23:03,642 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7979910712350499, 'Total loss': 0.7979910712350499} | train loss {'Reaction outcome loss': 0.8100365641025397, 'Total loss': 0.8100365641025397}
2022-11-23 01:23:03,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:03,643 INFO:     Epoch: 89
2022-11-23 01:23:04,525 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7897244061936032, 'Total loss': 0.7897244061936032} | train loss {'Reaction outcome loss': 0.8212846031314448, 'Total loss': 0.8212846031314448}
2022-11-23 01:23:04,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:04,525 INFO:     Epoch: 90
2022-11-23 01:23:05,394 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7901126037944447, 'Total loss': 0.7901126037944447} | train loss {'Reaction outcome loss': 0.8094704341791902, 'Total loss': 0.8094704341791902}
2022-11-23 01:23:05,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:05,394 INFO:     Epoch: 91
2022-11-23 01:23:06,283 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8144739046692848, 'Total loss': 0.8144739046692848} | train loss {'Reaction outcome loss': 0.8114365708490132, 'Total loss': 0.8114365708490132}
2022-11-23 01:23:06,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:06,284 INFO:     Epoch: 92
2022-11-23 01:23:07,097 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7982522303407843, 'Total loss': 0.7982522303407843} | train loss {'Reaction outcome loss': 0.8166094259453206, 'Total loss': 0.8166094259453206}
2022-11-23 01:23:07,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:07,098 INFO:     Epoch: 93
2022-11-23 01:23:07,883 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7949368723414161, 'Total loss': 0.7949368723414161} | train loss {'Reaction outcome loss': 0.817459623340653, 'Total loss': 0.817459623340653}
2022-11-23 01:23:07,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:07,883 INFO:     Epoch: 94
2022-11-23 01:23:08,683 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7782411941073157, 'Total loss': 0.7782411941073157} | train loss {'Reaction outcome loss': 0.8123495148623038, 'Total loss': 0.8123495148623038}
2022-11-23 01:23:08,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:08,683 INFO:     Epoch: 95
2022-11-23 01:23:09,478 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8079966658895666, 'Total loss': 0.8079966658895666} | train loss {'Reaction outcome loss': 0.8140869651608139, 'Total loss': 0.8140869651608139}
2022-11-23 01:23:09,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:09,479 INFO:     Epoch: 96
2022-11-23 01:23:10,286 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.79830848086964, 'Total loss': 0.79830848086964} | train loss {'Reaction outcome loss': 0.8173154371711406, 'Total loss': 0.8173154371711406}
2022-11-23 01:23:10,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:10,286 INFO:     Epoch: 97
2022-11-23 01:23:11,104 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.790261487391862, 'Total loss': 0.790261487391862} | train loss {'Reaction outcome loss': 0.813078718508786, 'Total loss': 0.813078718508786}
2022-11-23 01:23:11,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:11,104 INFO:     Epoch: 98
2022-11-23 01:23:11,897 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7848502736199986, 'Total loss': 0.7848502736199986} | train loss {'Reaction outcome loss': 0.8089848457560366, 'Total loss': 0.8089848457560366}
2022-11-23 01:23:11,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:11,897 INFO:     Epoch: 99
2022-11-23 01:23:12,698 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8393518538637594, 'Total loss': 0.8393518538637594} | train loss {'Reaction outcome loss': 0.8191488429843655, 'Total loss': 0.8191488429843655}
2022-11-23 01:23:12,698 INFO:     Best model found after epoch 52 of 100.
2022-11-23 01:23:12,698 INFO:   Done with stage: TRAINING
2022-11-23 01:23:12,698 INFO:   Starting stage: EVALUATION
2022-11-23 01:23:12,823 INFO:   Done with stage: EVALUATION
2022-11-23 01:23:12,824 INFO:   Leaving out SEQ value Fold_6
2022-11-23 01:23:12,837 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 01:23:12,837 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:23:13,517 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:23:13,517 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:23:13,591 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:23:13,591 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:23:13,592 INFO:     No hyperparam tuning for this model
2022-11-23 01:23:13,592 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:23:13,592 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:23:13,593 INFO:     None feature selector for col prot
2022-11-23 01:23:13,593 INFO:     None feature selector for col prot
2022-11-23 01:23:13,593 INFO:     None feature selector for col prot
2022-11-23 01:23:13,594 INFO:     None feature selector for col chem
2022-11-23 01:23:13,594 INFO:     None feature selector for col chem
2022-11-23 01:23:13,594 INFO:     None feature selector for col chem
2022-11-23 01:23:13,594 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:23:13,595 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:23:13,596 INFO:     Number of params in model 168571
2022-11-23 01:23:13,600 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:23:13,600 INFO:   Starting stage: TRAINING
2022-11-23 01:23:13,659 INFO:     Val loss before train {'Reaction outcome loss': 1.0135110129009595, 'Total loss': 1.0135110129009595}
2022-11-23 01:23:13,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:13,659 INFO:     Epoch: 0
2022-11-23 01:23:14,473 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8499811833555048, 'Total loss': 0.8499811833555048} | train loss {'Reaction outcome loss': 0.8702666435828094, 'Total loss': 0.8702666435828094}
2022-11-23 01:23:14,473 INFO:     Found new best model at epoch 0
2022-11-23 01:23:14,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:14,474 INFO:     Epoch: 1
2022-11-23 01:23:15,285 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8642322800376199, 'Total loss': 0.8642322800376199} | train loss {'Reaction outcome loss': 0.8446407401971971, 'Total loss': 0.8446407401971971}
2022-11-23 01:23:15,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:15,286 INFO:     Epoch: 2
2022-11-23 01:23:16,087 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8750470890240236, 'Total loss': 0.8750470890240236} | train loss {'Reaction outcome loss': 0.8490860000071738, 'Total loss': 0.8490860000071738}
2022-11-23 01:23:16,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:16,088 INFO:     Epoch: 3
2022-11-23 01:23:16,885 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8450219577009027, 'Total loss': 0.8450219577009027} | train loss {'Reaction outcome loss': 0.8417759325340209, 'Total loss': 0.8417759325340209}
2022-11-23 01:23:16,886 INFO:     Found new best model at epoch 3
2022-11-23 01:23:16,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:16,886 INFO:     Epoch: 4
2022-11-23 01:23:17,704 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8715888945893808, 'Total loss': 0.8715888945893808} | train loss {'Reaction outcome loss': 0.835364913288881, 'Total loss': 0.835364913288881}
2022-11-23 01:23:17,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:17,704 INFO:     Epoch: 5
2022-11-23 01:23:18,490 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8386942811987617, 'Total loss': 0.8386942811987617} | train loss {'Reaction outcome loss': 0.8294079653948907, 'Total loss': 0.8294079653948907}
2022-11-23 01:23:18,490 INFO:     Found new best model at epoch 5
2022-11-23 01:23:18,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:18,491 INFO:     Epoch: 6
2022-11-23 01:23:19,293 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.83918651396578, 'Total loss': 0.83918651396578} | train loss {'Reaction outcome loss': 0.8288978265847272, 'Total loss': 0.8288978265847272}
2022-11-23 01:23:19,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:19,293 INFO:     Epoch: 7
2022-11-23 01:23:20,067 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8353722576390613, 'Total loss': 0.8353722576390613} | train loss {'Reaction outcome loss': 0.823688510458479, 'Total loss': 0.823688510458479}
2022-11-23 01:23:20,067 INFO:     Found new best model at epoch 7
2022-11-23 01:23:20,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:20,068 INFO:     Epoch: 8
2022-11-23 01:23:20,852 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8312265994873914, 'Total loss': 0.8312265994873914} | train loss {'Reaction outcome loss': 0.8337489506493696, 'Total loss': 0.8337489506493696}
2022-11-23 01:23:20,852 INFO:     Found new best model at epoch 8
2022-11-23 01:23:20,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:20,853 INFO:     Epoch: 9
2022-11-23 01:23:21,618 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8234023031863299, 'Total loss': 0.8234023031863299} | train loss {'Reaction outcome loss': 0.8207051305153109, 'Total loss': 0.8207051305153109}
2022-11-23 01:23:21,618 INFO:     Found new best model at epoch 9
2022-11-23 01:23:21,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:21,619 INFO:     Epoch: 10
2022-11-23 01:23:22,412 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8208568570288745, 'Total loss': 0.8208568570288745} | train loss {'Reaction outcome loss': 0.8201054222429329, 'Total loss': 0.8201054222429329}
2022-11-23 01:23:22,412 INFO:     Found new best model at epoch 10
2022-11-23 01:23:22,413 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:22,413 INFO:     Epoch: 11
2022-11-23 01:23:23,184 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8271558670835062, 'Total loss': 0.8271558670835062} | train loss {'Reaction outcome loss': 0.8180105039465283, 'Total loss': 0.8180105039465283}
2022-11-23 01:23:23,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:23,184 INFO:     Epoch: 12
2022-11-23 01:23:23,957 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.828068078241565, 'Total loss': 0.828068078241565} | train loss {'Reaction outcome loss': 0.8242510076959123, 'Total loss': 0.8242510076959123}
2022-11-23 01:23:23,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:23,957 INFO:     Epoch: 13
2022-11-23 01:23:24,756 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8395075378092852, 'Total loss': 0.8395075378092852} | train loss {'Reaction outcome loss': 0.8146343719862733, 'Total loss': 0.8146343719862733}
2022-11-23 01:23:24,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:24,756 INFO:     Epoch: 14
2022-11-23 01:23:25,566 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8188872689550574, 'Total loss': 0.8188872689550574} | train loss {'Reaction outcome loss': 0.8272235814617713, 'Total loss': 0.8272235814617713}
2022-11-23 01:23:25,566 INFO:     Found new best model at epoch 14
2022-11-23 01:23:25,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:25,567 INFO:     Epoch: 15
2022-11-23 01:23:26,371 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8116846558722582, 'Total loss': 0.8116846558722582} | train loss {'Reaction outcome loss': 0.8172992804513769, 'Total loss': 0.8172992804513769}
2022-11-23 01:23:26,371 INFO:     Found new best model at epoch 15
2022-11-23 01:23:26,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:26,372 INFO:     Epoch: 16
2022-11-23 01:23:27,142 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8350243819030848, 'Total loss': 0.8350243819030848} | train loss {'Reaction outcome loss': 0.8136442427934423, 'Total loss': 0.8136442427934423}
2022-11-23 01:23:27,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:27,142 INFO:     Epoch: 17
2022-11-23 01:23:27,954 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8487489088015123, 'Total loss': 0.8487489088015123} | train loss {'Reaction outcome loss': 0.8255605306702587, 'Total loss': 0.8255605306702587}
2022-11-23 01:23:27,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:27,955 INFO:     Epoch: 18
2022-11-23 01:23:28,809 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8359810825098645, 'Total loss': 0.8359810825098645} | train loss {'Reaction outcome loss': 0.8179440120091805, 'Total loss': 0.8179440120091805}
2022-11-23 01:23:28,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:28,809 INFO:     Epoch: 19
2022-11-23 01:23:29,656 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8165061297741804, 'Total loss': 0.8165061297741804} | train loss {'Reaction outcome loss': 0.8107797439523071, 'Total loss': 0.8107797439523071}
2022-11-23 01:23:29,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:29,656 INFO:     Epoch: 20
2022-11-23 01:23:30,527 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8471229882402853, 'Total loss': 0.8471229882402853} | train loss {'Reaction outcome loss': 0.8072676925735194, 'Total loss': 0.8072676925735194}
2022-11-23 01:23:30,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:30,528 INFO:     Epoch: 21
2022-11-23 01:23:31,282 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8239885751496662, 'Total loss': 0.8239885751496662} | train loss {'Reaction outcome loss': 0.8162483496945879, 'Total loss': 0.8162483496945879}
2022-11-23 01:23:31,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:31,282 INFO:     Epoch: 22
2022-11-23 01:23:32,140 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8077882778915492, 'Total loss': 0.8077882778915492} | train loss {'Reaction outcome loss': 0.8122179970326211, 'Total loss': 0.8122179970326211}
2022-11-23 01:23:32,140 INFO:     Found new best model at epoch 22
2022-11-23 01:23:32,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:32,141 INFO:     Epoch: 23
2022-11-23 01:23:32,969 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8303832472725348, 'Total loss': 0.8303832472725348} | train loss {'Reaction outcome loss': 0.8141748732642123, 'Total loss': 0.8141748732642123}
2022-11-23 01:23:32,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:32,969 INFO:     Epoch: 24
2022-11-23 01:23:33,814 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8429351110350002, 'Total loss': 0.8429351110350002} | train loss {'Reaction outcome loss': 0.8160700433649998, 'Total loss': 0.8160700433649998}
2022-11-23 01:23:33,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:33,815 INFO:     Epoch: 25
2022-11-23 01:23:34,630 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8218295465816151, 'Total loss': 0.8218295465816151} | train loss {'Reaction outcome loss': 0.8139095217110175, 'Total loss': 0.8139095217110175}
2022-11-23 01:23:34,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:34,631 INFO:     Epoch: 26
2022-11-23 01:23:35,431 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8627914115786552, 'Total loss': 0.8627914115786552} | train loss {'Reaction outcome loss': 0.8180959619249892, 'Total loss': 0.8180959619249892}
2022-11-23 01:23:35,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:35,431 INFO:     Epoch: 27
2022-11-23 01:23:36,229 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8304338306188583, 'Total loss': 0.8304338306188583} | train loss {'Reaction outcome loss': 0.8135462277210675, 'Total loss': 0.8135462277210675}
2022-11-23 01:23:36,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:36,230 INFO:     Epoch: 28
2022-11-23 01:23:37,028 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8444590378891338, 'Total loss': 0.8444590378891338} | train loss {'Reaction outcome loss': 0.8144755788177613, 'Total loss': 0.8144755788177613}
2022-11-23 01:23:37,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:37,028 INFO:     Epoch: 29
2022-11-23 01:23:37,873 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8291224695064805, 'Total loss': 0.8291224695064805} | train loss {'Reaction outcome loss': 0.8180427826367892, 'Total loss': 0.8180427826367892}
2022-11-23 01:23:37,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:37,873 INFO:     Epoch: 30
2022-11-23 01:23:38,694 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8385059894485907, 'Total loss': 0.8385059894485907} | train loss {'Reaction outcome loss': 0.8234797190075461, 'Total loss': 0.8234797190075461}
2022-11-23 01:23:38,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:38,695 INFO:     Epoch: 31
2022-11-23 01:23:39,515 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.83757533878088, 'Total loss': 0.83757533878088} | train loss {'Reaction outcome loss': 0.8145883268250628, 'Total loss': 0.8145883268250628}
2022-11-23 01:23:39,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:39,516 INFO:     Epoch: 32
2022-11-23 01:23:40,300 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8142105666073886, 'Total loss': 0.8142105666073886} | train loss {'Reaction outcome loss': 0.8109854699870352, 'Total loss': 0.8109854699870352}
2022-11-23 01:23:40,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:40,300 INFO:     Epoch: 33
2022-11-23 01:23:41,146 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8237571066076105, 'Total loss': 0.8237571066076105} | train loss {'Reaction outcome loss': 0.8111008976393865, 'Total loss': 0.8111008976393865}
2022-11-23 01:23:41,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:41,146 INFO:     Epoch: 34
2022-11-23 01:23:41,979 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8165678612210534, 'Total loss': 0.8165678612210534} | train loss {'Reaction outcome loss': 0.819131740553659, 'Total loss': 0.819131740553659}
2022-11-23 01:23:41,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:41,979 INFO:     Epoch: 35
2022-11-23 01:23:42,770 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8287498944184997, 'Total loss': 0.8287498944184997} | train loss {'Reaction outcome loss': 0.8173749600706796, 'Total loss': 0.8173749600706796}
2022-11-23 01:23:42,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:42,771 INFO:     Epoch: 36
2022-11-23 01:23:43,546 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8175305595452135, 'Total loss': 0.8175305595452135} | train loss {'Reaction outcome loss': 0.8084980258152552, 'Total loss': 0.8084980258152552}
2022-11-23 01:23:43,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:43,546 INFO:     Epoch: 37
2022-11-23 01:23:44,358 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8395262157375162, 'Total loss': 0.8395262157375162} | train loss {'Reaction outcome loss': 0.8161840026195233, 'Total loss': 0.8161840026195233}
2022-11-23 01:23:44,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:44,358 INFO:     Epoch: 38
2022-11-23 01:23:45,142 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8267774324525486, 'Total loss': 0.8267774324525486} | train loss {'Reaction outcome loss': 0.8119071662908623, 'Total loss': 0.8119071662908623}
2022-11-23 01:23:45,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:45,142 INFO:     Epoch: 39
2022-11-23 01:23:45,924 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8210178390145302, 'Total loss': 0.8210178390145302} | train loss {'Reaction outcome loss': 0.8189444400762257, 'Total loss': 0.8189444400762257}
2022-11-23 01:23:45,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:45,924 INFO:     Epoch: 40
2022-11-23 01:23:46,741 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8290100551464341, 'Total loss': 0.8290100551464341} | train loss {'Reaction outcome loss': 0.8172383162415462, 'Total loss': 0.8172383162415462}
2022-11-23 01:23:46,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:46,742 INFO:     Epoch: 41
2022-11-23 01:23:47,557 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8304429629986937, 'Total loss': 0.8304429629986937} | train loss {'Reaction outcome loss': 0.8172279227117778, 'Total loss': 0.8172279227117778}
2022-11-23 01:23:47,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:47,558 INFO:     Epoch: 42
2022-11-23 01:23:48,419 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8172815238887613, 'Total loss': 0.8172815238887613} | train loss {'Reaction outcome loss': 0.817166792236359, 'Total loss': 0.817166792236359}
2022-11-23 01:23:48,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:48,419 INFO:     Epoch: 43
2022-11-23 01:23:49,210 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8627889454364777, 'Total loss': 0.8627889454364777} | train loss {'Reaction outcome loss': 0.8212234429743609, 'Total loss': 0.8212234429743609}
2022-11-23 01:23:49,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:49,210 INFO:     Epoch: 44
2022-11-23 01:23:50,032 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8240307027643378, 'Total loss': 0.8240307027643378} | train loss {'Reaction outcome loss': 0.8220005943948924, 'Total loss': 0.8220005943948924}
2022-11-23 01:23:50,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:50,032 INFO:     Epoch: 45
2022-11-23 01:23:50,836 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.81798950989138, 'Total loss': 0.81798950989138} | train loss {'Reaction outcome loss': 0.8195747357872334, 'Total loss': 0.8195747357872334}
2022-11-23 01:23:50,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:50,836 INFO:     Epoch: 46
2022-11-23 01:23:51,679 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8236763565377756, 'Total loss': 0.8236763565377756} | train loss {'Reaction outcome loss': 0.8211242216318725, 'Total loss': 0.8211242216318725}
2022-11-23 01:23:51,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:51,679 INFO:     Epoch: 47
2022-11-23 01:23:52,492 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8169886402108453, 'Total loss': 0.8169886402108453} | train loss {'Reaction outcome loss': 0.814112175572739, 'Total loss': 0.814112175572739}
2022-11-23 01:23:52,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:52,493 INFO:     Epoch: 48
2022-11-23 01:23:53,301 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8161623349243944, 'Total loss': 0.8161623349243944} | train loss {'Reaction outcome loss': 0.812809322104763, 'Total loss': 0.812809322104763}
2022-11-23 01:23:53,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:53,301 INFO:     Epoch: 49
2022-11-23 01:23:54,117 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8332480788230896, 'Total loss': 0.8332480788230896} | train loss {'Reaction outcome loss': 0.811601640000517, 'Total loss': 0.811601640000517}
2022-11-23 01:23:54,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:54,117 INFO:     Epoch: 50
2022-11-23 01:23:54,882 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8295892761512236, 'Total loss': 0.8295892761512236} | train loss {'Reaction outcome loss': 0.8146785310646782, 'Total loss': 0.8146785310646782}
2022-11-23 01:23:54,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:54,882 INFO:     Epoch: 51
2022-11-23 01:23:55,690 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8303549574180082, 'Total loss': 0.8303549574180082} | train loss {'Reaction outcome loss': 0.8147207202940334, 'Total loss': 0.8147207202940334}
2022-11-23 01:23:55,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:55,690 INFO:     Epoch: 52
2022-11-23 01:23:56,466 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8208129866556688, 'Total loss': 0.8208129866556688} | train loss {'Reaction outcome loss': 0.820783868130402, 'Total loss': 0.820783868130402}
2022-11-23 01:23:56,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:56,466 INFO:     Epoch: 53
2022-11-23 01:23:57,285 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8177892999215559, 'Total loss': 0.8177892999215559} | train loss {'Reaction outcome loss': 0.8115319335146954, 'Total loss': 0.8115319335146954}
2022-11-23 01:23:57,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:57,285 INFO:     Epoch: 54
2022-11-23 01:23:58,083 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8211356015367941, 'Total loss': 0.8211356015367941} | train loss {'Reaction outcome loss': 0.8133047361846878, 'Total loss': 0.8133047361846878}
2022-11-23 01:23:58,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:58,083 INFO:     Epoch: 55
2022-11-23 01:23:58,887 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8260585462505167, 'Total loss': 0.8260585462505167} | train loss {'Reaction outcome loss': 0.8125014924689343, 'Total loss': 0.8125014924689343}
2022-11-23 01:23:58,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:58,887 INFO:     Epoch: 56
2022-11-23 01:23:59,707 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8341077010739933, 'Total loss': 0.8341077010739933} | train loss {'Reaction outcome loss': 0.8149046452663206, 'Total loss': 0.8149046452663206}
2022-11-23 01:23:59,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:23:59,708 INFO:     Epoch: 57
2022-11-23 01:24:00,563 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8453250432556326, 'Total loss': 0.8453250432556326} | train loss {'Reaction outcome loss': 0.8106655483907051, 'Total loss': 0.8106655483907051}
2022-11-23 01:24:00,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:00,563 INFO:     Epoch: 58
2022-11-23 01:24:01,433 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8222176202318885, 'Total loss': 0.8222176202318885} | train loss {'Reaction outcome loss': 0.8152291260750187, 'Total loss': 0.8152291260750187}
2022-11-23 01:24:01,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:01,433 INFO:     Epoch: 59
2022-11-23 01:24:02,281 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8290450220758264, 'Total loss': 0.8290450220758264} | train loss {'Reaction outcome loss': 0.8122560499530089, 'Total loss': 0.8122560499530089}
2022-11-23 01:24:02,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:02,281 INFO:     Epoch: 60
2022-11-23 01:24:03,101 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.810989373786883, 'Total loss': 0.810989373786883} | train loss {'Reaction outcome loss': 0.8126119241902703, 'Total loss': 0.8126119241902703}
2022-11-23 01:24:03,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:03,101 INFO:     Epoch: 61
2022-11-23 01:24:03,911 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8540639917958867, 'Total loss': 0.8540639917958867} | train loss {'Reaction outcome loss': 0.8093982646581133, 'Total loss': 0.8093982646581133}
2022-11-23 01:24:03,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:03,911 INFO:     Epoch: 62
2022-11-23 01:24:04,695 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8093649203127081, 'Total loss': 0.8093649203127081} | train loss {'Reaction outcome loss': 0.8175005040429382, 'Total loss': 0.8175005040429382}
2022-11-23 01:24:04,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:04,695 INFO:     Epoch: 63
2022-11-23 01:24:05,518 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.9165702394463799, 'Total loss': 0.9165702394463799} | train loss {'Reaction outcome loss': 0.8224403047368594, 'Total loss': 0.8224403047368594}
2022-11-23 01:24:05,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:05,519 INFO:     Epoch: 64
2022-11-23 01:24:06,323 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8221115226095373, 'Total loss': 0.8221115226095373} | train loss {'Reaction outcome loss': 0.8155932501260086, 'Total loss': 0.8155932501260086}
2022-11-23 01:24:06,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:06,324 INFO:     Epoch: 65
2022-11-23 01:24:07,168 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8437511595812711, 'Total loss': 0.8437511595812711} | train loss {'Reaction outcome loss': 0.811286896587866, 'Total loss': 0.811286896587866}
2022-11-23 01:24:07,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:07,169 INFO:     Epoch: 66
2022-11-23 01:24:07,981 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8138545751571655, 'Total loss': 0.8138545751571655} | train loss {'Reaction outcome loss': 0.8063260791936384, 'Total loss': 0.8063260791936384}
2022-11-23 01:24:07,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:07,981 INFO:     Epoch: 67
2022-11-23 01:24:08,790 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8301011947068301, 'Total loss': 0.8301011947068301} | train loss {'Reaction outcome loss': 0.8283607075330217, 'Total loss': 0.8283607075330217}
2022-11-23 01:24:08,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:08,790 INFO:     Epoch: 68
2022-11-23 01:24:09,623 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.869345253164118, 'Total loss': 0.869345253164118} | train loss {'Reaction outcome loss': 0.8142007039143488, 'Total loss': 0.8142007039143488}
2022-11-23 01:24:09,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:09,623 INFO:     Epoch: 69
2022-11-23 01:24:10,454 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8251920220526782, 'Total loss': 0.8251920220526782} | train loss {'Reaction outcome loss': 0.8148041748807497, 'Total loss': 0.8148041748807497}
2022-11-23 01:24:10,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:10,455 INFO:     Epoch: 70
2022-11-23 01:24:11,273 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8287134143439207, 'Total loss': 0.8287134143439207} | train loss {'Reaction outcome loss': 0.8075557186113678, 'Total loss': 0.8075557186113678}
2022-11-23 01:24:11,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:11,273 INFO:     Epoch: 71
2022-11-23 01:24:12,066 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8309209123253822, 'Total loss': 0.8309209123253822} | train loss {'Reaction outcome loss': 0.8151562293531441, 'Total loss': 0.8151562293531441}
2022-11-23 01:24:12,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:12,066 INFO:     Epoch: 72
2022-11-23 01:24:12,861 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.817703824151646, 'Total loss': 0.817703824151646} | train loss {'Reaction outcome loss': 0.8153441611240025, 'Total loss': 0.8153441611240025}
2022-11-23 01:24:12,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:12,861 INFO:     Epoch: 73
2022-11-23 01:24:13,665 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8282633586363359, 'Total loss': 0.8282633586363359} | train loss {'Reaction outcome loss': 0.8136961480625245, 'Total loss': 0.8136961480625245}
2022-11-23 01:24:13,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:13,665 INFO:     Epoch: 74
2022-11-23 01:24:14,493 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8129698796705767, 'Total loss': 0.8129698796705767} | train loss {'Reaction outcome loss': 0.8162442862022261, 'Total loss': 0.8162442862022261}
2022-11-23 01:24:14,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:14,493 INFO:     Epoch: 75
2022-11-23 01:24:15,283 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8236450952562419, 'Total loss': 0.8236450952562419} | train loss {'Reaction outcome loss': 0.8190526433801844, 'Total loss': 0.8190526433801844}
2022-11-23 01:24:15,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:15,283 INFO:     Epoch: 76
2022-11-23 01:24:16,128 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8232495269992135, 'Total loss': 0.8232495269992135} | train loss {'Reaction outcome loss': 0.8114773428995117, 'Total loss': 0.8114773428995117}
2022-11-23 01:24:16,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:16,128 INFO:     Epoch: 77
2022-11-23 01:24:16,926 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8651221008463339, 'Total loss': 0.8651221008463339} | train loss {'Reaction outcome loss': 0.8159551268164446, 'Total loss': 0.8159551268164446}
2022-11-23 01:24:16,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:16,927 INFO:     Epoch: 78
2022-11-23 01:24:17,735 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.834625162861564, 'Total loss': 0.834625162861564} | train loss {'Reaction outcome loss': 0.8165109180487119, 'Total loss': 0.8165109180487119}
2022-11-23 01:24:17,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:17,735 INFO:     Epoch: 79
2022-11-23 01:24:18,559 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.829646270383488, 'Total loss': 0.829646270383488} | train loss {'Reaction outcome loss': 0.8080655715243537, 'Total loss': 0.8080655715243537}
2022-11-23 01:24:18,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:18,561 INFO:     Epoch: 80
2022-11-23 01:24:19,377 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8163718269629912, 'Total loss': 0.8163718269629912} | train loss {'Reaction outcome loss': 0.8193742426542135, 'Total loss': 0.8193742426542135}
2022-11-23 01:24:19,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:19,378 INFO:     Epoch: 81
2022-11-23 01:24:20,194 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.819712257520719, 'Total loss': 0.819712257520719} | train loss {'Reaction outcome loss': 0.8141019107841769, 'Total loss': 0.8141019107841769}
2022-11-23 01:24:20,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:20,195 INFO:     Epoch: 82
2022-11-23 01:24:20,998 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8133904364976016, 'Total loss': 0.8133904364976016} | train loss {'Reaction outcome loss': 0.8137622597487831, 'Total loss': 0.8137622597487831}
2022-11-23 01:24:20,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:20,998 INFO:     Epoch: 83
2022-11-23 01:24:21,775 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8177214197137139, 'Total loss': 0.8177214197137139} | train loss {'Reaction outcome loss': 0.809585302344218, 'Total loss': 0.809585302344218}
2022-11-23 01:24:21,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:21,775 INFO:     Epoch: 84
2022-11-23 01:24:22,567 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8165845559401945, 'Total loss': 0.8165845559401945} | train loss {'Reaction outcome loss': 0.8154746888861483, 'Total loss': 0.8154746888861483}
2022-11-23 01:24:22,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:22,567 INFO:     Epoch: 85
2022-11-23 01:24:23,362 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8242413767359473, 'Total loss': 0.8242413767359473} | train loss {'Reaction outcome loss': 0.8118191196126976, 'Total loss': 0.8118191196126976}
2022-11-23 01:24:23,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:23,363 INFO:     Epoch: 86
2022-11-23 01:24:24,172 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8633797371929343, 'Total loss': 0.8633797371929343} | train loss {'Reaction outcome loss': 0.813249695638896, 'Total loss': 0.813249695638896}
2022-11-23 01:24:24,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:24,173 INFO:     Epoch: 87
2022-11-23 01:24:24,986 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8272638646039095, 'Total loss': 0.8272638646039095} | train loss {'Reaction outcome loss': 0.8151789094031099, 'Total loss': 0.8151789094031099}
2022-11-23 01:24:24,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:24,986 INFO:     Epoch: 88
2022-11-23 01:24:25,799 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8248422227122567, 'Total loss': 0.8248422227122567} | train loss {'Reaction outcome loss': 0.8103566283910622, 'Total loss': 0.8103566283910622}
2022-11-23 01:24:25,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:25,799 INFO:     Epoch: 89
2022-11-23 01:24:26,625 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8355624445460059, 'Total loss': 0.8355624445460059} | train loss {'Reaction outcome loss': 0.817155086318491, 'Total loss': 0.817155086318491}
2022-11-23 01:24:26,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:26,625 INFO:     Epoch: 90
2022-11-23 01:24:27,430 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.821221033280546, 'Total loss': 0.821221033280546} | train loss {'Reaction outcome loss': 0.8142347349087719, 'Total loss': 0.8142347349087719}
2022-11-23 01:24:27,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:27,431 INFO:     Epoch: 91
2022-11-23 01:24:28,236 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8221997964111242, 'Total loss': 0.8221997964111242} | train loss {'Reaction outcome loss': 0.8173533477763898, 'Total loss': 0.8173533477763898}
2022-11-23 01:24:28,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:28,236 INFO:     Epoch: 92
2022-11-23 01:24:29,041 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8440053056586873, 'Total loss': 0.8440053056586873} | train loss {'Reaction outcome loss': 0.8197379090525361, 'Total loss': 0.8197379090525361}
2022-11-23 01:24:29,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:29,041 INFO:     Epoch: 93
2022-11-23 01:24:29,842 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8402058339931748, 'Total loss': 0.8402058339931748} | train loss {'Reaction outcome loss': 0.8164328024213613, 'Total loss': 0.8164328024213613}
2022-11-23 01:24:29,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:29,842 INFO:     Epoch: 94
2022-11-23 01:24:30,663 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8238541348413988, 'Total loss': 0.8238541348413988} | train loss {'Reaction outcome loss': 0.8103145444350928, 'Total loss': 0.8103145444350928}
2022-11-23 01:24:30,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:30,664 INFO:     Epoch: 95
2022-11-23 01:24:31,441 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8310919783332131, 'Total loss': 0.8310919783332131} | train loss {'Reaction outcome loss': 0.8154478875490335, 'Total loss': 0.8154478875490335}
2022-11-23 01:24:31,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:31,442 INFO:     Epoch: 96
2022-11-23 01:24:32,237 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8118045580658045, 'Total loss': 0.8118045580658045} | train loss {'Reaction outcome loss': 0.8157096774230602, 'Total loss': 0.8157096774230602}
2022-11-23 01:24:32,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:32,237 INFO:     Epoch: 97
2022-11-23 01:24:33,051 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.819114173000509, 'Total loss': 0.819114173000509} | train loss {'Reaction outcome loss': 0.8196934952668333, 'Total loss': 0.8196934952668333}
2022-11-23 01:24:33,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:33,051 INFO:     Epoch: 98
2022-11-23 01:24:33,871 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8227670152078975, 'Total loss': 0.8227670152078975} | train loss {'Reaction outcome loss': 0.8101435641528141, 'Total loss': 0.8101435641528141}
2022-11-23 01:24:33,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:33,871 INFO:     Epoch: 99
2022-11-23 01:24:34,688 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8146265677430413, 'Total loss': 0.8146265677430413} | train loss {'Reaction outcome loss': 0.8099161468536747, 'Total loss': 0.8099161468536747}
2022-11-23 01:24:34,688 INFO:     Best model found after epoch 23 of 100.
2022-11-23 01:24:34,689 INFO:   Done with stage: TRAINING
2022-11-23 01:24:34,689 INFO:   Starting stage: EVALUATION
2022-11-23 01:24:34,814 INFO:   Done with stage: EVALUATION
2022-11-23 01:24:34,814 INFO:   Leaving out SEQ value Fold_7
2022-11-23 01:24:34,828 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 01:24:34,828 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:24:35,509 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:24:35,509 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:24:35,580 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:24:35,581 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:24:35,581 INFO:     No hyperparam tuning for this model
2022-11-23 01:24:35,581 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:24:35,581 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:24:35,582 INFO:     None feature selector for col prot
2022-11-23 01:24:35,582 INFO:     None feature selector for col prot
2022-11-23 01:24:35,582 INFO:     None feature selector for col prot
2022-11-23 01:24:35,582 INFO:     None feature selector for col chem
2022-11-23 01:24:35,582 INFO:     None feature selector for col chem
2022-11-23 01:24:35,583 INFO:     None feature selector for col chem
2022-11-23 01:24:35,583 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:24:35,583 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:24:35,584 INFO:     Number of params in model 168571
2022-11-23 01:24:35,587 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:24:35,587 INFO:   Starting stage: TRAINING
2022-11-23 01:24:35,647 INFO:     Val loss before train {'Reaction outcome loss': 1.0066118998961016, 'Total loss': 1.0066118998961016}
2022-11-23 01:24:35,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:35,647 INFO:     Epoch: 0
2022-11-23 01:24:36,452 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8446135879917578, 'Total loss': 0.8446135879917578} | train loss {'Reaction outcome loss': 0.8772753590056973, 'Total loss': 0.8772753590056973}
2022-11-23 01:24:36,452 INFO:     Found new best model at epoch 0
2022-11-23 01:24:36,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:36,453 INFO:     Epoch: 1
2022-11-23 01:24:37,290 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.850844838402488, 'Total loss': 0.850844838402488} | train loss {'Reaction outcome loss': 0.8346970531969301, 'Total loss': 0.8346970531969301}
2022-11-23 01:24:37,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:37,291 INFO:     Epoch: 2
2022-11-23 01:24:38,111 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8472658571871844, 'Total loss': 0.8472658571871844} | train loss {'Reaction outcome loss': 0.8314510675207261, 'Total loss': 0.8314510675207261}
2022-11-23 01:24:38,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:38,111 INFO:     Epoch: 3
2022-11-23 01:24:38,967 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8454552590847015, 'Total loss': 0.8454552590847015} | train loss {'Reaction outcome loss': 0.8245630288316358, 'Total loss': 0.8245630288316358}
2022-11-23 01:24:38,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:38,967 INFO:     Epoch: 4
2022-11-23 01:24:39,790 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8345920849930156, 'Total loss': 0.8345920849930156} | train loss {'Reaction outcome loss': 0.8262375399710671, 'Total loss': 0.8262375399710671}
2022-11-23 01:24:39,790 INFO:     Found new best model at epoch 4
2022-11-23 01:24:39,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:39,791 INFO:     Epoch: 5
2022-11-23 01:24:40,616 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8395075242627751, 'Total loss': 0.8395075242627751} | train loss {'Reaction outcome loss': 0.8163643777370453, 'Total loss': 0.8163643777370453}
2022-11-23 01:24:40,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:40,617 INFO:     Epoch: 6
2022-11-23 01:24:41,408 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8361011472615328, 'Total loss': 0.8361011472615328} | train loss {'Reaction outcome loss': 0.8146443073787997, 'Total loss': 0.8146443073787997}
2022-11-23 01:24:41,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:41,408 INFO:     Epoch: 7
2022-11-23 01:24:42,191 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.837495897303928, 'Total loss': 0.837495897303928} | train loss {'Reaction outcome loss': 0.8186868054251517, 'Total loss': 0.8186868054251517}
2022-11-23 01:24:42,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:42,192 INFO:     Epoch: 8
2022-11-23 01:24:42,966 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8275446160273119, 'Total loss': 0.8275446160273119} | train loss {'Reaction outcome loss': 0.8123895841981134, 'Total loss': 0.8123895841981134}
2022-11-23 01:24:42,966 INFO:     Found new best model at epoch 8
2022-11-23 01:24:42,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:42,967 INFO:     Epoch: 9
2022-11-23 01:24:43,759 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8454086997292258, 'Total loss': 0.8454086997292258} | train loss {'Reaction outcome loss': 0.8137949767612642, 'Total loss': 0.8137949767612642}
2022-11-23 01:24:43,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:43,759 INFO:     Epoch: 10
2022-11-23 01:24:44,573 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8268272375518625, 'Total loss': 0.8268272375518625} | train loss {'Reaction outcome loss': 0.8109597662283529, 'Total loss': 0.8109597662283529}
2022-11-23 01:24:44,574 INFO:     Found new best model at epoch 10
2022-11-23 01:24:44,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:44,574 INFO:     Epoch: 11
2022-11-23 01:24:45,371 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8721065548333254, 'Total loss': 0.8721065548333254} | train loss {'Reaction outcome loss': 0.8074945187376391, 'Total loss': 0.8074945187376391}
2022-11-23 01:24:45,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:45,371 INFO:     Epoch: 12
2022-11-23 01:24:46,197 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8344848325306718, 'Total loss': 0.8344848325306718} | train loss {'Reaction outcome loss': 0.8077055929649261, 'Total loss': 0.8077055929649261}
2022-11-23 01:24:46,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:46,197 INFO:     Epoch: 13
2022-11-23 01:24:47,028 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8338084559548985, 'Total loss': 0.8338084559548985} | train loss {'Reaction outcome loss': 0.8085705186090162, 'Total loss': 0.8085705186090162}
2022-11-23 01:24:47,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:47,028 INFO:     Epoch: 14
2022-11-23 01:24:47,812 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8325035287575289, 'Total loss': 0.8325035287575289} | train loss {'Reaction outcome loss': 0.8091459145709392, 'Total loss': 0.8091459145709392}
2022-11-23 01:24:47,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:47,812 INFO:     Epoch: 15
2022-11-23 01:24:48,631 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8400993990627202, 'Total loss': 0.8400993990627202} | train loss {'Reaction outcome loss': 0.808972958415266, 'Total loss': 0.808972958415266}
2022-11-23 01:24:48,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:48,631 INFO:     Epoch: 16
2022-11-23 01:24:49,446 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8340443799441511, 'Total loss': 0.8340443799441511} | train loss {'Reaction outcome loss': 0.8071837309868105, 'Total loss': 0.8071837309868105}
2022-11-23 01:24:49,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:49,447 INFO:     Epoch: 17
2022-11-23 01:24:50,305 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.830725986849178, 'Total loss': 0.830725986849178} | train loss {'Reaction outcome loss': 0.8085757441097691, 'Total loss': 0.8085757441097691}
2022-11-23 01:24:50,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:50,305 INFO:     Epoch: 18
2022-11-23 01:24:51,121 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8315350677479397, 'Total loss': 0.8315350677479397} | train loss {'Reaction outcome loss': 0.8041558366629386, 'Total loss': 0.8041558366629386}
2022-11-23 01:24:51,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:51,121 INFO:     Epoch: 19
2022-11-23 01:24:51,912 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8333257545124401, 'Total loss': 0.8333257545124401} | train loss {'Reaction outcome loss': 0.8152577588635106, 'Total loss': 0.8152577588635106}
2022-11-23 01:24:51,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:51,913 INFO:     Epoch: 20
2022-11-23 01:24:52,718 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8555154719135978, 'Total loss': 0.8555154719135978} | train loss {'Reaction outcome loss': 0.8096862673278777, 'Total loss': 0.8096862673278777}
2022-11-23 01:24:52,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:52,719 INFO:     Epoch: 21
2022-11-23 01:24:53,513 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8319956077770754, 'Total loss': 0.8319956077770754} | train loss {'Reaction outcome loss': 0.8085016985574076, 'Total loss': 0.8085016985574076}
2022-11-23 01:24:53,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:53,513 INFO:     Epoch: 22
2022-11-23 01:24:54,320 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8698719292879105, 'Total loss': 0.8698719292879105} | train loss {'Reaction outcome loss': 0.8120686917776062, 'Total loss': 0.8120686917776062}
2022-11-23 01:24:54,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:54,321 INFO:     Epoch: 23
2022-11-23 01:24:55,113 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8288553072647615, 'Total loss': 0.8288553072647615} | train loss {'Reaction outcome loss': 0.8083620401880434, 'Total loss': 0.8083620401880434}
2022-11-23 01:24:55,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:55,113 INFO:     Epoch: 24
2022-11-23 01:24:55,896 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8451086655259132, 'Total loss': 0.8451086655259132} | train loss {'Reaction outcome loss': 0.8121477613045324, 'Total loss': 0.8121477613045324}
2022-11-23 01:24:55,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:55,897 INFO:     Epoch: 25
2022-11-23 01:24:56,703 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8577190976251255, 'Total loss': 0.8577190976251255} | train loss {'Reaction outcome loss': 0.8074237472347675, 'Total loss': 0.8074237472347675}
2022-11-23 01:24:56,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:56,703 INFO:     Epoch: 26
2022-11-23 01:24:57,502 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8454453599723902, 'Total loss': 0.8454453599723902} | train loss {'Reaction outcome loss': 0.8098007650865663, 'Total loss': 0.8098007650865663}
2022-11-23 01:24:57,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:57,503 INFO:     Epoch: 27
2022-11-23 01:24:58,371 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8378002535213124, 'Total loss': 0.8378002535213124} | train loss {'Reaction outcome loss': 0.8091354860413459, 'Total loss': 0.8091354860413459}
2022-11-23 01:24:58,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:58,371 INFO:     Epoch: 28
2022-11-23 01:24:59,223 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8403457694432952, 'Total loss': 0.8403457694432952} | train loss {'Reaction outcome loss': 0.8074960224330425, 'Total loss': 0.8074960224330425}
2022-11-23 01:24:59,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:24:59,223 INFO:     Epoch: 29
2022-11-23 01:25:00,045 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.831071412698789, 'Total loss': 0.831071412698789} | train loss {'Reaction outcome loss': 0.80915592238307, 'Total loss': 0.80915592238307}
2022-11-23 01:25:00,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:00,045 INFO:     Epoch: 30
2022-11-23 01:25:00,847 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8338017626242205, 'Total loss': 0.8338017626242205} | train loss {'Reaction outcome loss': 0.8091289367406599, 'Total loss': 0.8091289367406599}
2022-11-23 01:25:00,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:00,847 INFO:     Epoch: 31
2022-11-23 01:25:01,654 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8292281221259724, 'Total loss': 0.8292281221259724} | train loss {'Reaction outcome loss': 0.8092887789732025, 'Total loss': 0.8092887789732025}
2022-11-23 01:25:01,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:01,656 INFO:     Epoch: 32
2022-11-23 01:25:02,473 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.834727861664512, 'Total loss': 0.834727861664512} | train loss {'Reaction outcome loss': 0.8128234371542931, 'Total loss': 0.8128234371542931}
2022-11-23 01:25:02,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:02,474 INFO:     Epoch: 33
2022-11-23 01:25:03,313 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8261818967082284, 'Total loss': 0.8261818967082284} | train loss {'Reaction outcome loss': 0.8086324865298886, 'Total loss': 0.8086324865298886}
2022-11-23 01:25:03,313 INFO:     Found new best model at epoch 33
2022-11-23 01:25:03,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:03,314 INFO:     Epoch: 34
2022-11-23 01:25:04,174 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8254091238433664, 'Total loss': 0.8254091238433664} | train loss {'Reaction outcome loss': 0.8094147060426974, 'Total loss': 0.8094147060426974}
2022-11-23 01:25:04,174 INFO:     Found new best model at epoch 34
2022-11-23 01:25:04,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:04,175 INFO:     Epoch: 35
2022-11-23 01:25:05,016 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8244255726987665, 'Total loss': 0.8244255726987665} | train loss {'Reaction outcome loss': 0.8071431035716687, 'Total loss': 0.8071431035716687}
2022-11-23 01:25:05,017 INFO:     Found new best model at epoch 35
2022-11-23 01:25:05,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:05,017 INFO:     Epoch: 36
2022-11-23 01:25:05,798 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8446927937594327, 'Total loss': 0.8446927937594327} | train loss {'Reaction outcome loss': 0.8109649315236076, 'Total loss': 0.8109649315236076}
2022-11-23 01:25:05,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:05,798 INFO:     Epoch: 37
2022-11-23 01:25:06,594 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.838743615556847, 'Total loss': 0.838743615556847} | train loss {'Reaction outcome loss': 0.807147016929042, 'Total loss': 0.807147016929042}
2022-11-23 01:25:06,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:06,595 INFO:     Epoch: 38
2022-11-23 01:25:07,422 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8408099182627418, 'Total loss': 0.8408099182627418} | train loss {'Reaction outcome loss': 0.8094802631005165, 'Total loss': 0.8094802631005165}
2022-11-23 01:25:07,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:07,422 INFO:     Epoch: 39
2022-11-23 01:25:08,224 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.819348235021938, 'Total loss': 0.819348235021938} | train loss {'Reaction outcome loss': 0.8076726700509748, 'Total loss': 0.8076726700509748}
2022-11-23 01:25:08,225 INFO:     Found new best model at epoch 39
2022-11-23 01:25:08,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:08,226 INFO:     Epoch: 40
2022-11-23 01:25:09,023 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8331477838483724, 'Total loss': 0.8331477838483724} | train loss {'Reaction outcome loss': 0.8077789274675231, 'Total loss': 0.8077789274675231}
2022-11-23 01:25:09,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:09,023 INFO:     Epoch: 41
2022-11-23 01:25:09,815 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8307675929232077, 'Total loss': 0.8307675929232077} | train loss {'Reaction outcome loss': 0.8091124776870974, 'Total loss': 0.8091124776870974}
2022-11-23 01:25:09,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:09,816 INFO:     Epoch: 42
2022-11-23 01:25:10,593 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.835754016583616, 'Total loss': 0.835754016583616} | train loss {'Reaction outcome loss': 0.8081145142355273, 'Total loss': 0.8081145142355273}
2022-11-23 01:25:10,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:10,593 INFO:     Epoch: 43
2022-11-23 01:25:11,432 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8280817432837053, 'Total loss': 0.8280817432837053} | train loss {'Reaction outcome loss': 0.8105548033791203, 'Total loss': 0.8105548033791203}
2022-11-23 01:25:11,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:11,432 INFO:     Epoch: 44
2022-11-23 01:25:12,217 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8269354145635258, 'Total loss': 0.8269354145635258} | train loss {'Reaction outcome loss': 0.8075629217970756, 'Total loss': 0.8075629217970756}
2022-11-23 01:25:12,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:12,217 INFO:     Epoch: 45
2022-11-23 01:25:13,018 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8341230641711842, 'Total loss': 0.8341230641711842} | train loss {'Reaction outcome loss': 0.8096493754175401, 'Total loss': 0.8096493754175401}
2022-11-23 01:25:13,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:13,018 INFO:     Epoch: 46
2022-11-23 01:25:13,855 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8318070464513518, 'Total loss': 0.8318070464513518} | train loss {'Reaction outcome loss': 0.8105829515524449, 'Total loss': 0.8105829515524449}
2022-11-23 01:25:13,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:13,855 INFO:     Epoch: 47
2022-11-23 01:25:14,702 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8488408760590986, 'Total loss': 0.8488408760590986} | train loss {'Reaction outcome loss': 0.8062594523352962, 'Total loss': 0.8062594523352962}
2022-11-23 01:25:14,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:14,702 INFO:     Epoch: 48
2022-11-23 01:25:15,547 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8440561931241642, 'Total loss': 0.8440561931241642} | train loss {'Reaction outcome loss': 0.80638431018639, 'Total loss': 0.80638431018639}
2022-11-23 01:25:15,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:15,547 INFO:     Epoch: 49
2022-11-23 01:25:16,371 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8675757307897914, 'Total loss': 0.8675757307897914} | train loss {'Reaction outcome loss': 0.8089529724130707, 'Total loss': 0.8089529724130707}
2022-11-23 01:25:16,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:16,371 INFO:     Epoch: 50
2022-11-23 01:25:17,164 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8294622613625093, 'Total loss': 0.8294622613625093} | train loss {'Reaction outcome loss': 0.8143818857929399, 'Total loss': 0.8143818857929399}
2022-11-23 01:25:17,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:17,164 INFO:     Epoch: 51
2022-11-23 01:25:17,979 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8447481339628046, 'Total loss': 0.8447481339628046} | train loss {'Reaction outcome loss': 0.8137450748153271, 'Total loss': 0.8137450748153271}
2022-11-23 01:25:17,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:17,979 INFO:     Epoch: 52
2022-11-23 01:25:18,799 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8451608182354406, 'Total loss': 0.8451608182354406} | train loss {'Reaction outcome loss': 0.8096394276907367, 'Total loss': 0.8096394276907367}
2022-11-23 01:25:18,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:18,799 INFO:     Epoch: 53
2022-11-23 01:25:19,605 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.828778740357269, 'Total loss': 0.828778740357269} | train loss {'Reaction outcome loss': 0.8040990331961263, 'Total loss': 0.8040990331961263}
2022-11-23 01:25:19,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:19,605 INFO:     Epoch: 54
2022-11-23 01:25:20,383 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8409326266158711, 'Total loss': 0.8409326266158711} | train loss {'Reaction outcome loss': 0.8065315341997531, 'Total loss': 0.8065315341997531}
2022-11-23 01:25:20,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:20,384 INFO:     Epoch: 55
2022-11-23 01:25:21,181 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8237247074192221, 'Total loss': 0.8237247074192221} | train loss {'Reaction outcome loss': 0.8102839375215192, 'Total loss': 0.8102839375215192}
2022-11-23 01:25:21,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:21,181 INFO:     Epoch: 56
2022-11-23 01:25:21,954 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8391273638064211, 'Total loss': 0.8391273638064211} | train loss {'Reaction outcome loss': 0.8096670794390863, 'Total loss': 0.8096670794390863}
2022-11-23 01:25:21,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:21,954 INFO:     Epoch: 57
2022-11-23 01:25:22,765 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8190544918179512, 'Total loss': 0.8190544918179512} | train loss {'Reaction outcome loss': 0.8054833489079629, 'Total loss': 0.8054833489079629}
2022-11-23 01:25:22,765 INFO:     Found new best model at epoch 57
2022-11-23 01:25:22,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:22,766 INFO:     Epoch: 58
2022-11-23 01:25:23,552 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.835018044168299, 'Total loss': 0.835018044168299} | train loss {'Reaction outcome loss': 0.8075329477508222, 'Total loss': 0.8075329477508222}
2022-11-23 01:25:23,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:23,553 INFO:     Epoch: 59
2022-11-23 01:25:24,332 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8275576552206819, 'Total loss': 0.8275576552206819} | train loss {'Reaction outcome loss': 0.8110526422819784, 'Total loss': 0.8110526422819784}
2022-11-23 01:25:24,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:24,333 INFO:     Epoch: 60
2022-11-23 01:25:25,111 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8344511877406727, 'Total loss': 0.8344511877406727} | train loss {'Reaction outcome loss': 0.8051298908408611, 'Total loss': 0.8051298908408611}
2022-11-23 01:25:25,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:25,112 INFO:     Epoch: 61
2022-11-23 01:25:25,889 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8351541080258109, 'Total loss': 0.8351541080258109} | train loss {'Reaction outcome loss': 0.8045212124143878, 'Total loss': 0.8045212124143878}
2022-11-23 01:25:25,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:25,889 INFO:     Epoch: 62
2022-11-23 01:25:26,686 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8396104547110471, 'Total loss': 0.8396104547110471} | train loss {'Reaction outcome loss': 0.8086365601949154, 'Total loss': 0.8086365601949154}
2022-11-23 01:25:26,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:26,686 INFO:     Epoch: 63
2022-11-23 01:25:27,509 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8187602677128532, 'Total loss': 0.8187602677128532} | train loss {'Reaction outcome loss': 0.8088251173255905, 'Total loss': 0.8088251173255905}
2022-11-23 01:25:27,509 INFO:     Found new best model at epoch 63
2022-11-23 01:25:27,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:27,510 INFO:     Epoch: 64
2022-11-23 01:25:28,330 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.856746996668252, 'Total loss': 0.856746996668252} | train loss {'Reaction outcome loss': 0.8077298121586922, 'Total loss': 0.8077298121586922}
2022-11-23 01:25:28,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:28,331 INFO:     Epoch: 65
2022-11-23 01:25:29,108 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8366630944338712, 'Total loss': 0.8366630944338712} | train loss {'Reaction outcome loss': 0.8066003884999983, 'Total loss': 0.8066003884999983}
2022-11-23 01:25:29,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:29,108 INFO:     Epoch: 66
2022-11-23 01:25:29,908 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8258395581082865, 'Total loss': 0.8258395581082865} | train loss {'Reaction outcome loss': 0.8019253592337331, 'Total loss': 0.8019253592337331}
2022-11-23 01:25:29,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:29,908 INFO:     Epoch: 67
2022-11-23 01:25:30,726 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8402864384380254, 'Total loss': 0.8402864384380254} | train loss {'Reaction outcome loss': 0.8074347256652771, 'Total loss': 0.8074347256652771}
2022-11-23 01:25:30,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:30,726 INFO:     Epoch: 68
2022-11-23 01:25:31,558 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8584896515716206, 'Total loss': 0.8584896515716206} | train loss {'Reaction outcome loss': 0.8047037170298638, 'Total loss': 0.8047037170298638}
2022-11-23 01:25:31,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:31,558 INFO:     Epoch: 69
2022-11-23 01:25:32,353 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8293895531784404, 'Total loss': 0.8293895531784404} | train loss {'Reaction outcome loss': 0.8033851697560279, 'Total loss': 0.8033851697560279}
2022-11-23 01:25:32,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:32,354 INFO:     Epoch: 70
2022-11-23 01:25:33,169 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8395084271376784, 'Total loss': 0.8395084271376784} | train loss {'Reaction outcome loss': 0.8073224515443848, 'Total loss': 0.8073224515443848}
2022-11-23 01:25:33,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:33,169 INFO:     Epoch: 71
2022-11-23 01:25:34,018 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8421312421560287, 'Total loss': 0.8421312421560287} | train loss {'Reaction outcome loss': 0.8040309875242172, 'Total loss': 0.8040309875242172}
2022-11-23 01:25:34,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:34,019 INFO:     Epoch: 72
2022-11-23 01:25:34,844 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8297537416219711, 'Total loss': 0.8297537416219711} | train loss {'Reaction outcome loss': 0.806145686175554, 'Total loss': 0.806145686175554}
2022-11-23 01:25:34,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:34,844 INFO:     Epoch: 73
2022-11-23 01:25:35,645 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8398024243387309, 'Total loss': 0.8398024243387309} | train loss {'Reaction outcome loss': 0.8084940305880962, 'Total loss': 0.8084940305880962}
2022-11-23 01:25:35,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:35,646 INFO:     Epoch: 74
2022-11-23 01:25:36,429 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8347623544660482, 'Total loss': 0.8347623544660482} | train loss {'Reaction outcome loss': 0.8113941150687395, 'Total loss': 0.8113941150687395}
2022-11-23 01:25:36,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:36,429 INFO:     Epoch: 75
2022-11-23 01:25:37,245 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8577616864984686, 'Total loss': 0.8577616864984686} | train loss {'Reaction outcome loss': 0.8096477129767018, 'Total loss': 0.8096477129767018}
2022-11-23 01:25:37,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:37,246 INFO:     Epoch: 76
2022-11-23 01:25:38,061 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8300975222479213, 'Total loss': 0.8300975222479213} | train loss {'Reaction outcome loss': 0.8003807921082743, 'Total loss': 0.8003807921082743}
2022-11-23 01:25:38,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:38,061 INFO:     Epoch: 77
2022-11-23 01:25:38,861 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8230952830477194, 'Total loss': 0.8230952830477194} | train loss {'Reaction outcome loss': 0.8021527772709247, 'Total loss': 0.8021527772709247}
2022-11-23 01:25:38,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:38,862 INFO:     Epoch: 78
2022-11-23 01:25:39,667 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8329711231318387, 'Total loss': 0.8329711231318387} | train loss {'Reaction outcome loss': 0.7996483728770287, 'Total loss': 0.7996483728770287}
2022-11-23 01:25:39,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:39,667 INFO:     Epoch: 79
2022-11-23 01:25:40,514 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8472983146255667, 'Total loss': 0.8472983146255667} | train loss {'Reaction outcome loss': 0.806751839215717, 'Total loss': 0.806751839215717}
2022-11-23 01:25:40,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:40,514 INFO:     Epoch: 80
2022-11-23 01:25:41,349 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8548957847736098, 'Total loss': 0.8548957847736098} | train loss {'Reaction outcome loss': 0.8050514375490527, 'Total loss': 0.8050514375490527}
2022-11-23 01:25:41,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:41,350 INFO:     Epoch: 81
2022-11-23 01:25:42,169 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8333219933238897, 'Total loss': 0.8333219933238897} | train loss {'Reaction outcome loss': 0.8017273938223239, 'Total loss': 0.8017273938223239}
2022-11-23 01:25:42,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:42,170 INFO:     Epoch: 82
2022-11-23 01:25:42,961 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8444339345124635, 'Total loss': 0.8444339345124635} | train loss {'Reaction outcome loss': 0.807279922428631, 'Total loss': 0.807279922428631}
2022-11-23 01:25:42,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:42,961 INFO:     Epoch: 83
2022-11-23 01:25:43,718 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8227402513677423, 'Total loss': 0.8227402513677423} | train loss {'Reaction outcome loss': 0.8062632661913672, 'Total loss': 0.8062632661913672}
2022-11-23 01:25:43,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:43,719 INFO:     Epoch: 84
2022-11-23 01:25:44,572 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8423883332447573, 'Total loss': 0.8423883332447573} | train loss {'Reaction outcome loss': 0.8018541259150351, 'Total loss': 0.8018541259150351}
2022-11-23 01:25:44,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:44,573 INFO:     Epoch: 85
2022-11-23 01:25:45,381 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8085785616527904, 'Total loss': 0.8085785616527904} | train loss {'Reaction outcome loss': 0.8012794039903148, 'Total loss': 0.8012794039903148}
2022-11-23 01:25:45,381 INFO:     Found new best model at epoch 85
2022-11-23 01:25:45,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:45,382 INFO:     Epoch: 86
2022-11-23 01:25:46,208 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.855140430006114, 'Total loss': 0.855140430006114} | train loss {'Reaction outcome loss': 0.8041550258715306, 'Total loss': 0.8041550258715306}
2022-11-23 01:25:46,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:46,208 INFO:     Epoch: 87
2022-11-23 01:25:46,998 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8285132294351404, 'Total loss': 0.8285132294351404} | train loss {'Reaction outcome loss': 0.8046055360426826, 'Total loss': 0.8046055360426826}
2022-11-23 01:25:46,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:46,999 INFO:     Epoch: 88
2022-11-23 01:25:47,815 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8458273471756415, 'Total loss': 0.8458273471756415} | train loss {'Reaction outcome loss': 0.803091918388682, 'Total loss': 0.803091918388682}
2022-11-23 01:25:47,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:47,815 INFO:     Epoch: 89
2022-11-23 01:25:48,609 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.825640884990042, 'Total loss': 0.825640884990042} | train loss {'Reaction outcome loss': 0.806536226743652, 'Total loss': 0.806536226743652}
2022-11-23 01:25:48,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:48,610 INFO:     Epoch: 90
2022-11-23 01:25:49,389 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8433249944990332, 'Total loss': 0.8433249944990332} | train loss {'Reaction outcome loss': 0.8047295737891428, 'Total loss': 0.8047295737891428}
2022-11-23 01:25:49,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:49,389 INFO:     Epoch: 91
2022-11-23 01:25:50,245 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8330359716307033, 'Total loss': 0.8330359716307033} | train loss {'Reaction outcome loss': 0.7993595565278684, 'Total loss': 0.7993595565278684}
2022-11-23 01:25:50,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:50,245 INFO:     Epoch: 92
2022-11-23 01:25:51,080 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8207518051971089, 'Total loss': 0.8207518051971089} | train loss {'Reaction outcome loss': 0.7991890897673946, 'Total loss': 0.7991890897673946}
2022-11-23 01:25:51,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:51,081 INFO:     Epoch: 93
2022-11-23 01:25:51,871 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8207882967862216, 'Total loss': 0.8207882967862216} | train loss {'Reaction outcome loss': 0.803603870613921, 'Total loss': 0.803603870613921}
2022-11-23 01:25:51,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:51,872 INFO:     Epoch: 94
2022-11-23 01:25:52,712 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8266220763325691, 'Total loss': 0.8266220763325691} | train loss {'Reaction outcome loss': 0.8087357634137715, 'Total loss': 0.8087357634137715}
2022-11-23 01:25:52,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:52,712 INFO:     Epoch: 95
2022-11-23 01:25:53,526 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8348426148295403, 'Total loss': 0.8348426148295403} | train loss {'Reaction outcome loss': 0.8035621995166424, 'Total loss': 0.8035621995166424}
2022-11-23 01:25:53,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:53,527 INFO:     Epoch: 96
2022-11-23 01:25:54,317 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8247459077022292, 'Total loss': 0.8247459077022292} | train loss {'Reaction outcome loss': 0.8047798537919598, 'Total loss': 0.8047798537919598}
2022-11-23 01:25:54,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:54,317 INFO:     Epoch: 97
2022-11-23 01:25:55,118 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8447481393814087, 'Total loss': 0.8447481393814087} | train loss {'Reaction outcome loss': 0.8009928175278248, 'Total loss': 0.8009928175278248}
2022-11-23 01:25:55,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:55,118 INFO:     Epoch: 98
2022-11-23 01:25:55,897 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8375479253855619, 'Total loss': 0.8375479253855619} | train loss {'Reaction outcome loss': 0.8057849373548261, 'Total loss': 0.8057849373548261}
2022-11-23 01:25:55,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:55,897 INFO:     Epoch: 99
2022-11-23 01:25:56,727 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8433010185306723, 'Total loss': 0.8433010185306723} | train loss {'Reaction outcome loss': 0.8089400144113649, 'Total loss': 0.8089400144113649}
2022-11-23 01:25:56,727 INFO:     Best model found after epoch 86 of 100.
2022-11-23 01:25:56,727 INFO:   Done with stage: TRAINING
2022-11-23 01:25:56,727 INFO:   Starting stage: EVALUATION
2022-11-23 01:25:56,848 INFO:   Done with stage: EVALUATION
2022-11-23 01:25:56,848 INFO:   Leaving out SEQ value Fold_8
2022-11-23 01:25:56,861 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-23 01:25:56,861 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:25:57,521 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:25:57,521 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:25:57,593 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:25:57,593 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:25:57,593 INFO:     No hyperparam tuning for this model
2022-11-23 01:25:57,593 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:25:57,594 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:25:57,595 INFO:     None feature selector for col prot
2022-11-23 01:25:57,595 INFO:     None feature selector for col prot
2022-11-23 01:25:57,595 INFO:     None feature selector for col prot
2022-11-23 01:25:57,596 INFO:     None feature selector for col chem
2022-11-23 01:25:57,596 INFO:     None feature selector for col chem
2022-11-23 01:25:57,596 INFO:     None feature selector for col chem
2022-11-23 01:25:57,596 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:25:57,596 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:25:57,598 INFO:     Number of params in model 168571
2022-11-23 01:25:57,601 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:25:57,601 INFO:   Starting stage: TRAINING
2022-11-23 01:25:57,660 INFO:     Val loss before train {'Reaction outcome loss': 0.9775718006976816, 'Total loss': 0.9775718006976816}
2022-11-23 01:25:57,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:57,660 INFO:     Epoch: 0
2022-11-23 01:25:58,442 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8245995959570241, 'Total loss': 0.8245995959570241} | train loss {'Reaction outcome loss': 0.8753487089129744, 'Total loss': 0.8753487089129744}
2022-11-23 01:25:58,442 INFO:     Found new best model at epoch 0
2022-11-23 01:25:58,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:58,443 INFO:     Epoch: 1
2022-11-23 01:25:59,229 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8102474177992621, 'Total loss': 0.8102474177992621} | train loss {'Reaction outcome loss': 0.8404419054506255, 'Total loss': 0.8404419054506255}
2022-11-23 01:25:59,230 INFO:     Found new best model at epoch 1
2022-11-23 01:25:59,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:25:59,230 INFO:     Epoch: 2
2022-11-23 01:26:00,013 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8227280516957127, 'Total loss': 0.8227280516957127} | train loss {'Reaction outcome loss': 0.8355996396209373, 'Total loss': 0.8355996396209373}
2022-11-23 01:26:00,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:00,014 INFO:     Epoch: 3
2022-11-23 01:26:00,826 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8311123529145884, 'Total loss': 0.8311123529145884} | train loss {'Reaction outcome loss': 0.8409852611481167, 'Total loss': 0.8409852611481167}
2022-11-23 01:26:00,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:00,827 INFO:     Epoch: 4
2022-11-23 01:26:01,649 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8105913130349891, 'Total loss': 0.8105913130349891} | train loss {'Reaction outcome loss': 0.8333618754490477, 'Total loss': 0.8333618754490477}
2022-11-23 01:26:01,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:01,649 INFO:     Epoch: 5
2022-11-23 01:26:02,473 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8139548759127773, 'Total loss': 0.8139548759127773} | train loss {'Reaction outcome loss': 0.8286456617175556, 'Total loss': 0.8286456617175556}
2022-11-23 01:26:02,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:02,474 INFO:     Epoch: 6
2022-11-23 01:26:03,232 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8245622314685999, 'Total loss': 0.8245622314685999} | train loss {'Reaction outcome loss': 0.82579619046606, 'Total loss': 0.82579619046606}
2022-11-23 01:26:03,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:03,232 INFO:     Epoch: 7
2022-11-23 01:26:04,027 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8247950021610704, 'Total loss': 0.8247950021610704} | train loss {'Reaction outcome loss': 0.8260437071811958, 'Total loss': 0.8260437071811958}
2022-11-23 01:26:04,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:04,028 INFO:     Epoch: 8
2022-11-23 01:26:04,840 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.802359297525051, 'Total loss': 0.802359297525051} | train loss {'Reaction outcome loss': 0.823061685703817, 'Total loss': 0.823061685703817}
2022-11-23 01:26:04,840 INFO:     Found new best model at epoch 8
2022-11-23 01:26:04,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:04,841 INFO:     Epoch: 9
2022-11-23 01:26:05,666 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8133192027724067, 'Total loss': 0.8133192027724067} | train loss {'Reaction outcome loss': 0.823795563861972, 'Total loss': 0.823795563861972}
2022-11-23 01:26:05,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:05,667 INFO:     Epoch: 10
2022-11-23 01:26:06,531 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7964760869048363, 'Total loss': 0.7964760869048363} | train loss {'Reaction outcome loss': 0.8218115563275384, 'Total loss': 0.8218115563275384}
2022-11-23 01:26:06,531 INFO:     Found new best model at epoch 10
2022-11-23 01:26:06,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:06,532 INFO:     Epoch: 11
2022-11-23 01:26:07,439 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8073326564112375, 'Total loss': 0.8073326564112375} | train loss {'Reaction outcome loss': 0.822717765071353, 'Total loss': 0.822717765071353}
2022-11-23 01:26:07,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:07,440 INFO:     Epoch: 12
2022-11-23 01:26:08,300 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8266782677450846, 'Total loss': 0.8266782677450846} | train loss {'Reaction outcome loss': 0.8165432600701441, 'Total loss': 0.8165432600701441}
2022-11-23 01:26:08,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:08,300 INFO:     Epoch: 13
2022-11-23 01:26:09,121 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8173863541248233, 'Total loss': 0.8173863541248233} | train loss {'Reaction outcome loss': 0.8166828811412952, 'Total loss': 0.8166828811412952}
2022-11-23 01:26:09,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:09,122 INFO:     Epoch: 14
2022-11-23 01:26:09,914 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8077941065610841, 'Total loss': 0.8077941065610841} | train loss {'Reaction outcome loss': 0.8138303027534094, 'Total loss': 0.8138303027534094}
2022-11-23 01:26:09,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:09,915 INFO:     Epoch: 15
2022-11-23 01:26:10,701 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8095561792684156, 'Total loss': 0.8095561792684156} | train loss {'Reaction outcome loss': 0.8164801194531018, 'Total loss': 0.8164801194531018}
2022-11-23 01:26:10,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:10,702 INFO:     Epoch: 16
2022-11-23 01:26:11,522 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8041580402573874, 'Total loss': 0.8041580402573874} | train loss {'Reaction outcome loss': 0.8155711287113486, 'Total loss': 0.8155711287113486}
2022-11-23 01:26:11,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:11,522 INFO:     Epoch: 17
2022-11-23 01:26:12,327 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.808222483063853, 'Total loss': 0.808222483063853} | train loss {'Reaction outcome loss': 0.813714323595899, 'Total loss': 0.813714323595899}
2022-11-23 01:26:12,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:12,328 INFO:     Epoch: 18
2022-11-23 01:26:13,167 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.808304742325184, 'Total loss': 0.808304742325184} | train loss {'Reaction outcome loss': 0.8133326369475146, 'Total loss': 0.8133326369475146}
2022-11-23 01:26:13,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:13,167 INFO:     Epoch: 19
2022-11-23 01:26:14,016 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8043914465017097, 'Total loss': 0.8043914465017097} | train loss {'Reaction outcome loss': 0.8083723330351172, 'Total loss': 0.8083723330351172}
2022-11-23 01:26:14,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:14,016 INFO:     Epoch: 20
2022-11-23 01:26:14,829 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7979531135669974, 'Total loss': 0.7979531135669974} | train loss {'Reaction outcome loss': 0.8106852582976466, 'Total loss': 0.8106852582976466}
2022-11-23 01:26:14,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:14,829 INFO:     Epoch: 21
2022-11-23 01:26:15,635 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7980173909386923, 'Total loss': 0.7980173909386923} | train loss {'Reaction outcome loss': 0.8166346350898508, 'Total loss': 0.8166346350898508}
2022-11-23 01:26:15,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:15,635 INFO:     Epoch: 22
2022-11-23 01:26:16,469 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7943513067655785, 'Total loss': 0.7943513067655785} | train loss {'Reaction outcome loss': 0.8108867414173533, 'Total loss': 0.8108867414173533}
2022-11-23 01:26:16,469 INFO:     Found new best model at epoch 22
2022-11-23 01:26:16,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:16,470 INFO:     Epoch: 23
2022-11-23 01:26:17,245 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.803987440674804, 'Total loss': 0.803987440674804} | train loss {'Reaction outcome loss': 0.8125217105032968, 'Total loss': 0.8125217105032968}
2022-11-23 01:26:17,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:17,246 INFO:     Epoch: 24
2022-11-23 01:26:18,053 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7952871946401374, 'Total loss': 0.7952871946401374} | train loss {'Reaction outcome loss': 0.8135915677078435, 'Total loss': 0.8135915677078435}
2022-11-23 01:26:18,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:18,053 INFO:     Epoch: 25
2022-11-23 01:26:18,825 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7863318095373553, 'Total loss': 0.7863318095373553} | train loss {'Reaction outcome loss': 0.8086887133903191, 'Total loss': 0.8086887133903191}
2022-11-23 01:26:18,825 INFO:     Found new best model at epoch 25
2022-11-23 01:26:18,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:18,826 INFO:     Epoch: 26
2022-11-23 01:26:19,658 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7884269474550735, 'Total loss': 0.7884269474550735} | train loss {'Reaction outcome loss': 0.810536475699456, 'Total loss': 0.810536475699456}
2022-11-23 01:26:19,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:19,658 INFO:     Epoch: 27
2022-11-23 01:26:20,478 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7898425536100254, 'Total loss': 0.7898425536100254} | train loss {'Reaction outcome loss': 0.8103895329061102, 'Total loss': 0.8103895329061102}
2022-11-23 01:26:20,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:20,478 INFO:     Epoch: 28
2022-11-23 01:26:21,321 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8031127577604249, 'Total loss': 0.8031127577604249} | train loss {'Reaction outcome loss': 0.8129864431551246, 'Total loss': 0.8129864431551246}
2022-11-23 01:26:21,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:21,321 INFO:     Epoch: 29
2022-11-23 01:26:22,132 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8036677282910014, 'Total loss': 0.8036677282910014} | train loss {'Reaction outcome loss': 0.806179942166219, 'Total loss': 0.806179942166219}
2022-11-23 01:26:22,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:22,133 INFO:     Epoch: 30
2022-11-23 01:26:22,940 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7921996345353681, 'Total loss': 0.7921996345353681} | train loss {'Reaction outcome loss': 0.8055118781621339, 'Total loss': 0.8055118781621339}
2022-11-23 01:26:22,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:22,941 INFO:     Epoch: 31
2022-11-23 01:26:23,730 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7980632754259331, 'Total loss': 0.7980632754259331} | train loss {'Reaction outcome loss': 0.8093644910659946, 'Total loss': 0.8093644910659946}
2022-11-23 01:26:23,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:23,731 INFO:     Epoch: 32
2022-11-23 01:26:24,534 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8067161496295485, 'Total loss': 0.8067161496295485} | train loss {'Reaction outcome loss': 0.8050478407349743, 'Total loss': 0.8050478407349743}
2022-11-23 01:26:24,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:24,534 INFO:     Epoch: 33
2022-11-23 01:26:25,347 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.817248264024424, 'Total loss': 0.817248264024424} | train loss {'Reaction outcome loss': 0.8072362619101024, 'Total loss': 0.8072362619101024}
2022-11-23 01:26:25,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:25,347 INFO:     Epoch: 34
2022-11-23 01:26:26,183 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8038607267446296, 'Total loss': 0.8038607267446296} | train loss {'Reaction outcome loss': 0.8062075613463511, 'Total loss': 0.8062075613463511}
2022-11-23 01:26:26,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:26,183 INFO:     Epoch: 35
2022-11-23 01:26:27,005 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.797403235768163, 'Total loss': 0.797403235768163} | train loss {'Reaction outcome loss': 0.8050195429413045, 'Total loss': 0.8050195429413045}
2022-11-23 01:26:27,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:27,005 INFO:     Epoch: 36
2022-11-23 01:26:27,792 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.792666052663049, 'Total loss': 0.792666052663049} | train loss {'Reaction outcome loss': 0.809834868326539, 'Total loss': 0.809834868326539}
2022-11-23 01:26:27,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:27,792 INFO:     Epoch: 37
2022-11-23 01:26:28,583 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7992331441058669, 'Total loss': 0.7992331441058669} | train loss {'Reaction outcome loss': 0.811598834077843, 'Total loss': 0.811598834077843}
2022-11-23 01:26:28,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:28,583 INFO:     Epoch: 38
2022-11-23 01:26:29,369 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7996673625569011, 'Total loss': 0.7996673625569011} | train loss {'Reaction outcome loss': 0.8067462213459562, 'Total loss': 0.8067462213459562}
2022-11-23 01:26:29,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:29,369 INFO:     Epoch: 39
2022-11-23 01:26:30,171 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8114813635515612, 'Total loss': 0.8114813635515612} | train loss {'Reaction outcome loss': 0.8056231745686687, 'Total loss': 0.8056231745686687}
2022-11-23 01:26:30,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:30,171 INFO:     Epoch: 40
2022-11-23 01:26:30,956 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7929916901643886, 'Total loss': 0.7929916901643886} | train loss {'Reaction outcome loss': 0.8056101380068748, 'Total loss': 0.8056101380068748}
2022-11-23 01:26:30,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:30,956 INFO:     Epoch: 41
2022-11-23 01:26:31,723 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8139896039352861, 'Total loss': 0.8139896039352861} | train loss {'Reaction outcome loss': 0.8094906904658333, 'Total loss': 0.8094906904658333}
2022-11-23 01:26:31,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:31,723 INFO:     Epoch: 42
2022-11-23 01:26:32,506 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7908919259559276, 'Total loss': 0.7908919259559276} | train loss {'Reaction outcome loss': 0.8076325107793338, 'Total loss': 0.8076325107793338}
2022-11-23 01:26:32,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:32,506 INFO:     Epoch: 43
2022-11-23 01:26:33,295 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8187897898430048, 'Total loss': 0.8187897898430048} | train loss {'Reaction outcome loss': 0.8083940492790254, 'Total loss': 0.8083940492790254}
2022-11-23 01:26:33,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:33,295 INFO:     Epoch: 44
2022-11-23 01:26:34,117 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7830113214115764, 'Total loss': 0.7830113214115764} | train loss {'Reaction outcome loss': 0.805899369667788, 'Total loss': 0.805899369667788}
2022-11-23 01:26:34,117 INFO:     Found new best model at epoch 44
2022-11-23 01:26:34,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:34,118 INFO:     Epoch: 45
2022-11-23 01:26:34,914 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8278659429661063, 'Total loss': 0.8278659429661063} | train loss {'Reaction outcome loss': 0.8081775292998454, 'Total loss': 0.8081775292998454}
2022-11-23 01:26:34,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:34,915 INFO:     Epoch: 46
2022-11-23 01:26:35,770 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7984863387983899, 'Total loss': 0.7984863387983899} | train loss {'Reaction outcome loss': 0.8093075487213056, 'Total loss': 0.8093075487213056}
2022-11-23 01:26:35,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:35,771 INFO:     Epoch: 47
2022-11-23 01:26:36,551 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.809002242116041, 'Total loss': 0.809002242116041} | train loss {'Reaction outcome loss': 0.8052671971868296, 'Total loss': 0.8052671971868296}
2022-11-23 01:26:36,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:36,551 INFO:     Epoch: 48
2022-11-23 01:26:37,323 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8027632881042569, 'Total loss': 0.8027632881042569} | train loss {'Reaction outcome loss': 0.8110229773599593, 'Total loss': 0.8110229773599593}
2022-11-23 01:26:37,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:37,323 INFO:     Epoch: 49
2022-11-23 01:26:38,153 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7967609028483547, 'Total loss': 0.7967609028483547} | train loss {'Reaction outcome loss': 0.8042284818213494, 'Total loss': 0.8042284818213494}
2022-11-23 01:26:38,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:38,153 INFO:     Epoch: 50
2022-11-23 01:26:38,930 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7994588932325674, 'Total loss': 0.7994588932325674} | train loss {'Reaction outcome loss': 0.8078715638791929, 'Total loss': 0.8078715638791929}
2022-11-23 01:26:38,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:38,931 INFO:     Epoch: 51
2022-11-23 01:26:39,759 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8379006233326224, 'Total loss': 0.8379006233326224} | train loss {'Reaction outcome loss': 0.8075548714545907, 'Total loss': 0.8075548714545907}
2022-11-23 01:26:39,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:39,759 INFO:     Epoch: 52
2022-11-23 01:26:40,517 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7850672103637872, 'Total loss': 0.7850672103637872} | train loss {'Reaction outcome loss': 0.8042575725522197, 'Total loss': 0.8042575725522197}
2022-11-23 01:26:40,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:40,517 INFO:     Epoch: 53
2022-11-23 01:26:41,328 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7850623560506244, 'Total loss': 0.7850623560506244} | train loss {'Reaction outcome loss': 0.8115453878875638, 'Total loss': 0.8115453878875638}
2022-11-23 01:26:41,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:41,329 INFO:     Epoch: 54
2022-11-23 01:26:42,106 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7833623130654179, 'Total loss': 0.7833623130654179} | train loss {'Reaction outcome loss': 0.8059876250927566, 'Total loss': 0.8059876250927566}
2022-11-23 01:26:42,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:42,106 INFO:     Epoch: 55
2022-11-23 01:26:42,900 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8153245934220248, 'Total loss': 0.8153245934220248} | train loss {'Reaction outcome loss': 0.8000718443120112, 'Total loss': 0.8000718443120112}
2022-11-23 01:26:42,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:42,900 INFO:     Epoch: 56
2022-11-23 01:26:43,705 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7847230586894723, 'Total loss': 0.7847230586894723} | train loss {'Reaction outcome loss': 0.8081452665758915, 'Total loss': 0.8081452665758915}
2022-11-23 01:26:43,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:43,705 INFO:     Epoch: 57
2022-11-23 01:26:44,548 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7882133930228478, 'Total loss': 0.7882133930228478} | train loss {'Reaction outcome loss': 0.8053760842465963, 'Total loss': 0.8053760842465963}
2022-11-23 01:26:44,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:44,548 INFO:     Epoch: 58
2022-11-23 01:26:45,352 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8026917756989945, 'Total loss': 0.8026917756989945} | train loss {'Reaction outcome loss': 0.8137540557101125, 'Total loss': 0.8137540557101125}
2022-11-23 01:26:45,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:45,352 INFO:     Epoch: 59
2022-11-23 01:26:46,139 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7948437430137811, 'Total loss': 0.7948437430137811} | train loss {'Reaction outcome loss': 0.8078191376856116, 'Total loss': 0.8078191376856116}
2022-11-23 01:26:46,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:46,139 INFO:     Epoch: 60
2022-11-23 01:26:46,874 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8344095945358276, 'Total loss': 0.8344095945358276} | train loss {'Reaction outcome loss': 0.802234598969827, 'Total loss': 0.802234598969827}
2022-11-23 01:26:46,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:46,875 INFO:     Epoch: 61
2022-11-23 01:26:47,674 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7998011715190355, 'Total loss': 0.7998011715190355} | train loss {'Reaction outcome loss': 0.8092067175712742, 'Total loss': 0.8092067175712742}
2022-11-23 01:26:47,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:47,674 INFO:     Epoch: 62
2022-11-23 01:26:48,469 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8202573407528012, 'Total loss': 0.8202573407528012} | train loss {'Reaction outcome loss': 0.8055063596025842, 'Total loss': 0.8055063596025842}
2022-11-23 01:26:48,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:48,469 INFO:     Epoch: 63
2022-11-23 01:26:49,334 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7799284354198811, 'Total loss': 0.7799284354198811} | train loss {'Reaction outcome loss': 0.8067658774432589, 'Total loss': 0.8067658774432589}
2022-11-23 01:26:49,334 INFO:     Found new best model at epoch 63
2022-11-23 01:26:49,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:49,335 INFO:     Epoch: 64
2022-11-23 01:26:50,123 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7914168100024379, 'Total loss': 0.7914168100024379} | train loss {'Reaction outcome loss': 0.8016066626935708, 'Total loss': 0.8016066626935708}
2022-11-23 01:26:50,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:50,124 INFO:     Epoch: 65
2022-11-23 01:26:50,923 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8254759353260661, 'Total loss': 0.8254759353260661} | train loss {'Reaction outcome loss': 0.8052594393003182, 'Total loss': 0.8052594393003182}
2022-11-23 01:26:50,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:50,923 INFO:     Epoch: 66
2022-11-23 01:26:51,704 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8023322737494181, 'Total loss': 0.8023322737494181} | train loss {'Reaction outcome loss': 0.8003816530108452, 'Total loss': 0.8003816530108452}
2022-11-23 01:26:51,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:51,704 INFO:     Epoch: 67
2022-11-23 01:26:52,484 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8027976682019788, 'Total loss': 0.8027976682019788} | train loss {'Reaction outcome loss': 0.8062972016021853, 'Total loss': 0.8062972016021853}
2022-11-23 01:26:52,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:52,484 INFO:     Epoch: 68
2022-11-23 01:26:53,313 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7980801088865414, 'Total loss': 0.7980801088865414} | train loss {'Reaction outcome loss': 0.8073925103564732, 'Total loss': 0.8073925103564732}
2022-11-23 01:26:53,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:53,314 INFO:     Epoch: 69
2022-11-23 01:26:54,127 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8328856222851332, 'Total loss': 0.8328856222851332} | train loss {'Reaction outcome loss': 0.8090571855179599, 'Total loss': 0.8090571855179599}
2022-11-23 01:26:54,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:54,128 INFO:     Epoch: 70
2022-11-23 01:26:54,923 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8192191123962402, 'Total loss': 0.8192191123962402} | train loss {'Reaction outcome loss': 0.8089196569606906, 'Total loss': 0.8089196569606906}
2022-11-23 01:26:54,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:54,924 INFO:     Epoch: 71
2022-11-23 01:26:55,727 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8038082469341367, 'Total loss': 0.8038082469341367} | train loss {'Reaction outcome loss': 0.8062191148761844, 'Total loss': 0.8062191148761844}
2022-11-23 01:26:55,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:55,727 INFO:     Epoch: 72
2022-11-23 01:26:56,500 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7893522866936618, 'Total loss': 0.7893522866936618} | train loss {'Reaction outcome loss': 0.8059404770858952, 'Total loss': 0.8059404770858952}
2022-11-23 01:26:56,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:56,500 INFO:     Epoch: 73
2022-11-23 01:26:57,298 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8685086106145105, 'Total loss': 0.8685086106145105} | train loss {'Reaction outcome loss': 0.8095048189651771, 'Total loss': 0.8095048189651771}
2022-11-23 01:26:57,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:57,299 INFO:     Epoch: 74
2022-11-23 01:26:58,063 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7953702959903451, 'Total loss': 0.7953702959903451} | train loss {'Reaction outcome loss': 0.8091722486204789, 'Total loss': 0.8091722486204789}
2022-11-23 01:26:58,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:58,064 INFO:     Epoch: 75
2022-11-23 01:26:58,844 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7859795058882514, 'Total loss': 0.7859795058882514} | train loss {'Reaction outcome loss': 0.8068493212588498, 'Total loss': 0.8068493212588498}
2022-11-23 01:26:58,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:58,845 INFO:     Epoch: 76
2022-11-23 01:26:59,726 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7799889195797055, 'Total loss': 0.7799889195797055} | train loss {'Reaction outcome loss': 0.8094911946625006, 'Total loss': 0.8094911946625006}
2022-11-23 01:26:59,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:26:59,727 INFO:     Epoch: 77
2022-11-23 01:27:00,576 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7782524359780688, 'Total loss': 0.7782524359780688} | train loss {'Reaction outcome loss': 0.8031311786321343, 'Total loss': 0.8031311786321343}
2022-11-23 01:27:00,576 INFO:     Found new best model at epoch 77
2022-11-23 01:27:00,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:00,577 INFO:     Epoch: 78
2022-11-23 01:27:01,460 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7993414221807967, 'Total loss': 0.7993414221807967} | train loss {'Reaction outcome loss': 0.8008874665762558, 'Total loss': 0.8008874665762558}
2022-11-23 01:27:01,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:01,460 INFO:     Epoch: 79
2022-11-23 01:27:02,298 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7943777511286181, 'Total loss': 0.7943777511286181} | train loss {'Reaction outcome loss': 0.8057822643733416, 'Total loss': 0.8057822643733416}
2022-11-23 01:27:02,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:02,298 INFO:     Epoch: 80
2022-11-23 01:27:03,154 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7963082478489987, 'Total loss': 0.7963082478489987} | train loss {'Reaction outcome loss': 0.8023703606402288, 'Total loss': 0.8023703606402288}
2022-11-23 01:27:03,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:03,154 INFO:     Epoch: 81
2022-11-23 01:27:04,050 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7989259493905444, 'Total loss': 0.7989259493905444} | train loss {'Reaction outcome loss': 0.8076694340246623, 'Total loss': 0.8076694340246623}
2022-11-23 01:27:04,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:04,051 INFO:     Epoch: 82
2022-11-23 01:27:04,938 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7851438633231229, 'Total loss': 0.7851438633231229} | train loss {'Reaction outcome loss': 0.805368079880222, 'Total loss': 0.805368079880222}
2022-11-23 01:27:04,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:04,938 INFO:     Epoch: 83
2022-11-23 01:27:05,871 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8104896919671879, 'Total loss': 0.8104896919671879} | train loss {'Reaction outcome loss': 0.8030929119616258, 'Total loss': 0.8030929119616258}
2022-11-23 01:27:05,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:05,873 INFO:     Epoch: 84
2022-11-23 01:27:06,770 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7816658893296885, 'Total loss': 0.7816658893296885} | train loss {'Reaction outcome loss': 0.807173417117752, 'Total loss': 0.807173417117752}
2022-11-23 01:27:06,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:06,771 INFO:     Epoch: 85
2022-11-23 01:27:07,678 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7929287996403006, 'Total loss': 0.7929287996403006} | train loss {'Reaction outcome loss': 0.807100841134298, 'Total loss': 0.807100841134298}
2022-11-23 01:27:07,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:07,678 INFO:     Epoch: 86
2022-11-23 01:27:08,603 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7842811082684716, 'Total loss': 0.7842811082684716} | train loss {'Reaction outcome loss': 0.809103400614418, 'Total loss': 0.809103400614418}
2022-11-23 01:27:08,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:08,604 INFO:     Epoch: 87
2022-11-23 01:27:09,468 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7804982454277748, 'Total loss': 0.7804982454277748} | train loss {'Reaction outcome loss': 0.801784128805653, 'Total loss': 0.801784128805653}
2022-11-23 01:27:09,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:09,469 INFO:     Epoch: 88
2022-11-23 01:27:10,348 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7907511397849681, 'Total loss': 0.7907511397849681} | train loss {'Reaction outcome loss': 0.8027637519064497, 'Total loss': 0.8027637519064497}
2022-11-23 01:27:10,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:10,349 INFO:     Epoch: 89
2022-11-23 01:27:11,202 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.79808086434076, 'Total loss': 0.79808086434076} | train loss {'Reaction outcome loss': 0.8019095486426939, 'Total loss': 0.8019095486426939}
2022-11-23 01:27:11,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:11,202 INFO:     Epoch: 90
2022-11-23 01:27:12,105 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7916840342588203, 'Total loss': 0.7916840342588203} | train loss {'Reaction outcome loss': 0.8051308012399517, 'Total loss': 0.8051308012399517}
2022-11-23 01:27:12,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:12,107 INFO:     Epoch: 91
2022-11-23 01:27:12,983 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8000726831513781, 'Total loss': 0.8000726831513781} | train loss {'Reaction outcome loss': 0.801974533278434, 'Total loss': 0.801974533278434}
2022-11-23 01:27:12,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:12,984 INFO:     Epoch: 92
2022-11-23 01:27:13,870 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7879391631414724, 'Total loss': 0.7879391631414724} | train loss {'Reaction outcome loss': 0.8032475708693755, 'Total loss': 0.8032475708693755}
2022-11-23 01:27:13,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:13,871 INFO:     Epoch: 93
2022-11-23 01:27:14,726 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7923252610273139, 'Total loss': 0.7923252610273139} | train loss {'Reaction outcome loss': 0.802926712348813, 'Total loss': 0.802926712348813}
2022-11-23 01:27:14,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:14,726 INFO:     Epoch: 94
2022-11-23 01:27:15,634 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8004577118296956, 'Total loss': 0.8004577118296956} | train loss {'Reaction outcome loss': 0.8079992290891584, 'Total loss': 0.8079992290891584}
2022-11-23 01:27:15,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:15,634 INFO:     Epoch: 95
2022-11-23 01:27:16,543 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7963337343792583, 'Total loss': 0.7963337343792583} | train loss {'Reaction outcome loss': 0.806106227587481, 'Total loss': 0.806106227587481}
2022-11-23 01:27:16,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:16,543 INFO:     Epoch: 96
2022-11-23 01:27:17,444 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7924923522527828, 'Total loss': 0.7924923522527828} | train loss {'Reaction outcome loss': 0.8051845167503983, 'Total loss': 0.8051845167503983}
2022-11-23 01:27:17,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:17,445 INFO:     Epoch: 97
2022-11-23 01:27:18,316 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7909456089485524, 'Total loss': 0.7909456089485524} | train loss {'Reaction outcome loss': 0.8019473191167488, 'Total loss': 0.8019473191167488}
2022-11-23 01:27:18,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:18,316 INFO:     Epoch: 98
2022-11-23 01:27:19,211 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7896511922048968, 'Total loss': 0.7896511922048968} | train loss {'Reaction outcome loss': 0.8005765462752248, 'Total loss': 0.8005765462752248}
2022-11-23 01:27:19,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:19,211 INFO:     Epoch: 99
2022-11-23 01:27:20,095 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8018705075563386, 'Total loss': 0.8018705075563386} | train loss {'Reaction outcome loss': 0.7978472754847808, 'Total loss': 0.7978472754847808}
2022-11-23 01:27:20,095 INFO:     Best model found after epoch 78 of 100.
2022-11-23 01:27:20,095 INFO:   Done with stage: TRAINING
2022-11-23 01:27:20,095 INFO:   Starting stage: EVALUATION
2022-11-23 01:27:20,233 INFO:   Done with stage: EVALUATION
2022-11-23 01:27:20,233 INFO:   Leaving out SEQ value Fold_9
2022-11-23 01:27:20,246 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 01:27:20,247 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:27:20,928 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:27:20,928 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:27:21,002 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:27:21,003 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:27:21,003 INFO:     No hyperparam tuning for this model
2022-11-23 01:27:21,003 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:27:21,003 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:27:21,004 INFO:     None feature selector for col prot
2022-11-23 01:27:21,004 INFO:     None feature selector for col prot
2022-11-23 01:27:21,004 INFO:     None feature selector for col prot
2022-11-23 01:27:21,004 INFO:     None feature selector for col chem
2022-11-23 01:27:21,004 INFO:     None feature selector for col chem
2022-11-23 01:27:21,005 INFO:     None feature selector for col chem
2022-11-23 01:27:21,005 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:27:21,005 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:27:21,007 INFO:     Number of params in model 168571
2022-11-23 01:27:21,011 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:27:21,011 INFO:   Starting stage: TRAINING
2022-11-23 01:27:21,071 INFO:     Val loss before train {'Reaction outcome loss': 1.032246469096704, 'Total loss': 1.032246469096704}
2022-11-23 01:27:21,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:21,072 INFO:     Epoch: 0
2022-11-23 01:27:21,962 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8741690103303302, 'Total loss': 0.8741690103303302} | train loss {'Reaction outcome loss': 0.8889507283606837, 'Total loss': 0.8889507283606837}
2022-11-23 01:27:21,962 INFO:     Found new best model at epoch 0
2022-11-23 01:27:21,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:21,963 INFO:     Epoch: 1
2022-11-23 01:27:22,890 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8908224241300062, 'Total loss': 0.8908224241300062} | train loss {'Reaction outcome loss': 0.8542569071775482, 'Total loss': 0.8542569071775482}
2022-11-23 01:27:22,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:22,891 INFO:     Epoch: 2
2022-11-23 01:27:23,812 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8604976412924853, 'Total loss': 0.8604976412924853} | train loss {'Reaction outcome loss': 0.8454135270008156, 'Total loss': 0.8454135270008156}
2022-11-23 01:27:23,812 INFO:     Found new best model at epoch 2
2022-11-23 01:27:23,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:23,813 INFO:     Epoch: 3
2022-11-23 01:27:24,720 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8624018423936584, 'Total loss': 0.8624018423936584} | train loss {'Reaction outcome loss': 0.8453324458772137, 'Total loss': 0.8453324458772137}
2022-11-23 01:27:24,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:24,721 INFO:     Epoch: 4
2022-11-23 01:27:25,585 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.9142892665483735, 'Total loss': 0.9142892665483735} | train loss {'Reaction outcome loss': 0.8326984396384608, 'Total loss': 0.8326984396384608}
2022-11-23 01:27:25,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:25,585 INFO:     Epoch: 5
2022-11-23 01:27:26,496 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8564536822113124, 'Total loss': 0.8564536822113124} | train loss {'Reaction outcome loss': 0.8377706138116698, 'Total loss': 0.8377706138116698}
2022-11-23 01:27:26,496 INFO:     Found new best model at epoch 5
2022-11-23 01:27:26,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:26,497 INFO:     Epoch: 6
2022-11-23 01:27:27,382 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8439719500866804, 'Total loss': 0.8439719500866804} | train loss {'Reaction outcome loss': 0.8311013075853547, 'Total loss': 0.8311013075853547}
2022-11-23 01:27:27,382 INFO:     Found new best model at epoch 6
2022-11-23 01:27:27,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:27,383 INFO:     Epoch: 7
2022-11-23 01:27:28,234 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8511270501396873, 'Total loss': 0.8511270501396873} | train loss {'Reaction outcome loss': 0.8290687265896028, 'Total loss': 0.8290687265896028}
2022-11-23 01:27:28,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:28,234 INFO:     Epoch: 8
2022-11-23 01:27:29,079 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8807561519471082, 'Total loss': 0.8807561519471082} | train loss {'Reaction outcome loss': 0.8259548239650265, 'Total loss': 0.8259548239650265}
2022-11-23 01:27:29,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:29,080 INFO:     Epoch: 9
2022-11-23 01:27:29,964 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8489846329797398, 'Total loss': 0.8489846329797398} | train loss {'Reaction outcome loss': 0.8279171933329874, 'Total loss': 0.8279171933329874}
2022-11-23 01:27:29,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:29,965 INFO:     Epoch: 10
2022-11-23 01:27:30,827 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8440627740188078, 'Total loss': 0.8440627740188078} | train loss {'Reaction outcome loss': 0.8263236555841661, 'Total loss': 0.8263236555841661}
2022-11-23 01:27:30,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:30,828 INFO:     Epoch: 11
2022-11-23 01:27:31,692 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8425759429281409, 'Total loss': 0.8425759429281409} | train loss {'Reaction outcome loss': 0.824607546531385, 'Total loss': 0.824607546531385}
2022-11-23 01:27:31,692 INFO:     Found new best model at epoch 11
2022-11-23 01:27:31,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:31,693 INFO:     Epoch: 12
2022-11-23 01:27:32,590 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8427064730362459, 'Total loss': 0.8427064730362459} | train loss {'Reaction outcome loss': 0.8255176254578175, 'Total loss': 0.8255176254578175}
2022-11-23 01:27:32,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:32,590 INFO:     Epoch: 13
2022-11-23 01:27:33,497 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8586678518490358, 'Total loss': 0.8586678518490358} | train loss {'Reaction outcome loss': 0.8280999843151339, 'Total loss': 0.8280999843151339}
2022-11-23 01:27:33,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:33,497 INFO:     Epoch: 14
2022-11-23 01:27:34,404 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8395245684818788, 'Total loss': 0.8395245684818788} | train loss {'Reaction outcome loss': 0.8216375662915169, 'Total loss': 0.8216375662915169}
2022-11-23 01:27:34,404 INFO:     Found new best model at epoch 14
2022-11-23 01:27:34,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:34,405 INFO:     Epoch: 15
2022-11-23 01:27:35,284 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8456746935844421, 'Total loss': 0.8456746935844421} | train loss {'Reaction outcome loss': 0.8261247034515103, 'Total loss': 0.8261247034515103}
2022-11-23 01:27:35,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:35,285 INFO:     Epoch: 16
2022-11-23 01:27:36,183 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.842048082839359, 'Total loss': 0.842048082839359} | train loss {'Reaction outcome loss': 0.8246876525302087, 'Total loss': 0.8246876525302087}
2022-11-23 01:27:36,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:36,183 INFO:     Epoch: 17
2022-11-23 01:27:37,140 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8360275714234873, 'Total loss': 0.8360275714234873} | train loss {'Reaction outcome loss': 0.8235585237703016, 'Total loss': 0.8235585237703016}
2022-11-23 01:27:37,141 INFO:     Found new best model at epoch 17
2022-11-23 01:27:37,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:37,142 INFO:     Epoch: 18
2022-11-23 01:27:38,012 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8388272097164934, 'Total loss': 0.8388272097164934} | train loss {'Reaction outcome loss': 0.8212668530402645, 'Total loss': 0.8212668530402645}
2022-11-23 01:27:38,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:38,013 INFO:     Epoch: 19
2022-11-23 01:27:38,851 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8425482443787835, 'Total loss': 0.8425482443787835} | train loss {'Reaction outcome loss': 0.8242292592842733, 'Total loss': 0.8242292592842733}
2022-11-23 01:27:38,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:38,851 INFO:     Epoch: 20
2022-11-23 01:27:39,737 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.847435021942312, 'Total loss': 0.847435021942312} | train loss {'Reaction outcome loss': 0.8219574481369026, 'Total loss': 0.8219574481369026}
2022-11-23 01:27:39,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:39,737 INFO:     Epoch: 21
2022-11-23 01:27:40,637 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8438064510172064, 'Total loss': 0.8438064510172064} | train loss {'Reaction outcome loss': 0.8285553785822084, 'Total loss': 0.8285553785822084}
2022-11-23 01:27:40,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:40,637 INFO:     Epoch: 22
2022-11-23 01:27:41,474 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8546137674288317, 'Total loss': 0.8546137674288317} | train loss {'Reaction outcome loss': 0.8207099891958698, 'Total loss': 0.8207099891958698}
2022-11-23 01:27:41,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:41,475 INFO:     Epoch: 23
2022-11-23 01:27:42,341 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.853968274186958, 'Total loss': 0.853968274186958} | train loss {'Reaction outcome loss': 0.8232650625849923, 'Total loss': 0.8232650625849923}
2022-11-23 01:27:42,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:42,341 INFO:     Epoch: 24
2022-11-23 01:27:43,246 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8370746875351126, 'Total loss': 0.8370746875351126} | train loss {'Reaction outcome loss': 0.8249669496811205, 'Total loss': 0.8249669496811205}
2022-11-23 01:27:43,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:43,248 INFO:     Epoch: 25
2022-11-23 01:27:44,175 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8682879927483472, 'Total loss': 0.8682879927483472} | train loss {'Reaction outcome loss': 0.8220082456546445, 'Total loss': 0.8220082456546445}
2022-11-23 01:27:44,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:44,176 INFO:     Epoch: 26
2022-11-23 01:27:45,015 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.861510044471784, 'Total loss': 0.861510044471784} | train loss {'Reaction outcome loss': 0.8221220929896639, 'Total loss': 0.8221220929896639}
2022-11-23 01:27:45,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:45,016 INFO:     Epoch: 27
2022-11-23 01:27:45,907 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8448823067274961, 'Total loss': 0.8448823067274961} | train loss {'Reaction outcome loss': 0.8232903849453695, 'Total loss': 0.8232903849453695}
2022-11-23 01:27:45,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:45,907 INFO:     Epoch: 28
2022-11-23 01:27:46,821 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8690422366965901, 'Total loss': 0.8690422366965901} | train loss {'Reaction outcome loss': 0.8204967595877186, 'Total loss': 0.8204967595877186}
2022-11-23 01:27:46,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:46,822 INFO:     Epoch: 29
2022-11-23 01:27:47,671 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8590829033743251, 'Total loss': 0.8590829033743251} | train loss {'Reaction outcome loss': 0.8236910800539679, 'Total loss': 0.8236910800539679}
2022-11-23 01:27:47,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:47,672 INFO:     Epoch: 30
2022-11-23 01:27:48,549 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8394694152203473, 'Total loss': 0.8394694152203473} | train loss {'Reaction outcome loss': 0.8193963841805535, 'Total loss': 0.8193963841805535}
2022-11-23 01:27:48,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:48,549 INFO:     Epoch: 31
2022-11-23 01:27:49,398 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8432742113416846, 'Total loss': 0.8432742113416846} | train loss {'Reaction outcome loss': 0.827465851701075, 'Total loss': 0.827465851701075}
2022-11-23 01:27:49,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:49,399 INFO:     Epoch: 32
2022-11-23 01:27:50,295 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8380104127255353, 'Total loss': 0.8380104127255353} | train loss {'Reaction outcome loss': 0.8221181735636727, 'Total loss': 0.8221181735636727}
2022-11-23 01:27:50,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:50,295 INFO:     Epoch: 33
2022-11-23 01:27:51,231 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8777915334159677, 'Total loss': 0.8777915334159677} | train loss {'Reaction outcome loss': 0.8214620471962036, 'Total loss': 0.8214620471962036}
2022-11-23 01:27:51,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:51,231 INFO:     Epoch: 34
2022-11-23 01:27:52,120 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8430346772074699, 'Total loss': 0.8430346772074699} | train loss {'Reaction outcome loss': 0.8239004449738611, 'Total loss': 0.8239004449738611}
2022-11-23 01:27:52,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:52,120 INFO:     Epoch: 35
2022-11-23 01:27:53,001 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8471951416947625, 'Total loss': 0.8471951416947625} | train loss {'Reaction outcome loss': 0.8227208333630716, 'Total loss': 0.8227208333630716}
2022-11-23 01:27:53,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:53,002 INFO:     Epoch: 36
2022-11-23 01:27:53,920 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8571125953034922, 'Total loss': 0.8571125953034922} | train loss {'Reaction outcome loss': 0.8235307899453947, 'Total loss': 0.8235307899453947}
2022-11-23 01:27:53,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:53,920 INFO:     Epoch: 37
2022-11-23 01:27:54,785 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.860033858906139, 'Total loss': 0.860033858906139} | train loss {'Reaction outcome loss': 0.8238434129424633, 'Total loss': 0.8238434129424633}
2022-11-23 01:27:54,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:54,786 INFO:     Epoch: 38
2022-11-23 01:27:55,668 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.870913028717041, 'Total loss': 0.870913028717041} | train loss {'Reaction outcome loss': 0.8292017878303605, 'Total loss': 0.8292017878303605}
2022-11-23 01:27:55,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:55,669 INFO:     Epoch: 39
2022-11-23 01:27:56,579 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8586104830557649, 'Total loss': 0.8586104830557649} | train loss {'Reaction outcome loss': 0.819654036793978, 'Total loss': 0.819654036793978}
2022-11-23 01:27:56,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:56,579 INFO:     Epoch: 40
2022-11-23 01:27:57,514 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8549516099420461, 'Total loss': 0.8549516099420461} | train loss {'Reaction outcome loss': 0.8271399379497574, 'Total loss': 0.8271399379497574}
2022-11-23 01:27:57,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:57,515 INFO:     Epoch: 41
2022-11-23 01:27:58,415 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8563080714507536, 'Total loss': 0.8563080714507536} | train loss {'Reaction outcome loss': 0.8236716710511716, 'Total loss': 0.8236716710511716}
2022-11-23 01:27:58,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:58,415 INFO:     Epoch: 42
2022-11-23 01:27:59,328 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8365977785804055, 'Total loss': 0.8365977785804055} | train loss {'Reaction outcome loss': 0.8253891453627618, 'Total loss': 0.8253891453627618}
2022-11-23 01:27:59,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:27:59,328 INFO:     Epoch: 43
2022-11-23 01:28:00,207 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8520370301875201, 'Total loss': 0.8520370301875201} | train loss {'Reaction outcome loss': 0.8203839438576852, 'Total loss': 0.8203839438576852}
2022-11-23 01:28:00,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:00,207 INFO:     Epoch: 44
2022-11-23 01:28:01,091 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8613819805058566, 'Total loss': 0.8613819805058566} | train loss {'Reaction outcome loss': 0.8213676938847188, 'Total loss': 0.8213676938847188}
2022-11-23 01:28:01,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:01,092 INFO:     Epoch: 45
2022-11-23 01:28:02,000 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8311621269041841, 'Total loss': 0.8311621269041841} | train loss {'Reaction outcome loss': 0.8235302833059142, 'Total loss': 0.8235302833059142}
2022-11-23 01:28:02,000 INFO:     Found new best model at epoch 45
2022-11-23 01:28:02,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:02,001 INFO:     Epoch: 46
2022-11-23 01:28:02,879 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8445418971506032, 'Total loss': 0.8445418971506032} | train loss {'Reaction outcome loss': 0.8199887590542916, 'Total loss': 0.8199887590542916}
2022-11-23 01:28:02,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:02,879 INFO:     Epoch: 47
2022-11-23 01:28:03,720 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8639971803535115, 'Total loss': 0.8639971803535115} | train loss {'Reaction outcome loss': 0.8201854865877859, 'Total loss': 0.8201854865877859}
2022-11-23 01:28:03,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:03,721 INFO:     Epoch: 48
2022-11-23 01:28:04,579 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8466185040094636, 'Total loss': 0.8466185040094636} | train loss {'Reaction outcome loss': 0.8218961124939304, 'Total loss': 0.8218961124939304}
2022-11-23 01:28:04,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:04,579 INFO:     Epoch: 49
2022-11-23 01:28:05,452 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8455034778876738, 'Total loss': 0.8455034778876738} | train loss {'Reaction outcome loss': 0.820417108194482, 'Total loss': 0.820417108194482}
2022-11-23 01:28:05,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:05,452 INFO:     Epoch: 50
2022-11-23 01:28:06,271 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8526688130064444, 'Total loss': 0.8526688130064444} | train loss {'Reaction outcome loss': 0.8221606522077515, 'Total loss': 0.8221606522077515}
2022-11-23 01:28:06,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:06,271 INFO:     Epoch: 51
2022-11-23 01:28:07,108 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8470281572504477, 'Total loss': 0.8470281572504477} | train loss {'Reaction outcome loss': 0.8237844233310991, 'Total loss': 0.8237844233310991}
2022-11-23 01:28:07,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:07,109 INFO:     Epoch: 52
2022-11-23 01:28:07,990 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8422668941996314, 'Total loss': 0.8422668941996314} | train loss {'Reaction outcome loss': 0.8223792337361844, 'Total loss': 0.8223792337361844}
2022-11-23 01:28:07,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:07,991 INFO:     Epoch: 53
2022-11-23 01:28:08,843 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8434634655714035, 'Total loss': 0.8434634655714035} | train loss {'Reaction outcome loss': 0.8263153075691192, 'Total loss': 0.8263153075691192}
2022-11-23 01:28:08,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:08,845 INFO:     Epoch: 54
2022-11-23 01:28:09,706 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8542431477795948, 'Total loss': 0.8542431477795948} | train loss {'Reaction outcome loss': 0.8258928138642542, 'Total loss': 0.8258928138642542}
2022-11-23 01:28:09,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:09,706 INFO:     Epoch: 55
2022-11-23 01:28:10,548 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8666783787987449, 'Total loss': 0.8666783787987449} | train loss {'Reaction outcome loss': 0.8242307003707655, 'Total loss': 0.8242307003707655}
2022-11-23 01:28:10,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:10,549 INFO:     Epoch: 56
2022-11-23 01:28:11,393 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8473587740551342, 'Total loss': 0.8473587740551342} | train loss {'Reaction outcome loss': 0.8187409596097085, 'Total loss': 0.8187409596097085}
2022-11-23 01:28:11,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:11,393 INFO:     Epoch: 57
2022-11-23 01:28:12,196 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8453907844695178, 'Total loss': 0.8453907844695178} | train loss {'Reaction outcome loss': 0.8228250618182844, 'Total loss': 0.8228250618182844}
2022-11-23 01:28:12,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:12,196 INFO:     Epoch: 58
2022-11-23 01:28:13,053 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8405329646034674, 'Total loss': 0.8405329646034674} | train loss {'Reaction outcome loss': 0.8267213744261572, 'Total loss': 0.8267213744261572}
2022-11-23 01:28:13,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:13,053 INFO:     Epoch: 59
2022-11-23 01:28:13,897 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8463878021998839, 'Total loss': 0.8463878021998839} | train loss {'Reaction outcome loss': 0.8213496003900805, 'Total loss': 0.8213496003900805}
2022-11-23 01:28:13,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:13,897 INFO:     Epoch: 60
2022-11-23 01:28:14,761 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8493578664281152, 'Total loss': 0.8493578664281152} | train loss {'Reaction outcome loss': 0.8220650440742893, 'Total loss': 0.8220650440742893}
2022-11-23 01:28:14,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:14,762 INFO:     Epoch: 61
2022-11-23 01:28:15,579 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8590413684194739, 'Total loss': 0.8590413684194739} | train loss {'Reaction outcome loss': 0.8263407040747904, 'Total loss': 0.8263407040747904}
2022-11-23 01:28:15,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:15,580 INFO:     Epoch: 62
2022-11-23 01:28:16,380 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8366242904554714, 'Total loss': 0.8366242904554714} | train loss {'Reaction outcome loss': 0.8249151700687024, 'Total loss': 0.8249151700687024}
2022-11-23 01:28:16,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:16,380 INFO:     Epoch: 63
2022-11-23 01:28:17,172 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8303179761225526, 'Total loss': 0.8303179761225526} | train loss {'Reaction outcome loss': 0.8232608721140893, 'Total loss': 0.8232608721140893}
2022-11-23 01:28:17,172 INFO:     Found new best model at epoch 63
2022-11-23 01:28:17,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:17,173 INFO:     Epoch: 64
2022-11-23 01:28:17,944 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8594683876091783, 'Total loss': 0.8594683876091783} | train loss {'Reaction outcome loss': 0.8204635610022852, 'Total loss': 0.8204635610022852}
2022-11-23 01:28:17,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:17,944 INFO:     Epoch: 65
2022-11-23 01:28:18,712 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8379065225070174, 'Total loss': 0.8379065225070174} | train loss {'Reaction outcome loss': 0.8192822172516777, 'Total loss': 0.8192822172516777}
2022-11-23 01:28:18,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:18,713 INFO:     Epoch: 66
2022-11-23 01:28:19,496 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8248061300678686, 'Total loss': 0.8248061300678686} | train loss {'Reaction outcome loss': 0.819991898512648, 'Total loss': 0.819991898512648}
2022-11-23 01:28:19,496 INFO:     Found new best model at epoch 66
2022-11-23 01:28:19,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:19,497 INFO:     Epoch: 67
2022-11-23 01:28:20,253 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8456714403900233, 'Total loss': 0.8456714403900233} | train loss {'Reaction outcome loss': 0.8215455297500857, 'Total loss': 0.8215455297500857}
2022-11-23 01:28:20,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:20,253 INFO:     Epoch: 68
2022-11-23 01:28:21,030 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8589447486129674, 'Total loss': 0.8589447486129674} | train loss {'Reaction outcome loss': 0.8207288505809922, 'Total loss': 0.8207288505809922}
2022-11-23 01:28:21,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:21,031 INFO:     Epoch: 69
2022-11-23 01:28:21,799 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8309539299119603, 'Total loss': 0.8309539299119603} | train loss {'Reaction outcome loss': 0.8210027923266734, 'Total loss': 0.8210027923266734}
2022-11-23 01:28:21,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:21,800 INFO:     Epoch: 70
2022-11-23 01:28:22,581 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8748284063555978, 'Total loss': 0.8748284063555978} | train loss {'Reaction outcome loss': 0.823470527125943, 'Total loss': 0.823470527125943}
2022-11-23 01:28:22,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:22,581 INFO:     Epoch: 71
2022-11-23 01:28:23,355 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8454330400987105, 'Total loss': 0.8454330400987105} | train loss {'Reaction outcome loss': 0.8231338421183247, 'Total loss': 0.8231338421183247}
2022-11-23 01:28:23,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:23,355 INFO:     Epoch: 72
2022-11-23 01:28:24,135 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8447557254271074, 'Total loss': 0.8447557254271074} | train loss {'Reaction outcome loss': 0.8251756179717279, 'Total loss': 0.8251756179717279}
2022-11-23 01:28:24,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:24,135 INFO:     Epoch: 73
2022-11-23 01:28:24,928 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8505730838938192, 'Total loss': 0.8505730838938192} | train loss {'Reaction outcome loss': 0.822291906802885, 'Total loss': 0.822291906802885}
2022-11-23 01:28:24,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:24,928 INFO:     Epoch: 74
2022-11-23 01:28:25,736 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8481267162344672, 'Total loss': 0.8481267162344672} | train loss {'Reaction outcome loss': 0.819720683799636, 'Total loss': 0.819720683799636}
2022-11-23 01:28:25,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:25,736 INFO:     Epoch: 75
2022-11-23 01:28:26,568 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8384027555584908, 'Total loss': 0.8384027555584908} | train loss {'Reaction outcome loss': 0.8174806808031374, 'Total loss': 0.8174806808031374}
2022-11-23 01:28:26,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:26,568 INFO:     Epoch: 76
2022-11-23 01:28:27,361 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8451553793116049, 'Total loss': 0.8451553793116049} | train loss {'Reaction outcome loss': 0.8228526681421264, 'Total loss': 0.8228526681421264}
2022-11-23 01:28:27,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:27,361 INFO:     Epoch: 77
2022-11-23 01:28:28,129 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8421925048936497, 'Total loss': 0.8421925048936497} | train loss {'Reaction outcome loss': 0.8226796814030216, 'Total loss': 0.8226796814030216}
2022-11-23 01:28:28,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:28,130 INFO:     Epoch: 78
2022-11-23 01:28:28,933 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8544998954642903, 'Total loss': 0.8544998954642903} | train loss {'Reaction outcome loss': 0.8263215408209832, 'Total loss': 0.8263215408209832}
2022-11-23 01:28:28,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:28,933 INFO:     Epoch: 79
2022-11-23 01:28:29,733 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8335565585981716, 'Total loss': 0.8335565585981716} | train loss {'Reaction outcome loss': 0.8246461393371705, 'Total loss': 0.8246461393371705}
2022-11-23 01:28:29,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:29,733 INFO:     Epoch: 80
2022-11-23 01:28:30,496 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8408360081640157, 'Total loss': 0.8408360081640157} | train loss {'Reaction outcome loss': 0.8205054528530566, 'Total loss': 0.8205054528530566}
2022-11-23 01:28:30,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:30,496 INFO:     Epoch: 81
2022-11-23 01:28:31,261 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8479053899645805, 'Total loss': 0.8479053899645805} | train loss {'Reaction outcome loss': 0.8197619685482594, 'Total loss': 0.8197619685482594}
2022-11-23 01:28:31,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:31,261 INFO:     Epoch: 82
2022-11-23 01:28:32,053 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8347775191068649, 'Total loss': 0.8347775191068649} | train loss {'Reaction outcome loss': 0.8201914915154057, 'Total loss': 0.8201914915154057}
2022-11-23 01:28:32,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:32,053 INFO:     Epoch: 83
2022-11-23 01:28:32,867 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8420721367001534, 'Total loss': 0.8420721367001534} | train loss {'Reaction outcome loss': 0.8204391766940394, 'Total loss': 0.8204391766940394}
2022-11-23 01:28:32,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:32,868 INFO:     Epoch: 84
2022-11-23 01:28:33,657 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8514998826113614, 'Total loss': 0.8514998826113614} | train loss {'Reaction outcome loss': 0.820001573452065, 'Total loss': 0.820001573452065}
2022-11-23 01:28:33,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:33,657 INFO:     Epoch: 85
2022-11-23 01:28:34,451 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8631422587416389, 'Total loss': 0.8631422587416389} | train loss {'Reaction outcome loss': 0.8210314779031661, 'Total loss': 0.8210314779031661}
2022-11-23 01:28:34,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:34,452 INFO:     Epoch: 86
2022-11-23 01:28:35,277 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.842750068415295, 'Total loss': 0.842750068415295} | train loss {'Reaction outcome loss': 0.8219234624336804, 'Total loss': 0.8219234624336804}
2022-11-23 01:28:35,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:35,277 INFO:     Epoch: 87
2022-11-23 01:28:36,147 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8446765345605937, 'Total loss': 0.8446765345605937} | train loss {'Reaction outcome loss': 0.8271079392683122, 'Total loss': 0.8271079392683122}
2022-11-23 01:28:36,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:36,147 INFO:     Epoch: 88
2022-11-23 01:28:37,021 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8357241106304255, 'Total loss': 0.8357241106304255} | train loss {'Reaction outcome loss': 0.8206805751448677, 'Total loss': 0.8206805751448677}
2022-11-23 01:28:37,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:37,021 INFO:     Epoch: 89
2022-11-23 01:28:37,836 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.855081554163586, 'Total loss': 0.855081554163586} | train loss {'Reaction outcome loss': 0.8194228785653268, 'Total loss': 0.8194228785653268}
2022-11-23 01:28:37,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:37,836 INFO:     Epoch: 90
2022-11-23 01:28:38,664 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8379472981799733, 'Total loss': 0.8379472981799733} | train loss {'Reaction outcome loss': 0.8217409077671266, 'Total loss': 0.8217409077671266}
2022-11-23 01:28:38,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:38,664 INFO:     Epoch: 91
2022-11-23 01:28:39,468 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8495419506322254, 'Total loss': 0.8495419506322254} | train loss {'Reaction outcome loss': 0.8237581080006015, 'Total loss': 0.8237581080006015}
2022-11-23 01:28:39,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:39,469 INFO:     Epoch: 92
2022-11-23 01:28:40,289 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8474781289696693, 'Total loss': 0.8474781289696693} | train loss {'Reaction outcome loss': 0.8201367000658666, 'Total loss': 0.8201367000658666}
2022-11-23 01:28:40,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:40,290 INFO:     Epoch: 93
2022-11-23 01:28:41,096 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8367877981879495, 'Total loss': 0.8367877981879495} | train loss {'Reaction outcome loss': 0.821545694984736, 'Total loss': 0.821545694984736}
2022-11-23 01:28:41,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:41,096 INFO:     Epoch: 94
2022-11-23 01:28:41,929 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8320077793164686, 'Total loss': 0.8320077793164686} | train loss {'Reaction outcome loss': 0.821456708134182, 'Total loss': 0.821456708134182}
2022-11-23 01:28:41,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:41,929 INFO:     Epoch: 95
2022-11-23 01:28:42,706 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8539698056199334, 'Total loss': 0.8539698056199334} | train loss {'Reaction outcome loss': 0.8202406198627525, 'Total loss': 0.8202406198627525}
2022-11-23 01:28:42,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:42,706 INFO:     Epoch: 96
2022-11-23 01:28:43,544 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8561161302707412, 'Total loss': 0.8561161302707412} | train loss {'Reaction outcome loss': 0.822874678118575, 'Total loss': 0.822874678118575}
2022-11-23 01:28:43,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:43,544 INFO:     Epoch: 97
2022-11-23 01:28:44,376 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.855783262713389, 'Total loss': 0.855783262713389} | train loss {'Reaction outcome loss': 0.8197661492853395, 'Total loss': 0.8197661492853395}
2022-11-23 01:28:44,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:44,376 INFO:     Epoch: 98
2022-11-23 01:28:45,175 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8394032486460425, 'Total loss': 0.8394032486460425} | train loss {'Reaction outcome loss': 0.8196495594757218, 'Total loss': 0.8196495594757218}
2022-11-23 01:28:45,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:45,175 INFO:     Epoch: 99
2022-11-23 01:28:45,991 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8460090532898903, 'Total loss': 0.8460090532898903} | train loss {'Reaction outcome loss': 0.8176750419360976, 'Total loss': 0.8176750419360976}
2022-11-23 01:28:45,992 INFO:     Best model found after epoch 67 of 100.
2022-11-23 01:28:45,992 INFO:   Done with stage: TRAINING
2022-11-23 01:28:45,992 INFO:   Starting stage: EVALUATION
2022-11-23 01:28:46,111 INFO:   Done with stage: EVALUATION
2022-11-23 01:28:46,119 INFO:   Leaving out SEQ value Fold_0
2022-11-23 01:28:46,133 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 01:28:46,133 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:28:46,801 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:28:46,801 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:28:46,877 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:28:46,877 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:28:46,877 INFO:     No hyperparam tuning for this model
2022-11-23 01:28:46,877 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:28:46,877 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:28:46,878 INFO:     None feature selector for col prot
2022-11-23 01:28:46,878 INFO:     None feature selector for col prot
2022-11-23 01:28:46,878 INFO:     None feature selector for col prot
2022-11-23 01:28:46,879 INFO:     None feature selector for col chem
2022-11-23 01:28:46,879 INFO:     None feature selector for col chem
2022-11-23 01:28:46,879 INFO:     None feature selector for col chem
2022-11-23 01:28:46,879 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:28:46,879 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:28:46,881 INFO:     Number of params in model 168571
2022-11-23 01:28:46,884 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:28:46,884 INFO:   Starting stage: TRAINING
2022-11-23 01:28:46,942 INFO:     Val loss before train {'Reaction outcome loss': 0.9809600873426958, 'Total loss': 0.9809600873426958}
2022-11-23 01:28:46,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:46,942 INFO:     Epoch: 0
2022-11-23 01:28:47,722 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7989019731229002, 'Total loss': 0.7989019731229002} | train loss {'Reaction outcome loss': 0.8847123966043294, 'Total loss': 0.8847123966043294}
2022-11-23 01:28:47,722 INFO:     Found new best model at epoch 0
2022-11-23 01:28:47,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:47,723 INFO:     Epoch: 1
2022-11-23 01:28:48,544 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8073949244889346, 'Total loss': 0.8073949244889346} | train loss {'Reaction outcome loss': 0.8732990435501824, 'Total loss': 0.8732990435501824}
2022-11-23 01:28:48,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:48,544 INFO:     Epoch: 2
2022-11-23 01:28:49,346 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8287491195581176, 'Total loss': 0.8287491195581176} | train loss {'Reaction outcome loss': 0.8534671167432055, 'Total loss': 0.8534671167432055}
2022-11-23 01:28:49,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:49,346 INFO:     Epoch: 3
2022-11-23 01:28:50,106 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7932550168850205, 'Total loss': 0.7932550168850205} | train loss {'Reaction outcome loss': 0.8510934370249389, 'Total loss': 0.8510934370249389}
2022-11-23 01:28:50,106 INFO:     Found new best model at epoch 3
2022-11-23 01:28:50,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:50,107 INFO:     Epoch: 4
2022-11-23 01:28:50,912 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8002150268717245, 'Total loss': 0.8002150268717245} | train loss {'Reaction outcome loss': 0.8472606510768536, 'Total loss': 0.8472606510768536}
2022-11-23 01:28:50,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:50,912 INFO:     Epoch: 5
2022-11-23 01:28:51,687 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7864793064919385, 'Total loss': 0.7864793064919385} | train loss {'Reaction outcome loss': 0.8364441516669655, 'Total loss': 0.8364441516669655}
2022-11-23 01:28:51,688 INFO:     Found new best model at epoch 5
2022-11-23 01:28:51,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:51,689 INFO:     Epoch: 6
2022-11-23 01:28:52,493 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8367078412662853, 'Total loss': 0.8367078412662853} | train loss {'Reaction outcome loss': 0.8298743520429742, 'Total loss': 0.8298743520429742}
2022-11-23 01:28:52,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:52,493 INFO:     Epoch: 7
2022-11-23 01:28:53,301 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7753216502341357, 'Total loss': 0.7753216502341357} | train loss {'Reaction outcome loss': 0.8335974653089336, 'Total loss': 0.8335974653089336}
2022-11-23 01:28:53,301 INFO:     Found new best model at epoch 7
2022-11-23 01:28:53,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:53,302 INFO:     Epoch: 8
2022-11-23 01:28:54,104 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8132434216412631, 'Total loss': 0.8132434216412631} | train loss {'Reaction outcome loss': 0.8289640685807356, 'Total loss': 0.8289640685807356}
2022-11-23 01:28:54,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:54,104 INFO:     Epoch: 9
2022-11-23 01:28:54,902 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7752263681455092, 'Total loss': 0.7752263681455092} | train loss {'Reaction outcome loss': 0.8333445658326631, 'Total loss': 0.8333445658326631}
2022-11-23 01:28:54,902 INFO:     Found new best model at epoch 9
2022-11-23 01:28:54,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:54,903 INFO:     Epoch: 10
2022-11-23 01:28:55,756 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7769605070352554, 'Total loss': 0.7769605070352554} | train loss {'Reaction outcome loss': 0.8309961953143842, 'Total loss': 0.8309961953143842}
2022-11-23 01:28:55,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:55,757 INFO:     Epoch: 11
2022-11-23 01:28:56,554 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7868111011656848, 'Total loss': 0.7868111011656848} | train loss {'Reaction outcome loss': 0.8265344796151768, 'Total loss': 0.8265344796151768}
2022-11-23 01:28:56,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:56,554 INFO:     Epoch: 12
2022-11-23 01:28:57,377 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7965991828929294, 'Total loss': 0.7965991828929294} | train loss {'Reaction outcome loss': 0.8344902017338556, 'Total loss': 0.8344902017338556}
2022-11-23 01:28:57,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:57,377 INFO:     Epoch: 13
2022-11-23 01:28:58,206 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7758284319530834, 'Total loss': 0.7758284319530834} | train loss {'Reaction outcome loss': 0.8338013837935954, 'Total loss': 0.8338013837935954}
2022-11-23 01:28:58,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:58,207 INFO:     Epoch: 14
2022-11-23 01:28:59,043 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7849562696435235, 'Total loss': 0.7849562696435235} | train loss {'Reaction outcome loss': 0.8266059336392021, 'Total loss': 0.8266059336392021}
2022-11-23 01:28:59,043 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:59,043 INFO:     Epoch: 15
2022-11-23 01:28:59,836 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.827579140663147, 'Total loss': 0.827579140663147} | train loss {'Reaction outcome loss': 0.8203534561356431, 'Total loss': 0.8203534561356431}
2022-11-23 01:28:59,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:28:59,836 INFO:     Epoch: 16
2022-11-23 01:29:00,657 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7778661034323953, 'Total loss': 0.7778661034323953} | train loss {'Reaction outcome loss': 0.8235783776275905, 'Total loss': 0.8235783776275905}
2022-11-23 01:29:00,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:00,657 INFO:     Epoch: 17
2022-11-23 01:29:01,477 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7854573184793646, 'Total loss': 0.7854573184793646} | train loss {'Reaction outcome loss': 0.8234059591042368, 'Total loss': 0.8234059591042368}
2022-11-23 01:29:01,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:01,477 INFO:     Epoch: 18
2022-11-23 01:29:02,293 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7799839743159034, 'Total loss': 0.7799839743159034} | train loss {'Reaction outcome loss': 0.8238072576913756, 'Total loss': 0.8238072576913756}
2022-11-23 01:29:02,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:02,293 INFO:     Epoch: 19
2022-11-23 01:29:03,080 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8028439886190675, 'Total loss': 0.8028439886190675} | train loss {'Reaction outcome loss': 0.8244570471979829, 'Total loss': 0.8244570471979829}
2022-11-23 01:29:03,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:03,081 INFO:     Epoch: 20
2022-11-23 01:29:03,836 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7854298021305691, 'Total loss': 0.7854298021305691} | train loss {'Reaction outcome loss': 0.8232615815422796, 'Total loss': 0.8232615815422796}
2022-11-23 01:29:03,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:03,837 INFO:     Epoch: 21
2022-11-23 01:29:04,649 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8057214739647779, 'Total loss': 0.8057214739647779} | train loss {'Reaction outcome loss': 0.8222479325557045, 'Total loss': 0.8222479325557045}
2022-11-23 01:29:04,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:04,649 INFO:     Epoch: 22
2022-11-23 01:29:05,480 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7920301962982524, 'Total loss': 0.7920301962982524} | train loss {'Reaction outcome loss': 0.8289058617493401, 'Total loss': 0.8289058617493401}
2022-11-23 01:29:05,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:05,480 INFO:     Epoch: 23
2022-11-23 01:29:06,291 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.762907803397287, 'Total loss': 0.762907803397287} | train loss {'Reaction outcome loss': 0.8280425180911053, 'Total loss': 0.8280425180911053}
2022-11-23 01:29:06,291 INFO:     Found new best model at epoch 23
2022-11-23 01:29:06,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:06,292 INFO:     Epoch: 24
2022-11-23 01:29:07,131 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7750261541117321, 'Total loss': 0.7750261541117321} | train loss {'Reaction outcome loss': 0.8188093794502227, 'Total loss': 0.8188093794502227}
2022-11-23 01:29:07,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:07,132 INFO:     Epoch: 25
2022-11-23 01:29:07,900 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7807330218228427, 'Total loss': 0.7807330218228427} | train loss {'Reaction outcome loss': 0.8193735229794071, 'Total loss': 0.8193735229794071}
2022-11-23 01:29:07,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:07,901 INFO:     Epoch: 26
2022-11-23 01:29:08,723 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7706064947626807, 'Total loss': 0.7706064947626807} | train loss {'Reaction outcome loss': 0.8208897452846713, 'Total loss': 0.8208897452846713}
2022-11-23 01:29:08,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:08,724 INFO:     Epoch: 27
2022-11-23 01:29:09,538 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.77302570911971, 'Total loss': 0.77302570911971} | train loss {'Reaction outcome loss': 0.8290265934308049, 'Total loss': 0.8290265934308049}
2022-11-23 01:29:09,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:09,538 INFO:     Epoch: 28
2022-11-23 01:29:10,349 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7993504201824014, 'Total loss': 0.7993504201824014} | train loss {'Reaction outcome loss': 0.8264719764230705, 'Total loss': 0.8264719764230705}
2022-11-23 01:29:10,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:10,350 INFO:     Epoch: 29
2022-11-23 01:29:11,200 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7871516604315151, 'Total loss': 0.7871516604315151} | train loss {'Reaction outcome loss': 0.8263940852180667, 'Total loss': 0.8263940852180667}
2022-11-23 01:29:11,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:11,200 INFO:     Epoch: 30
2022-11-23 01:29:12,012 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8003546527840875, 'Total loss': 0.8003546527840875} | train loss {'Reaction outcome loss': 0.8225598743087367, 'Total loss': 0.8225598743087367}
2022-11-23 01:29:12,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:12,012 INFO:     Epoch: 31
2022-11-23 01:29:12,808 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7954678494821895, 'Total loss': 0.7954678494821895} | train loss {'Reaction outcome loss': 0.8209953904151917, 'Total loss': 0.8209953904151917}
2022-11-23 01:29:12,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:12,808 INFO:     Epoch: 32
2022-11-23 01:29:13,615 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7720336975021795, 'Total loss': 0.7720336975021795} | train loss {'Reaction outcome loss': 0.8316517935590706, 'Total loss': 0.8316517935590706}
2022-11-23 01:29:13,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:13,616 INFO:     Epoch: 33
2022-11-23 01:29:14,401 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7757210697640072, 'Total loss': 0.7757210697640072} | train loss {'Reaction outcome loss': 0.8198466045472786, 'Total loss': 0.8198466045472786}
2022-11-23 01:29:14,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:14,402 INFO:     Epoch: 34
2022-11-23 01:29:15,213 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7860446084629406, 'Total loss': 0.7860446084629406} | train loss {'Reaction outcome loss': 0.8242759744406711, 'Total loss': 0.8242759744406711}
2022-11-23 01:29:15,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:15,214 INFO:     Epoch: 35
2022-11-23 01:29:16,038 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7820832553234968, 'Total loss': 0.7820832553234968} | train loss {'Reaction outcome loss': 0.8229541468475512, 'Total loss': 0.8229541468475512}
2022-11-23 01:29:16,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:16,038 INFO:     Epoch: 36
2022-11-23 01:29:16,848 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7787510779770938, 'Total loss': 0.7787510779770938} | train loss {'Reaction outcome loss': 0.8276924889097329, 'Total loss': 0.8276924889097329}
2022-11-23 01:29:16,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:16,849 INFO:     Epoch: 37
2022-11-23 01:29:17,640 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7922303784977306, 'Total loss': 0.7922303784977306} | train loss {'Reaction outcome loss': 0.8233909066389447, 'Total loss': 0.8233909066389447}
2022-11-23 01:29:17,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:17,640 INFO:     Epoch: 38
2022-11-23 01:29:18,465 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7895652502775192, 'Total loss': 0.7895652502775192} | train loss {'Reaction outcome loss': 0.8258138732147603, 'Total loss': 0.8258138732147603}
2022-11-23 01:29:18,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:18,466 INFO:     Epoch: 39
2022-11-23 01:29:19,305 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7794308933344755, 'Total loss': 0.7794308933344755} | train loss {'Reaction outcome loss': 0.8282002412114549, 'Total loss': 0.8282002412114549}
2022-11-23 01:29:19,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:19,305 INFO:     Epoch: 40
2022-11-23 01:29:20,078 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7887191867286508, 'Total loss': 0.7887191867286508} | train loss {'Reaction outcome loss': 0.8253577028208898, 'Total loss': 0.8253577028208898}
2022-11-23 01:29:20,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:20,078 INFO:     Epoch: 41
2022-11-23 01:29:20,944 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7732861231673848, 'Total loss': 0.7732861231673848} | train loss {'Reaction outcome loss': 0.8191266872803209, 'Total loss': 0.8191266872803209}
2022-11-23 01:29:20,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:20,944 INFO:     Epoch: 42
2022-11-23 01:29:21,747 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8009376485239376, 'Total loss': 0.8009376485239376} | train loss {'Reaction outcome loss': 0.819771685309497, 'Total loss': 0.819771685309497}
2022-11-23 01:29:21,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:21,747 INFO:     Epoch: 43
2022-11-23 01:29:22,537 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7742748423056169, 'Total loss': 0.7742748423056169} | train loss {'Reaction outcome loss': 0.8267015697743728, 'Total loss': 0.8267015697743728}
2022-11-23 01:29:22,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:22,537 INFO:     Epoch: 44
2022-11-23 01:29:23,336 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7911603159525178, 'Total loss': 0.7911603159525178} | train loss {'Reaction outcome loss': 0.8262300659046482, 'Total loss': 0.8262300659046482}
2022-11-23 01:29:23,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:23,336 INFO:     Epoch: 45
2022-11-23 01:29:24,135 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7953433827920393, 'Total loss': 0.7953433827920393} | train loss {'Reaction outcome loss': 0.8181034789122792, 'Total loss': 0.8181034789122792}
2022-11-23 01:29:24,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:24,135 INFO:     Epoch: 46
2022-11-23 01:29:24,944 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7914745685729113, 'Total loss': 0.7914745685729113} | train loss {'Reaction outcome loss': 0.8235165253583236, 'Total loss': 0.8235165253583236}
2022-11-23 01:29:24,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:24,944 INFO:     Epoch: 47
2022-11-23 01:29:25,740 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7770719101483171, 'Total loss': 0.7770719101483171} | train loss {'Reaction outcome loss': 0.817367074581293, 'Total loss': 0.817367074581293}
2022-11-23 01:29:25,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:25,740 INFO:     Epoch: 48
2022-11-23 01:29:26,567 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.786856660111384, 'Total loss': 0.786856660111384} | train loss {'Reaction outcome loss': 0.8248667745937702, 'Total loss': 0.8248667745937702}
2022-11-23 01:29:26,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:26,567 INFO:     Epoch: 49
2022-11-23 01:29:27,373 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7618961486626755, 'Total loss': 0.7618961486626755} | train loss {'Reaction outcome loss': 0.8188802306709985, 'Total loss': 0.8188802306709985}
2022-11-23 01:29:27,373 INFO:     Found new best model at epoch 49
2022-11-23 01:29:27,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:27,374 INFO:     Epoch: 50
2022-11-23 01:29:28,208 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7770745970986106, 'Total loss': 0.7770745970986106} | train loss {'Reaction outcome loss': 0.8220363455986687, 'Total loss': 0.8220363455986687}
2022-11-23 01:29:28,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:28,208 INFO:     Epoch: 51
2022-11-23 01:29:29,026 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7909999516877261, 'Total loss': 0.7909999516877261} | train loss {'Reaction outcome loss': 0.8219659970356867, 'Total loss': 0.8219659970356867}
2022-11-23 01:29:29,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:29,027 INFO:     Epoch: 52
2022-11-23 01:29:29,867 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7927673465826295, 'Total loss': 0.7927673465826295} | train loss {'Reaction outcome loss': 0.8291885995189188, 'Total loss': 0.8291885995189188}
2022-11-23 01:29:29,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:29,868 INFO:     Epoch: 53
2022-11-23 01:29:30,698 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7732251354239204, 'Total loss': 0.7732251354239204} | train loss {'Reaction outcome loss': 0.8243881632924562, 'Total loss': 0.8243881632924562}
2022-11-23 01:29:30,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:30,699 INFO:     Epoch: 54
2022-11-23 01:29:31,467 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7744368287650022, 'Total loss': 0.7744368287650022} | train loss {'Reaction outcome loss': 0.8153406283874743, 'Total loss': 0.8153406283874743}
2022-11-23 01:29:31,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:31,467 INFO:     Epoch: 55
2022-11-23 01:29:32,268 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.782325957309116, 'Total loss': 0.782325957309116} | train loss {'Reaction outcome loss': 0.8181142140979226, 'Total loss': 0.8181142140979226}
2022-11-23 01:29:32,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:32,269 INFO:     Epoch: 56
2022-11-23 01:29:33,095 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.823884558271278, 'Total loss': 0.823884558271278} | train loss {'Reaction outcome loss': 0.8258210713805457, 'Total loss': 0.8258210713805457}
2022-11-23 01:29:33,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:33,096 INFO:     Epoch: 57
2022-11-23 01:29:33,939 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7771337777376175, 'Total loss': 0.7771337777376175} | train loss {'Reaction outcome loss': 0.8242647010787778, 'Total loss': 0.8242647010787778}
2022-11-23 01:29:33,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:33,939 INFO:     Epoch: 58
2022-11-23 01:29:34,733 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8099254715171728, 'Total loss': 0.8099254715171728} | train loss {'Reaction outcome loss': 0.8285205492123902, 'Total loss': 0.8285205492123902}
2022-11-23 01:29:34,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:34,733 INFO:     Epoch: 59
2022-11-23 01:29:35,536 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7996576949954033, 'Total loss': 0.7996576949954033} | train loss {'Reaction outcome loss': 0.8215547905035829, 'Total loss': 0.8215547905035829}
2022-11-23 01:29:35,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:35,536 INFO:     Epoch: 60
2022-11-23 01:29:36,331 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7765448852018877, 'Total loss': 0.7765448852018877} | train loss {'Reaction outcome loss': 0.8209025501480952, 'Total loss': 0.8209025501480952}
2022-11-23 01:29:36,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:36,331 INFO:     Epoch: 61
2022-11-23 01:29:37,119 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7882170948115262, 'Total loss': 0.7882170948115262} | train loss {'Reaction outcome loss': 0.8213363916043811, 'Total loss': 0.8213363916043811}
2022-11-23 01:29:37,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:37,120 INFO:     Epoch: 62
2022-11-23 01:29:37,940 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7888838658955964, 'Total loss': 0.7888838658955964} | train loss {'Reaction outcome loss': 0.8222530851600623, 'Total loss': 0.8222530851600623}
2022-11-23 01:29:37,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:37,940 INFO:     Epoch: 63
2022-11-23 01:29:38,742 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7778860520232808, 'Total loss': 0.7778860520232808} | train loss {'Reaction outcome loss': 0.8154229448753813, 'Total loss': 0.8154229448753813}
2022-11-23 01:29:38,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:38,742 INFO:     Epoch: 64
2022-11-23 01:29:39,540 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7690478644587777, 'Total loss': 0.7690478644587777} | train loss {'Reaction outcome loss': 0.8238472932504739, 'Total loss': 0.8238472932504739}
2022-11-23 01:29:39,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:39,541 INFO:     Epoch: 65
2022-11-23 01:29:40,302 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7769806852394884, 'Total loss': 0.7769806852394884} | train loss {'Reaction outcome loss': 0.8221062277010095, 'Total loss': 0.8221062277010095}
2022-11-23 01:29:40,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:40,303 INFO:     Epoch: 66
2022-11-23 01:29:41,097 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7682472135532986, 'Total loss': 0.7682472135532986} | train loss {'Reaction outcome loss': 0.8216353447934394, 'Total loss': 0.8216353447934394}
2022-11-23 01:29:41,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:41,098 INFO:     Epoch: 67
2022-11-23 01:29:41,899 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8074934076179158, 'Total loss': 0.8074934076179158} | train loss {'Reaction outcome loss': 0.8249789863704187, 'Total loss': 0.8249789863704187}
2022-11-23 01:29:41,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:41,899 INFO:     Epoch: 68
2022-11-23 01:29:42,681 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7715195952491327, 'Total loss': 0.7715195952491327} | train loss {'Reaction outcome loss': 0.8245451714587115, 'Total loss': 0.8245451714587115}
2022-11-23 01:29:42,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:42,682 INFO:     Epoch: 69
2022-11-23 01:29:43,459 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.772219836034558, 'Total loss': 0.772219836034558} | train loss {'Reaction outcome loss': 0.8176542802860862, 'Total loss': 0.8176542802860862}
2022-11-23 01:29:43,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:43,460 INFO:     Epoch: 70
2022-11-23 01:29:44,255 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7876333492723379, 'Total loss': 0.7876333492723379} | train loss {'Reaction outcome loss': 0.8147345424482697, 'Total loss': 0.8147345424482697}
2022-11-23 01:29:44,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:44,255 INFO:     Epoch: 71
2022-11-23 01:29:45,071 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8085394251075658, 'Total loss': 0.8085394251075658} | train loss {'Reaction outcome loss': 0.827053879678008, 'Total loss': 0.827053879678008}
2022-11-23 01:29:45,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:45,071 INFO:     Epoch: 72
2022-11-23 01:29:45,907 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7889310724355958, 'Total loss': 0.7889310724355958} | train loss {'Reaction outcome loss': 0.8288911037478852, 'Total loss': 0.8288911037478852}
2022-11-23 01:29:45,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:45,907 INFO:     Epoch: 73
2022-11-23 01:29:46,713 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7694917781786486, 'Total loss': 0.7694917781786486} | train loss {'Reaction outcome loss': 0.8139967779640244, 'Total loss': 0.8139967779640244}
2022-11-23 01:29:46,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:46,713 INFO:     Epoch: 74
2022-11-23 01:29:47,513 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7694906043735418, 'Total loss': 0.7694906043735418} | train loss {'Reaction outcome loss': 0.8216283252606025, 'Total loss': 0.8216283252606025}
2022-11-23 01:29:47,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:47,514 INFO:     Epoch: 75
2022-11-23 01:29:48,325 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7849735847928307, 'Total loss': 0.7849735847928307} | train loss {'Reaction outcome loss': 0.819922214456898, 'Total loss': 0.819922214456898}
2022-11-23 01:29:48,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:48,325 INFO:     Epoch: 76
2022-11-23 01:29:49,127 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7670440030368891, 'Total loss': 0.7670440030368891} | train loss {'Reaction outcome loss': 0.8308451803107011, 'Total loss': 0.8308451803107011}
2022-11-23 01:29:49,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:49,127 INFO:     Epoch: 77
2022-11-23 01:29:49,914 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7887092625552957, 'Total loss': 0.7887092625552957} | train loss {'Reaction outcome loss': 0.8235127525064747, 'Total loss': 0.8235127525064747}
2022-11-23 01:29:49,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:49,914 INFO:     Epoch: 78
2022-11-23 01:29:50,719 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7735139842737805, 'Total loss': 0.7735139842737805} | train loss {'Reaction outcome loss': 0.8200725785151184, 'Total loss': 0.8200725785151184}
2022-11-23 01:29:50,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:50,719 INFO:     Epoch: 79
2022-11-23 01:29:51,530 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.796787599270994, 'Total loss': 0.796787599270994} | train loss {'Reaction outcome loss': 0.818095203473983, 'Total loss': 0.818095203473983}
2022-11-23 01:29:51,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:51,531 INFO:     Epoch: 80
2022-11-23 01:29:52,343 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7997831973162565, 'Total loss': 0.7997831973162565} | train loss {'Reaction outcome loss': 0.8220073223596642, 'Total loss': 0.8220073223596642}
2022-11-23 01:29:52,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:52,343 INFO:     Epoch: 81
2022-11-23 01:29:53,169 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7688471444628455, 'Total loss': 0.7688471444628455} | train loss {'Reaction outcome loss': 0.824075642505638, 'Total loss': 0.824075642505638}
2022-11-23 01:29:53,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:53,170 INFO:     Epoch: 82
2022-11-23 01:29:53,969 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.787864011797038, 'Total loss': 0.787864011797038} | train loss {'Reaction outcome loss': 0.8233179880781212, 'Total loss': 0.8233179880781212}
2022-11-23 01:29:53,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:53,969 INFO:     Epoch: 83
2022-11-23 01:29:54,780 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7861380638046698, 'Total loss': 0.7861380638046698} | train loss {'Reaction outcome loss': 0.8179944748820563, 'Total loss': 0.8179944748820563}
2022-11-23 01:29:54,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:54,780 INFO:     Epoch: 84
2022-11-23 01:29:55,575 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7852988365021619, 'Total loss': 0.7852988365021619} | train loss {'Reaction outcome loss': 0.8243955475116066, 'Total loss': 0.8243955475116066}
2022-11-23 01:29:55,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:55,575 INFO:     Epoch: 85
2022-11-23 01:29:56,412 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7861322916366837, 'Total loss': 0.7861322916366837} | train loss {'Reaction outcome loss': 0.824552390980817, 'Total loss': 0.824552390980817}
2022-11-23 01:29:56,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:56,412 INFO:     Epoch: 86
2022-11-23 01:29:57,239 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7918767407536507, 'Total loss': 0.7918767407536507} | train loss {'Reaction outcome loss': 0.8243581424599234, 'Total loss': 0.8243581424599234}
2022-11-23 01:29:57,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:57,239 INFO:     Epoch: 87
2022-11-23 01:29:58,080 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7974453521045771, 'Total loss': 0.7974453521045771} | train loss {'Reaction outcome loss': 0.8256356702883717, 'Total loss': 0.8256356702883717}
2022-11-23 01:29:58,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:58,080 INFO:     Epoch: 88
2022-11-23 01:29:58,879 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7796047119931742, 'Total loss': 0.7796047119931742} | train loss {'Reaction outcome loss': 0.8230991399722544, 'Total loss': 0.8230991399722544}
2022-11-23 01:29:58,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:58,879 INFO:     Epoch: 89
2022-11-23 01:29:59,633 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8072688660838387, 'Total loss': 0.8072688660838387} | train loss {'Reaction outcome loss': 0.832591909628648, 'Total loss': 0.832591909628648}
2022-11-23 01:29:59,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:29:59,634 INFO:     Epoch: 90
2022-11-23 01:30:00,442 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7915043228051879, 'Total loss': 0.7915043228051879} | train loss {'Reaction outcome loss': 0.8297935100460825, 'Total loss': 0.8297935100460825}
2022-11-23 01:30:00,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:00,442 INFO:     Epoch: 91
2022-11-23 01:30:01,220 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7891300510276448, 'Total loss': 0.7891300510276448} | train loss {'Reaction outcome loss': 0.8208856779011154, 'Total loss': 0.8208856779011154}
2022-11-23 01:30:01,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:01,220 INFO:     Epoch: 92
2022-11-23 01:30:02,055 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8036460598761385, 'Total loss': 0.8036460598761385} | train loss {'Reaction outcome loss': 0.8281379795750143, 'Total loss': 0.8281379795750143}
2022-11-23 01:30:02,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:02,056 INFO:     Epoch: 93
2022-11-23 01:30:02,878 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7773244055834684, 'Total loss': 0.7773244055834684} | train loss {'Reaction outcome loss': 0.8210626032791639, 'Total loss': 0.8210626032791639}
2022-11-23 01:30:02,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:02,879 INFO:     Epoch: 94
2022-11-23 01:30:03,692 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.770158289508386, 'Total loss': 0.770158289508386} | train loss {'Reaction outcome loss': 0.8251388822851876, 'Total loss': 0.8251388822851876}
2022-11-23 01:30:03,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:03,692 INFO:     Epoch: 95
2022-11-23 01:30:04,497 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7701598947698419, 'Total loss': 0.7701598947698419} | train loss {'Reaction outcome loss': 0.8256685817048617, 'Total loss': 0.8256685817048617}
2022-11-23 01:30:04,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:04,498 INFO:     Epoch: 96
2022-11-23 01:30:05,345 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7826990139755335, 'Total loss': 0.7826990139755335} | train loss {'Reaction outcome loss': 0.8215224015326635, 'Total loss': 0.8215224015326635}
2022-11-23 01:30:05,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:05,345 INFO:     Epoch: 97
2022-11-23 01:30:06,122 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7923467423428189, 'Total loss': 0.7923467423428189} | train loss {'Reaction outcome loss': 0.8243275226851706, 'Total loss': 0.8243275226851706}
2022-11-23 01:30:06,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:06,122 INFO:     Epoch: 98
2022-11-23 01:30:06,903 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7687941762534055, 'Total loss': 0.7687941762534055} | train loss {'Reaction outcome loss': 0.8211731905879279, 'Total loss': 0.8211731905879279}
2022-11-23 01:30:06,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:06,903 INFO:     Epoch: 99
2022-11-23 01:30:07,672 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7816802696748213, 'Total loss': 0.7816802696748213} | train loss {'Reaction outcome loss': 0.8210333731734318, 'Total loss': 0.8210333731734318}
2022-11-23 01:30:07,672 INFO:     Best model found after epoch 50 of 100.
2022-11-23 01:30:07,672 INFO:   Done with stage: TRAINING
2022-11-23 01:30:07,672 INFO:   Starting stage: EVALUATION
2022-11-23 01:30:07,801 INFO:   Done with stage: EVALUATION
2022-11-23 01:30:07,801 INFO:   Leaving out SEQ value Fold_1
2022-11-23 01:30:07,814 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-23 01:30:07,814 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:30:08,479 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:30:08,479 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:30:08,550 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:30:08,550 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:30:08,550 INFO:     No hyperparam tuning for this model
2022-11-23 01:30:08,550 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:30:08,550 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:30:08,551 INFO:     None feature selector for col prot
2022-11-23 01:30:08,551 INFO:     None feature selector for col prot
2022-11-23 01:30:08,551 INFO:     None feature selector for col prot
2022-11-23 01:30:08,552 INFO:     None feature selector for col chem
2022-11-23 01:30:08,552 INFO:     None feature selector for col chem
2022-11-23 01:30:08,552 INFO:     None feature selector for col chem
2022-11-23 01:30:08,552 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:30:08,552 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:30:08,553 INFO:     Number of params in model 168571
2022-11-23 01:30:08,557 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:30:08,557 INFO:   Starting stage: TRAINING
2022-11-23 01:30:08,615 INFO:     Val loss before train {'Reaction outcome loss': 1.0567674803179363, 'Total loss': 1.0567674803179363}
2022-11-23 01:30:08,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:08,616 INFO:     Epoch: 0
2022-11-23 01:30:09,410 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8865800291992897, 'Total loss': 0.8865800291992897} | train loss {'Reaction outcome loss': 0.9020240904127129, 'Total loss': 0.9020240904127129}
2022-11-23 01:30:09,410 INFO:     Found new best model at epoch 0
2022-11-23 01:30:09,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:09,411 INFO:     Epoch: 1
2022-11-23 01:30:10,174 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.9463260437166968, 'Total loss': 0.9463260437166968} | train loss {'Reaction outcome loss': 0.8550930741269893, 'Total loss': 0.8550930741269893}
2022-11-23 01:30:10,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:10,175 INFO:     Epoch: 2
2022-11-23 01:30:10,985 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8687849640846252, 'Total loss': 0.8687849640846252} | train loss {'Reaction outcome loss': 0.8629836562729667, 'Total loss': 0.8629836562729667}
2022-11-23 01:30:10,985 INFO:     Found new best model at epoch 2
2022-11-23 01:30:10,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:10,986 INFO:     Epoch: 3
2022-11-23 01:30:11,773 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8581606648689093, 'Total loss': 0.8581606648689093} | train loss {'Reaction outcome loss': 0.8579336029511911, 'Total loss': 0.8579336029511911}
2022-11-23 01:30:11,774 INFO:     Found new best model at epoch 3
2022-11-23 01:30:11,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:11,775 INFO:     Epoch: 4
2022-11-23 01:30:12,573 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8821809402731962, 'Total loss': 0.8821809402731962} | train loss {'Reaction outcome loss': 0.8536224273251899, 'Total loss': 0.8536224273251899}
2022-11-23 01:30:12,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:12,573 INFO:     Epoch: 5
2022-11-23 01:30:13,351 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8996297148771064, 'Total loss': 0.8996297148771064} | train loss {'Reaction outcome loss': 0.8460818012800727, 'Total loss': 0.8460818012800727}
2022-11-23 01:30:13,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:13,352 INFO:     Epoch: 6
2022-11-23 01:30:14,175 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8699472782223724, 'Total loss': 0.8699472782223724} | train loss {'Reaction outcome loss': 0.8489577919857982, 'Total loss': 0.8489577919857982}
2022-11-23 01:30:14,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:14,175 INFO:     Epoch: 7
2022-11-23 01:30:15,017 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8596032414325449, 'Total loss': 0.8596032414325449} | train loss {'Reaction outcome loss': 0.8472987077363725, 'Total loss': 0.8472987077363725}
2022-11-23 01:30:15,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:15,017 INFO:     Epoch: 8
2022-11-23 01:30:15,814 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8501785037129425, 'Total loss': 0.8501785037129425} | train loss {'Reaction outcome loss': 0.8454406801074621, 'Total loss': 0.8454406801074621}
2022-11-23 01:30:15,814 INFO:     Found new best model at epoch 8
2022-11-23 01:30:15,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:15,815 INFO:     Epoch: 9
2022-11-23 01:30:16,652 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8639213401217793, 'Total loss': 0.8639213401217793} | train loss {'Reaction outcome loss': 0.8389798341464604, 'Total loss': 0.8389798341464604}
2022-11-23 01:30:16,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:16,652 INFO:     Epoch: 10
2022-11-23 01:30:17,455 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8805473183476648, 'Total loss': 0.8805473183476648} | train loss {'Reaction outcome loss': 0.8407022046699445, 'Total loss': 0.8407022046699445}
2022-11-23 01:30:17,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:17,455 INFO:     Epoch: 11
2022-11-23 01:30:18,282 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8463395847830661, 'Total loss': 0.8463395847830661} | train loss {'Reaction outcome loss': 0.8401628316920481, 'Total loss': 0.8401628316920481}
2022-11-23 01:30:18,283 INFO:     Found new best model at epoch 11
2022-11-23 01:30:18,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:18,285 INFO:     Epoch: 12
2022-11-23 01:30:19,094 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8411096930503845, 'Total loss': 0.8411096930503845} | train loss {'Reaction outcome loss': 0.8376216946070086, 'Total loss': 0.8376216946070086}
2022-11-23 01:30:19,094 INFO:     Found new best model at epoch 12
2022-11-23 01:30:19,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:19,095 INFO:     Epoch: 13
2022-11-23 01:30:19,909 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8423718948696934, 'Total loss': 0.8423718948696934} | train loss {'Reaction outcome loss': 0.845171278764191, 'Total loss': 0.845171278764191}
2022-11-23 01:30:19,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:19,909 INFO:     Epoch: 14
2022-11-23 01:30:20,725 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8367239583370297, 'Total loss': 0.8367239583370297} | train loss {'Reaction outcome loss': 0.8388126427499355, 'Total loss': 0.8388126427499355}
2022-11-23 01:30:20,725 INFO:     Found new best model at epoch 14
2022-11-23 01:30:20,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:20,726 INFO:     Epoch: 15
2022-11-23 01:30:21,536 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8548953436141791, 'Total loss': 0.8548953436141791} | train loss {'Reaction outcome loss': 0.8355509761429618, 'Total loss': 0.8355509761429618}
2022-11-23 01:30:21,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:21,537 INFO:     Epoch: 16
2022-11-23 01:30:22,341 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8679410662761954, 'Total loss': 0.8679410662761954} | train loss {'Reaction outcome loss': 0.8420414393576084, 'Total loss': 0.8420414393576084}
2022-11-23 01:30:22,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:22,341 INFO:     Epoch: 17
2022-11-23 01:30:23,164 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8959075482778771, 'Total loss': 0.8959075482778771} | train loss {'Reaction outcome loss': 0.8358644686118075, 'Total loss': 0.8358644686118075}
2022-11-23 01:30:23,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:23,164 INFO:     Epoch: 18
2022-11-23 01:30:23,967 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8588652368201766, 'Total loss': 0.8588652368201766} | train loss {'Reaction outcome loss': 0.8368370671576433, 'Total loss': 0.8368370671576433}
2022-11-23 01:30:23,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:23,967 INFO:     Epoch: 19
2022-11-23 01:30:24,729 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8708436932674674, 'Total loss': 0.8708436932674674} | train loss {'Reaction outcome loss': 0.8365568031744702, 'Total loss': 0.8365568031744702}
2022-11-23 01:30:24,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:24,730 INFO:     Epoch: 20
2022-11-23 01:30:25,506 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8936346866363702, 'Total loss': 0.8936346866363702} | train loss {'Reaction outcome loss': 0.8386126235434057, 'Total loss': 0.8386126235434057}
2022-11-23 01:30:25,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:25,506 INFO:     Epoch: 21
2022-11-23 01:30:26,311 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8382995558339496, 'Total loss': 0.8382995558339496} | train loss {'Reaction outcome loss': 0.8391503982337905, 'Total loss': 0.8391503982337905}
2022-11-23 01:30:26,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:26,311 INFO:     Epoch: 22
2022-11-23 01:30:27,108 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.851501234742098, 'Total loss': 0.851501234742098} | train loss {'Reaction outcome loss': 0.834846405090128, 'Total loss': 0.834846405090128}
2022-11-23 01:30:27,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:27,108 INFO:     Epoch: 23
2022-11-23 01:30:27,905 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.9004420028176419, 'Total loss': 0.9004420028176419} | train loss {'Reaction outcome loss': 0.8377437027393545, 'Total loss': 0.8377437027393545}
2022-11-23 01:30:27,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:27,906 INFO:     Epoch: 24
2022-11-23 01:30:28,688 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.840268588343332, 'Total loss': 0.840268588343332} | train loss {'Reaction outcome loss': 0.8386836538834826, 'Total loss': 0.8386836538834826}
2022-11-23 01:30:28,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:28,688 INFO:     Epoch: 25
2022-11-23 01:30:29,464 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8381506052128104, 'Total loss': 0.8381506052128104} | train loss {'Reaction outcome loss': 0.8300022080601979, 'Total loss': 0.8300022080601979}
2022-11-23 01:30:29,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:29,464 INFO:     Epoch: 26
2022-11-23 01:30:30,243 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8562315986600033, 'Total loss': 0.8562315986600033} | train loss {'Reaction outcome loss': 0.8330904850008066, 'Total loss': 0.8330904850008066}
2022-11-23 01:30:30,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:30,243 INFO:     Epoch: 27
2022-11-23 01:30:31,029 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8593099678671637, 'Total loss': 0.8593099678671637} | train loss {'Reaction outcome loss': 0.8403242729573583, 'Total loss': 0.8403242729573583}
2022-11-23 01:30:31,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:31,030 INFO:     Epoch: 28
2022-11-23 01:30:31,796 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8577184476131616, 'Total loss': 0.8577184476131616} | train loss {'Reaction outcome loss': 0.8350218659565772, 'Total loss': 0.8350218659565772}
2022-11-23 01:30:31,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:31,796 INFO:     Epoch: 29
2022-11-23 01:30:32,640 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8595959925374319, 'Total loss': 0.8595959925374319} | train loss {'Reaction outcome loss': 0.8368927681887591, 'Total loss': 0.8368927681887591}
2022-11-23 01:30:32,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:32,641 INFO:     Epoch: 30
2022-11-23 01:30:33,464 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8315175640028577, 'Total loss': 0.8315175640028577} | train loss {'Reaction outcome loss': 0.8401492415877526, 'Total loss': 0.8401492415877526}
2022-11-23 01:30:33,464 INFO:     Found new best model at epoch 30
2022-11-23 01:30:33,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:33,465 INFO:     Epoch: 31
2022-11-23 01:30:34,292 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8443967852481576, 'Total loss': 0.8443967852481576} | train loss {'Reaction outcome loss': 0.8358112659473969, 'Total loss': 0.8358112659473969}
2022-11-23 01:30:34,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:34,292 INFO:     Epoch: 32
2022-11-23 01:30:35,061 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8343377653942552, 'Total loss': 0.8343377653942552} | train loss {'Reaction outcome loss': 0.8347357014201796, 'Total loss': 0.8347357014201796}
2022-11-23 01:30:35,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:35,062 INFO:     Epoch: 33
2022-11-23 01:30:35,885 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8690356542897779, 'Total loss': 0.8690356542897779} | train loss {'Reaction outcome loss': 0.8370494443938565, 'Total loss': 0.8370494443938565}
2022-11-23 01:30:35,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:35,885 INFO:     Epoch: 34
2022-11-23 01:30:36,677 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8506156039792437, 'Total loss': 0.8506156039792437} | train loss {'Reaction outcome loss': 0.8350774326932774, 'Total loss': 0.8350774326932774}
2022-11-23 01:30:36,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:36,677 INFO:     Epoch: 35
2022-11-23 01:30:37,452 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8847504951233087, 'Total loss': 0.8847504951233087} | train loss {'Reaction outcome loss': 0.8332753232967707, 'Total loss': 0.8332753232967707}
2022-11-23 01:30:37,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:37,452 INFO:     Epoch: 36
2022-11-23 01:30:38,240 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.9011758552041165, 'Total loss': 0.9011758552041165} | train loss {'Reaction outcome loss': 0.8347322785069422, 'Total loss': 0.8347322785069422}
2022-11-23 01:30:38,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:38,240 INFO:     Epoch: 37
2022-11-23 01:30:39,036 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8533094178798587, 'Total loss': 0.8533094178798587} | train loss {'Reaction outcome loss': 0.8336190098107107, 'Total loss': 0.8336190098107107}
2022-11-23 01:30:39,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:39,036 INFO:     Epoch: 38
2022-11-23 01:30:39,855 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.854629960171012, 'Total loss': 0.854629960171012} | train loss {'Reaction outcome loss': 0.8292552625200876, 'Total loss': 0.8292552625200876}
2022-11-23 01:30:39,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:39,855 INFO:     Epoch: 39
2022-11-23 01:30:40,660 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8504195469756459, 'Total loss': 0.8504195469756459} | train loss {'Reaction outcome loss': 0.8315103369239917, 'Total loss': 0.8315103369239917}
2022-11-23 01:30:40,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:40,660 INFO:     Epoch: 40
2022-11-23 01:30:41,426 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.868431173091711, 'Total loss': 0.868431173091711} | train loss {'Reaction outcome loss': 0.8296391355647962, 'Total loss': 0.8296391355647962}
2022-11-23 01:30:41,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:41,426 INFO:     Epoch: 41
2022-11-23 01:30:42,228 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8476780091607293, 'Total loss': 0.8476780091607293} | train loss {'Reaction outcome loss': 0.8330143516568981, 'Total loss': 0.8330143516568981}
2022-11-23 01:30:42,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:42,228 INFO:     Epoch: 42
2022-11-23 01:30:43,014 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8502775860387225, 'Total loss': 0.8502775860387225} | train loss {'Reaction outcome loss': 0.8306853935551741, 'Total loss': 0.8306853935551741}
2022-11-23 01:30:43,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:43,014 INFO:     Epoch: 43
2022-11-23 01:30:43,848 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8652348754017852, 'Total loss': 0.8652348754017852} | train loss {'Reaction outcome loss': 0.8349640154789505, 'Total loss': 0.8349640154789505}
2022-11-23 01:30:43,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:43,850 INFO:     Epoch: 44
2022-11-23 01:30:44,650 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8389563740685929, 'Total loss': 0.8389563740685929} | train loss {'Reaction outcome loss': 0.8352320838121721, 'Total loss': 0.8352320838121721}
2022-11-23 01:30:44,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:44,650 INFO:     Epoch: 45
2022-11-23 01:30:45,451 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8533848953801532, 'Total loss': 0.8533848953801532} | train loss {'Reaction outcome loss': 0.8353839306919663, 'Total loss': 0.8353839306919663}
2022-11-23 01:30:45,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:45,452 INFO:     Epoch: 46
2022-11-23 01:30:46,293 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.852835170058317, 'Total loss': 0.852835170058317} | train loss {'Reaction outcome loss': 0.8365988158640058, 'Total loss': 0.8365988158640058}
2022-11-23 01:30:46,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:46,293 INFO:     Epoch: 47
2022-11-23 01:30:47,113 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8408998840076979, 'Total loss': 0.8408998840076979} | train loss {'Reaction outcome loss': 0.8300989455401652, 'Total loss': 0.8300989455401652}
2022-11-23 01:30:47,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:47,113 INFO:     Epoch: 48
2022-11-23 01:30:48,012 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8536777981491976, 'Total loss': 0.8536777981491976} | train loss {'Reaction outcome loss': 0.8341411720087499, 'Total loss': 0.8341411720087499}
2022-11-23 01:30:48,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:48,012 INFO:     Epoch: 49
2022-11-23 01:30:48,870 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8529137969017029, 'Total loss': 0.8529137969017029} | train loss {'Reaction outcome loss': 0.8360442428431883, 'Total loss': 0.8360442428431883}
2022-11-23 01:30:48,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:48,870 INFO:     Epoch: 50
2022-11-23 01:30:49,770 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8365645831407502, 'Total loss': 0.8365645831407502} | train loss {'Reaction outcome loss': 0.8328766045256407, 'Total loss': 0.8328766045256407}
2022-11-23 01:30:49,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:49,771 INFO:     Epoch: 51
2022-11-23 01:30:50,626 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8345044809718465, 'Total loss': 0.8345044809718465} | train loss {'Reaction outcome loss': 0.8385629543551693, 'Total loss': 0.8385629543551693}
2022-11-23 01:30:50,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:50,627 INFO:     Epoch: 52
2022-11-23 01:30:51,481 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8416090836358625, 'Total loss': 0.8416090836358625} | train loss {'Reaction outcome loss': 0.8320465484028491, 'Total loss': 0.8320465484028491}
2022-11-23 01:30:51,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:51,481 INFO:     Epoch: 53
2022-11-23 01:30:52,307 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.848088824471762, 'Total loss': 0.848088824471762} | train loss {'Reaction outcome loss': 0.8319371927667547, 'Total loss': 0.8319371927667547}
2022-11-23 01:30:52,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:52,307 INFO:     Epoch: 54
2022-11-23 01:30:53,079 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8758464192235192, 'Total loss': 0.8758464192235192} | train loss {'Reaction outcome loss': 0.8311674926016066, 'Total loss': 0.8311674926016066}
2022-11-23 01:30:53,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:53,079 INFO:     Epoch: 55
2022-11-23 01:30:53,930 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8289930307587912, 'Total loss': 0.8289930307587912} | train loss {'Reaction outcome loss': 0.8294223426791375, 'Total loss': 0.8294223426791375}
2022-11-23 01:30:53,931 INFO:     Found new best model at epoch 55
2022-11-23 01:30:53,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:53,932 INFO:     Epoch: 56
2022-11-23 01:30:54,753 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.889209715432899, 'Total loss': 0.889209715432899} | train loss {'Reaction outcome loss': 0.834701965497845, 'Total loss': 0.834701965497845}
2022-11-23 01:30:54,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:54,753 INFO:     Epoch: 57
2022-11-23 01:30:55,561 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8439911486104478, 'Total loss': 0.8439911486104478} | train loss {'Reaction outcome loss': 0.8322794981944708, 'Total loss': 0.8322794981944708}
2022-11-23 01:30:55,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:55,561 INFO:     Epoch: 58
2022-11-23 01:30:56,385 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8566381584766299, 'Total loss': 0.8566381584766299} | train loss {'Reaction outcome loss': 0.8287923622401163, 'Total loss': 0.8287923622401163}
2022-11-23 01:30:56,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:56,385 INFO:     Epoch: 59
2022-11-23 01:30:57,217 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8490255641382795, 'Total loss': 0.8490255641382795} | train loss {'Reaction outcome loss': 0.8376710773004916, 'Total loss': 0.8376710773004916}
2022-11-23 01:30:57,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:57,218 INFO:     Epoch: 60
2022-11-23 01:30:57,993 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8687602094439573, 'Total loss': 0.8687602094439573} | train loss {'Reaction outcome loss': 0.8333532655680621, 'Total loss': 0.8333532655680621}
2022-11-23 01:30:57,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:57,993 INFO:     Epoch: 61
2022-11-23 01:30:58,783 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8443660264791444, 'Total loss': 0.8443660264791444} | train loss {'Reaction outcome loss': 0.835296198787022, 'Total loss': 0.835296198787022}
2022-11-23 01:30:58,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:58,784 INFO:     Epoch: 62
2022-11-23 01:30:59,594 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8712772595327954, 'Total loss': 0.8712772595327954} | train loss {'Reaction outcome loss': 0.8309380865881963, 'Total loss': 0.8309380865881963}
2022-11-23 01:30:59,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:30:59,594 INFO:     Epoch: 63
2022-11-23 01:31:00,401 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8401293671408365, 'Total loss': 0.8401293671408365} | train loss {'Reaction outcome loss': 0.8308772404252747, 'Total loss': 0.8308772404252747}
2022-11-23 01:31:00,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:00,401 INFO:     Epoch: 64
2022-11-23 01:31:01,188 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.9482111986293349, 'Total loss': 0.9482111986293349} | train loss {'Reaction outcome loss': 0.8310692599771444, 'Total loss': 0.8310692599771444}
2022-11-23 01:31:01,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:01,189 INFO:     Epoch: 65
2022-11-23 01:31:01,974 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8483693856139516, 'Total loss': 0.8483693856139516} | train loss {'Reaction outcome loss': 0.8347874608795338, 'Total loss': 0.8347874608795338}
2022-11-23 01:31:01,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:01,975 INFO:     Epoch: 66
2022-11-23 01:31:02,743 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8281027730121169, 'Total loss': 0.8281027730121169} | train loss {'Reaction outcome loss': 0.829476831381213, 'Total loss': 0.829476831381213}
2022-11-23 01:31:02,744 INFO:     Found new best model at epoch 66
2022-11-23 01:31:02,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:02,745 INFO:     Epoch: 67
2022-11-23 01:31:03,506 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8432573197886001, 'Total loss': 0.8432573197886001} | train loss {'Reaction outcome loss': 0.8301703289703086, 'Total loss': 0.8301703289703086}
2022-11-23 01:31:03,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:03,506 INFO:     Epoch: 68
2022-11-23 01:31:04,310 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8388070963149847, 'Total loss': 0.8388070963149847} | train loss {'Reaction outcome loss': 0.829872314822036, 'Total loss': 0.829872314822036}
2022-11-23 01:31:04,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:04,311 INFO:     Epoch: 69
2022-11-23 01:31:05,088 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8463906638844069, 'Total loss': 0.8463906638844069} | train loss {'Reaction outcome loss': 0.828752649541745, 'Total loss': 0.828752649541745}
2022-11-23 01:31:05,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:05,088 INFO:     Epoch: 70
2022-11-23 01:31:05,886 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.837023631084797, 'Total loss': 0.837023631084797} | train loss {'Reaction outcome loss': 0.8330808146990867, 'Total loss': 0.8330808146990867}
2022-11-23 01:31:05,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:05,886 INFO:     Epoch: 71
2022-11-23 01:31:06,678 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8631787785263949, 'Total loss': 0.8631787785263949} | train loss {'Reaction outcome loss': 0.8255404113742059, 'Total loss': 0.8255404113742059}
2022-11-23 01:31:06,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:06,679 INFO:     Epoch: 72
2022-11-23 01:31:07,473 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8507493505644244, 'Total loss': 0.8507493505644244} | train loss {'Reaction outcome loss': 0.8255913930910604, 'Total loss': 0.8255913930910604}
2022-11-23 01:31:07,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:07,473 INFO:     Epoch: 73
2022-11-23 01:31:08,292 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8853435114372609, 'Total loss': 0.8853435114372609} | train loss {'Reaction outcome loss': 0.8245320339752323, 'Total loss': 0.8245320339752323}
2022-11-23 01:31:08,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:08,292 INFO:     Epoch: 74
2022-11-23 01:31:09,109 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8870239978612855, 'Total loss': 0.8870239978612855} | train loss {'Reaction outcome loss': 0.8291547525321505, 'Total loss': 0.8291547525321505}
2022-11-23 01:31:09,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:09,109 INFO:     Epoch: 75
2022-11-23 01:31:09,991 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8511536932268808, 'Total loss': 0.8511536932268808} | train loss {'Reaction outcome loss': 0.8310994092574335, 'Total loss': 0.8310994092574335}
2022-11-23 01:31:09,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:09,992 INFO:     Epoch: 76
2022-11-23 01:31:10,863 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8359913396280866, 'Total loss': 0.8359913396280866} | train loss {'Reaction outcome loss': 0.8308842856697585, 'Total loss': 0.8308842856697585}
2022-11-23 01:31:10,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:10,864 INFO:     Epoch: 77
2022-11-23 01:31:11,761 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8462727125300917, 'Total loss': 0.8462727125300917} | train loss {'Reaction outcome loss': 0.8310401096265503, 'Total loss': 0.8310401096265503}
2022-11-23 01:31:11,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:11,762 INFO:     Epoch: 78
2022-11-23 01:31:12,648 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8341516554355621, 'Total loss': 0.8341516554355621} | train loss {'Reaction outcome loss': 0.8277175707336316, 'Total loss': 0.8277175707336316}
2022-11-23 01:31:12,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:12,648 INFO:     Epoch: 79
2022-11-23 01:31:13,546 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8420607087224029, 'Total loss': 0.8420607087224029} | train loss {'Reaction outcome loss': 0.8296838472654791, 'Total loss': 0.8296838472654791}
2022-11-23 01:31:13,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:13,546 INFO:     Epoch: 80
2022-11-23 01:31:14,380 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8525060498437216, 'Total loss': 0.8525060498437216} | train loss {'Reaction outcome loss': 0.8304283472981473, 'Total loss': 0.8304283472981473}
2022-11-23 01:31:14,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:14,380 INFO:     Epoch: 81
2022-11-23 01:31:15,222 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8547363419865452, 'Total loss': 0.8547363419865452} | train loss {'Reaction outcome loss': 0.8324080922721345, 'Total loss': 0.8324080922721345}
2022-11-23 01:31:15,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:15,223 INFO:     Epoch: 82
2022-11-23 01:31:16,106 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8373877267504848, 'Total loss': 0.8373877267504848} | train loss {'Reaction outcome loss': 0.8223831043444543, 'Total loss': 0.8223831043444543}
2022-11-23 01:31:16,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:16,106 INFO:     Epoch: 83
2022-11-23 01:31:17,010 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8363555891569271, 'Total loss': 0.8363555891569271} | train loss {'Reaction outcome loss': 0.826565507876039, 'Total loss': 0.826565507876039}
2022-11-23 01:31:17,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:17,010 INFO:     Epoch: 84
2022-11-23 01:31:17,890 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8341619788214217, 'Total loss': 0.8341619788214217} | train loss {'Reaction outcome loss': 0.8314540517428284, 'Total loss': 0.8314540517428284}
2022-11-23 01:31:17,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:17,890 INFO:     Epoch: 85
2022-11-23 01:31:18,764 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8457286399464274, 'Total loss': 0.8457286399464274} | train loss {'Reaction outcome loss': 0.8258731021802612, 'Total loss': 0.8258731021802612}
2022-11-23 01:31:18,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:18,764 INFO:     Epoch: 86
2022-11-23 01:31:19,631 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8311625261639439, 'Total loss': 0.8311625261639439} | train loss {'Reaction outcome loss': 0.8274596896436479, 'Total loss': 0.8274596896436479}
2022-11-23 01:31:19,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:19,631 INFO:     Epoch: 87
2022-11-23 01:31:20,484 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8425411789916283, 'Total loss': 0.8425411789916283} | train loss {'Reaction outcome loss': 0.8292744071395309, 'Total loss': 0.8292744071395309}
2022-11-23 01:31:20,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:20,484 INFO:     Epoch: 88
2022-11-23 01:31:21,353 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8412867396376854, 'Total loss': 0.8412867396376854} | train loss {'Reaction outcome loss': 0.8287769329155423, 'Total loss': 0.8287769329155423}
2022-11-23 01:31:21,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:21,354 INFO:     Epoch: 89
2022-11-23 01:31:22,190 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8267523244369862, 'Total loss': 0.8267523244369862} | train loss {'Reaction outcome loss': 0.832416172135514, 'Total loss': 0.832416172135514}
2022-11-23 01:31:22,190 INFO:     Found new best model at epoch 89
2022-11-23 01:31:22,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:22,191 INFO:     Epoch: 90
2022-11-23 01:31:23,140 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8298211305640465, 'Total loss': 0.8298211305640465} | train loss {'Reaction outcome loss': 0.8260644644253539, 'Total loss': 0.8260644644253539}
2022-11-23 01:31:23,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:23,141 INFO:     Epoch: 91
2022-11-23 01:31:23,994 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8384353795716929, 'Total loss': 0.8384353795716929} | train loss {'Reaction outcome loss': 0.8278683043801736, 'Total loss': 0.8278683043801736}
2022-11-23 01:31:23,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:23,994 INFO:     Epoch: 92
2022-11-23 01:31:24,830 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8442162129768106, 'Total loss': 0.8442162129768106} | train loss {'Reaction outcome loss': 0.8235618932011687, 'Total loss': 0.8235618932011687}
2022-11-23 01:31:24,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:24,830 INFO:     Epoch: 93
2022-11-23 01:31:25,628 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8992098694623902, 'Total loss': 0.8992098694623902} | train loss {'Reaction outcome loss': 0.8235957877626144, 'Total loss': 0.8235957877626144}
2022-11-23 01:31:25,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:25,628 INFO:     Epoch: 94
2022-11-23 01:31:26,417 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8499962590461554, 'Total loss': 0.8499962590461554} | train loss {'Reaction outcome loss': 0.8280353551048311, 'Total loss': 0.8280353551048311}
2022-11-23 01:31:26,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:26,417 INFO:     Epoch: 95
2022-11-23 01:31:27,243 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8371750033178995, 'Total loss': 0.8371750033178995} | train loss {'Reaction outcome loss': 0.8275040576977984, 'Total loss': 0.8275040576977984}
2022-11-23 01:31:27,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:27,243 INFO:     Epoch: 96
2022-11-23 01:31:28,053 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8699079523252886, 'Total loss': 0.8699079523252886} | train loss {'Reaction outcome loss': 0.8271089085826168, 'Total loss': 0.8271089085826168}
2022-11-23 01:31:28,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:28,053 INFO:     Epoch: 97
2022-11-23 01:31:28,844 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8339365991049035, 'Total loss': 0.8339365991049035} | train loss {'Reaction outcome loss': 0.823376986838172, 'Total loss': 0.823376986838172}
2022-11-23 01:31:28,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:28,844 INFO:     Epoch: 98
2022-11-23 01:31:29,648 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8487780537716177, 'Total loss': 0.8487780537716177} | train loss {'Reaction outcome loss': 0.8237249699149112, 'Total loss': 0.8237249699149112}
2022-11-23 01:31:29,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:29,649 INFO:     Epoch: 99
2022-11-23 01:31:30,459 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8386223655800487, 'Total loss': 0.8386223655800487} | train loss {'Reaction outcome loss': 0.8216454521618752, 'Total loss': 0.8216454521618752}
2022-11-23 01:31:30,459 INFO:     Best model found after epoch 90 of 100.
2022-11-23 01:31:30,459 INFO:   Done with stage: TRAINING
2022-11-23 01:31:30,459 INFO:   Starting stage: EVALUATION
2022-11-23 01:31:30,603 INFO:   Done with stage: EVALUATION
2022-11-23 01:31:30,604 INFO:   Leaving out SEQ value Fold_2
2022-11-23 01:31:30,617 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-23 01:31:30,617 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:31:31,283 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:31:31,283 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:31:31,354 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:31:31,355 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:31:31,355 INFO:     No hyperparam tuning for this model
2022-11-23 01:31:31,355 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:31:31,355 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:31:31,356 INFO:     None feature selector for col prot
2022-11-23 01:31:31,356 INFO:     None feature selector for col prot
2022-11-23 01:31:31,356 INFO:     None feature selector for col prot
2022-11-23 01:31:31,356 INFO:     None feature selector for col chem
2022-11-23 01:31:31,356 INFO:     None feature selector for col chem
2022-11-23 01:31:31,357 INFO:     None feature selector for col chem
2022-11-23 01:31:31,357 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:31:31,357 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:31:31,358 INFO:     Number of params in model 168571
2022-11-23 01:31:31,361 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:31:31,361 INFO:   Starting stage: TRAINING
2022-11-23 01:31:31,420 INFO:     Val loss before train {'Reaction outcome loss': 1.0114361576058648, 'Total loss': 1.0114361576058648}
2022-11-23 01:31:31,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:31,420 INFO:     Epoch: 0
2022-11-23 01:31:32,245 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8563215034929189, 'Total loss': 0.8563215034929189} | train loss {'Reaction outcome loss': 0.8966969842813453, 'Total loss': 0.8966969842813453}
2022-11-23 01:31:32,245 INFO:     Found new best model at epoch 0
2022-11-23 01:31:32,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:32,246 INFO:     Epoch: 1
2022-11-23 01:31:33,194 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8244988119060342, 'Total loss': 0.8244988119060342} | train loss {'Reaction outcome loss': 0.8626797132346095, 'Total loss': 0.8626797132346095}
2022-11-23 01:31:33,195 INFO:     Found new best model at epoch 1
2022-11-23 01:31:33,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:33,196 INFO:     Epoch: 2
2022-11-23 01:31:34,025 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8498015173456885, 'Total loss': 0.8498015173456885} | train loss {'Reaction outcome loss': 0.8588807822490225, 'Total loss': 0.8588807822490225}
2022-11-23 01:31:34,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:34,026 INFO:     Epoch: 3
2022-11-23 01:31:34,878 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8147084618156607, 'Total loss': 0.8147084618156607} | train loss {'Reaction outcome loss': 0.8520496049705817, 'Total loss': 0.8520496049705817}
2022-11-23 01:31:34,878 INFO:     Found new best model at epoch 3
2022-11-23 01:31:34,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:34,879 INFO:     Epoch: 4
2022-11-23 01:31:35,708 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8016884970394048, 'Total loss': 0.8016884970394048} | train loss {'Reaction outcome loss': 0.8575374962115775, 'Total loss': 0.8575374962115775}
2022-11-23 01:31:35,708 INFO:     Found new best model at epoch 4
2022-11-23 01:31:35,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:35,709 INFO:     Epoch: 5
2022-11-23 01:31:36,643 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8181022839112715, 'Total loss': 0.8181022839112715} | train loss {'Reaction outcome loss': 0.8515165585644391, 'Total loss': 0.8515165585644391}
2022-11-23 01:31:36,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:36,644 INFO:     Epoch: 6
2022-11-23 01:31:37,526 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8148743496699766, 'Total loss': 0.8148743496699766} | train loss {'Reaction outcome loss': 0.8449626734062117, 'Total loss': 0.8449626734062117}
2022-11-23 01:31:37,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:37,527 INFO:     Epoch: 7
2022-11-23 01:31:38,359 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.828702216798609, 'Total loss': 0.828702216798609} | train loss {'Reaction outcome loss': 0.8406351132052285, 'Total loss': 0.8406351132052285}
2022-11-23 01:31:38,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:38,360 INFO:     Epoch: 8
2022-11-23 01:31:39,173 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8170916925777089, 'Total loss': 0.8170916925777089} | train loss {'Reaction outcome loss': 0.8394174263185384, 'Total loss': 0.8394174263185384}
2022-11-23 01:31:39,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:39,174 INFO:     Epoch: 9
2022-11-23 01:31:40,060 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8118052983825857, 'Total loss': 0.8118052983825857} | train loss {'Reaction outcome loss': 0.8375865223456402, 'Total loss': 0.8375865223456402}
2022-11-23 01:31:40,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:40,060 INFO:     Epoch: 10
2022-11-23 01:31:40,925 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8045750991864637, 'Total loss': 0.8045750991864637} | train loss {'Reaction outcome loss': 0.8376856095936833, 'Total loss': 0.8376856095936833}
2022-11-23 01:31:40,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:40,925 INFO:     Epoch: 11
2022-11-23 01:31:41,848 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8075433996590701, 'Total loss': 0.8075433996590701} | train loss {'Reaction outcome loss': 0.8380466281151285, 'Total loss': 0.8380466281151285}
2022-11-23 01:31:41,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:41,848 INFO:     Epoch: 12
2022-11-23 01:31:42,717 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8177093822847713, 'Total loss': 0.8177093822847713} | train loss {'Reaction outcome loss': 0.8392037874581862, 'Total loss': 0.8392037874581862}
2022-11-23 01:31:42,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:42,718 INFO:     Epoch: 13
2022-11-23 01:31:43,561 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8129627074707638, 'Total loss': 0.8129627074707638} | train loss {'Reaction outcome loss': 0.8406972690504424, 'Total loss': 0.8406972690504424}
2022-11-23 01:31:43,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:43,561 INFO:     Epoch: 14
2022-11-23 01:31:44,417 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8000351204113527, 'Total loss': 0.8000351204113527} | train loss {'Reaction outcome loss': 0.8345314266730328, 'Total loss': 0.8345314266730328}
2022-11-23 01:31:44,417 INFO:     Found new best model at epoch 14
2022-11-23 01:31:44,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:44,418 INFO:     Epoch: 15
2022-11-23 01:31:45,310 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8105462691323324, 'Total loss': 0.8105462691323324} | train loss {'Reaction outcome loss': 0.8303229721225038, 'Total loss': 0.8303229721225038}
2022-11-23 01:31:45,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:45,310 INFO:     Epoch: 16
2022-11-23 01:31:46,206 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8007657859813083, 'Total loss': 0.8007657859813083} | train loss {'Reaction outcome loss': 0.8363983926724414, 'Total loss': 0.8363983926724414}
2022-11-23 01:31:46,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:46,207 INFO:     Epoch: 17
2022-11-23 01:31:47,054 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8024245791814544, 'Total loss': 0.8024245791814544} | train loss {'Reaction outcome loss': 0.8342472547171067, 'Total loss': 0.8342472547171067}
2022-11-23 01:31:47,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:47,054 INFO:     Epoch: 18
2022-11-23 01:31:47,931 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8000423681329597, 'Total loss': 0.8000423681329597} | train loss {'Reaction outcome loss': 0.8354659633977073, 'Total loss': 0.8354659633977073}
2022-11-23 01:31:47,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:47,931 INFO:     Epoch: 19
2022-11-23 01:31:48,798 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8063969896598295, 'Total loss': 0.8063969896598295} | train loss {'Reaction outcome loss': 0.8370735353353073, 'Total loss': 0.8370735353353073}
2022-11-23 01:31:48,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:48,798 INFO:     Epoch: 20
2022-11-23 01:31:49,624 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8094212927601554, 'Total loss': 0.8094212927601554} | train loss {'Reaction outcome loss': 0.8338372636814506, 'Total loss': 0.8338372636814506}
2022-11-23 01:31:49,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:49,625 INFO:     Epoch: 21
2022-11-23 01:31:50,435 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.80517774481665, 'Total loss': 0.80517774481665} | train loss {'Reaction outcome loss': 0.8345012247562409, 'Total loss': 0.8345012247562409}
2022-11-23 01:31:50,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:50,436 INFO:     Epoch: 22
2022-11-23 01:31:51,289 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7906743437051773, 'Total loss': 0.7906743437051773} | train loss {'Reaction outcome loss': 0.8299006233409959, 'Total loss': 0.8299006233409959}
2022-11-23 01:31:51,289 INFO:     Found new best model at epoch 22
2022-11-23 01:31:51,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:51,290 INFO:     Epoch: 23
2022-11-23 01:31:52,114 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8285150514407591, 'Total loss': 0.8285150514407591} | train loss {'Reaction outcome loss': 0.8326391637325287, 'Total loss': 0.8326391637325287}
2022-11-23 01:31:52,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:52,115 INFO:     Epoch: 24
2022-11-23 01:31:52,975 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8085343990136277, 'Total loss': 0.8085343990136277} | train loss {'Reaction outcome loss': 0.8362003255863579, 'Total loss': 0.8362003255863579}
2022-11-23 01:31:52,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:52,976 INFO:     Epoch: 25
2022-11-23 01:31:53,832 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8572178930044174, 'Total loss': 0.8572178930044174} | train loss {'Reaction outcome loss': 0.8312961164785891, 'Total loss': 0.8312961164785891}
2022-11-23 01:31:53,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:53,833 INFO:     Epoch: 26
2022-11-23 01:31:54,725 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8378303775733168, 'Total loss': 0.8378303775733168} | train loss {'Reaction outcome loss': 0.8305430417158166, 'Total loss': 0.8305430417158166}
2022-11-23 01:31:54,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:54,725 INFO:     Epoch: 27
2022-11-23 01:31:55,551 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8118566809730097, 'Total loss': 0.8118566809730097} | train loss {'Reaction outcome loss': 0.8278251296403457, 'Total loss': 0.8278251296403457}
2022-11-23 01:31:55,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:55,552 INFO:     Epoch: 28
2022-11-23 01:31:56,374 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8227185932072726, 'Total loss': 0.8227185932072726} | train loss {'Reaction outcome loss': 0.8377546626694349, 'Total loss': 0.8377546626694349}
2022-11-23 01:31:56,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:56,374 INFO:     Epoch: 29
2022-11-23 01:31:57,165 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8045648885044184, 'Total loss': 0.8045648885044184} | train loss {'Reaction outcome loss': 0.8303221568769338, 'Total loss': 0.8303221568769338}
2022-11-23 01:31:57,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:57,166 INFO:     Epoch: 30
2022-11-23 01:31:58,067 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8192061741243709, 'Total loss': 0.8192061741243709} | train loss {'Reaction outcome loss': 0.8302240060300243, 'Total loss': 0.8302240060300243}
2022-11-23 01:31:58,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:58,067 INFO:     Epoch: 31
2022-11-23 01:31:58,882 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8100139972838488, 'Total loss': 0.8100139972838488} | train loss {'Reaction outcome loss': 0.8283958029990294, 'Total loss': 0.8283958029990294}
2022-11-23 01:31:58,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:58,883 INFO:     Epoch: 32
2022-11-23 01:31:59,762 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8232285793532025, 'Total loss': 0.8232285793532025} | train loss {'Reaction outcome loss': 0.8306704654985545, 'Total loss': 0.8306704654985545}
2022-11-23 01:31:59,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:31:59,762 INFO:     Epoch: 33
2022-11-23 01:32:00,648 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8254321068525314, 'Total loss': 0.8254321068525314} | train loss {'Reaction outcome loss': 0.8349787837388564, 'Total loss': 0.8349787837388564}
2022-11-23 01:32:00,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:00,649 INFO:     Epoch: 34
2022-11-23 01:32:01,544 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8136745989322662, 'Total loss': 0.8136745989322662} | train loss {'Reaction outcome loss': 0.830821404043509, 'Total loss': 0.830821404043509}
2022-11-23 01:32:01,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:01,544 INFO:     Epoch: 35
2022-11-23 01:32:02,421 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8292101479389451, 'Total loss': 0.8292101479389451} | train loss {'Reaction outcome loss': 0.836117682043387, 'Total loss': 0.836117682043387}
2022-11-23 01:32:02,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:02,421 INFO:     Epoch: 36
2022-11-23 01:32:03,229 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8179448734630238, 'Total loss': 0.8179448734630238} | train loss {'Reaction outcome loss': 0.8345470259384233, 'Total loss': 0.8345470259384233}
2022-11-23 01:32:03,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:03,230 INFO:     Epoch: 37
2022-11-23 01:32:04,064 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8163869645107876, 'Total loss': 0.8163869645107876} | train loss {'Reaction outcome loss': 0.8326134151341964, 'Total loss': 0.8326134151341964}
2022-11-23 01:32:04,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:04,065 INFO:     Epoch: 38
2022-11-23 01:32:04,960 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7960872453722087, 'Total loss': 0.7960872453722087} | train loss {'Reaction outcome loss': 0.8282603394012062, 'Total loss': 0.8282603394012062}
2022-11-23 01:32:04,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:04,960 INFO:     Epoch: 39
2022-11-23 01:32:05,810 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.801724490116943, 'Total loss': 0.801724490116943} | train loss {'Reaction outcome loss': 0.8294821435091447, 'Total loss': 0.8294821435091447}
2022-11-23 01:32:05,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:05,811 INFO:     Epoch: 40
2022-11-23 01:32:06,696 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8122225925326347, 'Total loss': 0.8122225925326347} | train loss {'Reaction outcome loss': 0.828355517436047, 'Total loss': 0.828355517436047}
2022-11-23 01:32:06,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:06,697 INFO:     Epoch: 41
2022-11-23 01:32:07,556 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8047620843757283, 'Total loss': 0.8047620843757283} | train loss {'Reaction outcome loss': 0.8295876496908616, 'Total loss': 0.8295876496908616}
2022-11-23 01:32:07,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:07,556 INFO:     Epoch: 42
2022-11-23 01:32:08,368 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7962896918708627, 'Total loss': 0.7962896918708627} | train loss {'Reaction outcome loss': 0.8313406174280206, 'Total loss': 0.8313406174280206}
2022-11-23 01:32:08,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:08,368 INFO:     Epoch: 43
2022-11-23 01:32:09,224 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8025364974005655, 'Total loss': 0.8025364974005655} | train loss {'Reaction outcome loss': 0.8287830319939827, 'Total loss': 0.8287830319939827}
2022-11-23 01:32:09,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:09,225 INFO:     Epoch: 44
2022-11-23 01:32:10,074 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8416273851286281, 'Total loss': 0.8416273851286281} | train loss {'Reaction outcome loss': 0.8320947695143369, 'Total loss': 0.8320947695143369}
2022-11-23 01:32:10,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:10,074 INFO:     Epoch: 45
2022-11-23 01:32:10,879 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7888973241841252, 'Total loss': 0.7888973241841252} | train loss {'Reaction outcome loss': 0.833115136988309, 'Total loss': 0.833115136988309}
2022-11-23 01:32:10,879 INFO:     Found new best model at epoch 45
2022-11-23 01:32:10,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:10,880 INFO:     Epoch: 46
2022-11-23 01:32:11,759 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7934390001676299, 'Total loss': 0.7934390001676299} | train loss {'Reaction outcome loss': 0.8293485984510305, 'Total loss': 0.8293485984510305}
2022-11-23 01:32:11,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:11,759 INFO:     Epoch: 47
2022-11-23 01:32:12,556 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7851544953882694, 'Total loss': 0.7851544953882694} | train loss {'Reaction outcome loss': 0.8299479012586632, 'Total loss': 0.8299479012586632}
2022-11-23 01:32:12,556 INFO:     Found new best model at epoch 47
2022-11-23 01:32:12,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:12,557 INFO:     Epoch: 48
2022-11-23 01:32:13,418 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8416516862132333, 'Total loss': 0.8416516862132333} | train loss {'Reaction outcome loss': 0.8280901040349687, 'Total loss': 0.8280901040349687}
2022-11-23 01:32:13,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:13,419 INFO:     Epoch: 49
2022-11-23 01:32:14,228 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8121574053710158, 'Total loss': 0.8121574053710158} | train loss {'Reaction outcome loss': 0.8303727921174497, 'Total loss': 0.8303727921174497}
2022-11-23 01:32:14,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:14,228 INFO:     Epoch: 50
2022-11-23 01:32:15,053 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8179464590820399, 'Total loss': 0.8179464590820399} | train loss {'Reaction outcome loss': 0.8300843957735567, 'Total loss': 0.8300843957735567}
2022-11-23 01:32:15,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:15,053 INFO:     Epoch: 51
2022-11-23 01:32:15,851 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.831326353279027, 'Total loss': 0.831326353279027} | train loss {'Reaction outcome loss': 0.8298758124818607, 'Total loss': 0.8298758124818607}
2022-11-23 01:32:15,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:15,851 INFO:     Epoch: 52
2022-11-23 01:32:16,668 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.809079070660201, 'Total loss': 0.809079070660201} | train loss {'Reaction outcome loss': 0.8238025108162238, 'Total loss': 0.8238025108162238}
2022-11-23 01:32:16,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:16,669 INFO:     Epoch: 53
2022-11-23 01:32:17,527 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8093614930456335, 'Total loss': 0.8093614930456335} | train loss {'Reaction outcome loss': 0.8321823874298407, 'Total loss': 0.8321823874298407}
2022-11-23 01:32:17,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:17,527 INFO:     Epoch: 54
2022-11-23 01:32:18,370 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7952408031983809, 'Total loss': 0.7952408031983809} | train loss {'Reaction outcome loss': 0.8288165240871663, 'Total loss': 0.8288165240871663}
2022-11-23 01:32:18,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:18,370 INFO:     Epoch: 55
2022-11-23 01:32:19,246 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8008038171313026, 'Total loss': 0.8008038171313026} | train loss {'Reaction outcome loss': 0.830975921543277, 'Total loss': 0.830975921543277}
2022-11-23 01:32:19,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:19,246 INFO:     Epoch: 56
2022-11-23 01:32:20,081 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8107700503685258, 'Total loss': 0.8107700503685258} | train loss {'Reaction outcome loss': 0.8285354679944564, 'Total loss': 0.8285354679944564}
2022-11-23 01:32:20,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:20,081 INFO:     Epoch: 57
2022-11-23 01:32:20,943 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8309038762341846, 'Total loss': 0.8309038762341846} | train loss {'Reaction outcome loss': 0.8285376323729146, 'Total loss': 0.8285376323729146}
2022-11-23 01:32:20,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:20,943 INFO:     Epoch: 58
2022-11-23 01:32:21,785 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.796041416850957, 'Total loss': 0.796041416850957} | train loss {'Reaction outcome loss': 0.8310003583528558, 'Total loss': 0.8310003583528558}
2022-11-23 01:32:21,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:21,785 INFO:     Epoch: 59
2022-11-23 01:32:22,660 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7959114854986017, 'Total loss': 0.7959114854986017} | train loss {'Reaction outcome loss': 0.8301219886663008, 'Total loss': 0.8301219886663008}
2022-11-23 01:32:22,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:22,660 INFO:     Epoch: 60
2022-11-23 01:32:23,459 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7961600846187635, 'Total loss': 0.7961600846187635} | train loss {'Reaction outcome loss': 0.8301613707931674, 'Total loss': 0.8301613707931674}
2022-11-23 01:32:23,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:23,460 INFO:     Epoch: 61
2022-11-23 01:32:24,283 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8193322616544637, 'Total loss': 0.8193322616544637} | train loss {'Reaction outcome loss': 0.8305210028375898, 'Total loss': 0.8305210028375898}
2022-11-23 01:32:24,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:24,283 INFO:     Epoch: 62
2022-11-23 01:32:25,137 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8008619770407677, 'Total loss': 0.8008619770407677} | train loss {'Reaction outcome loss': 0.8317850820872248, 'Total loss': 0.8317850820872248}
2022-11-23 01:32:25,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:25,137 INFO:     Epoch: 63
2022-11-23 01:32:25,979 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8142410476099361, 'Total loss': 0.8142410476099361} | train loss {'Reaction outcome loss': 0.8364918425375102, 'Total loss': 0.8364918425375102}
2022-11-23 01:32:25,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:25,980 INFO:     Epoch: 64
2022-11-23 01:32:26,828 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7923374089666388, 'Total loss': 0.7923374089666388} | train loss {'Reaction outcome loss': 0.8339313483968073, 'Total loss': 0.8339313483968073}
2022-11-23 01:32:26,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:26,828 INFO:     Epoch: 65
2022-11-23 01:32:27,684 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8039394319057465, 'Total loss': 0.8039394319057465} | train loss {'Reaction outcome loss': 0.8314962935690977, 'Total loss': 0.8314962935690977}
2022-11-23 01:32:27,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:27,685 INFO:     Epoch: 66
2022-11-23 01:32:28,497 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8040966818278487, 'Total loss': 0.8040966818278487} | train loss {'Reaction outcome loss': 0.8293148656280673, 'Total loss': 0.8293148656280673}
2022-11-23 01:32:28,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:28,498 INFO:     Epoch: 67
2022-11-23 01:32:29,323 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8083221919157288, 'Total loss': 0.8083221919157288} | train loss {'Reaction outcome loss': 0.8283196823937552, 'Total loss': 0.8283196823937552}
2022-11-23 01:32:29,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:29,324 INFO:     Epoch: 68
2022-11-23 01:32:30,164 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8113434294408018, 'Total loss': 0.8113434294408018} | train loss {'Reaction outcome loss': 0.8303784566266196, 'Total loss': 0.8303784566266196}
2022-11-23 01:32:30,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:30,165 INFO:     Epoch: 69
2022-11-23 01:32:30,997 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8198302374644713, 'Total loss': 0.8198302374644713} | train loss {'Reaction outcome loss': 0.8345795986603718, 'Total loss': 0.8345795986603718}
2022-11-23 01:32:30,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:30,997 INFO:     Epoch: 70
2022-11-23 01:32:31,851 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8243553909388456, 'Total loss': 0.8243553909388456} | train loss {'Reaction outcome loss': 0.8267968050071172, 'Total loss': 0.8267968050071172}
2022-11-23 01:32:31,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:31,852 INFO:     Epoch: 71
2022-11-23 01:32:32,733 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8209988650950518, 'Total loss': 0.8209988650950518} | train loss {'Reaction outcome loss': 0.8292494318923171, 'Total loss': 0.8292494318923171}
2022-11-23 01:32:32,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:32,733 INFO:     Epoch: 72
2022-11-23 01:32:33,529 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8053998310457576, 'Total loss': 0.8053998310457576} | train loss {'Reaction outcome loss': 0.8312348701515976, 'Total loss': 0.8312348701515976}
2022-11-23 01:32:33,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:33,529 INFO:     Epoch: 73
2022-11-23 01:32:34,322 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8014882789416746, 'Total loss': 0.8014882789416746} | train loss {'Reaction outcome loss': 0.8279639531155022, 'Total loss': 0.8279639531155022}
2022-11-23 01:32:34,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:34,322 INFO:     Epoch: 74
2022-11-23 01:32:35,112 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7831455177881501, 'Total loss': 0.7831455177881501} | train loss {'Reaction outcome loss': 0.8290354030472892, 'Total loss': 0.8290354030472892}
2022-11-23 01:32:35,112 INFO:     Found new best model at epoch 74
2022-11-23 01:32:35,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:35,113 INFO:     Epoch: 75
2022-11-23 01:32:35,906 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7990677153522318, 'Total loss': 0.7990677153522318} | train loss {'Reaction outcome loss': 0.8291119894202874, 'Total loss': 0.8291119894202874}
2022-11-23 01:32:35,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:35,908 INFO:     Epoch: 76
2022-11-23 01:32:36,719 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8068062778223645, 'Total loss': 0.8068062778223645} | train loss {'Reaction outcome loss': 0.8343089267915609, 'Total loss': 0.8343089267915609}
2022-11-23 01:32:36,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:36,719 INFO:     Epoch: 77
2022-11-23 01:32:37,526 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8305796818299727, 'Total loss': 0.8305796818299727} | train loss {'Reaction outcome loss': 0.8265888471992648, 'Total loss': 0.8265888471992648}
2022-11-23 01:32:37,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:37,526 INFO:     Epoch: 78
2022-11-23 01:32:38,340 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7940597290342505, 'Total loss': 0.7940597290342505} | train loss {'Reaction outcome loss': 0.8297759199020814, 'Total loss': 0.8297759199020814}
2022-11-23 01:32:38,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:38,341 INFO:     Epoch: 79
2022-11-23 01:32:39,155 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7877536071464419, 'Total loss': 0.7877536071464419} | train loss {'Reaction outcome loss': 0.8266960663454873, 'Total loss': 0.8266960663454873}
2022-11-23 01:32:39,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:39,155 INFO:     Epoch: 80
2022-11-23 01:32:39,992 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8167567016048864, 'Total loss': 0.8167567016048864} | train loss {'Reaction outcome loss': 0.8287257834356658, 'Total loss': 0.8287257834356658}
2022-11-23 01:32:39,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:39,992 INFO:     Epoch: 81
2022-11-23 01:32:40,824 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8153873397545381, 'Total loss': 0.8153873397545381} | train loss {'Reaction outcome loss': 0.8325743357745968, 'Total loss': 0.8325743357745968}
2022-11-23 01:32:40,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:40,825 INFO:     Epoch: 82
2022-11-23 01:32:41,713 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7942798249423504, 'Total loss': 0.7942798249423504} | train loss {'Reaction outcome loss': 0.8284076654181188, 'Total loss': 0.8284076654181188}
2022-11-23 01:32:41,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:41,713 INFO:     Epoch: 83
2022-11-23 01:32:42,595 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8163188391111114, 'Total loss': 0.8163188391111114} | train loss {'Reaction outcome loss': 0.8239139870721467, 'Total loss': 0.8239139870721467}
2022-11-23 01:32:42,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:42,595 INFO:     Epoch: 84
2022-11-23 01:32:43,418 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7940013977614316, 'Total loss': 0.7940013977614316} | train loss {'Reaction outcome loss': 0.8319493061425735, 'Total loss': 0.8319493061425735}
2022-11-23 01:32:43,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:43,418 INFO:     Epoch: 85
2022-11-23 01:32:44,248 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.820182204246521, 'Total loss': 0.820182204246521} | train loss {'Reaction outcome loss': 0.8297293907525588, 'Total loss': 0.8297293907525588}
2022-11-23 01:32:44,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:44,249 INFO:     Epoch: 86
2022-11-23 01:32:45,077 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7879843291911212, 'Total loss': 0.7879843291911212} | train loss {'Reaction outcome loss': 0.8271311092133424, 'Total loss': 0.8271311092133424}
2022-11-23 01:32:45,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:45,077 INFO:     Epoch: 87
2022-11-23 01:32:45,920 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7978740808638659, 'Total loss': 0.7978740808638659} | train loss {'Reaction outcome loss': 0.8256211294203388, 'Total loss': 0.8256211294203388}
2022-11-23 01:32:45,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:45,920 INFO:     Epoch: 88
2022-11-23 01:32:46,774 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8057040531526912, 'Total loss': 0.8057040531526912} | train loss {'Reaction outcome loss': 0.8260708738346489, 'Total loss': 0.8260708738346489}
2022-11-23 01:32:46,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:46,775 INFO:     Epoch: 89
2022-11-23 01:32:47,609 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7975055087696422, 'Total loss': 0.7975055087696422} | train loss {'Reaction outcome loss': 0.827958295661576, 'Total loss': 0.827958295661576}
2022-11-23 01:32:47,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:47,609 INFO:     Epoch: 90
2022-11-23 01:32:48,467 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.824225359342315, 'Total loss': 0.824225359342315} | train loss {'Reaction outcome loss': 0.8272479995172851, 'Total loss': 0.8272479995172851}
2022-11-23 01:32:48,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:48,468 INFO:     Epoch: 91
2022-11-23 01:32:49,296 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8016403256492182, 'Total loss': 0.8016403256492182} | train loss {'Reaction outcome loss': 0.8304555608301747, 'Total loss': 0.8304555608301747}
2022-11-23 01:32:49,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:49,297 INFO:     Epoch: 92
2022-11-23 01:32:50,099 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8016223372383551, 'Total loss': 0.8016223372383551} | train loss {'Reaction outcome loss': 0.8313662772275964, 'Total loss': 0.8313662772275964}
2022-11-23 01:32:50,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:50,100 INFO:     Epoch: 93
2022-11-23 01:32:50,943 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.792481388558041, 'Total loss': 0.792481388558041} | train loss {'Reaction outcome loss': 0.8305610656738281, 'Total loss': 0.8305610656738281}
2022-11-23 01:32:50,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:50,943 INFO:     Epoch: 94
2022-11-23 01:32:51,775 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8048293868249113, 'Total loss': 0.8048293868249113} | train loss {'Reaction outcome loss': 0.8284675768443517, 'Total loss': 0.8284675768443517}
2022-11-23 01:32:51,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:51,776 INFO:     Epoch: 95
2022-11-23 01:32:52,636 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8168788680976088, 'Total loss': 0.8168788680976088} | train loss {'Reaction outcome loss': 0.8281049086123097, 'Total loss': 0.8281049086123097}
2022-11-23 01:32:52,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:52,636 INFO:     Epoch: 96
2022-11-23 01:32:53,442 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7947558679363944, 'Total loss': 0.7947558679363944} | train loss {'Reaction outcome loss': 0.8284606517577658, 'Total loss': 0.8284606517577658}
2022-11-23 01:32:53,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:53,443 INFO:     Epoch: 97
2022-11-23 01:32:54,294 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7862437651915983, 'Total loss': 0.7862437651915983} | train loss {'Reaction outcome loss': 0.8273906666405347, 'Total loss': 0.8273906666405347}
2022-11-23 01:32:54,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:54,294 INFO:     Epoch: 98
2022-11-23 01:32:55,092 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8187668872150508, 'Total loss': 0.8187668872150508} | train loss {'Reaction outcome loss': 0.8302590941896244, 'Total loss': 0.8302590941896244}
2022-11-23 01:32:55,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:55,093 INFO:     Epoch: 99
2022-11-23 01:32:55,956 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.854700429873033, 'Total loss': 0.854700429873033} | train loss {'Reaction outcome loss': 0.8288390065942491, 'Total loss': 0.8288390065942491}
2022-11-23 01:32:55,956 INFO:     Best model found after epoch 75 of 100.
2022-11-23 01:32:55,956 INFO:   Done with stage: TRAINING
2022-11-23 01:32:55,956 INFO:   Starting stage: EVALUATION
2022-11-23 01:32:56,087 INFO:   Done with stage: EVALUATION
2022-11-23 01:32:56,087 INFO:   Leaving out SEQ value Fold_3
2022-11-23 01:32:56,100 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-23 01:32:56,101 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:32:56,781 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:32:56,782 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:32:56,854 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:32:56,854 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:32:56,854 INFO:     No hyperparam tuning for this model
2022-11-23 01:32:56,854 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:32:56,854 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:32:56,855 INFO:     None feature selector for col prot
2022-11-23 01:32:56,855 INFO:     None feature selector for col prot
2022-11-23 01:32:56,856 INFO:     None feature selector for col prot
2022-11-23 01:32:56,856 INFO:     None feature selector for col chem
2022-11-23 01:32:56,856 INFO:     None feature selector for col chem
2022-11-23 01:32:56,856 INFO:     None feature selector for col chem
2022-11-23 01:32:56,856 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:32:56,857 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:32:56,858 INFO:     Number of params in model 168571
2022-11-23 01:32:56,862 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:32:56,862 INFO:   Starting stage: TRAINING
2022-11-23 01:32:56,920 INFO:     Val loss before train {'Reaction outcome loss': 1.018151686272838, 'Total loss': 1.018151686272838}
2022-11-23 01:32:56,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:56,921 INFO:     Epoch: 0
2022-11-23 01:32:57,741 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8586049405011263, 'Total loss': 0.8586049405011263} | train loss {'Reaction outcome loss': 0.8749442264741781, 'Total loss': 0.8749442264741781}
2022-11-23 01:32:57,741 INFO:     Found new best model at epoch 0
2022-11-23 01:32:57,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:57,742 INFO:     Epoch: 1
2022-11-23 01:32:58,585 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.835743822157383, 'Total loss': 0.835743822157383} | train loss {'Reaction outcome loss': 0.8415503192921074, 'Total loss': 0.8415503192921074}
2022-11-23 01:32:58,585 INFO:     Found new best model at epoch 1
2022-11-23 01:32:58,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:58,586 INFO:     Epoch: 2
2022-11-23 01:32:59,416 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8143726573749022, 'Total loss': 0.8143726573749022} | train loss {'Reaction outcome loss': 0.8349920383521489, 'Total loss': 0.8349920383521489}
2022-11-23 01:32:59,416 INFO:     Found new best model at epoch 2
2022-11-23 01:32:59,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:32:59,417 INFO:     Epoch: 3
2022-11-23 01:33:00,274 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.851436466655948, 'Total loss': 0.851436466655948} | train loss {'Reaction outcome loss': 0.8346622650720635, 'Total loss': 0.8346622650720635}
2022-11-23 01:33:00,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:00,274 INFO:     Epoch: 4
2022-11-23 01:33:01,087 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8082789047197863, 'Total loss': 0.8082789047197863} | train loss {'Reaction outcome loss': 0.8293215550938431, 'Total loss': 0.8293215550938431}
2022-11-23 01:33:01,087 INFO:     Found new best model at epoch 4
2022-11-23 01:33:01,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:01,088 INFO:     Epoch: 5
2022-11-23 01:33:01,970 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7954696887596087, 'Total loss': 0.7954696887596087} | train loss {'Reaction outcome loss': 0.8240260428311873, 'Total loss': 0.8240260428311873}
2022-11-23 01:33:01,970 INFO:     Found new best model at epoch 5
2022-11-23 01:33:01,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:01,971 INFO:     Epoch: 6
2022-11-23 01:33:02,777 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7981664917685769, 'Total loss': 0.7981664917685769} | train loss {'Reaction outcome loss': 0.8197751073204741, 'Total loss': 0.8197751073204741}
2022-11-23 01:33:02,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:02,778 INFO:     Epoch: 7
2022-11-23 01:33:03,568 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8216890794309702, 'Total loss': 0.8216890794309702} | train loss {'Reaction outcome loss': 0.8194926007669799, 'Total loss': 0.8194926007669799}
2022-11-23 01:33:03,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:03,568 INFO:     Epoch: 8
2022-11-23 01:33:04,403 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8619385253299366, 'Total loss': 0.8619385253299366} | train loss {'Reaction outcome loss': 0.8177600467691616, 'Total loss': 0.8177600467691616}
2022-11-23 01:33:04,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:04,403 INFO:     Epoch: 9
2022-11-23 01:33:05,253 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8131811239502647, 'Total loss': 0.8131811239502647} | train loss {'Reaction outcome loss': 0.8230626331300152, 'Total loss': 0.8230626331300152}
2022-11-23 01:33:05,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:05,254 INFO:     Epoch: 10
2022-11-23 01:33:06,135 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8164345479824326, 'Total loss': 0.8164345479824326} | train loss {'Reaction outcome loss': 0.8232548424175807, 'Total loss': 0.8232548424175807}
2022-11-23 01:33:06,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:06,136 INFO:     Epoch: 11
2022-11-23 01:33:06,971 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8157833848487247, 'Total loss': 0.8157833848487247} | train loss {'Reaction outcome loss': 0.8198222067891335, 'Total loss': 0.8198222067891335}
2022-11-23 01:33:06,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:06,971 INFO:     Epoch: 12
2022-11-23 01:33:07,825 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8076777566562999, 'Total loss': 0.8076777566562999} | train loss {'Reaction outcome loss': 0.8149851443816204, 'Total loss': 0.8149851443816204}
2022-11-23 01:33:07,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:07,826 INFO:     Epoch: 13
2022-11-23 01:33:08,658 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8099060200832107, 'Total loss': 0.8099060200832107} | train loss {'Reaction outcome loss': 0.814025865039047, 'Total loss': 0.814025865039047}
2022-11-23 01:33:08,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:08,658 INFO:     Epoch: 14
2022-11-23 01:33:09,513 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8096028552813963, 'Total loss': 0.8096028552813963} | train loss {'Reaction outcome loss': 0.8195355330194746, 'Total loss': 0.8195355330194746}
2022-11-23 01:33:09,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:09,513 INFO:     Epoch: 15
2022-11-23 01:33:10,328 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8021861497651447, 'Total loss': 0.8021861497651447} | train loss {'Reaction outcome loss': 0.8220843272549766, 'Total loss': 0.8220843272549766}
2022-11-23 01:33:10,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:10,329 INFO:     Epoch: 16
2022-11-23 01:33:11,175 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8099496913227168, 'Total loss': 0.8099496913227168} | train loss {'Reaction outcome loss': 0.8170694083583598, 'Total loss': 0.8170694083583598}
2022-11-23 01:33:11,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:11,175 INFO:     Epoch: 17
2022-11-23 01:33:12,020 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8289529572833668, 'Total loss': 0.8289529572833668} | train loss {'Reaction outcome loss': 0.8199375844731622, 'Total loss': 0.8199375844731622}
2022-11-23 01:33:12,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:12,021 INFO:     Epoch: 18
2022-11-23 01:33:12,867 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8133557669141076, 'Total loss': 0.8133557669141076} | train loss {'Reaction outcome loss': 0.8170312661297467, 'Total loss': 0.8170312661297467}
2022-11-23 01:33:12,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:12,867 INFO:     Epoch: 19
2022-11-23 01:33:13,669 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8202852105552499, 'Total loss': 0.8202852105552499} | train loss {'Reaction outcome loss': 0.8170720066343035, 'Total loss': 0.8170720066343035}
2022-11-23 01:33:13,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:13,670 INFO:     Epoch: 20
2022-11-23 01:33:14,531 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8075296133756638, 'Total loss': 0.8075296133756638} | train loss {'Reaction outcome loss': 0.8175934363384636, 'Total loss': 0.8175934363384636}
2022-11-23 01:33:14,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:14,532 INFO:     Epoch: 21
2022-11-23 01:33:15,347 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8012358126315203, 'Total loss': 0.8012358126315203} | train loss {'Reaction outcome loss': 0.8150093184441937, 'Total loss': 0.8150093184441937}
2022-11-23 01:33:15,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:15,348 INFO:     Epoch: 22
2022-11-23 01:33:16,156 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8043431307781826, 'Total loss': 0.8043431307781826} | train loss {'Reaction outcome loss': 0.8145278020780914, 'Total loss': 0.8145278020780914}
2022-11-23 01:33:16,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:16,156 INFO:     Epoch: 23
2022-11-23 01:33:16,938 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8193780359896746, 'Total loss': 0.8193780359896746} | train loss {'Reaction outcome loss': 0.8131385995417225, 'Total loss': 0.8131385995417225}
2022-11-23 01:33:16,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:16,939 INFO:     Epoch: 24
2022-11-23 01:33:17,744 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8268052271821282, 'Total loss': 0.8268052271821282} | train loss {'Reaction outcome loss': 0.8167644392470924, 'Total loss': 0.8167644392470924}
2022-11-23 01:33:17,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:17,744 INFO:     Epoch: 25
2022-11-23 01:33:18,549 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8016361540014093, 'Total loss': 0.8016361540014093} | train loss {'Reaction outcome loss': 0.8166134913356937, 'Total loss': 0.8166134913356937}
2022-11-23 01:33:18,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:18,550 INFO:     Epoch: 26
2022-11-23 01:33:19,325 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8114685754884373, 'Total loss': 0.8114685754884373} | train loss {'Reaction outcome loss': 0.8134196997905264, 'Total loss': 0.8134196997905264}
2022-11-23 01:33:19,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:19,327 INFO:     Epoch: 27
2022-11-23 01:33:20,154 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8020071373744444, 'Total loss': 0.8020071373744444} | train loss {'Reaction outcome loss': 0.8135404504075342, 'Total loss': 0.8135404504075342}
2022-11-23 01:33:20,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:20,154 INFO:     Epoch: 28
2022-11-23 01:33:20,945 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7977092432027514, 'Total loss': 0.7977092432027514} | train loss {'Reaction outcome loss': 0.8172754048084726, 'Total loss': 0.8172754048084726}
2022-11-23 01:33:20,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:20,945 INFO:     Epoch: 29
2022-11-23 01:33:21,796 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8040655363689769, 'Total loss': 0.8040655363689769} | train loss {'Reaction outcome loss': 0.8103357091241953, 'Total loss': 0.8103357091241953}
2022-11-23 01:33:21,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:21,797 INFO:     Epoch: 30
2022-11-23 01:33:22,633 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8116718991236254, 'Total loss': 0.8116718991236254} | train loss {'Reaction outcome loss': 0.8117060174747389, 'Total loss': 0.8117060174747389}
2022-11-23 01:33:22,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:22,634 INFO:     Epoch: 31
2022-11-23 01:33:23,469 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7948862226171927, 'Total loss': 0.7948862226171927} | train loss {'Reaction outcome loss': 0.8111135010816612, 'Total loss': 0.8111135010816612}
2022-11-23 01:33:23,469 INFO:     Found new best model at epoch 31
2022-11-23 01:33:23,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:23,470 INFO:     Epoch: 32
2022-11-23 01:33:24,304 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8189745450561697, 'Total loss': 0.8189745450561697} | train loss {'Reaction outcome loss': 0.8142001985287179, 'Total loss': 0.8142001985287179}
2022-11-23 01:33:24,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:24,305 INFO:     Epoch: 33
2022-11-23 01:33:25,158 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8222684060985391, 'Total loss': 0.8222684060985391} | train loss {'Reaction outcome loss': 0.8144275642171198, 'Total loss': 0.8144275642171198}
2022-11-23 01:33:25,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:25,158 INFO:     Epoch: 34
2022-11-23 01:33:26,023 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7987717904827811, 'Total loss': 0.7987717904827811} | train loss {'Reaction outcome loss': 0.8168281680467178, 'Total loss': 0.8168281680467178}
2022-11-23 01:33:26,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:26,024 INFO:     Epoch: 35
2022-11-23 01:33:26,883 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8408208116889, 'Total loss': 0.8408208116889} | train loss {'Reaction outcome loss': 0.8110492416790553, 'Total loss': 0.8110492416790553}
2022-11-23 01:33:26,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:26,884 INFO:     Epoch: 36
2022-11-23 01:33:27,687 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7976172051646493, 'Total loss': 0.7976172051646493} | train loss {'Reaction outcome loss': 0.8138462076381762, 'Total loss': 0.8138462076381762}
2022-11-23 01:33:27,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:27,688 INFO:     Epoch: 37
2022-11-23 01:33:28,501 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8119124356995929, 'Total loss': 0.8119124356995929} | train loss {'Reaction outcome loss': 0.8102975821008488, 'Total loss': 0.8102975821008488}
2022-11-23 01:33:28,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:28,501 INFO:     Epoch: 38
2022-11-23 01:33:29,297 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8084539283405651, 'Total loss': 0.8084539283405651} | train loss {'Reaction outcome loss': 0.8132629555098865, 'Total loss': 0.8132629555098865}
2022-11-23 01:33:29,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:29,297 INFO:     Epoch: 39
2022-11-23 01:33:30,088 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7913522774522955, 'Total loss': 0.7913522774522955} | train loss {'Reaction outcome loss': 0.8140145582812173, 'Total loss': 0.8140145582812173}
2022-11-23 01:33:30,088 INFO:     Found new best model at epoch 39
2022-11-23 01:33:30,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:30,089 INFO:     Epoch: 40
2022-11-23 01:33:30,919 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8102226772091605, 'Total loss': 0.8102226772091605} | train loss {'Reaction outcome loss': 0.8143285584693052, 'Total loss': 0.8143285584693052}
2022-11-23 01:33:30,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:30,920 INFO:     Epoch: 41
2022-11-23 01:33:31,706 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8133703402497552, 'Total loss': 0.8133703402497552} | train loss {'Reaction outcome loss': 0.813381914216645, 'Total loss': 0.813381914216645}
2022-11-23 01:33:31,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:31,706 INFO:     Epoch: 42
2022-11-23 01:33:32,490 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7907705293460325, 'Total loss': 0.7907705293460325} | train loss {'Reaction outcome loss': 0.8105197339641804, 'Total loss': 0.8105197339641804}
2022-11-23 01:33:32,491 INFO:     Found new best model at epoch 42
2022-11-23 01:33:32,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:32,491 INFO:     Epoch: 43
2022-11-23 01:33:33,330 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8169908259402622, 'Total loss': 0.8169908259402622} | train loss {'Reaction outcome loss': 0.8175184147698539, 'Total loss': 0.8175184147698539}
2022-11-23 01:33:33,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:33,330 INFO:     Epoch: 44
2022-11-23 01:33:34,154 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8039838495579633, 'Total loss': 0.8039838495579633} | train loss {'Reaction outcome loss': 0.8143443361837037, 'Total loss': 0.8143443361837037}
2022-11-23 01:33:34,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:34,155 INFO:     Epoch: 45
2022-11-23 01:33:34,976 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8118676705793901, 'Total loss': 0.8118676705793901} | train loss {'Reaction outcome loss': 0.8094723666200833, 'Total loss': 0.8094723666200833}
2022-11-23 01:33:34,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:34,976 INFO:     Epoch: 46
2022-11-23 01:33:35,812 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8024869473143057, 'Total loss': 0.8024869473143057} | train loss {'Reaction outcome loss': 0.8087515803015962, 'Total loss': 0.8087515803015962}
2022-11-23 01:33:35,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:35,812 INFO:     Epoch: 47
2022-11-23 01:33:36,599 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8189410404725508, 'Total loss': 0.8189410404725508} | train loss {'Reaction outcome loss': 0.8100099935823557, 'Total loss': 0.8100099935823557}
2022-11-23 01:33:36,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:36,600 INFO:     Epoch: 48
2022-11-23 01:33:37,417 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8045309815894474, 'Total loss': 0.8045309815894474} | train loss {'Reaction outcome loss': 0.8128249809450033, 'Total loss': 0.8128249809450033}
2022-11-23 01:33:37,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:37,417 INFO:     Epoch: 49
2022-11-23 01:33:38,266 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8084929653189399, 'Total loss': 0.8084929653189399} | train loss {'Reaction outcome loss': 0.8169111223853365, 'Total loss': 0.8169111223853365}
2022-11-23 01:33:38,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:38,267 INFO:     Epoch: 50
2022-11-23 01:33:39,090 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7963845269246534, 'Total loss': 0.7963845269246534} | train loss {'Reaction outcome loss': 0.8149276131269884, 'Total loss': 0.8149276131269884}
2022-11-23 01:33:39,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:39,090 INFO:     Epoch: 51
2022-11-23 01:33:39,896 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.793864792720838, 'Total loss': 0.793864792720838} | train loss {'Reaction outcome loss': 0.8144999783866259, 'Total loss': 0.8144999783866259}
2022-11-23 01:33:39,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:39,897 INFO:     Epoch: 52
2022-11-23 01:33:40,747 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.806905556131493, 'Total loss': 0.806905556131493} | train loss {'Reaction outcome loss': 0.8129171924931663, 'Total loss': 0.8129171924931663}
2022-11-23 01:33:40,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:40,747 INFO:     Epoch: 53
2022-11-23 01:33:41,630 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8281515708023851, 'Total loss': 0.8281515708023851} | train loss {'Reaction outcome loss': 0.8127832704660843, 'Total loss': 0.8127832704660843}
2022-11-23 01:33:41,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:41,630 INFO:     Epoch: 54
2022-11-23 01:33:42,470 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7939609241756526, 'Total loss': 0.7939609241756526} | train loss {'Reaction outcome loss': 0.81068374356445, 'Total loss': 0.81068374356445}
2022-11-23 01:33:42,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:42,471 INFO:     Epoch: 55
2022-11-23 01:33:43,314 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7930705127390948, 'Total loss': 0.7930705127390948} | train loss {'Reaction outcome loss': 0.8083801157620488, 'Total loss': 0.8083801157620488}
2022-11-23 01:33:43,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:43,315 INFO:     Epoch: 56
2022-11-23 01:33:44,155 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.78945452618328, 'Total loss': 0.78945452618328} | train loss {'Reaction outcome loss': 0.8108746247632163, 'Total loss': 0.8108746247632163}
2022-11-23 01:33:44,155 INFO:     Found new best model at epoch 56
2022-11-23 01:33:44,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:44,156 INFO:     Epoch: 57
2022-11-23 01:33:44,961 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8269185640595176, 'Total loss': 0.8269185640595176} | train loss {'Reaction outcome loss': 0.811560410991007, 'Total loss': 0.811560410991007}
2022-11-23 01:33:44,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:44,962 INFO:     Epoch: 58
2022-11-23 01:33:45,817 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8167035058140755, 'Total loss': 0.8167035058140755} | train loss {'Reaction outcome loss': 0.8136514207538293, 'Total loss': 0.8136514207538293}
2022-11-23 01:33:45,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:45,818 INFO:     Epoch: 59
2022-11-23 01:33:46,705 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8178018683736975, 'Total loss': 0.8178018683736975} | train loss {'Reaction outcome loss': 0.812479331906961, 'Total loss': 0.812479331906961}
2022-11-23 01:33:46,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:46,705 INFO:     Epoch: 60
2022-11-23 01:33:47,506 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8250360536304387, 'Total loss': 0.8250360536304387} | train loss {'Reaction outcome loss': 0.8112929875753364, 'Total loss': 0.8112929875753364}
2022-11-23 01:33:47,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:47,506 INFO:     Epoch: 61
2022-11-23 01:33:48,341 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8568599704991687, 'Total loss': 0.8568599704991687} | train loss {'Reaction outcome loss': 0.812461265252561, 'Total loss': 0.812461265252561}
2022-11-23 01:33:48,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:48,341 INFO:     Epoch: 62
2022-11-23 01:33:49,173 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.798120877282186, 'Total loss': 0.798120877282186} | train loss {'Reaction outcome loss': 0.8148314074594147, 'Total loss': 0.8148314074594147}
2022-11-23 01:33:49,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:49,174 INFO:     Epoch: 63
2022-11-23 01:33:50,027 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7924219227649949, 'Total loss': 0.7924219227649949} | train loss {'Reaction outcome loss': 0.8101575673842917, 'Total loss': 0.8101575673842917}
2022-11-23 01:33:50,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:50,028 INFO:     Epoch: 64
2022-11-23 01:33:50,892 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8030543679540808, 'Total loss': 0.8030543679540808} | train loss {'Reaction outcome loss': 0.8114136970773035, 'Total loss': 0.8114136970773035}
2022-11-23 01:33:50,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:50,892 INFO:     Epoch: 65
2022-11-23 01:33:51,720 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7978834096680988, 'Total loss': 0.7978834096680988} | train loss {'Reaction outcome loss': 0.812607327286078, 'Total loss': 0.812607327286078}
2022-11-23 01:33:51,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:51,721 INFO:     Epoch: 66
2022-11-23 01:33:52,558 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8139337328347293, 'Total loss': 0.8139337328347293} | train loss {'Reaction outcome loss': 0.8121247941133928, 'Total loss': 0.8121247941133928}
2022-11-23 01:33:52,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:52,559 INFO:     Epoch: 67
2022-11-23 01:33:53,395 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7814499363303185, 'Total loss': 0.7814499363303185} | train loss {'Reaction outcome loss': 0.8123058765518422, 'Total loss': 0.8123058765518422}
2022-11-23 01:33:53,395 INFO:     Found new best model at epoch 67
2022-11-23 01:33:53,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:53,396 INFO:     Epoch: 68
2022-11-23 01:33:54,209 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8068685843185945, 'Total loss': 0.8068685843185945} | train loss {'Reaction outcome loss': 0.8118940824148606, 'Total loss': 0.8118940824148606}
2022-11-23 01:33:54,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:54,209 INFO:     Epoch: 69
2022-11-23 01:33:54,985 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.842643453316255, 'Total loss': 0.842643453316255} | train loss {'Reaction outcome loss': 0.804948427360885, 'Total loss': 0.804948427360885}
2022-11-23 01:33:54,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:54,986 INFO:     Epoch: 70
2022-11-23 01:33:55,793 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.797740061852065, 'Total loss': 0.797740061852065} | train loss {'Reaction outcome loss': 0.8137435591950708, 'Total loss': 0.8137435591950708}
2022-11-23 01:33:55,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:55,793 INFO:     Epoch: 71
2022-11-23 01:33:56,609 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7842330492355607, 'Total loss': 0.7842330492355607} | train loss {'Reaction outcome loss': 0.808630164058841, 'Total loss': 0.808630164058841}
2022-11-23 01:33:56,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:56,610 INFO:     Epoch: 72
2022-11-23 01:33:57,481 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8228244923732497, 'Total loss': 0.8228244923732497} | train loss {'Reaction outcome loss': 0.8101649853647972, 'Total loss': 0.8101649853647972}
2022-11-23 01:33:57,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:57,481 INFO:     Epoch: 73
2022-11-23 01:33:58,305 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8099042617461898, 'Total loss': 0.8099042617461898} | train loss {'Reaction outcome loss': 0.8127197673126143, 'Total loss': 0.8127197673126143}
2022-11-23 01:33:58,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:58,305 INFO:     Epoch: 74
2022-11-23 01:33:59,134 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8385989232496782, 'Total loss': 0.8385989232496782} | train loss {'Reaction outcome loss': 0.8105663572038923, 'Total loss': 0.8105663572038923}
2022-11-23 01:33:59,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:59,134 INFO:     Epoch: 75
2022-11-23 01:33:59,966 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8057187975130298, 'Total loss': 0.8057187975130298} | train loss {'Reaction outcome loss': 0.8115993547196291, 'Total loss': 0.8115993547196291}
2022-11-23 01:33:59,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:33:59,967 INFO:     Epoch: 76
2022-11-23 01:34:00,763 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8310916207053445, 'Total loss': 0.8310916207053445} | train loss {'Reaction outcome loss': 0.8077065270774219, 'Total loss': 0.8077065270774219}
2022-11-23 01:34:00,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:00,763 INFO:     Epoch: 77
2022-11-23 01:34:01,552 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7967906506224112, 'Total loss': 0.7967906506224112} | train loss {'Reaction outcome loss': 0.8137512484375311, 'Total loss': 0.8137512484375311}
2022-11-23 01:34:01,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:01,552 INFO:     Epoch: 78
2022-11-23 01:34:02,388 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8163932297717441, 'Total loss': 0.8163932297717441} | train loss {'Reaction outcome loss': 0.8057718401052514, 'Total loss': 0.8057718401052514}
2022-11-23 01:34:02,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:02,388 INFO:     Epoch: 79
2022-11-23 01:34:03,235 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8151094581593167, 'Total loss': 0.8151094581593167} | train loss {'Reaction outcome loss': 0.8119388729942089, 'Total loss': 0.8119388729942089}
2022-11-23 01:34:03,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:03,235 INFO:     Epoch: 80
2022-11-23 01:34:04,075 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8201476037502289, 'Total loss': 0.8201476037502289} | train loss {'Reaction outcome loss': 0.8149598030411467, 'Total loss': 0.8149598030411467}
2022-11-23 01:34:04,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:04,076 INFO:     Epoch: 81
2022-11-23 01:34:04,904 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7987834045832808, 'Total loss': 0.7987834045832808} | train loss {'Reaction outcome loss': 0.8104011562405801, 'Total loss': 0.8104011562405801}
2022-11-23 01:34:04,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:04,904 INFO:     Epoch: 82
2022-11-23 01:34:05,724 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8027879751541398, 'Total loss': 0.8027879751541398} | train loss {'Reaction outcome loss': 0.813534843556735, 'Total loss': 0.813534843556735}
2022-11-23 01:34:05,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:05,724 INFO:     Epoch: 83
2022-11-23 01:34:06,526 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8245909647508101, 'Total loss': 0.8245909647508101} | train loss {'Reaction outcome loss': 0.8077685483864375, 'Total loss': 0.8077685483864375}
2022-11-23 01:34:06,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:06,526 INFO:     Epoch: 84
2022-11-23 01:34:07,348 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8031947741454298, 'Total loss': 0.8031947741454298} | train loss {'Reaction outcome loss': 0.8113625362211344, 'Total loss': 0.8113625362211344}
2022-11-23 01:34:07,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:07,348 INFO:     Epoch: 85
2022-11-23 01:34:08,148 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8138959204608743, 'Total loss': 0.8138959204608743} | train loss {'Reaction outcome loss': 0.8081283464723704, 'Total loss': 0.8081283464723704}
2022-11-23 01:34:08,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:08,149 INFO:     Epoch: 86
2022-11-23 01:34:08,935 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.795423418960788, 'Total loss': 0.795423418960788} | train loss {'Reaction outcome loss': 0.8100407878963315, 'Total loss': 0.8100407878963315}
2022-11-23 01:34:08,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:08,936 INFO:     Epoch: 87
2022-11-23 01:34:09,762 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.821175220337781, 'Total loss': 0.821175220337781} | train loss {'Reaction outcome loss': 0.8068050697141764, 'Total loss': 0.8068050697141764}
2022-11-23 01:34:09,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:09,762 INFO:     Epoch: 88
2022-11-23 01:34:10,538 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8028606575998393, 'Total loss': 0.8028606575998393} | train loss {'Reaction outcome loss': 0.8096565269694036, 'Total loss': 0.8096565269694036}
2022-11-23 01:34:10,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:10,538 INFO:     Epoch: 89
2022-11-23 01:34:11,328 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8023641949350183, 'Total loss': 0.8023641949350183} | train loss {'Reaction outcome loss': 0.8103698779125603, 'Total loss': 0.8103698779125603}
2022-11-23 01:34:11,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:11,328 INFO:     Epoch: 90
2022-11-23 01:34:12,160 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7955153767358173, 'Total loss': 0.7955153767358173} | train loss {'Reaction outcome loss': 0.8090177004434624, 'Total loss': 0.8090177004434624}
2022-11-23 01:34:12,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:12,160 INFO:     Epoch: 91
2022-11-23 01:34:12,982 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8049757751551542, 'Total loss': 0.8049757751551542} | train loss {'Reaction outcome loss': 0.8085739416735512, 'Total loss': 0.8085739416735512}
2022-11-23 01:34:12,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:12,982 INFO:     Epoch: 92
2022-11-23 01:34:13,810 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8162691606716677, 'Total loss': 0.8162691606716677} | train loss {'Reaction outcome loss': 0.8105731318191606, 'Total loss': 0.8105731318191606}
2022-11-23 01:34:13,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:13,810 INFO:     Epoch: 93
2022-11-23 01:34:14,575 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.821816318414428, 'Total loss': 0.821816318414428} | train loss {'Reaction outcome loss': 0.807611229346723, 'Total loss': 0.807611229346723}
2022-11-23 01:34:14,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:14,575 INFO:     Epoch: 94
2022-11-23 01:34:15,384 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8006065982309255, 'Total loss': 0.8006065982309255} | train loss {'Reaction outcome loss': 0.8094206850139463, 'Total loss': 0.8094206850139463}
2022-11-23 01:34:15,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:15,384 INFO:     Epoch: 95
2022-11-23 01:34:16,153 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7925671535459432, 'Total loss': 0.7925671535459432} | train loss {'Reaction outcome loss': 0.8058973258855392, 'Total loss': 0.8058973258855392}
2022-11-23 01:34:16,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:16,154 INFO:     Epoch: 96
2022-11-23 01:34:16,949 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.806190051138401, 'Total loss': 0.806190051138401} | train loss {'Reaction outcome loss': 0.8101463367744368, 'Total loss': 0.8101463367744368}
2022-11-23 01:34:16,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:16,950 INFO:     Epoch: 97
2022-11-23 01:34:17,731 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8122010217471556, 'Total loss': 0.8122010217471556} | train loss {'Reaction outcome loss': 0.8075634149872527, 'Total loss': 0.8075634149872527}
2022-11-23 01:34:17,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:17,732 INFO:     Epoch: 98
2022-11-23 01:34:18,563 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.806854322552681, 'Total loss': 0.806854322552681} | train loss {'Reaction outcome loss': 0.811891183317924, 'Total loss': 0.811891183317924}
2022-11-23 01:34:18,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:18,563 INFO:     Epoch: 99
2022-11-23 01:34:19,343 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.815746100450104, 'Total loss': 0.815746100450104} | train loss {'Reaction outcome loss': 0.8064455456879674, 'Total loss': 0.8064455456879674}
2022-11-23 01:34:19,343 INFO:     Best model found after epoch 68 of 100.
2022-11-23 01:34:19,344 INFO:   Done with stage: TRAINING
2022-11-23 01:34:19,344 INFO:   Starting stage: EVALUATION
2022-11-23 01:34:19,474 INFO:   Done with stage: EVALUATION
2022-11-23 01:34:19,474 INFO:   Leaving out SEQ value Fold_4
2022-11-23 01:34:19,487 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 01:34:19,487 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:34:20,158 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:34:20,159 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:34:20,229 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:34:20,229 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:34:20,230 INFO:     No hyperparam tuning for this model
2022-11-23 01:34:20,230 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:34:20,230 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:34:20,231 INFO:     None feature selector for col prot
2022-11-23 01:34:20,231 INFO:     None feature selector for col prot
2022-11-23 01:34:20,231 INFO:     None feature selector for col prot
2022-11-23 01:34:20,231 INFO:     None feature selector for col chem
2022-11-23 01:34:20,232 INFO:     None feature selector for col chem
2022-11-23 01:34:20,232 INFO:     None feature selector for col chem
2022-11-23 01:34:20,232 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:34:20,232 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:34:20,233 INFO:     Number of params in model 168571
2022-11-23 01:34:20,237 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:34:20,237 INFO:   Starting stage: TRAINING
2022-11-23 01:34:20,295 INFO:     Val loss before train {'Reaction outcome loss': 1.007212449203838, 'Total loss': 1.007212449203838}
2022-11-23 01:34:20,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:20,295 INFO:     Epoch: 0
2022-11-23 01:34:21,113 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8391112624244257, 'Total loss': 0.8391112624244257} | train loss {'Reaction outcome loss': 0.8838367761387999, 'Total loss': 0.8838367761387999}
2022-11-23 01:34:21,114 INFO:     Found new best model at epoch 0
2022-11-23 01:34:21,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:21,114 INFO:     Epoch: 1
2022-11-23 01:34:21,937 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7932638160207055, 'Total loss': 0.7932638160207055} | train loss {'Reaction outcome loss': 0.8427062048482509, 'Total loss': 0.8427062048482509}
2022-11-23 01:34:21,938 INFO:     Found new best model at epoch 1
2022-11-23 01:34:21,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:21,939 INFO:     Epoch: 2
2022-11-23 01:34:22,784 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8107526898384094, 'Total loss': 0.8107526898384094} | train loss {'Reaction outcome loss': 0.8393518549469319, 'Total loss': 0.8393518549469319}
2022-11-23 01:34:22,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:22,785 INFO:     Epoch: 3
2022-11-23 01:34:23,615 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8156435232270848, 'Total loss': 0.8156435232270848} | train loss {'Reaction outcome loss': 0.8394857634175644, 'Total loss': 0.8394857634175644}
2022-11-23 01:34:23,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:23,616 INFO:     Epoch: 4
2022-11-23 01:34:24,451 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7943288622932001, 'Total loss': 0.7943288622932001} | train loss {'Reaction outcome loss': 0.8288829278970055, 'Total loss': 0.8288829278970055}
2022-11-23 01:34:24,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:24,451 INFO:     Epoch: 5
2022-11-23 01:34:25,252 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.765309864147143, 'Total loss': 0.765309864147143} | train loss {'Reaction outcome loss': 0.8251299213783944, 'Total loss': 0.8251299213783944}
2022-11-23 01:34:25,252 INFO:     Found new best model at epoch 5
2022-11-23 01:34:25,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:25,253 INFO:     Epoch: 6
2022-11-23 01:34:26,037 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7635020769455216, 'Total loss': 0.7635020769455216} | train loss {'Reaction outcome loss': 0.8205586977091878, 'Total loss': 0.8205586977091878}
2022-11-23 01:34:26,037 INFO:     Found new best model at epoch 6
2022-11-23 01:34:26,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:26,038 INFO:     Epoch: 7
2022-11-23 01:34:26,846 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.765713901005008, 'Total loss': 0.765713901005008} | train loss {'Reaction outcome loss': 0.8191806198614329, 'Total loss': 0.8191806198614329}
2022-11-23 01:34:26,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:26,846 INFO:     Epoch: 8
2022-11-23 01:34:27,664 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7958790158683603, 'Total loss': 0.7958790158683603} | train loss {'Reaction outcome loss': 0.8229348946679459, 'Total loss': 0.8229348946679459}
2022-11-23 01:34:27,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:27,664 INFO:     Epoch: 9
2022-11-23 01:34:28,506 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7642298699779944, 'Total loss': 0.7642298699779944} | train loss {'Reaction outcome loss': 0.8256185246623962, 'Total loss': 0.8256185246623962}
2022-11-23 01:34:28,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:28,507 INFO:     Epoch: 10
2022-11-23 01:34:29,328 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8038729727268219, 'Total loss': 0.8038729727268219} | train loss {'Reaction outcome loss': 0.8140896208704966, 'Total loss': 0.8140896208704966}
2022-11-23 01:34:29,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:29,328 INFO:     Epoch: 11
2022-11-23 01:34:30,153 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7580165565013885, 'Total loss': 0.7580165565013885} | train loss {'Reaction outcome loss': 0.8230034566601279, 'Total loss': 0.8230034566601279}
2022-11-23 01:34:30,153 INFO:     Found new best model at epoch 11
2022-11-23 01:34:30,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:30,154 INFO:     Epoch: 12
2022-11-23 01:34:31,031 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7641293203288858, 'Total loss': 0.7641293203288858} | train loss {'Reaction outcome loss': 0.8068389290046354, 'Total loss': 0.8068389290046354}
2022-11-23 01:34:31,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:31,031 INFO:     Epoch: 13
2022-11-23 01:34:31,886 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7811360040848906, 'Total loss': 0.7811360040848906} | train loss {'Reaction outcome loss': 0.8142470188951685, 'Total loss': 0.8142470188951685}
2022-11-23 01:34:31,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:31,886 INFO:     Epoch: 14
2022-11-23 01:34:32,731 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7757423940030012, 'Total loss': 0.7757423940030012} | train loss {'Reaction outcome loss': 0.8174827536228697, 'Total loss': 0.8174827536228697}
2022-11-23 01:34:32,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:32,732 INFO:     Epoch: 15
2022-11-23 01:34:33,535 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.76210152764212, 'Total loss': 0.76210152764212} | train loss {'Reaction outcome loss': 0.8124723107467297, 'Total loss': 0.8124723107467297}
2022-11-23 01:34:33,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:33,535 INFO:     Epoch: 16
2022-11-23 01:34:34,346 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7760990262031555, 'Total loss': 0.7760990262031555} | train loss {'Reaction outcome loss': 0.8139364961459328, 'Total loss': 0.8139364961459328}
2022-11-23 01:34:34,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:34,346 INFO:     Epoch: 17
2022-11-23 01:34:35,165 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7686834159222516, 'Total loss': 0.7686834159222516} | train loss {'Reaction outcome loss': 0.8111540144573339, 'Total loss': 0.8111540144573339}
2022-11-23 01:34:35,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:35,165 INFO:     Epoch: 18
2022-11-23 01:34:35,929 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7841311652551998, 'Total loss': 0.7841311652551998} | train loss {'Reaction outcome loss': 0.8188638023519323, 'Total loss': 0.8188638023519323}
2022-11-23 01:34:35,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:35,930 INFO:     Epoch: 19
2022-11-23 01:34:36,777 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.772607842629606, 'Total loss': 0.772607842629606} | train loss {'Reaction outcome loss': 0.8143666366092589, 'Total loss': 0.8143666366092589}
2022-11-23 01:34:36,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:36,777 INFO:     Epoch: 20
2022-11-23 01:34:37,590 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7667994404380972, 'Total loss': 0.7667994404380972} | train loss {'Reaction outcome loss': 0.8134583207035837, 'Total loss': 0.8134583207035837}
2022-11-23 01:34:37,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:37,591 INFO:     Epoch: 21
2022-11-23 01:34:38,372 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7733443237163804, 'Total loss': 0.7733443237163804} | train loss {'Reaction outcome loss': 0.8094146476704099, 'Total loss': 0.8094146476704099}
2022-11-23 01:34:38,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:38,372 INFO:     Epoch: 22
2022-11-23 01:34:39,205 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7510957758535038, 'Total loss': 0.7510957758535038} | train loss {'Reaction outcome loss': 0.8106909256715041, 'Total loss': 0.8106909256715041}
2022-11-23 01:34:39,205 INFO:     Found new best model at epoch 22
2022-11-23 01:34:39,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:39,206 INFO:     Epoch: 23
2022-11-23 01:34:40,023 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7643340189348568, 'Total loss': 0.7643340189348568} | train loss {'Reaction outcome loss': 0.8090716164242401, 'Total loss': 0.8090716164242401}
2022-11-23 01:34:40,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:40,024 INFO:     Epoch: 24
2022-11-23 01:34:40,839 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7766055884686384, 'Total loss': 0.7766055884686384} | train loss {'Reaction outcome loss': 0.8073823874899251, 'Total loss': 0.8073823874899251}
2022-11-23 01:34:40,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:40,840 INFO:     Epoch: 25
2022-11-23 01:34:41,649 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7561298351396214, 'Total loss': 0.7561298351396214} | train loss {'Reaction outcome loss': 0.8066979731746048, 'Total loss': 0.8066979731746048}
2022-11-23 01:34:41,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:41,649 INFO:     Epoch: 26
2022-11-23 01:34:42,454 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8034735884178769, 'Total loss': 0.8034735884178769} | train loss {'Reaction outcome loss': 0.8174078919385609, 'Total loss': 0.8174078919385609}
2022-11-23 01:34:42,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:42,454 INFO:     Epoch: 27
2022-11-23 01:34:43,277 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7762167799201879, 'Total loss': 0.7762167799201879} | train loss {'Reaction outcome loss': 0.8099021408480671, 'Total loss': 0.8099021408480671}
2022-11-23 01:34:43,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:43,278 INFO:     Epoch: 28
2022-11-23 01:34:44,060 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7768425088037144, 'Total loss': 0.7768425088037144} | train loss {'Reaction outcome loss': 0.8185250836345348, 'Total loss': 0.8185250836345348}
2022-11-23 01:34:44,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:44,060 INFO:     Epoch: 29
2022-11-23 01:34:44,877 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7649543048305945, 'Total loss': 0.7649543048305945} | train loss {'Reaction outcome loss': 0.8190145316394234, 'Total loss': 0.8190145316394234}
2022-11-23 01:34:44,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:44,877 INFO:     Epoch: 30
2022-11-23 01:34:45,771 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.785157402808016, 'Total loss': 0.785157402808016} | train loss {'Reaction outcome loss': 0.8136799026597367, 'Total loss': 0.8136799026597367}
2022-11-23 01:34:45,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:45,772 INFO:     Epoch: 31
2022-11-23 01:34:46,627 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8100009723143144, 'Total loss': 0.8100009723143144} | train loss {'Reaction outcome loss': 0.8195494233596663, 'Total loss': 0.8195494233596663}
2022-11-23 01:34:46,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:46,627 INFO:     Epoch: 32
2022-11-23 01:34:47,524 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7685272226279433, 'Total loss': 0.7685272226279433} | train loss {'Reaction outcome loss': 0.8149674100431836, 'Total loss': 0.8149674100431836}
2022-11-23 01:34:47,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:47,525 INFO:     Epoch: 33
2022-11-23 01:34:48,437 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7784550840204413, 'Total loss': 0.7784550840204413} | train loss {'Reaction outcome loss': 0.8074554587424043, 'Total loss': 0.8074554587424043}
2022-11-23 01:34:48,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:48,437 INFO:     Epoch: 34
2022-11-23 01:34:49,329 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7699664289301092, 'Total loss': 0.7699664289301092} | train loss {'Reaction outcome loss': 0.8074297553554237, 'Total loss': 0.8074297553554237}
2022-11-23 01:34:49,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:49,333 INFO:     Epoch: 35
2022-11-23 01:34:50,195 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7679960944435813, 'Total loss': 0.7679960944435813} | train loss {'Reaction outcome loss': 0.8092105442937086, 'Total loss': 0.8092105442937086}
2022-11-23 01:34:50,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:50,195 INFO:     Epoch: 36
2022-11-23 01:34:51,008 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7632816894487902, 'Total loss': 0.7632816894487902} | train loss {'Reaction outcome loss': 0.8097446010889191, 'Total loss': 0.8097446010889191}
2022-11-23 01:34:51,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:51,009 INFO:     Epoch: 37
2022-11-23 01:34:51,830 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7655463022264567, 'Total loss': 0.7655463022264567} | train loss {'Reaction outcome loss': 0.8089817196492725, 'Total loss': 0.8089817196492725}
2022-11-23 01:34:51,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:51,831 INFO:     Epoch: 38
2022-11-23 01:34:52,621 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7730647034265778, 'Total loss': 0.7730647034265778} | train loss {'Reaction outcome loss': 0.8094964968530756, 'Total loss': 0.8094964968530756}
2022-11-23 01:34:52,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:52,623 INFO:     Epoch: 39
2022-11-23 01:34:53,463 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7710868242112073, 'Total loss': 0.7710868242112073} | train loss {'Reaction outcome loss': 0.8106849629145402, 'Total loss': 0.8106849629145402}
2022-11-23 01:34:53,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:53,463 INFO:     Epoch: 40
2022-11-23 01:34:54,297 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7625516260212118, 'Total loss': 0.7625516260212118} | train loss {'Reaction outcome loss': 0.8167180910042906, 'Total loss': 0.8167180910042906}
2022-11-23 01:34:54,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:54,297 INFO:     Epoch: 41
2022-11-23 01:34:55,136 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7693578451871872, 'Total loss': 0.7693578451871872} | train loss {'Reaction outcome loss': 0.8127960242964478, 'Total loss': 0.8127960242964478}
2022-11-23 01:34:55,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:55,136 INFO:     Epoch: 42
2022-11-23 01:34:55,942 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.768260965293104, 'Total loss': 0.768260965293104} | train loss {'Reaction outcome loss': 0.812112145548166, 'Total loss': 0.812112145548166}
2022-11-23 01:34:55,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:55,942 INFO:     Epoch: 43
2022-11-23 01:34:56,747 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7533024657856334, 'Total loss': 0.7533024657856334} | train loss {'Reaction outcome loss': 0.8032568648517856, 'Total loss': 0.8032568648517856}
2022-11-23 01:34:56,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:56,748 INFO:     Epoch: 44
2022-11-23 01:34:57,581 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7595517269589684, 'Total loss': 0.7595517269589684} | train loss {'Reaction outcome loss': 0.8111469336004875, 'Total loss': 0.8111469336004875}
2022-11-23 01:34:57,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:57,581 INFO:     Epoch: 45
2022-11-23 01:34:58,367 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7541580620137128, 'Total loss': 0.7541580620137128} | train loss {'Reaction outcome loss': 0.8048905907613546, 'Total loss': 0.8048905907613546}
2022-11-23 01:34:58,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:58,367 INFO:     Epoch: 46
2022-11-23 01:34:59,199 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7907109788872979, 'Total loss': 0.7907109788872979} | train loss {'Reaction outcome loss': 0.814196336727876, 'Total loss': 0.814196336727876}
2022-11-23 01:34:59,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:34:59,200 INFO:     Epoch: 47
2022-11-23 01:35:00,051 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7666460641405799, 'Total loss': 0.7666460641405799} | train loss {'Reaction outcome loss': 0.8096396721718524, 'Total loss': 0.8096396721718524}
2022-11-23 01:35:00,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:00,052 INFO:     Epoch: 48
2022-11-23 01:35:00,851 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7536421804265543, 'Total loss': 0.7536421804265543} | train loss {'Reaction outcome loss': 0.8104647630863344, 'Total loss': 0.8104647630863344}
2022-11-23 01:35:00,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:00,851 INFO:     Epoch: 49
2022-11-23 01:35:01,676 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.768322120335969, 'Total loss': 0.768322120335969} | train loss {'Reaction outcome loss': 0.807600650106847, 'Total loss': 0.807600650106847}
2022-11-23 01:35:01,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:01,677 INFO:     Epoch: 50
2022-11-23 01:35:02,468 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7585916153409265, 'Total loss': 0.7585916153409265} | train loss {'Reaction outcome loss': 0.8096162635787778, 'Total loss': 0.8096162635787778}
2022-11-23 01:35:02,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:02,468 INFO:     Epoch: 51
2022-11-23 01:35:03,309 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7827742810953747, 'Total loss': 0.7827742810953747} | train loss {'Reaction outcome loss': 0.8060733757551141, 'Total loss': 0.8060733757551141}
2022-11-23 01:35:03,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:03,310 INFO:     Epoch: 52
2022-11-23 01:35:04,096 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7619076350873167, 'Total loss': 0.7619076350873167} | train loss {'Reaction outcome loss': 0.8082952922896335, 'Total loss': 0.8082952922896335}
2022-11-23 01:35:04,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:04,096 INFO:     Epoch: 53
2022-11-23 01:35:04,897 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7580424106933854, 'Total loss': 0.7580424106933854} | train loss {'Reaction outcome loss': 0.8118972690240575, 'Total loss': 0.8118972690240575}
2022-11-23 01:35:04,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:04,897 INFO:     Epoch: 54
2022-11-23 01:35:05,706 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7738149443810637, 'Total loss': 0.7738149443810637} | train loss {'Reaction outcome loss': 0.8092162471551162, 'Total loss': 0.8092162471551162}
2022-11-23 01:35:05,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:05,706 INFO:     Epoch: 55
2022-11-23 01:35:06,522 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7594973065636375, 'Total loss': 0.7594973065636375} | train loss {'Reaction outcome loss': 0.8132244570535204, 'Total loss': 0.8132244570535204}
2022-11-23 01:35:06,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:06,522 INFO:     Epoch: 56
2022-11-23 01:35:07,382 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.771393593062054, 'Total loss': 0.771393593062054} | train loss {'Reaction outcome loss': 0.8104771923439705, 'Total loss': 0.8104771923439705}
2022-11-23 01:35:07,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:07,382 INFO:     Epoch: 57
2022-11-23 01:35:08,192 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7861335142092272, 'Total loss': 0.7861335142092272} | train loss {'Reaction outcome loss': 0.8143733292214783, 'Total loss': 0.8143733292214783}
2022-11-23 01:35:08,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:08,192 INFO:     Epoch: 58
2022-11-23 01:35:08,995 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7528887384317138, 'Total loss': 0.7528887384317138} | train loss {'Reaction outcome loss': 0.8283795485129724, 'Total loss': 0.8283795485129724}
2022-11-23 01:35:08,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:08,995 INFO:     Epoch: 59
2022-11-23 01:35:09,827 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.78113757412542, 'Total loss': 0.78113757412542} | train loss {'Reaction outcome loss': 0.815209059580135, 'Total loss': 0.815209059580135}
2022-11-23 01:35:09,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:09,827 INFO:     Epoch: 60
2022-11-23 01:35:10,617 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7695700837807222, 'Total loss': 0.7695700837807222} | train loss {'Reaction outcome loss': 0.8142257870932822, 'Total loss': 0.8142257870932822}
2022-11-23 01:35:10,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:10,617 INFO:     Epoch: 61
2022-11-23 01:35:11,437 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7598768161101774, 'Total loss': 0.7598768161101774} | train loss {'Reaction outcome loss': 0.811513440570368, 'Total loss': 0.811513440570368}
2022-11-23 01:35:11,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:11,438 INFO:     Epoch: 62
2022-11-23 01:35:12,264 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7494051883166487, 'Total loss': 0.7494051883166487} | train loss {'Reaction outcome loss': 0.8134224743012958, 'Total loss': 0.8134224743012958}
2022-11-23 01:35:12,265 INFO:     Found new best model at epoch 62
2022-11-23 01:35:12,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:12,265 INFO:     Epoch: 63
2022-11-23 01:35:13,054 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7565443434498527, 'Total loss': 0.7565443434498527} | train loss {'Reaction outcome loss': 0.812582075113227, 'Total loss': 0.812582075113227}
2022-11-23 01:35:13,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:13,054 INFO:     Epoch: 64
2022-11-23 01:35:13,904 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7702507864345204, 'Total loss': 0.7702507864345204} | train loss {'Reaction outcome loss': 0.8121856799733783, 'Total loss': 0.8121856799733783}
2022-11-23 01:35:13,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:13,904 INFO:     Epoch: 65
2022-11-23 01:35:14,706 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7532130818475377, 'Total loss': 0.7532130818475377} | train loss {'Reaction outcome loss': 0.8120072963025405, 'Total loss': 0.8120072963025405}
2022-11-23 01:35:14,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:14,706 INFO:     Epoch: 66
2022-11-23 01:35:15,527 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7621094598011537, 'Total loss': 0.7621094598011537} | train loss {'Reaction outcome loss': 0.8118853502669315, 'Total loss': 0.8118853502669315}
2022-11-23 01:35:15,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:15,527 INFO:     Epoch: 67
2022-11-23 01:35:16,360 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7691941999576308, 'Total loss': 0.7691941999576308} | train loss {'Reaction outcome loss': 0.8065583073658499, 'Total loss': 0.8065583073658499}
2022-11-23 01:35:16,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:16,360 INFO:     Epoch: 68
2022-11-23 01:35:17,150 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7976590090177276, 'Total loss': 0.7976590090177276} | train loss {'Reaction outcome loss': 0.8154766113169281, 'Total loss': 0.8154766113169281}
2022-11-23 01:35:17,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:17,150 INFO:     Epoch: 69
2022-11-23 01:35:17,964 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7627282535487955, 'Total loss': 0.7627282535487955} | train loss {'Reaction outcome loss': 0.8102222011398207, 'Total loss': 0.8102222011398207}
2022-11-23 01:35:17,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:17,965 INFO:     Epoch: 70
2022-11-23 01:35:18,759 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7569325051524423, 'Total loss': 0.7569325051524423} | train loss {'Reaction outcome loss': 0.8030952099363814, 'Total loss': 0.8030952099363814}
2022-11-23 01:35:18,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:18,759 INFO:     Epoch: 71
2022-11-23 01:35:19,570 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7571873664855957, 'Total loss': 0.7571873664855957} | train loss {'Reaction outcome loss': 0.8144144386897686, 'Total loss': 0.8144144386897686}
2022-11-23 01:35:19,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:19,570 INFO:     Epoch: 72
2022-11-23 01:35:20,427 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7707333402200178, 'Total loss': 0.7707333402200178} | train loss {'Reaction outcome loss': 0.8123072670538899, 'Total loss': 0.8123072670538899}
2022-11-23 01:35:20,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:20,427 INFO:     Epoch: 73
2022-11-23 01:35:21,236 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7933055473999544, 'Total loss': 0.7933055473999544} | train loss {'Reaction outcome loss': 0.8070162672866211, 'Total loss': 0.8070162672866211}
2022-11-23 01:35:21,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:21,236 INFO:     Epoch: 74
2022-11-23 01:35:22,058 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7731845744631507, 'Total loss': 0.7731845744631507} | train loss {'Reaction outcome loss': 0.801163309890973, 'Total loss': 0.801163309890973}
2022-11-23 01:35:22,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:22,058 INFO:     Epoch: 75
2022-11-23 01:35:22,866 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7715575363148343, 'Total loss': 0.7715575363148343} | train loss {'Reaction outcome loss': 0.8050382255240973, 'Total loss': 0.8050382255240973}
2022-11-23 01:35:22,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:22,866 INFO:     Epoch: 76
2022-11-23 01:35:23,700 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7648208771239627, 'Total loss': 0.7648208771239627} | train loss {'Reaction outcome loss': 0.8160747105052114, 'Total loss': 0.8160747105052114}
2022-11-23 01:35:23,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:23,702 INFO:     Epoch: 77
2022-11-23 01:35:24,562 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7777599611065604, 'Total loss': 0.7777599611065604} | train loss {'Reaction outcome loss': 0.8176493935498149, 'Total loss': 0.8176493935498149}
2022-11-23 01:35:24,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:24,563 INFO:     Epoch: 78
2022-11-23 01:35:25,378 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7667041915384206, 'Total loss': 0.7667041915384206} | train loss {'Reaction outcome loss': 0.8184287030445901, 'Total loss': 0.8184287030445901}
2022-11-23 01:35:25,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:25,378 INFO:     Epoch: 79
2022-11-23 01:35:26,210 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7547518014907837, 'Total loss': 0.7547518014907837} | train loss {'Reaction outcome loss': 0.804304324422288, 'Total loss': 0.804304324422288}
2022-11-23 01:35:26,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:26,210 INFO:     Epoch: 80
2022-11-23 01:35:27,039 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.773011405359615, 'Total loss': 0.773011405359615} | train loss {'Reaction outcome loss': 0.8086691553052138, 'Total loss': 0.8086691553052138}
2022-11-23 01:35:27,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:27,039 INFO:     Epoch: 81
2022-11-23 01:35:27,835 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7628715641119264, 'Total loss': 0.7628715641119264} | train loss {'Reaction outcome loss': 0.810315361389747, 'Total loss': 0.810315361389747}
2022-11-23 01:35:27,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:27,835 INFO:     Epoch: 82
2022-11-23 01:35:28,652 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7643378173763101, 'Total loss': 0.7643378173763101} | train loss {'Reaction outcome loss': 0.8106200123122829, 'Total loss': 0.8106200123122829}
2022-11-23 01:35:28,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:28,653 INFO:     Epoch: 83
2022-11-23 01:35:29,464 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7635027922012589, 'Total loss': 0.7635027922012589} | train loss {'Reaction outcome loss': 0.8094235499981444, 'Total loss': 0.8094235499981444}
2022-11-23 01:35:29,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:29,464 INFO:     Epoch: 84
2022-11-23 01:35:30,288 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7578730149702593, 'Total loss': 0.7578730149702593} | train loss {'Reaction outcome loss': 0.804590650053642, 'Total loss': 0.804590650053642}
2022-11-23 01:35:30,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:30,289 INFO:     Epoch: 85
2022-11-23 01:35:31,131 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7441125844012607, 'Total loss': 0.7441125844012607} | train loss {'Reaction outcome loss': 0.808876131589596, 'Total loss': 0.808876131589596}
2022-11-23 01:35:31,131 INFO:     Found new best model at epoch 85
2022-11-23 01:35:31,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:31,132 INFO:     Epoch: 86
2022-11-23 01:35:31,969 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7969274791804227, 'Total loss': 0.7969274791804227} | train loss {'Reaction outcome loss': 0.8131745320100051, 'Total loss': 0.8131745320100051}
2022-11-23 01:35:31,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:31,970 INFO:     Epoch: 87
2022-11-23 01:35:32,815 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7764991650527174, 'Total loss': 0.7764991650527174} | train loss {'Reaction outcome loss': 0.8113148816322026, 'Total loss': 0.8113148816322026}
2022-11-23 01:35:32,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:32,815 INFO:     Epoch: 88
2022-11-23 01:35:33,681 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7784544039856304, 'Total loss': 0.7784544039856304} | train loss {'Reaction outcome loss': 0.8049171547658047, 'Total loss': 0.8049171547658047}
2022-11-23 01:35:33,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:33,682 INFO:     Epoch: 89
2022-11-23 01:35:34,488 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7557184858755632, 'Total loss': 0.7557184858755632} | train loss {'Reaction outcome loss': 0.8081552345562077, 'Total loss': 0.8081552345562077}
2022-11-23 01:35:34,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:34,488 INFO:     Epoch: 90
2022-11-23 01:35:35,319 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7569483315402811, 'Total loss': 0.7569483315402811} | train loss {'Reaction outcome loss': 0.807830451350463, 'Total loss': 0.807830451350463}
2022-11-23 01:35:35,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:35,319 INFO:     Epoch: 91
2022-11-23 01:35:36,129 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7694288722493432, 'Total loss': 0.7694288722493432} | train loss {'Reaction outcome loss': 0.8161279841473228, 'Total loss': 0.8161279841473228}
2022-11-23 01:35:36,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:36,129 INFO:     Epoch: 92
2022-11-23 01:35:36,995 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7656004117293791, 'Total loss': 0.7656004117293791} | train loss {'Reaction outcome loss': 0.8085249103756569, 'Total loss': 0.8085249103756569}
2022-11-23 01:35:36,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:36,995 INFO:     Epoch: 93
2022-11-23 01:35:37,838 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7938774715770375, 'Total loss': 0.7938774715770375} | train loss {'Reaction outcome loss': 0.8093264124654083, 'Total loss': 0.8093264124654083}
2022-11-23 01:35:37,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:37,838 INFO:     Epoch: 94
2022-11-23 01:35:38,638 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.761946898969737, 'Total loss': 0.761946898969737} | train loss {'Reaction outcome loss': 0.8047349105328925, 'Total loss': 0.8047349105328925}
2022-11-23 01:35:38,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:38,639 INFO:     Epoch: 95
2022-11-23 01:35:39,482 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7611152841286226, 'Total loss': 0.7611152841286226} | train loss {'Reaction outcome loss': 0.8203447385114214, 'Total loss': 0.8203447385114214}
2022-11-23 01:35:39,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:39,482 INFO:     Epoch: 96
2022-11-23 01:35:40,290 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7745871814814481, 'Total loss': 0.7745871814814481} | train loss {'Reaction outcome loss': 0.8099756914111766, 'Total loss': 0.8099756914111766}
2022-11-23 01:35:40,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:40,290 INFO:     Epoch: 97
2022-11-23 01:35:41,107 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8035786978223107, 'Total loss': 0.8035786978223107} | train loss {'Reaction outcome loss': 0.8155971267204053, 'Total loss': 0.8155971267204053}
2022-11-23 01:35:41,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:41,107 INFO:     Epoch: 98
2022-11-23 01:35:41,903 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7617487663572485, 'Total loss': 0.7617487663572485} | train loss {'Reaction outcome loss': 0.8156902897454467, 'Total loss': 0.8156902897454467}
2022-11-23 01:35:41,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:41,903 INFO:     Epoch: 99
2022-11-23 01:35:42,696 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7760091891342943, 'Total loss': 0.7760091891342943} | train loss {'Reaction outcome loss': 0.8194920739181611, 'Total loss': 0.8194920739181611}
2022-11-23 01:35:42,697 INFO:     Best model found after epoch 86 of 100.
2022-11-23 01:35:42,698 INFO:   Done with stage: TRAINING
2022-11-23 01:35:42,698 INFO:   Starting stage: EVALUATION
2022-11-23 01:35:42,822 INFO:   Done with stage: EVALUATION
2022-11-23 01:35:42,822 INFO:   Leaving out SEQ value Fold_5
2022-11-23 01:35:42,836 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 01:35:42,836 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:35:43,510 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:35:43,510 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:35:43,586 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:35:43,587 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:35:43,587 INFO:     No hyperparam tuning for this model
2022-11-23 01:35:43,587 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:35:43,587 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:35:43,588 INFO:     None feature selector for col prot
2022-11-23 01:35:43,588 INFO:     None feature selector for col prot
2022-11-23 01:35:43,588 INFO:     None feature selector for col prot
2022-11-23 01:35:43,589 INFO:     None feature selector for col chem
2022-11-23 01:35:43,590 INFO:     None feature selector for col chem
2022-11-23 01:35:43,590 INFO:     None feature selector for col chem
2022-11-23 01:35:43,590 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:35:43,590 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:35:43,592 INFO:     Number of params in model 168571
2022-11-23 01:35:43,598 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:35:43,598 INFO:   Starting stage: TRAINING
2022-11-23 01:35:43,658 INFO:     Val loss before train {'Reaction outcome loss': 0.9966916956684806, 'Total loss': 0.9966916956684806}
2022-11-23 01:35:43,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:43,658 INFO:     Epoch: 0
2022-11-23 01:35:44,520 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8408706581050699, 'Total loss': 0.8408706581050699} | train loss {'Reaction outcome loss': 0.8718585377979663, 'Total loss': 0.8718585377979663}
2022-11-23 01:35:44,521 INFO:     Found new best model at epoch 0
2022-11-23 01:35:44,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:44,522 INFO:     Epoch: 1
2022-11-23 01:35:45,374 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8150535544211214, 'Total loss': 0.8150535544211214} | train loss {'Reaction outcome loss': 0.848040685778664, 'Total loss': 0.848040685778664}
2022-11-23 01:35:45,374 INFO:     Found new best model at epoch 1
2022-11-23 01:35:45,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:45,375 INFO:     Epoch: 2
2022-11-23 01:35:46,236 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8119388622316447, 'Total loss': 0.8119388622316447} | train loss {'Reaction outcome loss': 0.8392179461736833, 'Total loss': 0.8392179461736833}
2022-11-23 01:35:46,236 INFO:     Found new best model at epoch 2
2022-11-23 01:35:46,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:46,237 INFO:     Epoch: 3
2022-11-23 01:35:47,127 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7981059388680891, 'Total loss': 0.7981059388680891} | train loss {'Reaction outcome loss': 0.8323778748031585, 'Total loss': 0.8323778748031585}
2022-11-23 01:35:47,127 INFO:     Found new best model at epoch 3
2022-11-23 01:35:47,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:47,128 INFO:     Epoch: 4
2022-11-23 01:35:47,985 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8217017501592636, 'Total loss': 0.8217017501592636} | train loss {'Reaction outcome loss': 0.8295513319392358, 'Total loss': 0.8295513319392358}
2022-11-23 01:35:47,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:47,985 INFO:     Epoch: 5
2022-11-23 01:35:48,928 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8006225871768865, 'Total loss': 0.8006225871768865} | train loss {'Reaction outcome loss': 0.8265947236889793, 'Total loss': 0.8265947236889793}
2022-11-23 01:35:48,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:48,928 INFO:     Epoch: 6
2022-11-23 01:35:49,877 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7945154952732, 'Total loss': 0.7945154952732} | train loss {'Reaction outcome loss': 0.8236995744368723, 'Total loss': 0.8236995744368723}
2022-11-23 01:35:49,877 INFO:     Found new best model at epoch 6
2022-11-23 01:35:49,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:49,878 INFO:     Epoch: 7
2022-11-23 01:35:50,740 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7912198013880036, 'Total loss': 0.7912198013880036} | train loss {'Reaction outcome loss': 0.8306431755904229, 'Total loss': 0.8306431755904229}
2022-11-23 01:35:50,741 INFO:     Found new best model at epoch 7
2022-11-23 01:35:50,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:50,742 INFO:     Epoch: 8
2022-11-23 01:35:51,695 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8153947496956045, 'Total loss': 0.8153947496956045} | train loss {'Reaction outcome loss': 0.823804461186932, 'Total loss': 0.823804461186932}
2022-11-23 01:35:51,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:51,695 INFO:     Epoch: 9
2022-11-23 01:35:52,647 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8079253814437173, 'Total loss': 0.8079253814437173} | train loss {'Reaction outcome loss': 0.8211600495682608, 'Total loss': 0.8211600495682608}
2022-11-23 01:35:52,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:52,647 INFO:     Epoch: 10
2022-11-23 01:35:53,500 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8150617940859362, 'Total loss': 0.8150617940859362} | train loss {'Reaction outcome loss': 0.8173491125625949, 'Total loss': 0.8173491125625949}
2022-11-23 01:35:53,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:53,500 INFO:     Epoch: 11
2022-11-23 01:35:54,432 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7992814880880442, 'Total loss': 0.7992814880880442} | train loss {'Reaction outcome loss': 0.8200944502267146, 'Total loss': 0.8200944502267146}
2022-11-23 01:35:54,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:54,433 INFO:     Epoch: 12
2022-11-23 01:35:55,295 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7930043705485084, 'Total loss': 0.7930043705485084} | train loss {'Reaction outcome loss': 0.8213073972973132, 'Total loss': 0.8213073972973132}
2022-11-23 01:35:55,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:55,295 INFO:     Epoch: 13
2022-11-23 01:35:56,212 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7999359721487219, 'Total loss': 0.7999359721487219} | train loss {'Reaction outcome loss': 0.8169779740273952, 'Total loss': 0.8169779740273952}
2022-11-23 01:35:56,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:56,212 INFO:     Epoch: 14
2022-11-23 01:35:57,133 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7994739508086984, 'Total loss': 0.7994739508086984} | train loss {'Reaction outcome loss': 0.8140835721165903, 'Total loss': 0.8140835721165903}
2022-11-23 01:35:57,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:57,133 INFO:     Epoch: 15
2022-11-23 01:35:58,073 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7971157031980428, 'Total loss': 0.7971157031980428} | train loss {'Reaction outcome loss': 0.8144425196993735, 'Total loss': 0.8144425196993735}
2022-11-23 01:35:58,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:58,073 INFO:     Epoch: 16
2022-11-23 01:35:58,979 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7901287837461992, 'Total loss': 0.7901287837461992} | train loss {'Reaction outcome loss': 0.8135605462856831, 'Total loss': 0.8135605462856831}
2022-11-23 01:35:58,979 INFO:     Found new best model at epoch 16
2022-11-23 01:35:58,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:58,980 INFO:     Epoch: 17
2022-11-23 01:35:59,933 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8085850863294168, 'Total loss': 0.8085850863294168} | train loss {'Reaction outcome loss': 0.8164066690350732, 'Total loss': 0.8164066690350732}
2022-11-23 01:35:59,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:35:59,933 INFO:     Epoch: 18
2022-11-23 01:36:00,863 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7838626835833896, 'Total loss': 0.7838626835833896} | train loss {'Reaction outcome loss': 0.8150764378088136, 'Total loss': 0.8150764378088136}
2022-11-23 01:36:00,864 INFO:     Found new best model at epoch 18
2022-11-23 01:36:00,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:00,865 INFO:     Epoch: 19
2022-11-23 01:36:01,753 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8001016026193445, 'Total loss': 0.8001016026193445} | train loss {'Reaction outcome loss': 0.8099690501488024, 'Total loss': 0.8099690501488024}
2022-11-23 01:36:01,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:01,754 INFO:     Epoch: 20
2022-11-23 01:36:02,638 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7887783158909191, 'Total loss': 0.7887783158909191} | train loss {'Reaction outcome loss': 0.8130855488200341, 'Total loss': 0.8130855488200341}
2022-11-23 01:36:02,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:02,638 INFO:     Epoch: 21
2022-11-23 01:36:03,484 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7970785546031866, 'Total loss': 0.7970785546031866} | train loss {'Reaction outcome loss': 0.8132844120264053, 'Total loss': 0.8132844120264053}
2022-11-23 01:36:03,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:03,485 INFO:     Epoch: 22
2022-11-23 01:36:04,336 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.790044480426745, 'Total loss': 0.790044480426745} | train loss {'Reaction outcome loss': 0.8167473554851548, 'Total loss': 0.8167473554851548}
2022-11-23 01:36:04,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:04,337 INFO:     Epoch: 23
2022-11-23 01:36:05,206 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7763268324461851, 'Total loss': 0.7763268324461851} | train loss {'Reaction outcome loss': 0.8144021297414457, 'Total loss': 0.8144021297414457}
2022-11-23 01:36:05,207 INFO:     Found new best model at epoch 23
2022-11-23 01:36:05,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:05,208 INFO:     Epoch: 24
2022-11-23 01:36:06,051 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7852354544130239, 'Total loss': 0.7852354544130239} | train loss {'Reaction outcome loss': 0.8105939356309753, 'Total loss': 0.8105939356309753}
2022-11-23 01:36:06,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:06,051 INFO:     Epoch: 25
2022-11-23 01:36:06,910 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7872263430194422, 'Total loss': 0.7872263430194422} | train loss {'Reaction outcome loss': 0.8145583674551979, 'Total loss': 0.8145583674551979}
2022-11-23 01:36:06,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:06,910 INFO:     Epoch: 26
2022-11-23 01:36:07,734 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7921165017919107, 'Total loss': 0.7921165017919107} | train loss {'Reaction outcome loss': 0.8142249464027344, 'Total loss': 0.8142249464027344}
2022-11-23 01:36:07,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:07,734 INFO:     Epoch: 27
2022-11-23 01:36:08,591 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8004625473510135, 'Total loss': 0.8004625473510135} | train loss {'Reaction outcome loss': 0.8141343708360388, 'Total loss': 0.8141343708360388}
2022-11-23 01:36:08,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:08,592 INFO:     Epoch: 28
2022-11-23 01:36:09,454 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7798390693285249, 'Total loss': 0.7798390693285249} | train loss {'Reaction outcome loss': 0.8121152736486927, 'Total loss': 0.8121152736486927}
2022-11-23 01:36:09,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:09,454 INFO:     Epoch: 29
2022-11-23 01:36:10,354 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7897857034748251, 'Total loss': 0.7897857034748251} | train loss {'Reaction outcome loss': 0.8111795308368821, 'Total loss': 0.8111795308368821}
2022-11-23 01:36:10,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:10,355 INFO:     Epoch: 30
2022-11-23 01:36:11,250 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7845459864898161, 'Total loss': 0.7845459864898161} | train loss {'Reaction outcome loss': 0.8115738985999938, 'Total loss': 0.8115738985999938}
2022-11-23 01:36:11,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:11,250 INFO:     Epoch: 31
2022-11-23 01:36:12,134 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.807633557102897, 'Total loss': 0.807633557102897} | train loss {'Reaction outcome loss': 0.8087184507279627, 'Total loss': 0.8087184507279627}
2022-11-23 01:36:12,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:12,135 INFO:     Epoch: 32
2022-11-23 01:36:13,004 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7870531982996247, 'Total loss': 0.7870531982996247} | train loss {'Reaction outcome loss': 0.811199497671858, 'Total loss': 0.811199497671858}
2022-11-23 01:36:13,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:13,005 INFO:     Epoch: 33
2022-11-23 01:36:13,874 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7881072434512052, 'Total loss': 0.7881072434512052} | train loss {'Reaction outcome loss': 0.8123238110734571, 'Total loss': 0.8123238110734571}
2022-11-23 01:36:13,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:13,874 INFO:     Epoch: 34
2022-11-23 01:36:14,712 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8113289326429367, 'Total loss': 0.8113289326429367} | train loss {'Reaction outcome loss': 0.8184464039100755, 'Total loss': 0.8184464039100755}
2022-11-23 01:36:14,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:14,712 INFO:     Epoch: 35
2022-11-23 01:36:15,591 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8111154558983716, 'Total loss': 0.8111154558983716} | train loss {'Reaction outcome loss': 0.8126635625958443, 'Total loss': 0.8126635625958443}
2022-11-23 01:36:15,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:15,591 INFO:     Epoch: 36
2022-11-23 01:36:16,451 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7964240055192601, 'Total loss': 0.7964240055192601} | train loss {'Reaction outcome loss': 0.8127880148108928, 'Total loss': 0.8127880148108928}
2022-11-23 01:36:16,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:16,451 INFO:     Epoch: 37
2022-11-23 01:36:17,322 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8046369898048314, 'Total loss': 0.8046369898048314} | train loss {'Reaction outcome loss': 0.810712161203546, 'Total loss': 0.810712161203546}
2022-11-23 01:36:17,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:17,322 INFO:     Epoch: 38
2022-11-23 01:36:18,167 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7845164876092564, 'Total loss': 0.7845164876092564} | train loss {'Reaction outcome loss': 0.8159331720803054, 'Total loss': 0.8159331720803054}
2022-11-23 01:36:18,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:18,167 INFO:     Epoch: 39
2022-11-23 01:36:19,055 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7873865352435545, 'Total loss': 0.7873865352435545} | train loss {'Reaction outcome loss': 0.8138137197782916, 'Total loss': 0.8138137197782916}
2022-11-23 01:36:19,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:19,055 INFO:     Epoch: 40
2022-11-23 01:36:19,939 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7802939696068113, 'Total loss': 0.7802939696068113} | train loss {'Reaction outcome loss': 0.8147761523723602, 'Total loss': 0.8147761523723602}
2022-11-23 01:36:19,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:19,940 INFO:     Epoch: 41
2022-11-23 01:36:20,851 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7805555435744199, 'Total loss': 0.7805555435744199} | train loss {'Reaction outcome loss': 0.8139470979090659, 'Total loss': 0.8139470979090659}
2022-11-23 01:36:20,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:20,851 INFO:     Epoch: 42
2022-11-23 01:36:21,694 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7954543314196847, 'Total loss': 0.7954543314196847} | train loss {'Reaction outcome loss': 0.8108583033805893, 'Total loss': 0.8108583033805893}
2022-11-23 01:36:21,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:21,695 INFO:     Epoch: 43
2022-11-23 01:36:22,549 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7986395501277663, 'Total loss': 0.7986395501277663} | train loss {'Reaction outcome loss': 0.8098063248419954, 'Total loss': 0.8098063248419954}
2022-11-23 01:36:22,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:22,549 INFO:     Epoch: 44
2022-11-23 01:36:23,414 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8042284616015174, 'Total loss': 0.8042284616015174} | train loss {'Reaction outcome loss': 0.8138875711348749, 'Total loss': 0.8138875711348749}
2022-11-23 01:36:23,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:23,415 INFO:     Epoch: 45
2022-11-23 01:36:24,285 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7937466556375677, 'Total loss': 0.7937466556375677} | train loss {'Reaction outcome loss': 0.8142781811616113, 'Total loss': 0.8142781811616113}
2022-11-23 01:36:24,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:24,286 INFO:     Epoch: 46
2022-11-23 01:36:25,170 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.785307610576803, 'Total loss': 0.785307610576803} | train loss {'Reaction outcome loss': 0.8161485802021718, 'Total loss': 0.8161485802021718}
2022-11-23 01:36:25,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:25,170 INFO:     Epoch: 47
2022-11-23 01:36:26,038 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7927497056397524, 'Total loss': 0.7927497056397524} | train loss {'Reaction outcome loss': 0.8134362644726231, 'Total loss': 0.8134362644726231}
2022-11-23 01:36:26,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:26,039 INFO:     Epoch: 48
2022-11-23 01:36:26,951 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7960019897330891, 'Total loss': 0.7960019897330891} | train loss {'Reaction outcome loss': 0.8113871299691738, 'Total loss': 0.8113871299691738}
2022-11-23 01:36:26,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:26,951 INFO:     Epoch: 49
2022-11-23 01:36:27,808 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8098680688576265, 'Total loss': 0.8098680688576265} | train loss {'Reaction outcome loss': 0.8131565618659219, 'Total loss': 0.8131565618659219}
2022-11-23 01:36:27,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:27,809 INFO:     Epoch: 50
2022-11-23 01:36:28,695 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8025402406399901, 'Total loss': 0.8025402406399901} | train loss {'Reaction outcome loss': 0.8098169089325012, 'Total loss': 0.8098169089325012}
2022-11-23 01:36:28,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:28,695 INFO:     Epoch: 51
2022-11-23 01:36:29,539 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7962653508240526, 'Total loss': 0.7962653508240526} | train loss {'Reaction outcome loss': 0.8108187009009623, 'Total loss': 0.8108187009009623}
2022-11-23 01:36:29,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:29,539 INFO:     Epoch: 52
2022-11-23 01:36:30,432 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7901010736823082, 'Total loss': 0.7901010736823082} | train loss {'Reaction outcome loss': 0.8114405473874461, 'Total loss': 0.8114405473874461}
2022-11-23 01:36:30,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:30,433 INFO:     Epoch: 53
2022-11-23 01:36:31,276 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8209843818436969, 'Total loss': 0.8209843818436969} | train loss {'Reaction outcome loss': 0.8121054079984465, 'Total loss': 0.8121054079984465}
2022-11-23 01:36:31,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:31,276 INFO:     Epoch: 54
2022-11-23 01:36:32,130 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7832982282746922, 'Total loss': 0.7832982282746922} | train loss {'Reaction outcome loss': 0.8158578977229134, 'Total loss': 0.8158578977229134}
2022-11-23 01:36:32,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:32,131 INFO:     Epoch: 55
2022-11-23 01:36:32,993 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8012962436134164, 'Total loss': 0.8012962436134164} | train loss {'Reaction outcome loss': 0.81164714669989, 'Total loss': 0.81164714669989}
2022-11-23 01:36:32,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:32,993 INFO:     Epoch: 56
2022-11-23 01:36:33,891 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7856604050506245, 'Total loss': 0.7856604050506245} | train loss {'Reaction outcome loss': 0.8101574366371478, 'Total loss': 0.8101574366371478}
2022-11-23 01:36:33,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:33,891 INFO:     Epoch: 57
2022-11-23 01:36:34,794 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7817202345891432, 'Total loss': 0.7817202345891432} | train loss {'Reaction outcome loss': 0.8110436318862823, 'Total loss': 0.8110436318862823}
2022-11-23 01:36:34,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:34,794 INFO:     Epoch: 58
2022-11-23 01:36:35,678 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8052681291645224, 'Total loss': 0.8052681291645224} | train loss {'Reaction outcome loss': 0.8085788298518427, 'Total loss': 0.8085788298518427}
2022-11-23 01:36:35,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:35,678 INFO:     Epoch: 59
2022-11-23 01:36:36,513 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.787223832173781, 'Total loss': 0.787223832173781} | train loss {'Reaction outcome loss': 0.8132904971078518, 'Total loss': 0.8132904971078518}
2022-11-23 01:36:36,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:36,513 INFO:     Epoch: 60
2022-11-23 01:36:37,408 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7926704761656848, 'Total loss': 0.7926704761656848} | train loss {'Reaction outcome loss': 0.8058065871798223, 'Total loss': 0.8058065871798223}
2022-11-23 01:36:37,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:37,408 INFO:     Epoch: 61
2022-11-23 01:36:38,247 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7944954200224443, 'Total loss': 0.7944954200224443} | train loss {'Reaction outcome loss': 0.8148073626141394, 'Total loss': 0.8148073626141394}
2022-11-23 01:36:38,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:38,247 INFO:     Epoch: 62
2022-11-23 01:36:39,113 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8028631901199167, 'Total loss': 0.8028631901199167} | train loss {'Reaction outcome loss': 0.8171054740105906, 'Total loss': 0.8171054740105906}
2022-11-23 01:36:39,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:39,113 INFO:     Epoch: 63
2022-11-23 01:36:40,004 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.781635120511055, 'Total loss': 0.781635120511055} | train loss {'Reaction outcome loss': 0.8113397125515246, 'Total loss': 0.8113397125515246}
2022-11-23 01:36:40,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:40,004 INFO:     Epoch: 64
2022-11-23 01:36:40,852 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7902842164039612, 'Total loss': 0.7902842164039612} | train loss {'Reaction outcome loss': 0.811414998385214, 'Total loss': 0.811414998385214}
2022-11-23 01:36:40,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:40,852 INFO:     Epoch: 65
2022-11-23 01:36:41,699 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7900644886222753, 'Total loss': 0.7900644886222753} | train loss {'Reaction outcome loss': 0.8106425099315182, 'Total loss': 0.8106425099315182}
2022-11-23 01:36:41,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:41,699 INFO:     Epoch: 66
2022-11-23 01:36:42,565 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7861454182050445, 'Total loss': 0.7861454182050445} | train loss {'Reaction outcome loss': 0.8106881485831353, 'Total loss': 0.8106881485831353}
2022-11-23 01:36:42,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:42,565 INFO:     Epoch: 67
2022-11-23 01:36:43,474 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7958521829410032, 'Total loss': 0.7958521829410032} | train loss {'Reaction outcome loss': 0.8092519523155305, 'Total loss': 0.8092519523155305}
2022-11-23 01:36:43,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:43,474 INFO:     Epoch: 68
2022-11-23 01:36:44,304 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7988213449716568, 'Total loss': 0.7988213449716568} | train loss {'Reaction outcome loss': 0.810838004273753, 'Total loss': 0.810838004273753}
2022-11-23 01:36:44,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:44,305 INFO:     Epoch: 69
2022-11-23 01:36:45,167 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7946432090618394, 'Total loss': 0.7946432090618394} | train loss {'Reaction outcome loss': 0.812481346990793, 'Total loss': 0.812481346990793}
2022-11-23 01:36:45,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:45,167 INFO:     Epoch: 70
2022-11-23 01:36:45,970 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8106909949671138, 'Total loss': 0.8106909949671138} | train loss {'Reaction outcome loss': 0.8129642306556625, 'Total loss': 0.8129642306556625}
2022-11-23 01:36:45,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:45,971 INFO:     Epoch: 71
2022-11-23 01:36:46,828 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7922494120218537, 'Total loss': 0.7922494120218537} | train loss {'Reaction outcome loss': 0.8095673131606271, 'Total loss': 0.8095673131606271}
2022-11-23 01:36:46,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:46,829 INFO:     Epoch: 72
2022-11-23 01:36:47,698 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8177819915793159, 'Total loss': 0.8177819915793159} | train loss {'Reaction outcome loss': 0.8106190170491895, 'Total loss': 0.8106190170491895}
2022-11-23 01:36:47,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:47,698 INFO:     Epoch: 73
2022-11-23 01:36:48,578 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8100937422026288, 'Total loss': 0.8100937422026288} | train loss {'Reaction outcome loss': 0.8158388349317736, 'Total loss': 0.8158388349317736}
2022-11-23 01:36:48,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:48,579 INFO:     Epoch: 74
2022-11-23 01:36:49,433 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.776544065638022, 'Total loss': 0.776544065638022} | train loss {'Reaction outcome loss': 0.8073448716632782, 'Total loss': 0.8073448716632782}
2022-11-23 01:36:49,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:49,433 INFO:     Epoch: 75
2022-11-23 01:36:50,271 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8107976737347516, 'Total loss': 0.8107976737347516} | train loss {'Reaction outcome loss': 0.8122003980942311, 'Total loss': 0.8122003980942311}
2022-11-23 01:36:50,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:50,271 INFO:     Epoch: 76
2022-11-23 01:36:51,065 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.793635864826766, 'Total loss': 0.793635864826766} | train loss {'Reaction outcome loss': 0.8168985945803504, 'Total loss': 0.8168985945803504}
2022-11-23 01:36:51,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:51,065 INFO:     Epoch: 77
2022-11-23 01:36:51,894 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7806518132036383, 'Total loss': 0.7806518132036383} | train loss {'Reaction outcome loss': 0.8118503516720187, 'Total loss': 0.8118503516720187}
2022-11-23 01:36:51,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:51,894 INFO:     Epoch: 78
2022-11-23 01:36:52,729 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8064417872916568, 'Total loss': 0.8064417872916568} | train loss {'Reaction outcome loss': 0.8141765509161257, 'Total loss': 0.8141765509161257}
2022-11-23 01:36:52,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:52,729 INFO:     Epoch: 79
2022-11-23 01:36:53,537 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.777529052035375, 'Total loss': 0.777529052035375} | train loss {'Reaction outcome loss': 0.8078045087956613, 'Total loss': 0.8078045087956613}
2022-11-23 01:36:53,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:53,537 INFO:     Epoch: 80
2022-11-23 01:36:54,345 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7970396158370104, 'Total loss': 0.7970396158370104} | train loss {'Reaction outcome loss': 0.807304805565265, 'Total loss': 0.807304805565265}
2022-11-23 01:36:54,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:54,345 INFO:     Epoch: 81
2022-11-23 01:36:55,147 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8406905220313505, 'Total loss': 0.8406905220313505} | train loss {'Reaction outcome loss': 0.8141190124855887, 'Total loss': 0.8141190124855887}
2022-11-23 01:36:55,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:55,147 INFO:     Epoch: 82
2022-11-23 01:36:55,953 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7948440232060172, 'Total loss': 0.7948440232060172} | train loss {'Reaction outcome loss': 0.81456258893013, 'Total loss': 0.81456258893013}
2022-11-23 01:36:55,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:55,953 INFO:     Epoch: 83
2022-11-23 01:36:56,766 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8023263839158145, 'Total loss': 0.8023263839158145} | train loss {'Reaction outcome loss': 0.8104956660780215, 'Total loss': 0.8104956660780215}
2022-11-23 01:36:56,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:56,767 INFO:     Epoch: 84
2022-11-23 01:36:57,604 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.793945272537795, 'Total loss': 0.793945272537795} | train loss {'Reaction outcome loss': 0.8088972304136522, 'Total loss': 0.8088972304136522}
2022-11-23 01:36:57,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:57,605 INFO:     Epoch: 85
2022-11-23 01:36:58,427 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8193403753367338, 'Total loss': 0.8193403753367338} | train loss {'Reaction outcome loss': 0.8101565145677135, 'Total loss': 0.8101565145677135}
2022-11-23 01:36:58,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:58,427 INFO:     Epoch: 86
2022-11-23 01:36:59,247 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7938655039126222, 'Total loss': 0.7938655039126222} | train loss {'Reaction outcome loss': 0.8115654755984584, 'Total loss': 0.8115654755984584}
2022-11-23 01:36:59,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:36:59,247 INFO:     Epoch: 87
2022-11-23 01:37:00,050 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.781247694383968, 'Total loss': 0.781247694383968} | train loss {'Reaction outcome loss': 0.8100567169247135, 'Total loss': 0.8100567169247135}
2022-11-23 01:37:00,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:00,050 INFO:     Epoch: 88
2022-11-23 01:37:00,858 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7882272066040472, 'Total loss': 0.7882272066040472} | train loss {'Reaction outcome loss': 0.812833247526038, 'Total loss': 0.812833247526038}
2022-11-23 01:37:00,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:00,858 INFO:     Epoch: 89
2022-11-23 01:37:01,646 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8011008440093561, 'Total loss': 0.8011008440093561} | train loss {'Reaction outcome loss': 0.8106840279313826, 'Total loss': 0.8106840279313826}
2022-11-23 01:37:01,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:01,646 INFO:     Epoch: 90
2022-11-23 01:37:02,464 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7912471721118147, 'Total loss': 0.7912471721118147} | train loss {'Reaction outcome loss': 0.8077535731417518, 'Total loss': 0.8077535731417518}
2022-11-23 01:37:02,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:02,464 INFO:     Epoch: 91
2022-11-23 01:37:03,303 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.783435042608868, 'Total loss': 0.783435042608868} | train loss {'Reaction outcome loss': 0.806661548213132, 'Total loss': 0.806661548213132}
2022-11-23 01:37:03,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:03,304 INFO:     Epoch: 92
2022-11-23 01:37:04,086 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7866754274476658, 'Total loss': 0.7866754274476658} | train loss {'Reaction outcome loss': 0.8100133038336231, 'Total loss': 0.8100133038336231}
2022-11-23 01:37:04,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:04,086 INFO:     Epoch: 93
2022-11-23 01:37:04,867 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7901884791525927, 'Total loss': 0.7901884791525927} | train loss {'Reaction outcome loss': 0.8151204201482958, 'Total loss': 0.8151204201482958}
2022-11-23 01:37:04,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:04,867 INFO:     Epoch: 94
2022-11-23 01:37:05,638 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7936389866200361, 'Total loss': 0.7936389866200361} | train loss {'Reaction outcome loss': 0.8103783828837257, 'Total loss': 0.8103783828837257}
2022-11-23 01:37:05,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:05,638 INFO:     Epoch: 95
2022-11-23 01:37:06,462 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7887355536222458, 'Total loss': 0.7887355536222458} | train loss {'Reaction outcome loss': 0.8110137339080533, 'Total loss': 0.8110137339080533}
2022-11-23 01:37:06,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:06,462 INFO:     Epoch: 96
2022-11-23 01:37:07,285 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7848118137229573, 'Total loss': 0.7848118137229573} | train loss {'Reaction outcome loss': 0.811686973057447, 'Total loss': 0.811686973057447}
2022-11-23 01:37:07,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:07,285 INFO:     Epoch: 97
2022-11-23 01:37:08,089 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8069104423577135, 'Total loss': 0.8069104423577135} | train loss {'Reaction outcome loss': 0.8067800015691788, 'Total loss': 0.8067800015691788}
2022-11-23 01:37:08,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:08,089 INFO:     Epoch: 98
2022-11-23 01:37:08,917 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8266827464103699, 'Total loss': 0.8266827464103699} | train loss {'Reaction outcome loss': 0.8097717377447313, 'Total loss': 0.8097717377447313}
2022-11-23 01:37:08,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:08,918 INFO:     Epoch: 99
2022-11-23 01:37:09,724 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7765007601542906, 'Total loss': 0.7765007601542906} | train loss {'Reaction outcome loss': 0.8117720290057121, 'Total loss': 0.8117720290057121}
2022-11-23 01:37:09,724 INFO:     Best model found after epoch 24 of 100.
2022-11-23 01:37:09,725 INFO:   Done with stage: TRAINING
2022-11-23 01:37:09,725 INFO:   Starting stage: EVALUATION
2022-11-23 01:37:09,846 INFO:   Done with stage: EVALUATION
2022-11-23 01:37:09,846 INFO:   Leaving out SEQ value Fold_6
2022-11-23 01:37:09,859 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-23 01:37:09,860 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:37:10,542 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:37:10,542 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:37:10,620 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:37:10,620 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:37:10,620 INFO:     No hyperparam tuning for this model
2022-11-23 01:37:10,620 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:37:10,620 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:37:10,621 INFO:     None feature selector for col prot
2022-11-23 01:37:10,621 INFO:     None feature selector for col prot
2022-11-23 01:37:10,621 INFO:     None feature selector for col prot
2022-11-23 01:37:10,622 INFO:     None feature selector for col chem
2022-11-23 01:37:10,622 INFO:     None feature selector for col chem
2022-11-23 01:37:10,622 INFO:     None feature selector for col chem
2022-11-23 01:37:10,622 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:37:10,622 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:37:10,624 INFO:     Number of params in model 168571
2022-11-23 01:37:10,627 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:37:10,627 INFO:   Starting stage: TRAINING
2022-11-23 01:37:10,686 INFO:     Val loss before train {'Reaction outcome loss': 0.9824598932808096, 'Total loss': 0.9824598932808096}
2022-11-23 01:37:10,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:10,686 INFO:     Epoch: 0
2022-11-23 01:37:11,487 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8221628950400786, 'Total loss': 0.8221628950400786} | train loss {'Reaction outcome loss': 0.8821078898204912, 'Total loss': 0.8821078898204912}
2022-11-23 01:37:11,487 INFO:     Found new best model at epoch 0
2022-11-23 01:37:11,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:11,488 INFO:     Epoch: 1
2022-11-23 01:37:12,296 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8225402249531313, 'Total loss': 0.8225402249531313} | train loss {'Reaction outcome loss': 0.8489152068091977, 'Total loss': 0.8489152068091977}
2022-11-23 01:37:12,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:12,296 INFO:     Epoch: 2
2022-11-23 01:37:13,114 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7849510745568709, 'Total loss': 0.7849510745568709} | train loss {'Reaction outcome loss': 0.8419980391138985, 'Total loss': 0.8419980391138985}
2022-11-23 01:37:13,114 INFO:     Found new best model at epoch 2
2022-11-23 01:37:13,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:13,115 INFO:     Epoch: 3
2022-11-23 01:37:13,933 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8053617003289136, 'Total loss': 0.8053617003289136} | train loss {'Reaction outcome loss': 0.8392669089859531, 'Total loss': 0.8392669089859531}
2022-11-23 01:37:13,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:13,933 INFO:     Epoch: 4
2022-11-23 01:37:14,732 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8039114881645549, 'Total loss': 0.8039114881645549} | train loss {'Reaction outcome loss': 0.8316720331147793, 'Total loss': 0.8316720331147793}
2022-11-23 01:37:14,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:14,733 INFO:     Epoch: 5
2022-11-23 01:37:15,502 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8064138489690694, 'Total loss': 0.8064138489690694} | train loss {'Reaction outcome loss': 0.8313709266724125, 'Total loss': 0.8313709266724125}
2022-11-23 01:37:15,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:15,503 INFO:     Epoch: 6
2022-11-23 01:37:16,317 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8049617653543298, 'Total loss': 0.8049617653543298} | train loss {'Reaction outcome loss': 0.8269785092242302, 'Total loss': 0.8269785092242302}
2022-11-23 01:37:16,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:16,317 INFO:     Epoch: 7
2022-11-23 01:37:17,093 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8016137873584573, 'Total loss': 0.8016137873584573} | train loss {'Reaction outcome loss': 0.8241892297181391, 'Total loss': 0.8241892297181391}
2022-11-23 01:37:17,094 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:17,094 INFO:     Epoch: 8
2022-11-23 01:37:17,845 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8027070489796725, 'Total loss': 0.8027070489796725} | train loss {'Reaction outcome loss': 0.8196256411892753, 'Total loss': 0.8196256411892753}
2022-11-23 01:37:17,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:17,846 INFO:     Epoch: 9
2022-11-23 01:37:18,671 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7866857133128426, 'Total loss': 0.7866857133128426} | train loss {'Reaction outcome loss': 0.8181891376453061, 'Total loss': 0.8181891376453061}
2022-11-23 01:37:18,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:18,672 INFO:     Epoch: 10
2022-11-23 01:37:19,463 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7959282567555254, 'Total loss': 0.7959282567555254} | train loss {'Reaction outcome loss': 0.8205441609025002, 'Total loss': 0.8205441609025002}
2022-11-23 01:37:19,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:19,463 INFO:     Epoch: 11
2022-11-23 01:37:20,224 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7829061286015944, 'Total loss': 0.7829061286015944} | train loss {'Reaction outcome loss': 0.8197256409593167, 'Total loss': 0.8197256409593167}
2022-11-23 01:37:20,224 INFO:     Found new best model at epoch 11
2022-11-23 01:37:20,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:20,225 INFO:     Epoch: 12
2022-11-23 01:37:21,070 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7806340706619349, 'Total loss': 0.7806340706619349} | train loss {'Reaction outcome loss': 0.817151666048073, 'Total loss': 0.817151666048073}
2022-11-23 01:37:21,070 INFO:     Found new best model at epoch 12
2022-11-23 01:37:21,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:21,071 INFO:     Epoch: 13
2022-11-23 01:37:21,916 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7881532948125493, 'Total loss': 0.7881532948125493} | train loss {'Reaction outcome loss': 0.8250131282594896, 'Total loss': 0.8250131282594896}
2022-11-23 01:37:21,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:21,916 INFO:     Epoch: 14
2022-11-23 01:37:22,742 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7737386429851706, 'Total loss': 0.7737386429851706} | train loss {'Reaction outcome loss': 0.8138486697308479, 'Total loss': 0.8138486697308479}
2022-11-23 01:37:22,742 INFO:     Found new best model at epoch 14
2022-11-23 01:37:22,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:22,743 INFO:     Epoch: 15
2022-11-23 01:37:23,539 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7750282626260411, 'Total loss': 0.7750282626260411} | train loss {'Reaction outcome loss': 0.815994123297353, 'Total loss': 0.815994123297353}
2022-11-23 01:37:23,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:23,539 INFO:     Epoch: 16
2022-11-23 01:37:24,349 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7727579589594494, 'Total loss': 0.7727579589594494} | train loss {'Reaction outcome loss': 0.8128690389135191, 'Total loss': 0.8128690389135191}
2022-11-23 01:37:24,349 INFO:     Found new best model at epoch 16
2022-11-23 01:37:24,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:24,350 INFO:     Epoch: 17
2022-11-23 01:37:25,194 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7713868137110363, 'Total loss': 0.7713868137110363} | train loss {'Reaction outcome loss': 0.8126271633851913, 'Total loss': 0.8126271633851913}
2022-11-23 01:37:25,194 INFO:     Found new best model at epoch 17
2022-11-23 01:37:25,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:25,195 INFO:     Epoch: 18
2022-11-23 01:37:26,058 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7762240632013842, 'Total loss': 0.7762240632013842} | train loss {'Reaction outcome loss': 0.8181129701195224, 'Total loss': 0.8181129701195224}
2022-11-23 01:37:26,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:26,058 INFO:     Epoch: 19
2022-11-23 01:37:26,920 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7772987735542384, 'Total loss': 0.7772987735542384} | train loss {'Reaction outcome loss': 0.8129165342017528, 'Total loss': 0.8129165342017528}
2022-11-23 01:37:26,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:26,920 INFO:     Epoch: 20
2022-11-23 01:37:27,838 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.778117954053662, 'Total loss': 0.778117954053662} | train loss {'Reaction outcome loss': 0.8160741960089053, 'Total loss': 0.8160741960089053}
2022-11-23 01:37:27,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:27,839 INFO:     Epoch: 21
2022-11-23 01:37:28,704 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7762355160984126, 'Total loss': 0.7762355160984126} | train loss {'Reaction outcome loss': 0.814230756774064, 'Total loss': 0.814230756774064}
2022-11-23 01:37:28,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:28,704 INFO:     Epoch: 22
2022-11-23 01:37:29,565 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8151349906216968, 'Total loss': 0.8151349906216968} | train loss {'Reaction outcome loss': 0.8111985413537871, 'Total loss': 0.8111985413537871}
2022-11-23 01:37:29,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:29,566 INFO:     Epoch: 23
2022-11-23 01:37:30,426 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7766166024587371, 'Total loss': 0.7766166024587371} | train loss {'Reaction outcome loss': 0.8180413200489937, 'Total loss': 0.8180413200489937}
2022-11-23 01:37:30,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:30,426 INFO:     Epoch: 24
2022-11-23 01:37:31,225 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7901999936862425, 'Total loss': 0.7901999936862425} | train loss {'Reaction outcome loss': 0.8110958121476635, 'Total loss': 0.8110958121476635}
2022-11-23 01:37:31,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:31,225 INFO:     Epoch: 25
2022-11-23 01:37:32,087 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7669404785741459, 'Total loss': 0.7669404785741459} | train loss {'Reaction outcome loss': 0.8132400384112712, 'Total loss': 0.8132400384112712}
2022-11-23 01:37:32,087 INFO:     Found new best model at epoch 25
2022-11-23 01:37:32,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:32,088 INFO:     Epoch: 26
2022-11-23 01:37:32,903 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7887207940220833, 'Total loss': 0.7887207940220833} | train loss {'Reaction outcome loss': 0.8132592625916004, 'Total loss': 0.8132592625916004}
2022-11-23 01:37:32,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:32,903 INFO:     Epoch: 27
2022-11-23 01:37:33,733 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.786366074600003, 'Total loss': 0.786366074600003} | train loss {'Reaction outcome loss': 0.8125178557970831, 'Total loss': 0.8125178557970831}
2022-11-23 01:37:33,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:33,733 INFO:     Epoch: 28
2022-11-23 01:37:34,561 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.804601054977287, 'Total loss': 0.804601054977287} | train loss {'Reaction outcome loss': 0.8126190392480742, 'Total loss': 0.8126190392480742}
2022-11-23 01:37:34,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:34,562 INFO:     Epoch: 29
2022-11-23 01:37:35,348 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7800832892006094, 'Total loss': 0.7800832892006094} | train loss {'Reaction outcome loss': 0.8158702485023006, 'Total loss': 0.8158702485023006}
2022-11-23 01:37:35,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:35,349 INFO:     Epoch: 30
2022-11-23 01:37:36,184 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7672495896166022, 'Total loss': 0.7672495896166022} | train loss {'Reaction outcome loss': 0.8082098166548437, 'Total loss': 0.8082098166548437}
2022-11-23 01:37:36,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:36,184 INFO:     Epoch: 31
2022-11-23 01:37:36,999 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.778240313922817, 'Total loss': 0.778240313922817} | train loss {'Reaction outcome loss': 0.8100602239851029, 'Total loss': 0.8100602239851029}
2022-11-23 01:37:37,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:37,000 INFO:     Epoch: 32
2022-11-23 01:37:37,822 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.784222004765814, 'Total loss': 0.784222004765814} | train loss {'Reaction outcome loss': 0.80781309570997, 'Total loss': 0.80781309570997}
2022-11-23 01:37:37,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:37,823 INFO:     Epoch: 33
2022-11-23 01:37:38,650 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7814201021736319, 'Total loss': 0.7814201021736319} | train loss {'Reaction outcome loss': 0.8119887285415204, 'Total loss': 0.8119887285415204}
2022-11-23 01:37:38,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:38,650 INFO:     Epoch: 34
2022-11-23 01:37:39,487 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7806104868650436, 'Total loss': 0.7806104868650436} | train loss {'Reaction outcome loss': 0.8110220830046362, 'Total loss': 0.8110220830046362}
2022-11-23 01:37:39,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:39,487 INFO:     Epoch: 35
2022-11-23 01:37:40,272 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7822362888943065, 'Total loss': 0.7822362888943065} | train loss {'Reaction outcome loss': 0.8117089716176833, 'Total loss': 0.8117089716176833}
2022-11-23 01:37:40,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:40,273 INFO:     Epoch: 36
2022-11-23 01:37:41,103 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7756952880458399, 'Total loss': 0.7756952880458399} | train loss {'Reaction outcome loss': 0.8087933616292092, 'Total loss': 0.8087933616292092}
2022-11-23 01:37:41,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:41,103 INFO:     Epoch: 37
2022-11-23 01:37:41,926 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7870968661525033, 'Total loss': 0.7870968661525033} | train loss {'Reaction outcome loss': 0.8091287622528691, 'Total loss': 0.8091287622528691}
2022-11-23 01:37:41,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:41,927 INFO:     Epoch: 38
2022-11-23 01:37:42,767 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7807132208889181, 'Total loss': 0.7807132208889181} | train loss {'Reaction outcome loss': 0.8139631809486497, 'Total loss': 0.8139631809486497}
2022-11-23 01:37:42,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:42,767 INFO:     Epoch: 39
2022-11-23 01:37:43,627 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7690508860078725, 'Total loss': 0.7690508860078725} | train loss {'Reaction outcome loss': 0.8103954890562642, 'Total loss': 0.8103954890562642}
2022-11-23 01:37:43,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:43,627 INFO:     Epoch: 40
2022-11-23 01:37:44,438 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7691943327134306, 'Total loss': 0.7691943327134306} | train loss {'Reaction outcome loss': 0.8115986332056984, 'Total loss': 0.8115986332056984}
2022-11-23 01:37:44,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:44,438 INFO:     Epoch: 41
2022-11-23 01:37:45,252 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7930981950326399, 'Total loss': 0.7930981950326399} | train loss {'Reaction outcome loss': 0.8104007810113891, 'Total loss': 0.8104007810113891}
2022-11-23 01:37:45,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:45,253 INFO:     Epoch: 42
2022-11-23 01:37:46,061 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7789738659154285, 'Total loss': 0.7789738659154285} | train loss {'Reaction outcome loss': 0.8147210048571709, 'Total loss': 0.8147210048571709}
2022-11-23 01:37:46,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:46,062 INFO:     Epoch: 43
2022-11-23 01:37:46,874 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7761724618348208, 'Total loss': 0.7761724618348208} | train loss {'Reaction outcome loss': 0.8097993839652308, 'Total loss': 0.8097993839652308}
2022-11-23 01:37:46,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:46,875 INFO:     Epoch: 44
2022-11-23 01:37:47,648 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7814332490617578, 'Total loss': 0.7814332490617578} | train loss {'Reaction outcome loss': 0.8088691796987287, 'Total loss': 0.8088691796987287}
2022-11-23 01:37:47,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:47,649 INFO:     Epoch: 45
2022-11-23 01:37:48,452 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7799146527593787, 'Total loss': 0.7799146527593787} | train loss {'Reaction outcome loss': 0.8083999042789782, 'Total loss': 0.8083999042789782}
2022-11-23 01:37:48,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:48,453 INFO:     Epoch: 46
2022-11-23 01:37:49,277 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.787965519184416, 'Total loss': 0.787965519184416} | train loss {'Reaction outcome loss': 0.8075599023892034, 'Total loss': 0.8075599023892034}
2022-11-23 01:37:49,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:49,278 INFO:     Epoch: 47
2022-11-23 01:37:50,098 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7874945889819752, 'Total loss': 0.7874945889819752} | train loss {'Reaction outcome loss': 0.811460180388343, 'Total loss': 0.811460180388343}
2022-11-23 01:37:50,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:50,098 INFO:     Epoch: 48
2022-11-23 01:37:50,907 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7765213671055707, 'Total loss': 0.7765213671055707} | train loss {'Reaction outcome loss': 0.8097554612303933, 'Total loss': 0.8097554612303933}
2022-11-23 01:37:50,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:50,907 INFO:     Epoch: 49
2022-11-23 01:37:51,718 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7700287049466913, 'Total loss': 0.7700287049466913} | train loss {'Reaction outcome loss': 0.8112228574051011, 'Total loss': 0.8112228574051011}
2022-11-23 01:37:51,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:51,719 INFO:     Epoch: 50
2022-11-23 01:37:52,545 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7884870327331803, 'Total loss': 0.7884870327331803} | train loss {'Reaction outcome loss': 0.8112105465223712, 'Total loss': 0.8112105465223712}
2022-11-23 01:37:52,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:52,545 INFO:     Epoch: 51
2022-11-23 01:37:53,382 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7916362597183748, 'Total loss': 0.7916362597183748} | train loss {'Reaction outcome loss': 0.8098559360350331, 'Total loss': 0.8098559360350331}
2022-11-23 01:37:53,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:53,382 INFO:     Epoch: 52
2022-11-23 01:37:54,184 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7766122804446653, 'Total loss': 0.7766122804446653} | train loss {'Reaction outcome loss': 0.8058831385306774, 'Total loss': 0.8058831385306774}
2022-11-23 01:37:54,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:54,185 INFO:     Epoch: 53
2022-11-23 01:37:54,989 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8036509501663122, 'Total loss': 0.8036509501663122} | train loss {'Reaction outcome loss': 0.8129926638737801, 'Total loss': 0.8129926638737801}
2022-11-23 01:37:54,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:54,989 INFO:     Epoch: 54
2022-11-23 01:37:55,816 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7564001286571677, 'Total loss': 0.7564001286571677} | train loss {'Reaction outcome loss': 0.8103206235795252, 'Total loss': 0.8103206235795252}
2022-11-23 01:37:55,816 INFO:     Found new best model at epoch 54
2022-11-23 01:37:55,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:55,817 INFO:     Epoch: 55
2022-11-23 01:37:56,623 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7901313873854551, 'Total loss': 0.7901313873854551} | train loss {'Reaction outcome loss': 0.8067877681985978, 'Total loss': 0.8067877681985978}
2022-11-23 01:37:56,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:56,624 INFO:     Epoch: 56
2022-11-23 01:37:57,449 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7631840793923899, 'Total loss': 0.7631840793923899} | train loss {'Reaction outcome loss': 0.8139213658869267, 'Total loss': 0.8139213658869267}
2022-11-23 01:37:57,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:57,449 INFO:     Epoch: 57
2022-11-23 01:37:58,243 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7665307399901476, 'Total loss': 0.7665307399901476} | train loss {'Reaction outcome loss': 0.8114320038547439, 'Total loss': 0.8114320038547439}
2022-11-23 01:37:58,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:58,244 INFO:     Epoch: 58
2022-11-23 01:37:59,086 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8118155883117155, 'Total loss': 0.8118155883117155} | train loss {'Reaction outcome loss': 0.8056143503035268, 'Total loss': 0.8056143503035268}
2022-11-23 01:37:59,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:59,086 INFO:     Epoch: 59
2022-11-23 01:37:59,932 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7946656034751372, 'Total loss': 0.7946656034751372} | train loss {'Reaction outcome loss': 0.812108171082312, 'Total loss': 0.812108171082312}
2022-11-23 01:37:59,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:37:59,933 INFO:     Epoch: 60
2022-11-23 01:38:00,739 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7849239713766358, 'Total loss': 0.7849239713766358} | train loss {'Reaction outcome loss': 0.8075121570258371, 'Total loss': 0.8075121570258371}
2022-11-23 01:38:00,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:00,740 INFO:     Epoch: 61
2022-11-23 01:38:01,581 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7721363482150164, 'Total loss': 0.7721363482150164} | train loss {'Reaction outcome loss': 0.8087336221529592, 'Total loss': 0.8087336221529592}
2022-11-23 01:38:01,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:01,581 INFO:     Epoch: 62
2022-11-23 01:38:02,415 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7838293205608021, 'Total loss': 0.7838293205608021} | train loss {'Reaction outcome loss': 0.810411307840578, 'Total loss': 0.810411307840578}
2022-11-23 01:38:02,415 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:02,415 INFO:     Epoch: 63
2022-11-23 01:38:03,243 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7727577395059846, 'Total loss': 0.7727577395059846} | train loss {'Reaction outcome loss': 0.811130570908708, 'Total loss': 0.811130570908708}
2022-11-23 01:38:03,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:03,243 INFO:     Epoch: 64
2022-11-23 01:38:04,033 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7681970650499518, 'Total loss': 0.7681970650499518} | train loss {'Reaction outcome loss': 0.8103317965663248, 'Total loss': 0.8103317965663248}
2022-11-23 01:38:04,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:04,033 INFO:     Epoch: 65
2022-11-23 01:38:04,881 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7796538831158117, 'Total loss': 0.7796538831158117} | train loss {'Reaction outcome loss': 0.8077607086348918, 'Total loss': 0.8077607086348918}
2022-11-23 01:38:04,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:04,882 INFO:     Epoch: 66
2022-11-23 01:38:05,737 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7824832776730711, 'Total loss': 0.7824832776730711} | train loss {'Reaction outcome loss': 0.8087193791664415, 'Total loss': 0.8087193791664415}
2022-11-23 01:38:05,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:05,737 INFO:     Epoch: 67
2022-11-23 01:38:06,568 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7695827673782002, 'Total loss': 0.7695827673782002} | train loss {'Reaction outcome loss': 0.8152201353542267, 'Total loss': 0.8152201353542267}
2022-11-23 01:38:06,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:06,568 INFO:     Epoch: 68
2022-11-23 01:38:07,416 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7668366818265482, 'Total loss': 0.7668366818265482} | train loss {'Reaction outcome loss': 0.810891795663103, 'Total loss': 0.810891795663103}
2022-11-23 01:38:07,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:07,416 INFO:     Epoch: 69
2022-11-23 01:38:08,193 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7668938210064714, 'Total loss': 0.7668938210064714} | train loss {'Reaction outcome loss': 0.8116923786940113, 'Total loss': 0.8116923786940113}
2022-11-23 01:38:08,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:08,193 INFO:     Epoch: 70
2022-11-23 01:38:09,021 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.781794168732383, 'Total loss': 0.781794168732383} | train loss {'Reaction outcome loss': 0.8105599249322568, 'Total loss': 0.8105599249322568}
2022-11-23 01:38:09,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:09,021 INFO:     Epoch: 71
2022-11-23 01:38:09,883 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7910931333899498, 'Total loss': 0.7910931333899498} | train loss {'Reaction outcome loss': 0.8023786505143489, 'Total loss': 0.8023786505143489}
2022-11-23 01:38:09,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:09,884 INFO:     Epoch: 72
2022-11-23 01:38:10,734 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7564632025631991, 'Total loss': 0.7564632025631991} | train loss {'Reaction outcome loss': 0.807123871940759, 'Total loss': 0.807123871940759}
2022-11-23 01:38:10,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:10,734 INFO:     Epoch: 73
2022-11-23 01:38:11,527 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7781251594424248, 'Total loss': 0.7781251594424248} | train loss {'Reaction outcome loss': 0.8072868954510458, 'Total loss': 0.8072868954510458}
2022-11-23 01:38:11,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:11,527 INFO:     Epoch: 74
2022-11-23 01:38:12,339 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8172693076458845, 'Total loss': 0.8172693076458845} | train loss {'Reaction outcome loss': 0.8057470285604077, 'Total loss': 0.8057470285604077}
2022-11-23 01:38:12,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:12,340 INFO:     Epoch: 75
2022-11-23 01:38:13,171 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7785208292982795, 'Total loss': 0.7785208292982795} | train loss {'Reaction outcome loss': 0.8106592833515136, 'Total loss': 0.8106592833515136}
2022-11-23 01:38:13,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:13,171 INFO:     Epoch: 76
2022-11-23 01:38:13,973 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7937078733335842, 'Total loss': 0.7937078733335842} | train loss {'Reaction outcome loss': 0.8034788087731407, 'Total loss': 0.8034788087731407}
2022-11-23 01:38:13,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:13,974 INFO:     Epoch: 77
2022-11-23 01:38:14,772 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7712418118661101, 'Total loss': 0.7712418118661101} | train loss {'Reaction outcome loss': 0.8099043374100039, 'Total loss': 0.8099043374100039}
2022-11-23 01:38:14,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:14,772 INFO:     Epoch: 78
2022-11-23 01:38:15,591 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7662403610619631, 'Total loss': 0.7662403610619631} | train loss {'Reaction outcome loss': 0.8049662590267197, 'Total loss': 0.8049662590267197}
2022-11-23 01:38:15,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:15,591 INFO:     Epoch: 79
2022-11-23 01:38:16,408 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7741530693390153, 'Total loss': 0.7741530693390153} | train loss {'Reaction outcome loss': 0.807597336629706, 'Total loss': 0.807597336629706}
2022-11-23 01:38:16,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:16,408 INFO:     Epoch: 80
2022-11-23 01:38:17,248 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8186097700487484, 'Total loss': 0.8186097700487484} | train loss {'Reaction outcome loss': 0.8039401820109736, 'Total loss': 0.8039401820109736}
2022-11-23 01:38:17,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:17,249 INFO:     Epoch: 81
2022-11-23 01:38:18,056 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7823796929283575, 'Total loss': 0.7823796929283575} | train loss {'Reaction outcome loss': 0.8037399965668878, 'Total loss': 0.8037399965668878}
2022-11-23 01:38:18,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:18,057 INFO:     Epoch: 82
2022-11-23 01:38:18,887 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.790275900201364, 'Total loss': 0.790275900201364} | train loss {'Reaction outcome loss': 0.8066300329181456, 'Total loss': 0.8066300329181456}
2022-11-23 01:38:18,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:18,887 INFO:     Epoch: 83
2022-11-23 01:38:19,724 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7704407748850909, 'Total loss': 0.7704407748850909} | train loss {'Reaction outcome loss': 0.8081595003604889, 'Total loss': 0.8081595003604889}
2022-11-23 01:38:19,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:19,724 INFO:     Epoch: 84
2022-11-23 01:38:20,506 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7686477093534037, 'Total loss': 0.7686477093534037} | train loss {'Reaction outcome loss': 0.812149868857476, 'Total loss': 0.812149868857476}
2022-11-23 01:38:20,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:20,506 INFO:     Epoch: 85
2022-11-23 01:38:21,322 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7765899801796133, 'Total loss': 0.7765899801796133} | train loss {'Reaction outcome loss': 0.8025696108177784, 'Total loss': 0.8025696108177784}
2022-11-23 01:38:21,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:21,322 INFO:     Epoch: 86
2022-11-23 01:38:22,262 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8284127583557909, 'Total loss': 0.8284127583557909} | train loss {'Reaction outcome loss': 0.8075586414385226, 'Total loss': 0.8075586414385226}
2022-11-23 01:38:22,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:22,262 INFO:     Epoch: 87
2022-11-23 01:38:23,072 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7733386409553614, 'Total loss': 0.7733386409553614} | train loss {'Reaction outcome loss': 0.8064076451043929, 'Total loss': 0.8064076451043929}
2022-11-23 01:38:23,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:23,072 INFO:     Epoch: 88
2022-11-23 01:38:23,934 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7993744103745981, 'Total loss': 0.7993744103745981} | train loss {'Reaction outcome loss': 0.8019290780348163, 'Total loss': 0.8019290780348163}
2022-11-23 01:38:23,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:23,934 INFO:     Epoch: 89
2022-11-23 01:38:24,781 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.771828709000891, 'Total loss': 0.771828709000891} | train loss {'Reaction outcome loss': 0.8048742502447097, 'Total loss': 0.8048742502447097}
2022-11-23 01:38:24,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:24,781 INFO:     Epoch: 90
2022-11-23 01:38:25,682 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7869837284088135, 'Total loss': 0.7869837284088135} | train loss {'Reaction outcome loss': 0.8085251868732514, 'Total loss': 0.8085251868732514}
2022-11-23 01:38:25,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:25,683 INFO:     Epoch: 91
2022-11-23 01:38:26,532 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7726245895028114, 'Total loss': 0.7726245895028114} | train loss {'Reaction outcome loss': 0.8062006206281723, 'Total loss': 0.8062006206281723}
2022-11-23 01:38:26,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:26,532 INFO:     Epoch: 92
2022-11-23 01:38:27,472 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.776005092669617, 'Total loss': 0.776005092669617} | train loss {'Reaction outcome loss': 0.7988205359828088, 'Total loss': 0.7988205359828088}
2022-11-23 01:38:27,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:27,472 INFO:     Epoch: 93
2022-11-23 01:38:28,366 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7902988791465759, 'Total loss': 0.7902988791465759} | train loss {'Reaction outcome loss': 0.8106961353651939, 'Total loss': 0.8106961353651939}
2022-11-23 01:38:28,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:28,366 INFO:     Epoch: 94
2022-11-23 01:38:29,242 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7777915495363149, 'Total loss': 0.7777915495363149} | train loss {'Reaction outcome loss': 0.8059198934464685, 'Total loss': 0.8059198934464685}
2022-11-23 01:38:29,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:29,243 INFO:     Epoch: 95
2022-11-23 01:38:30,118 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7686603421514685, 'Total loss': 0.7686603421514685} | train loss {'Reaction outcome loss': 0.8040951430316894, 'Total loss': 0.8040951430316894}
2022-11-23 01:38:30,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:30,119 INFO:     Epoch: 96
2022-11-23 01:38:31,033 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7904230735518716, 'Total loss': 0.7904230735518716} | train loss {'Reaction outcome loss': 0.806539892669647, 'Total loss': 0.806539892669647}
2022-11-23 01:38:31,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:31,033 INFO:     Epoch: 97
2022-11-23 01:38:31,963 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7786595611409708, 'Total loss': 0.7786595611409708} | train loss {'Reaction outcome loss': 0.800460223829554, 'Total loss': 0.800460223829554}
2022-11-23 01:38:31,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:31,964 INFO:     Epoch: 98
2022-11-23 01:38:32,845 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7761299434033307, 'Total loss': 0.7761299434033307} | train loss {'Reaction outcome loss': 0.8024156222180012, 'Total loss': 0.8024156222180012}
2022-11-23 01:38:32,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:32,845 INFO:     Epoch: 99
2022-11-23 01:38:33,779 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7625904496420514, 'Total loss': 0.7625904496420514} | train loss {'Reaction outcome loss': 0.8063304265660625, 'Total loss': 0.8063304265660625}
2022-11-23 01:38:33,779 INFO:     Best model found after epoch 55 of 100.
2022-11-23 01:38:33,779 INFO:   Done with stage: TRAINING
2022-11-23 01:38:33,779 INFO:   Starting stage: EVALUATION
2022-11-23 01:38:33,898 INFO:   Done with stage: EVALUATION
2022-11-23 01:38:33,899 INFO:   Leaving out SEQ value Fold_7
2022-11-23 01:38:33,912 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 01:38:33,912 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:38:34,596 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:38:34,596 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:38:34,670 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:38:34,670 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:38:34,670 INFO:     No hyperparam tuning for this model
2022-11-23 01:38:34,670 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:38:34,671 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:38:34,671 INFO:     None feature selector for col prot
2022-11-23 01:38:34,672 INFO:     None feature selector for col prot
2022-11-23 01:38:34,672 INFO:     None feature selector for col prot
2022-11-23 01:38:34,672 INFO:     None feature selector for col chem
2022-11-23 01:38:34,672 INFO:     None feature selector for col chem
2022-11-23 01:38:34,672 INFO:     None feature selector for col chem
2022-11-23 01:38:34,673 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:38:34,673 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:38:34,674 INFO:     Number of params in model 168571
2022-11-23 01:38:34,678 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:38:34,678 INFO:   Starting stage: TRAINING
2022-11-23 01:38:34,738 INFO:     Val loss before train {'Reaction outcome loss': 1.0264680189165203, 'Total loss': 1.0264680189165203}
2022-11-23 01:38:34,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:34,738 INFO:     Epoch: 0
2022-11-23 01:38:35,682 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8456324535337362, 'Total loss': 0.8456324535337362} | train loss {'Reaction outcome loss': 0.8737725224572155, 'Total loss': 0.8737725224572155}
2022-11-23 01:38:35,682 INFO:     Found new best model at epoch 0
2022-11-23 01:38:35,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:35,683 INFO:     Epoch: 1
2022-11-23 01:38:36,593 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8523569046096369, 'Total loss': 0.8523569046096369} | train loss {'Reaction outcome loss': 0.845418135405552, 'Total loss': 0.845418135405552}
2022-11-23 01:38:36,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:36,594 INFO:     Epoch: 2
2022-11-23 01:38:37,506 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8266193087805401, 'Total loss': 0.8266193087805401} | train loss {'Reaction outcome loss': 0.8398057370774659, 'Total loss': 0.8398057370774659}
2022-11-23 01:38:37,506 INFO:     Found new best model at epoch 2
2022-11-23 01:38:37,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:37,507 INFO:     Epoch: 3
2022-11-23 01:38:38,374 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8203888623551889, 'Total loss': 0.8203888623551889} | train loss {'Reaction outcome loss': 0.8302461101941252, 'Total loss': 0.8302461101941252}
2022-11-23 01:38:38,374 INFO:     Found new best model at epoch 3
2022-11-23 01:38:38,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:38,375 INFO:     Epoch: 4
2022-11-23 01:38:39,260 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.836341267959638, 'Total loss': 0.836341267959638} | train loss {'Reaction outcome loss': 0.8256664218810889, 'Total loss': 0.8256664218810889}
2022-11-23 01:38:39,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:39,261 INFO:     Epoch: 5
2022-11-23 01:38:40,149 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8133102160963145, 'Total loss': 0.8133102160963145} | train loss {'Reaction outcome loss': 0.8245914211639991, 'Total loss': 0.8245914211639991}
2022-11-23 01:38:40,149 INFO:     Found new best model at epoch 5
2022-11-23 01:38:40,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:40,150 INFO:     Epoch: 6
2022-11-23 01:38:41,026 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8204245966943827, 'Total loss': 0.8204245966943827} | train loss {'Reaction outcome loss': 0.8258295891738614, 'Total loss': 0.8258295891738614}
2022-11-23 01:38:41,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:41,026 INFO:     Epoch: 7
2022-11-23 01:38:41,895 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8094129711389542, 'Total loss': 0.8094129711389542} | train loss {'Reaction outcome loss': 0.8144750879843708, 'Total loss': 0.8144750879843708}
2022-11-23 01:38:41,895 INFO:     Found new best model at epoch 7
2022-11-23 01:38:41,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:41,896 INFO:     Epoch: 8
2022-11-23 01:38:42,756 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.833370097658851, 'Total loss': 0.833370097658851} | train loss {'Reaction outcome loss': 0.8197759062896374, 'Total loss': 0.8197759062896374}
2022-11-23 01:38:42,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:42,756 INFO:     Epoch: 9
2022-11-23 01:38:43,627 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8267630365761843, 'Total loss': 0.8267630365761843} | train loss {'Reaction outcome loss': 0.8233403364415111, 'Total loss': 0.8233403364415111}
2022-11-23 01:38:43,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:43,627 INFO:     Epoch: 10
2022-11-23 01:38:44,494 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8236643902280114, 'Total loss': 0.8236643902280114} | train loss {'Reaction outcome loss': 0.8140267101135331, 'Total loss': 0.8140267101135331}
2022-11-23 01:38:44,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:44,494 INFO:     Epoch: 11
2022-11-23 01:38:45,340 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8435979492285035, 'Total loss': 0.8435979492285035} | train loss {'Reaction outcome loss': 0.8108085097088987, 'Total loss': 0.8108085097088987}
2022-11-23 01:38:45,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:45,341 INFO:     Epoch: 12
2022-11-23 01:38:46,186 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8151223984631625, 'Total loss': 0.8151223984631625} | train loss {'Reaction outcome loss': 0.8125700971134279, 'Total loss': 0.8125700971134279}
2022-11-23 01:38:46,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:46,186 INFO:     Epoch: 13
2022-11-23 01:38:47,010 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8122063915837895, 'Total loss': 0.8122063915837895} | train loss {'Reaction outcome loss': 0.8063801308633828, 'Total loss': 0.8063801308633828}
2022-11-23 01:38:47,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:47,010 INFO:     Epoch: 14
2022-11-23 01:38:47,869 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8235140977935358, 'Total loss': 0.8235140977935358} | train loss {'Reaction outcome loss': 0.8023346727676237, 'Total loss': 0.8023346727676237}
2022-11-23 01:38:47,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:47,870 INFO:     Epoch: 15
2022-11-23 01:38:48,752 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7977855811742219, 'Total loss': 0.7977855811742219} | train loss {'Reaction outcome loss': 0.8116699065032759, 'Total loss': 0.8116699065032759}
2022-11-23 01:38:48,753 INFO:     Found new best model at epoch 15
2022-11-23 01:38:48,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:48,754 INFO:     Epoch: 16
2022-11-23 01:38:49,606 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8138954788446426, 'Total loss': 0.8138954788446426} | train loss {'Reaction outcome loss': 0.801513989927315, 'Total loss': 0.801513989927315}
2022-11-23 01:38:49,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:49,606 INFO:     Epoch: 17
2022-11-23 01:38:50,472 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8252266015518795, 'Total loss': 0.8252266015518795} | train loss {'Reaction outcome loss': 0.8034134238113758, 'Total loss': 0.8034134238113758}
2022-11-23 01:38:50,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:50,473 INFO:     Epoch: 18
2022-11-23 01:38:51,322 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.821663417599418, 'Total loss': 0.821663417599418} | train loss {'Reaction outcome loss': 0.8099990893713376, 'Total loss': 0.8099990893713376}
2022-11-23 01:38:51,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:51,322 INFO:     Epoch: 19
2022-11-23 01:38:52,151 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8368225131522525, 'Total loss': 0.8368225131522525} | train loss {'Reaction outcome loss': 0.8048638398589393, 'Total loss': 0.8048638398589393}
2022-11-23 01:38:52,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:52,152 INFO:     Epoch: 20
2022-11-23 01:38:52,994 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8206160352988676, 'Total loss': 0.8206160352988676} | train loss {'Reaction outcome loss': 0.8054306709890061, 'Total loss': 0.8054306709890061}
2022-11-23 01:38:52,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:52,994 INFO:     Epoch: 21
2022-11-23 01:38:53,883 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8165823268619451, 'Total loss': 0.8165823268619451} | train loss {'Reaction outcome loss': 0.8108425116249425, 'Total loss': 0.8108425116249425}
2022-11-23 01:38:53,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:53,884 INFO:     Epoch: 22
2022-11-23 01:38:54,756 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8204912096261978, 'Total loss': 0.8204912096261978} | train loss {'Reaction outcome loss': 0.8089864011476879, 'Total loss': 0.8089864011476879}
2022-11-23 01:38:54,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:54,757 INFO:     Epoch: 23
2022-11-23 01:38:55,628 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8265247392383489, 'Total loss': 0.8265247392383489} | train loss {'Reaction outcome loss': 0.8106240460023224, 'Total loss': 0.8106240460023224}
2022-11-23 01:38:55,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:55,629 INFO:     Epoch: 24
2022-11-23 01:38:56,586 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8222062621604312, 'Total loss': 0.8222062621604312} | train loss {'Reaction outcome loss': 0.8090796329473194, 'Total loss': 0.8090796329473194}
2022-11-23 01:38:56,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:56,586 INFO:     Epoch: 25
2022-11-23 01:38:57,443 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8260167925195261, 'Total loss': 0.8260167925195261} | train loss {'Reaction outcome loss': 0.8033284982930311, 'Total loss': 0.8033284982930311}
2022-11-23 01:38:57,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:57,444 INFO:     Epoch: 26
2022-11-23 01:38:58,393 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8072952452031049, 'Total loss': 0.8072952452031049} | train loss {'Reaction outcome loss': 0.8097864219292938, 'Total loss': 0.8097864219292938}
2022-11-23 01:38:58,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:58,393 INFO:     Epoch: 27
2022-11-23 01:38:59,273 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8152824890884486, 'Total loss': 0.8152824890884486} | train loss {'Reaction outcome loss': 0.8009681945990937, 'Total loss': 0.8009681945990937}
2022-11-23 01:38:59,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:38:59,273 INFO:     Epoch: 28
2022-11-23 01:39:00,142 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8073456334796819, 'Total loss': 0.8073456334796819} | train loss {'Reaction outcome loss': 0.802754744163409, 'Total loss': 0.802754744163409}
2022-11-23 01:39:00,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:00,143 INFO:     Epoch: 29
2022-11-23 01:39:00,974 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8020565408197317, 'Total loss': 0.8020565408197317} | train loss {'Reaction outcome loss': 0.8009059271107801, 'Total loss': 0.8009059271107801}
2022-11-23 01:39:00,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:00,974 INFO:     Epoch: 30
2022-11-23 01:39:01,857 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.798490697009997, 'Total loss': 0.798490697009997} | train loss {'Reaction outcome loss': 0.8075213527631181, 'Total loss': 0.8075213527631181}
2022-11-23 01:39:01,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:01,858 INFO:     Epoch: 31
2022-11-23 01:39:02,727 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8191064325245944, 'Total loss': 0.8191064325245944} | train loss {'Reaction outcome loss': 0.802554260155088, 'Total loss': 0.802554260155088}
2022-11-23 01:39:02,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:02,728 INFO:     Epoch: 32
2022-11-23 01:39:03,636 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.808090516789393, 'Total loss': 0.808090516789393} | train loss {'Reaction outcome loss': 0.8064086737661709, 'Total loss': 0.8064086737661709}
2022-11-23 01:39:03,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:03,637 INFO:     Epoch: 33
2022-11-23 01:39:04,495 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.805866652591662, 'Total loss': 0.805866652591662} | train loss {'Reaction outcome loss': 0.8044221103191376, 'Total loss': 0.8044221103191376}
2022-11-23 01:39:04,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:04,495 INFO:     Epoch: 34
2022-11-23 01:39:05,350 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8137575516646559, 'Total loss': 0.8137575516646559} | train loss {'Reaction outcome loss': 0.804399240113463, 'Total loss': 0.804399240113463}
2022-11-23 01:39:05,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:05,350 INFO:     Epoch: 35
2022-11-23 01:39:06,215 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8110056851397861, 'Total loss': 0.8110056851397861} | train loss {'Reaction outcome loss': 0.805461955094627, 'Total loss': 0.805461955094627}
2022-11-23 01:39:06,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:06,216 INFO:     Epoch: 36
2022-11-23 01:39:07,076 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8162997581742026, 'Total loss': 0.8162997581742026} | train loss {'Reaction outcome loss': 0.8096247139247322, 'Total loss': 0.8096247139247322}
2022-11-23 01:39:07,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:07,077 INFO:     Epoch: 37
2022-11-23 01:39:07,943 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8026458106257699, 'Total loss': 0.8026458106257699} | train loss {'Reaction outcome loss': 0.8094059849074977, 'Total loss': 0.8094059849074977}
2022-11-23 01:39:07,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:07,944 INFO:     Epoch: 38
2022-11-23 01:39:08,799 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8150571408596906, 'Total loss': 0.8150571408596906} | train loss {'Reaction outcome loss': 0.8026665388813868, 'Total loss': 0.8026665388813868}
2022-11-23 01:39:08,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:08,799 INFO:     Epoch: 39
2022-11-23 01:39:09,698 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8087691813707352, 'Total loss': 0.8087691813707352} | train loss {'Reaction outcome loss': 0.8035229341945185, 'Total loss': 0.8035229341945185}
2022-11-23 01:39:09,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:09,698 INFO:     Epoch: 40
2022-11-23 01:39:10,595 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8186058063398708, 'Total loss': 0.8186058063398708} | train loss {'Reaction outcome loss': 0.7993004382983876, 'Total loss': 0.7993004382983876}
2022-11-23 01:39:10,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:10,595 INFO:     Epoch: 41
2022-11-23 01:39:11,496 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8212013739076528, 'Total loss': 0.8212013739076528} | train loss {'Reaction outcome loss': 0.8109404398844793, 'Total loss': 0.8109404398844793}
2022-11-23 01:39:11,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:11,496 INFO:     Epoch: 42
2022-11-23 01:39:12,398 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8088916804302823, 'Total loss': 0.8088916804302823} | train loss {'Reaction outcome loss': 0.80499806710583, 'Total loss': 0.80499806710583}
2022-11-23 01:39:12,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:12,399 INFO:     Epoch: 43
2022-11-23 01:39:13,263 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8222051716663621, 'Total loss': 0.8222051716663621} | train loss {'Reaction outcome loss': 0.8067242004852063, 'Total loss': 0.8067242004852063}
2022-11-23 01:39:13,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:13,263 INFO:     Epoch: 44
2022-11-23 01:39:14,092 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8139468377286737, 'Total loss': 0.8139468377286737} | train loss {'Reaction outcome loss': 0.8040596011136225, 'Total loss': 0.8040596011136225}
2022-11-23 01:39:14,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:14,092 INFO:     Epoch: 45
2022-11-23 01:39:14,950 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8159463459795172, 'Total loss': 0.8159463459795172} | train loss {'Reaction outcome loss': 0.8088354040012669, 'Total loss': 0.8088354040012669}
2022-11-23 01:39:14,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:14,950 INFO:     Epoch: 46
2022-11-23 01:39:15,799 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8437507856975902, 'Total loss': 0.8437507856975902} | train loss {'Reaction outcome loss': 0.8179298828729251, 'Total loss': 0.8179298828729251}
2022-11-23 01:39:15,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:15,799 INFO:     Epoch: 47
2022-11-23 01:39:16,699 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8218578919768333, 'Total loss': 0.8218578919768333} | train loss {'Reaction outcome loss': 0.815350839362936, 'Total loss': 0.815350839362936}
2022-11-23 01:39:16,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:16,699 INFO:     Epoch: 48
2022-11-23 01:39:17,550 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8273834823207422, 'Total loss': 0.8273834823207422} | train loss {'Reaction outcome loss': 0.809557810486087, 'Total loss': 0.809557810486087}
2022-11-23 01:39:17,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:17,550 INFO:     Epoch: 49
2022-11-23 01:39:18,435 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8364727287129923, 'Total loss': 0.8364727287129923} | train loss {'Reaction outcome loss': 0.8104590649305567, 'Total loss': 0.8104590649305567}
2022-11-23 01:39:18,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:18,436 INFO:     Epoch: 50
2022-11-23 01:39:19,277 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8444853743368929, 'Total loss': 0.8444853743368929} | train loss {'Reaction outcome loss': 0.8002421553077003, 'Total loss': 0.8002421553077003}
2022-11-23 01:39:19,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:19,277 INFO:     Epoch: 51
2022-11-23 01:39:20,118 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8157571107149124, 'Total loss': 0.8157571107149124} | train loss {'Reaction outcome loss': 0.799131196158135, 'Total loss': 0.799131196158135}
2022-11-23 01:39:20,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:20,120 INFO:     Epoch: 52
2022-11-23 01:39:20,946 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8044044497338209, 'Total loss': 0.8044044497338209} | train loss {'Reaction outcome loss': 0.8079972135031271, 'Total loss': 0.8079972135031271}
2022-11-23 01:39:20,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:20,947 INFO:     Epoch: 53
2022-11-23 01:39:21,784 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8280197598717429, 'Total loss': 0.8280197598717429} | train loss {'Reaction outcome loss': 0.809510661402212, 'Total loss': 0.809510661402212}
2022-11-23 01:39:21,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:21,784 INFO:     Epoch: 54
2022-11-23 01:39:22,623 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8302092890847813, 'Total loss': 0.8302092890847813} | train loss {'Reaction outcome loss': 0.8079929599153851, 'Total loss': 0.8079929599153851}
2022-11-23 01:39:22,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:22,623 INFO:     Epoch: 55
2022-11-23 01:39:23,481 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8429493240334771, 'Total loss': 0.8429493240334771} | train loss {'Reaction outcome loss': 0.8047516314606917, 'Total loss': 0.8047516314606917}
2022-11-23 01:39:23,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:23,482 INFO:     Epoch: 56
2022-11-23 01:39:24,337 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8210855356671594, 'Total loss': 0.8210855356671594} | train loss {'Reaction outcome loss': 0.7994883348825972, 'Total loss': 0.7994883348825972}
2022-11-23 01:39:24,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:24,338 INFO:     Epoch: 57
2022-11-23 01:39:25,241 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8405879641121085, 'Total loss': 0.8405879641121085} | train loss {'Reaction outcome loss': 0.7970646864730819, 'Total loss': 0.7970646864730819}
2022-11-23 01:39:25,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:25,241 INFO:     Epoch: 58
2022-11-23 01:39:26,036 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8130839236757972, 'Total loss': 0.8130839236757972} | train loss {'Reaction outcome loss': 0.8071847821054189, 'Total loss': 0.8071847821054189}
2022-11-23 01:39:26,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:26,036 INFO:     Epoch: 59
2022-11-23 01:39:26,880 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8217459260062738, 'Total loss': 0.8217459260062738} | train loss {'Reaction outcome loss': 0.8059958517551422, 'Total loss': 0.8059958517551422}
2022-11-23 01:39:26,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:26,880 INFO:     Epoch: 60
2022-11-23 01:39:27,740 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8123803328384053, 'Total loss': 0.8123803328384053} | train loss {'Reaction outcome loss': 0.8044229362175049, 'Total loss': 0.8044229362175049}
2022-11-23 01:39:27,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:27,741 INFO:     Epoch: 61
2022-11-23 01:39:28,614 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8310646706006743, 'Total loss': 0.8310646706006743} | train loss {'Reaction outcome loss': 0.8076695289598544, 'Total loss': 0.8076695289598544}
2022-11-23 01:39:28,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:28,615 INFO:     Epoch: 62
2022-11-23 01:39:29,489 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7978468842127107, 'Total loss': 0.7978468842127107} | train loss {'Reaction outcome loss': 0.8049651894884312, 'Total loss': 0.8049651894884312}
2022-11-23 01:39:29,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:29,489 INFO:     Epoch: 63
2022-11-23 01:39:30,318 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.813554434613748, 'Total loss': 0.813554434613748} | train loss {'Reaction outcome loss': 0.8064766836914457, 'Total loss': 0.8064766836914457}
2022-11-23 01:39:30,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:30,318 INFO:     Epoch: 64
2022-11-23 01:39:31,173 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8054173019799319, 'Total loss': 0.8054173019799319} | train loss {'Reaction outcome loss': 0.8104122778182088, 'Total loss': 0.8104122778182088}
2022-11-23 01:39:31,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:31,173 INFO:     Epoch: 65
2022-11-23 01:39:31,994 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8130339627916162, 'Total loss': 0.8130339627916162} | train loss {'Reaction outcome loss': 0.8072164474952559, 'Total loss': 0.8072164474952559}
2022-11-23 01:39:31,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:31,995 INFO:     Epoch: 66
2022-11-23 01:39:32,798 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8244913152673028, 'Total loss': 0.8244913152673028} | train loss {'Reaction outcome loss': 0.8060886998649551, 'Total loss': 0.8060886998649551}
2022-11-23 01:39:32,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:32,800 INFO:     Epoch: 67
2022-11-23 01:39:33,613 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8210167295553468, 'Total loss': 0.8210167295553468} | train loss {'Reaction outcome loss': 0.8093645233615689, 'Total loss': 0.8093645233615689}
2022-11-23 01:39:33,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:33,613 INFO:     Epoch: 68
2022-11-23 01:39:34,464 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8165538676760413, 'Total loss': 0.8165538676760413} | train loss {'Reaction outcome loss': 0.8012941922645579, 'Total loss': 0.8012941922645579}
2022-11-23 01:39:34,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:34,464 INFO:     Epoch: 69
2022-11-23 01:39:35,276 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8251333453438499, 'Total loss': 0.8251333453438499} | train loss {'Reaction outcome loss': 0.8008889349908964, 'Total loss': 0.8008889349908964}
2022-11-23 01:39:35,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:35,276 INFO:     Epoch: 70
2022-11-23 01:39:36,051 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8127259686589241, 'Total loss': 0.8127259686589241} | train loss {'Reaction outcome loss': 0.8087432614342887, 'Total loss': 0.8087432614342887}
2022-11-23 01:39:36,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:36,052 INFO:     Epoch: 71
2022-11-23 01:39:36,914 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8408739146861163, 'Total loss': 0.8408739146861163} | train loss {'Reaction outcome loss': 0.8100245814574393, 'Total loss': 0.8100245814574393}
2022-11-23 01:39:36,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:36,914 INFO:     Epoch: 72
2022-11-23 01:39:37,735 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8056117404590953, 'Total loss': 0.8056117404590953} | train loss {'Reaction outcome loss': 0.7997085338662028, 'Total loss': 0.7997085338662028}
2022-11-23 01:39:37,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:37,735 INFO:     Epoch: 73
2022-11-23 01:39:38,574 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8245084468613971, 'Total loss': 0.8245084468613971} | train loss {'Reaction outcome loss': 0.8033714002443229, 'Total loss': 0.8033714002443229}
2022-11-23 01:39:38,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:38,574 INFO:     Epoch: 74
2022-11-23 01:39:39,338 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8131822103803809, 'Total loss': 0.8131822103803809} | train loss {'Reaction outcome loss': 0.8080917746431915, 'Total loss': 0.8080917746431915}
2022-11-23 01:39:39,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:39,339 INFO:     Epoch: 75
2022-11-23 01:39:40,144 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8090341998772188, 'Total loss': 0.8090341998772188} | train loss {'Reaction outcome loss': 0.8109018764032526, 'Total loss': 0.8109018764032526}
2022-11-23 01:39:40,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:40,144 INFO:     Epoch: 76
2022-11-23 01:39:40,936 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8117552921175957, 'Total loss': 0.8117552921175957} | train loss {'Reaction outcome loss': 0.8007822092848751, 'Total loss': 0.8007822092848751}
2022-11-23 01:39:40,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:40,937 INFO:     Epoch: 77
2022-11-23 01:39:41,729 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8158661235462535, 'Total loss': 0.8158661235462535} | train loss {'Reaction outcome loss': 0.7994591115939955, 'Total loss': 0.7994591115939955}
2022-11-23 01:39:41,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:41,729 INFO:     Epoch: 78
2022-11-23 01:39:42,553 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.81861162930727, 'Total loss': 0.81861162930727} | train loss {'Reaction outcome loss': 0.8100813423332415, 'Total loss': 0.8100813423332415}
2022-11-23 01:39:42,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:42,553 INFO:     Epoch: 79
2022-11-23 01:39:43,396 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8196834359656681, 'Total loss': 0.8196834359656681} | train loss {'Reaction outcome loss': 0.8162268537741441, 'Total loss': 0.8162268537741441}
2022-11-23 01:39:43,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:43,396 INFO:     Epoch: 80
2022-11-23 01:39:44,199 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.898954573680054, 'Total loss': 0.898954573680054} | train loss {'Reaction outcome loss': 0.8133314399101473, 'Total loss': 0.8133314399101473}
2022-11-23 01:39:44,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:44,199 INFO:     Epoch: 81
2022-11-23 01:39:45,092 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8272739940068938, 'Total loss': 0.8272739940068938} | train loss {'Reaction outcome loss': 0.8074696071536435, 'Total loss': 0.8074696071536435}
2022-11-23 01:39:45,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:45,092 INFO:     Epoch: 82
2022-11-23 01:39:45,923 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8004257678985596, 'Total loss': 0.8004257678985596} | train loss {'Reaction outcome loss': 0.8032585386986192, 'Total loss': 0.8032585386986192}
2022-11-23 01:39:45,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:45,923 INFO:     Epoch: 83
2022-11-23 01:39:46,726 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8064325289292769, 'Total loss': 0.8064325289292769} | train loss {'Reaction outcome loss': 0.798836081646956, 'Total loss': 0.798836081646956}
2022-11-23 01:39:46,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:46,726 INFO:     Epoch: 84
2022-11-23 01:39:47,510 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8067508441480723, 'Total loss': 0.8067508441480723} | train loss {'Reaction outcome loss': 0.8054712321835491, 'Total loss': 0.8054712321835491}
2022-11-23 01:39:47,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:47,510 INFO:     Epoch: 85
2022-11-23 01:39:48,313 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8026066618886861, 'Total loss': 0.8026066618886861} | train loss {'Reaction outcome loss': 0.8075666646001792, 'Total loss': 0.8075666646001792}
2022-11-23 01:39:48,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:48,313 INFO:     Epoch: 86
2022-11-23 01:39:49,136 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8288150355219841, 'Total loss': 0.8288150355219841} | train loss {'Reaction outcome loss': 0.8064959607867577, 'Total loss': 0.8064959607867577}
2022-11-23 01:39:49,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:49,136 INFO:     Epoch: 87
2022-11-23 01:39:49,913 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8202172761613672, 'Total loss': 0.8202172761613672} | train loss {'Reaction outcome loss': 0.8063995923831878, 'Total loss': 0.8063995923831878}
2022-11-23 01:39:49,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:49,914 INFO:     Epoch: 88
2022-11-23 01:39:50,741 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8131470443172888, 'Total loss': 0.8131470443172888} | train loss {'Reaction outcome loss': 0.8004955433399571, 'Total loss': 0.8004955433399571}
2022-11-23 01:39:50,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:50,741 INFO:     Epoch: 89
2022-11-23 01:39:51,540 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8110683512958613, 'Total loss': 0.8110683512958613} | train loss {'Reaction outcome loss': 0.8027103720647604, 'Total loss': 0.8027103720647604}
2022-11-23 01:39:51,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:51,541 INFO:     Epoch: 90
2022-11-23 01:39:52,362 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8451781117103316, 'Total loss': 0.8451781117103316} | train loss {'Reaction outcome loss': 0.8058635588840917, 'Total loss': 0.8058635588840917}
2022-11-23 01:39:52,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:52,362 INFO:     Epoch: 91
2022-11-23 01:39:53,160 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.810079076750712, 'Total loss': 0.810079076750712} | train loss {'Reaction outcome loss': 0.8089209518693237, 'Total loss': 0.8089209518693237}
2022-11-23 01:39:53,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:53,160 INFO:     Epoch: 92
2022-11-23 01:39:53,966 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8159395334395495, 'Total loss': 0.8159395334395495} | train loss {'Reaction outcome loss': 0.8102858456281515, 'Total loss': 0.8102858456281515}
2022-11-23 01:39:53,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:53,967 INFO:     Epoch: 93
2022-11-23 01:39:54,770 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8122978488152678, 'Total loss': 0.8122978488152678} | train loss {'Reaction outcome loss': 0.8052072272850916, 'Total loss': 0.8052072272850916}
2022-11-23 01:39:54,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:54,771 INFO:     Epoch: 94
2022-11-23 01:39:55,551 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8052362515167757, 'Total loss': 0.8052362515167757} | train loss {'Reaction outcome loss': 0.8090111373165841, 'Total loss': 0.8090111373165841}
2022-11-23 01:39:55,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:55,551 INFO:     Epoch: 95
2022-11-23 01:39:56,376 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8103065185926177, 'Total loss': 0.8103065185926177} | train loss {'Reaction outcome loss': 0.8033372379748928, 'Total loss': 0.8033372379748928}
2022-11-23 01:39:56,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:56,377 INFO:     Epoch: 96
2022-11-23 01:39:57,197 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8139561150561679, 'Total loss': 0.8139561150561679} | train loss {'Reaction outcome loss': 0.808698008568422, 'Total loss': 0.808698008568422}
2022-11-23 01:39:57,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:57,197 INFO:     Epoch: 97
2022-11-23 01:39:57,969 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8127068443731829, 'Total loss': 0.8127068443731829} | train loss {'Reaction outcome loss': 0.7968943262027826, 'Total loss': 0.7968943262027826}
2022-11-23 01:39:57,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:57,969 INFO:     Epoch: 98
2022-11-23 01:39:58,740 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8097320673140612, 'Total loss': 0.8097320673140612} | train loss {'Reaction outcome loss': 0.8107313435328635, 'Total loss': 0.8107313435328635}
2022-11-23 01:39:58,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:39:58,740 INFO:     Epoch: 99
2022-11-23 01:39:59,547 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8339115794409405, 'Total loss': 0.8339115794409405} | train loss {'Reaction outcome loss': 0.8109680115271677, 'Total loss': 0.8109680115271677}
2022-11-23 01:39:59,547 INFO:     Best model found after epoch 16 of 100.
2022-11-23 01:39:59,548 INFO:   Done with stage: TRAINING
2022-11-23 01:39:59,548 INFO:   Starting stage: EVALUATION
2022-11-23 01:39:59,674 INFO:   Done with stage: EVALUATION
2022-11-23 01:39:59,674 INFO:   Leaving out SEQ value Fold_8
2022-11-23 01:39:59,688 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-23 01:39:59,688 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:40:00,356 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:40:00,357 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:40:00,427 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:40:00,427 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:40:00,427 INFO:     No hyperparam tuning for this model
2022-11-23 01:40:00,427 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:40:00,427 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:40:00,428 INFO:     None feature selector for col prot
2022-11-23 01:40:00,428 INFO:     None feature selector for col prot
2022-11-23 01:40:00,428 INFO:     None feature selector for col prot
2022-11-23 01:40:00,429 INFO:     None feature selector for col chem
2022-11-23 01:40:00,429 INFO:     None feature selector for col chem
2022-11-23 01:40:00,429 INFO:     None feature selector for col chem
2022-11-23 01:40:00,429 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:40:00,429 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:40:00,431 INFO:     Number of params in model 168571
2022-11-23 01:40:00,434 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:40:00,434 INFO:   Starting stage: TRAINING
2022-11-23 01:40:00,494 INFO:     Val loss before train {'Reaction outcome loss': 0.9552396684885025, 'Total loss': 0.9552396684885025}
2022-11-23 01:40:00,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:00,494 INFO:     Epoch: 0
2022-11-23 01:40:01,249 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8020474091172218, 'Total loss': 0.8020474091172218} | train loss {'Reaction outcome loss': 0.8804223704094789, 'Total loss': 0.8804223704094789}
2022-11-23 01:40:01,250 INFO:     Found new best model at epoch 0
2022-11-23 01:40:01,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:01,250 INFO:     Epoch: 1
2022-11-23 01:40:02,021 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.782015593891794, 'Total loss': 0.782015593891794} | train loss {'Reaction outcome loss': 0.8463564653785861, 'Total loss': 0.8463564653785861}
2022-11-23 01:40:02,021 INFO:     Found new best model at epoch 1
2022-11-23 01:40:02,022 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:02,022 INFO:     Epoch: 2
2022-11-23 01:40:02,821 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8005996102636511, 'Total loss': 0.8005996102636511} | train loss {'Reaction outcome loss': 0.8449933942483396, 'Total loss': 0.8449933942483396}
2022-11-23 01:40:02,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:02,821 INFO:     Epoch: 3
2022-11-23 01:40:03,586 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7753937163136222, 'Total loss': 0.7753937163136222} | train loss {'Reaction outcome loss': 0.838081026563839, 'Total loss': 0.838081026563839}
2022-11-23 01:40:03,587 INFO:     Found new best model at epoch 3
2022-11-23 01:40:03,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:03,588 INFO:     Epoch: 4
2022-11-23 01:40:04,375 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7948542975566604, 'Total loss': 0.7948542975566604} | train loss {'Reaction outcome loss': 0.8378580033779144, 'Total loss': 0.8378580033779144}
2022-11-23 01:40:04,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:04,375 INFO:     Epoch: 5
2022-11-23 01:40:05,181 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8033688820221208, 'Total loss': 0.8033688820221208} | train loss {'Reaction outcome loss': 0.8335377500981701, 'Total loss': 0.8335377500981701}
2022-11-23 01:40:05,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:05,182 INFO:     Epoch: 6
2022-11-23 01:40:06,003 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7894439087672667, 'Total loss': 0.7894439087672667} | train loss {'Reaction outcome loss': 0.8350140790550076, 'Total loss': 0.8350140790550076}
2022-11-23 01:40:06,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:06,003 INFO:     Epoch: 7
2022-11-23 01:40:06,783 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7869602976874872, 'Total loss': 0.7869602976874872} | train loss {'Reaction outcome loss': 0.8316247150606039, 'Total loss': 0.8316247150606039}
2022-11-23 01:40:06,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:06,783 INFO:     Epoch: 8
2022-11-23 01:40:07,587 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7940872717987407, 'Total loss': 0.7940872717987407} | train loss {'Reaction outcome loss': 0.8243625119024394, 'Total loss': 0.8243625119024394}
2022-11-23 01:40:07,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:07,588 INFO:     Epoch: 9
2022-11-23 01:40:08,400 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7986649207093499, 'Total loss': 0.7986649207093499} | train loss {'Reaction outcome loss': 0.825883097672949, 'Total loss': 0.825883097672949}
2022-11-23 01:40:08,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:08,401 INFO:     Epoch: 10
2022-11-23 01:40:09,199 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7974775054238059, 'Total loss': 0.7974775054238059} | train loss {'Reaction outcome loss': 0.8249280514765759, 'Total loss': 0.8249280514765759}
2022-11-23 01:40:09,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:09,200 INFO:     Epoch: 11
2022-11-23 01:40:09,976 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7841909798708829, 'Total loss': 0.7841909798708829} | train loss {'Reaction outcome loss': 0.825343098932383, 'Total loss': 0.825343098932383}
2022-11-23 01:40:09,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:09,977 INFO:     Epoch: 12
2022-11-23 01:40:10,824 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7802648171782494, 'Total loss': 0.7802648171782494} | train loss {'Reaction outcome loss': 0.8206940537812758, 'Total loss': 0.8206940537812758}
2022-11-23 01:40:10,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:10,825 INFO:     Epoch: 13
2022-11-23 01:40:11,666 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7836938554590399, 'Total loss': 0.7836938554590399} | train loss {'Reaction outcome loss': 0.8209284315303881, 'Total loss': 0.8209284315303881}
2022-11-23 01:40:11,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:11,666 INFO:     Epoch: 14
2022-11-23 01:40:12,410 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7849229641936042, 'Total loss': 0.7849229641936042} | train loss {'Reaction outcome loss': 0.8191183675308616, 'Total loss': 0.8191183675308616}
2022-11-23 01:40:12,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:12,410 INFO:     Epoch: 15
2022-11-23 01:40:13,206 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7935089841485023, 'Total loss': 0.7935089841485023} | train loss {'Reaction outcome loss': 0.8204882349286761, 'Total loss': 0.8204882349286761}
2022-11-23 01:40:13,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:13,206 INFO:     Epoch: 16
2022-11-23 01:40:14,031 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.783997237005017, 'Total loss': 0.783997237005017} | train loss {'Reaction outcome loss': 0.821355260756551, 'Total loss': 0.821355260756551}
2022-11-23 01:40:14,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:14,032 INFO:     Epoch: 17
2022-11-23 01:40:14,829 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7812462090091272, 'Total loss': 0.7812462090091272} | train loss {'Reaction outcome loss': 0.8178467428197667, 'Total loss': 0.8178467428197667}
2022-11-23 01:40:14,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:14,829 INFO:     Epoch: 18
2022-11-23 01:40:15,668 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7647147629071366, 'Total loss': 0.7647147629071366} | train loss {'Reaction outcome loss': 0.819959383108178, 'Total loss': 0.819959383108178}
2022-11-23 01:40:15,668 INFO:     Found new best model at epoch 18
2022-11-23 01:40:15,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:15,669 INFO:     Epoch: 19
2022-11-23 01:40:16,454 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7790230871601538, 'Total loss': 0.7790230871601538} | train loss {'Reaction outcome loss': 0.8169970534285721, 'Total loss': 0.8169970534285721}
2022-11-23 01:40:16,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:16,454 INFO:     Epoch: 20
2022-11-23 01:40:17,256 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7739791775291617, 'Total loss': 0.7739791775291617} | train loss {'Reaction outcome loss': 0.8166103493194191, 'Total loss': 0.8166103493194191}
2022-11-23 01:40:17,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:17,256 INFO:     Epoch: 21
2022-11-23 01:40:18,046 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7867833944884214, 'Total loss': 0.7867833944884214} | train loss {'Reaction outcome loss': 0.820725046250285, 'Total loss': 0.820725046250285}
2022-11-23 01:40:18,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:18,046 INFO:     Epoch: 22
2022-11-23 01:40:18,903 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7722348679195751, 'Total loss': 0.7722348679195751} | train loss {'Reaction outcome loss': 0.8153247015816825, 'Total loss': 0.8153247015816825}
2022-11-23 01:40:18,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:18,903 INFO:     Epoch: 23
2022-11-23 01:40:19,699 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7840827263214372, 'Total loss': 0.7840827263214372} | train loss {'Reaction outcome loss': 0.8157561536954374, 'Total loss': 0.8157561536954374}
2022-11-23 01:40:19,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:19,700 INFO:     Epoch: 24
2022-11-23 01:40:20,470 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7930706983262842, 'Total loss': 0.7930706983262842} | train loss {'Reaction outcome loss': 0.8187400397597527, 'Total loss': 0.8187400397597527}
2022-11-23 01:40:20,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:20,470 INFO:     Epoch: 25
2022-11-23 01:40:21,239 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7693181837146933, 'Total loss': 0.7693181837146933} | train loss {'Reaction outcome loss': 0.8134022125176021, 'Total loss': 0.8134022125176021}
2022-11-23 01:40:21,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:21,239 INFO:     Epoch: 26
2022-11-23 01:40:22,037 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8083925260738893, 'Total loss': 0.8083925260738893} | train loss {'Reaction outcome loss': 0.817339601078812, 'Total loss': 0.817339601078812}
2022-11-23 01:40:22,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:22,037 INFO:     Epoch: 27
2022-11-23 01:40:22,808 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7743967832489447, 'Total loss': 0.7743967832489447} | train loss {'Reaction outcome loss': 0.8207580070106351, 'Total loss': 0.8207580070106351}
2022-11-23 01:40:22,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:22,808 INFO:     Epoch: 28
2022-11-23 01:40:23,624 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.769222382794727, 'Total loss': 0.769222382794727} | train loss {'Reaction outcome loss': 0.8166236769179909, 'Total loss': 0.8166236769179909}
2022-11-23 01:40:23,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:23,624 INFO:     Epoch: 29
2022-11-23 01:40:24,450 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7913922410119664, 'Total loss': 0.7913922410119664} | train loss {'Reaction outcome loss': 0.820713105250378, 'Total loss': 0.820713105250378}
2022-11-23 01:40:24,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:24,451 INFO:     Epoch: 30
2022-11-23 01:40:25,215 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7608648626641794, 'Total loss': 0.7608648626641794} | train loss {'Reaction outcome loss': 0.8186255244576202, 'Total loss': 0.8186255244576202}
2022-11-23 01:40:25,216 INFO:     Found new best model at epoch 30
2022-11-23 01:40:25,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:25,217 INFO:     Epoch: 31
2022-11-23 01:40:25,996 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7995287437330593, 'Total loss': 0.7995287437330593} | train loss {'Reaction outcome loss': 0.8157841725008829, 'Total loss': 0.8157841725008829}
2022-11-23 01:40:25,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:25,996 INFO:     Epoch: 32
2022-11-23 01:40:26,758 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7783361375331879, 'Total loss': 0.7783361375331879} | train loss {'Reaction outcome loss': 0.8127549960905192, 'Total loss': 0.8127549960905192}
2022-11-23 01:40:26,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:26,758 INFO:     Epoch: 33
2022-11-23 01:40:27,521 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7618593133308671, 'Total loss': 0.7618593133308671} | train loss {'Reaction outcome loss': 0.813914899436795, 'Total loss': 0.813914899436795}
2022-11-23 01:40:27,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:27,521 INFO:     Epoch: 34
2022-11-23 01:40:28,294 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7909646867351099, 'Total loss': 0.7909646867351099} | train loss {'Reaction outcome loss': 0.8179414509510508, 'Total loss': 0.8179414509510508}
2022-11-23 01:40:28,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:28,294 INFO:     Epoch: 35
2022-11-23 01:40:29,130 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.769362052733248, 'Total loss': 0.769362052733248} | train loss {'Reaction outcome loss': 0.8178096513358915, 'Total loss': 0.8178096513358915}
2022-11-23 01:40:29,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:29,130 INFO:     Epoch: 36
2022-11-23 01:40:29,927 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7673519429835406, 'Total loss': 0.7673519429835406} | train loss {'Reaction outcome loss': 0.8159155185125312, 'Total loss': 0.8159155185125312}
2022-11-23 01:40:29,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:29,927 INFO:     Epoch: 37
2022-11-23 01:40:30,743 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7614677568728273, 'Total loss': 0.7614677568728273} | train loss {'Reaction outcome loss': 0.8120794964079954, 'Total loss': 0.8120794964079954}
2022-11-23 01:40:30,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:30,744 INFO:     Epoch: 38
2022-11-23 01:40:31,514 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.760993748225949, 'Total loss': 0.760993748225949} | train loss {'Reaction outcome loss': 0.8146241391191678, 'Total loss': 0.8146241391191678}
2022-11-23 01:40:31,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:31,514 INFO:     Epoch: 39
2022-11-23 01:40:32,273 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7648288221521811, 'Total loss': 0.7648288221521811} | train loss {'Reaction outcome loss': 0.8140894962816823, 'Total loss': 0.8140894962816823}
2022-11-23 01:40:32,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:32,273 INFO:     Epoch: 40
2022-11-23 01:40:33,108 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7576501193371686, 'Total loss': 0.7576501193371686} | train loss {'Reaction outcome loss': 0.8138948809127419, 'Total loss': 0.8138948809127419}
2022-11-23 01:40:33,108 INFO:     Found new best model at epoch 40
2022-11-23 01:40:33,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:33,109 INFO:     Epoch: 41
2022-11-23 01:40:33,889 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7663702842864123, 'Total loss': 0.7663702842864123} | train loss {'Reaction outcome loss': 0.8118280919230714, 'Total loss': 0.8118280919230714}
2022-11-23 01:40:33,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:33,890 INFO:     Epoch: 42
2022-11-23 01:40:34,684 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.767085381529548, 'Total loss': 0.767085381529548} | train loss {'Reaction outcome loss': 0.8127661504307572, 'Total loss': 0.8127661504307572}
2022-11-23 01:40:34,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:34,685 INFO:     Epoch: 43
2022-11-23 01:40:35,462 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7777426107363268, 'Total loss': 0.7777426107363268} | train loss {'Reaction outcome loss': 0.8162337057444514, 'Total loss': 0.8162337057444514}
2022-11-23 01:40:35,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:35,462 INFO:     Epoch: 44
2022-11-23 01:40:36,275 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7748401151462034, 'Total loss': 0.7748401151462034} | train loss {'Reaction outcome loss': 0.8115596148432518, 'Total loss': 0.8115596148432518}
2022-11-23 01:40:36,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:36,276 INFO:     Epoch: 45
2022-11-23 01:40:37,060 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7702470272779465, 'Total loss': 0.7702470272779465} | train loss {'Reaction outcome loss': 0.8160592849157294, 'Total loss': 0.8160592849157294}
2022-11-23 01:40:37,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:37,060 INFO:     Epoch: 46
2022-11-23 01:40:37,845 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7630181793462146, 'Total loss': 0.7630181793462146} | train loss {'Reaction outcome loss': 0.8157544713847491, 'Total loss': 0.8157544713847491}
2022-11-23 01:40:37,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:37,845 INFO:     Epoch: 47
2022-11-23 01:40:38,642 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7905157655477524, 'Total loss': 0.7905157655477524} | train loss {'Reaction outcome loss': 0.813739576874947, 'Total loss': 0.813739576874947}
2022-11-23 01:40:38,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:38,642 INFO:     Epoch: 48
2022-11-23 01:40:39,476 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7783276892521165, 'Total loss': 0.7783276892521165} | train loss {'Reaction outcome loss': 0.8140261637921236, 'Total loss': 0.8140261637921236}
2022-11-23 01:40:39,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:39,477 INFO:     Epoch: 49
2022-11-23 01:40:40,270 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.798701748251915, 'Total loss': 0.798701748251915} | train loss {'Reaction outcome loss': 0.8134017202318932, 'Total loss': 0.8134017202318932}
2022-11-23 01:40:40,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:40,270 INFO:     Epoch: 50
2022-11-23 01:40:41,116 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.758949646895582, 'Total loss': 0.758949646895582} | train loss {'Reaction outcome loss': 0.8125997329244808, 'Total loss': 0.8125997329244808}
2022-11-23 01:40:41,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:41,116 INFO:     Epoch: 51
2022-11-23 01:40:41,918 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7922624004158106, 'Total loss': 0.7922624004158106} | train loss {'Reaction outcome loss': 0.8134899769510542, 'Total loss': 0.8134899769510542}
2022-11-23 01:40:41,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:41,919 INFO:     Epoch: 52
2022-11-23 01:40:42,728 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.794062618504871, 'Total loss': 0.794062618504871} | train loss {'Reaction outcome loss': 0.8111010371422281, 'Total loss': 0.8111010371422281}
2022-11-23 01:40:42,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:42,728 INFO:     Epoch: 53
2022-11-23 01:40:43,519 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7734910242936828, 'Total loss': 0.7734910242936828} | train loss {'Reaction outcome loss': 0.8181361514694837, 'Total loss': 0.8181361514694837}
2022-11-23 01:40:43,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:43,519 INFO:     Epoch: 54
2022-11-23 01:40:44,324 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7589024488221515, 'Total loss': 0.7589024488221515} | train loss {'Reaction outcome loss': 0.8155975226236849, 'Total loss': 0.8155975226236849}
2022-11-23 01:40:44,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:44,324 INFO:     Epoch: 55
2022-11-23 01:40:45,104 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.770922037010843, 'Total loss': 0.770922037010843} | train loss {'Reaction outcome loss': 0.8176887259191397, 'Total loss': 0.8176887259191397}
2022-11-23 01:40:45,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:45,105 INFO:     Epoch: 56
2022-11-23 01:40:45,915 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7836037840355526, 'Total loss': 0.7836037840355526} | train loss {'Reaction outcome loss': 0.8132756565298352, 'Total loss': 0.8132756565298352}
2022-11-23 01:40:45,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:45,915 INFO:     Epoch: 57
2022-11-23 01:40:46,690 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7812141417102381, 'Total loss': 0.7812141417102381} | train loss {'Reaction outcome loss': 0.8155618491221447, 'Total loss': 0.8155618491221447}
2022-11-23 01:40:46,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:46,690 INFO:     Epoch: 58
2022-11-23 01:40:47,530 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7713941796259447, 'Total loss': 0.7713941796259447} | train loss {'Reaction outcome loss': 0.8123096244675773, 'Total loss': 0.8123096244675773}
2022-11-23 01:40:47,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:47,531 INFO:     Epoch: 59
2022-11-23 01:40:48,314 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7624410922554407, 'Total loss': 0.7624410922554407} | train loss {'Reaction outcome loss': 0.8155021526375595, 'Total loss': 0.8155021526375595}
2022-11-23 01:40:48,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:48,315 INFO:     Epoch: 60
2022-11-23 01:40:49,104 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7743044211105867, 'Total loss': 0.7743044211105867} | train loss {'Reaction outcome loss': 0.8152756386873673, 'Total loss': 0.8152756386873673}
2022-11-23 01:40:49,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:49,104 INFO:     Epoch: 61
2022-11-23 01:40:49,903 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7668679756197062, 'Total loss': 0.7668679756197062} | train loss {'Reaction outcome loss': 0.8162643694147772, 'Total loss': 0.8162643694147772}
2022-11-23 01:40:49,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:49,903 INFO:     Epoch: 62
2022-11-23 01:40:50,667 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.767987690188668, 'Total loss': 0.767987690188668} | train loss {'Reaction outcome loss': 0.8144857474735805, 'Total loss': 0.8144857474735805}
2022-11-23 01:40:50,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:50,667 INFO:     Epoch: 63
2022-11-23 01:40:51,484 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7787868238308213, 'Total loss': 0.7787868238308213} | train loss {'Reaction outcome loss': 0.8140955258388909, 'Total loss': 0.8140955258388909}
2022-11-23 01:40:51,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:51,485 INFO:     Epoch: 64
2022-11-23 01:40:52,286 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7642690789970484, 'Total loss': 0.7642690789970484} | train loss {'Reaction outcome loss': 0.8104943827706941, 'Total loss': 0.8104943827706941}
2022-11-23 01:40:52,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:52,286 INFO:     Epoch: 65
2022-11-23 01:40:53,098 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7651836008510806, 'Total loss': 0.7651836008510806} | train loss {'Reaction outcome loss': 0.8111851120481686, 'Total loss': 0.8111851120481686}
2022-11-23 01:40:53,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:53,099 INFO:     Epoch: 66
2022-11-23 01:40:53,884 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.779172074388374, 'Total loss': 0.779172074388374} | train loss {'Reaction outcome loss': 0.809375744449849, 'Total loss': 0.809375744449849}
2022-11-23 01:40:53,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:53,884 INFO:     Epoch: 67
2022-11-23 01:40:54,700 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7684277133508162, 'Total loss': 0.7684277133508162} | train loss {'Reaction outcome loss': 0.8160536774567195, 'Total loss': 0.8160536774567195}
2022-11-23 01:40:54,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:54,700 INFO:     Epoch: 68
2022-11-23 01:40:55,503 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7859939377416264, 'Total loss': 0.7859939377416264} | train loss {'Reaction outcome loss': 0.8111772622380938, 'Total loss': 0.8111772622380938}
2022-11-23 01:40:55,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:55,503 INFO:     Epoch: 69
2022-11-23 01:40:56,369 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7638598782095042, 'Total loss': 0.7638598782095042} | train loss {'Reaction outcome loss': 0.8073997874649204, 'Total loss': 0.8073997874649204}
2022-11-23 01:40:56,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:56,369 INFO:     Epoch: 70
2022-11-23 01:40:57,207 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7644658258015459, 'Total loss': 0.7644658258015459} | train loss {'Reaction outcome loss': 0.8192597333265811, 'Total loss': 0.8192597333265811}
2022-11-23 01:40:57,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:57,208 INFO:     Epoch: 71
2022-11-23 01:40:58,117 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7812340185046196, 'Total loss': 0.7812340185046196} | train loss {'Reaction outcome loss': 0.8128966554087036, 'Total loss': 0.8128966554087036}
2022-11-23 01:40:58,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:58,117 INFO:     Epoch: 72
2022-11-23 01:40:59,023 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7780959795821797, 'Total loss': 0.7780959795821797} | train loss {'Reaction outcome loss': 0.8181846819361862, 'Total loss': 0.8181846819361862}
2022-11-23 01:40:59,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:59,025 INFO:     Epoch: 73
2022-11-23 01:40:59,921 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.775844588198445, 'Total loss': 0.775844588198445} | train loss {'Reaction outcome loss': 0.8147177264398459, 'Total loss': 0.8147177264398459}
2022-11-23 01:40:59,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:40:59,922 INFO:     Epoch: 74
2022-11-23 01:41:00,791 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7781996049664237, 'Total loss': 0.7781996049664237} | train loss {'Reaction outcome loss': 0.8127109302549946, 'Total loss': 0.8127109302549946}
2022-11-23 01:41:00,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:00,791 INFO:     Epoch: 75
2022-11-23 01:41:01,712 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7704408168792725, 'Total loss': 0.7704408168792725} | train loss {'Reaction outcome loss': 0.8144971224726463, 'Total loss': 0.8144971224726463}
2022-11-23 01:41:01,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:01,712 INFO:     Epoch: 76
2022-11-23 01:41:02,576 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.758373195474798, 'Total loss': 0.758373195474798} | train loss {'Reaction outcome loss': 0.8161383693315545, 'Total loss': 0.8161383693315545}
2022-11-23 01:41:02,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:02,576 INFO:     Epoch: 77
2022-11-23 01:41:03,387 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7760523124174639, 'Total loss': 0.7760523124174639} | train loss {'Reaction outcome loss': 0.8114373311704519, 'Total loss': 0.8114373311704519}
2022-11-23 01:41:03,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:03,388 INFO:     Epoch: 78
2022-11-23 01:41:04,194 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7761105542833154, 'Total loss': 0.7761105542833154} | train loss {'Reaction outcome loss': 0.8116168907710484, 'Total loss': 0.8116168907710484}
2022-11-23 01:41:04,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:04,195 INFO:     Epoch: 79
2022-11-23 01:41:04,973 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7602219513871453, 'Total loss': 0.7602219513871453} | train loss {'Reaction outcome loss': 0.8158623047020971, 'Total loss': 0.8158623047020971}
2022-11-23 01:41:04,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:04,974 INFO:     Epoch: 80
2022-11-23 01:41:05,802 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.766427414661104, 'Total loss': 0.766427414661104} | train loss {'Reaction outcome loss': 0.815163997241429, 'Total loss': 0.815163997241429}
2022-11-23 01:41:05,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:05,802 INFO:     Epoch: 81
2022-11-23 01:41:06,631 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7745338028127496, 'Total loss': 0.7745338028127496} | train loss {'Reaction outcome loss': 0.8120254761102248, 'Total loss': 0.8120254761102248}
2022-11-23 01:41:06,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:06,631 INFO:     Epoch: 82
2022-11-23 01:41:07,453 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7692252085967497, 'Total loss': 0.7692252085967497} | train loss {'Reaction outcome loss': 0.8140290722555044, 'Total loss': 0.8140290722555044}
2022-11-23 01:41:07,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:07,453 INFO:     Epoch: 83
2022-11-23 01:41:08,305 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8024991926821795, 'Total loss': 0.8024991926821795} | train loss {'Reaction outcome loss': 0.8130826420929967, 'Total loss': 0.8130826420929967}
2022-11-23 01:41:08,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:08,305 INFO:     Epoch: 84
2022-11-23 01:41:09,106 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7576853690499609, 'Total loss': 0.7576853690499609} | train loss {'Reaction outcome loss': 0.8139963732690227, 'Total loss': 0.8139963732690227}
2022-11-23 01:41:09,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:09,107 INFO:     Epoch: 85
2022-11-23 01:41:09,928 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7910651876167818, 'Total loss': 0.7910651876167818} | train loss {'Reaction outcome loss': 0.8164503127944712, 'Total loss': 0.8164503127944712}
2022-11-23 01:41:09,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:09,928 INFO:     Epoch: 86
2022-11-23 01:41:10,685 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7877458354288881, 'Total loss': 0.7877458354288881} | train loss {'Reaction outcome loss': 0.8130119062199884, 'Total loss': 0.8130119062199884}
2022-11-23 01:41:10,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:10,685 INFO:     Epoch: 87
2022-11-23 01:41:11,456 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7541018526323817, 'Total loss': 0.7541018526323817} | train loss {'Reaction outcome loss': 0.8154557388655993, 'Total loss': 0.8154557388655993}
2022-11-23 01:41:11,456 INFO:     Found new best model at epoch 87
2022-11-23 01:41:11,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:11,457 INFO:     Epoch: 88
2022-11-23 01:41:12,260 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7764890810305421, 'Total loss': 0.7764890810305421} | train loss {'Reaction outcome loss': 0.8124570021823961, 'Total loss': 0.8124570021823961}
2022-11-23 01:41:12,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:12,260 INFO:     Epoch: 89
2022-11-23 01:41:13,059 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7626534703780304, 'Total loss': 0.7626534703780304} | train loss {'Reaction outcome loss': 0.8169562825134822, 'Total loss': 0.8169562825134822}
2022-11-23 01:41:13,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:13,059 INFO:     Epoch: 90
2022-11-23 01:41:13,848 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7703189951452342, 'Total loss': 0.7703189951452342} | train loss {'Reaction outcome loss': 0.814467519278429, 'Total loss': 0.814467519278429}
2022-11-23 01:41:13,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:13,848 INFO:     Epoch: 91
2022-11-23 01:41:14,607 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7877595560117201, 'Total loss': 0.7877595560117201} | train loss {'Reaction outcome loss': 0.8139702040321973, 'Total loss': 0.8139702040321973}
2022-11-23 01:41:14,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:14,607 INFO:     Epoch: 92
2022-11-23 01:41:15,421 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7657030163840814, 'Total loss': 0.7657030163840814} | train loss {'Reaction outcome loss': 0.8120907759179874, 'Total loss': 0.8120907759179874}
2022-11-23 01:41:15,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:15,422 INFO:     Epoch: 93
2022-11-23 01:41:16,238 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7696922851557081, 'Total loss': 0.7696922851557081} | train loss {'Reaction outcome loss': 0.8141723391961079, 'Total loss': 0.8141723391961079}
2022-11-23 01:41:16,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:16,238 INFO:     Epoch: 94
2022-11-23 01:41:17,095 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7779953330755234, 'Total loss': 0.7779953330755234} | train loss {'Reaction outcome loss': 0.8154413557782465, 'Total loss': 0.8154413557782465}
2022-11-23 01:41:17,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:17,096 INFO:     Epoch: 95
2022-11-23 01:41:17,882 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.782820534977046, 'Total loss': 0.782820534977046} | train loss {'Reaction outcome loss': 0.8130161296348183, 'Total loss': 0.8130161296348183}
2022-11-23 01:41:17,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:17,882 INFO:     Epoch: 96
2022-11-23 01:41:18,712 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7638591067357496, 'Total loss': 0.7638591067357496} | train loss {'Reaction outcome loss': 0.8149597579119157, 'Total loss': 0.8149597579119157}
2022-11-23 01:41:18,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:18,712 INFO:     Epoch: 97
2022-11-23 01:41:19,556 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7698918161067095, 'Total loss': 0.7698918161067095} | train loss {'Reaction outcome loss': 0.8135699897396321, 'Total loss': 0.8135699897396321}
2022-11-23 01:41:19,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:19,556 INFO:     Epoch: 98
2022-11-23 01:41:20,337 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7727211767976935, 'Total loss': 0.7727211767976935} | train loss {'Reaction outcome loss': 0.8097093746370199, 'Total loss': 0.8097093746370199}
2022-11-23 01:41:20,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:20,337 INFO:     Epoch: 99
2022-11-23 01:41:21,117 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7809775431047786, 'Total loss': 0.7809775431047786} | train loss {'Reaction outcome loss': 0.8136516960299744, 'Total loss': 0.8136516960299744}
2022-11-23 01:41:21,118 INFO:     Best model found after epoch 88 of 100.
2022-11-23 01:41:21,118 INFO:   Done with stage: TRAINING
2022-11-23 01:41:21,118 INFO:   Starting stage: EVALUATION
2022-11-23 01:41:21,249 INFO:   Done with stage: EVALUATION
2022-11-23 01:41:21,249 INFO:   Leaving out SEQ value Fold_9
2022-11-23 01:41:21,262 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-23 01:41:21,263 INFO:   Starting stage: FEATURE SCALING
2022-11-23 01:41:21,934 INFO:   Done with stage: FEATURE SCALING
2022-11-23 01:41:21,934 INFO:   Starting stage: SCALING TARGETS
2022-11-23 01:41:22,004 INFO:   Done with stage: SCALING TARGETS
2022-11-23 01:41:22,005 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:41:22,005 INFO:     No hyperparam tuning for this model
2022-11-23 01:41:22,005 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-23 01:41:22,005 INFO:   Starting stage: FEATURE SELECTION
2022-11-23 01:41:22,006 INFO:     None feature selector for col prot
2022-11-23 01:41:22,006 INFO:     None feature selector for col prot
2022-11-23 01:41:22,006 INFO:     None feature selector for col prot
2022-11-23 01:41:22,006 INFO:     None feature selector for col chem
2022-11-23 01:41:22,006 INFO:     None feature selector for col chem
2022-11-23 01:41:22,007 INFO:     None feature selector for col chem
2022-11-23 01:41:22,007 INFO:   Done with stage: FEATURE SELECTION
2022-11-23 01:41:22,007 INFO:   Starting stage: BUILD MODEL
2022-11-23 01:41:22,008 INFO:     Number of params in model 168571
2022-11-23 01:41:22,011 INFO:   Done with stage: BUILD MODEL
2022-11-23 01:41:22,012 INFO:   Starting stage: TRAINING
2022-11-23 01:41:22,069 INFO:     Val loss before train {'Reaction outcome loss': 0.968853044916283, 'Total loss': 0.968853044916283}
2022-11-23 01:41:22,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:22,070 INFO:     Epoch: 0
2022-11-23 01:41:22,860 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9053310453891754, 'Total loss': 0.9053310453891754} | train loss {'Reaction outcome loss': 0.881975460149016, 'Total loss': 0.881975460149016}
2022-11-23 01:41:22,860 INFO:     Found new best model at epoch 0
2022-11-23 01:41:22,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:22,861 INFO:     Epoch: 1
2022-11-23 01:41:23,647 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8553223000331358, 'Total loss': 0.8553223000331358} | train loss {'Reaction outcome loss': 0.8494184635549422, 'Total loss': 0.8494184635549422}
2022-11-23 01:41:23,647 INFO:     Found new best model at epoch 1
2022-11-23 01:41:23,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:23,648 INFO:     Epoch: 2
2022-11-23 01:41:24,427 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8110643875869837, 'Total loss': 0.8110643875869837} | train loss {'Reaction outcome loss': 0.8457844370772482, 'Total loss': 0.8457844370772482}
2022-11-23 01:41:24,427 INFO:     Found new best model at epoch 2
2022-11-23 01:41:24,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:24,428 INFO:     Epoch: 3
2022-11-23 01:41:25,196 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8162856576117602, 'Total loss': 0.8162856576117602} | train loss {'Reaction outcome loss': 0.8443456316887126, 'Total loss': 0.8443456316887126}
2022-11-23 01:41:25,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:25,196 INFO:     Epoch: 4
2022-11-23 01:41:25,988 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8183637810024348, 'Total loss': 0.8183637810024348} | train loss {'Reaction outcome loss': 0.8347554349223612, 'Total loss': 0.8347554349223612}
2022-11-23 01:41:25,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:25,988 INFO:     Epoch: 5
2022-11-23 01:41:26,764 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8133477365428751, 'Total loss': 0.8133477365428751} | train loss {'Reaction outcome loss': 0.836950428934715, 'Total loss': 0.836950428934715}
2022-11-23 01:41:26,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:26,765 INFO:     Epoch: 6
2022-11-23 01:41:27,527 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8229572610421614, 'Total loss': 0.8229572610421614} | train loss {'Reaction outcome loss': 0.8356296406221776, 'Total loss': 0.8356296406221776}
2022-11-23 01:41:27,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:27,528 INFO:     Epoch: 7
2022-11-23 01:41:28,305 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8142492473125458, 'Total loss': 0.8142492473125458} | train loss {'Reaction outcome loss': 0.8316281840868807, 'Total loss': 0.8316281840868807}
2022-11-23 01:41:28,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:28,305 INFO:     Epoch: 8
2022-11-23 01:41:29,081 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8566713712432168, 'Total loss': 0.8566713712432168} | train loss {'Reaction outcome loss': 0.8294469508670481, 'Total loss': 0.8294469508670481}
2022-11-23 01:41:29,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:29,081 INFO:     Epoch: 9
2022-11-23 01:41:29,878 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8411029861731962, 'Total loss': 0.8411029861731962} | train loss {'Reaction outcome loss': 0.8232328583475067, 'Total loss': 0.8232328583475067}
2022-11-23 01:41:29,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:29,878 INFO:     Epoch: 10
2022-11-23 01:41:30,676 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8119294372471896, 'Total loss': 0.8119294372471896} | train loss {'Reaction outcome loss': 0.8254493220373686, 'Total loss': 0.8254493220373686}
2022-11-23 01:41:30,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:30,676 INFO:     Epoch: 11
2022-11-23 01:41:31,426 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8037647130814466, 'Total loss': 0.8037647130814466} | train loss {'Reaction outcome loss': 0.8301101575496226, 'Total loss': 0.8301101575496226}
2022-11-23 01:41:31,426 INFO:     Found new best model at epoch 11
2022-11-23 01:41:31,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:31,427 INFO:     Epoch: 12
2022-11-23 01:41:32,231 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7992045066573403, 'Total loss': 0.7992045066573403} | train loss {'Reaction outcome loss': 0.8271802077409227, 'Total loss': 0.8271802077409227}
2022-11-23 01:41:32,233 INFO:     Found new best model at epoch 12
2022-11-23 01:41:32,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:32,234 INFO:     Epoch: 13
2022-11-23 01:41:33,006 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8251112347299402, 'Total loss': 0.8251112347299402} | train loss {'Reaction outcome loss': 0.8266340487821382, 'Total loss': 0.8266340487821382}
2022-11-23 01:41:33,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:33,007 INFO:     Epoch: 14
2022-11-23 01:41:33,780 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8044903020967137, 'Total loss': 0.8044903020967137} | train loss {'Reaction outcome loss': 0.8262607321324136, 'Total loss': 0.8262607321324136}
2022-11-23 01:41:33,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:33,780 INFO:     Epoch: 15
2022-11-23 01:41:34,559 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8030393441969698, 'Total loss': 0.8030393441969698} | train loss {'Reaction outcome loss': 0.8209758280259878, 'Total loss': 0.8209758280259878}
2022-11-23 01:41:34,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:34,559 INFO:     Epoch: 16
2022-11-23 01:41:35,320 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8153613670305773, 'Total loss': 0.8153613670305773} | train loss {'Reaction outcome loss': 0.8236023380688811, 'Total loss': 0.8236023380688811}
2022-11-23 01:41:35,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:35,320 INFO:     Epoch: 17
2022-11-23 01:41:36,102 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8081229572946375, 'Total loss': 0.8081229572946375} | train loss {'Reaction outcome loss': 0.8283316741588145, 'Total loss': 0.8283316741588145}
2022-11-23 01:41:36,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:36,102 INFO:     Epoch: 18
2022-11-23 01:41:36,873 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7938486459580335, 'Total loss': 0.7938486459580335} | train loss {'Reaction outcome loss': 0.8152792919502567, 'Total loss': 0.8152792919502567}
2022-11-23 01:41:36,873 INFO:     Found new best model at epoch 18
2022-11-23 01:41:36,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:36,874 INFO:     Epoch: 19
2022-11-23 01:41:37,661 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7937170328064398, 'Total loss': 0.7937170328064398} | train loss {'Reaction outcome loss': 0.8215117028608978, 'Total loss': 0.8215117028608978}
2022-11-23 01:41:37,663 INFO:     Found new best model at epoch 19
2022-11-23 01:41:37,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:37,664 INFO:     Epoch: 20
2022-11-23 01:41:38,434 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7921304631639611, 'Total loss': 0.7921304631639611} | train loss {'Reaction outcome loss': 0.8187205992970872, 'Total loss': 0.8187205992970872}
2022-11-23 01:41:38,434 INFO:     Found new best model at epoch 20
2022-11-23 01:41:38,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:38,435 INFO:     Epoch: 21
2022-11-23 01:41:39,227 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8119374364614487, 'Total loss': 0.8119374364614487} | train loss {'Reaction outcome loss': 0.8187149200241576, 'Total loss': 0.8187149200241576}
2022-11-23 01:41:39,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:39,227 INFO:     Epoch: 22
2022-11-23 01:41:40,004 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8273579837246374, 'Total loss': 0.8273579837246374} | train loss {'Reaction outcome loss': 0.8264467999761403, 'Total loss': 0.8264467999761403}
2022-11-23 01:41:40,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:40,004 INFO:     Epoch: 23
2022-11-23 01:41:40,779 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7946377721699801, 'Total loss': 0.7946377721699801} | train loss {'Reaction outcome loss': 0.8331742591944783, 'Total loss': 0.8331742591944783}
2022-11-23 01:41:40,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:40,780 INFO:     Epoch: 24
2022-11-23 01:41:41,537 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8021245592019774, 'Total loss': 0.8021245592019774} | train loss {'Reaction outcome loss': 0.8265829136979724, 'Total loss': 0.8265829136979724}
2022-11-23 01:41:41,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:41,538 INFO:     Epoch: 25
2022-11-23 01:41:42,320 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.800793619318442, 'Total loss': 0.800793619318442} | train loss {'Reaction outcome loss': 0.8220464000817735, 'Total loss': 0.8220464000817735}
2022-11-23 01:41:42,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:42,320 INFO:     Epoch: 26
2022-11-23 01:41:43,100 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7983116852966222, 'Total loss': 0.7983116852966222} | train loss {'Reaction outcome loss': 0.8235459070094684, 'Total loss': 0.8235459070094684}
2022-11-23 01:41:43,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:43,101 INFO:     Epoch: 27
2022-11-23 01:41:43,863 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8069184530865062, 'Total loss': 0.8069184530865062} | train loss {'Reaction outcome loss': 0.817178132683642, 'Total loss': 0.817178132683642}
2022-11-23 01:41:43,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:43,863 INFO:     Epoch: 28
2022-11-23 01:41:44,609 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.791792979971929, 'Total loss': 0.791792979971929} | train loss {'Reaction outcome loss': 0.8130856774113921, 'Total loss': 0.8130856774113921}
2022-11-23 01:41:44,609 INFO:     Found new best model at epoch 28
2022-11-23 01:41:44,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:44,610 INFO:     Epoch: 29
2022-11-23 01:41:45,368 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7995198822834275, 'Total loss': 0.7995198822834275} | train loss {'Reaction outcome loss': 0.8176048373283162, 'Total loss': 0.8176048373283162}
2022-11-23 01:41:45,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:45,368 INFO:     Epoch: 30
2022-11-23 01:41:46,129 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.818149742755023, 'Total loss': 0.818149742755023} | train loss {'Reaction outcome loss': 0.8337170988441962, 'Total loss': 0.8337170988441962}
2022-11-23 01:41:46,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:46,130 INFO:     Epoch: 31
2022-11-23 01:41:46,876 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.798086820000952, 'Total loss': 0.798086820000952} | train loss {'Reaction outcome loss': 0.8210494558096897, 'Total loss': 0.8210494558096897}
2022-11-23 01:41:46,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:46,876 INFO:     Epoch: 32
2022-11-23 01:41:47,654 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8103367483074014, 'Total loss': 0.8103367483074014} | train loss {'Reaction outcome loss': 0.8110755799933966, 'Total loss': 0.8110755799933966}
2022-11-23 01:41:47,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:47,655 INFO:     Epoch: 33
2022-11-23 01:41:48,475 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8376129784367301, 'Total loss': 0.8376129784367301} | train loss {'Reaction outcome loss': 0.822965202181928, 'Total loss': 0.822965202181928}
2022-11-23 01:41:48,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:48,477 INFO:     Epoch: 34
2022-11-23 01:41:49,243 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8251636217940937, 'Total loss': 0.8251636217940937} | train loss {'Reaction outcome loss': 0.8199906870421128, 'Total loss': 0.8199906870421128}
2022-11-23 01:41:49,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:49,243 INFO:     Epoch: 35
2022-11-23 01:41:50,014 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.799421491948041, 'Total loss': 0.799421491948041} | train loss {'Reaction outcome loss': 0.8149887431970975, 'Total loss': 0.8149887431970975}
2022-11-23 01:41:50,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:50,015 INFO:     Epoch: 36
2022-11-23 01:41:50,780 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7983355224132538, 'Total loss': 0.7983355224132538} | train loss {'Reaction outcome loss': 0.8134692016883418, 'Total loss': 0.8134692016883418}
2022-11-23 01:41:50,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:50,781 INFO:     Epoch: 37
2022-11-23 01:41:51,584 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7873002283952453, 'Total loss': 0.7873002283952453} | train loss {'Reaction outcome loss': 0.8122091335564973, 'Total loss': 0.8122091335564973}
2022-11-23 01:41:51,584 INFO:     Found new best model at epoch 37
2022-11-23 01:41:51,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:51,585 INFO:     Epoch: 38
2022-11-23 01:41:52,388 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7902367541735823, 'Total loss': 0.7902367541735823} | train loss {'Reaction outcome loss': 0.8113072417706613, 'Total loss': 0.8113072417706613}
2022-11-23 01:41:52,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:52,388 INFO:     Epoch: 39
2022-11-23 01:41:53,224 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7978778393431143, 'Total loss': 0.7978778393431143} | train loss {'Reaction outcome loss': 0.817991990083263, 'Total loss': 0.817991990083263}
2022-11-23 01:41:53,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:53,225 INFO:     Epoch: 40
2022-11-23 01:41:53,987 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7986771613359451, 'Total loss': 0.7986771613359451} | train loss {'Reaction outcome loss': 0.8175493453437017, 'Total loss': 0.8175493453437017}
2022-11-23 01:41:53,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:53,988 INFO:     Epoch: 41
2022-11-23 01:41:54,767 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8024790314110842, 'Total loss': 0.8024790314110842} | train loss {'Reaction outcome loss': 0.819765403987425, 'Total loss': 0.819765403987425}
2022-11-23 01:41:54,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:54,768 INFO:     Epoch: 42
2022-11-23 01:41:55,573 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7907372117042542, 'Total loss': 0.7907372117042542} | train loss {'Reaction outcome loss': 0.8135785651110444, 'Total loss': 0.8135785651110444}
2022-11-23 01:41:55,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:55,573 INFO:     Epoch: 43
2022-11-23 01:41:56,348 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7960881076075814, 'Total loss': 0.7960881076075814} | train loss {'Reaction outcome loss': 0.8145370308445533, 'Total loss': 0.8145370308445533}
2022-11-23 01:41:56,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:56,348 INFO:     Epoch: 44
2022-11-23 01:41:57,149 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7924721891229803, 'Total loss': 0.7924721891229803} | train loss {'Reaction outcome loss': 0.8149978133589633, 'Total loss': 0.8149978133589633}
2022-11-23 01:41:57,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:57,149 INFO:     Epoch: 45
2022-11-23 01:41:57,921 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7971503538164225, 'Total loss': 0.7971503538164225} | train loss {'Reaction outcome loss': 0.8120964798126143, 'Total loss': 0.8120964798126143}
2022-11-23 01:41:57,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:57,921 INFO:     Epoch: 46
2022-11-23 01:41:58,750 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8071243194016543, 'Total loss': 0.8071243194016543} | train loss {'Reaction outcome loss': 0.8086680395279818, 'Total loss': 0.8086680395279818}
2022-11-23 01:41:58,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:58,750 INFO:     Epoch: 47
2022-11-23 01:41:59,636 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7901575389233503, 'Total loss': 0.7901575389233503} | train loss {'Reaction outcome loss': 0.8096692929504371, 'Total loss': 0.8096692929504371}
2022-11-23 01:41:59,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:41:59,637 INFO:     Epoch: 48
2022-11-23 01:42:00,484 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8617499057542194, 'Total loss': 0.8617499057542194} | train loss {'Reaction outcome loss': 0.8147709954846726, 'Total loss': 0.8147709954846726}
2022-11-23 01:42:00,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:00,484 INFO:     Epoch: 49
2022-11-23 01:42:01,347 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.792505491186272, 'Total loss': 0.792505491186272} | train loss {'Reaction outcome loss': 0.8096112172130631, 'Total loss': 0.8096112172130631}
2022-11-23 01:42:01,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:01,348 INFO:     Epoch: 50
2022-11-23 01:42:02,183 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8120274692773819, 'Total loss': 0.8120274692773819} | train loss {'Reaction outcome loss': 0.8127165889812384, 'Total loss': 0.8127165889812384}
2022-11-23 01:42:02,183 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:02,184 INFO:     Epoch: 51
2022-11-23 01:42:03,057 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7946846295486797, 'Total loss': 0.7946846295486797} | train loss {'Reaction outcome loss': 0.8109253668169744, 'Total loss': 0.8109253668169744}
2022-11-23 01:42:03,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:03,057 INFO:     Epoch: 52
2022-11-23 01:42:03,957 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.784881554543972, 'Total loss': 0.784881554543972} | train loss {'Reaction outcome loss': 0.8102627692193638, 'Total loss': 0.8102627692193638}
2022-11-23 01:42:03,957 INFO:     Found new best model at epoch 52
2022-11-23 01:42:03,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:03,958 INFO:     Epoch: 53
2022-11-23 01:42:04,837 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.792777797037905, 'Total loss': 0.792777797037905} | train loss {'Reaction outcome loss': 0.8174599600948302, 'Total loss': 0.8174599600948302}
2022-11-23 01:42:04,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:04,838 INFO:     Epoch: 54
2022-11-23 01:42:05,724 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7995425855571573, 'Total loss': 0.7995425855571573} | train loss {'Reaction outcome loss': 0.8141070125315354, 'Total loss': 0.8141070125315354}
2022-11-23 01:42:05,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:05,725 INFO:     Epoch: 55
2022-11-23 01:42:06,610 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.790419539944692, 'Total loss': 0.790419539944692} | train loss {'Reaction outcome loss': 0.8127556186817918, 'Total loss': 0.8127556186817918}
2022-11-23 01:42:06,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:06,610 INFO:     Epoch: 56
2022-11-23 01:42:07,548 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7998195060274818, 'Total loss': 0.7998195060274818} | train loss {'Reaction outcome loss': 0.8127697610149258, 'Total loss': 0.8127697610149258}
2022-11-23 01:42:07,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:07,548 INFO:     Epoch: 57
2022-11-23 01:42:08,442 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8242526325312528, 'Total loss': 0.8242526325312528} | train loss {'Reaction outcome loss': 0.8146760263122045, 'Total loss': 0.8146760263122045}
2022-11-23 01:42:08,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:08,443 INFO:     Epoch: 58
2022-11-23 01:42:09,406 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8063650368289514, 'Total loss': 0.8063650368289514} | train loss {'Reaction outcome loss': 0.81236884902846, 'Total loss': 0.81236884902846}
2022-11-23 01:42:09,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:09,407 INFO:     Epoch: 59
2022-11-23 01:42:10,333 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.783872014419599, 'Total loss': 0.783872014419599} | train loss {'Reaction outcome loss': 0.8124508535572392, 'Total loss': 0.8124508535572392}
2022-11-23 01:42:10,333 INFO:     Found new best model at epoch 59
2022-11-23 01:42:10,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:10,334 INFO:     Epoch: 60
2022-11-23 01:42:11,229 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7858557098291137, 'Total loss': 0.7858557098291137} | train loss {'Reaction outcome loss': 0.8181988623460777, 'Total loss': 0.8181988623460777}
2022-11-23 01:42:11,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:11,231 INFO:     Epoch: 61
2022-11-23 01:42:12,105 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7971924888816747, 'Total loss': 0.7971924888816747} | train loss {'Reaction outcome loss': 0.8173080174787807, 'Total loss': 0.8173080174787807}
2022-11-23 01:42:12,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:12,105 INFO:     Epoch: 62
2022-11-23 01:42:13,012 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7904308953068473, 'Total loss': 0.7904308953068473} | train loss {'Reaction outcome loss': 0.8159777615596409, 'Total loss': 0.8159777615596409}
2022-11-23 01:42:13,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:13,012 INFO:     Epoch: 63
2022-11-23 01:42:13,932 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7947070930491794, 'Total loss': 0.7947070930491794} | train loss {'Reaction outcome loss': 0.8143958425232274, 'Total loss': 0.8143958425232274}
2022-11-23 01:42:13,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:13,932 INFO:     Epoch: 64
2022-11-23 01:42:14,866 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8159580088474534, 'Total loss': 0.8159580088474534} | train loss {'Reaction outcome loss': 0.811438339019594, 'Total loss': 0.811438339019594}
2022-11-23 01:42:14,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:14,866 INFO:     Epoch: 65
2022-11-23 01:42:15,783 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8035711469975385, 'Total loss': 0.8035711469975385} | train loss {'Reaction outcome loss': 0.8183907660757482, 'Total loss': 0.8183907660757482}
2022-11-23 01:42:15,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:15,784 INFO:     Epoch: 66
2022-11-23 01:42:16,691 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7968393645503304, 'Total loss': 0.7968393645503304} | train loss {'Reaction outcome loss': 0.817507259396889, 'Total loss': 0.817507259396889}
2022-11-23 01:42:16,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:16,692 INFO:     Epoch: 67
2022-11-23 01:42:17,570 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7895221344449304, 'Total loss': 0.7895221344449304} | train loss {'Reaction outcome loss': 0.818483607609745, 'Total loss': 0.818483607609745}
2022-11-23 01:42:17,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:17,570 INFO:     Epoch: 68
2022-11-23 01:42:18,448 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8008238917047327, 'Total loss': 0.8008238917047327} | train loss {'Reaction outcome loss': 0.8127924860247716, 'Total loss': 0.8127924860247716}
2022-11-23 01:42:18,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:18,449 INFO:     Epoch: 69
2022-11-23 01:42:19,305 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7889099209146067, 'Total loss': 0.7889099209146067} | train loss {'Reaction outcome loss': 0.8129256320627112, 'Total loss': 0.8129256320627112}
2022-11-23 01:42:19,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:19,305 INFO:     Epoch: 70
2022-11-23 01:42:20,236 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.787451832131906, 'Total loss': 0.787451832131906} | train loss {'Reaction outcome loss': 0.824046232198414, 'Total loss': 0.824046232198414}
2022-11-23 01:42:20,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:20,236 INFO:     Epoch: 71
2022-11-23 01:42:21,105 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8067296784032475, 'Total loss': 0.8067296784032475} | train loss {'Reaction outcome loss': 0.8165745397931651, 'Total loss': 0.8165745397931651}
2022-11-23 01:42:21,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:21,106 INFO:     Epoch: 72
2022-11-23 01:42:21,958 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8109805367209695, 'Total loss': 0.8109805367209695} | train loss {'Reaction outcome loss': 0.8085738355331575, 'Total loss': 0.8085738355331575}
2022-11-23 01:42:21,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:21,958 INFO:     Epoch: 73
2022-11-23 01:42:22,866 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7917054092342203, 'Total loss': 0.7917054092342203} | train loss {'Reaction outcome loss': 0.808907015543235, 'Total loss': 0.808907015543235}
2022-11-23 01:42:22,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:22,867 INFO:     Epoch: 74
2022-11-23 01:42:23,760 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8005447137084875, 'Total loss': 0.8005447137084875} | train loss {'Reaction outcome loss': 0.8090239435072369, 'Total loss': 0.8090239435072369}
2022-11-23 01:42:23,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:23,760 INFO:     Epoch: 75
2022-11-23 01:42:24,662 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8008895110000264, 'Total loss': 0.8008895110000264} | train loss {'Reaction outcome loss': 0.8116922105553179, 'Total loss': 0.8116922105553179}
2022-11-23 01:42:24,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:24,662 INFO:     Epoch: 76
2022-11-23 01:42:25,528 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7882784422148358, 'Total loss': 0.7882784422148358} | train loss {'Reaction outcome loss': 0.8156220511144955, 'Total loss': 0.8156220511144955}
2022-11-23 01:42:25,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:25,529 INFO:     Epoch: 77
2022-11-23 01:42:26,432 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7916274720972235, 'Total loss': 0.7916274720972235} | train loss {'Reaction outcome loss': 0.8180928344306676, 'Total loss': 0.8180928344306676}
2022-11-23 01:42:26,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:26,432 INFO:     Epoch: 78
2022-11-23 01:42:27,301 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8226433274420825, 'Total loss': 0.8226433274420825} | train loss {'Reaction outcome loss': 0.8171987363442719, 'Total loss': 0.8171987363442719}
2022-11-23 01:42:27,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:27,302 INFO:     Epoch: 79
2022-11-23 01:42:28,192 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7823116047815843, 'Total loss': 0.7823116047815843} | train loss {'Reaction outcome loss': 0.8102567335553015, 'Total loss': 0.8102567335553015}
2022-11-23 01:42:28,192 INFO:     Found new best model at epoch 79
2022-11-23 01:42:28,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:28,193 INFO:     Epoch: 80
2022-11-23 01:42:29,066 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7901432480324398, 'Total loss': 0.7901432480324398} | train loss {'Reaction outcome loss': 0.8041149703069375, 'Total loss': 0.8041149703069375}
2022-11-23 01:42:29,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:29,066 INFO:     Epoch: 81
2022-11-23 01:42:29,941 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8076409650119868, 'Total loss': 0.8076409650119868} | train loss {'Reaction outcome loss': 0.8235714582779147, 'Total loss': 0.8235714582779147}
2022-11-23 01:42:29,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:29,942 INFO:     Epoch: 82
2022-11-23 01:42:30,755 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7855365113778547, 'Total loss': 0.7855365113778547} | train loss {'Reaction outcome loss': 0.8289051172945664, 'Total loss': 0.8289051172945664}
2022-11-23 01:42:30,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:30,755 INFO:     Epoch: 83
2022-11-23 01:42:31,675 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7978911467573859, 'Total loss': 0.7978911467573859} | train loss {'Reaction outcome loss': 0.8139861526593626, 'Total loss': 0.8139861526593626}
2022-11-23 01:42:31,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:31,675 INFO:     Epoch: 84
2022-11-23 01:42:32,567 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7971158447590742, 'Total loss': 0.7971158447590742} | train loss {'Reaction outcome loss': 0.8188837848694218, 'Total loss': 0.8188837848694218}
2022-11-23 01:42:32,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:32,568 INFO:     Epoch: 85
2022-11-23 01:42:33,449 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8042699762366035, 'Total loss': 0.8042699762366035} | train loss {'Reaction outcome loss': 0.8126635438034892, 'Total loss': 0.8126635438034892}
2022-11-23 01:42:33,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:33,449 INFO:     Epoch: 86
2022-11-23 01:42:34,323 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7895013547756455, 'Total loss': 0.7895013547756455} | train loss {'Reaction outcome loss': 0.8120596794946956, 'Total loss': 0.8120596794946956}
2022-11-23 01:42:34,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:34,323 INFO:     Epoch: 87
2022-11-23 01:42:35,208 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7991240200671282, 'Total loss': 0.7991240200671282} | train loss {'Reaction outcome loss': 0.8157075058352127, 'Total loss': 0.8157075058352127}
2022-11-23 01:42:35,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:35,208 INFO:     Epoch: 88
2022-11-23 01:42:36,088 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8076835504987023, 'Total loss': 0.8076835504987023} | train loss {'Reaction outcome loss': 0.815401520444314, 'Total loss': 0.815401520444314}
2022-11-23 01:42:36,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:36,088 INFO:     Epoch: 89
2022-11-23 01:42:36,972 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8017011217095635, 'Total loss': 0.8017011217095635} | train loss {'Reaction outcome loss': 0.8103030198498776, 'Total loss': 0.8103030198498776}
2022-11-23 01:42:36,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:36,972 INFO:     Epoch: 90
2022-11-23 01:42:37,820 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7875787399031899, 'Total loss': 0.7875787399031899} | train loss {'Reaction outcome loss': 0.8220451628630944, 'Total loss': 0.8220451628630944}
2022-11-23 01:42:37,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:37,822 INFO:     Epoch: 91
2022-11-23 01:42:38,706 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8098293095827103, 'Total loss': 0.8098293095827103} | train loss {'Reaction outcome loss': 0.8118572330426591, 'Total loss': 0.8118572330426591}
2022-11-23 01:42:38,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:38,706 INFO:     Epoch: 92
2022-11-23 01:42:39,572 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8001762161200697, 'Total loss': 0.8001762161200697} | train loss {'Reaction outcome loss': 0.8217869694175025, 'Total loss': 0.8217869694175025}
2022-11-23 01:42:39,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:39,572 INFO:     Epoch: 93
2022-11-23 01:42:40,463 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8128265304998918, 'Total loss': 0.8128265304998918} | train loss {'Reaction outcome loss': 0.8129409150133732, 'Total loss': 0.8129409150133732}
2022-11-23 01:42:40,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:40,463 INFO:     Epoch: 94
2022-11-23 01:42:41,312 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8163541426712816, 'Total loss': 0.8163541426712816} | train loss {'Reaction outcome loss': 0.8102142947164142, 'Total loss': 0.8102142947164142}
2022-11-23 01:42:41,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:41,312 INFO:     Epoch: 95
2022-11-23 01:42:42,146 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7922906875610352, 'Total loss': 0.7922906875610352} | train loss {'Reaction outcome loss': 0.8124825345118519, 'Total loss': 0.8124825345118519}
2022-11-23 01:42:42,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:42,146 INFO:     Epoch: 96
2022-11-23 01:42:43,011 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.793835041875189, 'Total loss': 0.793835041875189} | train loss {'Reaction outcome loss': 0.8220468445828086, 'Total loss': 0.8220468445828086}
2022-11-23 01:42:43,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:43,013 INFO:     Epoch: 97
2022-11-23 01:42:43,923 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8015721243890849, 'Total loss': 0.8015721243890849} | train loss {'Reaction outcome loss': 0.8130812209386092, 'Total loss': 0.8130812209386092}
2022-11-23 01:42:43,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:43,924 INFO:     Epoch: 98
2022-11-23 01:42:44,786 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7905101146210324, 'Total loss': 0.7905101146210324} | train loss {'Reaction outcome loss': 0.8170583036686727, 'Total loss': 0.8170583036686727}
2022-11-23 01:42:44,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-23 01:42:44,786 INFO:     Epoch: 99
2022-11-23 01:42:45,623 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7889370904727415, 'Total loss': 0.7889370904727415} | train loss {'Reaction outcome loss': 0.8127025275336586, 'Total loss': 0.8127025275336586}
2022-11-23 01:42:45,623 INFO:     Best model found after epoch 80 of 100.
2022-11-23 01:42:45,623 INFO:   Done with stage: TRAINING
2022-11-23 01:42:45,623 INFO:   Starting stage: EVALUATION
2022-11-23 01:42:45,749 INFO:   Done with stage: EVALUATION
2022-11-23 01:42:45,749 INFO: Done with stage: RUNNING SPLITS
2022-11-23 01:42:45,749 INFO: Starting stage: COMPUTE METRICS
2022-11-23 01:42:46,993 INFO: Done with stage: COMPUTE METRICS
2022-11-23 01:42:46,993 INFO: Starting stage: EXPORT RESULTS
2022-11-23 01:42:47,011 INFO:   Final results averaged over 50 folds: 
2022-11-23 01:42:47,015 INFO:   
                     mae  neg-spearman      rmse  spearman
dataset_split                                            
test           0.253001           NaN  0.347808       NaN
2022-11-23 01:42:48,749 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2022-11-23 01:42:48,756 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2022-11-23 01:42:48,757 DEBUG:   interactive is False
2022-11-23 01:42:48,757 DEBUG:   platform is linux
2022-11-23 01:42:48,758 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.sql.naming', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2022-11-23 01:42:48,953 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2022-11-23 01:42:48,955 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2022-11-23 01:42:49,411 DEBUG:   Loaded backend agg version unknown.
2022-11-23 01:42:49,415 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-11-23 01:42:49,415 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 01:42:49,416 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,416 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,416 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 01:42:49,416 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 01:42:49,416 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-23 01:42:49,416 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 01:42:49,416 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 01:42:49,416 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,416 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,417 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 01:42:49,417 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-23 01:42:49,417 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,417 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,417 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,417 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 01:42:49,417 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,417 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 01:42:49,417 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,418 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,418 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-23 01:42:49,418 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 01:42:49,418 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 01:42:49,418 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,418 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,418 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,418 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 01:42:49,418 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,419 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 01:42:49,419 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 01:42:49,419 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,419 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 01:42:49,419 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-23 01:42:49,419 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,419 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,419 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 01:42:49,419 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,419 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 01:42:49,420 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-23 01:42:49,420 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,420 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 01:42:49,420 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,420 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-23 01:42:49,420 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 01:42:49,420 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-23 01:42:49,479 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2022-11-23 01:42:49,479 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 01:42:49,480 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,480 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,480 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 01:42:49,480 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 01:42:49,480 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-23 01:42:49,480 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 01:42:49,480 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 01:42:49,480 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,480 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,480 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 01:42:49,481 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-23 01:42:49,481 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,481 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,481 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,481 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 01:42:49,481 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,481 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 01:42:49,481 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,481 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,481 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-23 01:42:49,481 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 01:42:49,481 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 01:42:49,481 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,482 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,482 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,482 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 01:42:49,482 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,482 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 01:42:49,482 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 01:42:49,482 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,482 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 01:42:49,482 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-23 01:42:49,482 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,482 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,482 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 01:42:49,483 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,483 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 01:42:49,483 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-23 01:42:49,483 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,483 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 01:42:49,483 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,483 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-23 01:42:49,483 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 01:42:49,483 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-23 01:42:49,493 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-11-23 01:42:49,493 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 01:42:49,493 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,493 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,493 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 01:42:49,493 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 01:42:49,493 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-23 01:42:49,493 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 01:42:49,493 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 01:42:49,493 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,494 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,494 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 01:42:49,494 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-23 01:42:49,494 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,494 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,494 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,494 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 01:42:49,494 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,494 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 01:42:49,494 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,494 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,494 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-23 01:42:49,494 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 01:42:49,494 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-23 01:42:49,494 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,495 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,495 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,495 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 01:42:49,495 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,495 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 01:42:49,495 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 01:42:49,495 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,495 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 01:42:49,495 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-23 01:42:49,495 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,495 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,495 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 01:42:49,495 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,495 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-23 01:42:49,495 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-23 01:42:49,496 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,496 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 01:42:49,496 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-23 01:42:49,496 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-23 01:42:49,496 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-23 01:42:49,496 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-23 01:42:50,012 INFO: Done with stage: EXPORT RESULTS
2022-11-23 01:42:50,012 INFO: Starting stage: SAVE MODEL
2022-11-23 01:42:50,071 INFO: Done with stage: SAVE MODEL
2022-11-23 01:42:50,071 INFO: Wall time for program:  4160.33 seconds
