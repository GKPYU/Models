2022-11-18 01:34:02,890 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffn/cd4dae7577771bee9b5fb6ca99493daa/2022_11_17-161905",
  "seed": 2,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "cat",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffn/a84e288a23e2297711eccae574abbf00/2021_05_26-165105_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffn",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.85,
  "val_size": 0.15,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.001491528877467142,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 2,
  "hidden_size": 90,
  "model_dropout": 0.13830197814960504,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.00785511672758935,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2022-11-18 01:34:02,907 INFO: Starting stage: BUILD FEATURIZERS
2022-11-18 01:34:02,911 INFO:   Creating esm representation model
2022-11-18 01:34:02,911 INFO:   Done esm representation model
2022-11-18 01:34:02,911 INFO: Done with stage: BUILD FEATURIZERS
2022-11-18 01:34:02,911 INFO: Starting stage: BUILDING DATASET
2022-11-18 01:34:02,980 INFO: Done with stage: BUILDING DATASET
2022-11-18 01:34:02,981 INFO: Starting stage: FEATURIZING DATA
2022-11-18 01:34:02,981 INFO:   Featurizing proteins
2022-11-18 01:34:02,983 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2022-11-18 01:34:03,000 INFO:   Loaded feature cache of size 204
2022-11-18 01:34:03,002 INFO:   Starting to pool ESM Embeddings
2022-11-18 01:34:03,134 INFO:   Featurizing molecules
2022-11-18 01:34:03,527 INFO: Done with stage: FEATURIZING DATA
2022-11-18 01:34:03,527 INFO: Starting stage: RUNNING SPLITS
2022-11-18 01:34:03,536 INFO:   Leaving out SEQ value Fold_0
2022-11-18 01:34:03,551 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-18 01:34:03,551 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:34:04,243 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:34:04,243 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:34:04,312 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:34:04,312 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:34:04,312 INFO:     No hyperparam tuning for this model
2022-11-18 01:34:04,312 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:34:04,312 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:34:04,313 INFO:     None feature selector for col prot
2022-11-18 01:34:04,313 INFO:     None feature selector for col prot
2022-11-18 01:34:04,313 INFO:     None feature selector for col prot
2022-11-18 01:34:04,314 INFO:     None feature selector for col chem
2022-11-18 01:34:04,314 INFO:     None feature selector for col chem
2022-11-18 01:34:04,314 INFO:     None feature selector for col chem
2022-11-18 01:34:04,314 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:34:04,314 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:34:04,315 INFO:     Number of params in model 168571
2022-11-18 01:34:04,316 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:34:04,316 INFO:   Starting stage: TRAINING
2022-11-18 01:34:05,985 INFO:     Val loss before train {'Reaction outcome loss': 1.0161613974460335, 'Total loss': 1.0161613974460335}
2022-11-18 01:34:05,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:05,986 INFO:     Epoch: 0
2022-11-18 01:34:06,773 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8471093094626139, 'Total loss': 0.8471093094626139} | train loss {'Reaction outcome loss': 0.8754944344524478, 'Total loss': 0.8754944344524478}
2022-11-18 01:34:06,773 INFO:     Found new best model at epoch 0
2022-11-18 01:34:06,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:06,774 INFO:     Epoch: 1
2022-11-18 01:34:07,698 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8390262376430423, 'Total loss': 0.8390262376430423} | train loss {'Reaction outcome loss': 0.8480675586911498, 'Total loss': 0.8480675586911498}
2022-11-18 01:34:07,698 INFO:     Found new best model at epoch 1
2022-11-18 01:34:07,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:07,699 INFO:     Epoch: 2
2022-11-18 01:34:08,596 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.863332076128139, 'Total loss': 0.863332076128139} | train loss {'Reaction outcome loss': 0.8411789290973397, 'Total loss': 0.8411789290973397}
2022-11-18 01:34:08,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:08,597 INFO:     Epoch: 3
2022-11-18 01:34:09,381 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8884265173313229, 'Total loss': 0.8884265173313229} | train loss {'Reaction outcome loss': 0.8394679477224585, 'Total loss': 0.8394679477224585}
2022-11-18 01:34:09,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:09,381 INFO:     Epoch: 4
2022-11-18 01:34:10,197 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8296204846958781, 'Total loss': 0.8296204846958781} | train loss {'Reaction outcome loss': 0.8357983597966491, 'Total loss': 0.8357983597966491}
2022-11-18 01:34:10,197 INFO:     Found new best model at epoch 4
2022-11-18 01:34:10,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:10,198 INFO:     Epoch: 5
2022-11-18 01:34:10,994 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8355511024940846, 'Total loss': 0.8355511024940846} | train loss {'Reaction outcome loss': 0.8381154225742231, 'Total loss': 0.8381154225742231}
2022-11-18 01:34:10,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:10,994 INFO:     Epoch: 6
2022-11-18 01:34:11,793 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8132280825182449, 'Total loss': 0.8132280825182449} | train loss {'Reaction outcome loss': 0.8295903105716236, 'Total loss': 0.8295903105716236}
2022-11-18 01:34:11,793 INFO:     Found new best model at epoch 6
2022-11-18 01:34:11,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:11,794 INFO:     Epoch: 7
2022-11-18 01:34:12,556 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8363032091495602, 'Total loss': 0.8363032091495602} | train loss {'Reaction outcome loss': 0.823959482986419, 'Total loss': 0.823959482986419}
2022-11-18 01:34:12,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:12,557 INFO:     Epoch: 8
2022-11-18 01:34:13,344 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8210645505162173, 'Total loss': 0.8210645505162173} | train loss {'Reaction outcome loss': 0.820439018797679, 'Total loss': 0.820439018797679}
2022-11-18 01:34:13,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:13,344 INFO:     Epoch: 9
2022-11-18 01:34:14,125 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8126515448093414, 'Total loss': 0.8126515448093414} | train loss {'Reaction outcome loss': 0.8231532838745196, 'Total loss': 0.8231532838745196}
2022-11-18 01:34:14,125 INFO:     Found new best model at epoch 9
2022-11-18 01:34:14,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:14,126 INFO:     Epoch: 10
2022-11-18 01:34:14,921 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8277613063191258, 'Total loss': 0.8277613063191258} | train loss {'Reaction outcome loss': 0.8240033561577562, 'Total loss': 0.8240033561577562}
2022-11-18 01:34:14,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:14,921 INFO:     Epoch: 11
2022-11-18 01:34:15,749 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8238070080446642, 'Total loss': 0.8238070080446642} | train loss {'Reaction outcome loss': 0.8257886063857157, 'Total loss': 0.8257886063857157}
2022-11-18 01:34:15,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:15,749 INFO:     Epoch: 12
2022-11-18 01:34:16,569 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8120682170224744, 'Total loss': 0.8120682170224744} | train loss {'Reaction outcome loss': 0.8233106248691434, 'Total loss': 0.8233106248691434}
2022-11-18 01:34:16,569 INFO:     Found new best model at epoch 12
2022-11-18 01:34:16,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:16,570 INFO:     Epoch: 13
2022-11-18 01:34:17,350 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8554008533788282, 'Total loss': 0.8554008533788282} | train loss {'Reaction outcome loss': 0.8197817252796205, 'Total loss': 0.8197817252796205}
2022-11-18 01:34:17,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:17,350 INFO:     Epoch: 14
2022-11-18 01:34:18,148 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8097660000934157, 'Total loss': 0.8097660000934157} | train loss {'Reaction outcome loss': 0.8223328550086647, 'Total loss': 0.8223328550086647}
2022-11-18 01:34:18,148 INFO:     Found new best model at epoch 14
2022-11-18 01:34:18,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:18,149 INFO:     Epoch: 15
2022-11-18 01:34:18,944 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8297400280486705, 'Total loss': 0.8297400280486705} | train loss {'Reaction outcome loss': 0.8166237512572867, 'Total loss': 0.8166237512572867}
2022-11-18 01:34:18,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:18,944 INFO:     Epoch: 16
2022-11-18 01:34:19,769 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8167834545290747, 'Total loss': 0.8167834545290747} | train loss {'Reaction outcome loss': 0.8202700917838049, 'Total loss': 0.8202700917838049}
2022-11-18 01:34:19,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:19,769 INFO:     Epoch: 17
2022-11-18 01:34:20,555 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8181513430074204, 'Total loss': 0.8181513430074204} | train loss {'Reaction outcome loss': 0.8143448083371413, 'Total loss': 0.8143448083371413}
2022-11-18 01:34:20,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:20,556 INFO:     Epoch: 18
2022-11-18 01:34:21,327 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8068771999935771, 'Total loss': 0.8068771999935771} | train loss {'Reaction outcome loss': 0.813346047992589, 'Total loss': 0.813346047992589}
2022-11-18 01:34:21,327 INFO:     Found new best model at epoch 18
2022-11-18 01:34:21,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:21,328 INFO:     Epoch: 19
2022-11-18 01:34:22,148 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8355748112811598, 'Total loss': 0.8355748112811598} | train loss {'Reaction outcome loss': 0.817972970179847, 'Total loss': 0.817972970179847}
2022-11-18 01:34:22,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:22,148 INFO:     Epoch: 20
2022-11-18 01:34:22,898 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8094645863355592, 'Total loss': 0.8094645863355592} | train loss {'Reaction outcome loss': 0.8208127510352213, 'Total loss': 0.8208127510352213}
2022-11-18 01:34:22,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:22,898 INFO:     Epoch: 21
2022-11-18 01:34:23,693 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8173250978769258, 'Total loss': 0.8173250978769258} | train loss {'Reaction outcome loss': 0.8185218528645938, 'Total loss': 0.8185218528645938}
2022-11-18 01:34:23,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:23,693 INFO:     Epoch: 22
2022-11-18 01:34:24,464 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8334582683651947, 'Total loss': 0.8334582683651947} | train loss {'Reaction outcome loss': 0.8164319363041003, 'Total loss': 0.8164319363041003}
2022-11-18 01:34:24,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:24,464 INFO:     Epoch: 23
2022-11-18 01:34:25,243 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8271174098170081, 'Total loss': 0.8271174098170081} | train loss {'Reaction outcome loss': 0.8160765177158059, 'Total loss': 0.8160765177158059}
2022-11-18 01:34:25,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:25,244 INFO:     Epoch: 24
2022-11-18 01:34:26,083 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8035333336785783, 'Total loss': 0.8035333336785783} | train loss {'Reaction outcome loss': 0.811796430559432, 'Total loss': 0.811796430559432}
2022-11-18 01:34:26,084 INFO:     Found new best model at epoch 24
2022-11-18 01:34:26,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:26,084 INFO:     Epoch: 25
2022-11-18 01:34:26,944 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8098344151363817, 'Total loss': 0.8098344151363817} | train loss {'Reaction outcome loss': 0.815070996152573, 'Total loss': 0.815070996152573}
2022-11-18 01:34:26,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:26,944 INFO:     Epoch: 26
2022-11-18 01:34:27,741 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8209235619666965, 'Total loss': 0.8209235619666965} | train loss {'Reaction outcome loss': 0.808893582615696, 'Total loss': 0.808893582615696}
2022-11-18 01:34:27,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:27,742 INFO:     Epoch: 27
2022-11-18 01:34:28,527 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8089023967121922, 'Total loss': 0.8089023967121922} | train loss {'Reaction outcome loss': 0.8147948933917968, 'Total loss': 0.8147948933917968}
2022-11-18 01:34:28,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:28,528 INFO:     Epoch: 28
2022-11-18 01:34:29,266 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8069593150948369, 'Total loss': 0.8069593150948369} | train loss {'Reaction outcome loss': 0.8090155995527252, 'Total loss': 0.8090155995527252}
2022-11-18 01:34:29,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:29,267 INFO:     Epoch: 29
2022-11-18 01:34:30,032 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8011905024218005, 'Total loss': 0.8011905024218005} | train loss {'Reaction outcome loss': 0.8167582541459897, 'Total loss': 0.8167582541459897}
2022-11-18 01:34:30,032 INFO:     Found new best model at epoch 29
2022-11-18 01:34:30,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:30,033 INFO:     Epoch: 30
2022-11-18 01:34:30,786 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8015638187874196, 'Total loss': 0.8015638187874196} | train loss {'Reaction outcome loss': 0.8110529208769564, 'Total loss': 0.8110529208769564}
2022-11-18 01:34:30,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:30,786 INFO:     Epoch: 31
2022-11-18 01:34:31,551 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8153879358324894, 'Total loss': 0.8153879358324894} | train loss {'Reaction outcome loss': 0.8190398273653672, 'Total loss': 0.8190398273653672}
2022-11-18 01:34:31,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:31,551 INFO:     Epoch: 32
2022-11-18 01:34:32,328 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8319929789665134, 'Total loss': 0.8319929789665134} | train loss {'Reaction outcome loss': 0.8125994002721348, 'Total loss': 0.8125994002721348}
2022-11-18 01:34:32,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:32,328 INFO:     Epoch: 33
2022-11-18 01:34:33,111 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7998666527659394, 'Total loss': 0.7998666527659394} | train loss {'Reaction outcome loss': 0.8148386799654023, 'Total loss': 0.8148386799654023}
2022-11-18 01:34:33,111 INFO:     Found new best model at epoch 33
2022-11-18 01:34:33,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:33,112 INFO:     Epoch: 34
2022-11-18 01:34:33,893 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8102843518867049, 'Total loss': 0.8102843518867049} | train loss {'Reaction outcome loss': 0.8161250131784893, 'Total loss': 0.8161250131784893}
2022-11-18 01:34:33,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:33,894 INFO:     Epoch: 35
2022-11-18 01:34:34,680 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8102439600367879, 'Total loss': 0.8102439600367879} | train loss {'Reaction outcome loss': 0.809920314638341, 'Total loss': 0.809920314638341}
2022-11-18 01:34:34,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:34,681 INFO:     Epoch: 36
2022-11-18 01:34:35,441 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8119979805724565, 'Total loss': 0.8119979805724565} | train loss {'Reaction outcome loss': 0.8133915715285989, 'Total loss': 0.8133915715285989}
2022-11-18 01:34:35,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:35,442 INFO:     Epoch: 37
2022-11-18 01:34:36,238 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8047883732374325, 'Total loss': 0.8047883732374325} | train loss {'Reaction outcome loss': 0.810761321885664, 'Total loss': 0.810761321885664}
2022-11-18 01:34:36,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:36,238 INFO:     Epoch: 38
2022-11-18 01:34:37,013 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8065681311973306, 'Total loss': 0.8065681311973306} | train loss {'Reaction outcome loss': 0.8127631382619749, 'Total loss': 0.8127631382619749}
2022-11-18 01:34:37,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:37,013 INFO:     Epoch: 39
2022-11-18 01:34:37,819 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8101798691028772, 'Total loss': 0.8101798691028772} | train loss {'Reaction outcome loss': 0.8133109920337552, 'Total loss': 0.8133109920337552}
2022-11-18 01:34:37,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:37,819 INFO:     Epoch: 40
2022-11-18 01:34:38,586 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8089180810506954, 'Total loss': 0.8089180810506954} | train loss {'Reaction outcome loss': 0.8143601004706055, 'Total loss': 0.8143601004706055}
2022-11-18 01:34:38,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:38,586 INFO:     Epoch: 41
2022-11-18 01:34:39,361 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8177128364873487, 'Total loss': 0.8177128364873487} | train loss {'Reaction outcome loss': 0.8134111060959394, 'Total loss': 0.8134111060959394}
2022-11-18 01:34:39,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:39,361 INFO:     Epoch: 42
2022-11-18 01:34:40,152 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8149425387382507, 'Total loss': 0.8149425387382507} | train loss {'Reaction outcome loss': 0.8097974010666863, 'Total loss': 0.8097974010666863}
2022-11-18 01:34:40,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:40,154 INFO:     Epoch: 43
2022-11-18 01:34:40,924 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8180023930793585, 'Total loss': 0.8180023930793585} | train loss {'Reaction outcome loss': 0.8133140256414648, 'Total loss': 0.8133140256414648}
2022-11-18 01:34:40,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:40,924 INFO:     Epoch: 44
2022-11-18 01:34:41,689 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8136417948922445, 'Total loss': 0.8136417948922445} | train loss {'Reaction outcome loss': 0.8115102075895325, 'Total loss': 0.8115102075895325}
2022-11-18 01:34:41,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:41,690 INFO:     Epoch: 45
2022-11-18 01:34:42,456 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8303306754245314, 'Total loss': 0.8303306754245314} | train loss {'Reaction outcome loss': 0.8125775657960626, 'Total loss': 0.8125775657960626}
2022-11-18 01:34:42,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:42,456 INFO:     Epoch: 46
2022-11-18 01:34:43,213 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8157750257225924, 'Total loss': 0.8157750257225924} | train loss {'Reaction outcome loss': 0.8113181201405213, 'Total loss': 0.8113181201405213}
2022-11-18 01:34:43,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:43,213 INFO:     Epoch: 47
2022-11-18 01:34:43,967 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8156212769275488, 'Total loss': 0.8156212769275488} | train loss {'Reaction outcome loss': 0.8176769922014142, 'Total loss': 0.8176769922014142}
2022-11-18 01:34:43,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:43,967 INFO:     Epoch: 48
2022-11-18 01:34:44,739 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8003608376480812, 'Total loss': 0.8003608376480812} | train loss {'Reaction outcome loss': 0.8158374351800465, 'Total loss': 0.8158374351800465}
2022-11-18 01:34:44,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:44,739 INFO:     Epoch: 49
2022-11-18 01:34:45,500 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8188342036202897, 'Total loss': 0.8188342036202897} | train loss {'Reaction outcome loss': 0.8110165902581371, 'Total loss': 0.8110165902581371}
2022-11-18 01:34:45,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:45,502 INFO:     Epoch: 50
2022-11-18 01:34:46,276 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8318241065324739, 'Total loss': 0.8318241065324739} | train loss {'Reaction outcome loss': 0.8107718474796561, 'Total loss': 0.8107718474796561}
2022-11-18 01:34:46,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:46,277 INFO:     Epoch: 51
2022-11-18 01:34:47,067 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8062073761640594, 'Total loss': 0.8062073761640594} | train loss {'Reaction outcome loss': 0.8148328869557772, 'Total loss': 0.8148328869557772}
2022-11-18 01:34:47,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:47,067 INFO:     Epoch: 52
2022-11-18 01:34:47,914 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.818563932596251, 'Total loss': 0.818563932596251} | train loss {'Reaction outcome loss': 0.8132300551553242, 'Total loss': 0.8132300551553242}
2022-11-18 01:34:47,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:47,915 INFO:     Epoch: 53
2022-11-18 01:34:48,709 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8051932204601376, 'Total loss': 0.8051932204601376} | train loss {'Reaction outcome loss': 0.8133598186197828, 'Total loss': 0.8133598186197828}
2022-11-18 01:34:48,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:48,709 INFO:     Epoch: 54
2022-11-18 01:34:49,470 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8188761937063794, 'Total loss': 0.8188761937063794} | train loss {'Reaction outcome loss': 0.8153099135541525, 'Total loss': 0.8153099135541525}
2022-11-18 01:34:49,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:49,470 INFO:     Epoch: 55
2022-11-18 01:34:50,249 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8039847834165706, 'Total loss': 0.8039847834165706} | train loss {'Reaction outcome loss': 0.809898348983194, 'Total loss': 0.809898348983194}
2022-11-18 01:34:50,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:50,249 INFO:     Epoch: 56
2022-11-18 01:34:51,022 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7992456271204837, 'Total loss': 0.7992456271204837} | train loss {'Reaction outcome loss': 0.8137263781467422, 'Total loss': 0.8137263781467422}
2022-11-18 01:34:51,024 INFO:     Found new best model at epoch 56
2022-11-18 01:34:51,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:51,025 INFO:     Epoch: 57
2022-11-18 01:34:51,808 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8305540306623592, 'Total loss': 0.8305540306623592} | train loss {'Reaction outcome loss': 0.8143445046954467, 'Total loss': 0.8143445046954467}
2022-11-18 01:34:51,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:51,808 INFO:     Epoch: 58
2022-11-18 01:34:52,563 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8016520690086276, 'Total loss': 0.8016520690086276} | train loss {'Reaction outcome loss': 0.8119300092097188, 'Total loss': 0.8119300092097188}
2022-11-18 01:34:52,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:52,563 INFO:     Epoch: 59
2022-11-18 01:34:53,357 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8300656503023103, 'Total loss': 0.8300656503023103} | train loss {'Reaction outcome loss': 0.8103892405013569, 'Total loss': 0.8103892405013569}
2022-11-18 01:34:53,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:53,357 INFO:     Epoch: 60
2022-11-18 01:34:54,128 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8416342222413351, 'Total loss': 0.8416342222413351} | train loss {'Reaction outcome loss': 0.81068914230974, 'Total loss': 0.81068914230974}
2022-11-18 01:34:54,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:54,128 INFO:     Epoch: 61
2022-11-18 01:34:54,889 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8318460687648418, 'Total loss': 0.8318460687648418} | train loss {'Reaction outcome loss': 0.8115458129370798, 'Total loss': 0.8115458129370798}
2022-11-18 01:34:54,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:54,890 INFO:     Epoch: 62
2022-11-18 01:34:55,681 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8105021950810455, 'Total loss': 0.8105021950810455} | train loss {'Reaction outcome loss': 0.8198522975454565, 'Total loss': 0.8198522975454565}
2022-11-18 01:34:55,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:55,681 INFO:     Epoch: 63
2022-11-18 01:34:56,489 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8203115567218425, 'Total loss': 0.8203115567218425} | train loss {'Reaction outcome loss': 0.8098722498436444, 'Total loss': 0.8098722498436444}
2022-11-18 01:34:56,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:56,491 INFO:     Epoch: 64
2022-11-18 01:34:57,290 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7981549910334653, 'Total loss': 0.7981549910334653} | train loss {'Reaction outcome loss': 0.8166898524419206, 'Total loss': 0.8166898524419206}
2022-11-18 01:34:57,290 INFO:     Found new best model at epoch 64
2022-11-18 01:34:57,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:57,291 INFO:     Epoch: 65
2022-11-18 01:34:58,046 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.817952016065287, 'Total loss': 0.817952016065287} | train loss {'Reaction outcome loss': 0.8133544432090931, 'Total loss': 0.8133544432090931}
2022-11-18 01:34:58,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:58,046 INFO:     Epoch: 66
2022-11-18 01:34:58,870 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8213060900222423, 'Total loss': 0.8213060900222423} | train loss {'Reaction outcome loss': 0.8097004236989334, 'Total loss': 0.8097004236989334}
2022-11-18 01:34:58,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:58,870 INFO:     Epoch: 67
2022-11-18 01:34:59,641 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8105088132758473, 'Total loss': 0.8105088132758473} | train loss {'Reaction outcome loss': 0.8082723472206319, 'Total loss': 0.8082723472206319}
2022-11-18 01:34:59,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:34:59,642 INFO:     Epoch: 68
2022-11-18 01:35:00,431 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.82174974402716, 'Total loss': 0.82174974402716} | train loss {'Reaction outcome loss': 0.8092284825493078, 'Total loss': 0.8092284825493078}
2022-11-18 01:35:00,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:00,431 INFO:     Epoch: 69
2022-11-18 01:35:01,186 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.830875507620878, 'Total loss': 0.830875507620878} | train loss {'Reaction outcome loss': 0.8107681602972453, 'Total loss': 0.8107681602972453}
2022-11-18 01:35:01,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:01,186 INFO:     Epoch: 70
2022-11-18 01:35:01,969 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8251086161580197, 'Total loss': 0.8251086161580197} | train loss {'Reaction outcome loss': 0.8144818661642856, 'Total loss': 0.8144818661642856}
2022-11-18 01:35:01,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:01,971 INFO:     Epoch: 71
2022-11-18 01:35:02,740 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8072416879409967, 'Total loss': 0.8072416879409967} | train loss {'Reaction outcome loss': 0.8115031526225512, 'Total loss': 0.8115031526225512}
2022-11-18 01:35:02,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:02,740 INFO:     Epoch: 72
2022-11-18 01:35:03,535 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.80073051535806, 'Total loss': 0.80073051535806} | train loss {'Reaction outcome loss': 0.81620975632648, 'Total loss': 0.81620975632648}
2022-11-18 01:35:03,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:03,535 INFO:     Epoch: 73
2022-11-18 01:35:04,326 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8243802238342374, 'Total loss': 0.8243802238342374} | train loss {'Reaction outcome loss': 0.8081893716923526, 'Total loss': 0.8081893716923526}
2022-11-18 01:35:04,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:04,326 INFO:     Epoch: 74
2022-11-18 01:35:05,104 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8339738637902016, 'Total loss': 0.8339738637902016} | train loss {'Reaction outcome loss': 0.8086319256757126, 'Total loss': 0.8086319256757126}
2022-11-18 01:35:05,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:05,104 INFO:     Epoch: 75
2022-11-18 01:35:05,865 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7971977799437767, 'Total loss': 0.7971977799437767} | train loss {'Reaction outcome loss': 0.8125333481880485, 'Total loss': 0.8125333481880485}
2022-11-18 01:35:05,865 INFO:     Found new best model at epoch 75
2022-11-18 01:35:05,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:05,866 INFO:     Epoch: 76
2022-11-18 01:35:06,638 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8314189883165581, 'Total loss': 0.8314189883165581} | train loss {'Reaction outcome loss': 0.8061885442890104, 'Total loss': 0.8061885442890104}
2022-11-18 01:35:06,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:06,638 INFO:     Epoch: 77
2022-11-18 01:35:07,405 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8045069027778714, 'Total loss': 0.8045069027778714} | train loss {'Reaction outcome loss': 0.8116427291123594, 'Total loss': 0.8116427291123594}
2022-11-18 01:35:07,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:07,407 INFO:     Epoch: 78
2022-11-18 01:35:08,196 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8130458302276079, 'Total loss': 0.8130458302276079} | train loss {'Reaction outcome loss': 0.8140491848109198, 'Total loss': 0.8140491848109198}
2022-11-18 01:35:08,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:08,196 INFO:     Epoch: 79
2022-11-18 01:35:09,037 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8072951110296471, 'Total loss': 0.8072951110296471} | train loss {'Reaction outcome loss': 0.8069650216913614, 'Total loss': 0.8069650216913614}
2022-11-18 01:35:09,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:09,037 INFO:     Epoch: 80
2022-11-18 01:35:09,834 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.802246208800826, 'Total loss': 0.802246208800826} | train loss {'Reaction outcome loss': 0.8102209096560713, 'Total loss': 0.8102209096560713}
2022-11-18 01:35:09,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:09,835 INFO:     Epoch: 81
2022-11-18 01:35:10,597 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7980051248572594, 'Total loss': 0.7980051248572594} | train loss {'Reaction outcome loss': 0.8126989901065826, 'Total loss': 0.8126989901065826}
2022-11-18 01:35:10,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:10,597 INFO:     Epoch: 82
2022-11-18 01:35:11,361 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8041204519050066, 'Total loss': 0.8041204519050066} | train loss {'Reaction outcome loss': 0.80639285240017, 'Total loss': 0.80639285240017}
2022-11-18 01:35:11,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:11,361 INFO:     Epoch: 83
2022-11-18 01:35:12,129 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8411287907944169, 'Total loss': 0.8411287907944169} | train loss {'Reaction outcome loss': 0.8120730507080672, 'Total loss': 0.8120730507080672}
2022-11-18 01:35:12,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:12,130 INFO:     Epoch: 84
2022-11-18 01:35:12,910 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8151609564936438, 'Total loss': 0.8151609564936438} | train loss {'Reaction outcome loss': 0.811007195564567, 'Total loss': 0.811007195564567}
2022-11-18 01:35:12,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:12,912 INFO:     Epoch: 85
2022-11-18 01:35:13,693 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.816806749549023, 'Total loss': 0.816806749549023} | train loss {'Reaction outcome loss': 0.8093486405054077, 'Total loss': 0.8093486405054077}
2022-11-18 01:35:13,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:13,693 INFO:     Epoch: 86
2022-11-18 01:35:14,472 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.813595960999644, 'Total loss': 0.813595960999644} | train loss {'Reaction outcome loss': 0.8108227392200564, 'Total loss': 0.8108227392200564}
2022-11-18 01:35:14,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:14,473 INFO:     Epoch: 87
2022-11-18 01:35:15,237 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7902669885823893, 'Total loss': 0.7902669885823893} | train loss {'Reaction outcome loss': 0.8139485704605697, 'Total loss': 0.8139485704605697}
2022-11-18 01:35:15,237 INFO:     Found new best model at epoch 87
2022-11-18 01:35:15,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:15,238 INFO:     Epoch: 88
2022-11-18 01:35:16,011 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8055644582870395, 'Total loss': 0.8055644582870395} | train loss {'Reaction outcome loss': 0.8136373929312972, 'Total loss': 0.8136373929312972}
2022-11-18 01:35:16,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:16,011 INFO:     Epoch: 89
2022-11-18 01:35:16,791 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8215703077094499, 'Total loss': 0.8215703077094499} | train loss {'Reaction outcome loss': 0.8057708665117865, 'Total loss': 0.8057708665117865}
2022-11-18 01:35:16,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:16,791 INFO:     Epoch: 90
2022-11-18 01:35:17,583 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.793521034163098, 'Total loss': 0.793521034163098} | train loss {'Reaction outcome loss': 0.808866836130619, 'Total loss': 0.808866836130619}
2022-11-18 01:35:17,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:17,583 INFO:     Epoch: 91
2022-11-18 01:35:18,383 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8269455516061117, 'Total loss': 0.8269455516061117} | train loss {'Reaction outcome loss': 0.8100598008661973, 'Total loss': 0.8100598008661973}
2022-11-18 01:35:18,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:18,385 INFO:     Epoch: 92
2022-11-18 01:35:19,195 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8021549194358116, 'Total loss': 0.8021549194358116} | train loss {'Reaction outcome loss': 0.8102465844789489, 'Total loss': 0.8102465844789489}
2022-11-18 01:35:19,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:19,196 INFO:     Epoch: 93
2022-11-18 01:35:19,990 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8329172834407451, 'Total loss': 0.8329172834407451} | train loss {'Reaction outcome loss': 0.8096506328123515, 'Total loss': 0.8096506328123515}
2022-11-18 01:35:19,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:19,991 INFO:     Epoch: 94
2022-11-18 01:35:20,748 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7965633335501648, 'Total loss': 0.7965633335501648} | train loss {'Reaction outcome loss': 0.810946843296778, 'Total loss': 0.810946843296778}
2022-11-18 01:35:20,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:20,748 INFO:     Epoch: 95
2022-11-18 01:35:21,495 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8258700571780981, 'Total loss': 0.8258700571780981} | train loss {'Reaction outcome loss': 0.809364808265303, 'Total loss': 0.809364808265303}
2022-11-18 01:35:21,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:21,495 INFO:     Epoch: 96
2022-11-18 01:35:22,290 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8018368787543718, 'Total loss': 0.8018368787543718} | train loss {'Reaction outcome loss': 0.811125718301437, 'Total loss': 0.811125718301437}
2022-11-18 01:35:22,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:22,290 INFO:     Epoch: 97
2022-11-18 01:35:23,047 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8110362374505331, 'Total loss': 0.8110362374505331} | train loss {'Reaction outcome loss': 0.806951569362742, 'Total loss': 0.806951569362742}
2022-11-18 01:35:23,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:23,047 INFO:     Epoch: 98
2022-11-18 01:35:23,808 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8026001016760982, 'Total loss': 0.8026001016760982} | train loss {'Reaction outcome loss': 0.8044490566263434, 'Total loss': 0.8044490566263434}
2022-11-18 01:35:23,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:23,808 INFO:     Epoch: 99
2022-11-18 01:35:24,566 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8252579008424005, 'Total loss': 0.8252579008424005} | train loss {'Reaction outcome loss': 0.8099005388431861, 'Total loss': 0.8099005388431861}
2022-11-18 01:35:24,567 INFO:     Best model found after epoch 88 of 100.
2022-11-18 01:35:24,567 INFO:   Done with stage: TRAINING
2022-11-18 01:35:24,567 INFO:   Starting stage: EVALUATION
2022-11-18 01:35:24,706 INFO:   Done with stage: EVALUATION
2022-11-18 01:35:24,706 INFO:   Leaving out SEQ value Fold_1
2022-11-18 01:35:24,719 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 01:35:24,719 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:35:25,396 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:35:25,396 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:35:25,467 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:35:25,467 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:35:25,467 INFO:     No hyperparam tuning for this model
2022-11-18 01:35:25,467 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:35:25,467 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:35:25,468 INFO:     None feature selector for col prot
2022-11-18 01:35:25,468 INFO:     None feature selector for col prot
2022-11-18 01:35:25,468 INFO:     None feature selector for col prot
2022-11-18 01:35:25,469 INFO:     None feature selector for col chem
2022-11-18 01:35:25,469 INFO:     None feature selector for col chem
2022-11-18 01:35:25,469 INFO:     None feature selector for col chem
2022-11-18 01:35:25,469 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:35:25,469 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:35:25,471 INFO:     Number of params in model 168571
2022-11-18 01:35:25,474 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:35:25,474 INFO:   Starting stage: TRAINING
2022-11-18 01:35:25,531 INFO:     Val loss before train {'Reaction outcome loss': 0.9910856512459841, 'Total loss': 0.9910856512459841}
2022-11-18 01:35:25,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:25,532 INFO:     Epoch: 0
2022-11-18 01:35:26,338 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8952613296833906, 'Total loss': 0.8952613296833906} | train loss {'Reaction outcome loss': 0.8762836832749216, 'Total loss': 0.8762836832749216}
2022-11-18 01:35:26,338 INFO:     Found new best model at epoch 0
2022-11-18 01:35:26,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:26,339 INFO:     Epoch: 1
2022-11-18 01:35:27,144 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8617427538741719, 'Total loss': 0.8617427538741719} | train loss {'Reaction outcome loss': 0.8532748828955025, 'Total loss': 0.8532748828955025}
2022-11-18 01:35:27,144 INFO:     Found new best model at epoch 1
2022-11-18 01:35:27,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:27,145 INFO:     Epoch: 2
2022-11-18 01:35:27,938 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8674687756733461, 'Total loss': 0.8674687756733461} | train loss {'Reaction outcome loss': 0.8423402637605243, 'Total loss': 0.8423402637605243}
2022-11-18 01:35:27,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:27,938 INFO:     Epoch: 3
2022-11-18 01:35:28,717 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8543019220232964, 'Total loss': 0.8543019220232964} | train loss {'Reaction outcome loss': 0.8457038640252009, 'Total loss': 0.8457038640252009}
2022-11-18 01:35:28,717 INFO:     Found new best model at epoch 3
2022-11-18 01:35:28,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:28,718 INFO:     Epoch: 4
2022-11-18 01:35:29,534 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8925345553593202, 'Total loss': 0.8925345553593202} | train loss {'Reaction outcome loss': 0.8437639070667236, 'Total loss': 0.8437639070667236}
2022-11-18 01:35:29,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:29,534 INFO:     Epoch: 5
2022-11-18 01:35:30,347 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8620785528963263, 'Total loss': 0.8620785528963263} | train loss {'Reaction outcome loss': 0.8364873705846578, 'Total loss': 0.8364873705846578}
2022-11-18 01:35:30,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:30,347 INFO:     Epoch: 6
2022-11-18 01:35:31,132 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8788924068212509, 'Total loss': 0.8788924068212509} | train loss {'Reaction outcome loss': 0.8308244649215266, 'Total loss': 0.8308244649215266}
2022-11-18 01:35:31,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:31,132 INFO:     Epoch: 7
2022-11-18 01:35:31,925 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8371719528328289, 'Total loss': 0.8371719528328289} | train loss {'Reaction outcome loss': 0.8303757471895894, 'Total loss': 0.8303757471895894}
2022-11-18 01:35:31,925 INFO:     Found new best model at epoch 7
2022-11-18 01:35:31,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:31,926 INFO:     Epoch: 8
2022-11-18 01:35:32,717 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8827617723833431, 'Total loss': 0.8827617723833431} | train loss {'Reaction outcome loss': 0.8272406279075484, 'Total loss': 0.8272406279075484}
2022-11-18 01:35:32,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:32,718 INFO:     Epoch: 9
2022-11-18 01:35:33,478 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8471080383116548, 'Total loss': 0.8471080383116548} | train loss {'Reaction outcome loss': 0.8315043811373383, 'Total loss': 0.8315043811373383}
2022-11-18 01:35:33,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:33,478 INFO:     Epoch: 10
2022-11-18 01:35:34,265 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8680186170068654, 'Total loss': 0.8680186170068654} | train loss {'Reaction outcome loss': 0.8268715385121372, 'Total loss': 0.8268715385121372}
2022-11-18 01:35:34,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:34,265 INFO:     Epoch: 11
2022-11-18 01:35:35,047 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8595828942277215, 'Total loss': 0.8595828942277215} | train loss {'Reaction outcome loss': 0.822423562347165, 'Total loss': 0.822423562347165}
2022-11-18 01:35:35,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:35,047 INFO:     Epoch: 12
2022-11-18 01:35:35,841 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.840438917956569, 'Total loss': 0.840438917956569} | train loss {'Reaction outcome loss': 0.8296302362733524, 'Total loss': 0.8296302362733524}
2022-11-18 01:35:35,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:35,841 INFO:     Epoch: 13
2022-11-18 01:35:36,598 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8639694194902073, 'Total loss': 0.8639694194902073} | train loss {'Reaction outcome loss': 0.8208038946877607, 'Total loss': 0.8208038946877607}
2022-11-18 01:35:36,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:36,599 INFO:     Epoch: 14
2022-11-18 01:35:37,404 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8515363951975649, 'Total loss': 0.8515363951975649} | train loss {'Reaction outcome loss': 0.8177206289430379, 'Total loss': 0.8177206289430379}
2022-11-18 01:35:37,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:37,404 INFO:     Epoch: 15
2022-11-18 01:35:38,191 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8432590778578412, 'Total loss': 0.8432590778578412} | train loss {'Reaction outcome loss': 0.8204379248232977, 'Total loss': 0.8204379248232977}
2022-11-18 01:35:38,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:38,191 INFO:     Epoch: 16
2022-11-18 01:35:38,980 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8605160957032983, 'Total loss': 0.8605160957032983} | train loss {'Reaction outcome loss': 0.8285260457500272, 'Total loss': 0.8285260457500272}
2022-11-18 01:35:38,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:38,980 INFO:     Epoch: 17
2022-11-18 01:35:39,733 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8405377742919055, 'Total loss': 0.8405377742919055} | train loss {'Reaction outcome loss': 0.822789584335528, 'Total loss': 0.822789584335528}
2022-11-18 01:35:39,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:39,733 INFO:     Epoch: 18
2022-11-18 01:35:40,512 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8618015037341551, 'Total loss': 0.8618015037341551} | train loss {'Reaction outcome loss': 0.8152312665936435, 'Total loss': 0.8152312665936435}
2022-11-18 01:35:40,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:40,512 INFO:     Epoch: 19
2022-11-18 01:35:41,339 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8597056472843344, 'Total loss': 0.8597056472843344} | train loss {'Reaction outcome loss': 0.8165300455894547, 'Total loss': 0.8165300455894547}
2022-11-18 01:35:41,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:41,339 INFO:     Epoch: 20
2022-11-18 01:35:42,127 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8275315382263877, 'Total loss': 0.8275315382263877} | train loss {'Reaction outcome loss': 0.8204152632338798, 'Total loss': 0.8204152632338798}
2022-11-18 01:35:42,127 INFO:     Found new best model at epoch 20
2022-11-18 01:35:42,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:42,128 INFO:     Epoch: 21
2022-11-18 01:35:42,910 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8511320535432209, 'Total loss': 0.8511320535432209} | train loss {'Reaction outcome loss': 0.816051516938306, 'Total loss': 0.816051516938306}
2022-11-18 01:35:42,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:42,910 INFO:     Epoch: 22
2022-11-18 01:35:43,712 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8443178473548456, 'Total loss': 0.8443178473548456} | train loss {'Reaction outcome loss': 0.8183299195066638, 'Total loss': 0.8183299195066638}
2022-11-18 01:35:43,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:43,712 INFO:     Epoch: 23
2022-11-18 01:35:44,457 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8441228541460905, 'Total loss': 0.8441228541460905} | train loss {'Reaction outcome loss': 0.8191229010883131, 'Total loss': 0.8191229010883131}
2022-11-18 01:35:44,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:44,457 INFO:     Epoch: 24
2022-11-18 01:35:45,256 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8551578264344822, 'Total loss': 0.8551578264344822} | train loss {'Reaction outcome loss': 0.8211308337657558, 'Total loss': 0.8211308337657558}
2022-11-18 01:35:45,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:45,256 INFO:     Epoch: 25
2022-11-18 01:35:46,013 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8412609899585898, 'Total loss': 0.8412609899585898} | train loss {'Reaction outcome loss': 0.816135226835606, 'Total loss': 0.816135226835606}
2022-11-18 01:35:46,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:46,013 INFO:     Epoch: 26
2022-11-18 01:35:46,790 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.836497729474848, 'Total loss': 0.836497729474848} | train loss {'Reaction outcome loss': 0.8198399760945123, 'Total loss': 0.8198399760945123}
2022-11-18 01:35:46,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:46,790 INFO:     Epoch: 27
2022-11-18 01:35:47,575 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.833224902098829, 'Total loss': 0.833224902098829} | train loss {'Reaction outcome loss': 0.8212334619842561, 'Total loss': 0.8212334619842561}
2022-11-18 01:35:47,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:47,575 INFO:     Epoch: 28
2022-11-18 01:35:48,361 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8312171866947954, 'Total loss': 0.8312171866947954} | train loss {'Reaction outcome loss': 0.8141332444874382, 'Total loss': 0.8141332444874382}
2022-11-18 01:35:48,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:48,361 INFO:     Epoch: 29
2022-11-18 01:35:49,143 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8486958477984775, 'Total loss': 0.8486958477984775} | train loss {'Reaction outcome loss': 0.8170011057273338, 'Total loss': 0.8170011057273338}
2022-11-18 01:35:49,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:49,145 INFO:     Epoch: 30
2022-11-18 01:35:50,103 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8395768620751121, 'Total loss': 0.8395768620751121} | train loss {'Reaction outcome loss': 0.8097712017505275, 'Total loss': 0.8097712017505275}
2022-11-18 01:35:50,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:50,104 INFO:     Epoch: 31
2022-11-18 01:35:50,892 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8320277096195654, 'Total loss': 0.8320277096195654} | train loss {'Reaction outcome loss': 0.8140953996403497, 'Total loss': 0.8140953996403497}
2022-11-18 01:35:50,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:50,892 INFO:     Epoch: 32
2022-11-18 01:35:51,715 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8431285958398472, 'Total loss': 0.8431285958398472} | train loss {'Reaction outcome loss': 0.8162003422555654, 'Total loss': 0.8162003422555654}
2022-11-18 01:35:51,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:51,715 INFO:     Epoch: 33
2022-11-18 01:35:52,525 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8355753780765967, 'Total loss': 0.8355753780765967} | train loss {'Reaction outcome loss': 0.8147446818438618, 'Total loss': 0.8147446818438618}
2022-11-18 01:35:52,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:52,525 INFO:     Epoch: 34
2022-11-18 01:35:53,338 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8256804374131289, 'Total loss': 0.8256804374131289} | train loss {'Reaction outcome loss': 0.814602358862456, 'Total loss': 0.814602358862456}
2022-11-18 01:35:53,339 INFO:     Found new best model at epoch 34
2022-11-18 01:35:53,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:53,340 INFO:     Epoch: 35
2022-11-18 01:35:54,144 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8341964700005271, 'Total loss': 0.8341964700005271} | train loss {'Reaction outcome loss': 0.8193538197380329, 'Total loss': 0.8193538197380329}
2022-11-18 01:35:54,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:54,145 INFO:     Epoch: 36
2022-11-18 01:35:54,901 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8492943116209724, 'Total loss': 0.8492943116209724} | train loss {'Reaction outcome loss': 0.8113403129674163, 'Total loss': 0.8113403129674163}
2022-11-18 01:35:54,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:54,901 INFO:     Epoch: 37
2022-11-18 01:35:55,680 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8382428342645819, 'Total loss': 0.8382428342645819} | train loss {'Reaction outcome loss': 0.8049995093210506, 'Total loss': 0.8049995093210506}
2022-11-18 01:35:55,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:55,682 INFO:     Epoch: 38
2022-11-18 01:35:56,498 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.844210645691915, 'Total loss': 0.844210645691915} | train loss {'Reaction outcome loss': 0.8139081663086347, 'Total loss': 0.8139081663086347}
2022-11-18 01:35:56,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:56,498 INFO:     Epoch: 39
2022-11-18 01:35:57,338 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8417308046059175, 'Total loss': 0.8417308046059175} | train loss {'Reaction outcome loss': 0.8039949542356406, 'Total loss': 0.8039949542356406}
2022-11-18 01:35:57,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:57,338 INFO:     Epoch: 40
2022-11-18 01:35:58,199 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8216731737960469, 'Total loss': 0.8216731737960469} | train loss {'Reaction outcome loss': 0.813318168344768, 'Total loss': 0.813318168344768}
2022-11-18 01:35:58,199 INFO:     Found new best model at epoch 40
2022-11-18 01:35:58,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:58,200 INFO:     Epoch: 41
2022-11-18 01:35:59,037 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8238584047014063, 'Total loss': 0.8238584047014063} | train loss {'Reaction outcome loss': 0.8114059234437673, 'Total loss': 0.8114059234437673}
2022-11-18 01:35:59,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:59,037 INFO:     Epoch: 42
2022-11-18 01:35:59,844 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8429582450877536, 'Total loss': 0.8429582450877536} | train loss {'Reaction outcome loss': 0.8057488492625927, 'Total loss': 0.8057488492625927}
2022-11-18 01:35:59,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:35:59,845 INFO:     Epoch: 43
2022-11-18 01:36:00,627 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8253728530623696, 'Total loss': 0.8253728530623696} | train loss {'Reaction outcome loss': 0.8102320059832291, 'Total loss': 0.8102320059832291}
2022-11-18 01:36:00,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:00,628 INFO:     Epoch: 44
2022-11-18 01:36:01,403 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8284262323921378, 'Total loss': 0.8284262323921378} | train loss {'Reaction outcome loss': 0.7997493862743802, 'Total loss': 0.7997493862743802}
2022-11-18 01:36:01,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:01,404 INFO:     Epoch: 45
2022-11-18 01:36:02,247 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8237971338358793, 'Total loss': 0.8237971338358793} | train loss {'Reaction outcome loss': 0.8053710159019902, 'Total loss': 0.8053710159019902}
2022-11-18 01:36:02,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:02,248 INFO:     Epoch: 46
2022-11-18 01:36:03,051 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8362165750427679, 'Total loss': 0.8362165750427679} | train loss {'Reaction outcome loss': 0.799411798657676, 'Total loss': 0.799411798657676}
2022-11-18 01:36:03,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:03,052 INFO:     Epoch: 47
2022-11-18 01:36:03,842 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8449464453892275, 'Total loss': 0.8449464453892275} | train loss {'Reaction outcome loss': 0.7982278352806925, 'Total loss': 0.7982278352806925}
2022-11-18 01:36:03,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:03,843 INFO:     Epoch: 48
2022-11-18 01:36:04,604 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8046089972962033, 'Total loss': 0.8046089972962033} | train loss {'Reaction outcome loss': 0.7969913521351722, 'Total loss': 0.7969913521351722}
2022-11-18 01:36:04,604 INFO:     Found new best model at epoch 48
2022-11-18 01:36:04,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:04,605 INFO:     Epoch: 49
2022-11-18 01:36:05,411 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8141257390379906, 'Total loss': 0.8141257390379906} | train loss {'Reaction outcome loss': 0.7932711519934388, 'Total loss': 0.7932711519934388}
2022-11-18 01:36:05,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:05,411 INFO:     Epoch: 50
2022-11-18 01:36:06,201 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8220507969910448, 'Total loss': 0.8220507969910448} | train loss {'Reaction outcome loss': 0.7893540548530185, 'Total loss': 0.7893540548530185}
2022-11-18 01:36:06,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:06,201 INFO:     Epoch: 51
2022-11-18 01:36:06,979 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8387929505922578, 'Total loss': 0.8387929505922578} | train loss {'Reaction outcome loss': 0.7991686471802021, 'Total loss': 0.7991686471802021}
2022-11-18 01:36:06,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:06,979 INFO:     Epoch: 52
2022-11-18 01:36:07,766 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8180532706054774, 'Total loss': 0.8180532706054774} | train loss {'Reaction outcome loss': 0.8033187635514417, 'Total loss': 0.8033187635514417}
2022-11-18 01:36:07,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:07,767 INFO:     Epoch: 53
2022-11-18 01:36:08,555 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8478479520841078, 'Total loss': 0.8478479520841078} | train loss {'Reaction outcome loss': 0.7935264420654127, 'Total loss': 0.7935264420654127}
2022-11-18 01:36:08,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:08,555 INFO:     Epoch: 54
2022-11-18 01:36:09,338 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8153037022460591, 'Total loss': 0.8153037022460591} | train loss {'Reaction outcome loss': 0.7877893327822086, 'Total loss': 0.7877893327822086}
2022-11-18 01:36:09,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:09,338 INFO:     Epoch: 55
2022-11-18 01:36:10,122 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8078873035582629, 'Total loss': 0.8078873035582629} | train loss {'Reaction outcome loss': 0.783500768395088, 'Total loss': 0.783500768395088}
2022-11-18 01:36:10,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:10,122 INFO:     Epoch: 56
2022-11-18 01:36:10,908 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8049775795503096, 'Total loss': 0.8049775795503096} | train loss {'Reaction outcome loss': 0.7852773882056537, 'Total loss': 0.7852773882056537}
2022-11-18 01:36:10,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:10,908 INFO:     Epoch: 57
2022-11-18 01:36:11,686 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8159652582623742, 'Total loss': 0.8159652582623742} | train loss {'Reaction outcome loss': 0.7862933145360909, 'Total loss': 0.7862933145360909}
2022-11-18 01:36:11,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:11,686 INFO:     Epoch: 58
2022-11-18 01:36:12,470 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7995312146165154, 'Total loss': 0.7995312146165154} | train loss {'Reaction outcome loss': 0.7794327889437135, 'Total loss': 0.7794327889437135}
2022-11-18 01:36:12,470 INFO:     Found new best model at epoch 58
2022-11-18 01:36:12,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:12,472 INFO:     Epoch: 59
2022-11-18 01:36:13,322 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8020940368825739, 'Total loss': 0.8020940368825739} | train loss {'Reaction outcome loss': 0.7858879714600953, 'Total loss': 0.7858879714600953}
2022-11-18 01:36:13,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:13,322 INFO:     Epoch: 60
2022-11-18 01:36:14,156 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8072727085514502, 'Total loss': 0.8072727085514502} | train loss {'Reaction outcome loss': 0.7816584706758922, 'Total loss': 0.7816584706758922}
2022-11-18 01:36:14,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:14,156 INFO:     Epoch: 61
2022-11-18 01:36:14,982 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7898792908950285, 'Total loss': 0.7898792908950285} | train loss {'Reaction outcome loss': 0.7795971559609479, 'Total loss': 0.7795971559609479}
2022-11-18 01:36:14,982 INFO:     Found new best model at epoch 61
2022-11-18 01:36:14,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:14,983 INFO:     Epoch: 62
2022-11-18 01:36:15,785 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8324006660418077, 'Total loss': 0.8324006660418077} | train loss {'Reaction outcome loss': 0.7886166016341221, 'Total loss': 0.7886166016341221}
2022-11-18 01:36:15,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:15,785 INFO:     Epoch: 63
2022-11-18 01:36:16,574 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7841039882464842, 'Total loss': 0.7841039882464842} | train loss {'Reaction outcome loss': 0.7808185056877522, 'Total loss': 0.7808185056877522}
2022-11-18 01:36:16,574 INFO:     Found new best model at epoch 63
2022-11-18 01:36:16,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:16,575 INFO:     Epoch: 64
2022-11-18 01:36:17,398 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8364362499930642, 'Total loss': 0.8364362499930642} | train loss {'Reaction outcome loss': 0.7672827028281052, 'Total loss': 0.7672827028281052}
2022-11-18 01:36:17,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:17,399 INFO:     Epoch: 65
2022-11-18 01:36:18,216 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7758091146295721, 'Total loss': 0.7758091146295721} | train loss {'Reaction outcome loss': 0.7673712167662647, 'Total loss': 0.7673712167662647}
2022-11-18 01:36:18,217 INFO:     Found new best model at epoch 65
2022-11-18 01:36:18,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:18,217 INFO:     Epoch: 66
2022-11-18 01:36:19,033 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8051486015319824, 'Total loss': 0.8051486015319824} | train loss {'Reaction outcome loss': 0.7628105789543647, 'Total loss': 0.7628105789543647}
2022-11-18 01:36:19,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:19,033 INFO:     Epoch: 67
2022-11-18 01:36:19,839 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8046073344620791, 'Total loss': 0.8046073344620791} | train loss {'Reaction outcome loss': 0.7608970940595696, 'Total loss': 0.7608970940595696}
2022-11-18 01:36:19,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:19,840 INFO:     Epoch: 68
2022-11-18 01:36:20,676 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7802552926269445, 'Total loss': 0.7802552926269445} | train loss {'Reaction outcome loss': 0.7567210414631647, 'Total loss': 0.7567210414631647}
2022-11-18 01:36:20,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:20,677 INFO:     Epoch: 69
2022-11-18 01:36:21,489 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7585248445922678, 'Total loss': 0.7585248445922678} | train loss {'Reaction outcome loss': 0.7477363734110164, 'Total loss': 0.7477363734110164}
2022-11-18 01:36:21,489 INFO:     Found new best model at epoch 69
2022-11-18 01:36:21,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:21,490 INFO:     Epoch: 70
2022-11-18 01:36:22,318 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7750153907320716, 'Total loss': 0.7750153907320716} | train loss {'Reaction outcome loss': 0.7410980119155004, 'Total loss': 0.7410980119155004}
2022-11-18 01:36:22,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:22,318 INFO:     Epoch: 71
2022-11-18 01:36:23,117 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7525387379256162, 'Total loss': 0.7525387379256162} | train loss {'Reaction outcome loss': 0.7375146137769164, 'Total loss': 0.7375146137769164}
2022-11-18 01:36:23,117 INFO:     Found new best model at epoch 71
2022-11-18 01:36:23,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:23,118 INFO:     Epoch: 72
2022-11-18 01:36:23,928 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7246977300806479, 'Total loss': 0.7246977300806479} | train loss {'Reaction outcome loss': 0.7159399239399172, 'Total loss': 0.7159399239399172}
2022-11-18 01:36:23,928 INFO:     Found new best model at epoch 72
2022-11-18 01:36:23,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:23,929 INFO:     Epoch: 73
2022-11-18 01:36:24,735 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.73247737234289, 'Total loss': 0.73247737234289} | train loss {'Reaction outcome loss': 0.7202310085537945, 'Total loss': 0.7202310085537945}
2022-11-18 01:36:24,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:24,736 INFO:     Epoch: 74
2022-11-18 01:36:25,525 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.6866408383304422, 'Total loss': 0.6866408383304422} | train loss {'Reaction outcome loss': 0.7123375414354116, 'Total loss': 0.7123375414354116}
2022-11-18 01:36:25,525 INFO:     Found new best model at epoch 74
2022-11-18 01:36:25,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:25,526 INFO:     Epoch: 75
2022-11-18 01:36:26,361 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.663940357890996, 'Total loss': 0.663940357890996} | train loss {'Reaction outcome loss': 0.6810322150527707, 'Total loss': 0.6810322150527707}
2022-11-18 01:36:26,362 INFO:     Found new best model at epoch 75
2022-11-18 01:36:26,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:26,364 INFO:     Epoch: 76
2022-11-18 01:36:27,213 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.706596736880866, 'Total loss': 0.706596736880866} | train loss {'Reaction outcome loss': 0.6747235401197966, 'Total loss': 0.6747235401197966}
2022-11-18 01:36:27,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:27,213 INFO:     Epoch: 77
2022-11-18 01:36:28,033 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7054613652554426, 'Total loss': 0.7054613652554426} | train loss {'Reaction outcome loss': 0.6479548040309898, 'Total loss': 0.6479548040309898}
2022-11-18 01:36:28,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:28,033 INFO:     Epoch: 78
2022-11-18 01:36:28,840 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.6330698105421934, 'Total loss': 0.6330698105421934} | train loss {'Reaction outcome loss': 0.6617278264692197, 'Total loss': 0.6617278264692197}
2022-11-18 01:36:28,840 INFO:     Found new best model at epoch 78
2022-11-18 01:36:28,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:28,841 INFO:     Epoch: 79
2022-11-18 01:36:29,678 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.6218935325741768, 'Total loss': 0.6218935325741768} | train loss {'Reaction outcome loss': 0.6193893530108185, 'Total loss': 0.6193893530108185}
2022-11-18 01:36:29,678 INFO:     Found new best model at epoch 79
2022-11-18 01:36:29,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:29,679 INFO:     Epoch: 80
2022-11-18 01:36:30,489 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.604650634594939, 'Total loss': 0.604650634594939} | train loss {'Reaction outcome loss': 0.6398515262101826, 'Total loss': 0.6398515262101826}
2022-11-18 01:36:30,489 INFO:     Found new best model at epoch 80
2022-11-18 01:36:30,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:30,490 INFO:     Epoch: 81
2022-11-18 01:36:31,293 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.6055436019193042, 'Total loss': 0.6055436019193042} | train loss {'Reaction outcome loss': 0.625143425546677, 'Total loss': 0.625143425546677}
2022-11-18 01:36:31,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:31,293 INFO:     Epoch: 82
2022-11-18 01:36:32,119 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.68546481362798, 'Total loss': 0.68546481362798} | train loss {'Reaction outcome loss': 0.6287349793109817, 'Total loss': 0.6287349793109817}
2022-11-18 01:36:32,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:32,119 INFO:     Epoch: 83
2022-11-18 01:36:32,969 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.63134554638104, 'Total loss': 0.63134554638104} | train loss {'Reaction outcome loss': 0.6466885717653552, 'Total loss': 0.6466885717653552}
2022-11-18 01:36:32,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:32,969 INFO:     Epoch: 84
2022-11-18 01:36:33,782 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.6682799878445539, 'Total loss': 0.6682799878445539} | train loss {'Reaction outcome loss': 0.6299570015808831, 'Total loss': 0.6299570015808831}
2022-11-18 01:36:33,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:33,782 INFO:     Epoch: 85
2022-11-18 01:36:34,594 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5808255266059529, 'Total loss': 0.5808255266059529} | train loss {'Reaction outcome loss': 0.6060904954609118, 'Total loss': 0.6060904954609118}
2022-11-18 01:36:34,594 INFO:     Found new best model at epoch 85
2022-11-18 01:36:34,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:34,595 INFO:     Epoch: 86
2022-11-18 01:36:35,385 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.6235561736605384, 'Total loss': 0.6235561736605384} | train loss {'Reaction outcome loss': 0.6072408232370369, 'Total loss': 0.6072408232370369}
2022-11-18 01:36:35,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:35,385 INFO:     Epoch: 87
2022-11-18 01:36:36,233 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7028786987066269, 'Total loss': 0.7028786987066269} | train loss {'Reaction outcome loss': 0.6362793571070621, 'Total loss': 0.6362793571070621}
2022-11-18 01:36:36,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:36,233 INFO:     Epoch: 88
2022-11-18 01:36:37,065 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.6362101632085714, 'Total loss': 0.6362101632085714} | train loss {'Reaction outcome loss': 0.6276244676788809, 'Total loss': 0.6276244676788809}
2022-11-18 01:36:37,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:37,065 INFO:     Epoch: 89
2022-11-18 01:36:37,840 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.572042582387274, 'Total loss': 0.572042582387274} | train loss {'Reaction outcome loss': 0.5935930032961765, 'Total loss': 0.5935930032961765}
2022-11-18 01:36:37,840 INFO:     Found new best model at epoch 89
2022-11-18 01:36:37,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:37,841 INFO:     Epoch: 90
2022-11-18 01:36:38,668 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5716841112483632, 'Total loss': 0.5716841112483632} | train loss {'Reaction outcome loss': 0.6157101705248057, 'Total loss': 0.6157101705248057}
2022-11-18 01:36:38,669 INFO:     Found new best model at epoch 90
2022-11-18 01:36:38,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:38,671 INFO:     Epoch: 91
2022-11-18 01:36:39,492 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5165732875466347, 'Total loss': 0.5165732875466347} | train loss {'Reaction outcome loss': 0.5850159790713777, 'Total loss': 0.5850159790713777}
2022-11-18 01:36:39,492 INFO:     Found new best model at epoch 91
2022-11-18 01:36:39,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:39,494 INFO:     Epoch: 92
2022-11-18 01:36:40,297 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.6397729827599092, 'Total loss': 0.6397729827599092} | train loss {'Reaction outcome loss': 0.6052973021862478, 'Total loss': 0.6052973021862478}
2022-11-18 01:36:40,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:40,298 INFO:     Epoch: 93
2022-11-18 01:36:41,114 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5515636280179024, 'Total loss': 0.5515636280179024} | train loss {'Reaction outcome loss': 0.5729438935214208, 'Total loss': 0.5729438935214208}
2022-11-18 01:36:41,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:41,114 INFO:     Epoch: 94
2022-11-18 01:36:41,909 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.6639486293901097, 'Total loss': 0.6639486293901097} | train loss {'Reaction outcome loss': 0.5888580047649893, 'Total loss': 0.5888580047649893}
2022-11-18 01:36:41,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:41,909 INFO:     Epoch: 95
2022-11-18 01:36:42,706 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.6611344678835436, 'Total loss': 0.6611344678835436} | train loss {'Reaction outcome loss': 0.6121971072395321, 'Total loss': 0.6121971072395321}
2022-11-18 01:36:42,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:42,706 INFO:     Epoch: 96
2022-11-18 01:36:43,530 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.6957889842716131, 'Total loss': 0.6957889842716131} | train loss {'Reaction outcome loss': 0.5726692666891615, 'Total loss': 0.5726692666891615}
2022-11-18 01:36:43,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:43,530 INFO:     Epoch: 97
2022-11-18 01:36:44,331 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5547512959350239, 'Total loss': 0.5547512959350239} | train loss {'Reaction outcome loss': 0.5899721695343975, 'Total loss': 0.5899721695343975}
2022-11-18 01:36:44,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:44,331 INFO:     Epoch: 98
2022-11-18 01:36:45,152 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.6662803265181455, 'Total loss': 0.6662803265181455} | train loss {'Reaction outcome loss': 0.5997369832355484, 'Total loss': 0.5997369832355484}
2022-11-18 01:36:45,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:45,152 INFO:     Epoch: 99
2022-11-18 01:36:45,976 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.6132768155498938, 'Total loss': 0.6132768155498938} | train loss {'Reaction outcome loss': 0.600903923287686, 'Total loss': 0.600903923287686}
2022-11-18 01:36:45,977 INFO:     Best model found after epoch 92 of 100.
2022-11-18 01:36:45,977 INFO:   Done with stage: TRAINING
2022-11-18 01:36:45,977 INFO:   Starting stage: EVALUATION
2022-11-18 01:36:46,102 INFO:   Done with stage: EVALUATION
2022-11-18 01:36:46,102 INFO:   Leaving out SEQ value Fold_2
2022-11-18 01:36:46,115 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 01:36:46,115 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:36:46,784 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:36:46,784 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:36:46,855 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:36:46,855 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:36:46,855 INFO:     No hyperparam tuning for this model
2022-11-18 01:36:46,855 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:36:46,855 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:36:46,856 INFO:     None feature selector for col prot
2022-11-18 01:36:46,856 INFO:     None feature selector for col prot
2022-11-18 01:36:46,856 INFO:     None feature selector for col prot
2022-11-18 01:36:46,857 INFO:     None feature selector for col chem
2022-11-18 01:36:46,857 INFO:     None feature selector for col chem
2022-11-18 01:36:46,857 INFO:     None feature selector for col chem
2022-11-18 01:36:46,857 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:36:46,857 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:36:46,858 INFO:     Number of params in model 168571
2022-11-18 01:36:46,862 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:36:46,862 INFO:   Starting stage: TRAINING
2022-11-18 01:36:46,920 INFO:     Val loss before train {'Reaction outcome loss': 0.9494263055649671, 'Total loss': 0.9494263055649671}
2022-11-18 01:36:46,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:46,920 INFO:     Epoch: 0
2022-11-18 01:36:47,735 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7929826080799103, 'Total loss': 0.7929826080799103} | train loss {'Reaction outcome loss': 0.8727207568227028, 'Total loss': 0.8727207568227028}
2022-11-18 01:36:47,735 INFO:     Found new best model at epoch 0
2022-11-18 01:36:47,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:47,736 INFO:     Epoch: 1
2022-11-18 01:36:48,544 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8154662651094523, 'Total loss': 0.8154662651094523} | train loss {'Reaction outcome loss': 0.8509889091764178, 'Total loss': 0.8509889091764178}
2022-11-18 01:36:48,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:48,544 INFO:     Epoch: 2
2022-11-18 01:36:49,381 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.790200686590238, 'Total loss': 0.790200686590238} | train loss {'Reaction outcome loss': 0.8434904845393434, 'Total loss': 0.8434904845393434}
2022-11-18 01:36:49,381 INFO:     Found new best model at epoch 2
2022-11-18 01:36:49,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:49,382 INFO:     Epoch: 3
2022-11-18 01:36:50,206 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7702673238448121, 'Total loss': 0.7702673238448121} | train loss {'Reaction outcome loss': 0.8435930765404993, 'Total loss': 0.8435930765404993}
2022-11-18 01:36:50,207 INFO:     Found new best model at epoch 3
2022-11-18 01:36:50,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:50,207 INFO:     Epoch: 4
2022-11-18 01:36:51,055 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7848887890577316, 'Total loss': 0.7848887890577316} | train loss {'Reaction outcome loss': 0.8429999148359104, 'Total loss': 0.8429999148359104}
2022-11-18 01:36:51,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:51,055 INFO:     Epoch: 5
2022-11-18 01:36:51,850 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8060910119251772, 'Total loss': 0.8060910119251772} | train loss {'Reaction outcome loss': 0.837728353179231, 'Total loss': 0.837728353179231}
2022-11-18 01:36:51,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:51,852 INFO:     Epoch: 6
2022-11-18 01:36:52,635 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7884782302108678, 'Total loss': 0.7884782302108678} | train loss {'Reaction outcome loss': 0.8337661729783428, 'Total loss': 0.8337661729783428}
2022-11-18 01:36:52,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:52,635 INFO:     Epoch: 7
2022-11-18 01:36:53,451 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7797939472577788, 'Total loss': 0.7797939472577788} | train loss {'Reaction outcome loss': 0.829254885595672, 'Total loss': 0.829254885595672}
2022-11-18 01:36:53,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:53,451 INFO:     Epoch: 8
2022-11-18 01:36:54,227 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7860637185248461, 'Total loss': 0.7860637185248461} | train loss {'Reaction outcome loss': 0.8287419996699509, 'Total loss': 0.8287419996699509}
2022-11-18 01:36:54,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:54,227 INFO:     Epoch: 9
2022-11-18 01:36:55,165 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7707880254496228, 'Total loss': 0.7707880254496228} | train loss {'Reaction outcome loss': 0.8271531315482392, 'Total loss': 0.8271531315482392}
2022-11-18 01:36:55,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:55,165 INFO:     Epoch: 10
2022-11-18 01:36:55,959 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7669375037605112, 'Total loss': 0.7669375037605112} | train loss {'Reaction outcome loss': 0.8301153987037893, 'Total loss': 0.8301153987037893}
2022-11-18 01:36:55,959 INFO:     Found new best model at epoch 10
2022-11-18 01:36:55,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:55,960 INFO:     Epoch: 11
2022-11-18 01:36:56,745 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7839171818711541, 'Total loss': 0.7839171818711541} | train loss {'Reaction outcome loss': 0.825849211337615, 'Total loss': 0.825849211337615}
2022-11-18 01:36:56,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:56,745 INFO:     Epoch: 12
2022-11-18 01:36:57,573 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7751587331295013, 'Total loss': 0.7751587331295013} | train loss {'Reaction outcome loss': 0.8239674638728707, 'Total loss': 0.8239674638728707}
2022-11-18 01:36:57,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:57,573 INFO:     Epoch: 13
2022-11-18 01:36:58,384 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8195567185228522, 'Total loss': 0.8195567185228522} | train loss {'Reaction outcome loss': 0.8268107954336672, 'Total loss': 0.8268107954336672}
2022-11-18 01:36:58,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:58,385 INFO:     Epoch: 14
2022-11-18 01:36:59,184 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7758021598512476, 'Total loss': 0.7758021598512476} | train loss {'Reaction outcome loss': 0.827245636497225, 'Total loss': 0.827245636497225}
2022-11-18 01:36:59,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:59,184 INFO:     Epoch: 15
2022-11-18 01:36:59,974 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7897868725386533, 'Total loss': 0.7897868725386533} | train loss {'Reaction outcome loss': 0.8168724390925194, 'Total loss': 0.8168724390925194}
2022-11-18 01:36:59,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:36:59,974 INFO:     Epoch: 16
2022-11-18 01:37:00,753 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7890753813765266, 'Total loss': 0.7890753813765266} | train loss {'Reaction outcome loss': 0.8265705063634989, 'Total loss': 0.8265705063634989}
2022-11-18 01:37:00,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:00,754 INFO:     Epoch: 17
2022-11-18 01:37:01,552 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.772862049666318, 'Total loss': 0.772862049666318} | train loss {'Reaction outcome loss': 0.8271237802748778, 'Total loss': 0.8271237802748778}
2022-11-18 01:37:01,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:01,552 INFO:     Epoch: 18
2022-11-18 01:37:02,359 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7793026959354227, 'Total loss': 0.7793026959354227} | train loss {'Reaction outcome loss': 0.8253938199306021, 'Total loss': 0.8253938199306021}
2022-11-18 01:37:02,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:02,360 INFO:     Epoch: 19
2022-11-18 01:37:03,141 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7800885195081885, 'Total loss': 0.7800885195081885} | train loss {'Reaction outcome loss': 0.8257808135480297, 'Total loss': 0.8257808135480297}
2022-11-18 01:37:03,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:03,142 INFO:     Epoch: 20
2022-11-18 01:37:03,956 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7893173877488483, 'Total loss': 0.7893173877488483} | train loss {'Reaction outcome loss': 0.8221529622467196, 'Total loss': 0.8221529622467196}
2022-11-18 01:37:03,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:03,956 INFO:     Epoch: 21
2022-11-18 01:37:04,761 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7723003246567466, 'Total loss': 0.7723003246567466} | train loss {'Reaction outcome loss': 0.821342738063968, 'Total loss': 0.821342738063968}
2022-11-18 01:37:04,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:04,761 INFO:     Epoch: 22
2022-11-18 01:37:05,581 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7837125482884321, 'Total loss': 0.7837125482884321} | train loss {'Reaction outcome loss': 0.8280714749073496, 'Total loss': 0.8280714749073496}
2022-11-18 01:37:05,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:05,581 INFO:     Epoch: 23
2022-11-18 01:37:06,363 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7706165862354365, 'Total loss': 0.7706165862354365} | train loss {'Reaction outcome loss': 0.8200940545724362, 'Total loss': 0.8200940545724362}
2022-11-18 01:37:06,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:06,364 INFO:     Epoch: 24
2022-11-18 01:37:07,164 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7691704698584296, 'Total loss': 0.7691704698584296} | train loss {'Reaction outcome loss': 0.8267830802469838, 'Total loss': 0.8267830802469838}
2022-11-18 01:37:07,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:07,164 INFO:     Epoch: 25
2022-11-18 01:37:07,964 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7820689447901465, 'Total loss': 0.7820689447901465} | train loss {'Reaction outcome loss': 0.8250807284092416, 'Total loss': 0.8250807284092416}
2022-11-18 01:37:07,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:07,964 INFO:     Epoch: 26
2022-11-18 01:37:08,784 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7590091909197244, 'Total loss': 0.7590091909197244} | train loss {'Reaction outcome loss': 0.8244065734804893, 'Total loss': 0.8244065734804893}
2022-11-18 01:37:08,784 INFO:     Found new best model at epoch 26
2022-11-18 01:37:08,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:08,785 INFO:     Epoch: 27
2022-11-18 01:37:09,551 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7784824039448391, 'Total loss': 0.7784824039448391} | train loss {'Reaction outcome loss': 0.8246131939547402, 'Total loss': 0.8246131939547402}
2022-11-18 01:37:09,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:09,551 INFO:     Epoch: 28
2022-11-18 01:37:10,343 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8251358920877631, 'Total loss': 0.8251358920877631} | train loss {'Reaction outcome loss': 0.8208759748205847, 'Total loss': 0.8208759748205847}
2022-11-18 01:37:10,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:10,343 INFO:     Epoch: 29
2022-11-18 01:37:11,116 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8019773614677516, 'Total loss': 0.8019773614677516} | train loss {'Reaction outcome loss': 0.8252522688739153, 'Total loss': 0.8252522688739153}
2022-11-18 01:37:11,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:11,117 INFO:     Epoch: 30
2022-11-18 01:37:11,964 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7773461524735797, 'Total loss': 0.7773461524735797} | train loss {'Reaction outcome loss': 0.8217462049455059, 'Total loss': 0.8217462049455059}
2022-11-18 01:37:11,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:11,965 INFO:     Epoch: 31
2022-11-18 01:37:12,798 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8012168597091328, 'Total loss': 0.8012168597091328} | train loss {'Reaction outcome loss': 0.8231689430012995, 'Total loss': 0.8231689430012995}
2022-11-18 01:37:12,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:12,799 INFO:     Epoch: 32
2022-11-18 01:37:13,559 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7916005287658084, 'Total loss': 0.7916005287658084} | train loss {'Reaction outcome loss': 0.8222268603285965, 'Total loss': 0.8222268603285965}
2022-11-18 01:37:13,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:13,559 INFO:     Epoch: 33
2022-11-18 01:37:14,327 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7777893936092203, 'Total loss': 0.7777893936092203} | train loss {'Reaction outcome loss': 0.824997809103557, 'Total loss': 0.824997809103557}
2022-11-18 01:37:14,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:14,327 INFO:     Epoch: 34
2022-11-18 01:37:15,095 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7800168306990103, 'Total loss': 0.7800168306990103} | train loss {'Reaction outcome loss': 0.8222312505147895, 'Total loss': 0.8222312505147895}
2022-11-18 01:37:15,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:15,095 INFO:     Epoch: 35
2022-11-18 01:37:15,877 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7908805012702942, 'Total loss': 0.7908805012702942} | train loss {'Reaction outcome loss': 0.8240479864028035, 'Total loss': 0.8240479864028035}
2022-11-18 01:37:15,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:15,877 INFO:     Epoch: 36
2022-11-18 01:37:16,679 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7617076364430514, 'Total loss': 0.7617076364430514} | train loss {'Reaction outcome loss': 0.8251005271259619, 'Total loss': 0.8251005271259619}
2022-11-18 01:37:16,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:16,680 INFO:     Epoch: 37
2022-11-18 01:37:17,454 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7740952616388147, 'Total loss': 0.7740952616388147} | train loss {'Reaction outcome loss': 0.8185459332806724, 'Total loss': 0.8185459332806724}
2022-11-18 01:37:17,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:17,454 INFO:     Epoch: 38
2022-11-18 01:37:18,241 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7705454487692226, 'Total loss': 0.7705454487692226} | train loss {'Reaction outcome loss': 0.8218975585334155, 'Total loss': 0.8218975585334155}
2022-11-18 01:37:18,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:18,241 INFO:     Epoch: 39
2022-11-18 01:37:19,004 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8158018331636082, 'Total loss': 0.8158018331636082} | train loss {'Reaction outcome loss': 0.8217157754362846, 'Total loss': 0.8217157754362846}
2022-11-18 01:37:19,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:19,004 INFO:     Epoch: 40
2022-11-18 01:37:19,778 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7707652432674711, 'Total loss': 0.7707652432674711} | train loss {'Reaction outcome loss': 0.8268997803026316, 'Total loss': 0.8268997803026316}
2022-11-18 01:37:19,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:19,778 INFO:     Epoch: 41
2022-11-18 01:37:20,561 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7722814672372558, 'Total loss': 0.7722814672372558} | train loss {'Reaction outcome loss': 0.8241321706041997, 'Total loss': 0.8241321706041997}
2022-11-18 01:37:20,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:20,561 INFO:     Epoch: 42
2022-11-18 01:37:21,350 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.782294740731066, 'Total loss': 0.782294740731066} | train loss {'Reaction outcome loss': 0.8227117329227681, 'Total loss': 0.8227117329227681}
2022-11-18 01:37:21,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:21,351 INFO:     Epoch: 43
2022-11-18 01:37:22,106 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7905948907136917, 'Total loss': 0.7905948907136917} | train loss {'Reaction outcome loss': 0.8209028392421956, 'Total loss': 0.8209028392421956}
2022-11-18 01:37:22,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:22,106 INFO:     Epoch: 44
2022-11-18 01:37:22,878 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7886847216974605, 'Total loss': 0.7886847216974605} | train loss {'Reaction outcome loss': 0.8247825412117705, 'Total loss': 0.8247825412117705}
2022-11-18 01:37:22,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:22,880 INFO:     Epoch: 45
2022-11-18 01:37:23,633 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7504269606010481, 'Total loss': 0.7504269606010481} | train loss {'Reaction outcome loss': 0.8248328627372274, 'Total loss': 0.8248328627372274}
2022-11-18 01:37:23,633 INFO:     Found new best model at epoch 45
2022-11-18 01:37:23,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:23,634 INFO:     Epoch: 46
2022-11-18 01:37:24,397 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7707392501390793, 'Total loss': 0.7707392501390793} | train loss {'Reaction outcome loss': 0.8234883647792194, 'Total loss': 0.8234883647792194}
2022-11-18 01:37:24,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:24,397 INFO:     Epoch: 47
2022-11-18 01:37:25,171 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7761947810649872, 'Total loss': 0.7761947810649872} | train loss {'Reaction outcome loss': 0.8271166887818551, 'Total loss': 0.8271166887818551}
2022-11-18 01:37:25,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:25,172 INFO:     Epoch: 48
2022-11-18 01:37:25,976 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7677523439580743, 'Total loss': 0.7677523439580743} | train loss {'Reaction outcome loss': 0.8223814152941412, 'Total loss': 0.8223814152941412}
2022-11-18 01:37:25,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:25,977 INFO:     Epoch: 49
2022-11-18 01:37:26,771 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7734074572270567, 'Total loss': 0.7734074572270567} | train loss {'Reaction outcome loss': 0.8228374348611248, 'Total loss': 0.8228374348611248}
2022-11-18 01:37:26,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:26,772 INFO:     Epoch: 50
2022-11-18 01:37:27,553 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7727149135687135, 'Total loss': 0.7727149135687135} | train loss {'Reaction outcome loss': 0.821199755887596, 'Total loss': 0.821199755887596}
2022-11-18 01:37:27,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:27,553 INFO:     Epoch: 51
2022-11-18 01:37:28,328 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7702859165993604, 'Total loss': 0.7702859165993604} | train loss {'Reaction outcome loss': 0.8257477012215828, 'Total loss': 0.8257477012215828}
2022-11-18 01:37:28,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:28,330 INFO:     Epoch: 52
2022-11-18 01:37:29,129 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7668613954023882, 'Total loss': 0.7668613954023882} | train loss {'Reaction outcome loss': 0.8239516351904188, 'Total loss': 0.8239516351904188}
2022-11-18 01:37:29,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:29,130 INFO:     Epoch: 53
2022-11-18 01:37:29,897 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7698462808674033, 'Total loss': 0.7698462808674033} | train loss {'Reaction outcome loss': 0.8235482079642159, 'Total loss': 0.8235482079642159}
2022-11-18 01:37:29,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:29,897 INFO:     Epoch: 54
2022-11-18 01:37:30,650 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7745758362791755, 'Total loss': 0.7745758362791755} | train loss {'Reaction outcome loss': 0.8214556649023173, 'Total loss': 0.8214556649023173}
2022-11-18 01:37:30,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:30,650 INFO:     Epoch: 55
2022-11-18 01:37:31,403 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7862362732941454, 'Total loss': 0.7862362732941454} | train loss {'Reaction outcome loss': 0.823180357290774, 'Total loss': 0.823180357290774}
2022-11-18 01:37:31,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:31,404 INFO:     Epoch: 56
2022-11-18 01:37:32,190 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7837213338776068, 'Total loss': 0.7837213338776068} | train loss {'Reaction outcome loss': 0.8197630780083792, 'Total loss': 0.8197630780083792}
2022-11-18 01:37:32,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:32,191 INFO:     Epoch: 57
2022-11-18 01:37:32,958 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7672217759219083, 'Total loss': 0.7672217759219083} | train loss {'Reaction outcome loss': 0.8214070790884446, 'Total loss': 0.8214070790884446}
2022-11-18 01:37:32,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:32,958 INFO:     Epoch: 58
2022-11-18 01:37:33,711 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7730044546452436, 'Total loss': 0.7730044546452436} | train loss {'Reaction outcome loss': 0.8199558495258799, 'Total loss': 0.8199558495258799}
2022-11-18 01:37:33,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:33,712 INFO:     Epoch: 59
2022-11-18 01:37:34,496 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7761907848444852, 'Total loss': 0.7761907848444852} | train loss {'Reaction outcome loss': 0.8192482363204567, 'Total loss': 0.8192482363204567}
2022-11-18 01:37:34,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:34,496 INFO:     Epoch: 60
2022-11-18 01:37:35,287 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7679063467816873, 'Total loss': 0.7679063467816873} | train loss {'Reaction outcome loss': 0.8220904432997411, 'Total loss': 0.8220904432997411}
2022-11-18 01:37:35,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:35,288 INFO:     Epoch: 61
2022-11-18 01:37:36,093 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7852004265243356, 'Total loss': 0.7852004265243356} | train loss {'Reaction outcome loss': 0.8228669648267785, 'Total loss': 0.8228669648267785}
2022-11-18 01:37:36,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:36,093 INFO:     Epoch: 62
2022-11-18 01:37:36,907 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7658888121897524, 'Total loss': 0.7658888121897524} | train loss {'Reaction outcome loss': 0.8233855299803675, 'Total loss': 0.8233855299803675}
2022-11-18 01:37:36,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:36,908 INFO:     Epoch: 63
2022-11-18 01:37:37,688 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7634917003187266, 'Total loss': 0.7634917003187266} | train loss {'Reaction outcome loss': 0.824260341026345, 'Total loss': 0.824260341026345}
2022-11-18 01:37:37,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:37,688 INFO:     Epoch: 64
2022-11-18 01:37:38,463 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7873960008675401, 'Total loss': 0.7873960008675401} | train loss {'Reaction outcome loss': 0.8249898929985202, 'Total loss': 0.8249898929985202}
2022-11-18 01:37:38,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:38,463 INFO:     Epoch: 65
2022-11-18 01:37:39,264 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7758916061032902, 'Total loss': 0.7758916061032902} | train loss {'Reaction outcome loss': 0.8277621032023916, 'Total loss': 0.8277621032023916}
2022-11-18 01:37:39,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:39,265 INFO:     Epoch: 66
2022-11-18 01:37:40,057 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8059747002341531, 'Total loss': 0.8059747002341531} | train loss {'Reaction outcome loss': 0.8243338645720969, 'Total loss': 0.8243338645720969}
2022-11-18 01:37:40,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:40,057 INFO:     Epoch: 67
2022-11-18 01:37:40,821 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7621525559913028, 'Total loss': 0.7621525559913028} | train loss {'Reaction outcome loss': 0.8229278187362515, 'Total loss': 0.8229278187362515}
2022-11-18 01:37:40,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:40,821 INFO:     Epoch: 68
2022-11-18 01:37:41,590 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7762795571576465, 'Total loss': 0.7762795571576465} | train loss {'Reaction outcome loss': 0.8224221665032055, 'Total loss': 0.8224221665032055}
2022-11-18 01:37:41,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:41,590 INFO:     Epoch: 69
2022-11-18 01:37:42,377 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7800806042822924, 'Total loss': 0.7800806042822924} | train loss {'Reaction outcome loss': 0.8251777479843218, 'Total loss': 0.8251777479843218}
2022-11-18 01:37:42,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:42,378 INFO:     Epoch: 70
2022-11-18 01:37:43,147 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7784891473976049, 'Total loss': 0.7784891473976049} | train loss {'Reaction outcome loss': 0.8187122427687353, 'Total loss': 0.8187122427687353}
2022-11-18 01:37:43,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:43,147 INFO:     Epoch: 71
2022-11-18 01:37:43,919 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7698942226442423, 'Total loss': 0.7698942226442423} | train loss {'Reaction outcome loss': 0.8204002129788301, 'Total loss': 0.8204002129788301}
2022-11-18 01:37:43,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:43,919 INFO:     Epoch: 72
2022-11-18 01:37:44,694 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7683776454492048, 'Total loss': 0.7683776454492048} | train loss {'Reaction outcome loss': 0.8246027563299452, 'Total loss': 0.8246027563299452}
2022-11-18 01:37:44,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:44,696 INFO:     Epoch: 73
2022-11-18 01:37:45,473 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7784467786550522, 'Total loss': 0.7784467786550522} | train loss {'Reaction outcome loss': 0.824598014476348, 'Total loss': 0.824598014476348}
2022-11-18 01:37:45,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:45,473 INFO:     Epoch: 74
2022-11-18 01:37:46,259 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7743651257319883, 'Total loss': 0.7743651257319883} | train loss {'Reaction outcome loss': 0.8189260591049583, 'Total loss': 0.8189260591049583}
2022-11-18 01:37:46,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:46,260 INFO:     Epoch: 75
2022-11-18 01:37:47,032 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7951124960725958, 'Total loss': 0.7951124960725958} | train loss {'Reaction outcome loss': 0.8242788086132128, 'Total loss': 0.8242788086132128}
2022-11-18 01:37:47,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:47,032 INFO:     Epoch: 76
2022-11-18 01:37:47,821 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.778738599609245, 'Total loss': 0.778738599609245} | train loss {'Reaction outcome loss': 0.8208228158707521, 'Total loss': 0.8208228158707521}
2022-11-18 01:37:47,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:47,821 INFO:     Epoch: 77
2022-11-18 01:37:48,604 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7982060103253885, 'Total loss': 0.7982060103253885} | train loss {'Reaction outcome loss': 0.822938956046591, 'Total loss': 0.822938956046591}
2022-11-18 01:37:48,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:48,604 INFO:     Epoch: 78
2022-11-18 01:37:49,386 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7729666588658636, 'Total loss': 0.7729666588658636} | train loss {'Reaction outcome loss': 0.8257093793275405, 'Total loss': 0.8257093793275405}
2022-11-18 01:37:49,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:49,386 INFO:     Epoch: 79
2022-11-18 01:37:50,208 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7756294100122019, 'Total loss': 0.7756294100122019} | train loss {'Reaction outcome loss': 0.8179237666178722, 'Total loss': 0.8179237666178722}
2022-11-18 01:37:50,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:50,209 INFO:     Epoch: 80
2022-11-18 01:37:50,979 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7840308560566469, 'Total loss': 0.7840308560566469} | train loss {'Reaction outcome loss': 0.8200114797572701, 'Total loss': 0.8200114797572701}
2022-11-18 01:37:50,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:50,979 INFO:     Epoch: 81
2022-11-18 01:37:51,771 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7817738868973472, 'Total loss': 0.7817738868973472} | train loss {'Reaction outcome loss': 0.8168660070214953, 'Total loss': 0.8168660070214953}
2022-11-18 01:37:51,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:51,772 INFO:     Epoch: 82
2022-11-18 01:37:52,569 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7760598883032799, 'Total loss': 0.7760598883032799} | train loss {'Reaction outcome loss': 0.8237019189766475, 'Total loss': 0.8237019189766475}
2022-11-18 01:37:52,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:52,569 INFO:     Epoch: 83
2022-11-18 01:37:53,375 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8020925250920382, 'Total loss': 0.8020925250920382} | train loss {'Reaction outcome loss': 0.8217898107304865, 'Total loss': 0.8217898107304865}
2022-11-18 01:37:53,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:53,375 INFO:     Epoch: 84
2022-11-18 01:37:54,136 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7626280425624414, 'Total loss': 0.7626280425624414} | train loss {'Reaction outcome loss': 0.8211082412272084, 'Total loss': 0.8211082412272084}
2022-11-18 01:37:54,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:54,136 INFO:     Epoch: 85
2022-11-18 01:37:54,896 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7780934545126829, 'Total loss': 0.7780934545126829} | train loss {'Reaction outcome loss': 0.8223255151388597, 'Total loss': 0.8223255151388597}
2022-11-18 01:37:54,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:54,896 INFO:     Epoch: 86
2022-11-18 01:37:55,697 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7657157338478349, 'Total loss': 0.7657157338478349} | train loss {'Reaction outcome loss': 0.8206745172033505, 'Total loss': 0.8206745172033505}
2022-11-18 01:37:55,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:55,699 INFO:     Epoch: 87
2022-11-18 01:37:56,485 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7702895565466448, 'Total loss': 0.7702895565466448} | train loss {'Reaction outcome loss': 0.8231352919218492, 'Total loss': 0.8231352919218492}
2022-11-18 01:37:56,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:56,485 INFO:     Epoch: 88
2022-11-18 01:37:57,292 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7846500751647082, 'Total loss': 0.7846500751647082} | train loss {'Reaction outcome loss': 0.8234814940666666, 'Total loss': 0.8234814940666666}
2022-11-18 01:37:57,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:57,293 INFO:     Epoch: 89
2022-11-18 01:37:58,172 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7871560650792989, 'Total loss': 0.7871560650792989} | train loss {'Reaction outcome loss': 0.8242506128184649, 'Total loss': 0.8242506128184649}
2022-11-18 01:37:58,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:58,172 INFO:     Epoch: 90
2022-11-18 01:37:59,056 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7816006155176596, 'Total loss': 0.7816006155176596} | train loss {'Reaction outcome loss': 0.8202707105753373, 'Total loss': 0.8202707105753373}
2022-11-18 01:37:59,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:59,056 INFO:     Epoch: 91
2022-11-18 01:37:59,870 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7633119130676443, 'Total loss': 0.7633119130676443} | train loss {'Reaction outcome loss': 0.8218082694374785, 'Total loss': 0.8218082694374785}
2022-11-18 01:37:59,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:37:59,871 INFO:     Epoch: 92
2022-11-18 01:38:00,705 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7584832209077749, 'Total loss': 0.7584832209077749} | train loss {'Reaction outcome loss': 0.8224366718409013, 'Total loss': 0.8224366718409013}
2022-11-18 01:38:00,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:00,705 INFO:     Epoch: 93
2022-11-18 01:38:01,537 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.781451901928945, 'Total loss': 0.781451901928945} | train loss {'Reaction outcome loss': 0.813416987657547, 'Total loss': 0.813416987657547}
2022-11-18 01:38:01,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:01,538 INFO:     Epoch: 94
2022-11-18 01:38:02,324 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7804671698673205, 'Total loss': 0.7804671698673205} | train loss {'Reaction outcome loss': 0.8206274120175109, 'Total loss': 0.8206274120175109}
2022-11-18 01:38:02,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:02,325 INFO:     Epoch: 95
2022-11-18 01:38:03,125 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7827161259271882, 'Total loss': 0.7827161259271882} | train loss {'Reaction outcome loss': 0.8173978750803033, 'Total loss': 0.8173978750803033}
2022-11-18 01:38:03,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:03,125 INFO:     Epoch: 96
2022-11-18 01:38:03,896 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7533131878484379, 'Total loss': 0.7533131878484379} | train loss {'Reaction outcome loss': 0.8222993178027017, 'Total loss': 0.8222993178027017}
2022-11-18 01:38:03,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:03,896 INFO:     Epoch: 97
2022-11-18 01:38:04,691 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7837932001460682, 'Total loss': 0.7837932001460682} | train loss {'Reaction outcome loss': 0.8224167446700894, 'Total loss': 0.8224167446700894}
2022-11-18 01:38:04,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:04,691 INFO:     Epoch: 98
2022-11-18 01:38:05,495 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7744214284149084, 'Total loss': 0.7744214284149084} | train loss {'Reaction outcome loss': 0.8232152583647747, 'Total loss': 0.8232152583647747}
2022-11-18 01:38:05,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:05,495 INFO:     Epoch: 99
2022-11-18 01:38:06,291 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7656242386861281, 'Total loss': 0.7656242386861281} | train loss {'Reaction outcome loss': 0.8227011516386149, 'Total loss': 0.8227011516386149}
2022-11-18 01:38:06,291 INFO:     Best model found after epoch 46 of 100.
2022-11-18 01:38:06,291 INFO:   Done with stage: TRAINING
2022-11-18 01:38:06,292 INFO:   Starting stage: EVALUATION
2022-11-18 01:38:06,422 INFO:   Done with stage: EVALUATION
2022-11-18 01:38:06,423 INFO:   Leaving out SEQ value Fold_3
2022-11-18 01:38:06,436 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-18 01:38:06,436 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:38:07,098 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:38:07,098 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:38:07,174 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:38:07,174 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:38:07,174 INFO:     No hyperparam tuning for this model
2022-11-18 01:38:07,174 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:38:07,174 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:38:07,175 INFO:     None feature selector for col prot
2022-11-18 01:38:07,176 INFO:     None feature selector for col prot
2022-11-18 01:38:07,176 INFO:     None feature selector for col prot
2022-11-18 01:38:07,176 INFO:     None feature selector for col chem
2022-11-18 01:38:07,177 INFO:     None feature selector for col chem
2022-11-18 01:38:07,177 INFO:     None feature selector for col chem
2022-11-18 01:38:07,177 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:38:07,177 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:38:07,179 INFO:     Number of params in model 168571
2022-11-18 01:38:07,184 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:38:07,184 INFO:   Starting stage: TRAINING
2022-11-18 01:38:07,243 INFO:     Val loss before train {'Reaction outcome loss': 0.9969325121058974, 'Total loss': 0.9969325121058974}
2022-11-18 01:38:07,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:07,243 INFO:     Epoch: 0
2022-11-18 01:38:08,023 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8528984313787416, 'Total loss': 0.8528984313787416} | train loss {'Reaction outcome loss': 0.8936443408248854, 'Total loss': 0.8936443408248854}
2022-11-18 01:38:08,023 INFO:     Found new best model at epoch 0
2022-11-18 01:38:08,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:08,024 INFO:     Epoch: 1
2022-11-18 01:38:08,843 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8478178312612135, 'Total loss': 0.8478178312612135} | train loss {'Reaction outcome loss': 0.8648757403258418, 'Total loss': 0.8648757403258418}
2022-11-18 01:38:08,843 INFO:     Found new best model at epoch 1
2022-11-18 01:38:08,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:08,843 INFO:     Epoch: 2
2022-11-18 01:38:09,626 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8404710050239119, 'Total loss': 0.8404710050239119} | train loss {'Reaction outcome loss': 0.8561204097798614, 'Total loss': 0.8561204097798614}
2022-11-18 01:38:09,626 INFO:     Found new best model at epoch 2
2022-11-18 01:38:09,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:09,627 INFO:     Epoch: 3
2022-11-18 01:38:10,427 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8570360707682233, 'Total loss': 0.8570360707682233} | train loss {'Reaction outcome loss': 0.8521398026190821, 'Total loss': 0.8521398026190821}
2022-11-18 01:38:10,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:10,428 INFO:     Epoch: 4
2022-11-18 01:38:11,253 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8335866664731225, 'Total loss': 0.8335866664731225} | train loss {'Reaction outcome loss': 0.8502594673487006, 'Total loss': 0.8502594673487006}
2022-11-18 01:38:11,253 INFO:     Found new best model at epoch 4
2022-11-18 01:38:11,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:11,254 INFO:     Epoch: 5
2022-11-18 01:38:12,060 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8739114999771118, 'Total loss': 0.8739114999771118} | train loss {'Reaction outcome loss': 0.8470551135842918, 'Total loss': 0.8470551135842918}
2022-11-18 01:38:12,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:12,062 INFO:     Epoch: 6
2022-11-18 01:38:12,844 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8294891146726386, 'Total loss': 0.8294891146726386} | train loss {'Reaction outcome loss': 0.8464304906178693, 'Total loss': 0.8464304906178693}
2022-11-18 01:38:12,844 INFO:     Found new best model at epoch 6
2022-11-18 01:38:12,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:12,845 INFO:     Epoch: 7
2022-11-18 01:38:13,665 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8235129949658416, 'Total loss': 0.8235129949658416} | train loss {'Reaction outcome loss': 0.8389193651373269, 'Total loss': 0.8389193651373269}
2022-11-18 01:38:13,666 INFO:     Found new best model at epoch 7
2022-11-18 01:38:13,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:13,666 INFO:     Epoch: 8
2022-11-18 01:38:14,473 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8166803371074588, 'Total loss': 0.8166803371074588} | train loss {'Reaction outcome loss': 0.840590202783952, 'Total loss': 0.840590202783952}
2022-11-18 01:38:14,473 INFO:     Found new best model at epoch 8
2022-11-18 01:38:14,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:14,474 INFO:     Epoch: 9
2022-11-18 01:38:15,267 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8423708566399508, 'Total loss': 0.8423708566399508} | train loss {'Reaction outcome loss': 0.8402623909174419, 'Total loss': 0.8402623909174419}
2022-11-18 01:38:15,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:15,267 INFO:     Epoch: 10
2022-11-18 01:38:16,050 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8182111715161523, 'Total loss': 0.8182111715161523} | train loss {'Reaction outcome loss': 0.8394272483763148, 'Total loss': 0.8394272483763148}
2022-11-18 01:38:16,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:16,051 INFO:     Epoch: 11
2022-11-18 01:38:16,832 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8185387835946194, 'Total loss': 0.8185387835946194} | train loss {'Reaction outcome loss': 0.8362437820092576, 'Total loss': 0.8362437820092576}
2022-11-18 01:38:16,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:16,832 INFO:     Epoch: 12
2022-11-18 01:38:17,637 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.813453618870225, 'Total loss': 0.813453618870225} | train loss {'Reaction outcome loss': 0.8332974171785058, 'Total loss': 0.8332974171785058}
2022-11-18 01:38:17,637 INFO:     Found new best model at epoch 12
2022-11-18 01:38:17,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:17,638 INFO:     Epoch: 13
2022-11-18 01:38:18,453 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8262192385141239, 'Total loss': 0.8262192385141239} | train loss {'Reaction outcome loss': 0.8332772489453926, 'Total loss': 0.8332772489453926}
2022-11-18 01:38:18,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:18,453 INFO:     Epoch: 14
2022-11-18 01:38:19,280 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.819010756736578, 'Total loss': 0.819010756736578} | train loss {'Reaction outcome loss': 0.8350413696932011, 'Total loss': 0.8350413696932011}
2022-11-18 01:38:19,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:19,281 INFO:     Epoch: 15
2022-11-18 01:38:20,089 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8203368436458499, 'Total loss': 0.8203368436458499} | train loss {'Reaction outcome loss': 0.8330591898716864, 'Total loss': 0.8330591898716864}
2022-11-18 01:38:20,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:20,089 INFO:     Epoch: 16
2022-11-18 01:38:20,899 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8172257951525754, 'Total loss': 0.8172257951525754} | train loss {'Reaction outcome loss': 0.8277365104829679, 'Total loss': 0.8277365104829679}
2022-11-18 01:38:20,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:20,899 INFO:     Epoch: 17
2022-11-18 01:38:21,738 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8143532816753831, 'Total loss': 0.8143532816753831} | train loss {'Reaction outcome loss': 0.8308540007374325, 'Total loss': 0.8308540007374325}
2022-11-18 01:38:21,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:21,738 INFO:     Epoch: 18
2022-11-18 01:38:22,543 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8288423862568167, 'Total loss': 0.8288423862568167} | train loss {'Reaction outcome loss': 0.8302465117857104, 'Total loss': 0.8302465117857104}
2022-11-18 01:38:22,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:22,544 INFO:     Epoch: 19
2022-11-18 01:38:23,342 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8098204385402591, 'Total loss': 0.8098204385402591} | train loss {'Reaction outcome loss': 0.8343173035832702, 'Total loss': 0.8343173035832702}
2022-11-18 01:38:23,344 INFO:     Found new best model at epoch 19
2022-11-18 01:38:23,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:23,345 INFO:     Epoch: 20
2022-11-18 01:38:24,188 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8351393674695214, 'Total loss': 0.8351393674695214} | train loss {'Reaction outcome loss': 0.8277312215478694, 'Total loss': 0.8277312215478694}
2022-11-18 01:38:24,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:24,189 INFO:     Epoch: 21
2022-11-18 01:38:24,985 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8265643383181372, 'Total loss': 0.8265643383181372} | train loss {'Reaction outcome loss': 0.8345527739309874, 'Total loss': 0.8345527739309874}
2022-11-18 01:38:24,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:24,986 INFO:     Epoch: 22
2022-11-18 01:38:25,774 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.808937820584275, 'Total loss': 0.808937820584275} | train loss {'Reaction outcome loss': 0.8280197513885186, 'Total loss': 0.8280197513885186}
2022-11-18 01:38:25,774 INFO:     Found new best model at epoch 22
2022-11-18 01:38:25,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:25,775 INFO:     Epoch: 23
2022-11-18 01:38:26,559 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8207181380238644, 'Total loss': 0.8207181380238644} | train loss {'Reaction outcome loss': 0.8289079278951785, 'Total loss': 0.8289079278951785}
2022-11-18 01:38:26,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:26,559 INFO:     Epoch: 24
2022-11-18 01:38:27,309 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8143673525300137, 'Total loss': 0.8143673525300137} | train loss {'Reaction outcome loss': 0.8303098073992573, 'Total loss': 0.8303098073992573}
2022-11-18 01:38:27,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:27,309 INFO:     Epoch: 25
2022-11-18 01:38:28,096 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8126162006411441, 'Total loss': 0.8126162006411441} | train loss {'Reaction outcome loss': 0.8256891813190257, 'Total loss': 0.8256891813190257}
2022-11-18 01:38:28,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:28,096 INFO:     Epoch: 26
2022-11-18 01:38:28,868 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8086509635282118, 'Total loss': 0.8086509635282118} | train loss {'Reaction outcome loss': 0.8284515825207116, 'Total loss': 0.8284515825207116}
2022-11-18 01:38:28,869 INFO:     Found new best model at epoch 26
2022-11-18 01:38:28,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:28,869 INFO:     Epoch: 27
2022-11-18 01:38:29,687 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.817370687806329, 'Total loss': 0.817370687806329} | train loss {'Reaction outcome loss': 0.8243743988578437, 'Total loss': 0.8243743988578437}
2022-11-18 01:38:29,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:29,688 INFO:     Epoch: 28
2022-11-18 01:38:30,491 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8158276739508606, 'Total loss': 0.8158276739508606} | train loss {'Reaction outcome loss': 0.8273103515632817, 'Total loss': 0.8273103515632817}
2022-11-18 01:38:30,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:30,491 INFO:     Epoch: 29
2022-11-18 01:38:31,278 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.825434195440869, 'Total loss': 0.825434195440869} | train loss {'Reaction outcome loss': 0.8207871922459758, 'Total loss': 0.8207871922459758}
2022-11-18 01:38:31,278 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:31,278 INFO:     Epoch: 30
2022-11-18 01:38:32,072 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8383507583030435, 'Total loss': 0.8383507583030435} | train loss {'Reaction outcome loss': 0.8247572455982692, 'Total loss': 0.8247572455982692}
2022-11-18 01:38:32,072 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:32,072 INFO:     Epoch: 31
2022-11-18 01:38:32,864 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8197189153626908, 'Total loss': 0.8197189153626908} | train loss {'Reaction outcome loss': 0.827673426661335, 'Total loss': 0.827673426661335}
2022-11-18 01:38:32,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:32,865 INFO:     Epoch: 32
2022-11-18 01:38:33,695 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8075661326563636, 'Total loss': 0.8075661326563636} | train loss {'Reaction outcome loss': 0.824883623201339, 'Total loss': 0.824883623201339}
2022-11-18 01:38:33,695 INFO:     Found new best model at epoch 32
2022-11-18 01:38:33,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:33,696 INFO:     Epoch: 33
2022-11-18 01:38:34,472 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8117008632005647, 'Total loss': 0.8117008632005647} | train loss {'Reaction outcome loss': 0.8249296800034945, 'Total loss': 0.8249296800034945}
2022-11-18 01:38:34,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:34,473 INFO:     Epoch: 34
2022-11-18 01:38:35,270 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8104243742865186, 'Total loss': 0.8104243742865186} | train loss {'Reaction outcome loss': 0.8293087549629758, 'Total loss': 0.8293087549629758}
2022-11-18 01:38:35,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:35,272 INFO:     Epoch: 35
2022-11-18 01:38:36,046 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8104575567467268, 'Total loss': 0.8104575567467268} | train loss {'Reaction outcome loss': 0.8318897326950168, 'Total loss': 0.8318897326950168}
2022-11-18 01:38:36,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:36,047 INFO:     Epoch: 36
2022-11-18 01:38:36,852 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8159464271955712, 'Total loss': 0.8159464271955712} | train loss {'Reaction outcome loss': 0.8263619014474212, 'Total loss': 0.8263619014474212}
2022-11-18 01:38:36,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:36,853 INFO:     Epoch: 37
2022-11-18 01:38:37,630 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8006614703078603, 'Total loss': 0.8006614703078603} | train loss {'Reaction outcome loss': 0.8262629963335444, 'Total loss': 0.8262629963335444}
2022-11-18 01:38:37,630 INFO:     Found new best model at epoch 37
2022-11-18 01:38:37,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:37,630 INFO:     Epoch: 38
2022-11-18 01:38:38,412 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8194543435130008, 'Total loss': 0.8194543435130008} | train loss {'Reaction outcome loss': 0.8229692490374456, 'Total loss': 0.8229692490374456}
2022-11-18 01:38:38,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:38,412 INFO:     Epoch: 39
2022-11-18 01:38:39,176 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8073913746101912, 'Total loss': 0.8073913746101912} | train loss {'Reaction outcome loss': 0.8212653513936723, 'Total loss': 0.8212653513936723}
2022-11-18 01:38:39,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:39,177 INFO:     Epoch: 40
2022-11-18 01:38:39,959 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8299532789130544, 'Total loss': 0.8299532789130544} | train loss {'Reaction outcome loss': 0.8247399432737319, 'Total loss': 0.8247399432737319}
2022-11-18 01:38:39,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:39,960 INFO:     Epoch: 41
2022-11-18 01:38:40,750 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.814797064592672, 'Total loss': 0.814797064592672} | train loss {'Reaction outcome loss': 0.8210959374660352, 'Total loss': 0.8210959374660352}
2022-11-18 01:38:40,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:40,752 INFO:     Epoch: 42
2022-11-18 01:38:41,553 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8324643519035605, 'Total loss': 0.8324643519035605} | train loss {'Reaction outcome loss': 0.8219857367335773, 'Total loss': 0.8219857367335773}
2022-11-18 01:38:41,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:41,553 INFO:     Epoch: 43
2022-11-18 01:38:42,351 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8144667716913445, 'Total loss': 0.8144667716913445} | train loss {'Reaction outcome loss': 0.8240308762818086, 'Total loss': 0.8240308762818086}
2022-11-18 01:38:42,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:42,352 INFO:     Epoch: 44
2022-11-18 01:38:43,116 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8204328015793202, 'Total loss': 0.8204328015793202} | train loss {'Reaction outcome loss': 0.8265801287088238, 'Total loss': 0.8265801287088238}
2022-11-18 01:38:43,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:43,116 INFO:     Epoch: 45
2022-11-18 01:38:43,886 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.813777066940485, 'Total loss': 0.813777066940485} | train loss {'Reaction outcome loss': 0.8243074436656764, 'Total loss': 0.8243074436656764}
2022-11-18 01:38:43,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:43,886 INFO:     Epoch: 46
2022-11-18 01:38:44,674 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8200359372205512, 'Total loss': 0.8200359372205512} | train loss {'Reaction outcome loss': 0.8212135519649162, 'Total loss': 0.8212135519649162}
2022-11-18 01:38:44,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:44,674 INFO:     Epoch: 47
2022-11-18 01:38:45,499 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8115776021813237, 'Total loss': 0.8115776021813237} | train loss {'Reaction outcome loss': 0.8243239247163788, 'Total loss': 0.8243239247163788}
2022-11-18 01:38:45,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:45,500 INFO:     Epoch: 48
2022-11-18 01:38:46,306 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8168393484381742, 'Total loss': 0.8168393484381742} | train loss {'Reaction outcome loss': 0.8260277589080763, 'Total loss': 0.8260277589080763}
2022-11-18 01:38:46,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:46,308 INFO:     Epoch: 49
2022-11-18 01:38:47,121 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8396705416745918, 'Total loss': 0.8396705416745918} | train loss {'Reaction outcome loss': 0.8252960998015325, 'Total loss': 0.8252960998015325}
2022-11-18 01:38:47,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:47,121 INFO:     Epoch: 50
2022-11-18 01:38:47,872 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8111717368281165, 'Total loss': 0.8111717368281165} | train loss {'Reaction outcome loss': 0.8264178443150442, 'Total loss': 0.8264178443150442}
2022-11-18 01:38:47,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:47,872 INFO:     Epoch: 51
2022-11-18 01:38:48,669 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8490890541742014, 'Total loss': 0.8490890541742014} | train loss {'Reaction outcome loss': 0.8207497448950517, 'Total loss': 0.8207497448950517}
2022-11-18 01:38:48,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:48,670 INFO:     Epoch: 52
2022-11-18 01:38:49,516 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8622063980546109, 'Total loss': 0.8622063980546109} | train loss {'Reaction outcome loss': 0.8257632727017168, 'Total loss': 0.8257632727017168}
2022-11-18 01:38:49,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:49,516 INFO:     Epoch: 53
2022-11-18 01:38:50,309 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8294435455355533, 'Total loss': 0.8294435455355533} | train loss {'Reaction outcome loss': 0.8247526923163992, 'Total loss': 0.8247526923163992}
2022-11-18 01:38:50,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:50,309 INFO:     Epoch: 54
2022-11-18 01:38:51,127 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8046785918779151, 'Total loss': 0.8046785918779151} | train loss {'Reaction outcome loss': 0.8282090656337191, 'Total loss': 0.8282090656337191}
2022-11-18 01:38:51,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:51,127 INFO:     Epoch: 55
2022-11-18 01:38:51,896 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8087265103362328, 'Total loss': 0.8087265103362328} | train loss {'Reaction outcome loss': 0.8275547792188457, 'Total loss': 0.8275547792188457}
2022-11-18 01:38:51,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:51,899 INFO:     Epoch: 56
2022-11-18 01:38:52,722 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8208770703437717, 'Total loss': 0.8208770703437717} | train loss {'Reaction outcome loss': 0.8193828312099957, 'Total loss': 0.8193828312099957}
2022-11-18 01:38:52,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:52,723 INFO:     Epoch: 57
2022-11-18 01:38:53,523 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.817838239115338, 'Total loss': 0.817838239115338} | train loss {'Reaction outcome loss': 0.8267702824268185, 'Total loss': 0.8267702824268185}
2022-11-18 01:38:53,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:53,523 INFO:     Epoch: 58
2022-11-18 01:38:54,339 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8040273293506267, 'Total loss': 0.8040273293506267} | train loss {'Reaction outcome loss': 0.8254412608068498, 'Total loss': 0.8254412608068498}
2022-11-18 01:38:54,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:54,339 INFO:     Epoch: 59
2022-11-18 01:38:55,174 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8115792815075364, 'Total loss': 0.8115792815075364} | train loss {'Reaction outcome loss': 0.8201093244992319, 'Total loss': 0.8201093244992319}
2022-11-18 01:38:55,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:55,174 INFO:     Epoch: 60
2022-11-18 01:38:55,951 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8132850763409637, 'Total loss': 0.8132850763409637} | train loss {'Reaction outcome loss': 0.8231153915651509, 'Total loss': 0.8231153915651509}
2022-11-18 01:38:55,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:55,951 INFO:     Epoch: 61
2022-11-18 01:38:56,741 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8053768436576045, 'Total loss': 0.8053768436576045} | train loss {'Reaction outcome loss': 0.8276267747898571, 'Total loss': 0.8276267747898571}
2022-11-18 01:38:56,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:56,741 INFO:     Epoch: 62
2022-11-18 01:38:57,566 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8033894245014634, 'Total loss': 0.8033894245014634} | train loss {'Reaction outcome loss': 0.8246475240734757, 'Total loss': 0.8246475240734757}
2022-11-18 01:38:57,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:57,567 INFO:     Epoch: 63
2022-11-18 01:38:58,382 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8224895610365757, 'Total loss': 0.8224895610365757} | train loss {'Reaction outcome loss': 0.8209547503072707, 'Total loss': 0.8209547503072707}
2022-11-18 01:38:58,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:58,382 INFO:     Epoch: 64
2022-11-18 01:38:59,157 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8073752113552981, 'Total loss': 0.8073752113552981} | train loss {'Reaction outcome loss': 0.8242827848088546, 'Total loss': 0.8242827848088546}
2022-11-18 01:38:59,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:59,158 INFO:     Epoch: 65
2022-11-18 01:38:59,975 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8089892614719479, 'Total loss': 0.8089892614719479} | train loss {'Reaction outcome loss': 0.8213912048300759, 'Total loss': 0.8213912048300759}
2022-11-18 01:38:59,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:38:59,976 INFO:     Epoch: 66
2022-11-18 01:39:00,757 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8420790558637574, 'Total loss': 0.8420790558637574} | train loss {'Reaction outcome loss': 0.8208630168047107, 'Total loss': 0.8208630168047107}
2022-11-18 01:39:00,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:00,757 INFO:     Epoch: 67
2022-11-18 01:39:01,535 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.805949657462364, 'Total loss': 0.805949657462364} | train loss {'Reaction outcome loss': 0.8250945824824396, 'Total loss': 0.8250945824824396}
2022-11-18 01:39:01,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:01,536 INFO:     Epoch: 68
2022-11-18 01:39:02,418 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7989098207895146, 'Total loss': 0.7989098207895146} | train loss {'Reaction outcome loss': 0.8255242636946382, 'Total loss': 0.8255242636946382}
2022-11-18 01:39:02,418 INFO:     Found new best model at epoch 68
2022-11-18 01:39:02,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:02,419 INFO:     Epoch: 69
2022-11-18 01:39:03,258 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8246633687684702, 'Total loss': 0.8246633687684702} | train loss {'Reaction outcome loss': 0.8232136196533187, 'Total loss': 0.8232136196533187}
2022-11-18 01:39:03,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:03,259 INFO:     Epoch: 70
2022-11-18 01:39:04,058 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8208334882592045, 'Total loss': 0.8208334882592045} | train loss {'Reaction outcome loss': 0.823247180854688, 'Total loss': 0.823247180854688}
2022-11-18 01:39:04,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:04,058 INFO:     Epoch: 71
2022-11-18 01:39:04,834 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8137661287950915, 'Total loss': 0.8137661287950915} | train loss {'Reaction outcome loss': 0.8213950495739453, 'Total loss': 0.8213950495739453}
2022-11-18 01:39:04,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:04,834 INFO:     Epoch: 72
2022-11-18 01:39:05,632 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8066489363825599, 'Total loss': 0.8066489363825599} | train loss {'Reaction outcome loss': 0.8209204157112074, 'Total loss': 0.8209204157112074}
2022-11-18 01:39:05,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:05,633 INFO:     Epoch: 73
2022-11-18 01:39:06,419 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7996339985104495, 'Total loss': 0.7996339985104495} | train loss {'Reaction outcome loss': 0.820472571327061, 'Total loss': 0.820472571327061}
2022-11-18 01:39:06,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:06,419 INFO:     Epoch: 74
2022-11-18 01:39:07,224 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8123963017796361, 'Total loss': 0.8123963017796361} | train loss {'Reaction outcome loss': 0.8277239925304397, 'Total loss': 0.8277239925304397}
2022-11-18 01:39:07,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:07,224 INFO:     Epoch: 75
2022-11-18 01:39:07,983 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8009763512500497, 'Total loss': 0.8009763512500497} | train loss {'Reaction outcome loss': 0.8190075282434948, 'Total loss': 0.8190075282434948}
2022-11-18 01:39:07,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:07,984 INFO:     Epoch: 76
2022-11-18 01:39:08,777 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8062005957891775, 'Total loss': 0.8062005957891775} | train loss {'Reaction outcome loss': 0.8203284781975825, 'Total loss': 0.8203284781975825}
2022-11-18 01:39:08,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:08,778 INFO:     Epoch: 77
2022-11-18 01:39:09,563 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8084026270134504, 'Total loss': 0.8084026270134504} | train loss {'Reaction outcome loss': 0.822680618552888, 'Total loss': 0.822680618552888}
2022-11-18 01:39:09,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:09,563 INFO:     Epoch: 78
2022-11-18 01:39:10,393 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8093461304209953, 'Total loss': 0.8093461304209953} | train loss {'Reaction outcome loss': 0.8287249420021401, 'Total loss': 0.8287249420021401}
2022-11-18 01:39:10,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:10,393 INFO:     Epoch: 79
2022-11-18 01:39:11,180 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8675899533338325, 'Total loss': 0.8675899533338325} | train loss {'Reaction outcome loss': 0.8224254130828575, 'Total loss': 0.8224254130828575}
2022-11-18 01:39:11,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:11,180 INFO:     Epoch: 80
2022-11-18 01:39:11,987 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8089325303255126, 'Total loss': 0.8089325303255126} | train loss {'Reaction outcome loss': 0.8194674037274767, 'Total loss': 0.8194674037274767}
2022-11-18 01:39:11,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:11,987 INFO:     Epoch: 81
2022-11-18 01:39:12,800 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8312824631846228, 'Total loss': 0.8312824631846228} | train loss {'Reaction outcome loss': 0.8236290816156591, 'Total loss': 0.8236290816156591}
2022-11-18 01:39:12,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:12,801 INFO:     Epoch: 82
2022-11-18 01:39:13,601 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7980959429297336, 'Total loss': 0.7980959429297336} | train loss {'Reaction outcome loss': 0.8202434989516852, 'Total loss': 0.8202434989516852}
2022-11-18 01:39:13,601 INFO:     Found new best model at epoch 82
2022-11-18 01:39:13,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:13,602 INFO:     Epoch: 83
2022-11-18 01:39:14,448 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8213413988434991, 'Total loss': 0.8213413988434991} | train loss {'Reaction outcome loss': 0.8235770544556321, 'Total loss': 0.8235770544556321}
2022-11-18 01:39:14,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:14,450 INFO:     Epoch: 84
2022-11-18 01:39:15,254 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8105020197324975, 'Total loss': 0.8105020197324975} | train loss {'Reaction outcome loss': 0.8218146508834401, 'Total loss': 0.8218146508834401}
2022-11-18 01:39:15,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:15,254 INFO:     Epoch: 85
2022-11-18 01:39:16,080 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8353422048480011, 'Total loss': 0.8353422048480011} | train loss {'Reaction outcome loss': 0.8240290501567183, 'Total loss': 0.8240290501567183}
2022-11-18 01:39:16,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:16,080 INFO:     Epoch: 86
2022-11-18 01:39:16,871 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8091291826824809, 'Total loss': 0.8091291826824809} | train loss {'Reaction outcome loss': 0.8237472336556091, 'Total loss': 0.8237472336556091}
2022-11-18 01:39:16,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:16,872 INFO:     Epoch: 87
2022-11-18 01:39:17,663 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8308321681133536, 'Total loss': 0.8308321681133536} | train loss {'Reaction outcome loss': 0.8260290077963813, 'Total loss': 0.8260290077963813}
2022-11-18 01:39:17,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:17,663 INFO:     Epoch: 88
2022-11-18 01:39:18,475 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8051360311896302, 'Total loss': 0.8051360311896302} | train loss {'Reaction outcome loss': 0.8187012994875673, 'Total loss': 0.8187012994875673}
2022-11-18 01:39:18,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:18,475 INFO:     Epoch: 89
2022-11-18 01:39:19,267 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8107104862845221, 'Total loss': 0.8107104862845221} | train loss {'Reaction outcome loss': 0.8273415630225276, 'Total loss': 0.8273415630225276}
2022-11-18 01:39:19,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:19,268 INFO:     Epoch: 90
2022-11-18 01:39:20,060 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8131502866744995, 'Total loss': 0.8131502866744995} | train loss {'Reaction outcome loss': 0.8258639295570186, 'Total loss': 0.8258639295570186}
2022-11-18 01:39:20,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:20,061 INFO:     Epoch: 91
2022-11-18 01:39:20,877 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8047022701695908, 'Total loss': 0.8047022701695908} | train loss {'Reaction outcome loss': 0.8191381058976298, 'Total loss': 0.8191381058976298}
2022-11-18 01:39:20,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:20,877 INFO:     Epoch: 92
2022-11-18 01:39:21,654 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8234225504620131, 'Total loss': 0.8234225504620131} | train loss {'Reaction outcome loss': 0.822809099418218, 'Total loss': 0.822809099418218}
2022-11-18 01:39:21,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:21,654 INFO:     Epoch: 93
2022-11-18 01:39:22,426 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8195230337076409, 'Total loss': 0.8195230337076409} | train loss {'Reaction outcome loss': 0.8246965280077496, 'Total loss': 0.8246965280077496}
2022-11-18 01:39:22,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:22,426 INFO:     Epoch: 94
2022-11-18 01:39:23,251 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8248169803342154, 'Total loss': 0.8248169803342154} | train loss {'Reaction outcome loss': 0.8176825338455497, 'Total loss': 0.8176825338455497}
2022-11-18 01:39:23,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:23,251 INFO:     Epoch: 95
2022-11-18 01:39:24,059 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8005731584027757, 'Total loss': 0.8005731584027757} | train loss {'Reaction outcome loss': 0.8226970528237155, 'Total loss': 0.8226970528237155}
2022-11-18 01:39:24,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:24,059 INFO:     Epoch: 96
2022-11-18 01:39:24,856 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8110670364180277, 'Total loss': 0.8110670364180277} | train loss {'Reaction outcome loss': 0.8264065974804221, 'Total loss': 0.8264065974804221}
2022-11-18 01:39:24,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:24,857 INFO:     Epoch: 97
2022-11-18 01:39:25,667 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8045424715031025, 'Total loss': 0.8045424715031025} | train loss {'Reaction outcome loss': 0.8221595723365174, 'Total loss': 0.8221595723365174}
2022-11-18 01:39:25,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:25,668 INFO:     Epoch: 98
2022-11-18 01:39:26,505 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8038930151351663, 'Total loss': 0.8038930151351663} | train loss {'Reaction outcome loss': 0.8244828917696828, 'Total loss': 0.8244828917696828}
2022-11-18 01:39:26,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:26,505 INFO:     Epoch: 99
2022-11-18 01:39:27,302 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8217296101326166, 'Total loss': 0.8217296101326166} | train loss {'Reaction outcome loss': 0.8178352825954313, 'Total loss': 0.8178352825954313}
2022-11-18 01:39:27,302 INFO:     Best model found after epoch 83 of 100.
2022-11-18 01:39:27,302 INFO:   Done with stage: TRAINING
2022-11-18 01:39:27,302 INFO:   Starting stage: EVALUATION
2022-11-18 01:39:27,440 INFO:   Done with stage: EVALUATION
2022-11-18 01:39:27,440 INFO:   Leaving out SEQ value Fold_4
2022-11-18 01:39:27,453 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 01:39:27,453 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:39:28,124 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:39:28,124 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:39:28,194 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:39:28,194 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:39:28,194 INFO:     No hyperparam tuning for this model
2022-11-18 01:39:28,194 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:39:28,194 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:39:28,195 INFO:     None feature selector for col prot
2022-11-18 01:39:28,195 INFO:     None feature selector for col prot
2022-11-18 01:39:28,195 INFO:     None feature selector for col prot
2022-11-18 01:39:28,196 INFO:     None feature selector for col chem
2022-11-18 01:39:28,196 INFO:     None feature selector for col chem
2022-11-18 01:39:28,196 INFO:     None feature selector for col chem
2022-11-18 01:39:28,196 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:39:28,196 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:39:28,198 INFO:     Number of params in model 168571
2022-11-18 01:39:28,201 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:39:28,201 INFO:   Starting stage: TRAINING
2022-11-18 01:39:28,259 INFO:     Val loss before train {'Reaction outcome loss': 1.025811605155468, 'Total loss': 1.025811605155468}
2022-11-18 01:39:28,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:28,259 INFO:     Epoch: 0
2022-11-18 01:39:29,060 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8710763061588461, 'Total loss': 0.8710763061588461} | train loss {'Reaction outcome loss': 0.8632235321546754, 'Total loss': 0.8632235321546754}
2022-11-18 01:39:29,060 INFO:     Found new best model at epoch 0
2022-11-18 01:39:29,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:29,061 INFO:     Epoch: 1
2022-11-18 01:39:29,891 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8816917105154558, 'Total loss': 0.8816917105154558} | train loss {'Reaction outcome loss': 0.8330878971084472, 'Total loss': 0.8330878971084472}
2022-11-18 01:39:29,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:29,891 INFO:     Epoch: 2
2022-11-18 01:39:30,704 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.852047052573074, 'Total loss': 0.852047052573074} | train loss {'Reaction outcome loss': 0.8285028155772917, 'Total loss': 0.8285028155772917}
2022-11-18 01:39:30,705 INFO:     Found new best model at epoch 2
2022-11-18 01:39:30,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:30,706 INFO:     Epoch: 3
2022-11-18 01:39:31,508 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8562307493253187, 'Total loss': 0.8562307493253187} | train loss {'Reaction outcome loss': 0.8199099390016448, 'Total loss': 0.8199099390016448}
2022-11-18 01:39:31,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:31,508 INFO:     Epoch: 4
2022-11-18 01:39:32,329 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8461861224337057, 'Total loss': 0.8461861224337057} | train loss {'Reaction outcome loss': 0.8144444316144912, 'Total loss': 0.8144444316144912}
2022-11-18 01:39:32,330 INFO:     Found new best model at epoch 4
2022-11-18 01:39:32,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:32,331 INFO:     Epoch: 5
2022-11-18 01:39:33,134 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8370620303533294, 'Total loss': 0.8370620303533294} | train loss {'Reaction outcome loss': 0.815651300693712, 'Total loss': 0.815651300693712}
2022-11-18 01:39:33,134 INFO:     Found new best model at epoch 5
2022-11-18 01:39:33,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:33,135 INFO:     Epoch: 6
2022-11-18 01:39:33,931 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8585064600814473, 'Total loss': 0.8585064600814473} | train loss {'Reaction outcome loss': 0.8097604564841716, 'Total loss': 0.8097604564841716}
2022-11-18 01:39:33,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:33,931 INFO:     Epoch: 7
2022-11-18 01:39:34,741 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8486893420869653, 'Total loss': 0.8486893420869653} | train loss {'Reaction outcome loss': 0.8103467637012082, 'Total loss': 0.8103467637012082}
2022-11-18 01:39:34,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:34,741 INFO:     Epoch: 8
2022-11-18 01:39:35,519 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8384692763740366, 'Total loss': 0.8384692763740366} | train loss {'Reaction outcome loss': 0.8085091061169102, 'Total loss': 0.8085091061169102}
2022-11-18 01:39:35,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:35,519 INFO:     Epoch: 9
2022-11-18 01:39:36,324 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.834008898247372, 'Total loss': 0.834008898247372} | train loss {'Reaction outcome loss': 0.8097736477371185, 'Total loss': 0.8097736477371185}
2022-11-18 01:39:36,325 INFO:     Found new best model at epoch 9
2022-11-18 01:39:36,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:36,325 INFO:     Epoch: 10
2022-11-18 01:39:37,135 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.838277364319021, 'Total loss': 0.838277364319021} | train loss {'Reaction outcome loss': 0.8032609922510963, 'Total loss': 0.8032609922510963}
2022-11-18 01:39:37,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:37,136 INFO:     Epoch: 11
2022-11-18 01:39:37,958 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8359092609448866, 'Total loss': 0.8359092609448866} | train loss {'Reaction outcome loss': 0.806136092711841, 'Total loss': 0.806136092711841}
2022-11-18 01:39:37,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:37,958 INFO:     Epoch: 12
2022-11-18 01:39:38,753 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8398419869217005, 'Total loss': 0.8398419869217005} | train loss {'Reaction outcome loss': 0.8062999495455334, 'Total loss': 0.8062999495455334}
2022-11-18 01:39:38,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:38,753 INFO:     Epoch: 13
2022-11-18 01:39:39,541 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8507883250713348, 'Total loss': 0.8507883250713348} | train loss {'Reaction outcome loss': 0.8069407520515304, 'Total loss': 0.8069407520515304}
2022-11-18 01:39:39,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:39,541 INFO:     Epoch: 14
2022-11-18 01:39:40,344 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8459050425074317, 'Total loss': 0.8459050425074317} | train loss {'Reaction outcome loss': 0.8019855881650602, 'Total loss': 0.8019855881650602}
2022-11-18 01:39:40,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:40,344 INFO:     Epoch: 15
2022-11-18 01:39:41,166 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8368449407545003, 'Total loss': 0.8368449407545003} | train loss {'Reaction outcome loss': 0.8076082099108927, 'Total loss': 0.8076082099108927}
2022-11-18 01:39:41,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:41,166 INFO:     Epoch: 16
2022-11-18 01:39:42,004 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8540508923205462, 'Total loss': 0.8540508923205462} | train loss {'Reaction outcome loss': 0.8072360273330442, 'Total loss': 0.8072360273330442}
2022-11-18 01:39:42,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:42,005 INFO:     Epoch: 17
2022-11-18 01:39:42,746 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.856602049686692, 'Total loss': 0.856602049686692} | train loss {'Reaction outcome loss': 0.805078829728788, 'Total loss': 0.805078829728788}
2022-11-18 01:39:42,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:42,747 INFO:     Epoch: 18
2022-11-18 01:39:43,566 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8330069875175302, 'Total loss': 0.8330069875175302} | train loss {'Reaction outcome loss': 0.799316967086446, 'Total loss': 0.799316967086446}
2022-11-18 01:39:43,566 INFO:     Found new best model at epoch 18
2022-11-18 01:39:43,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:43,567 INFO:     Epoch: 19
2022-11-18 01:39:44,358 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8483929363164034, 'Total loss': 0.8483929363164034} | train loss {'Reaction outcome loss': 0.8085969690113298, 'Total loss': 0.8085969690113298}
2022-11-18 01:39:44,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:44,359 INFO:     Epoch: 20
2022-11-18 01:39:45,174 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8374088135632601, 'Total loss': 0.8374088135632601} | train loss {'Reaction outcome loss': 0.8052512355629475, 'Total loss': 0.8052512355629475}
2022-11-18 01:39:45,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:45,174 INFO:     Epoch: 21
2022-11-18 01:39:45,991 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8273289488120512, 'Total loss': 0.8273289488120512} | train loss {'Reaction outcome loss': 0.8137589220798784, 'Total loss': 0.8137589220798784}
2022-11-18 01:39:45,992 INFO:     Found new best model at epoch 21
2022-11-18 01:39:45,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:45,992 INFO:     Epoch: 22
2022-11-18 01:39:46,811 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8300537182526155, 'Total loss': 0.8300537182526155} | train loss {'Reaction outcome loss': 0.8053529439193587, 'Total loss': 0.8053529439193587}
2022-11-18 01:39:46,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:46,811 INFO:     Epoch: 23
2022-11-18 01:39:47,650 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8245738826014779, 'Total loss': 0.8245738826014779} | train loss {'Reaction outcome loss': 0.8022163749462173, 'Total loss': 0.8022163749462173}
2022-11-18 01:39:47,650 INFO:     Found new best model at epoch 23
2022-11-18 01:39:47,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:47,651 INFO:     Epoch: 24
2022-11-18 01:39:48,510 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8189915757287632, 'Total loss': 0.8189915757287632} | train loss {'Reaction outcome loss': 0.8008410028151928, 'Total loss': 0.8008410028151928}
2022-11-18 01:39:48,510 INFO:     Found new best model at epoch 24
2022-11-18 01:39:48,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:48,511 INFO:     Epoch: 25
2022-11-18 01:39:49,314 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8295766697688536, 'Total loss': 0.8295766697688536} | train loss {'Reaction outcome loss': 0.8047475019289602, 'Total loss': 0.8047475019289602}
2022-11-18 01:39:49,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:49,314 INFO:     Epoch: 26
2022-11-18 01:39:50,150 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.835012558509003, 'Total loss': 0.835012558509003} | train loss {'Reaction outcome loss': 0.8057719890869433, 'Total loss': 0.8057719890869433}
2022-11-18 01:39:50,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:50,150 INFO:     Epoch: 27
2022-11-18 01:39:50,949 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8333870429884304, 'Total loss': 0.8333870429884304} | train loss {'Reaction outcome loss': 0.8065452723493499, 'Total loss': 0.8065452723493499}
2022-11-18 01:39:50,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:50,949 INFO:     Epoch: 28
2022-11-18 01:39:51,749 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8303074132312428, 'Total loss': 0.8303074132312428} | train loss {'Reaction outcome loss': 0.8020392891860777, 'Total loss': 0.8020392891860777}
2022-11-18 01:39:51,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:51,749 INFO:     Epoch: 29
2022-11-18 01:39:52,600 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8267960873517123, 'Total loss': 0.8267960873517123} | train loss {'Reaction outcome loss': 0.8004390235629774, 'Total loss': 0.8004390235629774}
2022-11-18 01:39:52,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:52,600 INFO:     Epoch: 30
2022-11-18 01:39:53,422 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8445463505658236, 'Total loss': 0.8445463505658236} | train loss {'Reaction outcome loss': 0.7979511598185185, 'Total loss': 0.7979511598185185}
2022-11-18 01:39:53,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:53,422 INFO:     Epoch: 31
2022-11-18 01:39:54,238 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8405524736100977, 'Total loss': 0.8405524736100977} | train loss {'Reaction outcome loss': 0.8076208722927878, 'Total loss': 0.8076208722927878}
2022-11-18 01:39:54,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:54,238 INFO:     Epoch: 32
2022-11-18 01:39:55,069 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8317060788924043, 'Total loss': 0.8317060788924043} | train loss {'Reaction outcome loss': 0.8004518844667943, 'Total loss': 0.8004518844667943}
2022-11-18 01:39:55,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:55,069 INFO:     Epoch: 33
2022-11-18 01:39:55,920 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8695146604017778, 'Total loss': 0.8695146604017778} | train loss {'Reaction outcome loss': 0.795562511249896, 'Total loss': 0.795562511249896}
2022-11-18 01:39:55,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:55,920 INFO:     Epoch: 34
2022-11-18 01:39:56,726 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8302305808121507, 'Total loss': 0.8302305808121507} | train loss {'Reaction outcome loss': 0.80266616950112, 'Total loss': 0.80266616950112}
2022-11-18 01:39:56,727 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:56,727 INFO:     Epoch: 35
2022-11-18 01:39:57,522 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8466635163534771, 'Total loss': 0.8466635163534771} | train loss {'Reaction outcome loss': 0.798807424403006, 'Total loss': 0.798807424403006}
2022-11-18 01:39:57,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:57,522 INFO:     Epoch: 36
2022-11-18 01:39:58,307 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.841457029635256, 'Total loss': 0.841457029635256} | train loss {'Reaction outcome loss': 0.8018348245851455, 'Total loss': 0.8018348245851455}
2022-11-18 01:39:58,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:58,307 INFO:     Epoch: 37
2022-11-18 01:39:59,086 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8364932394840501, 'Total loss': 0.8364932394840501} | train loss {'Reaction outcome loss': 0.8022770153418664, 'Total loss': 0.8022770153418664}
2022-11-18 01:39:59,086 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:59,087 INFO:     Epoch: 38
2022-11-18 01:39:59,887 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8308786289258436, 'Total loss': 0.8308786289258436} | train loss {'Reaction outcome loss': 0.8010447761945186, 'Total loss': 0.8010447761945186}
2022-11-18 01:39:59,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:39:59,887 INFO:     Epoch: 39
2022-11-18 01:40:00,664 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8289603604511782, 'Total loss': 0.8289603604511782} | train loss {'Reaction outcome loss': 0.8013943623631231, 'Total loss': 0.8013943623631231}
2022-11-18 01:40:00,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:00,664 INFO:     Epoch: 40
2022-11-18 01:40:01,439 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8360735950144854, 'Total loss': 0.8360735950144854} | train loss {'Reaction outcome loss': 0.8010015234110817, 'Total loss': 0.8010015234110817}
2022-11-18 01:40:01,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:01,439 INFO:     Epoch: 41
2022-11-18 01:40:02,256 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8371605818921869, 'Total loss': 0.8371605818921869} | train loss {'Reaction outcome loss': 0.8008468441905514, 'Total loss': 0.8008468441905514}
2022-11-18 01:40:02,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:02,256 INFO:     Epoch: 42
2022-11-18 01:40:03,049 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8304172605276108, 'Total loss': 0.8304172605276108} | train loss {'Reaction outcome loss': 0.8036905715782796, 'Total loss': 0.8036905715782796}
2022-11-18 01:40:03,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:03,050 INFO:     Epoch: 43
2022-11-18 01:40:03,828 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8220140839164908, 'Total loss': 0.8220140839164908} | train loss {'Reaction outcome loss': 0.7972647777247813, 'Total loss': 0.7972647777247813}
2022-11-18 01:40:03,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:03,828 INFO:     Epoch: 44
2022-11-18 01:40:04,619 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8202851888808337, 'Total loss': 0.8202851888808337} | train loss {'Reaction outcome loss': 0.7987327334140578, 'Total loss': 0.7987327334140578}
2022-11-18 01:40:04,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:04,619 INFO:     Epoch: 45
2022-11-18 01:40:05,400 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8220456432212483, 'Total loss': 0.8220456432212483} | train loss {'Reaction outcome loss': 0.7990897051509349, 'Total loss': 0.7990897051509349}
2022-11-18 01:40:05,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:05,400 INFO:     Epoch: 46
2022-11-18 01:40:06,217 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8780619556253607, 'Total loss': 0.8780619556253607} | train loss {'Reaction outcome loss': 0.7988229307436174, 'Total loss': 0.7988229307436174}
2022-11-18 01:40:06,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:06,217 INFO:     Epoch: 47
2022-11-18 01:40:06,991 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8259909315542742, 'Total loss': 0.8259909315542742} | train loss {'Reaction outcome loss': 0.8036553111047514, 'Total loss': 0.8036553111047514}
2022-11-18 01:40:06,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:06,992 INFO:     Epoch: 48
2022-11-18 01:40:07,760 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8603546064008366, 'Total loss': 0.8603546064008366} | train loss {'Reaction outcome loss': 0.801499085440751, 'Total loss': 0.801499085440751}
2022-11-18 01:40:07,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:07,760 INFO:     Epoch: 49
2022-11-18 01:40:08,528 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.834687434814193, 'Total loss': 0.834687434814193} | train loss {'Reaction outcome loss': 0.8009975195652054, 'Total loss': 0.8009975195652054}
2022-11-18 01:40:08,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:08,528 INFO:     Epoch: 50
2022-11-18 01:40:09,313 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8178422789682042, 'Total loss': 0.8178422789682042} | train loss {'Reaction outcome loss': 0.8024175686220969, 'Total loss': 0.8024175686220969}
2022-11-18 01:40:09,313 INFO:     Found new best model at epoch 50
2022-11-18 01:40:09,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:09,314 INFO:     Epoch: 51
2022-11-18 01:40:10,088 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8263761482455514, 'Total loss': 0.8263761482455514} | train loss {'Reaction outcome loss': 0.7987432798310634, 'Total loss': 0.7987432798310634}
2022-11-18 01:40:10,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:10,088 INFO:     Epoch: 52
2022-11-18 01:40:10,879 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8538948778401722, 'Total loss': 0.8538948778401722} | train loss {'Reaction outcome loss': 0.8006345802737821, 'Total loss': 0.8006345802737821}
2022-11-18 01:40:10,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:10,879 INFO:     Epoch: 53
2022-11-18 01:40:11,685 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8422933308915659, 'Total loss': 0.8422933308915659} | train loss {'Reaction outcome loss': 0.800602350023485, 'Total loss': 0.800602350023485}
2022-11-18 01:40:11,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:11,686 INFO:     Epoch: 54
2022-11-18 01:40:12,457 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8267016126350923, 'Total loss': 0.8267016126350923} | train loss {'Reaction outcome loss': 0.802727346338572, 'Total loss': 0.802727346338572}
2022-11-18 01:40:12,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:12,458 INFO:     Epoch: 55
2022-11-18 01:40:13,260 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8329053541476076, 'Total loss': 0.8329053541476076} | train loss {'Reaction outcome loss': 0.7988998983656207, 'Total loss': 0.7988998983656207}
2022-11-18 01:40:13,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:13,261 INFO:     Epoch: 56
2022-11-18 01:40:14,064 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8310386999086901, 'Total loss': 0.8310386999086901} | train loss {'Reaction outcome loss': 0.7994908286679175, 'Total loss': 0.7994908286679175}
2022-11-18 01:40:14,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:14,065 INFO:     Epoch: 57
2022-11-18 01:40:14,844 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8383472900498997, 'Total loss': 0.8383472900498997} | train loss {'Reaction outcome loss': 0.7978579004205042, 'Total loss': 0.7978579004205042}
2022-11-18 01:40:14,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:14,844 INFO:     Epoch: 58
2022-11-18 01:40:15,636 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8371744453907013, 'Total loss': 0.8371744453907013} | train loss {'Reaction outcome loss': 0.7997024213114092, 'Total loss': 0.7997024213114092}
2022-11-18 01:40:15,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:15,637 INFO:     Epoch: 59
2022-11-18 01:40:16,432 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8243658095598221, 'Total loss': 0.8243658095598221} | train loss {'Reaction outcome loss': 0.7980448014793857, 'Total loss': 0.7980448014793857}
2022-11-18 01:40:16,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:16,432 INFO:     Epoch: 60
2022-11-18 01:40:17,223 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8333541744134643, 'Total loss': 0.8333541744134643} | train loss {'Reaction outcome loss': 0.799435933631274, 'Total loss': 0.799435933631274}
2022-11-18 01:40:17,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:17,223 INFO:     Epoch: 61
2022-11-18 01:40:18,017 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8302037438208406, 'Total loss': 0.8302037438208406} | train loss {'Reaction outcome loss': 0.8023484485043634, 'Total loss': 0.8023484485043634}
2022-11-18 01:40:18,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:18,017 INFO:     Epoch: 62
2022-11-18 01:40:18,834 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8318776014176282, 'Total loss': 0.8318776014176282} | train loss {'Reaction outcome loss': 0.7957332070556379, 'Total loss': 0.7957332070556379}
2022-11-18 01:40:18,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:18,834 INFO:     Epoch: 63
2022-11-18 01:40:19,620 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8167100325226784, 'Total loss': 0.8167100325226784} | train loss {'Reaction outcome loss': 0.8003908594048792, 'Total loss': 0.8003908594048792}
2022-11-18 01:40:19,621 INFO:     Found new best model at epoch 63
2022-11-18 01:40:19,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:19,621 INFO:     Epoch: 64
2022-11-18 01:40:20,392 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8314722356471148, 'Total loss': 0.8314722356471148} | train loss {'Reaction outcome loss': 0.8006963088147102, 'Total loss': 0.8006963088147102}
2022-11-18 01:40:20,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:20,392 INFO:     Epoch: 65
2022-11-18 01:40:21,160 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.836063798178326, 'Total loss': 0.836063798178326} | train loss {'Reaction outcome loss': 0.7950652279560605, 'Total loss': 0.7950652279560605}
2022-11-18 01:40:21,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:21,160 INFO:     Epoch: 66
2022-11-18 01:40:21,939 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8239991001107476, 'Total loss': 0.8239991001107476} | train loss {'Reaction outcome loss': 0.7938195398497966, 'Total loss': 0.7938195398497966}
2022-11-18 01:40:21,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:21,939 INFO:     Epoch: 67
2022-11-18 01:40:22,734 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8329075066880747, 'Total loss': 0.8329075066880747} | train loss {'Reaction outcome loss': 0.7989471299994376, 'Total loss': 0.7989471299994376}
2022-11-18 01:40:22,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:22,734 INFO:     Epoch: 68
2022-11-18 01:40:23,487 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8210854631933299, 'Total loss': 0.8210854631933299} | train loss {'Reaction outcome loss': 0.7952737578701589, 'Total loss': 0.7952737578701589}
2022-11-18 01:40:23,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:23,487 INFO:     Epoch: 69
2022-11-18 01:40:24,268 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8209653848951514, 'Total loss': 0.8209653848951514} | train loss {'Reaction outcome loss': 0.7959097504856125, 'Total loss': 0.7959097504856125}
2022-11-18 01:40:24,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:24,268 INFO:     Epoch: 70
2022-11-18 01:40:25,090 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8217340870337053, 'Total loss': 0.8217340870337053} | train loss {'Reaction outcome loss': 0.7917776139032456, 'Total loss': 0.7917776139032456}
2022-11-18 01:40:25,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:25,090 INFO:     Epoch: 71
2022-11-18 01:40:25,885 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8239184333519503, 'Total loss': 0.8239184333519503} | train loss {'Reaction outcome loss': 0.7928792031541947, 'Total loss': 0.7928792031541947}
2022-11-18 01:40:25,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:25,886 INFO:     Epoch: 72
2022-11-18 01:40:26,688 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8330700072375211, 'Total loss': 0.8330700072375211} | train loss {'Reaction outcome loss': 0.7938274500831481, 'Total loss': 0.7938274500831481}
2022-11-18 01:40:26,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:26,688 INFO:     Epoch: 73
2022-11-18 01:40:27,464 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.852164823223244, 'Total loss': 0.852164823223244} | train loss {'Reaction outcome loss': 0.7973159791961792, 'Total loss': 0.7973159791961792}
2022-11-18 01:40:27,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:27,465 INFO:     Epoch: 74
2022-11-18 01:40:28,255 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8564523790370334, 'Total loss': 0.8564523790370334} | train loss {'Reaction outcome loss': 0.7926710595887515, 'Total loss': 0.7926710595887515}
2022-11-18 01:40:28,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:28,256 INFO:     Epoch: 75
2022-11-18 01:40:29,068 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8242307183417407, 'Total loss': 0.8242307183417407} | train loss {'Reaction outcome loss': 0.7922990873696343, 'Total loss': 0.7922990873696343}
2022-11-18 01:40:29,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:29,068 INFO:     Epoch: 76
2022-11-18 01:40:29,848 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8296987461772832, 'Total loss': 0.8296987461772832} | train loss {'Reaction outcome loss': 0.7930537856394245, 'Total loss': 0.7930537856394245}
2022-11-18 01:40:29,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:29,849 INFO:     Epoch: 77
2022-11-18 01:40:30,621 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8163809220899235, 'Total loss': 0.8163809220899235} | train loss {'Reaction outcome loss': 0.796011816950575, 'Total loss': 0.796011816950575}
2022-11-18 01:40:30,621 INFO:     Found new best model at epoch 77
2022-11-18 01:40:30,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:30,622 INFO:     Epoch: 78
2022-11-18 01:40:31,423 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8560104871338065, 'Total loss': 0.8560104871338065} | train loss {'Reaction outcome loss': 0.7984344990503404, 'Total loss': 0.7984344990503404}
2022-11-18 01:40:31,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:31,423 INFO:     Epoch: 79
2022-11-18 01:40:32,218 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8392423770644448, 'Total loss': 0.8392423770644448} | train loss {'Reaction outcome loss': 0.7991048877518023, 'Total loss': 0.7991048877518023}
2022-11-18 01:40:32,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:32,219 INFO:     Epoch: 80
2022-11-18 01:40:33,020 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8248761133714155, 'Total loss': 0.8248761133714155} | train loss {'Reaction outcome loss': 0.8006264525315454, 'Total loss': 0.8006264525315454}
2022-11-18 01:40:33,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:33,021 INFO:     Epoch: 81
2022-11-18 01:40:33,813 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8309119485995986, 'Total loss': 0.8309119485995986} | train loss {'Reaction outcome loss': 0.7987642813353769, 'Total loss': 0.7987642813353769}
2022-11-18 01:40:33,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:33,814 INFO:     Epoch: 82
2022-11-18 01:40:34,601 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8499795191667296, 'Total loss': 0.8499795191667296} | train loss {'Reaction outcome loss': 0.7942205328614481, 'Total loss': 0.7942205328614481}
2022-11-18 01:40:34,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:34,602 INFO:     Epoch: 83
2022-11-18 01:40:35,394 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8254185596650297, 'Total loss': 0.8254185596650297} | train loss {'Reaction outcome loss': 0.7925519365216455, 'Total loss': 0.7925519365216455}
2022-11-18 01:40:35,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:35,394 INFO:     Epoch: 84
2022-11-18 01:40:36,175 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8260694227435372, 'Total loss': 0.8260694227435372} | train loss {'Reaction outcome loss': 0.7918236766371035, 'Total loss': 0.7918236766371035}
2022-11-18 01:40:36,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:36,175 INFO:     Epoch: 85
2022-11-18 01:40:36,943 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8420841192657297, 'Total loss': 0.8420841192657297} | train loss {'Reaction outcome loss': 0.7995535285482483, 'Total loss': 0.7995535285482483}
2022-11-18 01:40:36,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:36,943 INFO:     Epoch: 86
2022-11-18 01:40:37,765 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8349116999994625, 'Total loss': 0.8349116999994625} | train loss {'Reaction outcome loss': 0.7969128610866685, 'Total loss': 0.7969128610866685}
2022-11-18 01:40:37,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:37,765 INFO:     Epoch: 87
2022-11-18 01:40:38,537 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.838452779433944, 'Total loss': 0.838452779433944} | train loss {'Reaction outcome loss': 0.7986434188581282, 'Total loss': 0.7986434188581282}
2022-11-18 01:40:38,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:38,538 INFO:     Epoch: 88
2022-11-18 01:40:39,325 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.835827882994305, 'Total loss': 0.835827882994305} | train loss {'Reaction outcome loss': 0.7932538339687932, 'Total loss': 0.7932538339687932}
2022-11-18 01:40:39,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:39,325 INFO:     Epoch: 89
2022-11-18 01:40:40,157 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8203863555734808, 'Total loss': 0.8203863555734808} | train loss {'Reaction outcome loss': 0.7964516915380955, 'Total loss': 0.7964516915380955}
2022-11-18 01:40:40,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:40,157 INFO:     Epoch: 90
2022-11-18 01:40:40,966 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.831391270187768, 'Total loss': 0.831391270187768} | train loss {'Reaction outcome loss': 0.7993288101448167, 'Total loss': 0.7993288101448167}
2022-11-18 01:40:40,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:40,966 INFO:     Epoch: 91
2022-11-18 01:40:41,757 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8209041756662455, 'Total loss': 0.8209041756662455} | train loss {'Reaction outcome loss': 0.7964841948161202, 'Total loss': 0.7964841948161202}
2022-11-18 01:40:41,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:41,757 INFO:     Epoch: 92
2022-11-18 01:40:42,575 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8189636008305983, 'Total loss': 0.8189636008305983} | train loss {'Reaction outcome loss': 0.7926251188881935, 'Total loss': 0.7926251188881935}
2022-11-18 01:40:42,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:42,575 INFO:     Epoch: 93
2022-11-18 01:40:43,358 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8234166103330526, 'Total loss': 0.8234166103330526} | train loss {'Reaction outcome loss': 0.7987128811017159, 'Total loss': 0.7987128811017159}
2022-11-18 01:40:43,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:43,358 INFO:     Epoch: 94
2022-11-18 01:40:44,180 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8303626145828854, 'Total loss': 0.8303626145828854} | train loss {'Reaction outcome loss': 0.7954289966052578, 'Total loss': 0.7954289966052578}
2022-11-18 01:40:44,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:44,180 INFO:     Epoch: 95
2022-11-18 01:40:44,981 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8469601320949468, 'Total loss': 0.8469601320949468} | train loss {'Reaction outcome loss': 0.7897205796212919, 'Total loss': 0.7897205796212919}
2022-11-18 01:40:44,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:44,981 INFO:     Epoch: 96
2022-11-18 01:40:45,818 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8382511226968332, 'Total loss': 0.8382511226968332} | train loss {'Reaction outcome loss': 0.7961246472212576, 'Total loss': 0.7961246472212576}
2022-11-18 01:40:45,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:45,819 INFO:     Epoch: 97
2022-11-18 01:40:46,670 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8236408233642578, 'Total loss': 0.8236408233642578} | train loss {'Reaction outcome loss': 0.7916927058850566, 'Total loss': 0.7916927058850566}
2022-11-18 01:40:46,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:46,671 INFO:     Epoch: 98
2022-11-18 01:40:47,454 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8139952929182486, 'Total loss': 0.8139952929182486} | train loss {'Reaction outcome loss': 0.7949739511935942, 'Total loss': 0.7949739511935942}
2022-11-18 01:40:47,454 INFO:     Found new best model at epoch 98
2022-11-18 01:40:47,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:47,455 INFO:     Epoch: 99
2022-11-18 01:40:48,248 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8577420643784783, 'Total loss': 0.8577420643784783} | train loss {'Reaction outcome loss': 0.7981166420204024, 'Total loss': 0.7981166420204024}
2022-11-18 01:40:48,248 INFO:     Best model found after epoch 99 of 100.
2022-11-18 01:40:48,248 INFO:   Done with stage: TRAINING
2022-11-18 01:40:48,248 INFO:   Starting stage: EVALUATION
2022-11-18 01:40:48,366 INFO:   Done with stage: EVALUATION
2022-11-18 01:40:48,366 INFO:   Leaving out SEQ value Fold_5
2022-11-18 01:40:48,379 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 01:40:48,379 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:40:49,055 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:40:49,055 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:40:49,126 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:40:49,126 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:40:49,126 INFO:     No hyperparam tuning for this model
2022-11-18 01:40:49,126 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:40:49,126 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:40:49,127 INFO:     None feature selector for col prot
2022-11-18 01:40:49,127 INFO:     None feature selector for col prot
2022-11-18 01:40:49,127 INFO:     None feature selector for col prot
2022-11-18 01:40:49,128 INFO:     None feature selector for col chem
2022-11-18 01:40:49,128 INFO:     None feature selector for col chem
2022-11-18 01:40:49,128 INFO:     None feature selector for col chem
2022-11-18 01:40:49,128 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:40:49,128 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:40:49,130 INFO:     Number of params in model 168571
2022-11-18 01:40:49,133 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:40:49,133 INFO:   Starting stage: TRAINING
2022-11-18 01:40:49,191 INFO:     Val loss before train {'Reaction outcome loss': 1.0222139615904202, 'Total loss': 1.0222139615904202}
2022-11-18 01:40:49,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:49,191 INFO:     Epoch: 0
2022-11-18 01:40:49,982 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8764320693232797, 'Total loss': 0.8764320693232797} | train loss {'Reaction outcome loss': 0.8879964354057466, 'Total loss': 0.8879964354057466}
2022-11-18 01:40:49,982 INFO:     Found new best model at epoch 0
2022-11-18 01:40:49,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:49,983 INFO:     Epoch: 1
2022-11-18 01:40:50,798 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8667104799639095, 'Total loss': 0.8667104799639095} | train loss {'Reaction outcome loss': 0.8540059933739323, 'Total loss': 0.8540059933739323}
2022-11-18 01:40:50,798 INFO:     Found new best model at epoch 1
2022-11-18 01:40:50,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:50,799 INFO:     Epoch: 2
2022-11-18 01:40:51,585 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.848119046877731, 'Total loss': 0.848119046877731} | train loss {'Reaction outcome loss': 0.8513739595730458, 'Total loss': 0.8513739595730458}
2022-11-18 01:40:51,586 INFO:     Found new best model at epoch 2
2022-11-18 01:40:51,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:51,586 INFO:     Epoch: 3
2022-11-18 01:40:52,426 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8527190238237381, 'Total loss': 0.8527190238237381} | train loss {'Reaction outcome loss': 0.8467957710306491, 'Total loss': 0.8467957710306491}
2022-11-18 01:40:52,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:52,426 INFO:     Epoch: 4
2022-11-18 01:40:53,241 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8601296205412258, 'Total loss': 0.8601296205412258} | train loss {'Reaction outcome loss': 0.8463906649379961, 'Total loss': 0.8463906649379961}
2022-11-18 01:40:53,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:53,241 INFO:     Epoch: 5
2022-11-18 01:40:54,054 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8609108863906427, 'Total loss': 0.8609108863906427} | train loss {'Reaction outcome loss': 0.8406182266771793, 'Total loss': 0.8406182266771793}
2022-11-18 01:40:54,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:54,054 INFO:     Epoch: 6
2022-11-18 01:40:54,864 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8620391284877603, 'Total loss': 0.8620391284877603} | train loss {'Reaction outcome loss': 0.8422704342632524, 'Total loss': 0.8422704342632524}
2022-11-18 01:40:54,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:54,864 INFO:     Epoch: 7
2022-11-18 01:40:55,671 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8644423877651041, 'Total loss': 0.8644423877651041} | train loss {'Reaction outcome loss': 0.8386711640463721, 'Total loss': 0.8386711640463721}
2022-11-18 01:40:55,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:55,671 INFO:     Epoch: 8
2022-11-18 01:40:56,510 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8356509032574567, 'Total loss': 0.8356509032574567} | train loss {'Reaction outcome loss': 0.8350396282490222, 'Total loss': 0.8350396282490222}
2022-11-18 01:40:56,510 INFO:     Found new best model at epoch 8
2022-11-18 01:40:56,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:56,511 INFO:     Epoch: 9
2022-11-18 01:40:57,328 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8607154942371629, 'Total loss': 0.8607154942371629} | train loss {'Reaction outcome loss': 0.8309207779745902, 'Total loss': 0.8309207779745902}
2022-11-18 01:40:57,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:57,328 INFO:     Epoch: 10
2022-11-18 01:40:58,128 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.827615616673773, 'Total loss': 0.827615616673773} | train loss {'Reaction outcome loss': 0.832055120819038, 'Total loss': 0.832055120819038}
2022-11-18 01:40:58,130 INFO:     Found new best model at epoch 10
2022-11-18 01:40:58,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:58,130 INFO:     Epoch: 11
2022-11-18 01:40:58,931 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8532989898865874, 'Total loss': 0.8532989898865874} | train loss {'Reaction outcome loss': 0.8301322781030209, 'Total loss': 0.8301322781030209}
2022-11-18 01:40:58,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:58,932 INFO:     Epoch: 12
2022-11-18 01:40:59,795 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8809710741043091, 'Total loss': 0.8809710741043091} | train loss {'Reaction outcome loss': 0.8304878041869209, 'Total loss': 0.8304878041869209}
2022-11-18 01:40:59,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:40:59,796 INFO:     Epoch: 13
2022-11-18 01:41:00,647 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8548045991496607, 'Total loss': 0.8548045991496607} | train loss {'Reaction outcome loss': 0.8293459065739186, 'Total loss': 0.8293459065739186}
2022-11-18 01:41:00,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:00,648 INFO:     Epoch: 14
2022-11-18 01:41:01,441 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.856517763977701, 'Total loss': 0.856517763977701} | train loss {'Reaction outcome loss': 0.8229561473333067, 'Total loss': 0.8229561473333067}
2022-11-18 01:41:01,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:01,441 INFO:     Epoch: 15
2022-11-18 01:41:02,225 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8326885605400259, 'Total loss': 0.8326885605400259} | train loss {'Reaction outcome loss': 0.8270357832793267, 'Total loss': 0.8270357832793267}
2022-11-18 01:41:02,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:02,225 INFO:     Epoch: 16
2022-11-18 01:41:03,015 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8379798904061317, 'Total loss': 0.8379798904061317} | train loss {'Reaction outcome loss': 0.826168472247739, 'Total loss': 0.826168472247739}
2022-11-18 01:41:03,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:03,015 INFO:     Epoch: 17
2022-11-18 01:41:03,782 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8276057548143647, 'Total loss': 0.8276057548143647} | train loss {'Reaction outcome loss': 0.8244759874238122, 'Total loss': 0.8244759874238122}
2022-11-18 01:41:03,782 INFO:     Found new best model at epoch 17
2022-11-18 01:41:03,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:03,783 INFO:     Epoch: 18
2022-11-18 01:41:04,596 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8317387876185504, 'Total loss': 0.8317387876185504} | train loss {'Reaction outcome loss': 0.8248571155052031, 'Total loss': 0.8248571155052031}
2022-11-18 01:41:04,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:04,597 INFO:     Epoch: 19
2022-11-18 01:41:05,381 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.822525058280338, 'Total loss': 0.822525058280338} | train loss {'Reaction outcome loss': 0.8305943758497315, 'Total loss': 0.8305943758497315}
2022-11-18 01:41:05,382 INFO:     Found new best model at epoch 19
2022-11-18 01:41:05,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:05,383 INFO:     Epoch: 20
2022-11-18 01:41:06,164 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8236319517547434, 'Total loss': 0.8236319517547434} | train loss {'Reaction outcome loss': 0.8250152105765958, 'Total loss': 0.8250152105765958}
2022-11-18 01:41:06,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:06,164 INFO:     Epoch: 21
2022-11-18 01:41:06,984 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8239125595851378, 'Total loss': 0.8239125595851378} | train loss {'Reaction outcome loss': 0.8284847280911861, 'Total loss': 0.8284847280911861}
2022-11-18 01:41:06,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:06,984 INFO:     Epoch: 22
2022-11-18 01:41:07,774 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8325119851665064, 'Total loss': 0.8325119851665064} | train loss {'Reaction outcome loss': 0.8218971041421737, 'Total loss': 0.8218971041421737}
2022-11-18 01:41:07,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:07,775 INFO:     Epoch: 23
2022-11-18 01:41:08,549 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8370525958863172, 'Total loss': 0.8370525958863172} | train loss {'Reaction outcome loss': 0.8214628767342337, 'Total loss': 0.8214628767342337}
2022-11-18 01:41:08,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:08,549 INFO:     Epoch: 24
2022-11-18 01:41:09,348 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8414297036149285, 'Total loss': 0.8414297036149285} | train loss {'Reaction outcome loss': 0.8280987686687901, 'Total loss': 0.8280987686687901}
2022-11-18 01:41:09,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:09,348 INFO:     Epoch: 25
2022-11-18 01:41:10,137 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8258731879971244, 'Total loss': 0.8258731879971244} | train loss {'Reaction outcome loss': 0.8285364614379022, 'Total loss': 0.8285364614379022}
2022-11-18 01:41:10,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:10,137 INFO:     Epoch: 26
2022-11-18 01:41:10,937 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8367133553732525, 'Total loss': 0.8367133553732525} | train loss {'Reaction outcome loss': 0.8226088608705229, 'Total loss': 0.8226088608705229}
2022-11-18 01:41:10,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:10,937 INFO:     Epoch: 27
2022-11-18 01:41:11,730 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8357525359500538, 'Total loss': 0.8357525359500538} | train loss {'Reaction outcome loss': 0.8266096226871014, 'Total loss': 0.8266096226871014}
2022-11-18 01:41:11,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:11,731 INFO:     Epoch: 28
2022-11-18 01:41:12,496 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8433060916987333, 'Total loss': 0.8433060916987333} | train loss {'Reaction outcome loss': 0.8223777868815006, 'Total loss': 0.8223777868815006}
2022-11-18 01:41:12,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:12,497 INFO:     Epoch: 29
2022-11-18 01:41:13,329 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.836489203301343, 'Total loss': 0.836489203301343} | train loss {'Reaction outcome loss': 0.8261096713043028, 'Total loss': 0.8261096713043028}
2022-11-18 01:41:13,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:13,329 INFO:     Epoch: 30
2022-11-18 01:41:14,118 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.835016319020228, 'Total loss': 0.835016319020228} | train loss {'Reaction outcome loss': 0.8226541656880609, 'Total loss': 0.8226541656880609}
2022-11-18 01:41:14,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:14,118 INFO:     Epoch: 31
2022-11-18 01:41:14,903 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8420739004557783, 'Total loss': 0.8420739004557783} | train loss {'Reaction outcome loss': 0.8234975930423506, 'Total loss': 0.8234975930423506}
2022-11-18 01:41:14,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:14,903 INFO:     Epoch: 32
2022-11-18 01:41:15,696 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8264285021207549, 'Total loss': 0.8264285021207549} | train loss {'Reaction outcome loss': 0.8257573471674996, 'Total loss': 0.8257573471674996}
2022-11-18 01:41:15,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:15,696 INFO:     Epoch: 33
2022-11-18 01:41:16,487 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8469819033687765, 'Total loss': 0.8469819033687765} | train loss {'Reaction outcome loss': 0.8212845605467597, 'Total loss': 0.8212845605467597}
2022-11-18 01:41:16,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:16,487 INFO:     Epoch: 34
2022-11-18 01:41:17,282 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8334110988812014, 'Total loss': 0.8334110988812014} | train loss {'Reaction outcome loss': 0.8216924505128015, 'Total loss': 0.8216924505128015}
2022-11-18 01:41:17,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:17,284 INFO:     Epoch: 35
2022-11-18 01:41:18,046 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8295101956887678, 'Total loss': 0.8295101956887678} | train loss {'Reaction outcome loss': 0.8193088504335573, 'Total loss': 0.8193088504335573}
2022-11-18 01:41:18,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:18,047 INFO:     Epoch: 36
2022-11-18 01:41:18,857 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8424130204049024, 'Total loss': 0.8424130204049024} | train loss {'Reaction outcome loss': 0.8217205116825719, 'Total loss': 0.8217205116825719}
2022-11-18 01:41:18,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:18,858 INFO:     Epoch: 37
2022-11-18 01:41:19,680 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8207251551476392, 'Total loss': 0.8207251551476392} | train loss {'Reaction outcome loss': 0.8215409248105942, 'Total loss': 0.8215409248105942}
2022-11-18 01:41:19,680 INFO:     Found new best model at epoch 37
2022-11-18 01:41:19,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:19,681 INFO:     Epoch: 38
2022-11-18 01:41:20,468 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8456955951723185, 'Total loss': 0.8456955951723185} | train loss {'Reaction outcome loss': 0.8205137543620602, 'Total loss': 0.8205137543620602}
2022-11-18 01:41:20,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:20,468 INFO:     Epoch: 39
2022-11-18 01:41:21,257 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8362914418632333, 'Total loss': 0.8362914418632333} | train loss {'Reaction outcome loss': 0.8196713017119516, 'Total loss': 0.8196713017119516}
2022-11-18 01:41:21,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:21,257 INFO:     Epoch: 40
2022-11-18 01:41:22,067 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8201201531020078, 'Total loss': 0.8201201531020078} | train loss {'Reaction outcome loss': 0.8227778405191437, 'Total loss': 0.8227778405191437}
2022-11-18 01:41:22,067 INFO:     Found new best model at epoch 40
2022-11-18 01:41:22,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:22,068 INFO:     Epoch: 41
2022-11-18 01:41:22,861 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8234576129100539, 'Total loss': 0.8234576129100539} | train loss {'Reaction outcome loss': 0.8214484289769204, 'Total loss': 0.8214484289769204}
2022-11-18 01:41:22,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:22,862 INFO:     Epoch: 42
2022-11-18 01:41:23,631 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8309172269972888, 'Total loss': 0.8309172269972888} | train loss {'Reaction outcome loss': 0.822480802694636, 'Total loss': 0.822480802694636}
2022-11-18 01:41:23,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:23,631 INFO:     Epoch: 43
2022-11-18 01:41:24,424 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8293062909082933, 'Total loss': 0.8293062909082933} | train loss {'Reaction outcome loss': 0.8238754064565704, 'Total loss': 0.8238754064565704}
2022-11-18 01:41:24,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:24,424 INFO:     Epoch: 44
2022-11-18 01:41:25,191 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8234769431027499, 'Total loss': 0.8234769431027499} | train loss {'Reaction outcome loss': 0.8219507286144841, 'Total loss': 0.8219507286144841}
2022-11-18 01:41:25,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:25,191 INFO:     Epoch: 45
2022-11-18 01:41:26,011 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8447968749837442, 'Total loss': 0.8447968749837442} | train loss {'Reaction outcome loss': 0.8186090755606851, 'Total loss': 0.8186090755606851}
2022-11-18 01:41:26,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:26,011 INFO:     Epoch: 46
2022-11-18 01:41:26,783 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8242682963609695, 'Total loss': 0.8242682963609695} | train loss {'Reaction outcome loss': 0.8218474702969674, 'Total loss': 0.8218474702969674}
2022-11-18 01:41:26,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:26,783 INFO:     Epoch: 47
2022-11-18 01:41:27,563 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8421843363480135, 'Total loss': 0.8421843363480135} | train loss {'Reaction outcome loss': 0.8181577642117778, 'Total loss': 0.8181577642117778}
2022-11-18 01:41:27,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:27,564 INFO:     Epoch: 48
2022-11-18 01:41:28,401 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8356401906772093, 'Total loss': 0.8356401906772093} | train loss {'Reaction outcome loss': 0.8212882475026192, 'Total loss': 0.8212882475026192}
2022-11-18 01:41:28,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:28,401 INFO:     Epoch: 49
2022-11-18 01:41:29,208 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8430869958617471, 'Total loss': 0.8430869958617471} | train loss {'Reaction outcome loss': 0.8182290744396948, 'Total loss': 0.8182290744396948}
2022-11-18 01:41:29,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:29,208 INFO:     Epoch: 50
2022-11-18 01:41:29,985 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8263125189326026, 'Total loss': 0.8263125189326026} | train loss {'Reaction outcome loss': 0.8190138844713089, 'Total loss': 0.8190138844713089}
2022-11-18 01:41:29,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:29,986 INFO:     Epoch: 51
2022-11-18 01:41:30,806 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8252567073160951, 'Total loss': 0.8252567073160951} | train loss {'Reaction outcome loss': 0.8180431337846864, 'Total loss': 0.8180431337846864}
2022-11-18 01:41:30,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:30,806 INFO:     Epoch: 52
2022-11-18 01:41:31,625 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8224153423851187, 'Total loss': 0.8224153423851187} | train loss {'Reaction outcome loss': 0.8190998311244673, 'Total loss': 0.8190998311244673}
2022-11-18 01:41:31,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:31,625 INFO:     Epoch: 53
2022-11-18 01:41:32,428 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8289034122770483, 'Total loss': 0.8289034122770483} | train loss {'Reaction outcome loss': 0.8167496821092021, 'Total loss': 0.8167496821092021}
2022-11-18 01:41:32,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:32,428 INFO:     Epoch: 54
2022-11-18 01:41:33,249 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8350569063966925, 'Total loss': 0.8350569063966925} | train loss {'Reaction outcome loss': 0.8208720851088723, 'Total loss': 0.8208720851088723}
2022-11-18 01:41:33,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:33,249 INFO:     Epoch: 55
2022-11-18 01:41:34,055 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8260709934613921, 'Total loss': 0.8260709934613921} | train loss {'Reaction outcome loss': 0.8232632287808003, 'Total loss': 0.8232632287808003}
2022-11-18 01:41:34,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:34,055 INFO:     Epoch: 56
2022-11-18 01:41:34,880 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8289227702400901, 'Total loss': 0.8289227702400901} | train loss {'Reaction outcome loss': 0.8147918583164292, 'Total loss': 0.8147918583164292}
2022-11-18 01:41:34,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:34,880 INFO:     Epoch: 57
2022-11-18 01:41:35,696 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8933305916461077, 'Total loss': 0.8933305916461077} | train loss {'Reaction outcome loss': 0.8156708603905093, 'Total loss': 0.8156708603905093}
2022-11-18 01:41:35,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:35,696 INFO:     Epoch: 58
2022-11-18 01:41:36,532 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.821284600279548, 'Total loss': 0.821284600279548} | train loss {'Reaction outcome loss': 0.8245185540328103, 'Total loss': 0.8245185540328103}
2022-11-18 01:41:36,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:36,533 INFO:     Epoch: 59
2022-11-18 01:41:37,375 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8371998633850705, 'Total loss': 0.8371998633850705} | train loss {'Reaction outcome loss': 0.8192608099310629, 'Total loss': 0.8192608099310629}
2022-11-18 01:41:37,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:37,375 INFO:     Epoch: 60
2022-11-18 01:41:38,209 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8261791196736422, 'Total loss': 0.8261791196736422} | train loss {'Reaction outcome loss': 0.8166589642003659, 'Total loss': 0.8166589642003659}
2022-11-18 01:41:38,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:38,210 INFO:     Epoch: 61
2022-11-18 01:41:39,041 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8282111998308789, 'Total loss': 0.8282111998308789} | train loss {'Reaction outcome loss': 0.8209262358084801, 'Total loss': 0.8209262358084801}
2022-11-18 01:41:39,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:39,041 INFO:     Epoch: 62
2022-11-18 01:41:39,849 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8732039860703729, 'Total loss': 0.8732039860703729} | train loss {'Reaction outcome loss': 0.8151019631374267, 'Total loss': 0.8151019631374267}
2022-11-18 01:41:39,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:39,849 INFO:     Epoch: 63
2022-11-18 01:41:40,666 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8517465124076063, 'Total loss': 0.8517465124076063} | train loss {'Reaction outcome loss': 0.8182340824315625, 'Total loss': 0.8182340824315625}
2022-11-18 01:41:40,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:40,667 INFO:     Epoch: 64
2022-11-18 01:41:41,550 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8414268358187242, 'Total loss': 0.8414268358187242} | train loss {'Reaction outcome loss': 0.8219614894159378, 'Total loss': 0.8219614894159378}
2022-11-18 01:41:41,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:41,550 INFO:     Epoch: 65
2022-11-18 01:41:42,363 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8298061747442592, 'Total loss': 0.8298061747442592} | train loss {'Reaction outcome loss': 0.8170520094854217, 'Total loss': 0.8170520094854217}
2022-11-18 01:41:42,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:42,363 INFO:     Epoch: 66
2022-11-18 01:41:43,206 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8479024334387346, 'Total loss': 0.8479024334387346} | train loss {'Reaction outcome loss': 0.8198054103601363, 'Total loss': 0.8198054103601363}
2022-11-18 01:41:43,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:43,206 INFO:     Epoch: 67
2022-11-18 01:41:44,005 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8394581892273643, 'Total loss': 0.8394581892273643} | train loss {'Reaction outcome loss': 0.8217552342722493, 'Total loss': 0.8217552342722493}
2022-11-18 01:41:44,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:44,006 INFO:     Epoch: 68
2022-11-18 01:41:44,816 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8252747316252101, 'Total loss': 0.8252747316252101} | train loss {'Reaction outcome loss': 0.8209098638786424, 'Total loss': 0.8209098638786424}
2022-11-18 01:41:44,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:44,816 INFO:     Epoch: 69
2022-11-18 01:41:45,643 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8163217773491686, 'Total loss': 0.8163217773491686} | train loss {'Reaction outcome loss': 0.8172363738619512, 'Total loss': 0.8172363738619512}
2022-11-18 01:41:45,643 INFO:     Found new best model at epoch 69
2022-11-18 01:41:45,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:45,644 INFO:     Epoch: 70
2022-11-18 01:41:46,458 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8335665681145408, 'Total loss': 0.8335665681145408} | train loss {'Reaction outcome loss': 0.8207452905274206, 'Total loss': 0.8207452905274206}
2022-11-18 01:41:46,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:46,459 INFO:     Epoch: 71
2022-11-18 01:41:47,232 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8229651112448085, 'Total loss': 0.8229651112448085} | train loss {'Reaction outcome loss': 0.8194940650174695, 'Total loss': 0.8194940650174695}
2022-11-18 01:41:47,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:47,232 INFO:     Epoch: 72
2022-11-18 01:41:48,046 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8315157450058244, 'Total loss': 0.8315157450058244} | train loss {'Reaction outcome loss': 0.820277888327837, 'Total loss': 0.820277888327837}
2022-11-18 01:41:48,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:48,046 INFO:     Epoch: 73
2022-11-18 01:41:48,853 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8287892612543973, 'Total loss': 0.8287892612543973} | train loss {'Reaction outcome loss': 0.8225130747643209, 'Total loss': 0.8225130747643209}
2022-11-18 01:41:48,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:48,854 INFO:     Epoch: 74
2022-11-18 01:41:49,636 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8252903941002759, 'Total loss': 0.8252903941002759} | train loss {'Reaction outcome loss': 0.8195841434982515, 'Total loss': 0.8195841434982515}
2022-11-18 01:41:49,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:49,636 INFO:     Epoch: 75
2022-11-18 01:41:50,465 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8165007612921975, 'Total loss': 0.8165007612921975} | train loss {'Reaction outcome loss': 0.8184495360380218, 'Total loss': 0.8184495360380218}
2022-11-18 01:41:50,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:50,466 INFO:     Epoch: 76
2022-11-18 01:41:51,266 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8693077171390707, 'Total loss': 0.8693077171390707} | train loss {'Reaction outcome loss': 0.8198649949364124, 'Total loss': 0.8198649949364124}
2022-11-18 01:41:51,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:51,266 INFO:     Epoch: 77
2022-11-18 01:41:52,091 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8430530855601485, 'Total loss': 0.8430530855601485} | train loss {'Reaction outcome loss': 0.8253083426144815, 'Total loss': 0.8253083426144815}
2022-11-18 01:41:52,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:52,091 INFO:     Epoch: 78
2022-11-18 01:41:52,878 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8352661498568275, 'Total loss': 0.8352661498568275} | train loss {'Reaction outcome loss': 0.8162586838006973, 'Total loss': 0.8162586838006973}
2022-11-18 01:41:52,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:52,878 INFO:     Epoch: 79
2022-11-18 01:41:53,694 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8298096074299379, 'Total loss': 0.8298096074299379} | train loss {'Reaction outcome loss': 0.8235389312669155, 'Total loss': 0.8235389312669155}
2022-11-18 01:41:53,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:53,695 INFO:     Epoch: 80
2022-11-18 01:41:54,489 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8157871534878557, 'Total loss': 0.8157871534878557} | train loss {'Reaction outcome loss': 0.818285807967186, 'Total loss': 0.818285807967186}
2022-11-18 01:41:54,489 INFO:     Found new best model at epoch 80
2022-11-18 01:41:54,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:54,490 INFO:     Epoch: 81
2022-11-18 01:41:55,303 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8251205574382435, 'Total loss': 0.8251205574382435} | train loss {'Reaction outcome loss': 0.8205105161234256, 'Total loss': 0.8205105161234256}
2022-11-18 01:41:55,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:55,303 INFO:     Epoch: 82
2022-11-18 01:41:56,080 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8195509104566141, 'Total loss': 0.8195509104566141} | train loss {'Reaction outcome loss': 0.8209545343152939, 'Total loss': 0.8209545343152939}
2022-11-18 01:41:56,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:56,080 INFO:     Epoch: 83
2022-11-18 01:41:56,872 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8402759757908908, 'Total loss': 0.8402759757908908} | train loss {'Reaction outcome loss': 0.8185340945999469, 'Total loss': 0.8185340945999469}
2022-11-18 01:41:56,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:56,872 INFO:     Epoch: 84
2022-11-18 01:41:57,683 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8353738859295845, 'Total loss': 0.8353738859295845} | train loss {'Reaction outcome loss': 0.8159045418423991, 'Total loss': 0.8159045418423991}
2022-11-18 01:41:57,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:57,684 INFO:     Epoch: 85
2022-11-18 01:41:58,538 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8295616175640713, 'Total loss': 0.8295616175640713} | train loss {'Reaction outcome loss': 0.8193460314744904, 'Total loss': 0.8193460314744904}
2022-11-18 01:41:58,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:58,538 INFO:     Epoch: 86
2022-11-18 01:41:59,350 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.825834343379194, 'Total loss': 0.825834343379194} | train loss {'Reaction outcome loss': 0.8210229074522373, 'Total loss': 0.8210229074522373}
2022-11-18 01:41:59,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:41:59,350 INFO:     Epoch: 87
2022-11-18 01:42:00,172 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8298143893480301, 'Total loss': 0.8298143893480301} | train loss {'Reaction outcome loss': 0.8226866189750933, 'Total loss': 0.8226866189750933}
2022-11-18 01:42:00,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:00,172 INFO:     Epoch: 88
2022-11-18 01:42:00,984 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8357585993680087, 'Total loss': 0.8357585993680087} | train loss {'Reaction outcome loss': 0.8185823010581155, 'Total loss': 0.8185823010581155}
2022-11-18 01:42:00,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:00,986 INFO:     Epoch: 89
2022-11-18 01:42:01,790 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8445239879868247, 'Total loss': 0.8445239879868247} | train loss {'Reaction outcome loss': 0.8166178499739016, 'Total loss': 0.8166178499739016}
2022-11-18 01:42:01,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:01,790 INFO:     Epoch: 90
2022-11-18 01:42:02,613 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8300478275526654, 'Total loss': 0.8300478275526654} | train loss {'Reaction outcome loss': 0.8203195287815986, 'Total loss': 0.8203195287815986}
2022-11-18 01:42:02,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:02,613 INFO:     Epoch: 91
2022-11-18 01:42:03,416 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8256948048418219, 'Total loss': 0.8256948048418219} | train loss {'Reaction outcome loss': 0.8198763606769424, 'Total loss': 0.8198763606769424}
2022-11-18 01:42:03,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:03,416 INFO:     Epoch: 92
2022-11-18 01:42:04,232 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.832375975495035, 'Total loss': 0.832375975495035} | train loss {'Reaction outcome loss': 0.818979193005831, 'Total loss': 0.818979193005831}
2022-11-18 01:42:04,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:04,233 INFO:     Epoch: 93
2022-11-18 01:42:05,079 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8362865617329424, 'Total loss': 0.8362865617329424} | train loss {'Reaction outcome loss': 0.8248197472383899, 'Total loss': 0.8248197472383899}
2022-11-18 01:42:05,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:05,079 INFO:     Epoch: 94
2022-11-18 01:42:05,871 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8420858572829854, 'Total loss': 0.8420858572829854} | train loss {'Reaction outcome loss': 0.8186067441298116, 'Total loss': 0.8186067441298116}
2022-11-18 01:42:05,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:05,871 INFO:     Epoch: 95
2022-11-18 01:42:06,683 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8318596400997855, 'Total loss': 0.8318596400997855} | train loss {'Reaction outcome loss': 0.8231885099122601, 'Total loss': 0.8231885099122601}
2022-11-18 01:42:06,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:06,684 INFO:     Epoch: 96
2022-11-18 01:42:07,491 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8665483207865194, 'Total loss': 0.8665483207865194} | train loss {'Reaction outcome loss': 0.8215813108028904, 'Total loss': 0.8215813108028904}
2022-11-18 01:42:07,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:07,492 INFO:     Epoch: 97
2022-11-18 01:42:08,290 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8312138664451513, 'Total loss': 0.8312138664451513} | train loss {'Reaction outcome loss': 0.8255219559275335, 'Total loss': 0.8255219559275335}
2022-11-18 01:42:08,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:08,290 INFO:     Epoch: 98
2022-11-18 01:42:09,109 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8401224274526943, 'Total loss': 0.8401224274526943} | train loss {'Reaction outcome loss': 0.8202796974970449, 'Total loss': 0.8202796974970449}
2022-11-18 01:42:09,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:09,109 INFO:     Epoch: 99
2022-11-18 01:42:09,909 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8339078771797094, 'Total loss': 0.8339078771797094} | train loss {'Reaction outcome loss': 0.8192375496991219, 'Total loss': 0.8192375496991219}
2022-11-18 01:42:09,909 INFO:     Best model found after epoch 81 of 100.
2022-11-18 01:42:09,910 INFO:   Done with stage: TRAINING
2022-11-18 01:42:09,910 INFO:   Starting stage: EVALUATION
2022-11-18 01:42:10,030 INFO:   Done with stage: EVALUATION
2022-11-18 01:42:10,030 INFO:   Leaving out SEQ value Fold_6
2022-11-18 01:42:10,043 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 01:42:10,043 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:42:10,721 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:42:10,721 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:42:10,792 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:42:10,792 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:42:10,792 INFO:     No hyperparam tuning for this model
2022-11-18 01:42:10,792 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:42:10,792 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:42:10,793 INFO:     None feature selector for col prot
2022-11-18 01:42:10,793 INFO:     None feature selector for col prot
2022-11-18 01:42:10,793 INFO:     None feature selector for col prot
2022-11-18 01:42:10,794 INFO:     None feature selector for col chem
2022-11-18 01:42:10,794 INFO:     None feature selector for col chem
2022-11-18 01:42:10,794 INFO:     None feature selector for col chem
2022-11-18 01:42:10,794 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:42:10,794 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:42:10,796 INFO:     Number of params in model 168571
2022-11-18 01:42:10,799 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:42:10,799 INFO:   Starting stage: TRAINING
2022-11-18 01:42:10,857 INFO:     Val loss before train {'Reaction outcome loss': 0.9871558560566469, 'Total loss': 0.9871558560566469}
2022-11-18 01:42:10,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:10,857 INFO:     Epoch: 0
2022-11-18 01:42:11,618 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8140229853716764, 'Total loss': 0.8140229853716764} | train loss {'Reaction outcome loss': 0.8844796306183261, 'Total loss': 0.8844796306183261}
2022-11-18 01:42:11,618 INFO:     Found new best model at epoch 0
2022-11-18 01:42:11,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:11,619 INFO:     Epoch: 1
2022-11-18 01:42:12,400 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8087447868152098, 'Total loss': 0.8087447868152098} | train loss {'Reaction outcome loss': 0.8535517224621388, 'Total loss': 0.8535517224621388}
2022-11-18 01:42:12,400 INFO:     Found new best model at epoch 1
2022-11-18 01:42:12,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:12,401 INFO:     Epoch: 2
2022-11-18 01:42:13,253 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7992876944216815, 'Total loss': 0.7992876944216815} | train loss {'Reaction outcome loss': 0.8467283586580907, 'Total loss': 0.8467283586580907}
2022-11-18 01:42:13,253 INFO:     Found new best model at epoch 2
2022-11-18 01:42:13,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:13,254 INFO:     Epoch: 3
2022-11-18 01:42:14,053 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8133382831107486, 'Total loss': 0.8133382831107486} | train loss {'Reaction outcome loss': 0.8391546178008279, 'Total loss': 0.8391546178008279}
2022-11-18 01:42:14,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:14,054 INFO:     Epoch: 4
2022-11-18 01:42:14,878 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8010179400444031, 'Total loss': 0.8010179400444031} | train loss {'Reaction outcome loss': 0.833056783243533, 'Total loss': 0.833056783243533}
2022-11-18 01:42:14,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:14,879 INFO:     Epoch: 5
2022-11-18 01:42:15,703 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7876972380009565, 'Total loss': 0.7876972380009565} | train loss {'Reaction outcome loss': 0.8268424516483661, 'Total loss': 0.8268424516483661}
2022-11-18 01:42:15,703 INFO:     Found new best model at epoch 5
2022-11-18 01:42:15,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:15,704 INFO:     Epoch: 6
2022-11-18 01:42:16,512 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8001178286292336, 'Total loss': 0.8001178286292336} | train loss {'Reaction outcome loss': 0.8283859935979689, 'Total loss': 0.8283859935979689}
2022-11-18 01:42:16,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:16,512 INFO:     Epoch: 7
2022-11-18 01:42:17,312 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7855105190114542, 'Total loss': 0.7855105190114542} | train loss {'Reaction outcome loss': 0.8305918687293606, 'Total loss': 0.8305918687293606}
2022-11-18 01:42:17,312 INFO:     Found new best model at epoch 7
2022-11-18 01:42:17,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:17,313 INFO:     Epoch: 8
2022-11-18 01:42:18,158 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7897661741484295, 'Total loss': 0.7897661741484295} | train loss {'Reaction outcome loss': 0.8274700336398617, 'Total loss': 0.8274700336398617}
2022-11-18 01:42:18,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:18,159 INFO:     Epoch: 9
2022-11-18 01:42:18,954 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.784201557663354, 'Total loss': 0.784201557663354} | train loss {'Reaction outcome loss': 0.8222231105450661, 'Total loss': 0.8222231105450661}
2022-11-18 01:42:18,955 INFO:     Found new best model at epoch 9
2022-11-18 01:42:18,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:18,956 INFO:     Epoch: 10
2022-11-18 01:42:19,766 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7772829776460474, 'Total loss': 0.7772829776460474} | train loss {'Reaction outcome loss': 0.8205071485811665, 'Total loss': 0.8205071485811665}
2022-11-18 01:42:19,766 INFO:     Found new best model at epoch 10
2022-11-18 01:42:19,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:19,767 INFO:     Epoch: 11
2022-11-18 01:42:20,566 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.787116221406243, 'Total loss': 0.787116221406243} | train loss {'Reaction outcome loss': 0.8247113625609106, 'Total loss': 0.8247113625609106}
2022-11-18 01:42:20,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:20,566 INFO:     Epoch: 12
2022-11-18 01:42:21,345 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7832763648845933, 'Total loss': 0.7832763648845933} | train loss {'Reaction outcome loss': 0.8200497443397199, 'Total loss': 0.8200497443397199}
2022-11-18 01:42:21,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:21,345 INFO:     Epoch: 13
2022-11-18 01:42:22,119 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7891056761145592, 'Total loss': 0.7891056761145592} | train loss {'Reaction outcome loss': 0.8269190033597331, 'Total loss': 0.8269190033597331}
2022-11-18 01:42:22,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:22,120 INFO:     Epoch: 14
2022-11-18 01:42:22,926 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7791668555953286, 'Total loss': 0.7791668555953286} | train loss {'Reaction outcome loss': 0.8233395751205183, 'Total loss': 0.8233395751205183}
2022-11-18 01:42:22,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:22,926 INFO:     Epoch: 15
2022-11-18 01:42:23,744 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8189984011379156, 'Total loss': 0.8189984011379156} | train loss {'Reaction outcome loss': 0.818270742532707, 'Total loss': 0.818270742532707}
2022-11-18 01:42:23,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:23,745 INFO:     Epoch: 16
2022-11-18 01:42:24,536 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7788198603825136, 'Total loss': 0.7788198603825136} | train loss {'Reaction outcome loss': 0.8218120064946913, 'Total loss': 0.8218120064946913}
2022-11-18 01:42:24,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:24,536 INFO:     Epoch: 17
2022-11-18 01:42:25,333 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.78083626892079, 'Total loss': 0.78083626892079} | train loss {'Reaction outcome loss': 0.8225937309044022, 'Total loss': 0.8225937309044022}
2022-11-18 01:42:25,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:25,333 INFO:     Epoch: 18
2022-11-18 01:42:26,169 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7806957472454418, 'Total loss': 0.7806957472454418} | train loss {'Reaction outcome loss': 0.8221516856743444, 'Total loss': 0.8221516856743444}
2022-11-18 01:42:26,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:26,169 INFO:     Epoch: 19
2022-11-18 01:42:26,974 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8068091828714717, 'Total loss': 0.8068091828714717} | train loss {'Reaction outcome loss': 0.8148674331605434, 'Total loss': 0.8148674331605434}
2022-11-18 01:42:26,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:26,975 INFO:     Epoch: 20
2022-11-18 01:42:27,768 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7736655602400954, 'Total loss': 0.7736655602400954} | train loss {'Reaction outcome loss': 0.8205899131153861, 'Total loss': 0.8205899131153861}
2022-11-18 01:42:27,769 INFO:     Found new best model at epoch 20
2022-11-18 01:42:27,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:27,769 INFO:     Epoch: 21
2022-11-18 01:42:28,595 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7832896289500323, 'Total loss': 0.7832896289500323} | train loss {'Reaction outcome loss': 0.8157069801443046, 'Total loss': 0.8157069801443046}
2022-11-18 01:42:28,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:28,596 INFO:     Epoch: 22
2022-11-18 01:42:29,418 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.77514959262176, 'Total loss': 0.77514959262176} | train loss {'Reaction outcome loss': 0.8205015631693025, 'Total loss': 0.8205015631693025}
2022-11-18 01:42:29,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:29,418 INFO:     Epoch: 23
2022-11-18 01:42:30,267 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8127365180037238, 'Total loss': 0.8127365180037238} | train loss {'Reaction outcome loss': 0.813284833344721, 'Total loss': 0.813284833344721}
2022-11-18 01:42:30,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:30,268 INFO:     Epoch: 24
2022-11-18 01:42:31,077 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7915055297992446, 'Total loss': 0.7915055297992446} | train loss {'Reaction outcome loss': 0.8222253455990746, 'Total loss': 0.8222253455990746}
2022-11-18 01:42:31,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:31,077 INFO:     Epoch: 25
2022-11-18 01:42:31,856 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7813186923211272, 'Total loss': 0.7813186923211272} | train loss {'Reaction outcome loss': 0.8143782377723725, 'Total loss': 0.8143782377723725}
2022-11-18 01:42:31,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:31,857 INFO:     Epoch: 26
2022-11-18 01:42:32,660 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.771125462922183, 'Total loss': 0.771125462922183} | train loss {'Reaction outcome loss': 0.8195489427495387, 'Total loss': 0.8195489427495387}
2022-11-18 01:42:32,660 INFO:     Found new best model at epoch 26
2022-11-18 01:42:32,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:32,661 INFO:     Epoch: 27
2022-11-18 01:42:33,445 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7755397856235504, 'Total loss': 0.7755397856235504} | train loss {'Reaction outcome loss': 0.814575886293765, 'Total loss': 0.814575886293765}
2022-11-18 01:42:33,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:33,445 INFO:     Epoch: 28
2022-11-18 01:42:34,251 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7757032547484745, 'Total loss': 0.7757032547484745} | train loss {'Reaction outcome loss': 0.8080808193452896, 'Total loss': 0.8080808193452896}
2022-11-18 01:42:34,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:34,252 INFO:     Epoch: 29
2022-11-18 01:42:35,093 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8064735599539496, 'Total loss': 0.8064735599539496} | train loss {'Reaction outcome loss': 0.814649858542027, 'Total loss': 0.814649858542027}
2022-11-18 01:42:35,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:35,093 INFO:     Epoch: 30
2022-11-18 01:42:35,925 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8174086260524663, 'Total loss': 0.8174086260524663} | train loss {'Reaction outcome loss': 0.8164983871242693, 'Total loss': 0.8164983871242693}
2022-11-18 01:42:35,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:35,926 INFO:     Epoch: 31
2022-11-18 01:42:36,724 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7827568155798045, 'Total loss': 0.7827568155798045} | train loss {'Reaction outcome loss': 0.8193451666062878, 'Total loss': 0.8193451666062878}
2022-11-18 01:42:36,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:36,724 INFO:     Epoch: 32
2022-11-18 01:42:37,517 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7944256636229429, 'Total loss': 0.7944256636229429} | train loss {'Reaction outcome loss': 0.8148219462844634, 'Total loss': 0.8148219462844634}
2022-11-18 01:42:37,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:37,517 INFO:     Epoch: 33
2022-11-18 01:42:38,332 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7752216498960148, 'Total loss': 0.7752216498960148} | train loss {'Reaction outcome loss': 0.821812228690232, 'Total loss': 0.821812228690232}
2022-11-18 01:42:38,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:38,334 INFO:     Epoch: 34
2022-11-18 01:42:39,159 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7872323922135613, 'Total loss': 0.7872323922135613} | train loss {'Reaction outcome loss': 0.8167982568904277, 'Total loss': 0.8167982568904277}
2022-11-18 01:42:39,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:39,160 INFO:     Epoch: 35
2022-11-18 01:42:39,937 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7822520184245977, 'Total loss': 0.7822520184245977} | train loss {'Reaction outcome loss': 0.8182227367595318, 'Total loss': 0.8182227367595318}
2022-11-18 01:42:39,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:39,938 INFO:     Epoch: 36
2022-11-18 01:42:40,743 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7953674007545818, 'Total loss': 0.7953674007545818} | train loss {'Reaction outcome loss': 0.8165134190311355, 'Total loss': 0.8165134190311355}
2022-11-18 01:42:40,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:40,744 INFO:     Epoch: 37
2022-11-18 01:42:41,559 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7781550992618907, 'Total loss': 0.7781550992618907} | train loss {'Reaction outcome loss': 0.8163459697558034, 'Total loss': 0.8163459697558034}
2022-11-18 01:42:41,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:41,559 INFO:     Epoch: 38
2022-11-18 01:42:42,322 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7922477722167969, 'Total loss': 0.7922477722167969} | train loss {'Reaction outcome loss': 0.812703795250385, 'Total loss': 0.812703795250385}
2022-11-18 01:42:42,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:42,322 INFO:     Epoch: 39
2022-11-18 01:42:43,120 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7744096490469846, 'Total loss': 0.7744096490469846} | train loss {'Reaction outcome loss': 0.8167836476237543, 'Total loss': 0.8167836476237543}
2022-11-18 01:42:43,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:43,121 INFO:     Epoch: 40
2022-11-18 01:42:43,921 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7732577730308879, 'Total loss': 0.7732577730308879} | train loss {'Reaction outcome loss': 0.8158826131013132, 'Total loss': 0.8158826131013132}
2022-11-18 01:42:43,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:43,921 INFO:     Epoch: 41
2022-11-18 01:42:44,728 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7872584441846068, 'Total loss': 0.7872584441846068} | train loss {'Reaction outcome loss': 0.8210060541187564, 'Total loss': 0.8210060541187564}
2022-11-18 01:42:44,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:44,728 INFO:     Epoch: 42
2022-11-18 01:42:45,577 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7730522487651218, 'Total loss': 0.7730522487651218} | train loss {'Reaction outcome loss': 0.8180057072351056, 'Total loss': 0.8180057072351056}
2022-11-18 01:42:45,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:45,577 INFO:     Epoch: 43
2022-11-18 01:42:46,378 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7966436262835156, 'Total loss': 0.7966436262835156} | train loss {'Reaction outcome loss': 0.818624554262046, 'Total loss': 0.818624554262046}
2022-11-18 01:42:46,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:46,378 INFO:     Epoch: 44
2022-11-18 01:42:47,196 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7865253233096816, 'Total loss': 0.7865253233096816} | train loss {'Reaction outcome loss': 0.8174244814342068, 'Total loss': 0.8174244814342068}
2022-11-18 01:42:47,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:47,196 INFO:     Epoch: 45
2022-11-18 01:42:48,039 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7740171097896316, 'Total loss': 0.7740171097896316} | train loss {'Reaction outcome loss': 0.8210976305267503, 'Total loss': 0.8210976305267503}
2022-11-18 01:42:48,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:48,039 INFO:     Epoch: 46
2022-11-18 01:42:48,852 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7801108902150934, 'Total loss': 0.7801108902150934} | train loss {'Reaction outcome loss': 0.8163611455069434, 'Total loss': 0.8163611455069434}
2022-11-18 01:42:48,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:48,852 INFO:     Epoch: 47
2022-11-18 01:42:49,693 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7889996157451109, 'Total loss': 0.7889996157451109} | train loss {'Reaction outcome loss': 0.8150757911705202, 'Total loss': 0.8150757911705202}
2022-11-18 01:42:49,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:49,694 INFO:     Epoch: 48
2022-11-18 01:42:50,534 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7891428524797613, 'Total loss': 0.7891428524797613} | train loss {'Reaction outcome loss': 0.8190811356950191, 'Total loss': 0.8190811356950191}
2022-11-18 01:42:50,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:50,535 INFO:     Epoch: 49
2022-11-18 01:42:51,336 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7961669733578508, 'Total loss': 0.7961669733578508} | train loss {'Reaction outcome loss': 0.814807309859222, 'Total loss': 0.814807309859222}
2022-11-18 01:42:51,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:51,336 INFO:     Epoch: 50
2022-11-18 01:42:52,161 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7656032754616304, 'Total loss': 0.7656032754616304} | train loss {'Reaction outcome loss': 0.8113225247831114, 'Total loss': 0.8113225247831114}
2022-11-18 01:42:52,161 INFO:     Found new best model at epoch 50
2022-11-18 01:42:52,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:52,162 INFO:     Epoch: 51
2022-11-18 01:42:52,954 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7794862755320289, 'Total loss': 0.7794862755320289} | train loss {'Reaction outcome loss': 0.8131296796904456, 'Total loss': 0.8131296796904456}
2022-11-18 01:42:52,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:52,954 INFO:     Epoch: 52
2022-11-18 01:42:53,729 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7835646542635831, 'Total loss': 0.7835646542635831} | train loss {'Reaction outcome loss': 0.8094570909536654, 'Total loss': 0.8094570909536654}
2022-11-18 01:42:53,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:53,729 INFO:     Epoch: 53
2022-11-18 01:42:54,538 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7751876264810562, 'Total loss': 0.7751876264810562} | train loss {'Reaction outcome loss': 0.8170350603759289, 'Total loss': 0.8170350603759289}
2022-11-18 01:42:54,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:54,538 INFO:     Epoch: 54
2022-11-18 01:42:55,353 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7838341431184248, 'Total loss': 0.7838341431184248} | train loss {'Reaction outcome loss': 0.8142126289106184, 'Total loss': 0.8142126289106184}
2022-11-18 01:42:55,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:55,353 INFO:     Epoch: 55
2022-11-18 01:42:56,216 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.789368945766579, 'Total loss': 0.789368945766579} | train loss {'Reaction outcome loss': 0.8149613908702328, 'Total loss': 0.8149613908702328}
2022-11-18 01:42:56,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:56,216 INFO:     Epoch: 56
2022-11-18 01:42:57,018 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8004040237177502, 'Total loss': 0.8004040237177502} | train loss {'Reaction outcome loss': 0.8093399696292416, 'Total loss': 0.8093399696292416}
2022-11-18 01:42:57,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:57,018 INFO:     Epoch: 57
2022-11-18 01:42:57,834 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7876646125858481, 'Total loss': 0.7876646125858481} | train loss {'Reaction outcome loss': 0.8193959665875281, 'Total loss': 0.8193959665875281}
2022-11-18 01:42:57,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:57,834 INFO:     Epoch: 58
2022-11-18 01:42:58,613 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8018897087736563, 'Total loss': 0.8018897087736563} | train loss {'Reaction outcome loss': 0.8161634865307039, 'Total loss': 0.8161634865307039}
2022-11-18 01:42:58,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:58,613 INFO:     Epoch: 59
2022-11-18 01:42:59,431 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7810740213502537, 'Total loss': 0.7810740213502537} | train loss {'Reaction outcome loss': 0.8199985453919056, 'Total loss': 0.8199985453919056}
2022-11-18 01:42:59,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:42:59,431 INFO:     Epoch: 60
2022-11-18 01:43:00,222 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.765993676402352, 'Total loss': 0.765993676402352} | train loss {'Reaction outcome loss': 0.8133618471122557, 'Total loss': 0.8133618471122557}
2022-11-18 01:43:00,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:00,222 INFO:     Epoch: 61
2022-11-18 01:43:00,977 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8057639951055701, 'Total loss': 0.8057639951055701} | train loss {'Reaction outcome loss': 0.8124187214960975, 'Total loss': 0.8124187214960975}
2022-11-18 01:43:00,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:00,977 INFO:     Epoch: 62
2022-11-18 01:43:01,778 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7828068110075864, 'Total loss': 0.7828068110075864} | train loss {'Reaction outcome loss': 0.8134304379984256, 'Total loss': 0.8134304379984256}
2022-11-18 01:43:01,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:01,778 INFO:     Epoch: 63
2022-11-18 01:43:02,553 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7731910673054782, 'Total loss': 0.7731910673054782} | train loss {'Reaction outcome loss': 0.8094724094675433, 'Total loss': 0.8094724094675433}
2022-11-18 01:43:02,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:02,554 INFO:     Epoch: 64
2022-11-18 01:43:03,339 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7847144122828137, 'Total loss': 0.7847144122828137} | train loss {'Reaction outcome loss': 0.8146164334349094, 'Total loss': 0.8146164334349094}
2022-11-18 01:43:03,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:03,339 INFO:     Epoch: 65
2022-11-18 01:43:04,114 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7732887654141947, 'Total loss': 0.7732887654141947} | train loss {'Reaction outcome loss': 0.8143181780413273, 'Total loss': 0.8143181780413273}
2022-11-18 01:43:04,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:04,114 INFO:     Epoch: 66
2022-11-18 01:43:04,888 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.791557136584412, 'Total loss': 0.791557136584412} | train loss {'Reaction outcome loss': 0.8126001150136993, 'Total loss': 0.8126001150136993}
2022-11-18 01:43:04,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:04,888 INFO:     Epoch: 67
2022-11-18 01:43:05,669 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8435210707512769, 'Total loss': 0.8435210707512769} | train loss {'Reaction outcome loss': 0.8186807164982441, 'Total loss': 0.8186807164982441}
2022-11-18 01:43:05,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:05,670 INFO:     Epoch: 68
2022-11-18 01:43:06,478 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8043062192472544, 'Total loss': 0.8043062192472544} | train loss {'Reaction outcome loss': 0.8124626046347041, 'Total loss': 0.8124626046347041}
2022-11-18 01:43:06,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:06,478 INFO:     Epoch: 69
2022-11-18 01:43:07,275 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7736509862271223, 'Total loss': 0.7736509862271223} | train loss {'Reaction outcome loss': 0.8094007946070163, 'Total loss': 0.8094007946070163}
2022-11-18 01:43:07,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:07,275 INFO:     Epoch: 70
2022-11-18 01:43:08,063 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7814967862584374, 'Total loss': 0.7814967862584374} | train loss {'Reaction outcome loss': 0.8132315177109933, 'Total loss': 0.8132315177109933}
2022-11-18 01:43:08,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:08,063 INFO:     Epoch: 71
2022-11-18 01:43:08,852 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8104294355620038, 'Total loss': 0.8104294355620038} | train loss {'Reaction outcome loss': 0.8091257321498087, 'Total loss': 0.8091257321498087}
2022-11-18 01:43:08,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:08,853 INFO:     Epoch: 72
2022-11-18 01:43:09,628 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7770689549771223, 'Total loss': 0.7770689549771223} | train loss {'Reaction outcome loss': 0.8159697379075712, 'Total loss': 0.8159697379075712}
2022-11-18 01:43:09,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:09,629 INFO:     Epoch: 73
2022-11-18 01:43:10,407 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7637053673917596, 'Total loss': 0.7637053673917596} | train loss {'Reaction outcome loss': 0.8142087888573447, 'Total loss': 0.8142087888573447}
2022-11-18 01:43:10,407 INFO:     Found new best model at epoch 73
2022-11-18 01:43:10,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:10,408 INFO:     Epoch: 74
2022-11-18 01:43:11,180 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7700350203297355, 'Total loss': 0.7700350203297355} | train loss {'Reaction outcome loss': 0.8140291827580621, 'Total loss': 0.8140291827580621}
2022-11-18 01:43:11,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:11,180 INFO:     Epoch: 75
2022-11-18 01:43:11,966 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8094240725040436, 'Total loss': 0.8094240725040436} | train loss {'Reaction outcome loss': 0.8143216192481979, 'Total loss': 0.8143216192481979}
2022-11-18 01:43:11,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:11,966 INFO:     Epoch: 76
2022-11-18 01:43:12,759 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7776407077908516, 'Total loss': 0.7776407077908516} | train loss {'Reaction outcome loss': 0.8161839946143089, 'Total loss': 0.8161839946143089}
2022-11-18 01:43:12,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:12,759 INFO:     Epoch: 77
2022-11-18 01:43:13,539 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8125030174851418, 'Total loss': 0.8125030174851418} | train loss {'Reaction outcome loss': 0.8112255402149693, 'Total loss': 0.8112255402149693}
2022-11-18 01:43:13,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:13,539 INFO:     Epoch: 78
2022-11-18 01:43:14,328 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.770381969484416, 'Total loss': 0.770381969484416} | train loss {'Reaction outcome loss': 0.8144270271783874, 'Total loss': 0.8144270271783874}
2022-11-18 01:43:14,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:14,328 INFO:     Epoch: 79
2022-11-18 01:43:15,115 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7936678948727521, 'Total loss': 0.7936678948727521} | train loss {'Reaction outcome loss': 0.8123121020053664, 'Total loss': 0.8123121020053664}
2022-11-18 01:43:15,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:15,115 INFO:     Epoch: 80
2022-11-18 01:43:15,891 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7894585538994182, 'Total loss': 0.7894585538994182} | train loss {'Reaction outcome loss': 0.8118613351496958, 'Total loss': 0.8118613351496958}
2022-11-18 01:43:15,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:15,892 INFO:     Epoch: 81
2022-11-18 01:43:16,673 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7790208485993472, 'Total loss': 0.7790208485993472} | train loss {'Reaction outcome loss': 0.8133842166393034, 'Total loss': 0.8133842166393034}
2022-11-18 01:43:16,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:16,674 INFO:     Epoch: 82
2022-11-18 01:43:17,469 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7734731903130357, 'Total loss': 0.7734731903130357} | train loss {'Reaction outcome loss': 0.8133728162896249, 'Total loss': 0.8133728162896249}
2022-11-18 01:43:17,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:17,470 INFO:     Epoch: 83
2022-11-18 01:43:18,233 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.787490422075445, 'Total loss': 0.787490422075445} | train loss {'Reaction outcome loss': 0.8112361044172318, 'Total loss': 0.8112361044172318}
2022-11-18 01:43:18,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:18,234 INFO:     Epoch: 84
2022-11-18 01:43:19,017 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.788285069167614, 'Total loss': 0.788285069167614} | train loss {'Reaction outcome loss': 0.8122273174024397, 'Total loss': 0.8122273174024397}
2022-11-18 01:43:19,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:19,017 INFO:     Epoch: 85
2022-11-18 01:43:19,801 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.795746086673303, 'Total loss': 0.795746086673303} | train loss {'Reaction outcome loss': 0.8170483643489499, 'Total loss': 0.8170483643489499}
2022-11-18 01:43:19,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:19,802 INFO:     Epoch: 86
2022-11-18 01:43:20,575 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7772741161964156, 'Total loss': 0.7772741161964156} | train loss {'Reaction outcome loss': 0.8161306532640611, 'Total loss': 0.8161306532640611}
2022-11-18 01:43:20,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:20,575 INFO:     Epoch: 87
2022-11-18 01:43:21,372 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7780531563542106, 'Total loss': 0.7780531563542106} | train loss {'Reaction outcome loss': 0.8104566928119429, 'Total loss': 0.8104566928119429}
2022-11-18 01:43:21,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:21,374 INFO:     Epoch: 88
2022-11-18 01:43:22,149 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7692953280427239, 'Total loss': 0.7692953280427239} | train loss {'Reaction outcome loss': 0.8099592080520045, 'Total loss': 0.8099592080520045}
2022-11-18 01:43:22,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:22,149 INFO:     Epoch: 89
2022-11-18 01:43:22,929 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7758752270178362, 'Total loss': 0.7758752270178362} | train loss {'Reaction outcome loss': 0.811903340561736, 'Total loss': 0.811903340561736}
2022-11-18 01:43:22,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:22,929 INFO:     Epoch: 90
2022-11-18 01:43:23,724 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7885207811539824, 'Total loss': 0.7885207811539824} | train loss {'Reaction outcome loss': 0.8154876073521953, 'Total loss': 0.8154876073521953}
2022-11-18 01:43:23,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:23,725 INFO:     Epoch: 91
2022-11-18 01:43:24,495 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7699195458130403, 'Total loss': 0.7699195458130403} | train loss {'Reaction outcome loss': 0.8158687409614364, 'Total loss': 0.8158687409614364}
2022-11-18 01:43:24,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:24,495 INFO:     Epoch: 92
2022-11-18 01:43:25,268 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7736718986522068, 'Total loss': 0.7736718986522068} | train loss {'Reaction outcome loss': 0.8111399378507368, 'Total loss': 0.8111399378507368}
2022-11-18 01:43:25,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:25,268 INFO:     Epoch: 93
2022-11-18 01:43:26,037 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7767015025019646, 'Total loss': 0.7767015025019646} | train loss {'Reaction outcome loss': 0.8086026366199216, 'Total loss': 0.8086026366199216}
2022-11-18 01:43:26,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:26,038 INFO:     Epoch: 94
2022-11-18 01:43:26,816 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7766535485332663, 'Total loss': 0.7766535485332663} | train loss {'Reaction outcome loss': 0.8122763633728027, 'Total loss': 0.8122763633728027}
2022-11-18 01:43:26,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:26,816 INFO:     Epoch: 95
2022-11-18 01:43:27,638 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7655803507024591, 'Total loss': 0.7655803507024591} | train loss {'Reaction outcome loss': 0.8093880949722182, 'Total loss': 0.8093880949722182}
2022-11-18 01:43:27,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:27,638 INFO:     Epoch: 96
2022-11-18 01:43:28,423 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7761332203041423, 'Total loss': 0.7761332203041423} | train loss {'Reaction outcome loss': 0.81786861066376, 'Total loss': 0.81786861066376}
2022-11-18 01:43:28,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:28,424 INFO:     Epoch: 97
2022-11-18 01:43:29,206 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7728341695937243, 'Total loss': 0.7728341695937243} | train loss {'Reaction outcome loss': 0.8129660826056234, 'Total loss': 0.8129660826056234}
2022-11-18 01:43:29,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:29,206 INFO:     Epoch: 98
2022-11-18 01:43:29,970 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7679809074510228, 'Total loss': 0.7679809074510228} | train loss {'Reaction outcome loss': 0.8108710765598282, 'Total loss': 0.8108710765598282}
2022-11-18 01:43:29,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:29,971 INFO:     Epoch: 99
2022-11-18 01:43:30,760 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7742099193009463, 'Total loss': 0.7742099193009463} | train loss {'Reaction outcome loss': 0.8092409332673396, 'Total loss': 0.8092409332673396}
2022-11-18 01:43:30,760 INFO:     Best model found after epoch 74 of 100.
2022-11-18 01:43:30,761 INFO:   Done with stage: TRAINING
2022-11-18 01:43:30,761 INFO:   Starting stage: EVALUATION
2022-11-18 01:43:30,880 INFO:   Done with stage: EVALUATION
2022-11-18 01:43:30,880 INFO:   Leaving out SEQ value Fold_7
2022-11-18 01:43:30,893 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-18 01:43:30,893 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:43:31,561 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:43:31,561 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:43:31,631 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:43:31,631 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:43:31,631 INFO:     No hyperparam tuning for this model
2022-11-18 01:43:31,631 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:43:31,631 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:43:31,632 INFO:     None feature selector for col prot
2022-11-18 01:43:31,632 INFO:     None feature selector for col prot
2022-11-18 01:43:31,632 INFO:     None feature selector for col prot
2022-11-18 01:43:31,633 INFO:     None feature selector for col chem
2022-11-18 01:43:31,633 INFO:     None feature selector for col chem
2022-11-18 01:43:31,633 INFO:     None feature selector for col chem
2022-11-18 01:43:31,633 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:43:31,633 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:43:31,634 INFO:     Number of params in model 168571
2022-11-18 01:43:31,638 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:43:31,638 INFO:   Starting stage: TRAINING
2022-11-18 01:43:31,694 INFO:     Val loss before train {'Reaction outcome loss': 1.0394145250320435, 'Total loss': 1.0394145250320435}
2022-11-18 01:43:31,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:31,694 INFO:     Epoch: 0
2022-11-18 01:43:32,466 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8227917995563773, 'Total loss': 0.8227917995563773} | train loss {'Reaction outcome loss': 0.8630034262772466, 'Total loss': 0.8630034262772466}
2022-11-18 01:43:32,466 INFO:     Found new best model at epoch 0
2022-11-18 01:43:32,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:32,467 INFO:     Epoch: 1
2022-11-18 01:43:33,257 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8589800568514092, 'Total loss': 0.8589800568514092} | train loss {'Reaction outcome loss': 0.8319829246792637, 'Total loss': 0.8319829246792637}
2022-11-18 01:43:33,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:33,257 INFO:     Epoch: 2
2022-11-18 01:43:34,022 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8445691189100576, 'Total loss': 0.8445691189100576} | train loss {'Reaction outcome loss': 0.8281626250655925, 'Total loss': 0.8281626250655925}
2022-11-18 01:43:34,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:34,023 INFO:     Epoch: 3
2022-11-18 01:43:34,775 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8342586977537289, 'Total loss': 0.8342586977537289} | train loss {'Reaction outcome loss': 0.8232716523477288, 'Total loss': 0.8232716523477288}
2022-11-18 01:43:34,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:34,776 INFO:     Epoch: 4
2022-11-18 01:43:35,537 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8193162042041158, 'Total loss': 0.8193162042041158} | train loss {'Reaction outcome loss': 0.8199906919579036, 'Total loss': 0.8199906919579036}
2022-11-18 01:43:35,537 INFO:     Found new best model at epoch 4
2022-11-18 01:43:35,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:35,538 INFO:     Epoch: 5
2022-11-18 01:43:36,315 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.820540726184845, 'Total loss': 0.820540726184845} | train loss {'Reaction outcome loss': 0.815116187343832, 'Total loss': 0.815116187343832}
2022-11-18 01:43:36,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:36,315 INFO:     Epoch: 6
2022-11-18 01:43:37,075 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8205257120520569, 'Total loss': 0.8205257120520569} | train loss {'Reaction outcome loss': 0.8147564266548782, 'Total loss': 0.8147564266548782}
2022-11-18 01:43:37,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:37,075 INFO:     Epoch: 7
2022-11-18 01:43:37,852 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8225102556306262, 'Total loss': 0.8225102556306262} | train loss {'Reaction outcome loss': 0.8098622518973272, 'Total loss': 0.8098622518973272}
2022-11-18 01:43:37,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:37,852 INFO:     Epoch: 8
2022-11-18 01:43:38,643 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.815238076587056, 'Total loss': 0.815238076587056} | train loss {'Reaction outcome loss': 0.809302979927571, 'Total loss': 0.809302979927571}
2022-11-18 01:43:38,643 INFO:     Found new best model at epoch 8
2022-11-18 01:43:38,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:38,644 INFO:     Epoch: 9
2022-11-18 01:43:39,452 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.823291328064231, 'Total loss': 0.823291328064231} | train loss {'Reaction outcome loss': 0.8032589585321849, 'Total loss': 0.8032589585321849}
2022-11-18 01:43:39,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:39,453 INFO:     Epoch: 10
2022-11-18 01:43:40,273 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8198090500609819, 'Total loss': 0.8198090500609819} | train loss {'Reaction outcome loss': 0.8080450081434406, 'Total loss': 0.8080450081434406}
2022-11-18 01:43:40,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:40,274 INFO:     Epoch: 11
2022-11-18 01:43:41,051 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8346363839715026, 'Total loss': 0.8346363839715026} | train loss {'Reaction outcome loss': 0.8096551180618708, 'Total loss': 0.8096551180618708}
2022-11-18 01:43:41,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:41,052 INFO:     Epoch: 12
2022-11-18 01:43:41,850 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8486084050910417, 'Total loss': 0.8486084050910417} | train loss {'Reaction outcome loss': 0.8076070979481837, 'Total loss': 0.8076070979481837}
2022-11-18 01:43:41,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:41,851 INFO:     Epoch: 13
2022-11-18 01:43:42,603 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8119259483592455, 'Total loss': 0.8119259483592455} | train loss {'Reaction outcome loss': 0.8079804269993891, 'Total loss': 0.8079804269993891}
2022-11-18 01:43:42,603 INFO:     Found new best model at epoch 13
2022-11-18 01:43:42,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:42,604 INFO:     Epoch: 14
2022-11-18 01:43:43,439 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8131360744321069, 'Total loss': 0.8131360744321069} | train loss {'Reaction outcome loss': 0.8044535013251617, 'Total loss': 0.8044535013251617}
2022-11-18 01:43:43,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:43,439 INFO:     Epoch: 15
2022-11-18 01:43:44,224 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8047379470148752, 'Total loss': 0.8047379470148752} | train loss {'Reaction outcome loss': 0.810406002842012, 'Total loss': 0.810406002842012}
2022-11-18 01:43:44,224 INFO:     Found new best model at epoch 15
2022-11-18 01:43:44,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:44,225 INFO:     Epoch: 16
2022-11-18 01:43:45,056 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8344476722007574, 'Total loss': 0.8344476722007574} | train loss {'Reaction outcome loss': 0.7977438826785713, 'Total loss': 0.7977438826785713}
2022-11-18 01:43:45,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:45,056 INFO:     Epoch: 17
2022-11-18 01:43:45,848 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8123974100101826, 'Total loss': 0.8123974100101826} | train loss {'Reaction outcome loss': 0.8070001542323926, 'Total loss': 0.8070001542323926}
2022-11-18 01:43:45,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:45,848 INFO:     Epoch: 18
2022-11-18 01:43:46,613 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8022841000279715, 'Total loss': 0.8022841000279715} | train loss {'Reaction outcome loss': 0.80137015659301, 'Total loss': 0.80137015659301}
2022-11-18 01:43:46,613 INFO:     Found new best model at epoch 18
2022-11-18 01:43:46,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:46,614 INFO:     Epoch: 19
2022-11-18 01:43:47,403 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8092465830403704, 'Total loss': 0.8092465830403704} | train loss {'Reaction outcome loss': 0.808812708517567, 'Total loss': 0.808812708517567}
2022-11-18 01:43:47,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:47,403 INFO:     Epoch: 20
2022-11-18 01:43:48,211 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8189930472263071, 'Total loss': 0.8189930472263071} | train loss {'Reaction outcome loss': 0.806120554321125, 'Total loss': 0.806120554321125}
2022-11-18 01:43:48,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:48,211 INFO:     Epoch: 21
2022-11-18 01:43:49,048 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8248447443163672, 'Total loss': 0.8248447443163672} | train loss {'Reaction outcome loss': 0.8056064516794487, 'Total loss': 0.8056064516794487}
2022-11-18 01:43:49,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:49,048 INFO:     Epoch: 22
2022-11-18 01:43:49,845 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8082377709621607, 'Total loss': 0.8082377709621607} | train loss {'Reaction outcome loss': 0.8064803079259201, 'Total loss': 0.8064803079259201}
2022-11-18 01:43:49,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:49,846 INFO:     Epoch: 23
2022-11-18 01:43:50,621 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7989489955957546, 'Total loss': 0.7989489955957546} | train loss {'Reaction outcome loss': 0.7998760299848728, 'Total loss': 0.7998760299848728}
2022-11-18 01:43:50,621 INFO:     Found new best model at epoch 23
2022-11-18 01:43:50,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:50,622 INFO:     Epoch: 24
2022-11-18 01:43:51,376 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8048205223194388, 'Total loss': 0.8048205223194388} | train loss {'Reaction outcome loss': 0.8054522650896526, 'Total loss': 0.8054522650896526}
2022-11-18 01:43:51,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:51,377 INFO:     Epoch: 25
2022-11-18 01:43:52,151 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8052261229171309, 'Total loss': 0.8052261229171309} | train loss {'Reaction outcome loss': 0.8035800533949352, 'Total loss': 0.8035800533949352}
2022-11-18 01:43:52,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:52,151 INFO:     Epoch: 26
2022-11-18 01:43:52,980 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8125964638798736, 'Total loss': 0.8125964638798736} | train loss {'Reaction outcome loss': 0.7981331744154946, 'Total loss': 0.7981331744154946}
2022-11-18 01:43:52,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:52,981 INFO:     Epoch: 27
2022-11-18 01:43:53,795 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8089952815410703, 'Total loss': 0.8089952815410703} | train loss {'Reaction outcome loss': 0.8030226731398067, 'Total loss': 0.8030226731398067}
2022-11-18 01:43:53,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:53,795 INFO:     Epoch: 28
2022-11-18 01:43:54,645 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7987294169359429, 'Total loss': 0.7987294169359429} | train loss {'Reaction outcome loss': 0.8009471727199242, 'Total loss': 0.8009471727199242}
2022-11-18 01:43:54,645 INFO:     Found new best model at epoch 28
2022-11-18 01:43:54,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:54,646 INFO:     Epoch: 29
2022-11-18 01:43:55,448 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8057806505713352, 'Total loss': 0.8057806505713352} | train loss {'Reaction outcome loss': 0.8020986024229253, 'Total loss': 0.8020986024229253}
2022-11-18 01:43:55,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:55,448 INFO:     Epoch: 30
2022-11-18 01:43:56,243 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8290328522061192, 'Total loss': 0.8290328522061192} | train loss {'Reaction outcome loss': 0.8012544592140151, 'Total loss': 0.8012544592140151}
2022-11-18 01:43:56,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:56,243 INFO:     Epoch: 31
2022-11-18 01:43:56,997 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8117154899031617, 'Total loss': 0.8117154899031617} | train loss {'Reaction outcome loss': 0.803575476051354, 'Total loss': 0.803575476051354}
2022-11-18 01:43:56,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:56,997 INFO:     Epoch: 32
2022-11-18 01:43:57,804 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8166866011397783, 'Total loss': 0.8166866011397783} | train loss {'Reaction outcome loss': 0.8003397139369465, 'Total loss': 0.8003397139369465}
2022-11-18 01:43:57,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:57,804 INFO:     Epoch: 33
2022-11-18 01:43:58,594 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8234246137530304, 'Total loss': 0.8234246137530304} | train loss {'Reaction outcome loss': 0.7994405665114278, 'Total loss': 0.7994405665114278}
2022-11-18 01:43:58,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:58,595 INFO:     Epoch: 34
2022-11-18 01:43:59,390 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8088354662407277, 'Total loss': 0.8088354662407277} | train loss {'Reaction outcome loss': 0.8011681725744342, 'Total loss': 0.8011681725744342}
2022-11-18 01:43:59,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:43:59,390 INFO:     Epoch: 35
2022-11-18 01:44:00,192 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7971614529920179, 'Total loss': 0.7971614529920179} | train loss {'Reaction outcome loss': 0.8020449637389574, 'Total loss': 0.8020449637389574}
2022-11-18 01:44:00,192 INFO:     Found new best model at epoch 35
2022-11-18 01:44:00,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:00,193 INFO:     Epoch: 36
2022-11-18 01:44:00,976 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8285405178402745, 'Total loss': 0.8285405178402745} | train loss {'Reaction outcome loss': 0.7974002803446817, 'Total loss': 0.7974002803446817}
2022-11-18 01:44:00,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:00,976 INFO:     Epoch: 37
2022-11-18 01:44:01,743 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8100567647190982, 'Total loss': 0.8100567647190982} | train loss {'Reaction outcome loss': 0.8006352272922875, 'Total loss': 0.8006352272922875}
2022-11-18 01:44:01,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:01,743 INFO:     Epoch: 38
2022-11-18 01:44:02,555 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8078151372976081, 'Total loss': 0.8078151372976081} | train loss {'Reaction outcome loss': 0.7987901719867206, 'Total loss': 0.7987901719867206}
2022-11-18 01:44:02,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:02,556 INFO:     Epoch: 39
2022-11-18 01:44:03,376 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8068898535052011, 'Total loss': 0.8068898535052011} | train loss {'Reaction outcome loss': 0.8058806679776458, 'Total loss': 0.8058806679776458}
2022-11-18 01:44:03,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:03,376 INFO:     Epoch: 40
2022-11-18 01:44:04,189 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8038442543772764, 'Total loss': 0.8038442543772764} | train loss {'Reaction outcome loss': 0.7983897082874032, 'Total loss': 0.7983897082874032}
2022-11-18 01:44:04,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:04,190 INFO:     Epoch: 41
2022-11-18 01:44:05,001 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8042815286059712, 'Total loss': 0.8042815286059712} | train loss {'Reaction outcome loss': 0.7987133339047432, 'Total loss': 0.7987133339047432}
2022-11-18 01:44:05,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:05,003 INFO:     Epoch: 42
2022-11-18 01:44:05,808 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8109995681186055, 'Total loss': 0.8109995681186055} | train loss {'Reaction outcome loss': 0.7993825454203809, 'Total loss': 0.7993825454203809}
2022-11-18 01:44:05,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:05,808 INFO:     Epoch: 43
2022-11-18 01:44:06,642 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7976510018803352, 'Total loss': 0.7976510018803352} | train loss {'Reaction outcome loss': 0.8002293185621011, 'Total loss': 0.8002293185621011}
2022-11-18 01:44:06,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:06,643 INFO:     Epoch: 44
2022-11-18 01:44:07,417 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8209564269975175, 'Total loss': 0.8209564269975175} | train loss {'Reaction outcome loss': 0.7944840678914649, 'Total loss': 0.7944840678914649}
2022-11-18 01:44:07,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:07,417 INFO:     Epoch: 45
2022-11-18 01:44:08,198 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.810967049626417, 'Total loss': 0.810967049626417} | train loss {'Reaction outcome loss': 0.8027330400025259, 'Total loss': 0.8027330400025259}
2022-11-18 01:44:08,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:08,198 INFO:     Epoch: 46
2022-11-18 01:44:09,018 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8132644683815712, 'Total loss': 0.8132644683815712} | train loss {'Reaction outcome loss': 0.7974240210701208, 'Total loss': 0.7974240210701208}
2022-11-18 01:44:09,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:09,018 INFO:     Epoch: 47
2022-11-18 01:44:09,765 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.817509627619455, 'Total loss': 0.817509627619455} | train loss {'Reaction outcome loss': 0.8009701054848608, 'Total loss': 0.8009701054848608}
2022-11-18 01:44:09,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:09,765 INFO:     Epoch: 48
2022-11-18 01:44:10,548 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7944636358771213, 'Total loss': 0.7944636358771213} | train loss {'Reaction outcome loss': 0.7949999233738321, 'Total loss': 0.7949999233738321}
2022-11-18 01:44:10,548 INFO:     Found new best model at epoch 48
2022-11-18 01:44:10,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:10,549 INFO:     Epoch: 49
2022-11-18 01:44:11,391 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8296762635541517, 'Total loss': 0.8296762635541517} | train loss {'Reaction outcome loss': 0.7972243494186245, 'Total loss': 0.7972243494186245}
2022-11-18 01:44:11,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:11,392 INFO:     Epoch: 50
2022-11-18 01:44:12,231 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8114575494167416, 'Total loss': 0.8114575494167416} | train loss {'Reaction outcome loss': 0.8011952931763696, 'Total loss': 0.8011952931763696}
2022-11-18 01:44:12,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:12,231 INFO:     Epoch: 51
2022-11-18 01:44:13,001 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7882968034855155, 'Total loss': 0.7882968034855155} | train loss {'Reaction outcome loss': 0.7945293874525633, 'Total loss': 0.7945293874525633}
2022-11-18 01:44:13,002 INFO:     Found new best model at epoch 51
2022-11-18 01:44:13,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:13,003 INFO:     Epoch: 52
2022-11-18 01:44:13,799 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8199157167312711, 'Total loss': 0.8199157167312711} | train loss {'Reaction outcome loss': 0.7985879931537831, 'Total loss': 0.7985879931537831}
2022-11-18 01:44:13,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:13,799 INFO:     Epoch: 53
2022-11-18 01:44:14,592 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8211598368578179, 'Total loss': 0.8211598368578179} | train loss {'Reaction outcome loss': 0.7971148013335759, 'Total loss': 0.7971148013335759}
2022-11-18 01:44:14,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:14,593 INFO:     Epoch: 54
2022-11-18 01:44:15,384 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7957224637963051, 'Total loss': 0.7957224637963051} | train loss {'Reaction outcome loss': 0.7944641649478772, 'Total loss': 0.7944641649478772}
2022-11-18 01:44:15,384 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:15,384 INFO:     Epoch: 55
2022-11-18 01:44:16,180 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8092384352240451, 'Total loss': 0.8092384352240451} | train loss {'Reaction outcome loss': 0.7945199293679879, 'Total loss': 0.7945199293679879}
2022-11-18 01:44:16,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:16,180 INFO:     Epoch: 56
2022-11-18 01:44:16,960 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8300635232481846, 'Total loss': 0.8300635232481846} | train loss {'Reaction outcome loss': 0.7987659304845528, 'Total loss': 0.7987659304845528}
2022-11-18 01:44:16,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:16,961 INFO:     Epoch: 57
2022-11-18 01:44:17,759 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8008012328036996, 'Total loss': 0.8008012328036996} | train loss {'Reaction outcome loss': 0.7968066999169646, 'Total loss': 0.7968066999169646}
2022-11-18 01:44:17,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:17,759 INFO:     Epoch: 58
2022-11-18 01:44:18,571 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8018884333067162, 'Total loss': 0.8018884333067162} | train loss {'Reaction outcome loss': 0.7933107251759435, 'Total loss': 0.7933107251759435}
2022-11-18 01:44:18,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:18,571 INFO:     Epoch: 59
2022-11-18 01:44:19,402 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7917158638322076, 'Total loss': 0.7917158638322076} | train loss {'Reaction outcome loss': 0.7913471339423148, 'Total loss': 0.7913471339423148}
2022-11-18 01:44:19,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:19,402 INFO:     Epoch: 60
2022-11-18 01:44:20,181 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8097508494244066, 'Total loss': 0.8097508494244066} | train loss {'Reaction outcome loss': 0.7913244586499011, 'Total loss': 0.7913244586499011}
2022-11-18 01:44:20,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:20,182 INFO:     Epoch: 61
2022-11-18 01:44:20,956 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7981769096019656, 'Total loss': 0.7981769096019656} | train loss {'Reaction outcome loss': 0.7924830703461756, 'Total loss': 0.7924830703461756}
2022-11-18 01:44:20,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:20,956 INFO:     Epoch: 62
2022-11-18 01:44:21,772 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7902220640071603, 'Total loss': 0.7902220640071603} | train loss {'Reaction outcome loss': 0.7934540721480964, 'Total loss': 0.7934540721480964}
2022-11-18 01:44:21,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:21,772 INFO:     Epoch: 63
2022-11-18 01:44:22,598 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7983248289241347, 'Total loss': 0.7983248289241347} | train loss {'Reaction outcome loss': 0.7898664854344775, 'Total loss': 0.7898664854344775}
2022-11-18 01:44:22,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:22,598 INFO:     Epoch: 64
2022-11-18 01:44:23,430 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8255494126053744, 'Total loss': 0.8255494126053744} | train loss {'Reaction outcome loss': 0.800675274162996, 'Total loss': 0.800675274162996}
2022-11-18 01:44:23,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:23,431 INFO:     Epoch: 65
2022-11-18 01:44:24,232 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7967008213664211, 'Total loss': 0.7967008213664211} | train loss {'Reaction outcome loss': 0.7952167886446734, 'Total loss': 0.7952167886446734}
2022-11-18 01:44:24,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:24,232 INFO:     Epoch: 66
2022-11-18 01:44:24,993 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7925666750863541, 'Total loss': 0.7925666750863541} | train loss {'Reaction outcome loss': 0.7918263977912606, 'Total loss': 0.7918263977912606}
2022-11-18 01:44:24,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:24,993 INFO:     Epoch: 67
2022-11-18 01:44:25,754 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.787407730900964, 'Total loss': 0.787407730900964} | train loss {'Reaction outcome loss': 0.7925922737502661, 'Total loss': 0.7925922737502661}
2022-11-18 01:44:25,754 INFO:     Found new best model at epoch 67
2022-11-18 01:44:25,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:25,755 INFO:     Epoch: 68
2022-11-18 01:44:26,516 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8178892121758572, 'Total loss': 0.8178892121758572} | train loss {'Reaction outcome loss': 0.7949956386792855, 'Total loss': 0.7949956386792855}
2022-11-18 01:44:26,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:26,516 INFO:     Epoch: 69
2022-11-18 01:44:27,292 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7837245783140493, 'Total loss': 0.7837245783140493} | train loss {'Reaction outcome loss': 0.787186216501916, 'Total loss': 0.787186216501916}
2022-11-18 01:44:27,292 INFO:     Found new best model at epoch 69
2022-11-18 01:44:27,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:27,293 INFO:     Epoch: 70
2022-11-18 01:44:28,065 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.78094052159509, 'Total loss': 0.78094052159509} | train loss {'Reaction outcome loss': 0.7855196010138168, 'Total loss': 0.7855196010138168}
2022-11-18 01:44:28,066 INFO:     Found new best model at epoch 70
2022-11-18 01:44:28,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:28,066 INFO:     Epoch: 71
2022-11-18 01:44:28,862 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7948701582675757, 'Total loss': 0.7948701582675757} | train loss {'Reaction outcome loss': 0.7896740021275692, 'Total loss': 0.7896740021275692}
2022-11-18 01:44:28,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:28,862 INFO:     Epoch: 72
2022-11-18 01:44:29,638 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.810580033202504, 'Total loss': 0.810580033202504} | train loss {'Reaction outcome loss': 0.7876963772978939, 'Total loss': 0.7876963772978939}
2022-11-18 01:44:29,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:29,638 INFO:     Epoch: 73
2022-11-18 01:44:30,413 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.790916885747466, 'Total loss': 0.790916885747466} | train loss {'Reaction outcome loss': 0.78436033922385, 'Total loss': 0.78436033922385}
2022-11-18 01:44:30,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:30,414 INFO:     Epoch: 74
2022-11-18 01:44:31,207 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8005770555762357, 'Total loss': 0.8005770555762357} | train loss {'Reaction outcome loss': 0.7821023357940502, 'Total loss': 0.7821023357940502}
2022-11-18 01:44:31,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:31,207 INFO:     Epoch: 75
2022-11-18 01:44:31,990 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7836374730564827, 'Total loss': 0.7836374730564827} | train loss {'Reaction outcome loss': 0.7855666433690024, 'Total loss': 0.7855666433690024}
2022-11-18 01:44:31,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:31,991 INFO:     Epoch: 76
2022-11-18 01:44:32,756 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.780687014723933, 'Total loss': 0.780687014723933} | train loss {'Reaction outcome loss': 0.7840483721162452, 'Total loss': 0.7840483721162452}
2022-11-18 01:44:32,756 INFO:     Found new best model at epoch 76
2022-11-18 01:44:32,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:32,757 INFO:     Epoch: 77
2022-11-18 01:44:33,542 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8263310083123141, 'Total loss': 0.8263310083123141} | train loss {'Reaction outcome loss': 0.7804865089596295, 'Total loss': 0.7804865089596295}
2022-11-18 01:44:33,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:33,543 INFO:     Epoch: 78
2022-11-18 01:44:34,338 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7695480002913364, 'Total loss': 0.7695480002913364} | train loss {'Reaction outcome loss': 0.7780487599675773, 'Total loss': 0.7780487599675773}
2022-11-18 01:44:34,338 INFO:     Found new best model at epoch 78
2022-11-18 01:44:34,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:34,339 INFO:     Epoch: 79
2022-11-18 01:44:35,083 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7899445378503134, 'Total loss': 0.7899445378503134} | train loss {'Reaction outcome loss': 0.7852355385901498, 'Total loss': 0.7852355385901498}
2022-11-18 01:44:35,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:35,083 INFO:     Epoch: 80
2022-11-18 01:44:35,865 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.797409977330718, 'Total loss': 0.797409977330718} | train loss {'Reaction outcome loss': 0.7841217483653397, 'Total loss': 0.7841217483653397}
2022-11-18 01:44:35,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:35,867 INFO:     Epoch: 81
2022-11-18 01:44:36,635 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.798344258652177, 'Total loss': 0.798344258652177} | train loss {'Reaction outcome loss': 0.7793774119898921, 'Total loss': 0.7793774119898921}
2022-11-18 01:44:36,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:36,635 INFO:     Epoch: 82
2022-11-18 01:44:37,408 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7581203378910242, 'Total loss': 0.7581203378910242} | train loss {'Reaction outcome loss': 0.7800871688322942, 'Total loss': 0.7800871688322942}
2022-11-18 01:44:37,408 INFO:     Found new best model at epoch 82
2022-11-18 01:44:37,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:37,409 INFO:     Epoch: 83
2022-11-18 01:44:38,168 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7806509712407755, 'Total loss': 0.7806509712407755} | train loss {'Reaction outcome loss': 0.7719811539425224, 'Total loss': 0.7719811539425224}
2022-11-18 01:44:38,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:38,169 INFO:     Epoch: 84
2022-11-18 01:44:38,954 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7793094668277475, 'Total loss': 0.7793094668277475} | train loss {'Reaction outcome loss': 0.7758696228265762, 'Total loss': 0.7758696228265762}
2022-11-18 01:44:38,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:38,954 INFO:     Epoch: 85
2022-11-18 01:44:39,742 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.779878556728363, 'Total loss': 0.779878556728363} | train loss {'Reaction outcome loss': 0.769600616126764, 'Total loss': 0.769600616126764}
2022-11-18 01:44:39,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:39,742 INFO:     Epoch: 86
2022-11-18 01:44:40,501 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7887577615505041, 'Total loss': 0.7887577615505041} | train loss {'Reaction outcome loss': 0.7705119479386533, 'Total loss': 0.7705119479386533}
2022-11-18 01:44:40,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:40,501 INFO:     Epoch: 87
2022-11-18 01:44:41,289 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.769999272601549, 'Total loss': 0.769999272601549} | train loss {'Reaction outcome loss': 0.7646327235537475, 'Total loss': 0.7646327235537475}
2022-11-18 01:44:41,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:41,290 INFO:     Epoch: 88
2022-11-18 01:44:42,069 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7659617080244907, 'Total loss': 0.7659617080244907} | train loss {'Reaction outcome loss': 0.766759105393144, 'Total loss': 0.766759105393144}
2022-11-18 01:44:42,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:42,070 INFO:     Epoch: 89
2022-11-18 01:44:42,858 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8005178716293601, 'Total loss': 0.8005178716293601} | train loss {'Reaction outcome loss': 0.7671869888168866, 'Total loss': 0.7671869888168866}
2022-11-18 01:44:42,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:42,858 INFO:     Epoch: 90
2022-11-18 01:44:43,625 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.772081866513851, 'Total loss': 0.772081866513851} | train loss {'Reaction outcome loss': 0.7586960388255901, 'Total loss': 0.7586960388255901}
2022-11-18 01:44:43,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:43,625 INFO:     Epoch: 91
2022-11-18 01:44:44,401 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7464021423528361, 'Total loss': 0.7464021423528361} | train loss {'Reaction outcome loss': 0.7593275643274432, 'Total loss': 0.7593275643274432}
2022-11-18 01:44:44,401 INFO:     Found new best model at epoch 91
2022-11-18 01:44:44,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:44,402 INFO:     Epoch: 92
2022-11-18 01:44:45,166 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7930521770965221, 'Total loss': 0.7930521770965221} | train loss {'Reaction outcome loss': 0.75191494981285, 'Total loss': 0.75191494981285}
2022-11-18 01:44:45,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:45,166 INFO:     Epoch: 93
2022-11-18 01:44:45,947 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8221844892169154, 'Total loss': 0.8221844892169154} | train loss {'Reaction outcome loss': 0.7522261091431633, 'Total loss': 0.7522261091431633}
2022-11-18 01:44:45,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:45,948 INFO:     Epoch: 94
2022-11-18 01:44:46,709 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7431066036224365, 'Total loss': 0.7431066036224365} | train loss {'Reaction outcome loss': 0.7486413724598338, 'Total loss': 0.7486413724598338}
2022-11-18 01:44:46,709 INFO:     Found new best model at epoch 94
2022-11-18 01:44:46,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:46,710 INFO:     Epoch: 95
2022-11-18 01:44:47,465 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7859404974205549, 'Total loss': 0.7859404974205549} | train loss {'Reaction outcome loss': 0.7406715281674119, 'Total loss': 0.7406715281674119}
2022-11-18 01:44:47,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:47,466 INFO:     Epoch: 96
2022-11-18 01:44:48,246 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7159030118653941, 'Total loss': 0.7159030118653941} | train loss {'Reaction outcome loss': 0.745679500650187, 'Total loss': 0.745679500650187}
2022-11-18 01:44:48,246 INFO:     Found new best model at epoch 96
2022-11-18 01:44:48,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:48,247 INFO:     Epoch: 97
2022-11-18 01:44:49,027 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7094893815905549, 'Total loss': 0.7094893815905549} | train loss {'Reaction outcome loss': 0.7278352010934079, 'Total loss': 0.7278352010934079}
2022-11-18 01:44:49,027 INFO:     Found new best model at epoch 97
2022-11-18 01:44:49,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:49,028 INFO:     Epoch: 98
2022-11-18 01:44:49,795 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7592343029587768, 'Total loss': 0.7592343029587768} | train loss {'Reaction outcome loss': 0.7212166184040366, 'Total loss': 0.7212166184040366}
2022-11-18 01:44:49,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:49,795 INFO:     Epoch: 99
2022-11-18 01:44:50,582 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.6752581582512966, 'Total loss': 0.6752581582512966} | train loss {'Reaction outcome loss': 0.7180059400738262, 'Total loss': 0.7180059400738262}
2022-11-18 01:44:50,582 INFO:     Found new best model at epoch 99
2022-11-18 01:44:50,582 INFO:     Best model found after epoch 100 of 100.
2022-11-18 01:44:50,583 INFO:   Done with stage: TRAINING
2022-11-18 01:44:50,583 INFO:   Starting stage: EVALUATION
2022-11-18 01:44:50,720 INFO:   Done with stage: EVALUATION
2022-11-18 01:44:50,720 INFO:   Leaving out SEQ value Fold_8
2022-11-18 01:44:50,733 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 01:44:50,733 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:44:51,396 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:44:51,397 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:44:51,470 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:44:51,470 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:44:51,470 INFO:     No hyperparam tuning for this model
2022-11-18 01:44:51,470 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:44:51,470 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:44:51,471 INFO:     None feature selector for col prot
2022-11-18 01:44:51,471 INFO:     None feature selector for col prot
2022-11-18 01:44:51,471 INFO:     None feature selector for col prot
2022-11-18 01:44:51,472 INFO:     None feature selector for col chem
2022-11-18 01:44:51,472 INFO:     None feature selector for col chem
2022-11-18 01:44:51,472 INFO:     None feature selector for col chem
2022-11-18 01:44:51,472 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:44:51,472 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:44:51,474 INFO:     Number of params in model 168571
2022-11-18 01:44:51,477 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:44:51,477 INFO:   Starting stage: TRAINING
2022-11-18 01:44:51,534 INFO:     Val loss before train {'Reaction outcome loss': 0.9972437850453637, 'Total loss': 0.9972437850453637}
2022-11-18 01:44:51,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:51,535 INFO:     Epoch: 0
2022-11-18 01:44:52,312 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8098394295031374, 'Total loss': 0.8098394295031374} | train loss {'Reaction outcome loss': 0.8936057824354905, 'Total loss': 0.8936057824354905}
2022-11-18 01:44:52,313 INFO:     Found new best model at epoch 0
2022-11-18 01:44:52,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:52,313 INFO:     Epoch: 1
2022-11-18 01:44:53,090 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8085271485827186, 'Total loss': 0.8085271485827186} | train loss {'Reaction outcome loss': 0.8720234599914628, 'Total loss': 0.8720234599914628}
2022-11-18 01:44:53,090 INFO:     Found new best model at epoch 1
2022-11-18 01:44:53,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:53,091 INFO:     Epoch: 2
2022-11-18 01:44:53,886 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8140124854716387, 'Total loss': 0.8140124854716387} | train loss {'Reaction outcome loss': 0.8577875236750614, 'Total loss': 0.8577875236750614}
2022-11-18 01:44:53,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:53,887 INFO:     Epoch: 3
2022-11-18 01:44:54,672 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8050824112512849, 'Total loss': 0.8050824112512849} | train loss {'Reaction outcome loss': 0.8578058165094631, 'Total loss': 0.8578058165094631}
2022-11-18 01:44:54,673 INFO:     Found new best model at epoch 3
2022-11-18 01:44:54,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:54,674 INFO:     Epoch: 4
2022-11-18 01:44:55,445 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8390855450521816, 'Total loss': 0.8390855450521816} | train loss {'Reaction outcome loss': 0.8568047303178532, 'Total loss': 0.8568047303178532}
2022-11-18 01:44:55,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:55,445 INFO:     Epoch: 5
2022-11-18 01:44:56,222 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.802231799472462, 'Total loss': 0.802231799472462} | train loss {'Reaction outcome loss': 0.8432722856641298, 'Total loss': 0.8432722856641298}
2022-11-18 01:44:56,222 INFO:     Found new best model at epoch 5
2022-11-18 01:44:56,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:56,223 INFO:     Epoch: 6
2022-11-18 01:44:57,032 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8011245734312318, 'Total loss': 0.8011245734312318} | train loss {'Reaction outcome loss': 0.8427750678499218, 'Total loss': 0.8427750678499218}
2022-11-18 01:44:57,033 INFO:     Found new best model at epoch 6
2022-11-18 01:44:57,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:57,033 INFO:     Epoch: 7
2022-11-18 01:44:57,852 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7930229326540773, 'Total loss': 0.7930229326540773} | train loss {'Reaction outcome loss': 0.844369941153507, 'Total loss': 0.844369941153507}
2022-11-18 01:44:57,853 INFO:     Found new best model at epoch 7
2022-11-18 01:44:57,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:57,853 INFO:     Epoch: 8
2022-11-18 01:44:58,635 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8181100677360188, 'Total loss': 0.8181100677360188} | train loss {'Reaction outcome loss': 0.8473217141652397, 'Total loss': 0.8473217141652397}
2022-11-18 01:44:58,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:58,635 INFO:     Epoch: 9
2022-11-18 01:44:59,420 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8130306256088343, 'Total loss': 0.8130306256088343} | train loss {'Reaction outcome loss': 0.8384848436121999, 'Total loss': 0.8384848436121999}
2022-11-18 01:44:59,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:44:59,420 INFO:     Epoch: 10
2022-11-18 01:45:00,219 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8002833554690535, 'Total loss': 0.8002833554690535} | train loss {'Reaction outcome loss': 0.8397022423669998, 'Total loss': 0.8397022423669998}
2022-11-18 01:45:00,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:00,219 INFO:     Epoch: 11
2022-11-18 01:45:01,030 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.809706496244127, 'Total loss': 0.809706496244127} | train loss {'Reaction outcome loss': 0.8336088227839605, 'Total loss': 0.8336088227839605}
2022-11-18 01:45:01,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:01,030 INFO:     Epoch: 12
2022-11-18 01:45:01,796 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7744736292145469, 'Total loss': 0.7744736292145469} | train loss {'Reaction outcome loss': 0.8385020076987232, 'Total loss': 0.8385020076987232}
2022-11-18 01:45:01,796 INFO:     Found new best model at epoch 12
2022-11-18 01:45:01,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:01,797 INFO:     Epoch: 13
2022-11-18 01:45:02,574 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8071841170841997, 'Total loss': 0.8071841170841997} | train loss {'Reaction outcome loss': 0.8290404070259226, 'Total loss': 0.8290404070259226}
2022-11-18 01:45:02,574 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:02,574 INFO:     Epoch: 14
2022-11-18 01:45:03,349 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7873530638488856, 'Total loss': 0.7873530638488856} | train loss {'Reaction outcome loss': 0.8318981428438352, 'Total loss': 0.8318981428438352}
2022-11-18 01:45:03,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:03,349 INFO:     Epoch: 15
2022-11-18 01:45:04,136 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7939254438335245, 'Total loss': 0.7939254438335245} | train loss {'Reaction outcome loss': 0.8341643423264326, 'Total loss': 0.8341643423264326}
2022-11-18 01:45:04,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:04,137 INFO:     Epoch: 16
2022-11-18 01:45:04,910 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7974991026249799, 'Total loss': 0.7974991026249799} | train loss {'Reaction outcome loss': 0.8357904869535191, 'Total loss': 0.8357904869535191}
2022-11-18 01:45:04,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:04,911 INFO:     Epoch: 17
2022-11-18 01:45:05,682 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.794427256015214, 'Total loss': 0.794427256015214} | train loss {'Reaction outcome loss': 0.8349958841164826, 'Total loss': 0.8349958841164826}
2022-11-18 01:45:05,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:05,682 INFO:     Epoch: 18
2022-11-18 01:45:06,468 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7783906232904304, 'Total loss': 0.7783906232904304} | train loss {'Reaction outcome loss': 0.8291809350131494, 'Total loss': 0.8291809350131494}
2022-11-18 01:45:06,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:06,468 INFO:     Epoch: 19
2022-11-18 01:45:07,242 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7839382792061026, 'Total loss': 0.7839382792061026} | train loss {'Reaction outcome loss': 0.8380892378115944, 'Total loss': 0.8380892378115944}
2022-11-18 01:45:07,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:07,244 INFO:     Epoch: 20
2022-11-18 01:45:08,027 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7752725712277673, 'Total loss': 0.7752725712277673} | train loss {'Reaction outcome loss': 0.8437166937932312, 'Total loss': 0.8437166937932312}
2022-11-18 01:45:08,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:08,027 INFO:     Epoch: 21
2022-11-18 01:45:08,827 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8203609010035341, 'Total loss': 0.8203609010035341} | train loss {'Reaction outcome loss': 0.8334062906050006, 'Total loss': 0.8334062906050006}
2022-11-18 01:45:08,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:08,827 INFO:     Epoch: 22
2022-11-18 01:45:09,626 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7864639183337038, 'Total loss': 0.7864639183337038} | train loss {'Reaction outcome loss': 0.8308425102880609, 'Total loss': 0.8308425102880609}
2022-11-18 01:45:09,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:09,626 INFO:     Epoch: 23
2022-11-18 01:45:10,387 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7838408289985224, 'Total loss': 0.7838408289985224} | train loss {'Reaction outcome loss': 0.8342883940409069, 'Total loss': 0.8342883940409069}
2022-11-18 01:45:10,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:10,387 INFO:     Epoch: 24
2022-11-18 01:45:11,164 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8022669540210203, 'Total loss': 0.8022669540210203} | train loss {'Reaction outcome loss': 0.8407375128404332, 'Total loss': 0.8407375128404332}
2022-11-18 01:45:11,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:11,164 INFO:     Epoch: 25
2022-11-18 01:45:11,945 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8087869923223149, 'Total loss': 0.8087869923223149} | train loss {'Reaction outcome loss': 0.8374612788681076, 'Total loss': 0.8374612788681076}
2022-11-18 01:45:11,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:11,946 INFO:     Epoch: 26
2022-11-18 01:45:12,709 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7818219397555698, 'Total loss': 0.7818219397555698} | train loss {'Reaction outcome loss': 0.8393523977835652, 'Total loss': 0.8393523977835652}
2022-11-18 01:45:12,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:12,709 INFO:     Epoch: 27
2022-11-18 01:45:13,481 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8102633187716658, 'Total loss': 0.8102633187716658} | train loss {'Reaction outcome loss': 0.8338675426568097, 'Total loss': 0.8338675426568097}
2022-11-18 01:45:13,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:13,482 INFO:     Epoch: 28
2022-11-18 01:45:14,304 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7933485805988312, 'Total loss': 0.7933485805988312} | train loss {'Reaction outcome loss': 0.8378449120381584, 'Total loss': 0.8378449120381584}
2022-11-18 01:45:14,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:14,305 INFO:     Epoch: 29
2022-11-18 01:45:15,130 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8056997182694349, 'Total loss': 0.8056997182694349} | train loss {'Reaction outcome loss': 0.8252164393904721, 'Total loss': 0.8252164393904721}
2022-11-18 01:45:15,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:15,131 INFO:     Epoch: 30
2022-11-18 01:45:15,913 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7803221839395437, 'Total loss': 0.7803221839395437} | train loss {'Reaction outcome loss': 0.8287618882984285, 'Total loss': 0.8287618882984285}
2022-11-18 01:45:15,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:15,913 INFO:     Epoch: 31
2022-11-18 01:45:16,701 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7778679105368528, 'Total loss': 0.7778679105368528} | train loss {'Reaction outcome loss': 0.8286475166980072, 'Total loss': 0.8286475166980072}
2022-11-18 01:45:16,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:16,702 INFO:     Epoch: 32
2022-11-18 01:45:17,490 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7745712033726952, 'Total loss': 0.7745712033726952} | train loss {'Reaction outcome loss': 0.8381919862046415, 'Total loss': 0.8381919862046415}
2022-11-18 01:45:17,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:17,490 INFO:     Epoch: 33
2022-11-18 01:45:18,271 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7856257578188722, 'Total loss': 0.7856257578188722} | train loss {'Reaction outcome loss': 0.8368237165786959, 'Total loss': 0.8368237165786959}
2022-11-18 01:45:18,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:18,272 INFO:     Epoch: 34
2022-11-18 01:45:19,026 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8088781129230153, 'Total loss': 0.8088781129230153} | train loss {'Reaction outcome loss': 0.8268806854722953, 'Total loss': 0.8268806854722953}
2022-11-18 01:45:19,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:19,027 INFO:     Epoch: 35
2022-11-18 01:45:19,790 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7765575850551779, 'Total loss': 0.7765575850551779} | train loss {'Reaction outcome loss': 0.8407872771685906, 'Total loss': 0.8407872771685906}
2022-11-18 01:45:19,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:19,790 INFO:     Epoch: 36
2022-11-18 01:45:20,560 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7711002095179125, 'Total loss': 0.7711002095179125} | train loss {'Reaction outcome loss': 0.8369972774615655, 'Total loss': 0.8369972774615655}
2022-11-18 01:45:20,560 INFO:     Found new best model at epoch 36
2022-11-18 01:45:20,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:20,561 INFO:     Epoch: 37
2022-11-18 01:45:21,344 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7908636439930309, 'Total loss': 0.7908636439930309} | train loss {'Reaction outcome loss': 0.8318390725595266, 'Total loss': 0.8318390725595266}
2022-11-18 01:45:21,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:21,345 INFO:     Epoch: 38
2022-11-18 01:45:22,131 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7928568964654749, 'Total loss': 0.7928568964654749} | train loss {'Reaction outcome loss': 0.8417158016429739, 'Total loss': 0.8417158016429739}
2022-11-18 01:45:22,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:22,131 INFO:     Epoch: 39
2022-11-18 01:45:22,933 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8036633506417274, 'Total loss': 0.8036633506417274} | train loss {'Reaction outcome loss': 0.832580153638052, 'Total loss': 0.832580153638052}
2022-11-18 01:45:22,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:22,933 INFO:     Epoch: 40
2022-11-18 01:45:23,714 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7892005050724203, 'Total loss': 0.7892005050724203} | train loss {'Reaction outcome loss': 0.845336732714765, 'Total loss': 0.845336732714765}
2022-11-18 01:45:23,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:23,714 INFO:     Epoch: 41
2022-11-18 01:45:24,489 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8013703362508253, 'Total loss': 0.8013703362508253} | train loss {'Reaction outcome loss': 0.8349470946832225, 'Total loss': 0.8349470946832225}
2022-11-18 01:45:24,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:24,489 INFO:     Epoch: 42
2022-11-18 01:45:25,273 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8059444082054225, 'Total loss': 0.8059444082054225} | train loss {'Reaction outcome loss': 0.8278420892834422, 'Total loss': 0.8278420892834422}
2022-11-18 01:45:25,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:25,274 INFO:     Epoch: 43
2022-11-18 01:45:26,046 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8466909697110002, 'Total loss': 0.8466909697110002} | train loss {'Reaction outcome loss': 0.8330238413231575, 'Total loss': 0.8330238413231575}
2022-11-18 01:45:26,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:26,047 INFO:     Epoch: 44
2022-11-18 01:45:26,842 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7823216400363229, 'Total loss': 0.7823216400363229} | train loss {'Reaction outcome loss': 0.8341217418672585, 'Total loss': 0.8341217418672585}
2022-11-18 01:45:26,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:26,842 INFO:     Epoch: 45
2022-11-18 01:45:27,626 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8001822890205816, 'Total loss': 0.8001822890205816} | train loss {'Reaction outcome loss': 0.8279095598560596, 'Total loss': 0.8279095598560596}
2022-11-18 01:45:27,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:27,626 INFO:     Epoch: 46
2022-11-18 01:45:28,438 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8010120154781775, 'Total loss': 0.8010120154781775} | train loss {'Reaction outcome loss': 0.8315021535042326, 'Total loss': 0.8315021535042326}
2022-11-18 01:45:28,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:28,438 INFO:     Epoch: 47
2022-11-18 01:45:29,250 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7818163497881456, 'Total loss': 0.7818163497881456} | train loss {'Reaction outcome loss': 0.8373741018868651, 'Total loss': 0.8373741018868651}
2022-11-18 01:45:29,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:29,250 INFO:     Epoch: 48
2022-11-18 01:45:30,059 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7938851219686595, 'Total loss': 0.7938851219686595} | train loss {'Reaction outcome loss': 0.8333414231958659, 'Total loss': 0.8333414231958659}
2022-11-18 01:45:30,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:30,059 INFO:     Epoch: 49
2022-11-18 01:45:30,847 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7712063430385157, 'Total loss': 0.7712063430385157} | train loss {'Reaction outcome loss': 0.8281948543511904, 'Total loss': 0.8281948543511904}
2022-11-18 01:45:30,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:30,847 INFO:     Epoch: 50
2022-11-18 01:45:31,629 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7905952781438828, 'Total loss': 0.7905952781438828} | train loss {'Reaction outcome loss': 0.8296158590659439, 'Total loss': 0.8296158590659439}
2022-11-18 01:45:31,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:31,630 INFO:     Epoch: 51
2022-11-18 01:45:32,425 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7743182185698639, 'Total loss': 0.7743182185698639} | train loss {'Reaction outcome loss': 0.8276476577708596, 'Total loss': 0.8276476577708596}
2022-11-18 01:45:32,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:32,425 INFO:     Epoch: 52
2022-11-18 01:45:33,233 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7756526334719225, 'Total loss': 0.7756526334719225} | train loss {'Reaction outcome loss': 0.8347904978976076, 'Total loss': 0.8347904978976076}
2022-11-18 01:45:33,233 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:33,233 INFO:     Epoch: 53
2022-11-18 01:45:34,028 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.809961274266243, 'Total loss': 0.809961274266243} | train loss {'Reaction outcome loss': 0.834580745050299, 'Total loss': 0.834580745050299}
2022-11-18 01:45:34,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:34,028 INFO:     Epoch: 54
2022-11-18 01:45:34,835 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8029714030298319, 'Total loss': 0.8029714030298319} | train loss {'Reaction outcome loss': 0.8314677589094108, 'Total loss': 0.8314677589094108}
2022-11-18 01:45:34,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:34,835 INFO:     Epoch: 55
2022-11-18 01:45:35,622 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.780894244259054, 'Total loss': 0.780894244259054} | train loss {'Reaction outcome loss': 0.8392480311364781, 'Total loss': 0.8392480311364781}
2022-11-18 01:45:35,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:35,622 INFO:     Epoch: 56
2022-11-18 01:45:36,410 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7817250896583904, 'Total loss': 0.7817250896583904} | train loss {'Reaction outcome loss': 0.832455785650956, 'Total loss': 0.832455785650956}
2022-11-18 01:45:36,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:36,410 INFO:     Epoch: 57
2022-11-18 01:45:37,204 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8055380559103056, 'Total loss': 0.8055380559103056} | train loss {'Reaction outcome loss': 0.8278048040895809, 'Total loss': 0.8278048040895809}
2022-11-18 01:45:37,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:37,205 INFO:     Epoch: 58
2022-11-18 01:45:37,994 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7821991064331748, 'Total loss': 0.7821991064331748} | train loss {'Reaction outcome loss': 0.8355926125638398, 'Total loss': 0.8355926125638398}
2022-11-18 01:45:37,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:37,995 INFO:     Epoch: 59
2022-11-18 01:45:38,758 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.775536107068712, 'Total loss': 0.775536107068712} | train loss {'Reaction outcome loss': 0.8246182749869853, 'Total loss': 0.8246182749869853}
2022-11-18 01:45:38,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:38,758 INFO:     Epoch: 60
2022-11-18 01:45:39,547 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7860796857963909, 'Total loss': 0.7860796857963909} | train loss {'Reaction outcome loss': 0.8239505681311071, 'Total loss': 0.8239505681311071}
2022-11-18 01:45:39,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:39,548 INFO:     Epoch: 61
2022-11-18 01:45:40,351 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7841798676685854, 'Total loss': 0.7841798676685854} | train loss {'Reaction outcome loss': 0.8206563907626429, 'Total loss': 0.8206563907626429}
2022-11-18 01:45:40,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:40,351 INFO:     Epoch: 62
2022-11-18 01:45:41,156 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7763773846355352, 'Total loss': 0.7763773846355352} | train loss {'Reaction outcome loss': 0.8281171522461451, 'Total loss': 0.8281171522461451}
2022-11-18 01:45:41,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:41,156 INFO:     Epoch: 63
2022-11-18 01:45:41,936 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7956262975931168, 'Total loss': 0.7956262975931168} | train loss {'Reaction outcome loss': 0.8303040699196248, 'Total loss': 0.8303040699196248}
2022-11-18 01:45:41,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:41,936 INFO:     Epoch: 64
2022-11-18 01:45:42,722 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7907298322428357, 'Total loss': 0.7907298322428357} | train loss {'Reaction outcome loss': 0.8218174410252436, 'Total loss': 0.8218174410252436}
2022-11-18 01:45:42,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:42,723 INFO:     Epoch: 65
2022-11-18 01:45:43,527 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7775261734019626, 'Total loss': 0.7775261734019626} | train loss {'Reaction outcome loss': 0.8252669528187045, 'Total loss': 0.8252669528187045}
2022-11-18 01:45:43,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:43,527 INFO:     Epoch: 66
2022-11-18 01:45:44,312 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7909006469629027, 'Total loss': 0.7909006469629027} | train loss {'Reaction outcome loss': 0.8327060493863063, 'Total loss': 0.8327060493863063}
2022-11-18 01:45:44,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:44,313 INFO:     Epoch: 67
2022-11-18 01:45:45,083 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7743012749335982, 'Total loss': 0.7743012749335982} | train loss {'Reaction outcome loss': 0.8386457323545387, 'Total loss': 0.8386457323545387}
2022-11-18 01:45:45,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:45,083 INFO:     Epoch: 68
2022-11-18 01:45:45,859 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7879144630648873, 'Total loss': 0.7879144630648873} | train loss {'Reaction outcome loss': 0.8265580000423709, 'Total loss': 0.8265580000423709}
2022-11-18 01:45:45,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:45,860 INFO:     Epoch: 69
2022-11-18 01:45:46,630 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7827698297121308, 'Total loss': 0.7827698297121308} | train loss {'Reaction outcome loss': 0.8257365273801904, 'Total loss': 0.8257365273801904}
2022-11-18 01:45:46,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:46,630 INFO:     Epoch: 70
2022-11-18 01:45:47,421 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.771380134604194, 'Total loss': 0.771380134604194} | train loss {'Reaction outcome loss': 0.8275941729786908, 'Total loss': 0.8275941729786908}
2022-11-18 01:45:47,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:47,421 INFO:     Epoch: 71
2022-11-18 01:45:48,199 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7736900130456145, 'Total loss': 0.7736900130456145} | train loss {'Reaction outcome loss': 0.8268886425717157, 'Total loss': 0.8268886425717157}
2022-11-18 01:45:48,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:48,199 INFO:     Epoch: 72
2022-11-18 01:45:48,975 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8072789846496149, 'Total loss': 0.8072789846496149} | train loss {'Reaction outcome loss': 0.8306038049068528, 'Total loss': 0.8306038049068528}
2022-11-18 01:45:48,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:48,975 INFO:     Epoch: 73
2022-11-18 01:45:49,750 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.781655724753033, 'Total loss': 0.781655724753033} | train loss {'Reaction outcome loss': 0.8339664936065674, 'Total loss': 0.8339664936065674}
2022-11-18 01:45:49,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:49,750 INFO:     Epoch: 74
2022-11-18 01:45:50,514 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.773772343993187, 'Total loss': 0.773772343993187} | train loss {'Reaction outcome loss': 0.8309717128875285, 'Total loss': 0.8309717128875285}
2022-11-18 01:45:50,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:50,514 INFO:     Epoch: 75
2022-11-18 01:45:51,316 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7705591984770515, 'Total loss': 0.7705591984770515} | train loss {'Reaction outcome loss': 0.8292797768888204, 'Total loss': 0.8292797768888204}
2022-11-18 01:45:51,316 INFO:     Found new best model at epoch 75
2022-11-18 01:45:51,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:51,317 INFO:     Epoch: 76
2022-11-18 01:45:52,100 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7988619228655641, 'Total loss': 0.7988619228655641} | train loss {'Reaction outcome loss': 0.8204927738861516, 'Total loss': 0.8204927738861516}
2022-11-18 01:45:52,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:52,100 INFO:     Epoch: 77
2022-11-18 01:45:52,875 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7839095538312738, 'Total loss': 0.7839095538312738} | train loss {'Reaction outcome loss': 0.829035554337598, 'Total loss': 0.829035554337598}
2022-11-18 01:45:52,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:52,875 INFO:     Epoch: 78
2022-11-18 01:45:53,671 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7817494141107256, 'Total loss': 0.7817494141107256} | train loss {'Reaction outcome loss': 0.8264133255280223, 'Total loss': 0.8264133255280223}
2022-11-18 01:45:53,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:53,671 INFO:     Epoch: 79
2022-11-18 01:45:54,446 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7730797298929908, 'Total loss': 0.7730797298929908} | train loss {'Reaction outcome loss': 0.8245230005820271, 'Total loss': 0.8245230005820271}
2022-11-18 01:45:54,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:54,446 INFO:     Epoch: 80
2022-11-18 01:45:55,215 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8003854311325334, 'Total loss': 0.8003854311325334} | train loss {'Reaction outcome loss': 0.8195815845147559, 'Total loss': 0.8195815845147559}
2022-11-18 01:45:55,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:55,216 INFO:     Epoch: 81
2022-11-18 01:45:55,998 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7971656207333911, 'Total loss': 0.7971656207333911} | train loss {'Reaction outcome loss': 0.8166607775186238, 'Total loss': 0.8166607775186238}
2022-11-18 01:45:55,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:55,998 INFO:     Epoch: 82
2022-11-18 01:45:56,785 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7750473191792314, 'Total loss': 0.7750473191792314} | train loss {'Reaction outcome loss': 0.8237399078211803, 'Total loss': 0.8237399078211803}
2022-11-18 01:45:56,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:56,787 INFO:     Epoch: 83
2022-11-18 01:45:57,787 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7895363772457297, 'Total loss': 0.7895363772457297} | train loss {'Reaction outcome loss': 0.8255318426168882, 'Total loss': 0.8255318426168882}
2022-11-18 01:45:57,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:57,788 INFO:     Epoch: 84
2022-11-18 01:45:58,701 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7741215804761107, 'Total loss': 0.7741215804761107} | train loss {'Reaction outcome loss': 0.8260087408276222, 'Total loss': 0.8260087408276222}
2022-11-18 01:45:58,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:58,701 INFO:     Epoch: 85
2022-11-18 01:45:59,537 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7872218096798117, 'Total loss': 0.7872218096798117} | train loss {'Reaction outcome loss': 0.8208170108466979, 'Total loss': 0.8208170108466979}
2022-11-18 01:45:59,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:45:59,538 INFO:     Epoch: 86
2022-11-18 01:46:00,402 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7666540044275197, 'Total loss': 0.7666540044275197} | train loss {'Reaction outcome loss': 0.8161334796895382, 'Total loss': 0.8161334796895382}
2022-11-18 01:46:00,402 INFO:     Found new best model at epoch 86
2022-11-18 01:46:00,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:00,403 INFO:     Epoch: 87
2022-11-18 01:46:01,222 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7782705886797472, 'Total loss': 0.7782705886797472} | train loss {'Reaction outcome loss': 0.8285260284960512, 'Total loss': 0.8285260284960512}
2022-11-18 01:46:01,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:01,222 INFO:     Epoch: 88
2022-11-18 01:46:02,041 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7970919954505834, 'Total loss': 0.7970919954505834} | train loss {'Reaction outcome loss': 0.8307100010786944, 'Total loss': 0.8307100010786944}
2022-11-18 01:46:02,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:02,041 INFO:     Epoch: 89
2022-11-18 01:46:02,832 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7763032655824315, 'Total loss': 0.7763032655824315} | train loss {'Reaction outcome loss': 0.8224952481536247, 'Total loss': 0.8224952481536247}
2022-11-18 01:46:02,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:02,832 INFO:     Epoch: 90
2022-11-18 01:46:03,684 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.78917545825243, 'Total loss': 0.78917545825243} | train loss {'Reaction outcome loss': 0.826549210046467, 'Total loss': 0.826549210046467}
2022-11-18 01:46:03,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:03,684 INFO:     Epoch: 91
2022-11-18 01:46:04,511 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.788609700446779, 'Total loss': 0.788609700446779} | train loss {'Reaction outcome loss': 0.8293804544427616, 'Total loss': 0.8293804544427616}
2022-11-18 01:46:04,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:04,512 INFO:     Epoch: 92
2022-11-18 01:46:05,329 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.76707362993197, 'Total loss': 0.76707362993197} | train loss {'Reaction outcome loss': 0.8217341040792735, 'Total loss': 0.8217341040792735}
2022-11-18 01:46:05,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:05,329 INFO:     Epoch: 93
2022-11-18 01:46:06,130 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8145026327534155, 'Total loss': 0.8145026327534155} | train loss {'Reaction outcome loss': 0.8173551212558862, 'Total loss': 0.8173551212558862}
2022-11-18 01:46:06,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:06,130 INFO:     Epoch: 94
2022-11-18 01:46:06,930 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7728954899040136, 'Total loss': 0.7728954899040136} | train loss {'Reaction outcome loss': 0.8269076300294775, 'Total loss': 0.8269076300294775}
2022-11-18 01:46:06,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:06,930 INFO:     Epoch: 95
2022-11-18 01:46:07,701 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7632097452878952, 'Total loss': 0.7632097452878952} | train loss {'Reaction outcome loss': 0.8152494438083066, 'Total loss': 0.8152494438083066}
2022-11-18 01:46:07,701 INFO:     Found new best model at epoch 95
2022-11-18 01:46:07,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:07,702 INFO:     Epoch: 96
2022-11-18 01:46:08,477 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7893635935404084, 'Total loss': 0.7893635935404084} | train loss {'Reaction outcome loss': 0.8101413613449224, 'Total loss': 0.8101413613449224}
2022-11-18 01:46:08,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:08,477 INFO:     Epoch: 97
2022-11-18 01:46:09,276 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7665065093473955, 'Total loss': 0.7665065093473955} | train loss {'Reaction outcome loss': 0.8186042279849651, 'Total loss': 0.8186042279849651}
2022-11-18 01:46:09,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:09,276 INFO:     Epoch: 98
2022-11-18 01:46:10,104 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7651703364469788, 'Total loss': 0.7651703364469788} | train loss {'Reaction outcome loss': 0.8157936128286215, 'Total loss': 0.8157936128286215}
2022-11-18 01:46:10,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:10,105 INFO:     Epoch: 99
2022-11-18 01:46:11,022 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7722937254743143, 'Total loss': 0.7722937254743143} | train loss {'Reaction outcome loss': 0.8180483416748433, 'Total loss': 0.8180483416748433}
2022-11-18 01:46:11,023 INFO:     Best model found after epoch 96 of 100.
2022-11-18 01:46:11,023 INFO:   Done with stage: TRAINING
2022-11-18 01:46:11,023 INFO:   Starting stage: EVALUATION
2022-11-18 01:46:11,148 INFO:   Done with stage: EVALUATION
2022-11-18 01:46:11,149 INFO:   Leaving out SEQ value Fold_9
2022-11-18 01:46:11,162 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 01:46:11,162 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:46:11,847 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:46:11,848 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:46:11,918 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:46:11,918 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:46:11,918 INFO:     No hyperparam tuning for this model
2022-11-18 01:46:11,918 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:46:11,919 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:46:11,919 INFO:     None feature selector for col prot
2022-11-18 01:46:11,920 INFO:     None feature selector for col prot
2022-11-18 01:46:11,920 INFO:     None feature selector for col prot
2022-11-18 01:46:11,920 INFO:     None feature selector for col chem
2022-11-18 01:46:11,920 INFO:     None feature selector for col chem
2022-11-18 01:46:11,921 INFO:     None feature selector for col chem
2022-11-18 01:46:11,921 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:46:11,921 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:46:11,922 INFO:     Number of params in model 168571
2022-11-18 01:46:11,925 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:46:11,926 INFO:   Starting stage: TRAINING
2022-11-18 01:46:11,983 INFO:     Val loss before train {'Reaction outcome loss': 1.0043792006644336, 'Total loss': 1.0043792006644336}
2022-11-18 01:46:11,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:11,984 INFO:     Epoch: 0
2022-11-18 01:46:12,815 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8077723167159341, 'Total loss': 0.8077723167159341} | train loss {'Reaction outcome loss': 0.864875453324453, 'Total loss': 0.864875453324453}
2022-11-18 01:46:12,815 INFO:     Found new best model at epoch 0
2022-11-18 01:46:12,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:12,816 INFO:     Epoch: 1
2022-11-18 01:46:13,651 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8045377731323242, 'Total loss': 0.8045377731323242} | train loss {'Reaction outcome loss': 0.8422590898357423, 'Total loss': 0.8422590898357423}
2022-11-18 01:46:13,652 INFO:     Found new best model at epoch 1
2022-11-18 01:46:13,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:13,652 INFO:     Epoch: 2
2022-11-18 01:46:14,452 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.774372240359133, 'Total loss': 0.774372240359133} | train loss {'Reaction outcome loss': 0.8296727012646826, 'Total loss': 0.8296727012646826}
2022-11-18 01:46:14,452 INFO:     Found new best model at epoch 2
2022-11-18 01:46:14,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:14,453 INFO:     Epoch: 3
2022-11-18 01:46:15,226 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8125366087664257, 'Total loss': 0.8125366087664257} | train loss {'Reaction outcome loss': 0.8300170674090565, 'Total loss': 0.8300170674090565}
2022-11-18 01:46:15,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:15,227 INFO:     Epoch: 4
2022-11-18 01:46:16,058 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7796630940654061, 'Total loss': 0.7796630940654061} | train loss {'Reaction outcome loss': 0.8214137701370455, 'Total loss': 0.8214137701370455}
2022-11-18 01:46:16,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:16,058 INFO:     Epoch: 5
2022-11-18 01:46:16,900 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.787954218685627, 'Total loss': 0.787954218685627} | train loss {'Reaction outcome loss': 0.8287782336053579, 'Total loss': 0.8287782336053579}
2022-11-18 01:46:16,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:16,901 INFO:     Epoch: 6
2022-11-18 01:46:17,677 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7820924791422758, 'Total loss': 0.7820924791422758} | train loss {'Reaction outcome loss': 0.8305044223663778, 'Total loss': 0.8305044223663778}
2022-11-18 01:46:17,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:17,677 INFO:     Epoch: 7
2022-11-18 01:46:18,455 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7872090908614072, 'Total loss': 0.7872090908614072} | train loss {'Reaction outcome loss': 0.8140182123493086, 'Total loss': 0.8140182123493086}
2022-11-18 01:46:18,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:18,455 INFO:     Epoch: 8
2022-11-18 01:46:19,279 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7920429489829324, 'Total loss': 0.7920429489829324} | train loss {'Reaction outcome loss': 0.8136075770082744, 'Total loss': 0.8136075770082744}
2022-11-18 01:46:19,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:19,279 INFO:     Epoch: 9
2022-11-18 01:46:20,111 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7719544483856722, 'Total loss': 0.7719544483856722} | train loss {'Reaction outcome loss': 0.8137343779266605, 'Total loss': 0.8137343779266605}
2022-11-18 01:46:20,111 INFO:     Found new best model at epoch 9
2022-11-18 01:46:20,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:20,112 INFO:     Epoch: 10
2022-11-18 01:46:20,929 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7635029513727535, 'Total loss': 0.7635029513727535} | train loss {'Reaction outcome loss': 0.8070238923978227, 'Total loss': 0.8070238923978227}
2022-11-18 01:46:20,930 INFO:     Found new best model at epoch 10
2022-11-18 01:46:20,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:20,931 INFO:     Epoch: 11
2022-11-18 01:46:21,751 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7789855897426605, 'Total loss': 0.7789855897426605} | train loss {'Reaction outcome loss': 0.8140874670343361, 'Total loss': 0.8140874670343361}
2022-11-18 01:46:21,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:21,751 INFO:     Epoch: 12
2022-11-18 01:46:22,562 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7922548258846457, 'Total loss': 0.7922548258846457} | train loss {'Reaction outcome loss': 0.8082463112678605, 'Total loss': 0.8082463112678605}
2022-11-18 01:46:22,562 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:22,562 INFO:     Epoch: 13
2022-11-18 01:46:23,352 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.761904039843516, 'Total loss': 0.761904039843516} | train loss {'Reaction outcome loss': 0.8111464987520264, 'Total loss': 0.8111464987520264}
2022-11-18 01:46:23,352 INFO:     Found new best model at epoch 13
2022-11-18 01:46:23,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:23,353 INFO:     Epoch: 14
2022-11-18 01:46:24,131 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7627434134483337, 'Total loss': 0.7627434134483337} | train loss {'Reaction outcome loss': 0.8028464900095936, 'Total loss': 0.8028464900095936}
2022-11-18 01:46:24,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:24,131 INFO:     Epoch: 15
2022-11-18 01:46:24,908 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7715304893526164, 'Total loss': 0.7715304893526164} | train loss {'Reaction outcome loss': 0.8059011695356022, 'Total loss': 0.8059011695356022}
2022-11-18 01:46:24,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:24,908 INFO:     Epoch: 16
2022-11-18 01:46:25,711 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8067677440968427, 'Total loss': 0.8067677440968427} | train loss {'Reaction outcome loss': 0.803227380581713, 'Total loss': 0.803227380581713}
2022-11-18 01:46:25,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:25,711 INFO:     Epoch: 17
2022-11-18 01:46:26,482 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7674939754334363, 'Total loss': 0.7674939754334363} | train loss {'Reaction outcome loss': 0.8052706328420504, 'Total loss': 0.8052706328420504}
2022-11-18 01:46:26,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:26,482 INFO:     Epoch: 18
2022-11-18 01:46:27,256 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7798198691823266, 'Total loss': 0.7798198691823266} | train loss {'Reaction outcome loss': 0.8034014187843693, 'Total loss': 0.8034014187843693}
2022-11-18 01:46:27,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:27,256 INFO:     Epoch: 19
2022-11-18 01:46:28,052 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7666169201785867, 'Total loss': 0.7666169201785867} | train loss {'Reaction outcome loss': 0.8037410648728189, 'Total loss': 0.8037410648728189}
2022-11-18 01:46:28,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:28,053 INFO:     Epoch: 20
2022-11-18 01:46:28,824 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7905628450892188, 'Total loss': 0.7905628450892188} | train loss {'Reaction outcome loss': 0.8026045376231313, 'Total loss': 0.8026045376231313}
2022-11-18 01:46:28,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:28,825 INFO:     Epoch: 21
2022-11-18 01:46:29,602 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8207180960611864, 'Total loss': 0.8207180960611864} | train loss {'Reaction outcome loss': 0.8108283984757628, 'Total loss': 0.8108283984757628}
2022-11-18 01:46:29,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:29,604 INFO:     Epoch: 22
2022-11-18 01:46:30,381 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7830480689352209, 'Total loss': 0.7830480689352209} | train loss {'Reaction outcome loss': 0.8221417203364585, 'Total loss': 0.8221417203364585}
2022-11-18 01:46:30,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:30,382 INFO:     Epoch: 23
2022-11-18 01:46:31,168 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7759128490632231, 'Total loss': 0.7759128490632231} | train loss {'Reaction outcome loss': 0.8022171520149177, 'Total loss': 0.8022171520149177}
2022-11-18 01:46:31,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:31,168 INFO:     Epoch: 24
2022-11-18 01:46:31,996 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7948433201421391, 'Total loss': 0.7948433201421391} | train loss {'Reaction outcome loss': 0.806632268706314, 'Total loss': 0.806632268706314}
2022-11-18 01:46:31,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:31,997 INFO:     Epoch: 25
2022-11-18 01:46:32,815 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7588116587562994, 'Total loss': 0.7588116587562994} | train loss {'Reaction outcome loss': 0.8103970102060903, 'Total loss': 0.8103970102060903}
2022-11-18 01:46:32,815 INFO:     Found new best model at epoch 25
2022-11-18 01:46:32,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:32,816 INFO:     Epoch: 26
2022-11-18 01:46:33,595 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7596736374226484, 'Total loss': 0.7596736374226484} | train loss {'Reaction outcome loss': 0.8046486874220342, 'Total loss': 0.8046486874220342}
2022-11-18 01:46:33,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:33,595 INFO:     Epoch: 27
2022-11-18 01:46:34,385 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7735027440569617, 'Total loss': 0.7735027440569617} | train loss {'Reaction outcome loss': 0.8017320723314336, 'Total loss': 0.8017320723314336}
2022-11-18 01:46:34,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:34,385 INFO:     Epoch: 28
2022-11-18 01:46:35,196 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.755551740527153, 'Total loss': 0.755551740527153} | train loss {'Reaction outcome loss': 0.8035821006124318, 'Total loss': 0.8035821006124318}
2022-11-18 01:46:35,196 INFO:     Found new best model at epoch 28
2022-11-18 01:46:35,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:35,197 INFO:     Epoch: 29
2022-11-18 01:46:35,990 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.79193215072155, 'Total loss': 0.79193215072155} | train loss {'Reaction outcome loss': 0.8049918738936606, 'Total loss': 0.8049918738936606}
2022-11-18 01:46:35,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:35,991 INFO:     Epoch: 30
2022-11-18 01:46:36,772 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7779666632413864, 'Total loss': 0.7779666632413864} | train loss {'Reaction outcome loss': 0.8013174515745418, 'Total loss': 0.8013174515745418}
2022-11-18 01:46:36,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:36,772 INFO:     Epoch: 31
2022-11-18 01:46:37,573 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7594890323552218, 'Total loss': 0.7594890323552218} | train loss {'Reaction outcome loss': 0.808682797650094, 'Total loss': 0.808682797650094}
2022-11-18 01:46:37,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:37,573 INFO:     Epoch: 32
2022-11-18 01:46:38,395 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8126326636834578, 'Total loss': 0.8126326636834578} | train loss {'Reaction outcome loss': 0.8014572508904615, 'Total loss': 0.8014572508904615}
2022-11-18 01:46:38,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:38,395 INFO:     Epoch: 33
2022-11-18 01:46:39,209 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7719638178294356, 'Total loss': 0.7719638178294356} | train loss {'Reaction outcome loss': 0.8090091611933612, 'Total loss': 0.8090091611933612}
2022-11-18 01:46:39,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:39,209 INFO:     Epoch: 34
2022-11-18 01:46:40,013 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7839410772377794, 'Total loss': 0.7839410772377794} | train loss {'Reaction outcome loss': 0.8089963350339457, 'Total loss': 0.8089963350339457}
2022-11-18 01:46:40,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:40,013 INFO:     Epoch: 35
2022-11-18 01:46:40,850 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7647719261321154, 'Total loss': 0.7647719261321154} | train loss {'Reaction outcome loss': 0.8098406286133446, 'Total loss': 0.8098406286133446}
2022-11-18 01:46:40,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:40,852 INFO:     Epoch: 36
2022-11-18 01:46:41,643 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7942259481007402, 'Total loss': 0.7942259481007402} | train loss {'Reaction outcome loss': 0.8083605309005691, 'Total loss': 0.8083605309005691}
2022-11-18 01:46:41,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:41,644 INFO:     Epoch: 37
2022-11-18 01:46:42,446 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7610562660477378, 'Total loss': 0.7610562660477378} | train loss {'Reaction outcome loss': 0.8007976420615849, 'Total loss': 0.8007976420615849}
2022-11-18 01:46:42,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:42,446 INFO:     Epoch: 38
2022-11-18 01:46:43,290 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7599361064759168, 'Total loss': 0.7599361064759168} | train loss {'Reaction outcome loss': 0.8043808097298811, 'Total loss': 0.8043808097298811}
2022-11-18 01:46:43,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:43,290 INFO:     Epoch: 39
2022-11-18 01:46:44,078 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7611749267036264, 'Total loss': 0.7611749267036264} | train loss {'Reaction outcome loss': 0.8039444853902346, 'Total loss': 0.8039444853902346}
2022-11-18 01:46:44,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:44,078 INFO:     Epoch: 40
2022-11-18 01:46:44,897 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7820797047831796, 'Total loss': 0.7820797047831796} | train loss {'Reaction outcome loss': 0.8002067515965898, 'Total loss': 0.8002067515965898}
2022-11-18 01:46:44,898 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:44,898 INFO:     Epoch: 41
2022-11-18 01:46:45,697 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7791433178565719, 'Total loss': 0.7791433178565719} | train loss {'Reaction outcome loss': 0.8054708436825256, 'Total loss': 0.8054708436825256}
2022-11-18 01:46:45,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:45,697 INFO:     Epoch: 42
2022-11-18 01:46:46,477 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7584063292227008, 'Total loss': 0.7584063292227008} | train loss {'Reaction outcome loss': 0.8024918987200811, 'Total loss': 0.8024918987200811}
2022-11-18 01:46:46,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:46,477 INFO:     Epoch: 43
2022-11-18 01:46:47,313 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7679040635173972, 'Total loss': 0.7679040635173972} | train loss {'Reaction outcome loss': 0.807948603683155, 'Total loss': 0.807948603683155}
2022-11-18 01:46:47,314 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:47,314 INFO:     Epoch: 44
2022-11-18 01:46:48,153 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7664026922800324, 'Total loss': 0.7664026922800324} | train loss {'Reaction outcome loss': 0.8023297742371135, 'Total loss': 0.8023297742371135}
2022-11-18 01:46:48,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:48,154 INFO:     Epoch: 45
2022-11-18 01:46:48,979 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8014999790625139, 'Total loss': 0.8014999790625139} | train loss {'Reaction outcome loss': 0.803463542389001, 'Total loss': 0.803463542389001}
2022-11-18 01:46:48,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:48,979 INFO:     Epoch: 46
2022-11-18 01:46:49,776 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7666796039451252, 'Total loss': 0.7666796039451252} | train loss {'Reaction outcome loss': 0.8141623455503209, 'Total loss': 0.8141623455503209}
2022-11-18 01:46:49,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:49,776 INFO:     Epoch: 47
2022-11-18 01:46:50,590 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7708178304813125, 'Total loss': 0.7708178304813125} | train loss {'Reaction outcome loss': 0.8147524213983945, 'Total loss': 0.8147524213983945}
2022-11-18 01:46:50,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:50,591 INFO:     Epoch: 48
2022-11-18 01:46:51,428 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7756190150976181, 'Total loss': 0.7756190150976181} | train loss {'Reaction outcome loss': 0.8062794335216645, 'Total loss': 0.8062794335216645}
2022-11-18 01:46:51,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:51,429 INFO:     Epoch: 49
2022-11-18 01:46:52,257 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7616030316461216, 'Total loss': 0.7616030316461216} | train loss {'Reaction outcome loss': 0.8020193833209243, 'Total loss': 0.8020193833209243}
2022-11-18 01:46:52,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:52,257 INFO:     Epoch: 50
2022-11-18 01:46:53,047 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7786641981114041, 'Total loss': 0.7786641981114041} | train loss {'Reaction outcome loss': 0.7972580325989588, 'Total loss': 0.7972580325989588}
2022-11-18 01:46:53,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:53,047 INFO:     Epoch: 51
2022-11-18 01:46:53,875 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7637904963710092, 'Total loss': 0.7637904963710092} | train loss {'Reaction outcome loss': 0.8066869562695383, 'Total loss': 0.8066869562695383}
2022-11-18 01:46:53,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:53,876 INFO:     Epoch: 52
2022-11-18 01:46:54,719 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7640044350515712, 'Total loss': 0.7640044350515712} | train loss {'Reaction outcome loss': 0.8053583254215688, 'Total loss': 0.8053583254215688}
2022-11-18 01:46:54,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:54,720 INFO:     Epoch: 53
2022-11-18 01:46:55,524 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8128059899265115, 'Total loss': 0.8128059899265115} | train loss {'Reaction outcome loss': 0.8033985758599965, 'Total loss': 0.8033985758599965}
2022-11-18 01:46:55,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:55,525 INFO:     Epoch: 54
2022-11-18 01:46:56,357 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7660534910180352, 'Total loss': 0.7660534910180352} | train loss {'Reaction outcome loss': 0.8026562191636456, 'Total loss': 0.8026562191636456}
2022-11-18 01:46:56,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:56,357 INFO:     Epoch: 55
2022-11-18 01:46:57,179 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7756724520163103, 'Total loss': 0.7756724520163103} | train loss {'Reaction outcome loss': 0.8125466892593786, 'Total loss': 0.8125466892593786}
2022-11-18 01:46:57,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:57,180 INFO:     Epoch: 56
2022-11-18 01:46:57,996 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7814866968176581, 'Total loss': 0.7814866968176581} | train loss {'Reaction outcome loss': 0.804412461244143, 'Total loss': 0.804412461244143}
2022-11-18 01:46:57,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:57,996 INFO:     Epoch: 57
2022-11-18 01:46:58,804 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7699746618216688, 'Total loss': 0.7699746618216688} | train loss {'Reaction outcome loss': 0.7950857950125628, 'Total loss': 0.7950857950125628}
2022-11-18 01:46:58,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:58,804 INFO:     Epoch: 58
2022-11-18 01:46:59,632 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7790572263977744, 'Total loss': 0.7790572263977744} | train loss {'Reaction outcome loss': 0.8128454764844918, 'Total loss': 0.8128454764844918}
2022-11-18 01:46:59,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:46:59,634 INFO:     Epoch: 59
2022-11-18 01:47:00,457 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.767816882241856, 'Total loss': 0.767816882241856} | train loss {'Reaction outcome loss': 0.8085668949704421, 'Total loss': 0.8085668949704421}
2022-11-18 01:47:00,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:00,458 INFO:     Epoch: 60
2022-11-18 01:47:01,246 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.775152409618551, 'Total loss': 0.775152409618551} | train loss {'Reaction outcome loss': 0.8026264096319917, 'Total loss': 0.8026264096319917}
2022-11-18 01:47:01,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:01,247 INFO:     Epoch: 61
2022-11-18 01:47:02,105 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7901552265340631, 'Total loss': 0.7901552265340631} | train loss {'Reaction outcome loss': 0.8010573877014129, 'Total loss': 0.8010573877014129}
2022-11-18 01:47:02,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:02,105 INFO:     Epoch: 62
2022-11-18 01:47:02,928 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7677719870751555, 'Total loss': 0.7677719870751555} | train loss {'Reaction outcome loss': 0.8012161297112824, 'Total loss': 0.8012161297112824}
2022-11-18 01:47:02,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:02,928 INFO:     Epoch: 63
2022-11-18 01:47:03,736 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7787445878440683, 'Total loss': 0.7787445878440683} | train loss {'Reaction outcome loss': 0.8016815267593754, 'Total loss': 0.8016815267593754}
2022-11-18 01:47:03,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:03,737 INFO:     Epoch: 64
2022-11-18 01:47:04,542 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7947186008095741, 'Total loss': 0.7947186008095741} | train loss {'Reaction outcome loss': 0.8086956493285021, 'Total loss': 0.8086956493285021}
2022-11-18 01:47:04,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:04,542 INFO:     Epoch: 65
2022-11-18 01:47:05,396 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.777250276370482, 'Total loss': 0.777250276370482} | train loss {'Reaction outcome loss': 0.8116228801277485, 'Total loss': 0.8116228801277485}
2022-11-18 01:47:05,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:05,396 INFO:     Epoch: 66
2022-11-18 01:47:06,191 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8025000271472064, 'Total loss': 0.8025000271472064} | train loss {'Reaction outcome loss': 0.80770886390798, 'Total loss': 0.80770886390798}
2022-11-18 01:47:06,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:06,191 INFO:     Epoch: 67
2022-11-18 01:47:06,999 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7764444967562502, 'Total loss': 0.7764444967562502} | train loss {'Reaction outcome loss': 0.7990877144491142, 'Total loss': 0.7990877144491142}
2022-11-18 01:47:06,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:06,999 INFO:     Epoch: 68
2022-11-18 01:47:07,812 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7790954492308877, 'Total loss': 0.7790954492308877} | train loss {'Reaction outcome loss': 0.8044007324014115, 'Total loss': 0.8044007324014115}
2022-11-18 01:47:07,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:07,812 INFO:     Epoch: 69
2022-11-18 01:47:08,663 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7727971239523455, 'Total loss': 0.7727971239523455} | train loss {'Reaction outcome loss': 0.8093527861934925, 'Total loss': 0.8093527861934925}
2022-11-18 01:47:08,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:08,663 INFO:     Epoch: 70
2022-11-18 01:47:09,477 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7699534811756827, 'Total loss': 0.7699534811756827} | train loss {'Reaction outcome loss': 0.8089869071838827, 'Total loss': 0.8089869071838827}
2022-11-18 01:47:09,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:09,478 INFO:     Epoch: 71
2022-11-18 01:47:10,283 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7725272320888259, 'Total loss': 0.7725272320888259} | train loss {'Reaction outcome loss': 0.8028073297127297, 'Total loss': 0.8028073297127297}
2022-11-18 01:47:10,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:10,283 INFO:     Epoch: 72
2022-11-18 01:47:11,102 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7799646549604156, 'Total loss': 0.7799646549604156} | train loss {'Reaction outcome loss': 0.8012622555016506, 'Total loss': 0.8012622555016506}
2022-11-18 01:47:11,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:11,102 INFO:     Epoch: 73
2022-11-18 01:47:11,891 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7647171027281068, 'Total loss': 0.7647171027281068} | train loss {'Reaction outcome loss': 0.8149011254551922, 'Total loss': 0.8149011254551922}
2022-11-18 01:47:11,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:11,891 INFO:     Epoch: 74
2022-11-18 01:47:12,695 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7524236366152763, 'Total loss': 0.7524236366152763} | train loss {'Reaction outcome loss': 0.8023907679777879, 'Total loss': 0.8023907679777879}
2022-11-18 01:47:12,696 INFO:     Found new best model at epoch 74
2022-11-18 01:47:12,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:12,697 INFO:     Epoch: 75
2022-11-18 01:47:13,531 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7557298737493429, 'Total loss': 0.7557298737493429} | train loss {'Reaction outcome loss': 0.8032445077471405, 'Total loss': 0.8032445077471405}
2022-11-18 01:47:13,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:13,531 INFO:     Epoch: 76
2022-11-18 01:47:14,346 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7684761773456227, 'Total loss': 0.7684761773456227} | train loss {'Reaction outcome loss': 0.8015895817685224, 'Total loss': 0.8015895817685224}
2022-11-18 01:47:14,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:14,346 INFO:     Epoch: 77
2022-11-18 01:47:15,140 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7936353121291507, 'Total loss': 0.7936353121291507} | train loss {'Reaction outcome loss': 0.8058590628357551, 'Total loss': 0.8058590628357551}
2022-11-18 01:47:15,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:15,140 INFO:     Epoch: 78
2022-11-18 01:47:15,967 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8045339564030821, 'Total loss': 0.8045339564030821} | train loss {'Reaction outcome loss': 0.8057787512478075, 'Total loss': 0.8057787512478075}
2022-11-18 01:47:15,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:15,967 INFO:     Epoch: 79
2022-11-18 01:47:16,783 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7988218102942813, 'Total loss': 0.7988218102942813} | train loss {'Reaction outcome loss': 0.8025791242055083, 'Total loss': 0.8025791242055083}
2022-11-18 01:47:16,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:16,783 INFO:     Epoch: 80
2022-11-18 01:47:17,621 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7573914683677934, 'Total loss': 0.7573914683677934} | train loss {'Reaction outcome loss': 0.8056285016932468, 'Total loss': 0.8056285016932468}
2022-11-18 01:47:17,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:17,621 INFO:     Epoch: 81
2022-11-18 01:47:18,468 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7988125505772504, 'Total loss': 0.7988125505772504} | train loss {'Reaction outcome loss': 0.804663786762639, 'Total loss': 0.804663786762639}
2022-11-18 01:47:18,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:18,469 INFO:     Epoch: 82
2022-11-18 01:47:19,284 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7654599791223352, 'Total loss': 0.7654599791223352} | train loss {'Reaction outcome loss': 0.8118125112191868, 'Total loss': 0.8118125112191868}
2022-11-18 01:47:19,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:19,285 INFO:     Epoch: 83
2022-11-18 01:47:20,110 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7666511488231745, 'Total loss': 0.7666511488231745} | train loss {'Reaction outcome loss': 0.8008978681767035, 'Total loss': 0.8008978681767035}
2022-11-18 01:47:20,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:20,110 INFO:     Epoch: 84
2022-11-18 01:47:20,931 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7700857777487148, 'Total loss': 0.7700857777487148} | train loss {'Reaction outcome loss': 0.8054300599735276, 'Total loss': 0.8054300599735276}
2022-11-18 01:47:20,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:20,931 INFO:     Epoch: 85
2022-11-18 01:47:21,751 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7593515718525107, 'Total loss': 0.7593515718525107} | train loss {'Reaction outcome loss': 0.8072253760055974, 'Total loss': 0.8072253760055974}
2022-11-18 01:47:21,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:21,751 INFO:     Epoch: 86
2022-11-18 01:47:22,553 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7711227360096845, 'Total loss': 0.7711227360096845} | train loss {'Reaction outcome loss': 0.8065739380203278, 'Total loss': 0.8065739380203278}
2022-11-18 01:47:22,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:22,554 INFO:     Epoch: 87
2022-11-18 01:47:23,386 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7642317678440701, 'Total loss': 0.7642317678440701} | train loss {'Reaction outcome loss': 0.8081639368041806, 'Total loss': 0.8081639368041806}
2022-11-18 01:47:23,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:23,386 INFO:     Epoch: 88
2022-11-18 01:47:24,219 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7803028320724313, 'Total loss': 0.7803028320724313} | train loss {'Reaction outcome loss': 0.8022988233489063, 'Total loss': 0.8022988233489063}
2022-11-18 01:47:24,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:24,220 INFO:     Epoch: 89
2022-11-18 01:47:25,008 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7814359597184442, 'Total loss': 0.7814359597184442} | train loss {'Reaction outcome loss': 0.8070536290827067, 'Total loss': 0.8070536290827067}
2022-11-18 01:47:25,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:25,009 INFO:     Epoch: 90
2022-11-18 01:47:25,811 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7707887129350142, 'Total loss': 0.7707887129350142} | train loss {'Reaction outcome loss': 0.8032168986781044, 'Total loss': 0.8032168986781044}
2022-11-18 01:47:25,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:25,811 INFO:     Epoch: 91
2022-11-18 01:47:26,651 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7590282810005274, 'Total loss': 0.7590282810005274} | train loss {'Reaction outcome loss': 0.8014825641626289, 'Total loss': 0.8014825641626289}
2022-11-18 01:47:26,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:26,652 INFO:     Epoch: 92
2022-11-18 01:47:27,463 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7709567665376447, 'Total loss': 0.7709567665376447} | train loss {'Reaction outcome loss': 0.8006032029777644, 'Total loss': 0.8006032029777644}
2022-11-18 01:47:27,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:27,463 INFO:     Epoch: 93
2022-11-18 01:47:28,221 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7754072242162444, 'Total loss': 0.7754072242162444} | train loss {'Reaction outcome loss': 0.807482546519654, 'Total loss': 0.807482546519654}
2022-11-18 01:47:28,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:28,221 INFO:     Epoch: 94
2022-11-18 01:47:29,022 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7803657407110388, 'Total loss': 0.7803657407110388} | train loss {'Reaction outcome loss': 0.8032885764533209, 'Total loss': 0.8032885764533209}
2022-11-18 01:47:29,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:29,023 INFO:     Epoch: 95
2022-11-18 01:47:29,795 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7725736986507069, 'Total loss': 0.7725736986507069} | train loss {'Reaction outcome loss': 0.8033770875409547, 'Total loss': 0.8033770875409547}
2022-11-18 01:47:29,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:29,795 INFO:     Epoch: 96
2022-11-18 01:47:30,629 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7704963751814582, 'Total loss': 0.7704963751814582} | train loss {'Reaction outcome loss': 0.8041676284089262, 'Total loss': 0.8041676284089262}
2022-11-18 01:47:30,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:30,630 INFO:     Epoch: 97
2022-11-18 01:47:31,417 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7570279802788388, 'Total loss': 0.7570279802788388} | train loss {'Reaction outcome loss': 0.8004011008662251, 'Total loss': 0.8004011008662251}
2022-11-18 01:47:31,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:31,418 INFO:     Epoch: 98
2022-11-18 01:47:32,210 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7913650450381365, 'Total loss': 0.7913650450381365} | train loss {'Reaction outcome loss': 0.7998161886626409, 'Total loss': 0.7998161886626409}
2022-11-18 01:47:32,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:32,210 INFO:     Epoch: 99
2022-11-18 01:47:33,009 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7618347413160584, 'Total loss': 0.7618347413160584} | train loss {'Reaction outcome loss': 0.8027304666350606, 'Total loss': 0.8027304666350606}
2022-11-18 01:47:33,009 INFO:     Best model found after epoch 75 of 100.
2022-11-18 01:47:33,010 INFO:   Done with stage: TRAINING
2022-11-18 01:47:33,010 INFO:   Starting stage: EVALUATION
2022-11-18 01:47:33,137 INFO:   Done with stage: EVALUATION
2022-11-18 01:47:33,145 INFO:   Leaving out SEQ value Fold_0
2022-11-18 01:47:33,158 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 01:47:33,158 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:47:33,826 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:47:33,826 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:47:33,895 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:47:33,895 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:47:33,895 INFO:     No hyperparam tuning for this model
2022-11-18 01:47:33,895 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:47:33,896 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:47:33,896 INFO:     None feature selector for col prot
2022-11-18 01:47:33,896 INFO:     None feature selector for col prot
2022-11-18 01:47:33,897 INFO:     None feature selector for col prot
2022-11-18 01:47:33,897 INFO:     None feature selector for col chem
2022-11-18 01:47:33,897 INFO:     None feature selector for col chem
2022-11-18 01:47:33,897 INFO:     None feature selector for col chem
2022-11-18 01:47:33,897 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:47:33,897 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:47:33,899 INFO:     Number of params in model 168571
2022-11-18 01:47:33,902 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:47:33,902 INFO:   Starting stage: TRAINING
2022-11-18 01:47:33,959 INFO:     Val loss before train {'Reaction outcome loss': 0.99750132587823, 'Total loss': 0.99750132587823}
2022-11-18 01:47:33,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:33,959 INFO:     Epoch: 0
2022-11-18 01:47:34,752 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8612251620401036, 'Total loss': 0.8612251620401036} | train loss {'Reaction outcome loss': 0.8738826405905519, 'Total loss': 0.8738826405905519}
2022-11-18 01:47:34,752 INFO:     Found new best model at epoch 0
2022-11-18 01:47:34,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:34,753 INFO:     Epoch: 1
2022-11-18 01:47:35,516 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8564659275791862, 'Total loss': 0.8564659275791862} | train loss {'Reaction outcome loss': 0.8485789244715501, 'Total loss': 0.8485789244715501}
2022-11-18 01:47:35,516 INFO:     Found new best model at epoch 1
2022-11-18 01:47:35,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:35,517 INFO:     Epoch: 2
2022-11-18 01:47:36,333 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8440613909201189, 'Total loss': 0.8440613909201189} | train loss {'Reaction outcome loss': 0.8326257183725535, 'Total loss': 0.8326257183725535}
2022-11-18 01:47:36,333 INFO:     Found new best model at epoch 2
2022-11-18 01:47:36,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:36,334 INFO:     Epoch: 3
2022-11-18 01:47:37,109 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8243588507175446, 'Total loss': 0.8243588507175446} | train loss {'Reaction outcome loss': 0.8320356492812817, 'Total loss': 0.8320356492812817}
2022-11-18 01:47:37,110 INFO:     Found new best model at epoch 3
2022-11-18 01:47:37,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:37,111 INFO:     Epoch: 4
2022-11-18 01:47:37,926 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8256454847075723, 'Total loss': 0.8256454847075723} | train loss {'Reaction outcome loss': 0.8297716452766527, 'Total loss': 0.8297716452766527}
2022-11-18 01:47:37,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:37,926 INFO:     Epoch: 5
2022-11-18 01:47:38,723 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8332825567234646, 'Total loss': 0.8332825567234646} | train loss {'Reaction outcome loss': 0.8279536442476728, 'Total loss': 0.8279536442476728}
2022-11-18 01:47:38,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:38,724 INFO:     Epoch: 6
2022-11-18 01:47:39,519 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8187064040790905, 'Total loss': 0.8187064040790905} | train loss {'Reaction outcome loss': 0.8199188530535592, 'Total loss': 0.8199188530535592}
2022-11-18 01:47:39,519 INFO:     Found new best model at epoch 6
2022-11-18 01:47:39,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:39,520 INFO:     Epoch: 7
2022-11-18 01:47:40,312 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8244408071041107, 'Total loss': 0.8244408071041107} | train loss {'Reaction outcome loss': 0.8264065787859773, 'Total loss': 0.8264065787859773}
2022-11-18 01:47:40,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:40,313 INFO:     Epoch: 8
2022-11-18 01:47:41,105 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8114955425262451, 'Total loss': 0.8114955425262451} | train loss {'Reaction outcome loss': 0.8305533406464195, 'Total loss': 0.8305533406464195}
2022-11-18 01:47:41,106 INFO:     Found new best model at epoch 8
2022-11-18 01:47:41,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:41,106 INFO:     Epoch: 9
2022-11-18 01:47:41,901 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8140066611495885, 'Total loss': 0.8140066611495885} | train loss {'Reaction outcome loss': 0.81917639492977, 'Total loss': 0.81917639492977}
2022-11-18 01:47:41,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:41,901 INFO:     Epoch: 10
2022-11-18 01:47:42,731 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7946797399358316, 'Total loss': 0.7946797399358316} | train loss {'Reaction outcome loss': 0.8194577491235154, 'Total loss': 0.8194577491235154}
2022-11-18 01:47:42,731 INFO:     Found new best model at epoch 10
2022-11-18 01:47:42,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:42,732 INFO:     Epoch: 11
2022-11-18 01:47:43,520 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8216558478095315, 'Total loss': 0.8216558478095315} | train loss {'Reaction outcome loss': 0.8167140423527613, 'Total loss': 0.8167140423527613}
2022-11-18 01:47:43,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:43,521 INFO:     Epoch: 12
2022-11-18 01:47:44,304 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8430151993578131, 'Total loss': 0.8430151993578131} | train loss {'Reaction outcome loss': 0.8136611094600276, 'Total loss': 0.8136611094600276}
2022-11-18 01:47:44,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:44,304 INFO:     Epoch: 13
2022-11-18 01:47:45,135 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8163527805696834, 'Total loss': 0.8163527805696834} | train loss {'Reaction outcome loss': 0.814516841038036, 'Total loss': 0.814516841038036}
2022-11-18 01:47:45,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:45,135 INFO:     Epoch: 14
2022-11-18 01:47:45,928 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8236752193082463, 'Total loss': 0.8236752193082463} | train loss {'Reaction outcome loss': 0.8159184093900055, 'Total loss': 0.8159184093900055}
2022-11-18 01:47:45,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:45,929 INFO:     Epoch: 15
2022-11-18 01:47:46,751 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8116305375641043, 'Total loss': 0.8116305375641043} | train loss {'Reaction outcome loss': 0.8116700438111417, 'Total loss': 0.8116700438111417}
2022-11-18 01:47:46,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:46,751 INFO:     Epoch: 16
2022-11-18 01:47:47,559 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8169437470761213, 'Total loss': 0.8169437470761213} | train loss {'Reaction outcome loss': 0.8235088293610314, 'Total loss': 0.8235088293610314}
2022-11-18 01:47:47,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:47,560 INFO:     Epoch: 17
2022-11-18 01:47:48,405 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7941801349886439, 'Total loss': 0.7941801349886439} | train loss {'Reaction outcome loss': 0.821578411800176, 'Total loss': 0.821578411800176}
2022-11-18 01:47:48,406 INFO:     Found new best model at epoch 17
2022-11-18 01:47:48,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:48,406 INFO:     Epoch: 18
2022-11-18 01:47:49,242 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8041417381980203, 'Total loss': 0.8041417381980203} | train loss {'Reaction outcome loss': 0.8166878562465854, 'Total loss': 0.8166878562465854}
2022-11-18 01:47:49,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:49,243 INFO:     Epoch: 19
2022-11-18 01:47:50,026 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8164730410684239, 'Total loss': 0.8164730410684239} | train loss {'Reaction outcome loss': 0.8151745215842598, 'Total loss': 0.8151745215842598}
2022-11-18 01:47:50,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:50,027 INFO:     Epoch: 20
2022-11-18 01:47:50,801 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8206979537552054, 'Total loss': 0.8206979537552054} | train loss {'Reaction outcome loss': 0.8271130138804555, 'Total loss': 0.8271130138804555}
2022-11-18 01:47:50,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:50,801 INFO:     Epoch: 21
2022-11-18 01:47:51,605 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8136536871845071, 'Total loss': 0.8136536871845071} | train loss {'Reaction outcome loss': 0.8193894909461018, 'Total loss': 0.8193894909461018}
2022-11-18 01:47:51,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:51,605 INFO:     Epoch: 22
2022-11-18 01:47:52,421 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7972529787908901, 'Total loss': 0.7972529787908901} | train loss {'Reaction outcome loss': 0.8112223192989102, 'Total loss': 0.8112223192989102}
2022-11-18 01:47:52,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:52,422 INFO:     Epoch: 23
2022-11-18 01:47:53,204 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8379837823185053, 'Total loss': 0.8379837823185053} | train loss {'Reaction outcome loss': 0.8117904121335219, 'Total loss': 0.8117904121335219}
2022-11-18 01:47:53,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:53,205 INFO:     Epoch: 24
2022-11-18 01:47:53,975 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.799512811682441, 'Total loss': 0.799512811682441} | train loss {'Reaction outcome loss': 0.8230465860501958, 'Total loss': 0.8230465860501958}
2022-11-18 01:47:53,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:53,976 INFO:     Epoch: 25
2022-11-18 01:47:54,750 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8079125068404458, 'Total loss': 0.8079125068404458} | train loss {'Reaction outcome loss': 0.814930469642284, 'Total loss': 0.814930469642284}
2022-11-18 01:47:54,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:54,751 INFO:     Epoch: 26
2022-11-18 01:47:55,527 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8308067294684324, 'Total loss': 0.8308067294684324} | train loss {'Reaction outcome loss': 0.8071219361564408, 'Total loss': 0.8071219361564408}
2022-11-18 01:47:55,527 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:55,527 INFO:     Epoch: 27
2022-11-18 01:47:56,314 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8191231462088499, 'Total loss': 0.8191231462088499} | train loss {'Reaction outcome loss': 0.8102495568212469, 'Total loss': 0.8102495568212469}
2022-11-18 01:47:56,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:56,315 INFO:     Epoch: 28
2022-11-18 01:47:57,090 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8102238137613643, 'Total loss': 0.8102238137613643} | train loss {'Reaction outcome loss': 0.8132145307083362, 'Total loss': 0.8132145307083362}
2022-11-18 01:47:57,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:57,090 INFO:     Epoch: 29
2022-11-18 01:47:57,869 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8150751367211342, 'Total loss': 0.8150751367211342} | train loss {'Reaction outcome loss': 0.8178981033413999, 'Total loss': 0.8178981033413999}
2022-11-18 01:47:57,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:57,869 INFO:     Epoch: 30
2022-11-18 01:47:58,691 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8133410188284788, 'Total loss': 0.8133410188284788} | train loss {'Reaction outcome loss': 0.8216343464156394, 'Total loss': 0.8216343464156394}
2022-11-18 01:47:58,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:58,691 INFO:     Epoch: 31
2022-11-18 01:47:59,438 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8096392953937704, 'Total loss': 0.8096392953937704} | train loss {'Reaction outcome loss': 0.815949754314384, 'Total loss': 0.815949754314384}
2022-11-18 01:47:59,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:47:59,438 INFO:     Epoch: 32
2022-11-18 01:48:00,237 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8207693750208075, 'Total loss': 0.8207693750208075} | train loss {'Reaction outcome loss': 0.8080710715082614, 'Total loss': 0.8080710715082614}
2022-11-18 01:48:00,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:00,237 INFO:     Epoch: 33
2022-11-18 01:48:01,081 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8256851041858847, 'Total loss': 0.8256851041858847} | train loss {'Reaction outcome loss': 0.8089853267558673, 'Total loss': 0.8089853267558673}
2022-11-18 01:48:01,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:01,082 INFO:     Epoch: 34
2022-11-18 01:48:01,833 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8373934883962978, 'Total loss': 0.8373934883962978} | train loss {'Reaction outcome loss': 0.8157332831548776, 'Total loss': 0.8157332831548776}
2022-11-18 01:48:01,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:01,833 INFO:     Epoch: 35
2022-11-18 01:48:02,618 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8040890822356398, 'Total loss': 0.8040890822356398} | train loss {'Reaction outcome loss': 0.8130395539135102, 'Total loss': 0.8130395539135102}
2022-11-18 01:48:02,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:02,619 INFO:     Epoch: 36
2022-11-18 01:48:03,425 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8055574541742151, 'Total loss': 0.8055574541742151} | train loss {'Reaction outcome loss': 0.8135579692931311, 'Total loss': 0.8135579692931311}
2022-11-18 01:48:03,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:03,425 INFO:     Epoch: 37
2022-11-18 01:48:04,199 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7940244403752413, 'Total loss': 0.7940244403752413} | train loss {'Reaction outcome loss': 0.8101632094334977, 'Total loss': 0.8101632094334977}
2022-11-18 01:48:04,199 INFO:     Found new best model at epoch 37
2022-11-18 01:48:04,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:04,200 INFO:     Epoch: 38
2022-11-18 01:48:04,985 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.804945635524663, 'Total loss': 0.804945635524663} | train loss {'Reaction outcome loss': 0.8196474388543411, 'Total loss': 0.8196474388543411}
2022-11-18 01:48:04,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:04,985 INFO:     Epoch: 39
2022-11-18 01:48:05,766 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8162481459704313, 'Total loss': 0.8162481459704313} | train loss {'Reaction outcome loss': 0.8084954207966685, 'Total loss': 0.8084954207966685}
2022-11-18 01:48:05,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:05,766 INFO:     Epoch: 40
2022-11-18 01:48:06,524 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8062460320917043, 'Total loss': 0.8062460320917043} | train loss {'Reaction outcome loss': 0.8102744789982614, 'Total loss': 0.8102744789982614}
2022-11-18 01:48:06,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:06,525 INFO:     Epoch: 41
2022-11-18 01:48:07,312 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8022393069484017, 'Total loss': 0.8022393069484017} | train loss {'Reaction outcome loss': 0.81471162696599, 'Total loss': 0.81471162696599}
2022-11-18 01:48:07,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:07,313 INFO:     Epoch: 42
2022-11-18 01:48:08,093 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8150439052419229, 'Total loss': 0.8150439052419229} | train loss {'Reaction outcome loss': 0.8079022584173844, 'Total loss': 0.8079022584173844}
2022-11-18 01:48:08,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:08,093 INFO:     Epoch: 43
2022-11-18 01:48:08,869 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8080173168670047, 'Total loss': 0.8080173168670047} | train loss {'Reaction outcome loss': 0.8137828561699825, 'Total loss': 0.8137828561699825}
2022-11-18 01:48:08,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:08,869 INFO:     Epoch: 44
2022-11-18 01:48:09,667 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8142922039736401, 'Total loss': 0.8142922039736401} | train loss {'Reaction outcome loss': 0.8111274912048448, 'Total loss': 0.8111274912048448}
2022-11-18 01:48:09,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:09,667 INFO:     Epoch: 45
2022-11-18 01:48:10,467 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8054524294354699, 'Total loss': 0.8054524294354699} | train loss {'Reaction outcome loss': 0.8086293431277941, 'Total loss': 0.8086293431277941}
2022-11-18 01:48:10,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:10,468 INFO:     Epoch: 46
2022-11-18 01:48:11,277 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8082854124632749, 'Total loss': 0.8082854124632749} | train loss {'Reaction outcome loss': 0.8080346702564101, 'Total loss': 0.8080346702564101}
2022-11-18 01:48:11,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:11,277 INFO:     Epoch: 47
2022-11-18 01:48:12,075 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8014958663420244, 'Total loss': 0.8014958663420244} | train loss {'Reaction outcome loss': 0.8052889622506584, 'Total loss': 0.8052889622506584}
2022-11-18 01:48:12,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:12,075 INFO:     Epoch: 48
2022-11-18 01:48:12,859 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8100834082473408, 'Total loss': 0.8100834082473408} | train loss {'Reaction outcome loss': 0.8055475022085765, 'Total loss': 0.8055475022085765}
2022-11-18 01:48:12,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:12,859 INFO:     Epoch: 49
2022-11-18 01:48:13,686 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8241720077666369, 'Total loss': 0.8241720077666369} | train loss {'Reaction outcome loss': 0.81426812786805, 'Total loss': 0.81426812786805}
2022-11-18 01:48:13,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:13,686 INFO:     Epoch: 50
2022-11-18 01:48:14,484 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.810919114811854, 'Total loss': 0.810919114811854} | train loss {'Reaction outcome loss': 0.810892028123261, 'Total loss': 0.810892028123261}
2022-11-18 01:48:14,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:14,486 INFO:     Epoch: 51
2022-11-18 01:48:15,265 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7995859682559967, 'Total loss': 0.7995859682559967} | train loss {'Reaction outcome loss': 0.8115785397016085, 'Total loss': 0.8115785397016085}
2022-11-18 01:48:15,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:15,265 INFO:     Epoch: 52
2022-11-18 01:48:16,053 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8089408292011782, 'Total loss': 0.8089408292011782} | train loss {'Reaction outcome loss': 0.8141958263480229, 'Total loss': 0.8141958263480229}
2022-11-18 01:48:16,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:16,053 INFO:     Epoch: 53
2022-11-18 01:48:16,851 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7995250225067139, 'Total loss': 0.7995250225067139} | train loss {'Reaction outcome loss': 0.8080947905296256, 'Total loss': 0.8080947905296256}
2022-11-18 01:48:16,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:16,852 INFO:     Epoch: 54
2022-11-18 01:48:17,637 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8386573764410886, 'Total loss': 0.8386573764410886} | train loss {'Reaction outcome loss': 0.8055573683759945, 'Total loss': 0.8055573683759945}
2022-11-18 01:48:17,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:17,638 INFO:     Epoch: 55
2022-11-18 01:48:18,413 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8052514473145659, 'Total loss': 0.8052514473145659} | train loss {'Reaction outcome loss': 0.8104627198777218, 'Total loss': 0.8104627198777218}
2022-11-18 01:48:18,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:18,414 INFO:     Epoch: 56
2022-11-18 01:48:19,187 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8066038179465316, 'Total loss': 0.8066038179465316} | train loss {'Reaction outcome loss': 0.8097624796846135, 'Total loss': 0.8097624796846135}
2022-11-18 01:48:19,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:19,188 INFO:     Epoch: 57
2022-11-18 01:48:19,992 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8227688670158386, 'Total loss': 0.8227688670158386} | train loss {'Reaction outcome loss': 0.8105820634587091, 'Total loss': 0.8105820634587091}
2022-11-18 01:48:19,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:19,992 INFO:     Epoch: 58
2022-11-18 01:48:20,767 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8089233968745578, 'Total loss': 0.8089233968745578} | train loss {'Reaction outcome loss': 0.817726047777454, 'Total loss': 0.817726047777454}
2022-11-18 01:48:20,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:20,768 INFO:     Epoch: 59
2022-11-18 01:48:21,563 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8271593898534775, 'Total loss': 0.8271593898534775} | train loss {'Reaction outcome loss': 0.814505070689236, 'Total loss': 0.814505070689236}
2022-11-18 01:48:21,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:21,563 INFO:     Epoch: 60
2022-11-18 01:48:22,348 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7966373962434855, 'Total loss': 0.7966373962434855} | train loss {'Reaction outcome loss': 0.8117002567902267, 'Total loss': 0.8117002567902267}
2022-11-18 01:48:22,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:22,349 INFO:     Epoch: 61
2022-11-18 01:48:23,141 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8015437932177023, 'Total loss': 0.8015437932177023} | train loss {'Reaction outcome loss': 0.8036570073018673, 'Total loss': 0.8036570073018673}
2022-11-18 01:48:23,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:23,141 INFO:     Epoch: 62
2022-11-18 01:48:23,953 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8134631900624796, 'Total loss': 0.8134631900624796} | train loss {'Reaction outcome loss': 0.8014064876415469, 'Total loss': 0.8014064876415469}
2022-11-18 01:48:23,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:23,954 INFO:     Epoch: 63
2022-11-18 01:48:24,750 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7984885302456942, 'Total loss': 0.7984885302456942} | train loss {'Reaction outcome loss': 0.8114249237364362, 'Total loss': 0.8114249237364362}
2022-11-18 01:48:24,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:24,750 INFO:     Epoch: 64
2022-11-18 01:48:25,537 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8069773851470514, 'Total loss': 0.8069773851470514} | train loss {'Reaction outcome loss': 0.8124559714726591, 'Total loss': 0.8124559714726591}
2022-11-18 01:48:25,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:25,537 INFO:     Epoch: 65
2022-11-18 01:48:26,320 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8105245889587835, 'Total loss': 0.8105245889587835} | train loss {'Reaction outcome loss': 0.8142627293040395, 'Total loss': 0.8142627293040395}
2022-11-18 01:48:26,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:26,320 INFO:     Epoch: 66
2022-11-18 01:48:27,131 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8303278373046354, 'Total loss': 0.8303278373046354} | train loss {'Reaction outcome loss': 0.8085357482858032, 'Total loss': 0.8085357482858032}
2022-11-18 01:48:27,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:27,131 INFO:     Epoch: 67
2022-11-18 01:48:27,911 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8347748477350582, 'Total loss': 0.8347748477350582} | train loss {'Reaction outcome loss': 0.8098902289684002, 'Total loss': 0.8098902289684002}
2022-11-18 01:48:27,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:27,911 INFO:     Epoch: 68
2022-11-18 01:48:28,694 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8013247712091967, 'Total loss': 0.8013247712091967} | train loss {'Reaction outcome loss': 0.8192221425805497, 'Total loss': 0.8192221425805497}
2022-11-18 01:48:28,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:28,695 INFO:     Epoch: 69
2022-11-18 01:48:29,466 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8244664059443907, 'Total loss': 0.8244664059443907} | train loss {'Reaction outcome loss': 0.8032682731084013, 'Total loss': 0.8032682731084013}
2022-11-18 01:48:29,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:29,466 INFO:     Epoch: 70
2022-11-18 01:48:30,277 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.806853664869612, 'Total loss': 0.806853664869612} | train loss {'Reaction outcome loss': 0.8089047273402272, 'Total loss': 0.8089047273402272}
2022-11-18 01:48:30,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:30,277 INFO:     Epoch: 71
2022-11-18 01:48:31,057 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8304077976129272, 'Total loss': 0.8304077976129272} | train loss {'Reaction outcome loss': 0.8118437421225343, 'Total loss': 0.8118437421225343}
2022-11-18 01:48:31,058 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:31,058 INFO:     Epoch: 72
2022-11-18 01:48:31,863 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.9182639216834848, 'Total loss': 0.9182639216834848} | train loss {'Reaction outcome loss': 0.8094102857325242, 'Total loss': 0.8094102857325242}
2022-11-18 01:48:31,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:31,864 INFO:     Epoch: 73
2022-11-18 01:48:32,634 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8421678021550179, 'Total loss': 0.8421678021550179} | train loss {'Reaction outcome loss': 0.8057106791237588, 'Total loss': 0.8057106791237588}
2022-11-18 01:48:32,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:32,635 INFO:     Epoch: 74
2022-11-18 01:48:33,453 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8168500621210445, 'Total loss': 0.8168500621210445} | train loss {'Reaction outcome loss': 0.8133305856573437, 'Total loss': 0.8133305856573437}
2022-11-18 01:48:33,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:33,454 INFO:     Epoch: 75
2022-11-18 01:48:34,252 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8203279660506682, 'Total loss': 0.8203279660506682} | train loss {'Reaction outcome loss': 0.810286208678052, 'Total loss': 0.810286208678052}
2022-11-18 01:48:34,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:34,252 INFO:     Epoch: 76
2022-11-18 01:48:35,077 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8084315122528509, 'Total loss': 0.8084315122528509} | train loss {'Reaction outcome loss': 0.8140956411960154, 'Total loss': 0.8140956411960154}
2022-11-18 01:48:35,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:35,077 INFO:     Epoch: 77
2022-11-18 01:48:35,862 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.800088616257364, 'Total loss': 0.800088616257364} | train loss {'Reaction outcome loss': 0.81002365951596, 'Total loss': 0.81002365951596}
2022-11-18 01:48:35,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:35,863 INFO:     Epoch: 78
2022-11-18 01:48:36,645 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8213047391989015, 'Total loss': 0.8213047391989015} | train loss {'Reaction outcome loss': 0.8092291509574242, 'Total loss': 0.8092291509574242}
2022-11-18 01:48:36,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:36,645 INFO:     Epoch: 79
2022-11-18 01:48:37,418 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8410724360834468, 'Total loss': 0.8410724360834468} | train loss {'Reaction outcome loss': 0.8092556928816111, 'Total loss': 0.8092556928816111}
2022-11-18 01:48:37,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:37,418 INFO:     Epoch: 80
2022-11-18 01:48:38,188 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.81198750436306, 'Total loss': 0.81198750436306} | train loss {'Reaction outcome loss': 0.810540858550593, 'Total loss': 0.810540858550593}
2022-11-18 01:48:38,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:38,188 INFO:     Epoch: 81
2022-11-18 01:48:38,984 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8084438477050174, 'Total loss': 0.8084438477050174} | train loss {'Reaction outcome loss': 0.8129544488572882, 'Total loss': 0.8129544488572882}
2022-11-18 01:48:38,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:38,984 INFO:     Epoch: 82
2022-11-18 01:48:39,761 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.834633971479806, 'Total loss': 0.834633971479806} | train loss {'Reaction outcome loss': 0.8080968392281397, 'Total loss': 0.8080968392281397}
2022-11-18 01:48:39,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:39,762 INFO:     Epoch: 83
2022-11-18 01:48:40,552 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8054315664551475, 'Total loss': 0.8054315664551475} | train loss {'Reaction outcome loss': 0.8185163920948862, 'Total loss': 0.8185163920948862}
2022-11-18 01:48:40,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:40,552 INFO:     Epoch: 84
2022-11-18 01:48:41,358 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8035153976895593, 'Total loss': 0.8035153976895593} | train loss {'Reaction outcome loss': 0.8138375863855184, 'Total loss': 0.8138375863855184}
2022-11-18 01:48:41,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:41,358 INFO:     Epoch: 85
2022-11-18 01:48:42,162 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8118171529336409, 'Total loss': 0.8118171529336409} | train loss {'Reaction outcome loss': 0.8111078595584221, 'Total loss': 0.8111078595584221}
2022-11-18 01:48:42,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:42,162 INFO:     Epoch: 86
2022-11-18 01:48:42,947 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8320045132528652, 'Total loss': 0.8320045132528652} | train loss {'Reaction outcome loss': 0.8084772062687738, 'Total loss': 0.8084772062687738}
2022-11-18 01:48:42,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:42,947 INFO:     Epoch: 87
2022-11-18 01:48:43,745 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8118430972099304, 'Total loss': 0.8118430972099304} | train loss {'Reaction outcome loss': 0.8135271827701614, 'Total loss': 0.8135271827701614}
2022-11-18 01:48:43,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:43,745 INFO:     Epoch: 88
2022-11-18 01:48:44,535 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.808966884558851, 'Total loss': 0.808966884558851} | train loss {'Reaction outcome loss': 0.8064432664197466, 'Total loss': 0.8064432664197466}
2022-11-18 01:48:44,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:44,535 INFO:     Epoch: 89
2022-11-18 01:48:45,349 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8198888085105203, 'Total loss': 0.8198888085105203} | train loss {'Reaction outcome loss': 0.8143813003171311, 'Total loss': 0.8143813003171311}
2022-11-18 01:48:45,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:45,350 INFO:     Epoch: 90
2022-11-18 01:48:46,149 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7992727736180479, 'Total loss': 0.7992727736180479} | train loss {'Reaction outcome loss': 0.8111716553508511, 'Total loss': 0.8111716553508511}
2022-11-18 01:48:46,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:46,149 INFO:     Epoch: 91
2022-11-18 01:48:46,939 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8029677603732456, 'Total loss': 0.8029677603732456} | train loss {'Reaction outcome loss': 0.8100641005434971, 'Total loss': 0.8100641005434971}
2022-11-18 01:48:46,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:46,940 INFO:     Epoch: 92
2022-11-18 01:48:47,725 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8339640633626417, 'Total loss': 0.8339640633626417} | train loss {'Reaction outcome loss': 0.8152273916281186, 'Total loss': 0.8152273916281186}
2022-11-18 01:48:47,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:47,725 INFO:     Epoch: 93
2022-11-18 01:48:48,515 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7995569624684074, 'Total loss': 0.7995569624684074} | train loss {'Reaction outcome loss': 0.8196674920769356, 'Total loss': 0.8196674920769356}
2022-11-18 01:48:48,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:48,516 INFO:     Epoch: 94
2022-11-18 01:48:49,294 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8065747950564731, 'Total loss': 0.8065747950564731} | train loss {'Reaction outcome loss': 0.8089573642895048, 'Total loss': 0.8089573642895048}
2022-11-18 01:48:49,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:49,295 INFO:     Epoch: 95
2022-11-18 01:48:50,071 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8289146518165414, 'Total loss': 0.8289146518165414} | train loss {'Reaction outcome loss': 0.8109250359448344, 'Total loss': 0.8109250359448344}
2022-11-18 01:48:50,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:50,071 INFO:     Epoch: 96
2022-11-18 01:48:50,817 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8041049912571907, 'Total loss': 0.8041049912571907} | train loss {'Reaction outcome loss': 0.8116732525680712, 'Total loss': 0.8116732525680712}
2022-11-18 01:48:50,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:50,817 INFO:     Epoch: 97
2022-11-18 01:48:51,643 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8597762083465402, 'Total loss': 0.8597762083465402} | train loss {'Reaction outcome loss': 0.8153253856458162, 'Total loss': 0.8153253856458162}
2022-11-18 01:48:51,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:51,644 INFO:     Epoch: 98
2022-11-18 01:48:52,463 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8158977499062364, 'Total loss': 0.8158977499062364} | train loss {'Reaction outcome loss': 0.8225814980051296, 'Total loss': 0.8225814980051296}
2022-11-18 01:48:52,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:52,463 INFO:     Epoch: 99
2022-11-18 01:48:53,455 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8006965829567476, 'Total loss': 0.8006965829567476} | train loss {'Reaction outcome loss': 0.818543215089964, 'Total loss': 0.818543215089964}
2022-11-18 01:48:53,456 INFO:     Best model found after epoch 38 of 100.
2022-11-18 01:48:53,456 INFO:   Done with stage: TRAINING
2022-11-18 01:48:53,456 INFO:   Starting stage: EVALUATION
2022-11-18 01:48:53,650 INFO:   Done with stage: EVALUATION
2022-11-18 01:48:53,651 INFO:   Leaving out SEQ value Fold_1
2022-11-18 01:48:53,671 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 01:48:53,672 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:48:54,384 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:48:54,384 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:48:54,457 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:48:54,457 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:48:54,457 INFO:     No hyperparam tuning for this model
2022-11-18 01:48:54,457 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:48:54,457 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:48:54,458 INFO:     None feature selector for col prot
2022-11-18 01:48:54,458 INFO:     None feature selector for col prot
2022-11-18 01:48:54,458 INFO:     None feature selector for col prot
2022-11-18 01:48:54,459 INFO:     None feature selector for col chem
2022-11-18 01:48:54,459 INFO:     None feature selector for col chem
2022-11-18 01:48:54,459 INFO:     None feature selector for col chem
2022-11-18 01:48:54,460 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:48:54,460 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:48:54,461 INFO:     Number of params in model 168571
2022-11-18 01:48:54,466 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:48:54,466 INFO:   Starting stage: TRAINING
2022-11-18 01:48:54,526 INFO:     Val loss before train {'Reaction outcome loss': 0.9971103952689604, 'Total loss': 0.9971103952689604}
2022-11-18 01:48:54,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:54,526 INFO:     Epoch: 0
2022-11-18 01:48:55,381 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8159894360737368, 'Total loss': 0.8159894360737368} | train loss {'Reaction outcome loss': 0.8911170786932895, 'Total loss': 0.8911170786932895}
2022-11-18 01:48:55,382 INFO:     Found new best model at epoch 0
2022-11-18 01:48:55,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:55,382 INFO:     Epoch: 1
2022-11-18 01:48:56,184 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8146303140304305, 'Total loss': 0.8146303140304305} | train loss {'Reaction outcome loss': 0.8497510726454287, 'Total loss': 0.8497510726454287}
2022-11-18 01:48:56,185 INFO:     Found new best model at epoch 1
2022-11-18 01:48:56,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:56,185 INFO:     Epoch: 2
2022-11-18 01:48:56,965 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8164252977479588, 'Total loss': 0.8164252977479588} | train loss {'Reaction outcome loss': 0.8451171744207622, 'Total loss': 0.8451171744207622}
2022-11-18 01:48:56,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:56,965 INFO:     Epoch: 3
2022-11-18 01:48:57,773 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8060783865776929, 'Total loss': 0.8060783865776929} | train loss {'Reaction outcome loss': 0.8397363535305749, 'Total loss': 0.8397363535305749}
2022-11-18 01:48:57,773 INFO:     Found new best model at epoch 3
2022-11-18 01:48:57,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:57,774 INFO:     Epoch: 4
2022-11-18 01:48:58,557 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8078632144765421, 'Total loss': 0.8078632144765421} | train loss {'Reaction outcome loss': 0.8349001102360637, 'Total loss': 0.8349001102360637}
2022-11-18 01:48:58,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:58,557 INFO:     Epoch: 5
2022-11-18 01:48:59,369 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8183751810680736, 'Total loss': 0.8183751810680736} | train loss {'Reaction outcome loss': 0.8369359450060346, 'Total loss': 0.8369359450060346}
2022-11-18 01:48:59,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:48:59,370 INFO:     Epoch: 6
2022-11-18 01:49:00,189 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.803796764801849, 'Total loss': 0.803796764801849} | train loss {'Reaction outcome loss': 0.8376558757262674, 'Total loss': 0.8376558757262674}
2022-11-18 01:49:00,189 INFO:     Found new best model at epoch 6
2022-11-18 01:49:00,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:00,190 INFO:     Epoch: 7
2022-11-18 01:49:01,006 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8137640953063965, 'Total loss': 0.8137640953063965} | train loss {'Reaction outcome loss': 0.8256454807121744, 'Total loss': 0.8256454807121744}
2022-11-18 01:49:01,006 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:01,006 INFO:     Epoch: 8
2022-11-18 01:49:01,806 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.807788876647299, 'Total loss': 0.807788876647299} | train loss {'Reaction outcome loss': 0.8292676882463911, 'Total loss': 0.8292676882463911}
2022-11-18 01:49:01,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:01,806 INFO:     Epoch: 9
2022-11-18 01:49:02,620 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.794496745548465, 'Total loss': 0.794496745548465} | train loss {'Reaction outcome loss': 0.8347251528670431, 'Total loss': 0.8347251528670431}
2022-11-18 01:49:02,620 INFO:     Found new best model at epoch 9
2022-11-18 01:49:02,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:02,621 INFO:     Epoch: 10
2022-11-18 01:49:03,438 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7956227172504772, 'Total loss': 0.7956227172504772} | train loss {'Reaction outcome loss': 0.8294961950798266, 'Total loss': 0.8294961950798266}
2022-11-18 01:49:03,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:03,438 INFO:     Epoch: 11
2022-11-18 01:49:04,235 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8282265961170197, 'Total loss': 0.8282265961170197} | train loss {'Reaction outcome loss': 0.8324403993272589, 'Total loss': 0.8324403993272589}
2022-11-18 01:49:04,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:04,236 INFO:     Epoch: 12
2022-11-18 01:49:05,028 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8144291503862902, 'Total loss': 0.8144291503862902} | train loss {'Reaction outcome loss': 0.836060819717554, 'Total loss': 0.836060819717554}
2022-11-18 01:49:05,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:05,028 INFO:     Epoch: 13
2022-11-18 01:49:05,868 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7845253449949351, 'Total loss': 0.7845253449949351} | train loss {'Reaction outcome loss': 0.8270499923451227, 'Total loss': 0.8270499923451227}
2022-11-18 01:49:05,868 INFO:     Found new best model at epoch 13
2022-11-18 01:49:05,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:05,869 INFO:     Epoch: 14
2022-11-18 01:49:06,677 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8000346435741945, 'Total loss': 0.8000346435741945} | train loss {'Reaction outcome loss': 0.823257968312333, 'Total loss': 0.823257968312333}
2022-11-18 01:49:06,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:06,677 INFO:     Epoch: 15
2022-11-18 01:49:07,457 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8015720674937422, 'Total loss': 0.8015720674937422} | train loss {'Reaction outcome loss': 0.828401915940196, 'Total loss': 0.828401915940196}
2022-11-18 01:49:07,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:07,457 INFO:     Epoch: 16
2022-11-18 01:49:08,263 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.809313525530425, 'Total loss': 0.809313525530425} | train loss {'Reaction outcome loss': 0.8284636306376593, 'Total loss': 0.8284636306376593}
2022-11-18 01:49:08,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:08,264 INFO:     Epoch: 17
2022-11-18 01:49:09,034 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8115824129093777, 'Total loss': 0.8115824129093777} | train loss {'Reaction outcome loss': 0.8185451390214173, 'Total loss': 0.8185451390214173}
2022-11-18 01:49:09,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:09,034 INFO:     Epoch: 18
2022-11-18 01:49:09,880 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8105949908494949, 'Total loss': 0.8105949908494949} | train loss {'Reaction outcome loss': 0.819288569302694, 'Total loss': 0.819288569302694}
2022-11-18 01:49:09,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:09,880 INFO:     Epoch: 19
2022-11-18 01:49:10,709 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7993723072788932, 'Total loss': 0.7993723072788932} | train loss {'Reaction outcome loss': 0.8251431777258875, 'Total loss': 0.8251431777258875}
2022-11-18 01:49:10,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:10,709 INFO:     Epoch: 20
2022-11-18 01:49:11,474 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8047765046358109, 'Total loss': 0.8047765046358109} | train loss {'Reaction outcome loss': 0.8214919028977151, 'Total loss': 0.8214919028977151}
2022-11-18 01:49:11,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:11,475 INFO:     Epoch: 21
2022-11-18 01:49:12,269 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.797472623938864, 'Total loss': 0.797472623938864} | train loss {'Reaction outcome loss': 0.8312940059403177, 'Total loss': 0.8312940059403177}
2022-11-18 01:49:12,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:12,269 INFO:     Epoch: 22
2022-11-18 01:49:13,128 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8320438116788864, 'Total loss': 0.8320438116788864} | train loss {'Reaction outcome loss': 0.8334579951608712, 'Total loss': 0.8334579951608712}
2022-11-18 01:49:13,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:13,128 INFO:     Epoch: 23
2022-11-18 01:49:13,950 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8007301647554744, 'Total loss': 0.8007301647554744} | train loss {'Reaction outcome loss': 0.8402874971690931, 'Total loss': 0.8402874971690931}
2022-11-18 01:49:13,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:13,950 INFO:     Epoch: 24
2022-11-18 01:49:14,771 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7890307808464224, 'Total loss': 0.7890307808464224} | train loss {'Reaction outcome loss': 0.8267764925715412, 'Total loss': 0.8267764925715412}
2022-11-18 01:49:14,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:14,771 INFO:     Epoch: 25
2022-11-18 01:49:15,598 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.795110437003049, 'Total loss': 0.795110437003049} | train loss {'Reaction outcome loss': 0.8259268804841678, 'Total loss': 0.8259268804841678}
2022-11-18 01:49:15,598 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:15,599 INFO:     Epoch: 26
2022-11-18 01:49:16,402 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8060157637704503, 'Total loss': 0.8060157637704503} | train loss {'Reaction outcome loss': 0.8190448295611602, 'Total loss': 0.8190448295611602}
2022-11-18 01:49:16,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:16,404 INFO:     Epoch: 27
2022-11-18 01:49:17,209 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8280978392470967, 'Total loss': 0.8280978392470967} | train loss {'Reaction outcome loss': 0.8219566813364685, 'Total loss': 0.8219566813364685}
2022-11-18 01:49:17,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:17,209 INFO:     Epoch: 28
2022-11-18 01:49:18,013 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7936159263957631, 'Total loss': 0.7936159263957631} | train loss {'Reaction outcome loss': 0.8287244652688261, 'Total loss': 0.8287244652688261}
2022-11-18 01:49:18,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:18,014 INFO:     Epoch: 29
2022-11-18 01:49:18,807 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.811395145275376, 'Total loss': 0.811395145275376} | train loss {'Reaction outcome loss': 0.8295911225954048, 'Total loss': 0.8295911225954048}
2022-11-18 01:49:18,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:18,807 INFO:     Epoch: 30
2022-11-18 01:49:19,620 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8061652569608255, 'Total loss': 0.8061652569608255} | train loss {'Reaction outcome loss': 0.8206131201584329, 'Total loss': 0.8206131201584329}
2022-11-18 01:49:19,620 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:19,620 INFO:     Epoch: 31
2022-11-18 01:49:20,441 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8164890672672879, 'Total loss': 0.8164890672672879} | train loss {'Reaction outcome loss': 0.8255021077418617, 'Total loss': 0.8255021077418617}
2022-11-18 01:49:20,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:20,442 INFO:     Epoch: 32
2022-11-18 01:49:21,275 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8369770260019735, 'Total loss': 0.8369770260019735} | train loss {'Reaction outcome loss': 0.8220570507319832, 'Total loss': 0.8220570507319832}
2022-11-18 01:49:21,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:21,275 INFO:     Epoch: 33
2022-11-18 01:49:22,093 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.805199877104976, 'Total loss': 0.805199877104976} | train loss {'Reaction outcome loss': 0.8216195205445231, 'Total loss': 0.8216195205445231}
2022-11-18 01:49:22,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:22,093 INFO:     Epoch: 34
2022-11-18 01:49:22,923 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8043028448115696, 'Total loss': 0.8043028448115696} | train loss {'Reaction outcome loss': 0.8124755200767807, 'Total loss': 0.8124755200767807}
2022-11-18 01:49:22,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:22,924 INFO:     Epoch: 35
2022-11-18 01:49:23,768 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.82033467089588, 'Total loss': 0.82033467089588} | train loss {'Reaction outcome loss': 0.8155505947301142, 'Total loss': 0.8155505947301142}
2022-11-18 01:49:23,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:23,769 INFO:     Epoch: 36
2022-11-18 01:49:24,557 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8177012672478502, 'Total loss': 0.8177012672478502} | train loss {'Reaction outcome loss': 0.8302218281788382, 'Total loss': 0.8302218281788382}
2022-11-18 01:49:24,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:24,557 INFO:     Epoch: 37
2022-11-18 01:49:25,415 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8090718632394617, 'Total loss': 0.8090718632394617} | train loss {'Reaction outcome loss': 0.8195913921181972, 'Total loss': 0.8195913921181972}
2022-11-18 01:49:25,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:25,416 INFO:     Epoch: 38
2022-11-18 01:49:26,228 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8159204206683419, 'Total loss': 0.8159204206683419} | train loss {'Reaction outcome loss': 0.8178077868604468, 'Total loss': 0.8178077868604468}
2022-11-18 01:49:26,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:26,228 INFO:     Epoch: 39
2022-11-18 01:49:27,020 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7929136427966031, 'Total loss': 0.7929136427966031} | train loss {'Reaction outcome loss': 0.8305882681236576, 'Total loss': 0.8305882681236576}
2022-11-18 01:49:27,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:27,020 INFO:     Epoch: 40
2022-11-18 01:49:27,820 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7933714396574281, 'Total loss': 0.7933714396574281} | train loss {'Reaction outcome loss': 0.8196334697698292, 'Total loss': 0.8196334697698292}
2022-11-18 01:49:27,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:27,821 INFO:     Epoch: 41
2022-11-18 01:49:28,639 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7939862507310781, 'Total loss': 0.7939862507310781} | train loss {'Reaction outcome loss': 0.8278210779674623, 'Total loss': 0.8278210779674623}
2022-11-18 01:49:28,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:28,640 INFO:     Epoch: 42
2022-11-18 01:49:29,488 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7946435233408754, 'Total loss': 0.7946435233408754} | train loss {'Reaction outcome loss': 0.8201736298800721, 'Total loss': 0.8201736298800721}
2022-11-18 01:49:29,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:29,488 INFO:     Epoch: 43
2022-11-18 01:49:30,291 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8141523619944399, 'Total loss': 0.8141523619944399} | train loss {'Reaction outcome loss': 0.8150872411998177, 'Total loss': 0.8150872411998177}
2022-11-18 01:49:30,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:30,291 INFO:     Epoch: 44
2022-11-18 01:49:31,130 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7910248217257586, 'Total loss': 0.7910248217257586} | train loss {'Reaction outcome loss': 0.8209506625588606, 'Total loss': 0.8209506625588606}
2022-11-18 01:49:31,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:31,131 INFO:     Epoch: 45
2022-11-18 01:49:31,968 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7967666008255698, 'Total loss': 0.7967666008255698} | train loss {'Reaction outcome loss': 0.8208237126288627, 'Total loss': 0.8208237126288627}
2022-11-18 01:49:31,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:31,968 INFO:     Epoch: 46
2022-11-18 01:49:32,805 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7895499163053252, 'Total loss': 0.7895499163053252} | train loss {'Reaction outcome loss': 0.8140937548417312, 'Total loss': 0.8140937548417312}
2022-11-18 01:49:32,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:32,805 INFO:     Epoch: 47
2022-11-18 01:49:33,610 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7900433425198902, 'Total loss': 0.7900433425198902} | train loss {'Reaction outcome loss': 0.8141487495076318, 'Total loss': 0.8141487495076318}
2022-11-18 01:49:33,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:33,610 INFO:     Epoch: 48
2022-11-18 01:49:34,424 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8165678612210534, 'Total loss': 0.8165678612210534} | train loss {'Reaction outcome loss': 0.8144063757136766, 'Total loss': 0.8144063757136766}
2022-11-18 01:49:34,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:34,425 INFO:     Epoch: 49
2022-11-18 01:49:35,252 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7930216938257217, 'Total loss': 0.7930216938257217} | train loss {'Reaction outcome loss': 0.8157580766510143, 'Total loss': 0.8157580766510143}
2022-11-18 01:49:35,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:35,253 INFO:     Epoch: 50
2022-11-18 01:49:36,070 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7974651530385017, 'Total loss': 0.7974651530385017} | train loss {'Reaction outcome loss': 0.8158408279119715, 'Total loss': 0.8158408279119715}
2022-11-18 01:49:36,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:36,071 INFO:     Epoch: 51
2022-11-18 01:49:36,905 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8377191979776729, 'Total loss': 0.8377191979776729} | train loss {'Reaction outcome loss': 0.8196973437481081, 'Total loss': 0.8196973437481081}
2022-11-18 01:49:36,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:36,905 INFO:     Epoch: 52
2022-11-18 01:49:37,708 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.803293065591292, 'Total loss': 0.803293065591292} | train loss {'Reaction outcome loss': 0.8155676454064335, 'Total loss': 0.8155676454064335}
2022-11-18 01:49:37,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:37,708 INFO:     Epoch: 53
2022-11-18 01:49:38,504 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8069575537334789, 'Total loss': 0.8069575537334789} | train loss {'Reaction outcome loss': 0.8161756838502189, 'Total loss': 0.8161756838502189}
2022-11-18 01:49:38,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:38,505 INFO:     Epoch: 54
2022-11-18 01:49:39,290 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.797538934783502, 'Total loss': 0.797538934783502} | train loss {'Reaction outcome loss': 0.8231456966293969, 'Total loss': 0.8231456966293969}
2022-11-18 01:49:39,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:39,290 INFO:     Epoch: 55
2022-11-18 01:49:40,058 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7776282890276476, 'Total loss': 0.7776282890276476} | train loss {'Reaction outcome loss': 0.8131568452064325, 'Total loss': 0.8131568452064325}
2022-11-18 01:49:40,058 INFO:     Found new best model at epoch 55
2022-11-18 01:49:40,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:40,059 INFO:     Epoch: 56
2022-11-18 01:49:40,847 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7910149246454239, 'Total loss': 0.7910149246454239} | train loss {'Reaction outcome loss': 0.8136570057134155, 'Total loss': 0.8136570057134155}
2022-11-18 01:49:40,848 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:40,848 INFO:     Epoch: 57
2022-11-18 01:49:41,625 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7751339633356441, 'Total loss': 0.7751339633356441} | train loss {'Reaction outcome loss': 0.8130073213142904, 'Total loss': 0.8130073213142904}
2022-11-18 01:49:41,625 INFO:     Found new best model at epoch 57
2022-11-18 01:49:41,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:41,626 INFO:     Epoch: 58
2022-11-18 01:49:42,382 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7745547314936464, 'Total loss': 0.7745547314936464} | train loss {'Reaction outcome loss': 0.8175857916534671, 'Total loss': 0.8175857916534671}
2022-11-18 01:49:42,382 INFO:     Found new best model at epoch 58
2022-11-18 01:49:42,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:42,383 INFO:     Epoch: 59
2022-11-18 01:49:43,204 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7804445793682878, 'Total loss': 0.7804445793682878} | train loss {'Reaction outcome loss': 0.8182213597210796, 'Total loss': 0.8182213597210796}
2022-11-18 01:49:43,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:43,204 INFO:     Epoch: 60
2022-11-18 01:49:43,991 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7853057160973549, 'Total loss': 0.7853057160973549} | train loss {'Reaction outcome loss': 0.8273356239564023, 'Total loss': 0.8273356239564023}
2022-11-18 01:49:43,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:43,992 INFO:     Epoch: 61
2022-11-18 01:49:44,781 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7886128913272511, 'Total loss': 0.7886128913272511} | train loss {'Reaction outcome loss': 0.8177073900455888, 'Total loss': 0.8177073900455888}
2022-11-18 01:49:44,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:44,782 INFO:     Epoch: 62
2022-11-18 01:49:45,555 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7840742793950167, 'Total loss': 0.7840742793950167} | train loss {'Reaction outcome loss': 0.8092435673180862, 'Total loss': 0.8092435673180862}
2022-11-18 01:49:45,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:45,556 INFO:     Epoch: 63
2022-11-18 01:49:46,341 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7894077510996298, 'Total loss': 0.7894077510996298} | train loss {'Reaction outcome loss': 0.8163649303469098, 'Total loss': 0.8163649303469098}
2022-11-18 01:49:46,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:46,342 INFO:     Epoch: 64
2022-11-18 01:49:47,130 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8090434738180854, 'Total loss': 0.8090434738180854} | train loss {'Reaction outcome loss': 0.8216419028125794, 'Total loss': 0.8216419028125794}
2022-11-18 01:49:47,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:47,131 INFO:     Epoch: 65
2022-11-18 01:49:47,904 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8033014732328329, 'Total loss': 0.8033014732328329} | train loss {'Reaction outcome loss': 0.8186213240208413, 'Total loss': 0.8186213240208413}
2022-11-18 01:49:47,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:47,905 INFO:     Epoch: 66
2022-11-18 01:49:48,708 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7897327847101472, 'Total loss': 0.7897327847101472} | train loss {'Reaction outcome loss': 0.8239370859586276, 'Total loss': 0.8239370859586276}
2022-11-18 01:49:48,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:48,708 INFO:     Epoch: 67
2022-11-18 01:49:49,486 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8055320625955408, 'Total loss': 0.8055320625955408} | train loss {'Reaction outcome loss': 0.8112924990700445, 'Total loss': 0.8112924990700445}
2022-11-18 01:49:49,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:49,486 INFO:     Epoch: 68
2022-11-18 01:49:50,253 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.797045387327671, 'Total loss': 0.797045387327671} | train loss {'Reaction outcome loss': 0.8174999270904885, 'Total loss': 0.8174999270904885}
2022-11-18 01:49:50,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:50,253 INFO:     Epoch: 69
2022-11-18 01:49:51,025 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7841568687422709, 'Total loss': 0.7841568687422709} | train loss {'Reaction outcome loss': 0.8143251418826069, 'Total loss': 0.8143251418826069}
2022-11-18 01:49:51,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:51,025 INFO:     Epoch: 70
2022-11-18 01:49:51,821 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7869074602018703, 'Total loss': 0.7869074602018703} | train loss {'Reaction outcome loss': 0.8206203507508344, 'Total loss': 0.8206203507508344}
2022-11-18 01:49:51,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:51,821 INFO:     Epoch: 71
2022-11-18 01:49:52,579 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.810066584836353, 'Total loss': 0.810066584836353} | train loss {'Reaction outcome loss': 0.8087062409170244, 'Total loss': 0.8087062409170244}
2022-11-18 01:49:52,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:52,579 INFO:     Epoch: 72
2022-11-18 01:49:53,386 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.793100239878351, 'Total loss': 0.793100239878351} | train loss {'Reaction outcome loss': 0.8251598700579361, 'Total loss': 0.8251598700579361}
2022-11-18 01:49:53,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:53,387 INFO:     Epoch: 73
2022-11-18 01:49:54,192 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7797855910929766, 'Total loss': 0.7797855910929766} | train loss {'Reaction outcome loss': 0.8226559806147568, 'Total loss': 0.8226559806147568}
2022-11-18 01:49:54,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:54,192 INFO:     Epoch: 74
2022-11-18 01:49:54,987 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7997755835002119, 'Total loss': 0.7997755835002119} | train loss {'Reaction outcome loss': 0.8142338424076435, 'Total loss': 0.8142338424076435}
2022-11-18 01:49:54,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:54,987 INFO:     Epoch: 75
2022-11-18 01:49:55,783 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7819189029661092, 'Total loss': 0.7819189029661092} | train loss {'Reaction outcome loss': 0.8199135714214341, 'Total loss': 0.8199135714214341}
2022-11-18 01:49:55,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:55,783 INFO:     Epoch: 76
2022-11-18 01:49:56,544 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.791559830985286, 'Total loss': 0.791559830985286} | train loss {'Reaction outcome loss': 0.8141357839590142, 'Total loss': 0.8141357839590142}
2022-11-18 01:49:56,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:56,545 INFO:     Epoch: 77
2022-11-18 01:49:57,357 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7848291769623756, 'Total loss': 0.7848291769623756} | train loss {'Reaction outcome loss': 0.8191737413768344, 'Total loss': 0.8191737413768344}
2022-11-18 01:49:57,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:57,357 INFO:     Epoch: 78
2022-11-18 01:49:58,145 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7882679057392207, 'Total loss': 0.7882679057392207} | train loss {'Reaction outcome loss': 0.8180428778353007, 'Total loss': 0.8180428778353007}
2022-11-18 01:49:58,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:58,145 INFO:     Epoch: 79
2022-11-18 01:49:58,923 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7880333709445867, 'Total loss': 0.7880333709445867} | train loss {'Reaction outcome loss': 0.8220534419965165, 'Total loss': 0.8220534419965165}
2022-11-18 01:49:58,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:58,923 INFO:     Epoch: 80
2022-11-18 01:49:59,700 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7793773426250978, 'Total loss': 0.7793773426250978} | train loss {'Reaction outcome loss': 0.818178185929171, 'Total loss': 0.818178185929171}
2022-11-18 01:49:59,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:49:59,701 INFO:     Epoch: 81
2022-11-18 01:50:00,498 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7850846221501177, 'Total loss': 0.7850846221501177} | train loss {'Reaction outcome loss': 0.8160677622204368, 'Total loss': 0.8160677622204368}
2022-11-18 01:50:00,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:00,499 INFO:     Epoch: 82
2022-11-18 01:50:01,300 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7779297422279011, 'Total loss': 0.7779297422279011} | train loss {'Reaction outcome loss': 0.8188882421264764, 'Total loss': 0.8188882421264764}
2022-11-18 01:50:01,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:01,300 INFO:     Epoch: 83
2022-11-18 01:50:02,074 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7958722493865273, 'Total loss': 0.7958722493865273} | train loss {'Reaction outcome loss': 0.8159685880549041, 'Total loss': 0.8159685880549041}
2022-11-18 01:50:02,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:02,074 INFO:     Epoch: 84
2022-11-18 01:50:02,849 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8011090430346403, 'Total loss': 0.8011090430346403} | train loss {'Reaction outcome loss': 0.816967995543229, 'Total loss': 0.816967995543229}
2022-11-18 01:50:02,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:02,849 INFO:     Epoch: 85
2022-11-18 01:50:03,624 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7992670712145892, 'Total loss': 0.7992670712145892} | train loss {'Reaction outcome loss': 0.8180093635552326, 'Total loss': 0.8180093635552326}
2022-11-18 01:50:03,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:03,625 INFO:     Epoch: 86
2022-11-18 01:50:04,396 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.797550886192105, 'Total loss': 0.797550886192105} | train loss {'Reaction outcome loss': 0.8112344365370902, 'Total loss': 0.8112344365370902}
2022-11-18 01:50:04,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:04,396 INFO:     Epoch: 87
2022-11-18 01:50:05,188 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8010145940563895, 'Total loss': 0.8010145940563895} | train loss {'Reaction outcome loss': 0.8135767833665315, 'Total loss': 0.8135767833665315}
2022-11-18 01:50:05,188 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:05,188 INFO:     Epoch: 88
2022-11-18 01:50:05,997 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7935670593922789, 'Total loss': 0.7935670593922789} | train loss {'Reaction outcome loss': 0.8132135576685431, 'Total loss': 0.8132135576685431}
2022-11-18 01:50:05,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:05,998 INFO:     Epoch: 89
2022-11-18 01:50:06,783 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8178450858051126, 'Total loss': 0.8178450858051126} | train loss {'Reaction outcome loss': 0.8260214117615812, 'Total loss': 0.8260214117615812}
2022-11-18 01:50:06,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:06,783 INFO:     Epoch: 90
2022-11-18 01:50:07,552 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8202189769257199, 'Total loss': 0.8202189769257199} | train loss {'Reaction outcome loss': 0.8148110987324464, 'Total loss': 0.8148110987324464}
2022-11-18 01:50:07,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:07,553 INFO:     Epoch: 91
2022-11-18 01:50:08,352 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7839118733324788, 'Total loss': 0.7839118733324788} | train loss {'Reaction outcome loss': 0.8181899156165027, 'Total loss': 0.8181899156165027}
2022-11-18 01:50:08,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:08,352 INFO:     Epoch: 92
2022-11-18 01:50:09,152 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7984395826404745, 'Total loss': 0.7984395826404745} | train loss {'Reaction outcome loss': 0.8104768379738456, 'Total loss': 0.8104768379738456}
2022-11-18 01:50:09,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:09,152 INFO:     Epoch: 93
2022-11-18 01:50:09,951 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7834424180063334, 'Total loss': 0.7834424180063334} | train loss {'Reaction outcome loss': 0.8172213513600198, 'Total loss': 0.8172213513600198}
2022-11-18 01:50:09,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:09,951 INFO:     Epoch: 94
2022-11-18 01:50:10,719 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.810255884446881, 'Total loss': 0.810255884446881} | train loss {'Reaction outcome loss': 0.8122099640398373, 'Total loss': 0.8122099640398373}
2022-11-18 01:50:10,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:10,719 INFO:     Epoch: 95
2022-11-18 01:50:11,488 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7827668704769828, 'Total loss': 0.7827668704769828} | train loss {'Reaction outcome loss': 0.8146254137641022, 'Total loss': 0.8146254137641022}
2022-11-18 01:50:11,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:11,488 INFO:     Epoch: 96
2022-11-18 01:50:12,291 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8034323182972994, 'Total loss': 0.8034323182972994} | train loss {'Reaction outcome loss': 0.8282863007865937, 'Total loss': 0.8282863007865937}
2022-11-18 01:50:12,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:12,292 INFO:     Epoch: 97
2022-11-18 01:50:13,073 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7936211607672952, 'Total loss': 0.7936211607672952} | train loss {'Reaction outcome loss': 0.8156164870088399, 'Total loss': 0.8156164870088399}
2022-11-18 01:50:13,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:13,073 INFO:     Epoch: 98
2022-11-18 01:50:13,858 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8026389967311512, 'Total loss': 0.8026389967311512} | train loss {'Reaction outcome loss': 0.8175370047690897, 'Total loss': 0.8175370047690897}
2022-11-18 01:50:13,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:13,858 INFO:     Epoch: 99
2022-11-18 01:50:14,700 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7901024662635543, 'Total loss': 0.7901024662635543} | train loss {'Reaction outcome loss': 0.8124816589027282, 'Total loss': 0.8124816589027282}
2022-11-18 01:50:14,700 INFO:     Best model found after epoch 59 of 100.
2022-11-18 01:50:14,700 INFO:   Done with stage: TRAINING
2022-11-18 01:50:14,700 INFO:   Starting stage: EVALUATION
2022-11-18 01:50:14,826 INFO:   Done with stage: EVALUATION
2022-11-18 01:50:14,826 INFO:   Leaving out SEQ value Fold_2
2022-11-18 01:50:14,839 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-18 01:50:14,839 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:50:15,501 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:50:15,502 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:50:15,571 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:50:15,571 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:50:15,571 INFO:     No hyperparam tuning for this model
2022-11-18 01:50:15,571 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:50:15,571 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:50:15,572 INFO:     None feature selector for col prot
2022-11-18 01:50:15,572 INFO:     None feature selector for col prot
2022-11-18 01:50:15,572 INFO:     None feature selector for col prot
2022-11-18 01:50:15,573 INFO:     None feature selector for col chem
2022-11-18 01:50:15,573 INFO:     None feature selector for col chem
2022-11-18 01:50:15,573 INFO:     None feature selector for col chem
2022-11-18 01:50:15,573 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:50:15,573 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:50:15,575 INFO:     Number of params in model 168571
2022-11-18 01:50:15,578 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:50:15,578 INFO:   Starting stage: TRAINING
2022-11-18 01:50:15,637 INFO:     Val loss before train {'Reaction outcome loss': 1.0517087287681048, 'Total loss': 1.0517087287681048}
2022-11-18 01:50:15,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:15,637 INFO:     Epoch: 0
2022-11-18 01:50:16,471 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8566110522248024, 'Total loss': 0.8566110522248024} | train loss {'Reaction outcome loss': 0.866249823667964, 'Total loss': 0.866249823667964}
2022-11-18 01:50:16,471 INFO:     Found new best model at epoch 0
2022-11-18 01:50:16,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:16,472 INFO:     Epoch: 1
2022-11-18 01:50:17,258 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8268113926399586, 'Total loss': 0.8268113926399586} | train loss {'Reaction outcome loss': 0.8362431102355973, 'Total loss': 0.8362431102355973}
2022-11-18 01:50:17,258 INFO:     Found new best model at epoch 1
2022-11-18 01:50:17,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:17,259 INFO:     Epoch: 2
2022-11-18 01:50:18,095 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.835669091274572, 'Total loss': 0.835669091274572} | train loss {'Reaction outcome loss': 0.8258961949680672, 'Total loss': 0.8258961949680672}
2022-11-18 01:50:18,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:18,097 INFO:     Epoch: 3
2022-11-18 01:50:18,905 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8584336721619894, 'Total loss': 0.8584336721619894} | train loss {'Reaction outcome loss': 0.8353903327809006, 'Total loss': 0.8353903327809006}
2022-11-18 01:50:18,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:18,906 INFO:     Epoch: 4
2022-11-18 01:50:19,753 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8601045858028323, 'Total loss': 0.8601045858028323} | train loss {'Reaction outcome loss': 0.8226127088314197, 'Total loss': 0.8226127088314197}
2022-11-18 01:50:19,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:19,754 INFO:     Epoch: 5
2022-11-18 01:50:20,579 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8968927555306013, 'Total loss': 0.8968927555306013} | train loss {'Reaction outcome loss': 0.8289276807278884, 'Total loss': 0.8289276807278884}
2022-11-18 01:50:20,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:20,579 INFO:     Epoch: 6
2022-11-18 01:50:21,382 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8326756475969802, 'Total loss': 0.8326756475969802} | train loss {'Reaction outcome loss': 0.8195202321302696, 'Total loss': 0.8195202321302696}
2022-11-18 01:50:21,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:21,382 INFO:     Epoch: 7
2022-11-18 01:50:22,192 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8164511357629022, 'Total loss': 0.8164511357629022} | train loss {'Reaction outcome loss': 0.823011331382345, 'Total loss': 0.823011331382345}
2022-11-18 01:50:22,192 INFO:     Found new best model at epoch 7
2022-11-18 01:50:22,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:22,193 INFO:     Epoch: 8
2022-11-18 01:50:23,009 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8242526012797688, 'Total loss': 0.8242526012797688} | train loss {'Reaction outcome loss': 0.819361673515351, 'Total loss': 0.819361673515351}
2022-11-18 01:50:23,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:23,009 INFO:     Epoch: 9
2022-11-18 01:50:23,845 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.823104877804601, 'Total loss': 0.823104877804601} | train loss {'Reaction outcome loss': 0.8167563382475103, 'Total loss': 0.8167563382475103}
2022-11-18 01:50:23,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:23,845 INFO:     Epoch: 10
2022-11-18 01:50:24,653 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.841667712427849, 'Total loss': 0.841667712427849} | train loss {'Reaction outcome loss': 0.8121414428851643, 'Total loss': 0.8121414428851643}
2022-11-18 01:50:24,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:24,654 INFO:     Epoch: 11
2022-11-18 01:50:25,485 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.83270263671875, 'Total loss': 0.83270263671875} | train loss {'Reaction outcome loss': 0.8171398861974967, 'Total loss': 0.8171398861974967}
2022-11-18 01:50:25,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:25,485 INFO:     Epoch: 12
2022-11-18 01:50:26,295 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8326322353163431, 'Total loss': 0.8326322353163431} | train loss {'Reaction outcome loss': 0.8109180240846071, 'Total loss': 0.8109180240846071}
2022-11-18 01:50:26,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:26,295 INFO:     Epoch: 13
2022-11-18 01:50:27,107 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.826784155396528, 'Total loss': 0.826784155396528} | train loss {'Reaction outcome loss': 0.8116413798244273, 'Total loss': 0.8116413798244273}
2022-11-18 01:50:27,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:27,108 INFO:     Epoch: 14
2022-11-18 01:50:27,920 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8290437203507091, 'Total loss': 0.8290437203507091} | train loss {'Reaction outcome loss': 0.8102941497183237, 'Total loss': 0.8102941497183237}
2022-11-18 01:50:27,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:27,920 INFO:     Epoch: 15
2022-11-18 01:50:28,709 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8289716825928799, 'Total loss': 0.8289716825928799} | train loss {'Reaction outcome loss': 0.8081508026015564, 'Total loss': 0.8081508026015564}
2022-11-18 01:50:28,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:28,709 INFO:     Epoch: 16
2022-11-18 01:50:29,483 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8446657089299934, 'Total loss': 0.8446657089299934} | train loss {'Reaction outcome loss': 0.8105529418489972, 'Total loss': 0.8105529418489972}
2022-11-18 01:50:29,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:29,484 INFO:     Epoch: 17
2022-11-18 01:50:30,326 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8148494238077209, 'Total loss': 0.8148494238077209} | train loss {'Reaction outcome loss': 0.8082747008712565, 'Total loss': 0.8082747008712565}
2022-11-18 01:50:30,326 INFO:     Found new best model at epoch 17
2022-11-18 01:50:30,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:30,327 INFO:     Epoch: 18
2022-11-18 01:50:31,136 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8191202906675117, 'Total loss': 0.8191202906675117} | train loss {'Reaction outcome loss': 0.8101251965663472, 'Total loss': 0.8101251965663472}
2022-11-18 01:50:31,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:31,136 INFO:     Epoch: 19
2022-11-18 01:50:31,919 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8378762533498365, 'Total loss': 0.8378762533498365} | train loss {'Reaction outcome loss': 0.8079759799798981, 'Total loss': 0.8079759799798981}
2022-11-18 01:50:31,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:31,919 INFO:     Epoch: 20
2022-11-18 01:50:32,717 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8391132770582687, 'Total loss': 0.8391132770582687} | train loss {'Reaction outcome loss': 0.806949833377463, 'Total loss': 0.806949833377463}
2022-11-18 01:50:32,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:32,717 INFO:     Epoch: 21
2022-11-18 01:50:33,543 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8270441564016564, 'Total loss': 0.8270441564016564} | train loss {'Reaction outcome loss': 0.8069597071067232, 'Total loss': 0.8069597071067232}
2022-11-18 01:50:33,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:33,543 INFO:     Epoch: 22
2022-11-18 01:50:34,378 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8477877253709838, 'Total loss': 0.8477877253709838} | train loss {'Reaction outcome loss': 0.8070121618812202, 'Total loss': 0.8070121618812202}
2022-11-18 01:50:34,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:34,378 INFO:     Epoch: 23
2022-11-18 01:50:35,209 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8255652591239574, 'Total loss': 0.8255652591239574} | train loss {'Reaction outcome loss': 0.8067962684836544, 'Total loss': 0.8067962684836544}
2022-11-18 01:50:35,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:35,210 INFO:     Epoch: 24
2022-11-18 01:50:35,996 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8083266144575074, 'Total loss': 0.8083266144575074} | train loss {'Reaction outcome loss': 0.8025569346595983, 'Total loss': 0.8025569346595983}
2022-11-18 01:50:35,996 INFO:     Found new best model at epoch 24
2022-11-18 01:50:35,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:35,997 INFO:     Epoch: 25
2022-11-18 01:50:36,799 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8263685225054275, 'Total loss': 0.8263685225054275} | train loss {'Reaction outcome loss': 0.8057756729301859, 'Total loss': 0.8057756729301859}
2022-11-18 01:50:36,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:36,800 INFO:     Epoch: 26
2022-11-18 01:50:37,593 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8312416256860246, 'Total loss': 0.8312416256860246} | train loss {'Reaction outcome loss': 0.802699559047574, 'Total loss': 0.802699559047574}
2022-11-18 01:50:37,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:37,593 INFO:     Epoch: 27
2022-11-18 01:50:38,372 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8316571393678355, 'Total loss': 0.8316571393678355} | train loss {'Reaction outcome loss': 0.8051319350717497, 'Total loss': 0.8051319350717497}
2022-11-18 01:50:38,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:38,373 INFO:     Epoch: 28
2022-11-18 01:50:39,191 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8299457597178083, 'Total loss': 0.8299457597178083} | train loss {'Reaction outcome loss': 0.8065603219094823, 'Total loss': 0.8065603219094823}
2022-11-18 01:50:39,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:39,191 INFO:     Epoch: 29
2022-11-18 01:50:39,971 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8275501734988634, 'Total loss': 0.8275501734988634} | train loss {'Reaction outcome loss': 0.802839246929669, 'Total loss': 0.802839246929669}
2022-11-18 01:50:39,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:39,972 INFO:     Epoch: 30
2022-11-18 01:50:40,750 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8204469223355138, 'Total loss': 0.8204469223355138} | train loss {'Reaction outcome loss': 0.8062376245612004, 'Total loss': 0.8062376245612004}
2022-11-18 01:50:40,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:40,751 INFO:     Epoch: 31
2022-11-18 01:50:41,578 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8158273683037869, 'Total loss': 0.8158273683037869} | train loss {'Reaction outcome loss': 0.8084756793057333, 'Total loss': 0.8084756793057333}
2022-11-18 01:50:41,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:41,579 INFO:     Epoch: 32
2022-11-18 01:50:42,371 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8161812362282775, 'Total loss': 0.8161812362282775} | train loss {'Reaction outcome loss': 0.804002084937252, 'Total loss': 0.804002084937252}
2022-11-18 01:50:42,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:42,372 INFO:     Epoch: 33
2022-11-18 01:50:43,172 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8223648168319879, 'Total loss': 0.8223648168319879} | train loss {'Reaction outcome loss': 0.8052597746985858, 'Total loss': 0.8052597746985858}
2022-11-18 01:50:43,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:43,172 INFO:     Epoch: 34
2022-11-18 01:50:44,004 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8148369151492452, 'Total loss': 0.8148369151492452} | train loss {'Reaction outcome loss': 0.8073804238047756, 'Total loss': 0.8073804238047756}
2022-11-18 01:50:44,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:44,004 INFO:     Epoch: 35
2022-11-18 01:50:44,781 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8145007802996524, 'Total loss': 0.8145007802996524} | train loss {'Reaction outcome loss': 0.8041232194079727, 'Total loss': 0.8041232194079727}
2022-11-18 01:50:44,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:44,782 INFO:     Epoch: 36
2022-11-18 01:50:45,560 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8185475177543108, 'Total loss': 0.8185475177543108} | train loss {'Reaction outcome loss': 0.8029036559775228, 'Total loss': 0.8029036559775228}
2022-11-18 01:50:45,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:45,560 INFO:     Epoch: 37
2022-11-18 01:50:46,365 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8229030141996783, 'Total loss': 0.8229030141996783} | train loss {'Reaction outcome loss': 0.8057805969089759, 'Total loss': 0.8057805969089759}
2022-11-18 01:50:46,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:46,366 INFO:     Epoch: 38
2022-11-18 01:50:47,162 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8250524595726368, 'Total loss': 0.8250524595726368} | train loss {'Reaction outcome loss': 0.8056804090738297, 'Total loss': 0.8056804090738297}
2022-11-18 01:50:47,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:47,162 INFO:     Epoch: 39
2022-11-18 01:50:47,984 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8213627518609513, 'Total loss': 0.8213627518609513} | train loss {'Reaction outcome loss': 0.8033303496290426, 'Total loss': 0.8033303496290426}
2022-11-18 01:50:47,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:47,985 INFO:     Epoch: 40
2022-11-18 01:50:48,768 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8409230369468068, 'Total loss': 0.8409230369468068} | train loss {'Reaction outcome loss': 0.8027995970161235, 'Total loss': 0.8027995970161235}
2022-11-18 01:50:48,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:48,769 INFO:     Epoch: 41
2022-11-18 01:50:49,565 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8442825439364411, 'Total loss': 0.8442825439364411} | train loss {'Reaction outcome loss': 0.8032571366820179, 'Total loss': 0.8032571366820179}
2022-11-18 01:50:49,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:49,565 INFO:     Epoch: 42
2022-11-18 01:50:50,327 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8139797407527303, 'Total loss': 0.8139797407527303} | train loss {'Reaction outcome loss': 0.8003756165748737, 'Total loss': 0.8003756165748737}
2022-11-18 01:50:50,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:50,327 INFO:     Epoch: 43
2022-11-18 01:50:51,190 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8327727220779242, 'Total loss': 0.8327727220779242} | train loss {'Reaction outcome loss': 0.8023703021348499, 'Total loss': 0.8023703021348499}
2022-11-18 01:50:51,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:51,190 INFO:     Epoch: 44
2022-11-18 01:50:51,961 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8175242598666701, 'Total loss': 0.8175242598666701} | train loss {'Reaction outcome loss': 0.8049534473751412, 'Total loss': 0.8049534473751412}
2022-11-18 01:50:51,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:51,962 INFO:     Epoch: 45
2022-11-18 01:50:52,768 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8195864211681277, 'Total loss': 0.8195864211681277} | train loss {'Reaction outcome loss': 0.8005545715816685, 'Total loss': 0.8005545715816685}
2022-11-18 01:50:52,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:52,769 INFO:     Epoch: 46
2022-11-18 01:50:53,546 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8164523666681245, 'Total loss': 0.8164523666681245} | train loss {'Reaction outcome loss': 0.800050423526373, 'Total loss': 0.800050423526373}
2022-11-18 01:50:53,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:53,546 INFO:     Epoch: 47
2022-11-18 01:50:54,369 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8160728715186896, 'Total loss': 0.8160728715186896} | train loss {'Reaction outcome loss': 0.8011406111668368, 'Total loss': 0.8011406111668368}
2022-11-18 01:50:54,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:54,370 INFO:     Epoch: 48
2022-11-18 01:50:55,144 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.822051677592965, 'Total loss': 0.822051677592965} | train loss {'Reaction outcome loss': 0.8008538880309121, 'Total loss': 0.8008538880309121}
2022-11-18 01:50:55,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:55,145 INFO:     Epoch: 49
2022-11-18 01:50:55,940 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.823486192281856, 'Total loss': 0.823486192281856} | train loss {'Reaction outcome loss': 0.800161704176762, 'Total loss': 0.800161704176762}
2022-11-18 01:50:55,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:55,941 INFO:     Epoch: 50
2022-11-18 01:50:56,719 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8285644213820613, 'Total loss': 0.8285644213820613} | train loss {'Reaction outcome loss': 0.7999021093376347, 'Total loss': 0.7999021093376347}
2022-11-18 01:50:56,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:56,719 INFO:     Epoch: 51
2022-11-18 01:50:57,535 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8078485741171726, 'Total loss': 0.8078485741171726} | train loss {'Reaction outcome loss': 0.8031781668790051, 'Total loss': 0.8031781668790051}
2022-11-18 01:50:57,536 INFO:     Found new best model at epoch 51
2022-11-18 01:50:57,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:57,536 INFO:     Epoch: 52
2022-11-18 01:50:58,312 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8148086819537851, 'Total loss': 0.8148086819537851} | train loss {'Reaction outcome loss': 0.7989034585532595, 'Total loss': 0.7989034585532595}
2022-11-18 01:50:58,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:58,312 INFO:     Epoch: 53
2022-11-18 01:50:59,079 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.813689107118651, 'Total loss': 0.813689107118651} | train loss {'Reaction outcome loss': 0.8028362977211593, 'Total loss': 0.8028362977211593}
2022-11-18 01:50:59,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:59,079 INFO:     Epoch: 54
2022-11-18 01:50:59,891 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8162113823169885, 'Total loss': 0.8162113823169885} | train loss {'Reaction outcome loss': 0.7998383664449707, 'Total loss': 0.7998383664449707}
2022-11-18 01:50:59,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:50:59,891 INFO:     Epoch: 55
2022-11-18 01:51:00,700 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8155513918677042, 'Total loss': 0.8155513918677042} | train loss {'Reaction outcome loss': 0.7965302659107036, 'Total loss': 0.7965302659107036}
2022-11-18 01:51:00,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:00,700 INFO:     Epoch: 56
2022-11-18 01:51:01,509 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8223196808681932, 'Total loss': 0.8223196808681932} | train loss {'Reaction outcome loss': 0.8041302354120817, 'Total loss': 0.8041302354120817}
2022-11-18 01:51:01,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:01,510 INFO:     Epoch: 57
2022-11-18 01:51:02,311 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8386410460915676, 'Total loss': 0.8386410460915676} | train loss {'Reaction outcome loss': 0.8052761091804895, 'Total loss': 0.8052761091804895}
2022-11-18 01:51:02,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:02,312 INFO:     Epoch: 58
2022-11-18 01:51:03,126 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8317869846210924, 'Total loss': 0.8317869846210924} | train loss {'Reaction outcome loss': 0.7989895181333433, 'Total loss': 0.7989895181333433}
2022-11-18 01:51:03,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:03,126 INFO:     Epoch: 59
2022-11-18 01:51:03,954 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8123104045557421, 'Total loss': 0.8123104045557421} | train loss {'Reaction outcome loss': 0.7987154623890509, 'Total loss': 0.7987154623890509}
2022-11-18 01:51:03,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:03,954 INFO:     Epoch: 60
2022-11-18 01:51:04,781 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8294852639353553, 'Total loss': 0.8294852639353553} | train loss {'Reaction outcome loss': 0.7977813372357947, 'Total loss': 0.7977813372357947}
2022-11-18 01:51:04,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:04,781 INFO:     Epoch: 61
2022-11-18 01:51:05,613 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8022766279619794, 'Total loss': 0.8022766279619794} | train loss {'Reaction outcome loss': 0.8030772868727074, 'Total loss': 0.8030772868727074}
2022-11-18 01:51:05,613 INFO:     Found new best model at epoch 61
2022-11-18 01:51:05,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:05,614 INFO:     Epoch: 62
2022-11-18 01:51:06,394 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8109615417413933, 'Total loss': 0.8109615417413933} | train loss {'Reaction outcome loss': 0.7994572947748372, 'Total loss': 0.7994572947748372}
2022-11-18 01:51:06,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:06,394 INFO:     Epoch: 63
2022-11-18 01:51:07,192 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8051378394282142, 'Total loss': 0.8051378394282142} | train loss {'Reaction outcome loss': 0.802038447778733, 'Total loss': 0.802038447778733}
2022-11-18 01:51:07,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:07,193 INFO:     Epoch: 64
2022-11-18 01:51:07,970 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8101697252240292, 'Total loss': 0.8101697252240292} | train loss {'Reaction outcome loss': 0.7971613488969256, 'Total loss': 0.7971613488969256}
2022-11-18 01:51:07,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:07,970 INFO:     Epoch: 65
2022-11-18 01:51:08,787 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8416074063888815, 'Total loss': 0.8416074063888815} | train loss {'Reaction outcome loss': 0.7998351650159867, 'Total loss': 0.7998351650159867}
2022-11-18 01:51:08,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:08,788 INFO:     Epoch: 66
2022-11-18 01:51:09,578 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8232109200122745, 'Total loss': 0.8232109200122745} | train loss {'Reaction outcome loss': 0.7989947545479555, 'Total loss': 0.7989947545479555}
2022-11-18 01:51:09,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:09,579 INFO:     Epoch: 67
2022-11-18 01:51:10,356 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.815482918606248, 'Total loss': 0.815482918606248} | train loss {'Reaction outcome loss': 0.8013740349255625, 'Total loss': 0.8013740349255625}
2022-11-18 01:51:10,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:10,356 INFO:     Epoch: 68
2022-11-18 01:51:11,130 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8149499837742296, 'Total loss': 0.8149499837742296} | train loss {'Reaction outcome loss': 0.7969973401212301, 'Total loss': 0.7969973401212301}
2022-11-18 01:51:11,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:11,130 INFO:     Epoch: 69
2022-11-18 01:51:11,929 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8262467758600102, 'Total loss': 0.8262467758600102} | train loss {'Reaction outcome loss': 0.7996763510049366, 'Total loss': 0.7996763510049366}
2022-11-18 01:51:11,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:11,929 INFO:     Epoch: 70
2022-11-18 01:51:12,704 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8170144668845243, 'Total loss': 0.8170144668845243} | train loss {'Reaction outcome loss': 0.796065455821694, 'Total loss': 0.796065455821694}
2022-11-18 01:51:12,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:12,705 INFO:     Epoch: 71
2022-11-18 01:51:13,472 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8059286405873853, 'Total loss': 0.8059286405873853} | train loss {'Reaction outcome loss': 0.7965486414852689, 'Total loss': 0.7965486414852689}
2022-11-18 01:51:13,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:13,472 INFO:     Epoch: 72
2022-11-18 01:51:14,251 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8132778842781865, 'Total loss': 0.8132778842781865} | train loss {'Reaction outcome loss': 0.7994159089981533, 'Total loss': 0.7994159089981533}
2022-11-18 01:51:14,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:14,252 INFO:     Epoch: 73
2022-11-18 01:51:15,032 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8427160389201586, 'Total loss': 0.8427160389201586} | train loss {'Reaction outcome loss': 0.7945927465792562, 'Total loss': 0.7945927465792562}
2022-11-18 01:51:15,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:15,032 INFO:     Epoch: 74
2022-11-18 01:51:15,815 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8107600378435712, 'Total loss': 0.8107600378435712} | train loss {'Reaction outcome loss': 0.7982503294211919, 'Total loss': 0.7982503294211919}
2022-11-18 01:51:15,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:15,815 INFO:     Epoch: 75
2022-11-18 01:51:16,580 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8230161694593208, 'Total loss': 0.8230161694593208} | train loss {'Reaction outcome loss': 0.8005779439308605, 'Total loss': 0.8005779439308605}
2022-11-18 01:51:16,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:16,580 INFO:     Epoch: 76
2022-11-18 01:51:17,350 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8268201489781224, 'Total loss': 0.8268201489781224} | train loss {'Reaction outcome loss': 0.7998581281939491, 'Total loss': 0.7998581281939491}
2022-11-18 01:51:17,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:17,350 INFO:     Epoch: 77
2022-11-18 01:51:18,142 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8172099507132242, 'Total loss': 0.8172099507132242} | train loss {'Reaction outcome loss': 0.7949903628132382, 'Total loss': 0.7949903628132382}
2022-11-18 01:51:18,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:18,142 INFO:     Epoch: 78
2022-11-18 01:51:18,912 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8102875629136729, 'Total loss': 0.8102875629136729} | train loss {'Reaction outcome loss': 0.7944737151265144, 'Total loss': 0.7944737151265144}
2022-11-18 01:51:18,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:18,912 INFO:     Epoch: 79
2022-11-18 01:51:19,718 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8062552934469178, 'Total loss': 0.8062552934469178} | train loss {'Reaction outcome loss': 0.7989187287014039, 'Total loss': 0.7989187287014039}
2022-11-18 01:51:19,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:19,719 INFO:     Epoch: 80
2022-11-18 01:51:20,497 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8350810325422953, 'Total loss': 0.8350810325422953} | train loss {'Reaction outcome loss': 0.7980782587508686, 'Total loss': 0.7980782587508686}
2022-11-18 01:51:20,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:20,498 INFO:     Epoch: 81
2022-11-18 01:51:21,296 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8072729124579319, 'Total loss': 0.8072729124579319} | train loss {'Reaction outcome loss': 0.7961507158689811, 'Total loss': 0.7961507158689811}
2022-11-18 01:51:21,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:21,296 INFO:     Epoch: 82
2022-11-18 01:51:22,061 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8100666258224222, 'Total loss': 0.8100666258224222} | train loss {'Reaction outcome loss': 0.7971874184784342, 'Total loss': 0.7971874184784342}
2022-11-18 01:51:22,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:22,061 INFO:     Epoch: 83
2022-11-18 01:51:22,849 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8355982539265655, 'Total loss': 0.8355982539265655} | train loss {'Reaction outcome loss': 0.8010150118440879, 'Total loss': 0.8010150118440879}
2022-11-18 01:51:22,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:22,849 INFO:     Epoch: 84
2022-11-18 01:51:23,626 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8185461080351542, 'Total loss': 0.8185461080351542} | train loss {'Reaction outcome loss': 0.7957394637289594, 'Total loss': 0.7957394637289594}
2022-11-18 01:51:23,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:23,626 INFO:     Epoch: 85
2022-11-18 01:51:24,437 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8060474562090497, 'Total loss': 0.8060474562090497} | train loss {'Reaction outcome loss': 0.7973755182789974, 'Total loss': 0.7973755182789974}
2022-11-18 01:51:24,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:24,437 INFO:     Epoch: 86
2022-11-18 01:51:25,203 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8514472225377726, 'Total loss': 0.8514472225377726} | train loss {'Reaction outcome loss': 0.8001958933032927, 'Total loss': 0.8001958933032927}
2022-11-18 01:51:25,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:25,203 INFO:     Epoch: 87
2022-11-18 01:51:25,990 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8079902391101039, 'Total loss': 0.8079902391101039} | train loss {'Reaction outcome loss': 0.7998367153474542, 'Total loss': 0.7998367153474542}
2022-11-18 01:51:25,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:25,991 INFO:     Epoch: 88
2022-11-18 01:51:26,770 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8048346936702728, 'Total loss': 0.8048346936702728} | train loss {'Reaction outcome loss': 0.7958483576286034, 'Total loss': 0.7958483576286034}
2022-11-18 01:51:26,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:26,770 INFO:     Epoch: 89
2022-11-18 01:51:27,532 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8197397291660309, 'Total loss': 0.8197397291660309} | train loss {'Reaction outcome loss': 0.7975913291094733, 'Total loss': 0.7975913291094733}
2022-11-18 01:51:27,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:27,532 INFO:     Epoch: 90
2022-11-18 01:51:28,312 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8211409258981084, 'Total loss': 0.8211409258981084} | train loss {'Reaction outcome loss': 0.7958088810326623, 'Total loss': 0.7958088810326623}
2022-11-18 01:51:28,312 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:28,312 INFO:     Epoch: 91
2022-11-18 01:51:29,094 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8307620335456937, 'Total loss': 0.8307620335456937} | train loss {'Reaction outcome loss': 0.797760859498235, 'Total loss': 0.797760859498235}
2022-11-18 01:51:29,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:29,095 INFO:     Epoch: 92
2022-11-18 01:51:29,889 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8160058363925579, 'Total loss': 0.8160058363925579} | train loss {'Reaction outcome loss': 0.7924581767349946, 'Total loss': 0.7924581767349946}
2022-11-18 01:51:29,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:29,889 INFO:     Epoch: 93
2022-11-18 01:51:30,725 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8542378212130347, 'Total loss': 0.8542378212130347} | train loss {'Reaction outcome loss': 0.7990679451432384, 'Total loss': 0.7990679451432384}
2022-11-18 01:51:30,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:30,726 INFO:     Epoch: 94
2022-11-18 01:51:31,502 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8168784747290057, 'Total loss': 0.8168784747290057} | train loss {'Reaction outcome loss': 0.7958663074208088, 'Total loss': 0.7958663074208088}
2022-11-18 01:51:31,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:31,502 INFO:     Epoch: 95
2022-11-18 01:51:32,254 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8346228447071341, 'Total loss': 0.8346228447071341} | train loss {'Reaction outcome loss': 0.7966763161000658, 'Total loss': 0.7966763161000658}
2022-11-18 01:51:32,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:32,255 INFO:     Epoch: 96
2022-11-18 01:51:33,070 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8113257171109666, 'Total loss': 0.8113257171109666} | train loss {'Reaction outcome loss': 0.7948366782215776, 'Total loss': 0.7948366782215776}
2022-11-18 01:51:33,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:33,070 INFO:     Epoch: 97
2022-11-18 01:51:33,862 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8054338069849236, 'Total loss': 0.8054338069849236} | train loss {'Reaction outcome loss': 0.7957846088731875, 'Total loss': 0.7957846088731875}
2022-11-18 01:51:33,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:33,862 INFO:     Epoch: 98
2022-11-18 01:51:34,617 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8094292567219845, 'Total loss': 0.8094292567219845} | train loss {'Reaction outcome loss': 0.79944267746855, 'Total loss': 0.79944267746855}
2022-11-18 01:51:34,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:34,618 INFO:     Epoch: 99
2022-11-18 01:51:35,414 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.80303444488104, 'Total loss': 0.80303444488104} | train loss {'Reaction outcome loss': 0.7982763146035007, 'Total loss': 0.7982763146035007}
2022-11-18 01:51:35,414 INFO:     Best model found after epoch 62 of 100.
2022-11-18 01:51:35,415 INFO:   Done with stage: TRAINING
2022-11-18 01:51:35,415 INFO:   Starting stage: EVALUATION
2022-11-18 01:51:35,552 INFO:   Done with stage: EVALUATION
2022-11-18 01:51:35,552 INFO:   Leaving out SEQ value Fold_3
2022-11-18 01:51:35,565 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 01:51:35,565 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:51:36,234 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:51:36,234 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:51:36,303 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:51:36,304 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:51:36,304 INFO:     No hyperparam tuning for this model
2022-11-18 01:51:36,304 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:51:36,304 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:51:36,305 INFO:     None feature selector for col prot
2022-11-18 01:51:36,305 INFO:     None feature selector for col prot
2022-11-18 01:51:36,305 INFO:     None feature selector for col prot
2022-11-18 01:51:36,305 INFO:     None feature selector for col chem
2022-11-18 01:51:36,306 INFO:     None feature selector for col chem
2022-11-18 01:51:36,306 INFO:     None feature selector for col chem
2022-11-18 01:51:36,306 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:51:36,306 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:51:36,307 INFO:     Number of params in model 168571
2022-11-18 01:51:36,310 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:51:36,310 INFO:   Starting stage: TRAINING
2022-11-18 01:51:36,368 INFO:     Val loss before train {'Reaction outcome loss': 0.9855483181097291, 'Total loss': 0.9855483181097291}
2022-11-18 01:51:36,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:36,368 INFO:     Epoch: 0
2022-11-18 01:51:37,160 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8724821169268001, 'Total loss': 0.8724821169268001} | train loss {'Reaction outcome loss': 0.8904828584924036, 'Total loss': 0.8904828584924036}
2022-11-18 01:51:37,160 INFO:     Found new best model at epoch 0
2022-11-18 01:51:37,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:37,161 INFO:     Epoch: 1
2022-11-18 01:51:37,967 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8347814225337722, 'Total loss': 0.8347814225337722} | train loss {'Reaction outcome loss': 0.8519609256666534, 'Total loss': 0.8519609256666534}
2022-11-18 01:51:37,967 INFO:     Found new best model at epoch 1
2022-11-18 01:51:37,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:37,968 INFO:     Epoch: 2
2022-11-18 01:51:38,764 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8554544950073416, 'Total loss': 0.8554544950073416} | train loss {'Reaction outcome loss': 0.8557878516158279, 'Total loss': 0.8557878516158279}
2022-11-18 01:51:38,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:38,765 INFO:     Epoch: 3
2022-11-18 01:51:39,566 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8587841276418079, 'Total loss': 0.8587841276418079} | train loss {'Reaction outcome loss': 0.8421346384651807, 'Total loss': 0.8421346384651807}
2022-11-18 01:51:39,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:39,566 INFO:     Epoch: 4
2022-11-18 01:51:40,343 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8295631862499497, 'Total loss': 0.8295631862499497} | train loss {'Reaction outcome loss': 0.840972778991777, 'Total loss': 0.840972778991777}
2022-11-18 01:51:40,344 INFO:     Found new best model at epoch 4
2022-11-18 01:51:40,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:40,345 INFO:     Epoch: 5
2022-11-18 01:51:41,138 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8350588794458996, 'Total loss': 0.8350588794458996} | train loss {'Reaction outcome loss': 0.8366078072664689, 'Total loss': 0.8366078072664689}
2022-11-18 01:51:41,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:41,139 INFO:     Epoch: 6
2022-11-18 01:51:41,993 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8294569633223794, 'Total loss': 0.8294569633223794} | train loss {'Reaction outcome loss': 0.8365836360016647, 'Total loss': 0.8365836360016647}
2022-11-18 01:51:41,993 INFO:     Found new best model at epoch 6
2022-11-18 01:51:41,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:41,994 INFO:     Epoch: 7
2022-11-18 01:51:42,822 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8201671276580204, 'Total loss': 0.8201671276580204} | train loss {'Reaction outcome loss': 0.8301372166799039, 'Total loss': 0.8301372166799039}
2022-11-18 01:51:42,822 INFO:     Found new best model at epoch 7
2022-11-18 01:51:42,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:42,823 INFO:     Epoch: 8
2022-11-18 01:51:43,631 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.833041907034137, 'Total loss': 0.833041907034137} | train loss {'Reaction outcome loss': 0.8301650822162628, 'Total loss': 0.8301650822162628}
2022-11-18 01:51:43,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:43,631 INFO:     Epoch: 9
2022-11-18 01:51:44,436 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8154705762863159, 'Total loss': 0.8154705762863159} | train loss {'Reaction outcome loss': 0.829721066173242, 'Total loss': 0.829721066173242}
2022-11-18 01:51:44,436 INFO:     Found new best model at epoch 9
2022-11-18 01:51:44,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:44,437 INFO:     Epoch: 10
2022-11-18 01:51:45,269 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8331305452368476, 'Total loss': 0.8331305452368476} | train loss {'Reaction outcome loss': 0.8278930914645293, 'Total loss': 0.8278930914645293}
2022-11-18 01:51:45,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:45,269 INFO:     Epoch: 11
2022-11-18 01:51:46,065 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8117879290472377, 'Total loss': 0.8117879290472377} | train loss {'Reaction outcome loss': 0.8288734551595182, 'Total loss': 0.8288734551595182}
2022-11-18 01:51:46,066 INFO:     Found new best model at epoch 11
2022-11-18 01:51:46,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:46,067 INFO:     Epoch: 12
2022-11-18 01:51:46,867 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8176513795148243, 'Total loss': 0.8176513795148243} | train loss {'Reaction outcome loss': 0.82648553300877, 'Total loss': 0.82648553300877}
2022-11-18 01:51:46,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:46,867 INFO:     Epoch: 13
2022-11-18 01:51:47,675 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8391639278693632, 'Total loss': 0.8391639278693632} | train loss {'Reaction outcome loss': 0.8290716784340995, 'Total loss': 0.8290716784340995}
2022-11-18 01:51:47,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:47,675 INFO:     Epoch: 14
2022-11-18 01:51:48,467 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8284496021541682, 'Total loss': 0.8284496021541682} | train loss {'Reaction outcome loss': 0.8270236616231957, 'Total loss': 0.8270236616231957}
2022-11-18 01:51:48,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:48,467 INFO:     Epoch: 15
2022-11-18 01:51:49,253 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8265766880728982, 'Total loss': 0.8265766880728982} | train loss {'Reaction outcome loss': 0.8224784477632873, 'Total loss': 0.8224784477632873}
2022-11-18 01:51:49,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:49,254 INFO:     Epoch: 16
2022-11-18 01:51:50,013 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8391678414561532, 'Total loss': 0.8391678414561532} | train loss {'Reaction outcome loss': 0.8231560096448781, 'Total loss': 0.8231560096448781}
2022-11-18 01:51:50,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:50,013 INFO:     Epoch: 17
2022-11-18 01:51:50,803 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8402647118676793, 'Total loss': 0.8402647118676793} | train loss {'Reaction outcome loss': 0.8230815835145056, 'Total loss': 0.8230815835145056}
2022-11-18 01:51:50,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:50,805 INFO:     Epoch: 18
2022-11-18 01:51:51,612 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7994646138765595, 'Total loss': 0.7994646138765595} | train loss {'Reaction outcome loss': 0.8208448573034637, 'Total loss': 0.8208448573034637}
2022-11-18 01:51:51,613 INFO:     Found new best model at epoch 18
2022-11-18 01:51:51,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:51,614 INFO:     Epoch: 19
2022-11-18 01:51:52,407 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8377402011643756, 'Total loss': 0.8377402011643756} | train loss {'Reaction outcome loss': 0.8230078234964487, 'Total loss': 0.8230078234964487}
2022-11-18 01:51:52,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:52,407 INFO:     Epoch: 20
2022-11-18 01:51:53,224 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8236462704159997, 'Total loss': 0.8236462704159997} | train loss {'Reaction outcome loss': 0.8222983651015223, 'Total loss': 0.8222983651015223}
2022-11-18 01:51:53,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:53,224 INFO:     Epoch: 21
2022-11-18 01:51:54,016 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8087646080688997, 'Total loss': 0.8087646080688997} | train loss {'Reaction outcome loss': 0.817076997124419, 'Total loss': 0.817076997124419}
2022-11-18 01:51:54,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:54,016 INFO:     Epoch: 22
2022-11-18 01:51:54,812 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8428098125891252, 'Total loss': 0.8428098125891252} | train loss {'Reaction outcome loss': 0.8248837901621449, 'Total loss': 0.8248837901621449}
2022-11-18 01:51:54,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:54,812 INFO:     Epoch: 23
2022-11-18 01:51:55,642 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8157925727692518, 'Total loss': 0.8157925727692518} | train loss {'Reaction outcome loss': 0.8185457328144385, 'Total loss': 0.8185457328144385}
2022-11-18 01:51:55,642 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:55,642 INFO:     Epoch: 24
2022-11-18 01:51:56,412 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8136897100643679, 'Total loss': 0.8136897100643679} | train loss {'Reaction outcome loss': 0.8228774643674188, 'Total loss': 0.8228774643674188}
2022-11-18 01:51:56,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:56,412 INFO:     Epoch: 25
2022-11-18 01:51:57,213 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8189163384112444, 'Total loss': 0.8189163384112444} | train loss {'Reaction outcome loss': 0.8200931047906681, 'Total loss': 0.8200931047906681}
2022-11-18 01:51:57,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:57,214 INFO:     Epoch: 26
2022-11-18 01:51:57,999 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8175188804214651, 'Total loss': 0.8175188804214651} | train loss {'Reaction outcome loss': 0.8271780685502655, 'Total loss': 0.8271780685502655}
2022-11-18 01:51:57,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:58,000 INFO:     Epoch: 27
2022-11-18 01:51:58,863 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8155961273746057, 'Total loss': 0.8155961273746057} | train loss {'Reaction outcome loss': 0.8187324143185908, 'Total loss': 0.8187324143185908}
2022-11-18 01:51:58,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:58,863 INFO:     Epoch: 28
2022-11-18 01:51:59,699 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8139745992693034, 'Total loss': 0.8139745992693034} | train loss {'Reaction outcome loss': 0.8194360071299027, 'Total loss': 0.8194360071299027}
2022-11-18 01:51:59,700 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:51:59,700 INFO:     Epoch: 29
2022-11-18 01:52:00,493 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8243107463825833, 'Total loss': 0.8243107463825833} | train loss {'Reaction outcome loss': 0.8161999814364375, 'Total loss': 0.8161999814364375}
2022-11-18 01:52:00,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:00,493 INFO:     Epoch: 30
2022-11-18 01:52:01,273 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8167907988483255, 'Total loss': 0.8167907988483255} | train loss {'Reaction outcome loss': 0.8169477091760051, 'Total loss': 0.8169477091760051}
2022-11-18 01:52:01,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:01,273 INFO:     Epoch: 31
2022-11-18 01:52:02,090 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.803972721777179, 'Total loss': 0.803972721777179} | train loss {'Reaction outcome loss': 0.8211565962859563, 'Total loss': 0.8211565962859563}
2022-11-18 01:52:02,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:02,090 INFO:     Epoch: 32
2022-11-18 01:52:02,912 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8386917249722914, 'Total loss': 0.8386917249722914} | train loss {'Reaction outcome loss': 0.8215924378560514, 'Total loss': 0.8215924378560514}
2022-11-18 01:52:02,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:02,912 INFO:     Epoch: 33
2022-11-18 01:52:03,747 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.815852475437251, 'Total loss': 0.815852475437251} | train loss {'Reaction outcome loss': 0.8221594181596016, 'Total loss': 0.8221594181596016}
2022-11-18 01:52:03,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:03,747 INFO:     Epoch: 34
2022-11-18 01:52:04,543 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8129718053069982, 'Total loss': 0.8129718053069982} | train loss {'Reaction outcome loss': 0.8191129329253216, 'Total loss': 0.8191129329253216}
2022-11-18 01:52:04,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:04,544 INFO:     Epoch: 35
2022-11-18 01:52:05,366 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8285559815439311, 'Total loss': 0.8285559815439311} | train loss {'Reaction outcome loss': 0.818530416123721, 'Total loss': 0.818530416123721}
2022-11-18 01:52:05,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:05,366 INFO:     Epoch: 36
2022-11-18 01:52:06,173 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8395363268527117, 'Total loss': 0.8395363268527117} | train loss {'Reaction outcome loss': 0.8202820537041645, 'Total loss': 0.8202820537041645}
2022-11-18 01:52:06,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:06,173 INFO:     Epoch: 37
2022-11-18 01:52:06,926 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.818234192376787, 'Total loss': 0.818234192376787} | train loss {'Reaction outcome loss': 0.822219793042358, 'Total loss': 0.822219793042358}
2022-11-18 01:52:06,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:06,926 INFO:     Epoch: 38
2022-11-18 01:52:07,733 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8222955587235364, 'Total loss': 0.8222955587235364} | train loss {'Reaction outcome loss': 0.819202379669462, 'Total loss': 0.819202379669462}
2022-11-18 01:52:07,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:07,734 INFO:     Epoch: 39
2022-11-18 01:52:08,501 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8306243243542585, 'Total loss': 0.8306243243542585} | train loss {'Reaction outcome loss': 0.8199263515521069, 'Total loss': 0.8199263515521069}
2022-11-18 01:52:08,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:08,502 INFO:     Epoch: 40
2022-11-18 01:52:09,342 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8338681676171043, 'Total loss': 0.8338681676171043} | train loss {'Reaction outcome loss': 0.8164817340519963, 'Total loss': 0.8164817340519963}
2022-11-18 01:52:09,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:09,343 INFO:     Epoch: 41
2022-11-18 01:52:10,173 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8084397451444105, 'Total loss': 0.8084397451444105} | train loss {'Reaction outcome loss': 0.8216561942684407, 'Total loss': 0.8216561942684407}
2022-11-18 01:52:10,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:10,173 INFO:     Epoch: 42
2022-11-18 01:52:10,957 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8077757717533545, 'Total loss': 0.8077757717533545} | train loss {'Reaction outcome loss': 0.8203771107050837, 'Total loss': 0.8203771107050837}
2022-11-18 01:52:10,957 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:10,957 INFO:     Epoch: 43
2022-11-18 01:52:11,768 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8226623806086454, 'Total loss': 0.8226623806086454} | train loss {'Reaction outcome loss': 0.8176328898692617, 'Total loss': 0.8176328898692617}
2022-11-18 01:52:11,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:11,768 INFO:     Epoch: 44
2022-11-18 01:52:12,583 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8412598479877819, 'Total loss': 0.8412598479877819} | train loss {'Reaction outcome loss': 0.8178366884893301, 'Total loss': 0.8178366884893301}
2022-11-18 01:52:12,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:12,584 INFO:     Epoch: 45
2022-11-18 01:52:13,376 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8131832927465439, 'Total loss': 0.8131832927465439} | train loss {'Reaction outcome loss': 0.8216297642308839, 'Total loss': 0.8216297642308839}
2022-11-18 01:52:13,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:13,376 INFO:     Epoch: 46
2022-11-18 01:52:14,132 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8158395134589889, 'Total loss': 0.8158395134589889} | train loss {'Reaction outcome loss': 0.8190994700606988, 'Total loss': 0.8190994700606988}
2022-11-18 01:52:14,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:14,132 INFO:     Epoch: 47
2022-11-18 01:52:14,937 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8027051876891743, 'Total loss': 0.8027051876891743} | train loss {'Reaction outcome loss': 0.8221862131235551, 'Total loss': 0.8221862131235551}
2022-11-18 01:52:14,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:14,938 INFO:     Epoch: 48
2022-11-18 01:52:15,748 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8200927959247069, 'Total loss': 0.8200927959247069} | train loss {'Reaction outcome loss': 0.8196753914258919, 'Total loss': 0.8196753914258919}
2022-11-18 01:52:15,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:15,748 INFO:     Epoch: 49
2022-11-18 01:52:16,539 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8392616977745836, 'Total loss': 0.8392616977745836} | train loss {'Reaction outcome loss': 0.8182021268776485, 'Total loss': 0.8182021268776485}
2022-11-18 01:52:16,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:16,540 INFO:     Epoch: 50
2022-11-18 01:52:17,342 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8211564110084013, 'Total loss': 0.8211564110084013} | train loss {'Reaction outcome loss': 0.8188291783235511, 'Total loss': 0.8188291783235511}
2022-11-18 01:52:17,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:17,343 INFO:     Epoch: 51
2022-11-18 01:52:18,152 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8377066918394782, 'Total loss': 0.8377066918394782} | train loss {'Reaction outcome loss': 0.8199318053771039, 'Total loss': 0.8199318053771039}
2022-11-18 01:52:18,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:18,152 INFO:     Epoch: 52
2022-11-18 01:52:18,927 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8233856748450886, 'Total loss': 0.8233856748450886} | train loss {'Reaction outcome loss': 0.813314331186061, 'Total loss': 0.813314331186061}
2022-11-18 01:52:18,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:18,928 INFO:     Epoch: 53
2022-11-18 01:52:19,756 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8104925196279179, 'Total loss': 0.8104925196279179} | train loss {'Reaction outcome loss': 0.8166791548534316, 'Total loss': 0.8166791548534316}
2022-11-18 01:52:19,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:19,756 INFO:     Epoch: 54
2022-11-18 01:52:20,573 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8097295327620073, 'Total loss': 0.8097295327620073} | train loss {'Reaction outcome loss': 0.8175098432570088, 'Total loss': 0.8175098432570088}
2022-11-18 01:52:20,573 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:20,574 INFO:     Epoch: 55
2022-11-18 01:52:21,357 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8107969462871552, 'Total loss': 0.8107969462871552} | train loss {'Reaction outcome loss': 0.8223985343563314, 'Total loss': 0.8223985343563314}
2022-11-18 01:52:21,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:21,358 INFO:     Epoch: 56
2022-11-18 01:52:22,165 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8548758883367885, 'Total loss': 0.8548758883367885} | train loss {'Reaction outcome loss': 0.8159188726726844, 'Total loss': 0.8159188726726844}
2022-11-18 01:52:22,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:22,166 INFO:     Epoch: 57
2022-11-18 01:52:23,005 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8285508379340172, 'Total loss': 0.8285508379340172} | train loss {'Reaction outcome loss': 0.8221867816788809, 'Total loss': 0.8221867816788809}
2022-11-18 01:52:23,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:23,006 INFO:     Epoch: 58
2022-11-18 01:52:23,828 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8191056820479307, 'Total loss': 0.8191056820479307} | train loss {'Reaction outcome loss': 0.8183681823769394, 'Total loss': 0.8183681823769394}
2022-11-18 01:52:23,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:23,829 INFO:     Epoch: 59
2022-11-18 01:52:24,615 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8221446031873877, 'Total loss': 0.8221446031873877} | train loss {'Reaction outcome loss': 0.8148857394043281, 'Total loss': 0.8148857394043281}
2022-11-18 01:52:24,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:24,615 INFO:     Epoch: 60
2022-11-18 01:52:25,442 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.804823634299365, 'Total loss': 0.804823634299365} | train loss {'Reaction outcome loss': 0.8152484729581949, 'Total loss': 0.8152484729581949}
2022-11-18 01:52:25,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:25,442 INFO:     Epoch: 61
2022-11-18 01:52:26,289 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8321626443754543, 'Total loss': 0.8321626443754543} | train loss {'Reaction outcome loss': 0.8159189910304789, 'Total loss': 0.8159189910304789}
2022-11-18 01:52:26,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:26,290 INFO:     Epoch: 62
2022-11-18 01:52:27,154 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8279090591452338, 'Total loss': 0.8279090591452338} | train loss {'Reaction outcome loss': 0.8159323985479316, 'Total loss': 0.8159323985479316}
2022-11-18 01:52:27,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:27,154 INFO:     Epoch: 63
2022-11-18 01:52:27,969 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8336657583713531, 'Total loss': 0.8336657583713531} | train loss {'Reaction outcome loss': 0.8112276676966219, 'Total loss': 0.8112276676966219}
2022-11-18 01:52:27,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:27,969 INFO:     Epoch: 64
2022-11-18 01:52:28,776 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8079055622220039, 'Total loss': 0.8079055622220039} | train loss {'Reaction outcome loss': 0.8162552878564718, 'Total loss': 0.8162552878564718}
2022-11-18 01:52:28,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:28,777 INFO:     Epoch: 65
2022-11-18 01:52:29,549 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8195880502462387, 'Total loss': 0.8195880502462387} | train loss {'Reaction outcome loss': 0.8147831065314156, 'Total loss': 0.8147831065314156}
2022-11-18 01:52:29,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:29,550 INFO:     Epoch: 66
2022-11-18 01:52:30,354 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8069255643270232, 'Total loss': 0.8069255643270232} | train loss {'Reaction outcome loss': 0.8172041775012503, 'Total loss': 0.8172041775012503}
2022-11-18 01:52:30,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:30,354 INFO:     Epoch: 67
2022-11-18 01:52:31,142 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8133753836154938, 'Total loss': 0.8133753836154938} | train loss {'Reaction outcome loss': 0.812566833106839, 'Total loss': 0.812566833106839}
2022-11-18 01:52:31,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:31,142 INFO:     Epoch: 68
2022-11-18 01:52:31,977 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8257559226317839, 'Total loss': 0.8257559226317839} | train loss {'Reaction outcome loss': 0.8170682225908552, 'Total loss': 0.8170682225908552}
2022-11-18 01:52:31,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:31,977 INFO:     Epoch: 69
2022-11-18 01:52:32,782 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8162254325368188, 'Total loss': 0.8162254325368188} | train loss {'Reaction outcome loss': 0.819188555892633, 'Total loss': 0.819188555892633}
2022-11-18 01:52:32,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:32,782 INFO:     Epoch: 70
2022-11-18 01:52:33,558 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.816614456474781, 'Total loss': 0.816614456474781} | train loss {'Reaction outcome loss': 0.8131253188970138, 'Total loss': 0.8131253188970138}
2022-11-18 01:52:33,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:33,558 INFO:     Epoch: 71
2022-11-18 01:52:34,379 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8206470114263621, 'Total loss': 0.8206470114263621} | train loss {'Reaction outcome loss': 0.8150095394679479, 'Total loss': 0.8150095394679479}
2022-11-18 01:52:34,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:34,379 INFO:     Epoch: 72
2022-11-18 01:52:35,255 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8103415505452589, 'Total loss': 0.8103415505452589} | train loss {'Reaction outcome loss': 0.819088429090928, 'Total loss': 0.819088429090928}
2022-11-18 01:52:35,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:35,255 INFO:     Epoch: 73
2022-11-18 01:52:36,084 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.81760504164479, 'Total loss': 0.81760504164479} | train loss {'Reaction outcome loss': 0.819102698199603, 'Total loss': 0.819102698199603}
2022-11-18 01:52:36,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:36,085 INFO:     Epoch: 74
2022-11-18 01:52:36,843 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8288022076541727, 'Total loss': 0.8288022076541727} | train loss {'Reaction outcome loss': 0.8136010184579966, 'Total loss': 0.8136010184579966}
2022-11-18 01:52:36,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:36,844 INFO:     Epoch: 75
2022-11-18 01:52:37,656 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8295125141739845, 'Total loss': 0.8295125141739845} | train loss {'Reaction outcome loss': 0.8133420398040694, 'Total loss': 0.8133420398040694}
2022-11-18 01:52:37,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:37,656 INFO:     Epoch: 76
2022-11-18 01:52:38,492 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8392773311246525, 'Total loss': 0.8392773311246525} | train loss {'Reaction outcome loss': 0.8149493367088084, 'Total loss': 0.8149493367088084}
2022-11-18 01:52:38,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:38,492 INFO:     Epoch: 77
2022-11-18 01:52:39,324 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8071763755922968, 'Total loss': 0.8071763755922968} | train loss {'Reaction outcome loss': 0.8192359632375289, 'Total loss': 0.8192359632375289}
2022-11-18 01:52:39,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:39,325 INFO:     Epoch: 78
2022-11-18 01:52:40,138 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8267881775444205, 'Total loss': 0.8267881775444205} | train loss {'Reaction outcome loss': 0.8172482962511024, 'Total loss': 0.8172482962511024}
2022-11-18 01:52:40,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:40,138 INFO:     Epoch: 79
2022-11-18 01:52:40,933 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8442167057232424, 'Total loss': 0.8442167057232424} | train loss {'Reaction outcome loss': 0.8171228030506446, 'Total loss': 0.8171228030506446}
2022-11-18 01:52:40,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:40,934 INFO:     Epoch: 80
2022-11-18 01:52:41,732 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8210743882439353, 'Total loss': 0.8210743882439353} | train loss {'Reaction outcome loss': 0.8129873838959908, 'Total loss': 0.8129873838959908}
2022-11-18 01:52:41,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:41,733 INFO:     Epoch: 81
2022-11-18 01:52:42,507 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8167273090644316, 'Total loss': 0.8167273090644316} | train loss {'Reaction outcome loss': 0.8169779615742819, 'Total loss': 0.8169779615742819}
2022-11-18 01:52:42,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:42,507 INFO:     Epoch: 82
2022-11-18 01:52:43,317 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.805661104619503, 'Total loss': 0.805661104619503} | train loss {'Reaction outcome loss': 0.8174375004914343, 'Total loss': 0.8174375004914343}
2022-11-18 01:52:43,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:43,317 INFO:     Epoch: 83
2022-11-18 01:52:44,109 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8455500385978005, 'Total loss': 0.8455500385978005} | train loss {'Reaction outcome loss': 0.8169762208753703, 'Total loss': 0.8169762208753703}
2022-11-18 01:52:44,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:44,110 INFO:     Epoch: 84
2022-11-18 01:52:44,902 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8223023360425775, 'Total loss': 0.8223023360425775} | train loss {'Reaction outcome loss': 0.8181002582822527, 'Total loss': 0.8181002582822527}
2022-11-18 01:52:44,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:44,902 INFO:     Epoch: 85
2022-11-18 01:52:45,705 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8155919455669143, 'Total loss': 0.8155919455669143} | train loss {'Reaction outcome loss': 0.813981781322129, 'Total loss': 0.813981781322129}
2022-11-18 01:52:45,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:45,705 INFO:     Epoch: 86
2022-11-18 01:52:46,512 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8093944659287279, 'Total loss': 0.8093944659287279} | train loss {'Reaction outcome loss': 0.8165554330057028, 'Total loss': 0.8165554330057028}
2022-11-18 01:52:46,513 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:46,513 INFO:     Epoch: 87
2022-11-18 01:52:47,343 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8174021352421154, 'Total loss': 0.8174021352421154} | train loss {'Reaction outcome loss': 0.8194480286569011, 'Total loss': 0.8194480286569011}
2022-11-18 01:52:47,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:47,343 INFO:     Epoch: 88
2022-11-18 01:52:48,143 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8365622691132806, 'Total loss': 0.8365622691132806} | train loss {'Reaction outcome loss': 0.8206112314243705, 'Total loss': 0.8206112314243705}
2022-11-18 01:52:48,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:48,144 INFO:     Epoch: 89
2022-11-18 01:52:48,928 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8353095610033382, 'Total loss': 0.8353095610033382} | train loss {'Reaction outcome loss': 0.8167691301326363, 'Total loss': 0.8167691301326363}
2022-11-18 01:52:48,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:48,928 INFO:     Epoch: 90
2022-11-18 01:52:49,738 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8213008628650145, 'Total loss': 0.8213008628650145} | train loss {'Reaction outcome loss': 0.8196608992255464, 'Total loss': 0.8196608992255464}
2022-11-18 01:52:49,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:49,738 INFO:     Epoch: 91
2022-11-18 01:52:50,537 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.815705618397756, 'Total loss': 0.815705618397756} | train loss {'Reaction outcome loss': 0.816560983779479, 'Total loss': 0.816560983779479}
2022-11-18 01:52:50,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:50,537 INFO:     Epoch: 92
2022-11-18 01:52:51,369 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8043755455450579, 'Total loss': 0.8043755455450579} | train loss {'Reaction outcome loss': 0.8187641873651621, 'Total loss': 0.8187641873651621}
2022-11-18 01:52:51,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:51,370 INFO:     Epoch: 93
2022-11-18 01:52:52,146 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8036452802744779, 'Total loss': 0.8036452802744779} | train loss {'Reaction outcome loss': 0.8198687454875635, 'Total loss': 0.8198687454875635}
2022-11-18 01:52:52,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:52,147 INFO:     Epoch: 94
2022-11-18 01:52:52,949 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8191576857458461, 'Total loss': 0.8191576857458461} | train loss {'Reaction outcome loss': 0.8200154061220131, 'Total loss': 0.8200154061220131}
2022-11-18 01:52:52,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:52,955 INFO:     Epoch: 95
2022-11-18 01:52:53,757 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8140184303576296, 'Total loss': 0.8140184303576296} | train loss {'Reaction outcome loss': 0.8187558812754495, 'Total loss': 0.8187558812754495}
2022-11-18 01:52:53,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:53,757 INFO:     Epoch: 96
2022-11-18 01:52:54,526 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8085536069490693, 'Total loss': 0.8085536069490693} | train loss {'Reaction outcome loss': 0.8209476727612165, 'Total loss': 0.8209476727612165}
2022-11-18 01:52:54,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:54,526 INFO:     Epoch: 97
2022-11-18 01:52:55,290 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8142980696125464, 'Total loss': 0.8142980696125464} | train loss {'Reaction outcome loss': 0.8142977364209234, 'Total loss': 0.8142977364209234}
2022-11-18 01:52:55,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:55,291 INFO:     Epoch: 98
2022-11-18 01:52:56,102 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8428856513716958, 'Total loss': 0.8428856513716958} | train loss {'Reaction outcome loss': 0.8196135076941277, 'Total loss': 0.8196135076941277}
2022-11-18 01:52:56,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:56,102 INFO:     Epoch: 99
2022-11-18 01:52:56,926 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8158190710978075, 'Total loss': 0.8158190710978075} | train loss {'Reaction outcome loss': 0.8193039124109307, 'Total loss': 0.8193039124109307}
2022-11-18 01:52:56,926 INFO:     Best model found after epoch 19 of 100.
2022-11-18 01:52:56,926 INFO:   Done with stage: TRAINING
2022-11-18 01:52:56,926 INFO:   Starting stage: EVALUATION
2022-11-18 01:52:57,056 INFO:   Done with stage: EVALUATION
2022-11-18 01:52:57,057 INFO:   Leaving out SEQ value Fold_4
2022-11-18 01:52:57,070 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 01:52:57,070 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:52:57,748 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:52:57,748 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:52:57,818 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:52:57,818 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:52:57,818 INFO:     No hyperparam tuning for this model
2022-11-18 01:52:57,818 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:52:57,818 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:52:57,819 INFO:     None feature selector for col prot
2022-11-18 01:52:57,819 INFO:     None feature selector for col prot
2022-11-18 01:52:57,819 INFO:     None feature selector for col prot
2022-11-18 01:52:57,820 INFO:     None feature selector for col chem
2022-11-18 01:52:57,820 INFO:     None feature selector for col chem
2022-11-18 01:52:57,820 INFO:     None feature selector for col chem
2022-11-18 01:52:57,820 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:52:57,820 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:52:57,822 INFO:     Number of params in model 168571
2022-11-18 01:52:57,825 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:52:57,825 INFO:   Starting stage: TRAINING
2022-11-18 01:52:57,883 INFO:     Val loss before train {'Reaction outcome loss': 1.0288439677520231, 'Total loss': 1.0288439677520231}
2022-11-18 01:52:57,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:57,883 INFO:     Epoch: 0
2022-11-18 01:52:58,694 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.890174765478481, 'Total loss': 0.890174765478481} | train loss {'Reaction outcome loss': 0.878694015113931, 'Total loss': 0.878694015113931}
2022-11-18 01:52:58,694 INFO:     Found new best model at epoch 0
2022-11-18 01:52:58,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:58,695 INFO:     Epoch: 1
2022-11-18 01:52:59,520 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8670060255310752, 'Total loss': 0.8670060255310752} | train loss {'Reaction outcome loss': 0.8456170952271836, 'Total loss': 0.8456170952271836}
2022-11-18 01:52:59,521 INFO:     Found new best model at epoch 1
2022-11-18 01:52:59,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:52:59,522 INFO:     Epoch: 2
2022-11-18 01:53:00,308 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.9087719524448569, 'Total loss': 0.9087719524448569} | train loss {'Reaction outcome loss': 0.8387301145536215, 'Total loss': 0.8387301145536215}
2022-11-18 01:53:00,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:00,309 INFO:     Epoch: 3
2022-11-18 01:53:01,098 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8624072616750543, 'Total loss': 0.8624072616750543} | train loss {'Reaction outcome loss': 0.8342384734089195, 'Total loss': 0.8342384734089195}
2022-11-18 01:53:01,098 INFO:     Found new best model at epoch 3
2022-11-18 01:53:01,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:01,099 INFO:     Epoch: 4
2022-11-18 01:53:01,901 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8812376856803894, 'Total loss': 0.8812376856803894} | train loss {'Reaction outcome loss': 0.827886767956892, 'Total loss': 0.827886767956892}
2022-11-18 01:53:01,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:01,901 INFO:     Epoch: 5
2022-11-18 01:53:02,692 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8573819453066046, 'Total loss': 0.8573819453066046} | train loss {'Reaction outcome loss': 0.822098929148454, 'Total loss': 0.822098929148454}
2022-11-18 01:53:02,692 INFO:     Found new best model at epoch 5
2022-11-18 01:53:02,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:02,693 INFO:     Epoch: 6
2022-11-18 01:53:03,519 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8444511687213724, 'Total loss': 0.8444511687213724} | train loss {'Reaction outcome loss': 0.8241338542839776, 'Total loss': 0.8241338542839776}
2022-11-18 01:53:03,520 INFO:     Found new best model at epoch 6
2022-11-18 01:53:03,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:03,520 INFO:     Epoch: 7
2022-11-18 01:53:04,318 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8401924046603116, 'Total loss': 0.8401924046603116} | train loss {'Reaction outcome loss': 0.8163512525891485, 'Total loss': 0.8163512525891485}
2022-11-18 01:53:04,318 INFO:     Found new best model at epoch 7
2022-11-18 01:53:04,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:04,319 INFO:     Epoch: 8
2022-11-18 01:53:05,166 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8321374140002511, 'Total loss': 0.8321374140002511} | train loss {'Reaction outcome loss': 0.8168574383384303, 'Total loss': 0.8168574383384303}
2022-11-18 01:53:05,166 INFO:     Found new best model at epoch 8
2022-11-18 01:53:05,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:05,167 INFO:     Epoch: 9
2022-11-18 01:53:05,974 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.836090053347024, 'Total loss': 0.836090053347024} | train loss {'Reaction outcome loss': 0.816768164456132, 'Total loss': 0.816768164456132}
2022-11-18 01:53:05,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:05,975 INFO:     Epoch: 10
2022-11-18 01:53:06,823 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8359794684431769, 'Total loss': 0.8359794684431769} | train loss {'Reaction outcome loss': 0.8211942777218606, 'Total loss': 0.8211942777218606}
2022-11-18 01:53:06,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:06,823 INFO:     Epoch: 11
2022-11-18 01:53:07,636 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8502193025567315, 'Total loss': 0.8502193025567315} | train loss {'Reaction outcome loss': 0.8210664619559701, 'Total loss': 0.8210664619559701}
2022-11-18 01:53:07,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:07,636 INFO:     Epoch: 12
2022-11-18 01:53:08,465 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8393169119954109, 'Total loss': 0.8393169119954109} | train loss {'Reaction outcome loss': 0.8171540288488391, 'Total loss': 0.8171540288488391}
2022-11-18 01:53:08,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:08,465 INFO:     Epoch: 13
2022-11-18 01:53:09,279 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8401294696060094, 'Total loss': 0.8401294696060094} | train loss {'Reaction outcome loss': 0.8145882998883482, 'Total loss': 0.8145882998883482}
2022-11-18 01:53:09,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:09,280 INFO:     Epoch: 14
2022-11-18 01:53:10,096 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8718779608607292, 'Total loss': 0.8718779608607292} | train loss {'Reaction outcome loss': 0.8222343003460271, 'Total loss': 0.8222343003460271}
2022-11-18 01:53:10,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:10,097 INFO:     Epoch: 15
2022-11-18 01:53:10,897 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.832567765631459, 'Total loss': 0.832567765631459} | train loss {'Reaction outcome loss': 0.8193820007899513, 'Total loss': 0.8193820007899513}
2022-11-18 01:53:10,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:10,897 INFO:     Epoch: 16
2022-11-18 01:53:11,708 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8675795353271745, 'Total loss': 0.8675795353271745} | train loss {'Reaction outcome loss': 0.8175631181189889, 'Total loss': 0.8175631181189889}
2022-11-18 01:53:11,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:11,709 INFO:     Epoch: 17
2022-11-18 01:53:12,537 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8460586436770179, 'Total loss': 0.8460586436770179} | train loss {'Reaction outcome loss': 0.8180883441135468, 'Total loss': 0.8180883441135468}
2022-11-18 01:53:12,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:12,537 INFO:     Epoch: 18
2022-11-18 01:53:13,343 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.842516265809536, 'Total loss': 0.842516265809536} | train loss {'Reaction outcome loss': 0.8108235846465899, 'Total loss': 0.8108235846465899}
2022-11-18 01:53:13,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:13,343 INFO:     Epoch: 19
2022-11-18 01:53:14,171 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8536419421434402, 'Total loss': 0.8536419421434402} | train loss {'Reaction outcome loss': 0.8100715209598001, 'Total loss': 0.8100715209598001}
2022-11-18 01:53:14,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:14,171 INFO:     Epoch: 20
2022-11-18 01:53:15,032 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8347699208693071, 'Total loss': 0.8347699208693071} | train loss {'Reaction outcome loss': 0.8195057610268535, 'Total loss': 0.8195057610268535}
2022-11-18 01:53:15,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:15,033 INFO:     Epoch: 21
2022-11-18 01:53:15,822 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8383682803674177, 'Total loss': 0.8383682803674177} | train loss {'Reaction outcome loss': 0.8239826780823079, 'Total loss': 0.8239826780823079}
2022-11-18 01:53:15,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:15,822 INFO:     Epoch: 22
2022-11-18 01:53:16,671 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8559094471010295, 'Total loss': 0.8559094471010295} | train loss {'Reaction outcome loss': 0.8174729072130643, 'Total loss': 0.8174729072130643}
2022-11-18 01:53:16,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:16,671 INFO:     Epoch: 23
2022-11-18 01:53:17,456 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8670106841759249, 'Total loss': 0.8670106841759249} | train loss {'Reaction outcome loss': 0.8161233586338368, 'Total loss': 0.8161233586338368}
2022-11-18 01:53:17,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:17,456 INFO:     Epoch: 24
2022-11-18 01:53:18,277 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.841659888625145, 'Total loss': 0.841659888625145} | train loss {'Reaction outcome loss': 0.8114221985282203, 'Total loss': 0.8114221985282203}
2022-11-18 01:53:18,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:18,277 INFO:     Epoch: 25
2022-11-18 01:53:19,047 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8258939798582684, 'Total loss': 0.8258939798582684} | train loss {'Reaction outcome loss': 0.8124210973258926, 'Total loss': 0.8124210973258926}
2022-11-18 01:53:19,047 INFO:     Found new best model at epoch 25
2022-11-18 01:53:19,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:19,048 INFO:     Epoch: 26
2022-11-18 01:53:19,842 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8345311561768706, 'Total loss': 0.8345311561768706} | train loss {'Reaction outcome loss': 0.8143287081467477, 'Total loss': 0.8143287081467477}
2022-11-18 01:53:19,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:19,843 INFO:     Epoch: 27
2022-11-18 01:53:20,661 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8368715115568854, 'Total loss': 0.8368715115568854} | train loss {'Reaction outcome loss': 0.813109946275047, 'Total loss': 0.813109946275047}
2022-11-18 01:53:20,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:20,661 INFO:     Epoch: 28
2022-11-18 01:53:21,506 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8568050319498236, 'Total loss': 0.8568050319498236} | train loss {'Reaction outcome loss': 0.817339622660687, 'Total loss': 0.817339622660687}
2022-11-18 01:53:21,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:21,506 INFO:     Epoch: 29
2022-11-18 01:53:22,296 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8571754043752496, 'Total loss': 0.8571754043752496} | train loss {'Reaction outcome loss': 0.8136981820408632, 'Total loss': 0.8136981820408632}
2022-11-18 01:53:22,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:22,296 INFO:     Epoch: 30
2022-11-18 01:53:23,101 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.864190934733911, 'Total loss': 0.864190934733911} | train loss {'Reaction outcome loss': 0.8140823620292339, 'Total loss': 0.8140823620292339}
2022-11-18 01:53:23,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:23,101 INFO:     Epoch: 31
2022-11-18 01:53:23,945 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8692850639874284, 'Total loss': 0.8692850639874284} | train loss {'Reaction outcome loss': 0.811760342434833, 'Total loss': 0.811760342434833}
2022-11-18 01:53:23,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:23,946 INFO:     Epoch: 32
2022-11-18 01:53:24,736 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8384306410496886, 'Total loss': 0.8384306410496886} | train loss {'Reaction outcome loss': 0.818135892452016, 'Total loss': 0.818135892452016}
2022-11-18 01:53:24,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:24,737 INFO:     Epoch: 33
2022-11-18 01:53:25,579 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.827412792227485, 'Total loss': 0.827412792227485} | train loss {'Reaction outcome loss': 0.8162693105004577, 'Total loss': 0.8162693105004577}
2022-11-18 01:53:25,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:25,580 INFO:     Epoch: 34
2022-11-18 01:53:26,374 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8376772647554224, 'Total loss': 0.8376772647554224} | train loss {'Reaction outcome loss': 0.8150112720636221, 'Total loss': 0.8150112720636221}
2022-11-18 01:53:26,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:26,375 INFO:     Epoch: 35
2022-11-18 01:53:27,190 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8259447183121335, 'Total loss': 0.8259447183121335} | train loss {'Reaction outcome loss': 0.8187984894161765, 'Total loss': 0.8187984894161765}
2022-11-18 01:53:27,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:27,190 INFO:     Epoch: 36
2022-11-18 01:53:28,003 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8321810188618574, 'Total loss': 0.8321810188618574} | train loss {'Reaction outcome loss': 0.8129359585598774, 'Total loss': 0.8129359585598774}
2022-11-18 01:53:28,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:28,004 INFO:     Epoch: 37
2022-11-18 01:53:28,833 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8468198776245117, 'Total loss': 0.8468198776245117} | train loss {'Reaction outcome loss': 0.8166283340106609, 'Total loss': 0.8166283340106609}
2022-11-18 01:53:28,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:28,833 INFO:     Epoch: 38
2022-11-18 01:53:29,657 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8327520990913565, 'Total loss': 0.8327520990913565} | train loss {'Reaction outcome loss': 0.8193910006086836, 'Total loss': 0.8193910006086836}
2022-11-18 01:53:29,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:29,658 INFO:     Epoch: 39
2022-11-18 01:53:30,465 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8522592010823163, 'Total loss': 0.8522592010823163} | train loss {'Reaction outcome loss': 0.8115294266205567, 'Total loss': 0.8115294266205567}
2022-11-18 01:53:30,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:30,466 INFO:     Epoch: 40
2022-11-18 01:53:31,324 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8406825404275547, 'Total loss': 0.8406825404275547} | train loss {'Reaction outcome loss': 0.8151966721905388, 'Total loss': 0.8151966721905388}
2022-11-18 01:53:31,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:31,324 INFO:     Epoch: 41
2022-11-18 01:53:32,132 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8298631093718789, 'Total loss': 0.8298631093718789} | train loss {'Reaction outcome loss': 0.8111992975779874, 'Total loss': 0.8111992975779874}
2022-11-18 01:53:32,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:32,133 INFO:     Epoch: 42
2022-11-18 01:53:32,939 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8329582092436877, 'Total loss': 0.8329582092436877} | train loss {'Reaction outcome loss': 0.8194130815957722, 'Total loss': 0.8194130815957722}
2022-11-18 01:53:32,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:32,940 INFO:     Epoch: 43
2022-11-18 01:53:33,763 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8309555338187651, 'Total loss': 0.8309555338187651} | train loss {'Reaction outcome loss': 0.8122206821374083, 'Total loss': 0.8122206821374083}
2022-11-18 01:53:33,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:33,764 INFO:     Epoch: 44
2022-11-18 01:53:34,588 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8478891917250373, 'Total loss': 0.8478891917250373} | train loss {'Reaction outcome loss': 0.8127257366804218, 'Total loss': 0.8127257366804218}
2022-11-18 01:53:34,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:34,588 INFO:     Epoch: 45
2022-11-18 01:53:35,381 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8322554467753931, 'Total loss': 0.8322554467753931} | train loss {'Reaction outcome loss': 0.8078759568799966, 'Total loss': 0.8078759568799966}
2022-11-18 01:53:35,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:35,381 INFO:     Epoch: 46
2022-11-18 01:53:36,172 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8478704447096045, 'Total loss': 0.8478704447096045} | train loss {'Reaction outcome loss': 0.8117874211627945, 'Total loss': 0.8117874211627945}
2022-11-18 01:53:36,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:36,172 INFO:     Epoch: 47
2022-11-18 01:53:36,960 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8327261717482046, 'Total loss': 0.8327261717482046} | train loss {'Reaction outcome loss': 0.8204754633218171, 'Total loss': 0.8204754633218171}
2022-11-18 01:53:36,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:36,960 INFO:     Epoch: 48
2022-11-18 01:53:37,759 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8407009602947668, 'Total loss': 0.8407009602947668} | train loss {'Reaction outcome loss': 0.8185552622866534, 'Total loss': 0.8185552622866534}
2022-11-18 01:53:37,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:37,759 INFO:     Epoch: 49
2022-11-18 01:53:38,567 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8457069925286553, 'Total loss': 0.8457069925286553} | train loss {'Reaction outcome loss': 0.8142119533861214, 'Total loss': 0.8142119533861214}
2022-11-18 01:53:38,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:38,567 INFO:     Epoch: 50
2022-11-18 01:53:39,380 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8460887094790285, 'Total loss': 0.8460887094790285} | train loss {'Reaction outcome loss': 0.8088449147126453, 'Total loss': 0.8088449147126453}
2022-11-18 01:53:39,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:39,381 INFO:     Epoch: 51
2022-11-18 01:53:40,220 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8381331718780778, 'Total loss': 0.8381331718780778} | train loss {'Reaction outcome loss': 0.813988318689439, 'Total loss': 0.813988318689439}
2022-11-18 01:53:40,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:40,220 INFO:     Epoch: 52
2022-11-18 01:53:41,025 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8519254651936617, 'Total loss': 0.8519254651936617} | train loss {'Reaction outcome loss': 0.8198974995236648, 'Total loss': 0.8198974995236648}
2022-11-18 01:53:41,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:41,026 INFO:     Epoch: 53
2022-11-18 01:53:41,853 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8424872403795068, 'Total loss': 0.8424872403795068} | train loss {'Reaction outcome loss': 0.8168027779833991, 'Total loss': 0.8168027779833991}
2022-11-18 01:53:41,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:41,853 INFO:     Epoch: 54
2022-11-18 01:53:42,664 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8279219527136196, 'Total loss': 0.8279219527136196} | train loss {'Reaction outcome loss': 0.8126376315891018, 'Total loss': 0.8126376315891018}
2022-11-18 01:53:42,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:42,665 INFO:     Epoch: 55
2022-11-18 01:53:43,473 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8435706712982871, 'Total loss': 0.8435706712982871} | train loss {'Reaction outcome loss': 0.8089907293317289, 'Total loss': 0.8089907293317289}
2022-11-18 01:53:43,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:43,473 INFO:     Epoch: 56
2022-11-18 01:53:44,279 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.832542241296985, 'Total loss': 0.832542241296985} | train loss {'Reaction outcome loss': 0.8058930062330686, 'Total loss': 0.8058930062330686}
2022-11-18 01:53:44,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:44,280 INFO:     Epoch: 57
2022-11-18 01:53:45,072 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8200677599419247, 'Total loss': 0.8200677599419247} | train loss {'Reaction outcome loss': 0.8241970060084031, 'Total loss': 0.8241970060084031}
2022-11-18 01:53:45,072 INFO:     Found new best model at epoch 57
2022-11-18 01:53:45,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:45,073 INFO:     Epoch: 58
2022-11-18 01:53:45,855 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8348013731566343, 'Total loss': 0.8348013731566343} | train loss {'Reaction outcome loss': 0.8145627378210848, 'Total loss': 0.8145627378210848}
2022-11-18 01:53:45,855 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:45,856 INFO:     Epoch: 59
2022-11-18 01:53:46,628 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8311432125893506, 'Total loss': 0.8311432125893506} | train loss {'Reaction outcome loss': 0.817596124372019, 'Total loss': 0.817596124372019}
2022-11-18 01:53:46,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:46,628 INFO:     Epoch: 60
2022-11-18 01:53:47,382 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8297492360526865, 'Total loss': 0.8297492360526865} | train loss {'Reaction outcome loss': 0.8296089848043465, 'Total loss': 0.8296089848043465}
2022-11-18 01:53:47,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:47,382 INFO:     Epoch: 61
2022-11-18 01:53:48,178 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8302520296790383, 'Total loss': 0.8302520296790383} | train loss {'Reaction outcome loss': 0.8110024818796137, 'Total loss': 0.8110024818796137}
2022-11-18 01:53:48,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:48,178 INFO:     Epoch: 62
2022-11-18 01:53:48,952 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8285694420337677, 'Total loss': 0.8285694420337677} | train loss {'Reaction outcome loss': 0.8087299828104645, 'Total loss': 0.8087299828104645}
2022-11-18 01:53:48,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:48,952 INFO:     Epoch: 63
2022-11-18 01:53:49,720 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8388450342145833, 'Total loss': 0.8388450342145833} | train loss {'Reaction outcome loss': 0.8136716249742006, 'Total loss': 0.8136716249742006}
2022-11-18 01:53:49,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:49,720 INFO:     Epoch: 64
2022-11-18 01:53:50,502 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8927981067787517, 'Total loss': 0.8927981067787517} | train loss {'Reaction outcome loss': 0.808611310204031, 'Total loss': 0.808611310204031}
2022-11-18 01:53:50,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:50,502 INFO:     Epoch: 65
2022-11-18 01:53:51,292 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8442445092580535, 'Total loss': 0.8442445092580535} | train loss {'Reaction outcome loss': 0.8086190938889256, 'Total loss': 0.8086190938889256}
2022-11-18 01:53:51,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:51,292 INFO:     Epoch: 66
2022-11-18 01:53:52,061 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8361720375039361, 'Total loss': 0.8361720375039361} | train loss {'Reaction outcome loss': 0.8193666661075252, 'Total loss': 0.8193666661075252}
2022-11-18 01:53:52,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:52,062 INFO:     Epoch: 67
2022-11-18 01:53:52,879 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8319930515506051, 'Total loss': 0.8319930515506051} | train loss {'Reaction outcome loss': 0.8205280610424305, 'Total loss': 0.8205280610424305}
2022-11-18 01:53:52,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:52,879 INFO:     Epoch: 68
2022-11-18 01:53:53,665 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8342297185551036, 'Total loss': 0.8342297185551036} | train loss {'Reaction outcome loss': 0.8136904832081273, 'Total loss': 0.8136904832081273}
2022-11-18 01:53:53,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:53,665 INFO:     Epoch: 69
2022-11-18 01:53:54,437 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8476417200131849, 'Total loss': 0.8476417200131849} | train loss {'Reaction outcome loss': 0.8050437821188436, 'Total loss': 0.8050437821188436}
2022-11-18 01:53:54,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:54,439 INFO:     Epoch: 70
2022-11-18 01:53:55,239 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8303451538085938, 'Total loss': 0.8303451538085938} | train loss {'Reaction outcome loss': 0.8101494009436866, 'Total loss': 0.8101494009436866}
2022-11-18 01:53:55,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:55,239 INFO:     Epoch: 71
2022-11-18 01:53:56,102 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8274408633058722, 'Total loss': 0.8274408633058722} | train loss {'Reaction outcome loss': 0.8044592571644648, 'Total loss': 0.8044592571644648}
2022-11-18 01:53:56,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:56,102 INFO:     Epoch: 72
2022-11-18 01:53:56,888 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8375724540515379, 'Total loss': 0.8375724540515379} | train loss {'Reaction outcome loss': 0.8077004473460349, 'Total loss': 0.8077004473460349}
2022-11-18 01:53:56,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:56,888 INFO:     Epoch: 73
2022-11-18 01:53:57,663 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8274947587739337, 'Total loss': 0.8274947587739337} | train loss {'Reaction outcome loss': 0.8127525454831992, 'Total loss': 0.8127525454831992}
2022-11-18 01:53:57,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:57,664 INFO:     Epoch: 74
2022-11-18 01:53:58,516 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8335802311247046, 'Total loss': 0.8335802311247046} | train loss {'Reaction outcome loss': 0.8136110922344301, 'Total loss': 0.8136110922344301}
2022-11-18 01:53:58,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:58,517 INFO:     Epoch: 75
2022-11-18 01:53:59,304 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8468710482120514, 'Total loss': 0.8468710482120514} | train loss {'Reaction outcome loss': 0.8087120822325409, 'Total loss': 0.8087120822325409}
2022-11-18 01:53:59,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:53:59,305 INFO:     Epoch: 76
2022-11-18 01:54:00,144 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8183269974860278, 'Total loss': 0.8183269974860278} | train loss {'Reaction outcome loss': 0.815181880344746, 'Total loss': 0.815181880344746}
2022-11-18 01:54:00,144 INFO:     Found new best model at epoch 76
2022-11-18 01:54:00,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:00,145 INFO:     Epoch: 77
2022-11-18 01:54:00,965 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8226226825605739, 'Total loss': 0.8226226825605739} | train loss {'Reaction outcome loss': 0.8151834002933521, 'Total loss': 0.8151834002933521}
2022-11-18 01:54:00,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:00,967 INFO:     Epoch: 78
2022-11-18 01:54:01,785 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8294702165506103, 'Total loss': 0.8294702165506103} | train loss {'Reaction outcome loss': 0.8153595854396279, 'Total loss': 0.8153595854396279}
2022-11-18 01:54:01,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:01,785 INFO:     Epoch: 79
2022-11-18 01:54:02,639 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8535667861049826, 'Total loss': 0.8535667861049826} | train loss {'Reaction outcome loss': 0.8083970278863483, 'Total loss': 0.8083970278863483}
2022-11-18 01:54:02,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:02,639 INFO:     Epoch: 80
2022-11-18 01:54:03,478 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8395543159409002, 'Total loss': 0.8395543159409002} | train loss {'Reaction outcome loss': 0.8140276448446729, 'Total loss': 0.8140276448446729}
2022-11-18 01:54:03,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:03,479 INFO:     Epoch: 81
2022-11-18 01:54:04,262 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8332969790155237, 'Total loss': 0.8332969790155237} | train loss {'Reaction outcome loss': 0.8212759008533076, 'Total loss': 0.8212759008533076}
2022-11-18 01:54:04,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:04,262 INFO:     Epoch: 82
2022-11-18 01:54:05,114 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8330796340649779, 'Total loss': 0.8330796340649779} | train loss {'Reaction outcome loss': 0.8228433003068453, 'Total loss': 0.8228433003068453}
2022-11-18 01:54:05,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:05,114 INFO:     Epoch: 83
2022-11-18 01:54:05,925 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8273651803081686, 'Total loss': 0.8273651803081686} | train loss {'Reaction outcome loss': 0.8115570373561701, 'Total loss': 0.8115570373561701}
2022-11-18 01:54:05,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:05,925 INFO:     Epoch: 84
2022-11-18 01:54:06,723 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8380575003949079, 'Total loss': 0.8380575003949079} | train loss {'Reaction outcome loss': 0.8094692461886387, 'Total loss': 0.8094692461886387}
2022-11-18 01:54:06,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:06,723 INFO:     Epoch: 85
2022-11-18 01:54:07,518 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8352819816632704, 'Total loss': 0.8352819816632704} | train loss {'Reaction outcome loss': 0.8136332629904574, 'Total loss': 0.8136332629904574}
2022-11-18 01:54:07,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:07,518 INFO:     Epoch: 86
2022-11-18 01:54:08,270 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8355361182581295, 'Total loss': 0.8355361182581295} | train loss {'Reaction outcome loss': 0.8152723044519, 'Total loss': 0.8152723044519}
2022-11-18 01:54:08,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:08,270 INFO:     Epoch: 87
2022-11-18 01:54:09,070 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8175305954434655, 'Total loss': 0.8175305954434655} | train loss {'Reaction outcome loss': 0.8064518423396566, 'Total loss': 0.8064518423396566}
2022-11-18 01:54:09,070 INFO:     Found new best model at epoch 87
2022-11-18 01:54:09,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:09,071 INFO:     Epoch: 88
2022-11-18 01:54:09,874 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8334129398519342, 'Total loss': 0.8334129398519342} | train loss {'Reaction outcome loss': 0.8144824451763137, 'Total loss': 0.8144824451763137}
2022-11-18 01:54:09,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:09,874 INFO:     Epoch: 89
2022-11-18 01:54:10,665 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8593780208717693, 'Total loss': 0.8593780208717693} | train loss {'Reaction outcome loss': 0.8135376867012456, 'Total loss': 0.8135376867012456}
2022-11-18 01:54:10,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:10,665 INFO:     Epoch: 90
2022-11-18 01:54:11,424 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8439374064857309, 'Total loss': 0.8439374064857309} | train loss {'Reaction outcome loss': 0.8124501006262987, 'Total loss': 0.8124501006262987}
2022-11-18 01:54:11,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:11,424 INFO:     Epoch: 91
2022-11-18 01:54:12,212 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8208524103869091, 'Total loss': 0.8208524103869091} | train loss {'Reaction outcome loss': 0.8147677685085096, 'Total loss': 0.8147677685085096}
2022-11-18 01:54:12,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:12,212 INFO:     Epoch: 92
2022-11-18 01:54:12,992 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8642971346324141, 'Total loss': 0.8642971346324141} | train loss {'Reaction outcome loss': 0.8188130255894139, 'Total loss': 0.8188130255894139}
2022-11-18 01:54:12,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:12,993 INFO:     Epoch: 93
2022-11-18 01:54:13,783 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8332209858027372, 'Total loss': 0.8332209858027372} | train loss {'Reaction outcome loss': 0.816148253587576, 'Total loss': 0.816148253587576}
2022-11-18 01:54:13,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:13,783 INFO:     Epoch: 94
2022-11-18 01:54:14,564 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8395121280442585, 'Total loss': 0.8395121280442585} | train loss {'Reaction outcome loss': 0.811441461325657, 'Total loss': 0.811441461325657}
2022-11-18 01:54:14,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:14,564 INFO:     Epoch: 95
2022-11-18 01:54:15,344 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8500338156114925, 'Total loss': 0.8500338156114925} | train loss {'Reaction outcome loss': 0.8076221506122635, 'Total loss': 0.8076221506122635}
2022-11-18 01:54:15,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:15,344 INFO:     Epoch: 96
2022-11-18 01:54:16,123 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8907214755361731, 'Total loss': 0.8907214755361731} | train loss {'Reaction outcome loss': 0.811955260965023, 'Total loss': 0.811955260965023}
2022-11-18 01:54:16,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:16,123 INFO:     Epoch: 97
2022-11-18 01:54:16,888 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8318071175705303, 'Total loss': 0.8318071175705303} | train loss {'Reaction outcome loss': 0.8075883948670225, 'Total loss': 0.8075883948670225}
2022-11-18 01:54:16,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:16,888 INFO:     Epoch: 98
2022-11-18 01:54:17,671 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8337281400507147, 'Total loss': 0.8337281400507147} | train loss {'Reaction outcome loss': 0.8090024174224992, 'Total loss': 0.8090024174224992}
2022-11-18 01:54:17,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:17,671 INFO:     Epoch: 99
2022-11-18 01:54:18,456 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8254086876457388, 'Total loss': 0.8254086876457388} | train loss {'Reaction outcome loss': 0.8102830101845235, 'Total loss': 0.8102830101845235}
2022-11-18 01:54:18,456 INFO:     Best model found after epoch 88 of 100.
2022-11-18 01:54:18,456 INFO:   Done with stage: TRAINING
2022-11-18 01:54:18,456 INFO:   Starting stage: EVALUATION
2022-11-18 01:54:18,586 INFO:   Done with stage: EVALUATION
2022-11-18 01:54:18,586 INFO:   Leaving out SEQ value Fold_5
2022-11-18 01:54:18,601 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 01:54:18,601 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:54:19,273 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:54:19,274 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:54:19,343 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:54:19,343 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:54:19,343 INFO:     No hyperparam tuning for this model
2022-11-18 01:54:19,343 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:54:19,343 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:54:19,344 INFO:     None feature selector for col prot
2022-11-18 01:54:19,344 INFO:     None feature selector for col prot
2022-11-18 01:54:19,344 INFO:     None feature selector for col prot
2022-11-18 01:54:19,345 INFO:     None feature selector for col chem
2022-11-18 01:54:19,345 INFO:     None feature selector for col chem
2022-11-18 01:54:19,345 INFO:     None feature selector for col chem
2022-11-18 01:54:19,345 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:54:19,345 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:54:19,346 INFO:     Number of params in model 168571
2022-11-18 01:54:19,350 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:54:19,350 INFO:   Starting stage: TRAINING
2022-11-18 01:54:19,407 INFO:     Val loss before train {'Reaction outcome loss': 0.9765493815595453, 'Total loss': 0.9765493815595453}
2022-11-18 01:54:19,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:19,407 INFO:     Epoch: 0
2022-11-18 01:54:20,173 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8410177996212785, 'Total loss': 0.8410177996212785} | train loss {'Reaction outcome loss': 0.8947472543485703, 'Total loss': 0.8947472543485703}
2022-11-18 01:54:20,174 INFO:     Found new best model at epoch 0
2022-11-18 01:54:20,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:20,174 INFO:     Epoch: 1
2022-11-18 01:54:20,972 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8092034858736125, 'Total loss': 0.8092034858736125} | train loss {'Reaction outcome loss': 0.8545764843302388, 'Total loss': 0.8545764843302388}
2022-11-18 01:54:20,973 INFO:     Found new best model at epoch 1
2022-11-18 01:54:20,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:20,974 INFO:     Epoch: 2
2022-11-18 01:54:21,761 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8044368543408134, 'Total loss': 0.8044368543408134} | train loss {'Reaction outcome loss': 0.8518841183714329, 'Total loss': 0.8518841183714329}
2022-11-18 01:54:21,761 INFO:     Found new best model at epoch 2
2022-11-18 01:54:21,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:21,762 INFO:     Epoch: 3
2022-11-18 01:54:22,556 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8190366171977737, 'Total loss': 0.8190366171977737} | train loss {'Reaction outcome loss': 0.8482807618716071, 'Total loss': 0.8482807618716071}
2022-11-18 01:54:22,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:22,556 INFO:     Epoch: 4
2022-11-18 01:54:23,352 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.810397439382293, 'Total loss': 0.810397439382293} | train loss {'Reaction outcome loss': 0.8353673883022801, 'Total loss': 0.8353673883022801}
2022-11-18 01:54:23,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:23,352 INFO:     Epoch: 5
2022-11-18 01:54:24,117 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7920697690411047, 'Total loss': 0.7920697690411047} | train loss {'Reaction outcome loss': 0.8307434565597965, 'Total loss': 0.8307434565597965}
2022-11-18 01:54:24,117 INFO:     Found new best model at epoch 5
2022-11-18 01:54:24,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:24,118 INFO:     Epoch: 6
2022-11-18 01:54:24,927 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8103936612606049, 'Total loss': 0.8103936612606049} | train loss {'Reaction outcome loss': 0.8255130480374059, 'Total loss': 0.8255130480374059}
2022-11-18 01:54:24,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:24,928 INFO:     Epoch: 7
2022-11-18 01:54:25,703 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7895327549089085, 'Total loss': 0.7895327549089085} | train loss {'Reaction outcome loss': 0.8280213155573414, 'Total loss': 0.8280213155573414}
2022-11-18 01:54:25,703 INFO:     Found new best model at epoch 7
2022-11-18 01:54:25,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:25,704 INFO:     Epoch: 8
2022-11-18 01:54:26,489 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7780134251171892, 'Total loss': 0.7780134251171892} | train loss {'Reaction outcome loss': 0.8241876817999347, 'Total loss': 0.8241876817999347}
2022-11-18 01:54:26,490 INFO:     Found new best model at epoch 8
2022-11-18 01:54:26,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:26,491 INFO:     Epoch: 9
2022-11-18 01:54:27,291 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8091330176050012, 'Total loss': 0.8091330176050012} | train loss {'Reaction outcome loss': 0.8282014571370617, 'Total loss': 0.8282014571370617}
2022-11-18 01:54:27,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:27,292 INFO:     Epoch: 10
2022-11-18 01:54:28,097 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7907666895877231, 'Total loss': 0.7907666895877231} | train loss {'Reaction outcome loss': 0.8253871136375012, 'Total loss': 0.8253871136375012}
2022-11-18 01:54:28,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:28,097 INFO:     Epoch: 11
2022-11-18 01:54:28,888 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7807016460732981, 'Total loss': 0.7807016460732981} | train loss {'Reaction outcome loss': 0.8263843661594775, 'Total loss': 0.8263843661594775}
2022-11-18 01:54:28,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:28,888 INFO:     Epoch: 12
2022-11-18 01:54:29,753 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7936996255408634, 'Total loss': 0.7936996255408634} | train loss {'Reaction outcome loss': 0.8263820445825977, 'Total loss': 0.8263820445825977}
2022-11-18 01:54:29,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:29,753 INFO:     Epoch: 13
2022-11-18 01:54:30,610 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7841988172043454, 'Total loss': 0.7841988172043454} | train loss {'Reaction outcome loss': 0.8233359748077008, 'Total loss': 0.8233359748077008}
2022-11-18 01:54:30,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:30,611 INFO:     Epoch: 14
2022-11-18 01:54:31,447 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7946016571738503, 'Total loss': 0.7946016571738503} | train loss {'Reaction outcome loss': 0.8211841328490165, 'Total loss': 0.8211841328490165}
2022-11-18 01:54:31,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:31,447 INFO:     Epoch: 15
2022-11-18 01:54:32,266 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8061007532206449, 'Total loss': 0.8061007532206449} | train loss {'Reaction outcome loss': 0.8265845967877296, 'Total loss': 0.8265845967877296}
2022-11-18 01:54:32,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:32,266 INFO:     Epoch: 16
2022-11-18 01:54:33,072 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7733215127478946, 'Total loss': 0.7733215127478946} | train loss {'Reaction outcome loss': 0.826168894166908, 'Total loss': 0.826168894166908}
2022-11-18 01:54:33,073 INFO:     Found new best model at epoch 16
2022-11-18 01:54:33,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:33,074 INFO:     Epoch: 17
2022-11-18 01:54:33,851 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.770385550504381, 'Total loss': 0.770385550504381} | train loss {'Reaction outcome loss': 0.8224664872452137, 'Total loss': 0.8224664872452137}
2022-11-18 01:54:33,851 INFO:     Found new best model at epoch 17
2022-11-18 01:54:33,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:33,852 INFO:     Epoch: 18
2022-11-18 01:54:34,668 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7757222381505099, 'Total loss': 0.7757222381505099} | train loss {'Reaction outcome loss': 0.820081293342575, 'Total loss': 0.820081293342575}
2022-11-18 01:54:34,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:34,668 INFO:     Epoch: 19
2022-11-18 01:54:35,476 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7842918898571621, 'Total loss': 0.7842918898571621} | train loss {'Reaction outcome loss': 0.819058553946595, 'Total loss': 0.819058553946595}
2022-11-18 01:54:35,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:35,476 INFO:     Epoch: 20
2022-11-18 01:54:36,280 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7750221876935526, 'Total loss': 0.7750221876935526} | train loss {'Reaction outcome loss': 0.8224745533399044, 'Total loss': 0.8224745533399044}
2022-11-18 01:54:36,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:36,281 INFO:     Epoch: 21
2022-11-18 01:54:37,098 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7814108343286947, 'Total loss': 0.7814108343286947} | train loss {'Reaction outcome loss': 0.8169173466101769, 'Total loss': 0.8169173466101769}
2022-11-18 01:54:37,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:37,098 INFO:     Epoch: 22
2022-11-18 01:54:37,903 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7832576232877645, 'Total loss': 0.7832576232877645} | train loss {'Reaction outcome loss': 0.8215568533107158, 'Total loss': 0.8215568533107158}
2022-11-18 01:54:37,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:37,904 INFO:     Epoch: 23
2022-11-18 01:54:38,740 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7766608040441166, 'Total loss': 0.7766608040441166} | train loss {'Reaction outcome loss': 0.8198977839802543, 'Total loss': 0.8198977839802543}
2022-11-18 01:54:38,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:38,740 INFO:     Epoch: 24
2022-11-18 01:54:39,543 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8011332892558791, 'Total loss': 0.8011332892558791} | train loss {'Reaction outcome loss': 0.817454790396075, 'Total loss': 0.817454790396075}
2022-11-18 01:54:39,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:39,543 INFO:     Epoch: 25
2022-11-18 01:54:40,362 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8024178912693803, 'Total loss': 0.8024178912693803} | train loss {'Reaction outcome loss': 0.8296045286040152, 'Total loss': 0.8296045286040152}
2022-11-18 01:54:40,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:40,362 INFO:     Epoch: 26
2022-11-18 01:54:41,177 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7858190556818788, 'Total loss': 0.7858190556818788} | train loss {'Reaction outcome loss': 0.8195722670324387, 'Total loss': 0.8195722670324387}
2022-11-18 01:54:41,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:41,178 INFO:     Epoch: 27
2022-11-18 01:54:41,965 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7769623493606393, 'Total loss': 0.7769623493606393} | train loss {'Reaction outcome loss': 0.815570896070811, 'Total loss': 0.815570896070811}
2022-11-18 01:54:41,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:41,966 INFO:     Epoch: 28
2022-11-18 01:54:42,769 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7689225815913894, 'Total loss': 0.7689225815913894} | train loss {'Reaction outcome loss': 0.8226195931915314, 'Total loss': 0.8226195931915314}
2022-11-18 01:54:42,770 INFO:     Found new best model at epoch 28
2022-11-18 01:54:42,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:42,771 INFO:     Epoch: 29
2022-11-18 01:54:43,609 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7791257798671722, 'Total loss': 0.7791257798671722} | train loss {'Reaction outcome loss': 0.8207738059422662, 'Total loss': 0.8207738059422662}
2022-11-18 01:54:43,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:43,609 INFO:     Epoch: 30
2022-11-18 01:54:44,485 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7693023044954647, 'Total loss': 0.7693023044954647} | train loss {'Reaction outcome loss': 0.8233583964888127, 'Total loss': 0.8233583964888127}
2022-11-18 01:54:44,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:44,485 INFO:     Epoch: 31
2022-11-18 01:54:45,307 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.79313470965082, 'Total loss': 0.79313470965082} | train loss {'Reaction outcome loss': 0.8235343134691638, 'Total loss': 0.8235343134691638}
2022-11-18 01:54:45,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:45,308 INFO:     Epoch: 32
2022-11-18 01:54:46,117 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7802483161742036, 'Total loss': 0.7802483161742036} | train loss {'Reaction outcome loss': 0.8248913213610649, 'Total loss': 0.8248913213610649}
2022-11-18 01:54:46,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:46,118 INFO:     Epoch: 33
2022-11-18 01:54:46,913 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7993608354167505, 'Total loss': 0.7993608354167505} | train loss {'Reaction outcome loss': 0.8157300310990503, 'Total loss': 0.8157300310990503}
2022-11-18 01:54:46,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:46,914 INFO:     Epoch: 34
2022-11-18 01:54:47,679 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.777983198789033, 'Total loss': 0.777983198789033} | train loss {'Reaction outcome loss': 0.8178812967192742, 'Total loss': 0.8178812967192742}
2022-11-18 01:54:47,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:47,679 INFO:     Epoch: 35
2022-11-18 01:54:48,522 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.784049812365662, 'Total loss': 0.784049812365662} | train loss {'Reaction outcome loss': 0.8213305127236151, 'Total loss': 0.8213305127236151}
2022-11-18 01:54:48,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:48,522 INFO:     Epoch: 36
2022-11-18 01:54:49,322 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7849150286479429, 'Total loss': 0.7849150286479429} | train loss {'Reaction outcome loss': 0.8183922119919331, 'Total loss': 0.8183922119919331}
2022-11-18 01:54:49,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:49,322 INFO:     Epoch: 37
2022-11-18 01:54:50,185 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7726133689284325, 'Total loss': 0.7726133689284325} | train loss {'Reaction outcome loss': 0.82194244717398, 'Total loss': 0.82194244717398}
2022-11-18 01:54:50,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:50,185 INFO:     Epoch: 38
2022-11-18 01:54:50,973 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.790202603421428, 'Total loss': 0.790202603421428} | train loss {'Reaction outcome loss': 0.8162789899976023, 'Total loss': 0.8162789899976023}
2022-11-18 01:54:50,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:50,974 INFO:     Epoch: 39
2022-11-18 01:54:51,793 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7690883339806036, 'Total loss': 0.7690883339806036} | train loss {'Reaction outcome loss': 0.8168945640565888, 'Total loss': 0.8168945640565888}
2022-11-18 01:54:51,793 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:51,793 INFO:     Epoch: 40
2022-11-18 01:54:52,612 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7809169793670828, 'Total loss': 0.7809169793670828} | train loss {'Reaction outcome loss': 0.8141973471689609, 'Total loss': 0.8141973471689609}
2022-11-18 01:54:52,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:52,613 INFO:     Epoch: 41
2022-11-18 01:54:53,448 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8041811991821636, 'Total loss': 0.8041811991821636} | train loss {'Reaction outcome loss': 0.816174964991308, 'Total loss': 0.816174964991308}
2022-11-18 01:54:53,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:53,448 INFO:     Epoch: 42
2022-11-18 01:54:54,234 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7881373864683238, 'Total loss': 0.7881373864683238} | train loss {'Reaction outcome loss': 0.8176180069004336, 'Total loss': 0.8176180069004336}
2022-11-18 01:54:54,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:54,234 INFO:     Epoch: 43
2022-11-18 01:54:54,998 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7924173494631593, 'Total loss': 0.7924173494631593} | train loss {'Reaction outcome loss': 0.8199085796311978, 'Total loss': 0.8199085796311978}
2022-11-18 01:54:54,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:54,999 INFO:     Epoch: 44
2022-11-18 01:54:55,814 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7888509116389535, 'Total loss': 0.7888509116389535} | train loss {'Reaction outcome loss': 0.8183064117066322, 'Total loss': 0.8183064117066322}
2022-11-18 01:54:55,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:55,815 INFO:     Epoch: 45
2022-11-18 01:54:56,638 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7811451120810076, 'Total loss': 0.7811451120810076} | train loss {'Reaction outcome loss': 0.8160037099113387, 'Total loss': 0.8160037099113387}
2022-11-18 01:54:56,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:56,638 INFO:     Epoch: 46
2022-11-18 01:54:57,456 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7757548087022521, 'Total loss': 0.7757548087022521} | train loss {'Reaction outcome loss': 0.8156698806391608, 'Total loss': 0.8156698806391608}
2022-11-18 01:54:57,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:57,457 INFO:     Epoch: 47
2022-11-18 01:54:58,241 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7927733930674467, 'Total loss': 0.7927733930674467} | train loss {'Reaction outcome loss': 0.8200460179678856, 'Total loss': 0.8200460179678856}
2022-11-18 01:54:58,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:58,242 INFO:     Epoch: 48
2022-11-18 01:54:59,037 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7801807380535386, 'Total loss': 0.7801807380535386} | train loss {'Reaction outcome loss': 0.8203363649306759, 'Total loss': 0.8203363649306759}
2022-11-18 01:54:59,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:59,037 INFO:     Epoch: 49
2022-11-18 01:54:59,865 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8209271803498268, 'Total loss': 0.8209271803498268} | train loss {'Reaction outcome loss': 0.8166953935738532, 'Total loss': 0.8166953935738532}
2022-11-18 01:54:59,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:54:59,866 INFO:     Epoch: 50
2022-11-18 01:55:00,689 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7952898903326555, 'Total loss': 0.7952898903326555} | train loss {'Reaction outcome loss': 0.823567230134241, 'Total loss': 0.823567230134241}
2022-11-18 01:55:00,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:00,689 INFO:     Epoch: 51
2022-11-18 01:55:01,477 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8102432597767223, 'Total loss': 0.8102432597767223} | train loss {'Reaction outcome loss': 0.8153853233783476, 'Total loss': 0.8153853233783476}
2022-11-18 01:55:01,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:01,478 INFO:     Epoch: 52
2022-11-18 01:55:02,280 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.775983685796911, 'Total loss': 0.775983685796911} | train loss {'Reaction outcome loss': 0.8186989892874995, 'Total loss': 0.8186989892874995}
2022-11-18 01:55:02,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:02,280 INFO:     Epoch: 53
2022-11-18 01:55:03,138 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7874673096971079, 'Total loss': 0.7874673096971079} | train loss {'Reaction outcome loss': 0.8173602559874135, 'Total loss': 0.8173602559874135}
2022-11-18 01:55:03,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:03,138 INFO:     Epoch: 54
2022-11-18 01:55:03,949 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7768852284008806, 'Total loss': 0.7768852284008806} | train loss {'Reaction outcome loss': 0.817734724571628, 'Total loss': 0.817734724571628}
2022-11-18 01:55:03,950 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:03,950 INFO:     Epoch: 55
2022-11-18 01:55:04,756 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7882596037604592, 'Total loss': 0.7882596037604592} | train loss {'Reaction outcome loss': 0.8185357265174389, 'Total loss': 0.8185357265174389}
2022-11-18 01:55:04,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:04,756 INFO:     Epoch: 56
2022-11-18 01:55:05,565 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7691077231006189, 'Total loss': 0.7691077231006189} | train loss {'Reaction outcome loss': 0.8174923259404397, 'Total loss': 0.8174923259404397}
2022-11-18 01:55:05,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:05,565 INFO:     Epoch: 57
2022-11-18 01:55:06,368 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7809044739062135, 'Total loss': 0.7809044739062135} | train loss {'Reaction outcome loss': 0.8154643459185478, 'Total loss': 0.8154643459185478}
2022-11-18 01:55:06,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:06,369 INFO:     Epoch: 58
2022-11-18 01:55:07,163 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8049653219905767, 'Total loss': 0.8049653219905767} | train loss {'Reaction outcome loss': 0.8160148063494314, 'Total loss': 0.8160148063494314}
2022-11-18 01:55:07,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:07,163 INFO:     Epoch: 59
2022-11-18 01:55:07,993 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7839480394666846, 'Total loss': 0.7839480394666846} | train loss {'Reaction outcome loss': 0.8144854570348417, 'Total loss': 0.8144854570348417}
2022-11-18 01:55:07,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:07,994 INFO:     Epoch: 60
2022-11-18 01:55:08,786 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7815581133419817, 'Total loss': 0.7815581133419817} | train loss {'Reaction outcome loss': 0.8110315285382732, 'Total loss': 0.8110315285382732}
2022-11-18 01:55:08,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:08,787 INFO:     Epoch: 61
2022-11-18 01:55:09,629 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7755897627635435, 'Total loss': 0.7755897627635435} | train loss {'Reaction outcome loss': 0.8135435727815474, 'Total loss': 0.8135435727815474}
2022-11-18 01:55:09,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:09,629 INFO:     Epoch: 62
2022-11-18 01:55:10,470 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7786279171705246, 'Total loss': 0.7786279171705246} | train loss {'Reaction outcome loss': 0.8171852714712581, 'Total loss': 0.8171852714712581}
2022-11-18 01:55:10,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:10,470 INFO:     Epoch: 63
2022-11-18 01:55:11,258 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7871506810188293, 'Total loss': 0.7871506810188293} | train loss {'Reaction outcome loss': 0.8144925674123149, 'Total loss': 0.8144925674123149}
2022-11-18 01:55:11,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:11,259 INFO:     Epoch: 64
2022-11-18 01:55:12,055 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7860964502800595, 'Total loss': 0.7860964502800595} | train loss {'Reaction outcome loss': 0.8126255385577679, 'Total loss': 0.8126255385577679}
2022-11-18 01:55:12,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:12,055 INFO:     Epoch: 65
2022-11-18 01:55:12,850 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7760945037007332, 'Total loss': 0.7760945037007332} | train loss {'Reaction outcome loss': 0.8118477129647809, 'Total loss': 0.8118477129647809}
2022-11-18 01:55:12,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:12,851 INFO:     Epoch: 66
2022-11-18 01:55:13,666 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7700437679886818, 'Total loss': 0.7700437679886818} | train loss {'Reaction outcome loss': 0.8199857712513016, 'Total loss': 0.8199857712513016}
2022-11-18 01:55:13,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:13,666 INFO:     Epoch: 67
2022-11-18 01:55:14,494 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7848577661947771, 'Total loss': 0.7848577661947771} | train loss {'Reaction outcome loss': 0.8207949377115695, 'Total loss': 0.8207949377115695}
2022-11-18 01:55:14,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:14,494 INFO:     Epoch: 68
2022-11-18 01:55:15,282 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.777691092680801, 'Total loss': 0.777691092680801} | train loss {'Reaction outcome loss': 0.8198729496929915, 'Total loss': 0.8198729496929915}
2022-11-18 01:55:15,283 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:15,283 INFO:     Epoch: 69
2022-11-18 01:55:16,091 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8024477565830405, 'Total loss': 0.8024477565830405} | train loss {'Reaction outcome loss': 0.8168865234380768, 'Total loss': 0.8168865234380768}
2022-11-18 01:55:16,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:16,092 INFO:     Epoch: 70
2022-11-18 01:55:16,940 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7772773998704824, 'Total loss': 0.7772773998704824} | train loss {'Reaction outcome loss': 0.8132443379971289, 'Total loss': 0.8132443379971289}
2022-11-18 01:55:16,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:16,940 INFO:     Epoch: 71
2022-11-18 01:55:17,710 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7678114209662784, 'Total loss': 0.7678114209662784} | train loss {'Reaction outcome loss': 0.8124542772289245, 'Total loss': 0.8124542772289245}
2022-11-18 01:55:17,711 INFO:     Found new best model at epoch 71
2022-11-18 01:55:17,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:17,711 INFO:     Epoch: 72
2022-11-18 01:55:18,510 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7820273339748383, 'Total loss': 0.7820273339748383} | train loss {'Reaction outcome loss': 0.8182469173785178, 'Total loss': 0.8182469173785178}
2022-11-18 01:55:18,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:18,510 INFO:     Epoch: 73
2022-11-18 01:55:19,325 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.784956501966173, 'Total loss': 0.784956501966173} | train loss {'Reaction outcome loss': 0.8107944510636791, 'Total loss': 0.8107944510636791}
2022-11-18 01:55:19,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:19,325 INFO:     Epoch: 74
2022-11-18 01:55:20,123 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7890390753746033, 'Total loss': 0.7890390753746033} | train loss {'Reaction outcome loss': 0.8135346747454135, 'Total loss': 0.8135346747454135}
2022-11-18 01:55:20,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:20,123 INFO:     Epoch: 75
2022-11-18 01:55:20,927 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7777335846965964, 'Total loss': 0.7777335846965964} | train loss {'Reaction outcome loss': 0.8123401771149328, 'Total loss': 0.8123401771149328}
2022-11-18 01:55:20,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:20,927 INFO:     Epoch: 76
2022-11-18 01:55:21,718 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7907131273638118, 'Total loss': 0.7907131273638118} | train loss {'Reaction outcome loss': 0.8115133146845526, 'Total loss': 0.8115133146845526}
2022-11-18 01:55:21,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:21,718 INFO:     Epoch: 77
2022-11-18 01:55:22,553 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8055746555328369, 'Total loss': 0.8055746555328369} | train loss {'Reaction outcome loss': 0.8153847145938105, 'Total loss': 0.8153847145938105}
2022-11-18 01:55:22,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:22,554 INFO:     Epoch: 78
2022-11-18 01:55:23,359 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7678067535161972, 'Total loss': 0.7678067535161972} | train loss {'Reaction outcome loss': 0.8185401682651812, 'Total loss': 0.8185401682651812}
2022-11-18 01:55:23,359 INFO:     Found new best model at epoch 78
2022-11-18 01:55:23,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:23,360 INFO:     Epoch: 79
2022-11-18 01:55:24,153 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7774329713799737, 'Total loss': 0.7774329713799737} | train loss {'Reaction outcome loss': 0.8161371456038568, 'Total loss': 0.8161371456038568}
2022-11-18 01:55:24,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:24,153 INFO:     Epoch: 80
2022-11-18 01:55:24,970 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7826158356937495, 'Total loss': 0.7826158356937495} | train loss {'Reaction outcome loss': 0.8139614795725192, 'Total loss': 0.8139614795725192}
2022-11-18 01:55:24,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:24,971 INFO:     Epoch: 81
2022-11-18 01:55:25,746 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7825256863778288, 'Total loss': 0.7825256863778288} | train loss {'Reaction outcome loss': 0.8119372693040678, 'Total loss': 0.8119372693040678}
2022-11-18 01:55:25,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:25,746 INFO:     Epoch: 82
2022-11-18 01:55:26,610 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7810571918433363, 'Total loss': 0.7810571918433363} | train loss {'Reaction outcome loss': 0.807075421896673, 'Total loss': 0.807075421896673}
2022-11-18 01:55:26,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:26,610 INFO:     Epoch: 83
2022-11-18 01:55:27,459 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8055812919681723, 'Total loss': 0.8055812919681723} | train loss {'Reaction outcome loss': 0.8152209682570349, 'Total loss': 0.8152209682570349}
2022-11-18 01:55:27,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:27,459 INFO:     Epoch: 84
2022-11-18 01:55:28,293 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7809219577095725, 'Total loss': 0.7809219577095725} | train loss {'Reaction outcome loss': 0.8117428538539717, 'Total loss': 0.8117428538539717}
2022-11-18 01:55:28,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:28,294 INFO:     Epoch: 85
2022-11-18 01:55:29,103 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.796886985952204, 'Total loss': 0.796886985952204} | train loss {'Reaction outcome loss': 0.8077897120627665, 'Total loss': 0.8077897120627665}
2022-11-18 01:55:29,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:29,103 INFO:     Epoch: 86
2022-11-18 01:55:29,892 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7790073914961382, 'Total loss': 0.7790073914961382} | train loss {'Reaction outcome loss': 0.8151241764426231, 'Total loss': 0.8151241764426231}
2022-11-18 01:55:29,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:29,893 INFO:     Epoch: 87
2022-11-18 01:55:30,733 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7872438776222143, 'Total loss': 0.7872438776222143} | train loss {'Reaction outcome loss': 0.8154821019739874, 'Total loss': 0.8154821019739874}
2022-11-18 01:55:30,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:30,733 INFO:     Epoch: 88
2022-11-18 01:55:31,516 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7673258510502902, 'Total loss': 0.7673258510502902} | train loss {'Reaction outcome loss': 0.8109654881540806, 'Total loss': 0.8109654881540806}
2022-11-18 01:55:31,516 INFO:     Found new best model at epoch 88
2022-11-18 01:55:31,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:31,517 INFO:     Epoch: 89
2022-11-18 01:55:32,343 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7679200971668417, 'Total loss': 0.7679200971668417} | train loss {'Reaction outcome loss': 0.8149951943947423, 'Total loss': 0.8149951943947423}
2022-11-18 01:55:32,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:32,343 INFO:     Epoch: 90
2022-11-18 01:55:33,142 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7748796756971966, 'Total loss': 0.7748796756971966} | train loss {'Reaction outcome loss': 0.8102434570750883, 'Total loss': 0.8102434570750883}
2022-11-18 01:55:33,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:33,142 INFO:     Epoch: 91
2022-11-18 01:55:33,970 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8028165183284066, 'Total loss': 0.8028165183284066} | train loss {'Reaction outcome loss': 0.8176773822595996, 'Total loss': 0.8176773822595996}
2022-11-18 01:55:33,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:33,970 INFO:     Epoch: 92
2022-11-18 01:55:34,796 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.771327636458657, 'Total loss': 0.771327636458657} | train loss {'Reaction outcome loss': 0.8107888594029411, 'Total loss': 0.8107888594029411}
2022-11-18 01:55:34,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:34,797 INFO:     Epoch: 93
2022-11-18 01:55:35,607 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.771932531486858, 'Total loss': 0.771932531486858} | train loss {'Reaction outcome loss': 0.8149874890523572, 'Total loss': 0.8149874890523572}
2022-11-18 01:55:35,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:35,608 INFO:     Epoch: 94
2022-11-18 01:55:36,456 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7728489115834236, 'Total loss': 0.7728489115834236} | train loss {'Reaction outcome loss': 0.8142142134808725, 'Total loss': 0.8142142134808725}
2022-11-18 01:55:36,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:36,457 INFO:     Epoch: 95
2022-11-18 01:55:37,295 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.775002346797423, 'Total loss': 0.775002346797423} | train loss {'Reaction outcome loss': 0.8082196728116081, 'Total loss': 0.8082196728116081}
2022-11-18 01:55:37,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:37,296 INFO:     Epoch: 96
2022-11-18 01:55:38,068 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7708946832201697, 'Total loss': 0.7708946832201697} | train loss {'Reaction outcome loss': 0.8127719336940397, 'Total loss': 0.8127719336940397}
2022-11-18 01:55:38,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:38,068 INFO:     Epoch: 97
2022-11-18 01:55:38,901 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.771399590102109, 'Total loss': 0.771399590102109} | train loss {'Reaction outcome loss': 0.8161424947602134, 'Total loss': 0.8161424947602134}
2022-11-18 01:55:38,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:38,902 INFO:     Epoch: 98
2022-11-18 01:55:39,728 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7809814444997094, 'Total loss': 0.7809814444997094} | train loss {'Reaction outcome loss': 0.8103222797714895, 'Total loss': 0.8103222797714895}
2022-11-18 01:55:39,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:39,728 INFO:     Epoch: 99
2022-11-18 01:55:40,529 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7713973474773493, 'Total loss': 0.7713973474773493} | train loss {'Reaction outcome loss': 0.8165166619564256, 'Total loss': 0.8165166619564256}
2022-11-18 01:55:40,529 INFO:     Best model found after epoch 89 of 100.
2022-11-18 01:55:40,530 INFO:   Done with stage: TRAINING
2022-11-18 01:55:40,530 INFO:   Starting stage: EVALUATION
2022-11-18 01:55:40,651 INFO:   Done with stage: EVALUATION
2022-11-18 01:55:40,651 INFO:   Leaving out SEQ value Fold_6
2022-11-18 01:55:40,664 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 01:55:40,665 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:55:41,333 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:55:41,333 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:55:41,405 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:55:41,405 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:55:41,405 INFO:     No hyperparam tuning for this model
2022-11-18 01:55:41,405 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:55:41,405 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:55:41,406 INFO:     None feature selector for col prot
2022-11-18 01:55:41,406 INFO:     None feature selector for col prot
2022-11-18 01:55:41,406 INFO:     None feature selector for col prot
2022-11-18 01:55:41,407 INFO:     None feature selector for col chem
2022-11-18 01:55:41,407 INFO:     None feature selector for col chem
2022-11-18 01:55:41,407 INFO:     None feature selector for col chem
2022-11-18 01:55:41,407 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:55:41,407 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:55:41,408 INFO:     Number of params in model 168571
2022-11-18 01:55:41,412 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:55:41,412 INFO:   Starting stage: TRAINING
2022-11-18 01:55:41,470 INFO:     Val loss before train {'Reaction outcome loss': 0.988549227064306, 'Total loss': 0.988549227064306}
2022-11-18 01:55:41,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:41,470 INFO:     Epoch: 0
2022-11-18 01:55:42,238 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8505811799656261, 'Total loss': 0.8505811799656261} | train loss {'Reaction outcome loss': 0.8799929267289687, 'Total loss': 0.8799929267289687}
2022-11-18 01:55:42,238 INFO:     Found new best model at epoch 0
2022-11-18 01:55:42,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:42,239 INFO:     Epoch: 1
2022-11-18 01:55:43,025 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8346848623319105, 'Total loss': 0.8346848623319105} | train loss {'Reaction outcome loss': 0.8481719017028808, 'Total loss': 0.8481719017028808}
2022-11-18 01:55:43,025 INFO:     Found new best model at epoch 1
2022-11-18 01:55:43,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:43,026 INFO:     Epoch: 2
2022-11-18 01:55:43,799 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8160334134643729, 'Total loss': 0.8160334134643729} | train loss {'Reaction outcome loss': 0.83476427233949, 'Total loss': 0.83476427233949}
2022-11-18 01:55:43,799 INFO:     Found new best model at epoch 2
2022-11-18 01:55:43,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:43,800 INFO:     Epoch: 3
2022-11-18 01:55:44,581 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7869297205047174, 'Total loss': 0.7869297205047174} | train loss {'Reaction outcome loss': 0.8359597248690469, 'Total loss': 0.8359597248690469}
2022-11-18 01:55:44,581 INFO:     Found new best model at epoch 3
2022-11-18 01:55:44,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:44,582 INFO:     Epoch: 4
2022-11-18 01:55:45,363 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.812592320821502, 'Total loss': 0.812592320821502} | train loss {'Reaction outcome loss': 0.830378761583445, 'Total loss': 0.830378761583445}
2022-11-18 01:55:45,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:45,363 INFO:     Epoch: 5
2022-11-18 01:55:46,165 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7991267205639319, 'Total loss': 0.7991267205639319} | train loss {'Reaction outcome loss': 0.8273900948008712, 'Total loss': 0.8273900948008712}
2022-11-18 01:55:46,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:46,166 INFO:     Epoch: 6
2022-11-18 01:55:46,946 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8101030886173248, 'Total loss': 0.8101030886173248} | train loss {'Reaction outcome loss': 0.8286394867361808, 'Total loss': 0.8286394867361808}
2022-11-18 01:55:46,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:46,947 INFO:     Epoch: 7
2022-11-18 01:55:47,704 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7773738503456116, 'Total loss': 0.7773738503456116} | train loss {'Reaction outcome loss': 0.8222828316445253, 'Total loss': 0.8222828316445253}
2022-11-18 01:55:47,705 INFO:     Found new best model at epoch 7
2022-11-18 01:55:47,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:47,705 INFO:     Epoch: 8
2022-11-18 01:55:48,498 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8015714037147436, 'Total loss': 0.8015714037147436} | train loss {'Reaction outcome loss': 0.8223615085592075, 'Total loss': 0.8223615085592075}
2022-11-18 01:55:48,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:48,498 INFO:     Epoch: 9
2022-11-18 01:55:49,259 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8045840927145698, 'Total loss': 0.8045840927145698} | train loss {'Reaction outcome loss': 0.8243956823738254, 'Total loss': 0.8243956823738254}
2022-11-18 01:55:49,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:49,259 INFO:     Epoch: 10
2022-11-18 01:55:50,016 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.792973748662255, 'Total loss': 0.792973748662255} | train loss {'Reaction outcome loss': 0.8194411214517088, 'Total loss': 0.8194411214517088}
2022-11-18 01:55:50,017 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:50,017 INFO:     Epoch: 11
2022-11-18 01:55:50,807 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8020634596998041, 'Total loss': 0.8020634596998041} | train loss {'Reaction outcome loss': 0.8190287240913936, 'Total loss': 0.8190287240913936}
2022-11-18 01:55:50,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:50,807 INFO:     Epoch: 12
2022-11-18 01:55:51,578 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7940650318156589, 'Total loss': 0.7940650318156589} | train loss {'Reaction outcome loss': 0.822475680526422, 'Total loss': 0.822475680526422}
2022-11-18 01:55:51,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:51,579 INFO:     Epoch: 13
2022-11-18 01:55:52,369 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8192717229778116, 'Total loss': 0.8192717229778116} | train loss {'Reaction outcome loss': 0.8169232216416573, 'Total loss': 0.8169232216416573}
2022-11-18 01:55:52,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:52,369 INFO:     Epoch: 14
2022-11-18 01:55:53,155 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7882807207378474, 'Total loss': 0.7882807207378474} | train loss {'Reaction outcome loss': 0.8222608099178392, 'Total loss': 0.8222608099178392}
2022-11-18 01:55:53,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:53,156 INFO:     Epoch: 15
2022-11-18 01:55:53,933 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8274987543171103, 'Total loss': 0.8274987543171103} | train loss {'Reaction outcome loss': 0.8194099952979964, 'Total loss': 0.8194099952979964}
2022-11-18 01:55:53,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:53,934 INFO:     Epoch: 16
2022-11-18 01:55:54,717 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7915398194031282, 'Total loss': 0.7915398194031282} | train loss {'Reaction outcome loss': 0.8213576691491263, 'Total loss': 0.8213576691491263}
2022-11-18 01:55:54,717 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:54,717 INFO:     Epoch: 17
2022-11-18 01:55:55,486 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8283389915119518, 'Total loss': 0.8283389915119518} | train loss {'Reaction outcome loss': 0.8147181448887806, 'Total loss': 0.8147181448887806}
2022-11-18 01:55:55,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:55,486 INFO:     Epoch: 18
2022-11-18 01:55:56,260 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.810602686621926, 'Total loss': 0.810602686621926} | train loss {'Reaction outcome loss': 0.8157388952313637, 'Total loss': 0.8157388952313637}
2022-11-18 01:55:56,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:56,261 INFO:     Epoch: 19
2022-11-18 01:55:57,046 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8010588484731588, 'Total loss': 0.8010588484731588} | train loss {'Reaction outcome loss': 0.8187821065892978, 'Total loss': 0.8187821065892978}
2022-11-18 01:55:57,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:57,046 INFO:     Epoch: 20
2022-11-18 01:55:57,819 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8016095249490305, 'Total loss': 0.8016095249490305} | train loss {'Reaction outcome loss': 0.8128989158844461, 'Total loss': 0.8128989158844461}
2022-11-18 01:55:57,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:57,819 INFO:     Epoch: 21
2022-11-18 01:55:58,593 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.791966821659695, 'Total loss': 0.791966821659695} | train loss {'Reaction outcome loss': 0.8216198777665897, 'Total loss': 0.8216198777665897}
2022-11-18 01:55:58,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:58,594 INFO:     Epoch: 22
2022-11-18 01:55:59,337 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7898671986027197, 'Total loss': 0.7898671986027197} | train loss {'Reaction outcome loss': 0.8175116961099663, 'Total loss': 0.8175116961099663}
2022-11-18 01:55:59,337 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:55:59,337 INFO:     Epoch: 23
2022-11-18 01:56:00,148 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7905482785268263, 'Total loss': 0.7905482785268263} | train loss {'Reaction outcome loss': 0.8132161147740422, 'Total loss': 0.8132161147740422}
2022-11-18 01:56:00,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:00,150 INFO:     Epoch: 24
2022-11-18 01:56:00,918 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7832747453993018, 'Total loss': 0.7832747453993018} | train loss {'Reaction outcome loss': 0.8165602173124041, 'Total loss': 0.8165602173124041}
2022-11-18 01:56:00,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:00,918 INFO:     Epoch: 25
2022-11-18 01:56:01,704 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7897450199181383, 'Total loss': 0.7897450199181383} | train loss {'Reaction outcome loss': 0.8150370607570726, 'Total loss': 0.8150370607570726}
2022-11-18 01:56:01,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:01,705 INFO:     Epoch: 26
2022-11-18 01:56:02,473 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8101075582883575, 'Total loss': 0.8101075582883575} | train loss {'Reaction outcome loss': 0.816320199869117, 'Total loss': 0.816320199869117}
2022-11-18 01:56:02,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:02,473 INFO:     Epoch: 27
2022-11-18 01:56:03,246 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7888149138201367, 'Total loss': 0.7888149138201367} | train loss {'Reaction outcome loss': 0.8167689668888949, 'Total loss': 0.8167689668888949}
2022-11-18 01:56:03,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:03,247 INFO:     Epoch: 28
2022-11-18 01:56:04,029 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7800602222030814, 'Total loss': 0.7800602222030814} | train loss {'Reaction outcome loss': 0.8125200685189695, 'Total loss': 0.8125200685189695}
2022-11-18 01:56:04,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:04,029 INFO:     Epoch: 29
2022-11-18 01:56:04,799 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7872983765873042, 'Total loss': 0.7872983765873042} | train loss {'Reaction outcome loss': 0.8158092330913155, 'Total loss': 0.8158092330913155}
2022-11-18 01:56:04,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:04,799 INFO:     Epoch: 30
2022-11-18 01:56:05,556 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7943510568954728, 'Total loss': 0.7943510568954728} | train loss {'Reaction outcome loss': 0.8148422145113653, 'Total loss': 0.8148422145113653}
2022-11-18 01:56:05,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:05,556 INFO:     Epoch: 31
2022-11-18 01:56:06,347 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8189174011349678, 'Total loss': 0.8189174011349678} | train loss {'Reaction outcome loss': 0.8149646604547696, 'Total loss': 0.8149646604547696}
2022-11-18 01:56:06,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:06,349 INFO:     Epoch: 32
2022-11-18 01:56:07,123 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7979414713653651, 'Total loss': 0.7979414713653651} | train loss {'Reaction outcome loss': 0.8150796336787087, 'Total loss': 0.8150796336787087}
2022-11-18 01:56:07,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:07,123 INFO:     Epoch: 33
2022-11-18 01:56:07,880 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8505709658969532, 'Total loss': 0.8505709658969532} | train loss {'Reaction outcome loss': 0.8163178164131787, 'Total loss': 0.8163178164131787}
2022-11-18 01:56:07,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:07,881 INFO:     Epoch: 34
2022-11-18 01:56:08,643 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7787176749923013, 'Total loss': 0.7787176749923013} | train loss {'Reaction outcome loss': 0.8160021438890573, 'Total loss': 0.8160021438890573}
2022-11-18 01:56:08,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:08,644 INFO:     Epoch: 35
2022-11-18 01:56:09,422 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7852265990593217, 'Total loss': 0.7852265990593217} | train loss {'Reaction outcome loss': 0.810494134255818, 'Total loss': 0.810494134255818}
2022-11-18 01:56:09,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:09,423 INFO:     Epoch: 36
2022-11-18 01:56:10,201 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8126685419543223, 'Total loss': 0.8126685419543223} | train loss {'Reaction outcome loss': 0.815740325377912, 'Total loss': 0.815740325377912}
2022-11-18 01:56:10,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:10,202 INFO:     Epoch: 37
2022-11-18 01:56:10,967 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7924429205330935, 'Total loss': 0.7924429205330935} | train loss {'Reaction outcome loss': 0.8134726946451226, 'Total loss': 0.8134726946451226}
2022-11-18 01:56:10,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:10,967 INFO:     Epoch: 38
2022-11-18 01:56:11,762 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8246991309252653, 'Total loss': 0.8246991309252653} | train loss {'Reaction outcome loss': 0.8160454419194435, 'Total loss': 0.8160454419194435}
2022-11-18 01:56:11,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:11,762 INFO:     Epoch: 39
2022-11-18 01:56:12,545 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.776119107211178, 'Total loss': 0.776119107211178} | train loss {'Reaction outcome loss': 0.8161427063601358, 'Total loss': 0.8161427063601358}
2022-11-18 01:56:12,545 INFO:     Found new best model at epoch 39
2022-11-18 01:56:12,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:12,546 INFO:     Epoch: 40
2022-11-18 01:56:13,319 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7749416868795048, 'Total loss': 0.7749416868795048} | train loss {'Reaction outcome loss': 0.8159985908440182, 'Total loss': 0.8159985908440182}
2022-11-18 01:56:13,319 INFO:     Found new best model at epoch 40
2022-11-18 01:56:13,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:13,320 INFO:     Epoch: 41
2022-11-18 01:56:14,099 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7959137477658011, 'Total loss': 0.7959137477658011} | train loss {'Reaction outcome loss': 0.8156966163187611, 'Total loss': 0.8156966163187611}
2022-11-18 01:56:14,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:14,100 INFO:     Epoch: 42
2022-11-18 01:56:14,889 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7941504540768537, 'Total loss': 0.7941504540768537} | train loss {'Reaction outcome loss': 0.8104168874876839, 'Total loss': 0.8104168874876839}
2022-11-18 01:56:14,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:14,889 INFO:     Epoch: 43
2022-11-18 01:56:15,647 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8271590789610689, 'Total loss': 0.8271590789610689} | train loss {'Reaction outcome loss': 0.8163538645724862, 'Total loss': 0.8163538645724862}
2022-11-18 01:56:15,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:15,647 INFO:     Epoch: 44
2022-11-18 01:56:16,454 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7981413474137132, 'Total loss': 0.7981413474137132} | train loss {'Reaction outcome loss': 0.8155193038132726, 'Total loss': 0.8155193038132726}
2022-11-18 01:56:16,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:16,454 INFO:     Epoch: 45
2022-11-18 01:56:17,238 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7773457928137346, 'Total loss': 0.7773457928137346} | train loss {'Reaction outcome loss': 0.8125044180422413, 'Total loss': 0.8125044180422413}
2022-11-18 01:56:17,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:17,238 INFO:     Epoch: 46
2022-11-18 01:56:18,016 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.805734857916832, 'Total loss': 0.805734857916832} | train loss {'Reaction outcome loss': 0.8147640435063109, 'Total loss': 0.8147640435063109}
2022-11-18 01:56:18,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:18,016 INFO:     Epoch: 47
2022-11-18 01:56:18,795 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7924568460068919, 'Total loss': 0.7924568460068919} | train loss {'Reaction outcome loss': 0.8134601301076461, 'Total loss': 0.8134601301076461}
2022-11-18 01:56:18,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:18,796 INFO:     Epoch: 48
2022-11-18 01:56:19,571 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7905700437047265, 'Total loss': 0.7905700437047265} | train loss {'Reaction outcome loss': 0.8118380539271296, 'Total loss': 0.8118380539271296}
2022-11-18 01:56:19,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:19,572 INFO:     Epoch: 49
2022-11-18 01:56:20,349 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8038012724031102, 'Total loss': 0.8038012724031102} | train loss {'Reaction outcome loss': 0.80945242168952, 'Total loss': 0.80945242168952}
2022-11-18 01:56:20,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:20,350 INFO:     Epoch: 50
2022-11-18 01:56:21,134 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7765039354562759, 'Total loss': 0.7765039354562759} | train loss {'Reaction outcome loss': 0.8135958109583173, 'Total loss': 0.8135958109583173}
2022-11-18 01:56:21,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:21,134 INFO:     Epoch: 51
2022-11-18 01:56:21,914 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7892709455706857, 'Total loss': 0.7892709455706857} | train loss {'Reaction outcome loss': 0.8139441681151487, 'Total loss': 0.8139441681151487}
2022-11-18 01:56:21,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:21,914 INFO:     Epoch: 52
2022-11-18 01:56:22,681 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7711269767446951, 'Total loss': 0.7711269767446951} | train loss {'Reaction outcome loss': 0.8131158520980757, 'Total loss': 0.8131158520980757}
2022-11-18 01:56:22,682 INFO:     Found new best model at epoch 52
2022-11-18 01:56:22,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:22,682 INFO:     Epoch: 53
2022-11-18 01:56:23,461 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7889277521859516, 'Total loss': 0.7889277521859516} | train loss {'Reaction outcome loss': 0.8134888253649887, 'Total loss': 0.8134888253649887}
2022-11-18 01:56:23,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:23,461 INFO:     Epoch: 54
2022-11-18 01:56:24,261 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8615770163861188, 'Total loss': 0.8615770163861188} | train loss {'Reaction outcome loss': 0.8112418990962359, 'Total loss': 0.8112418990962359}
2022-11-18 01:56:24,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:24,261 INFO:     Epoch: 55
2022-11-18 01:56:25,064 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7897691225463693, 'Total loss': 0.7897691225463693} | train loss {'Reaction outcome loss': 0.8136773260272279, 'Total loss': 0.8136773260272279}
2022-11-18 01:56:25,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:25,065 INFO:     Epoch: 56
2022-11-18 01:56:25,837 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7910061261870645, 'Total loss': 0.7910061261870645} | train loss {'Reaction outcome loss': 0.8075726257295025, 'Total loss': 0.8075726257295025}
2022-11-18 01:56:25,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:25,837 INFO:     Epoch: 57
2022-11-18 01:56:26,607 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8188759582963857, 'Total loss': 0.8188759582963857} | train loss {'Reaction outcome loss': 0.8150188809754897, 'Total loss': 0.8150188809754897}
2022-11-18 01:56:26,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:26,607 INFO:     Epoch: 58
2022-11-18 01:56:27,358 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7842990322546526, 'Total loss': 0.7842990322546526} | train loss {'Reaction outcome loss': 0.8101056084340933, 'Total loss': 0.8101056084340933}
2022-11-18 01:56:27,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:27,358 INFO:     Epoch: 59
2022-11-18 01:56:28,145 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.784796038811857, 'Total loss': 0.784796038811857} | train loss {'Reaction outcome loss': 0.810549422064606, 'Total loss': 0.810549422064606}
2022-11-18 01:56:28,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:28,145 INFO:     Epoch: 60
2022-11-18 01:56:28,927 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7890276475386186, 'Total loss': 0.7890276475386186} | train loss {'Reaction outcome loss': 0.8111319846036483, 'Total loss': 0.8111319846036483}
2022-11-18 01:56:28,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:28,927 INFO:     Epoch: 61
2022-11-18 01:56:29,719 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7946617102081125, 'Total loss': 0.7946617102081125} | train loss {'Reaction outcome loss': 0.8156488317616132, 'Total loss': 0.8156488317616132}
2022-11-18 01:56:29,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:29,719 INFO:     Epoch: 62
2022-11-18 01:56:30,464 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7844683954661543, 'Total loss': 0.7844683954661543} | train loss {'Reaction outcome loss': 0.8124194319150886, 'Total loss': 0.8124194319150886}
2022-11-18 01:56:30,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:30,464 INFO:     Epoch: 63
2022-11-18 01:56:31,286 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.786752811209722, 'Total loss': 0.786752811209722} | train loss {'Reaction outcome loss': 0.8090687403873521, 'Total loss': 0.8090687403873521}
2022-11-18 01:56:31,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:31,288 INFO:     Epoch: 64
2022-11-18 01:56:32,063 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7596573484214869, 'Total loss': 0.7596573484214869} | train loss {'Reaction outcome loss': 0.807865627201236, 'Total loss': 0.807865627201236}
2022-11-18 01:56:32,063 INFO:     Found new best model at epoch 64
2022-11-18 01:56:32,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:32,064 INFO:     Epoch: 65
2022-11-18 01:56:32,833 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.786991766907952, 'Total loss': 0.786991766907952} | train loss {'Reaction outcome loss': 0.8122732006773656, 'Total loss': 0.8122732006773656}
2022-11-18 01:56:32,833 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:32,833 INFO:     Epoch: 66
2022-11-18 01:56:33,621 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7715335583144968, 'Total loss': 0.7715335583144968} | train loss {'Reaction outcome loss': 0.8086723528346237, 'Total loss': 0.8086723528346237}
2022-11-18 01:56:33,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:33,621 INFO:     Epoch: 67
2022-11-18 01:56:34,398 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.781638271429322, 'Total loss': 0.781638271429322} | train loss {'Reaction outcome loss': 0.8116463220849329, 'Total loss': 0.8116463220849329}
2022-11-18 01:56:34,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:34,399 INFO:     Epoch: 68
2022-11-18 01:56:35,178 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.767146344889294, 'Total loss': 0.767146344889294} | train loss {'Reaction outcome loss': 0.8042362798233421, 'Total loss': 0.8042362798233421}
2022-11-18 01:56:35,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:35,178 INFO:     Epoch: 69
2022-11-18 01:56:35,969 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7840481515635144, 'Total loss': 0.7840481515635144} | train loss {'Reaction outcome loss': 0.8093313279200574, 'Total loss': 0.8093313279200574}
2022-11-18 01:56:35,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:35,969 INFO:     Epoch: 70
2022-11-18 01:56:36,747 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8112917373126204, 'Total loss': 0.8112917373126204} | train loss {'Reaction outcome loss': 0.8115217779363905, 'Total loss': 0.8115217779363905}
2022-11-18 01:56:36,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:36,747 INFO:     Epoch: 71
2022-11-18 01:56:37,524 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7770307443358682, 'Total loss': 0.7770307443358682} | train loss {'Reaction outcome loss': 0.8085154336325976, 'Total loss': 0.8085154336325976}
2022-11-18 01:56:37,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:37,525 INFO:     Epoch: 72
2022-11-18 01:56:38,311 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7763981846245852, 'Total loss': 0.7763981846245852} | train loss {'Reaction outcome loss': 0.8105483333675229, 'Total loss': 0.8105483333675229}
2022-11-18 01:56:38,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:38,311 INFO:     Epoch: 73
2022-11-18 01:56:39,087 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.776354690167037, 'Total loss': 0.776354690167037} | train loss {'Reaction outcome loss': 0.8067704894104782, 'Total loss': 0.8067704894104782}
2022-11-18 01:56:39,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:39,088 INFO:     Epoch: 74
2022-11-18 01:56:39,879 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7780128351666711, 'Total loss': 0.7780128351666711} | train loss {'Reaction outcome loss': 0.8093817859279866, 'Total loss': 0.8093817859279866}
2022-11-18 01:56:39,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:39,879 INFO:     Epoch: 75
2022-11-18 01:56:40,653 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7692958021705801, 'Total loss': 0.7692958021705801} | train loss {'Reaction outcome loss': 0.812382394318678, 'Total loss': 0.812382394318678}
2022-11-18 01:56:40,653 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:40,653 INFO:     Epoch: 76
2022-11-18 01:56:41,439 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.783882004970854, 'Total loss': 0.783882004970854} | train loss {'Reaction outcome loss': 0.812114054086257, 'Total loss': 0.812114054086257}
2022-11-18 01:56:41,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:41,440 INFO:     Epoch: 77
2022-11-18 01:56:42,199 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7929199920459227, 'Total loss': 0.7929199920459227} | train loss {'Reaction outcome loss': 0.8050480167476498, 'Total loss': 0.8050480167476498}
2022-11-18 01:56:42,199 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:42,199 INFO:     Epoch: 78
2022-11-18 01:56:42,957 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7794091894545339, 'Total loss': 0.7794091894545339} | train loss {'Reaction outcome loss': 0.809628087403823, 'Total loss': 0.809628087403823}
2022-11-18 01:56:42,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:42,958 INFO:     Epoch: 79
2022-11-18 01:56:43,743 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8078826022419062, 'Total loss': 0.8078826022419062} | train loss {'Reaction outcome loss': 0.8111459487554978, 'Total loss': 0.8111459487554978}
2022-11-18 01:56:43,744 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:43,744 INFO:     Epoch: 80
2022-11-18 01:56:44,547 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7798629274422472, 'Total loss': 0.7798629274422472} | train loss {'Reaction outcome loss': 0.8106215615661777, 'Total loss': 0.8106215615661777}
2022-11-18 01:56:44,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:44,547 INFO:     Epoch: 81
2022-11-18 01:56:45,328 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7852605760774829, 'Total loss': 0.7852605760774829} | train loss {'Reaction outcome loss': 0.8046878733197037, 'Total loss': 0.8046878733197037}
2022-11-18 01:56:45,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:45,329 INFO:     Epoch: 82
2022-11-18 01:56:46,124 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8094634136015718, 'Total loss': 0.8094634136015718} | train loss {'Reaction outcome loss': 0.8047846507052986, 'Total loss': 0.8047846507052986}
2022-11-18 01:56:46,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:46,124 INFO:     Epoch: 83
2022-11-18 01:56:46,875 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7770694717764854, 'Total loss': 0.7770694717764854} | train loss {'Reaction outcome loss': 0.8074449921140865, 'Total loss': 0.8074449921140865}
2022-11-18 01:56:46,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:46,875 INFO:     Epoch: 84
2022-11-18 01:56:47,642 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7564474107189612, 'Total loss': 0.7564474107189612} | train loss {'Reaction outcome loss': 0.8074443718608545, 'Total loss': 0.8074443718608545}
2022-11-18 01:56:47,642 INFO:     Found new best model at epoch 84
2022-11-18 01:56:47,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:47,643 INFO:     Epoch: 85
2022-11-18 01:56:48,434 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7850128026171164, 'Total loss': 0.7850128026171164} | train loss {'Reaction outcome loss': 0.8045429223654221, 'Total loss': 0.8045429223654221}
2022-11-18 01:56:48,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:48,434 INFO:     Epoch: 86
2022-11-18 01:56:49,191 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7716849900104783, 'Total loss': 0.7716849900104783} | train loss {'Reaction outcome loss': 0.8072705644734052, 'Total loss': 0.8072705644734052}
2022-11-18 01:56:49,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:49,192 INFO:     Epoch: 87
2022-11-18 01:56:49,975 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7863109511407939, 'Total loss': 0.7863109511407939} | train loss {'Reaction outcome loss': 0.8023175322279639, 'Total loss': 0.8023175322279639}
2022-11-18 01:56:49,976 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:49,976 INFO:     Epoch: 88
2022-11-18 01:56:50,750 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8269613845781847, 'Total loss': 0.8269613845781847} | train loss {'Reaction outcome loss': 0.8047776401042939, 'Total loss': 0.8047776401042939}
2022-11-18 01:56:50,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:50,750 INFO:     Epoch: 89
2022-11-18 01:56:51,530 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7806975082917647, 'Total loss': 0.7806975082917647} | train loss {'Reaction outcome loss': 0.8050990351608821, 'Total loss': 0.8050990351608821}
2022-11-18 01:56:51,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:51,530 INFO:     Epoch: 90
2022-11-18 01:56:52,315 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7728277241641824, 'Total loss': 0.7728277241641824} | train loss {'Reaction outcome loss': 0.8011292511103104, 'Total loss': 0.8011292511103104}
2022-11-18 01:56:52,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:52,315 INFO:     Epoch: 91
2022-11-18 01:56:53,075 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7626424025405537, 'Total loss': 0.7626424025405537} | train loss {'Reaction outcome loss': 0.8018922290023492, 'Total loss': 0.8018922290023492}
2022-11-18 01:56:53,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:53,075 INFO:     Epoch: 92
2022-11-18 01:56:53,847 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8232310116291046, 'Total loss': 0.8232310116291046} | train loss {'Reaction outcome loss': 0.8042086718033771, 'Total loss': 0.8042086718033771}
2022-11-18 01:56:53,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:53,848 INFO:     Epoch: 93
2022-11-18 01:56:54,614 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7807010811838236, 'Total loss': 0.7807010811838236} | train loss {'Reaction outcome loss': 0.807887377301041, 'Total loss': 0.807887377301041}
2022-11-18 01:56:54,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:54,615 INFO:     Epoch: 94
2022-11-18 01:56:55,378 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7914916663007303, 'Total loss': 0.7914916663007303} | train loss {'Reaction outcome loss': 0.7981816515630605, 'Total loss': 0.7981816515630605}
2022-11-18 01:56:55,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:55,378 INFO:     Epoch: 95
2022-11-18 01:56:56,149 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7537783133712682, 'Total loss': 0.7537783133712682} | train loss {'Reaction outcome loss': 0.7999763753949379, 'Total loss': 0.7999763753949379}
2022-11-18 01:56:56,149 INFO:     Found new best model at epoch 95
2022-11-18 01:56:56,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:56,150 INFO:     Epoch: 96
2022-11-18 01:56:56,939 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7549516660245982, 'Total loss': 0.7549516660245982} | train loss {'Reaction outcome loss': 0.8005467683685069, 'Total loss': 0.8005467683685069}
2022-11-18 01:56:56,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:56,939 INFO:     Epoch: 97
2022-11-18 01:56:57,716 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7833710421215404, 'Total loss': 0.7833710421215404} | train loss {'Reaction outcome loss': 0.7977874094126176, 'Total loss': 0.7977874094126176}
2022-11-18 01:56:57,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:57,716 INFO:     Epoch: 98
2022-11-18 01:56:58,502 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7594730630517006, 'Total loss': 0.7594730630517006} | train loss {'Reaction outcome loss': 0.7962415051703551, 'Total loss': 0.7962415051703551}
2022-11-18 01:56:58,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:56:58,502 INFO:     Epoch: 99
2022-11-18 01:56:59,250 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7779238251122561, 'Total loss': 0.7779238251122561} | train loss {'Reaction outcome loss': 0.7969949420617551, 'Total loss': 0.7969949420617551}
2022-11-18 01:56:59,250 INFO:     Best model found after epoch 96 of 100.
2022-11-18 01:56:59,251 INFO:   Done with stage: TRAINING
2022-11-18 01:56:59,251 INFO:   Starting stage: EVALUATION
2022-11-18 01:56:59,381 INFO:   Done with stage: EVALUATION
2022-11-18 01:56:59,381 INFO:   Leaving out SEQ value Fold_7
2022-11-18 01:56:59,395 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 01:56:59,395 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:57:00,059 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:57:00,059 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:57:00,128 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:57:00,128 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:57:00,128 INFO:     No hyperparam tuning for this model
2022-11-18 01:57:00,128 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:57:00,128 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:57:00,129 INFO:     None feature selector for col prot
2022-11-18 01:57:00,129 INFO:     None feature selector for col prot
2022-11-18 01:57:00,129 INFO:     None feature selector for col prot
2022-11-18 01:57:00,130 INFO:     None feature selector for col chem
2022-11-18 01:57:00,130 INFO:     None feature selector for col chem
2022-11-18 01:57:00,130 INFO:     None feature selector for col chem
2022-11-18 01:57:00,130 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:57:00,130 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:57:00,132 INFO:     Number of params in model 168571
2022-11-18 01:57:00,136 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:57:00,136 INFO:   Starting stage: TRAINING
2022-11-18 01:57:00,194 INFO:     Val loss before train {'Reaction outcome loss': 1.0832505036484112, 'Total loss': 1.0832505036484112}
2022-11-18 01:57:00,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:00,194 INFO:     Epoch: 0
2022-11-18 01:57:00,937 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.886606977744536, 'Total loss': 0.886606977744536} | train loss {'Reaction outcome loss': 0.8666275720207058, 'Total loss': 0.8666275720207058}
2022-11-18 01:57:00,937 INFO:     Found new best model at epoch 0
2022-11-18 01:57:00,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:00,938 INFO:     Epoch: 1
2022-11-18 01:57:01,713 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8991724103689194, 'Total loss': 0.8991724103689194} | train loss {'Reaction outcome loss': 0.8386268269042579, 'Total loss': 0.8386268269042579}
2022-11-18 01:57:01,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:01,713 INFO:     Epoch: 2
2022-11-18 01:57:02,475 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.892642614516345, 'Total loss': 0.892642614516345} | train loss {'Reaction outcome loss': 0.8313422453646757, 'Total loss': 0.8313422453646757}
2022-11-18 01:57:02,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:02,477 INFO:     Epoch: 3
2022-11-18 01:57:03,241 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8891896903514862, 'Total loss': 0.8891896903514862} | train loss {'Reaction outcome loss': 0.8249673427367697, 'Total loss': 0.8249673427367697}
2022-11-18 01:57:03,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:03,242 INFO:     Epoch: 4
2022-11-18 01:57:04,002 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8725717399608005, 'Total loss': 0.8725717399608005} | train loss {'Reaction outcome loss': 0.8241101739357929, 'Total loss': 0.8241101739357929}
2022-11-18 01:57:04,003 INFO:     Found new best model at epoch 4
2022-11-18 01:57:04,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:04,003 INFO:     Epoch: 5
2022-11-18 01:57:04,780 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8635414879430424, 'Total loss': 0.8635414879430424} | train loss {'Reaction outcome loss': 0.8216746866703033, 'Total loss': 0.8216746866703033}
2022-11-18 01:57:04,781 INFO:     Found new best model at epoch 5
2022-11-18 01:57:04,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:04,781 INFO:     Epoch: 6
2022-11-18 01:57:05,537 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8584412024779753, 'Total loss': 0.8584412024779753} | train loss {'Reaction outcome loss': 0.8162759111852061, 'Total loss': 0.8162759111852061}
2022-11-18 01:57:05,537 INFO:     Found new best model at epoch 6
2022-11-18 01:57:05,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:05,538 INFO:     Epoch: 7
2022-11-18 01:57:06,306 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8654473383318294, 'Total loss': 0.8654473383318294} | train loss {'Reaction outcome loss': 0.8178904847222932, 'Total loss': 0.8178904847222932}
2022-11-18 01:57:06,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:06,307 INFO:     Epoch: 8
2022-11-18 01:57:07,088 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8901560618118807, 'Total loss': 0.8901560618118807} | train loss {'Reaction outcome loss': 0.8154133257817249, 'Total loss': 0.8154133257817249}
2022-11-18 01:57:07,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:07,088 INFO:     Epoch: 9
2022-11-18 01:57:07,866 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8706711611964486, 'Total loss': 0.8706711611964486} | train loss {'Reaction outcome loss': 0.8108759745043151, 'Total loss': 0.8108759745043151}
2022-11-18 01:57:07,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:07,866 INFO:     Epoch: 10
2022-11-18 01:57:08,625 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8682843595743179, 'Total loss': 0.8682843595743179} | train loss {'Reaction outcome loss': 0.817497917097442, 'Total loss': 0.817497917097442}
2022-11-18 01:57:08,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:08,626 INFO:     Epoch: 11
2022-11-18 01:57:09,411 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.870865598320961, 'Total loss': 0.870865598320961} | train loss {'Reaction outcome loss': 0.8143910218258293, 'Total loss': 0.8143910218258293}
2022-11-18 01:57:09,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:09,412 INFO:     Epoch: 12
2022-11-18 01:57:10,191 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8857833208008246, 'Total loss': 0.8857833208008246} | train loss {'Reaction outcome loss': 0.8149510516195881, 'Total loss': 0.8149510516195881}
2022-11-18 01:57:10,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:10,192 INFO:     Epoch: 13
2022-11-18 01:57:10,981 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.858479417860508, 'Total loss': 0.858479417860508} | train loss {'Reaction outcome loss': 0.8155997057350315, 'Total loss': 0.8155997057350315}
2022-11-18 01:57:10,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:10,982 INFO:     Epoch: 14
2022-11-18 01:57:11,761 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8743541227145628, 'Total loss': 0.8743541227145628} | train loss {'Reaction outcome loss': 0.8188170026759712, 'Total loss': 0.8188170026759712}
2022-11-18 01:57:11,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:11,762 INFO:     Epoch: 15
2022-11-18 01:57:12,550 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8777649944478815, 'Total loss': 0.8777649944478815} | train loss {'Reaction outcome loss': 0.81826780657379, 'Total loss': 0.81826780657379}
2022-11-18 01:57:12,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:12,550 INFO:     Epoch: 16
2022-11-18 01:57:13,322 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8662297305735674, 'Total loss': 0.8662297305735674} | train loss {'Reaction outcome loss': 0.8079046414822948, 'Total loss': 0.8079046414822948}
2022-11-18 01:57:13,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:13,322 INFO:     Epoch: 17
2022-11-18 01:57:14,082 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.877441327680241, 'Total loss': 0.877441327680241} | train loss {'Reaction outcome loss': 0.8148259903703418, 'Total loss': 0.8148259903703418}
2022-11-18 01:57:14,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:14,082 INFO:     Epoch: 18
2022-11-18 01:57:14,837 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8751432475718585, 'Total loss': 0.8751432475718585} | train loss {'Reaction outcome loss': 0.8130687914332565, 'Total loss': 0.8130687914332565}
2022-11-18 01:57:14,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:14,837 INFO:     Epoch: 19
2022-11-18 01:57:15,626 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8714677515355024, 'Total loss': 0.8714677515355024} | train loss {'Reaction outcome loss': 0.8140910580450175, 'Total loss': 0.8140910580450175}
2022-11-18 01:57:15,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:15,627 INFO:     Epoch: 20
2022-11-18 01:57:16,407 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8596077398820356, 'Total loss': 0.8596077398820356} | train loss {'Reaction outcome loss': 0.8109300799515783, 'Total loss': 0.8109300799515783}
2022-11-18 01:57:16,407 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:16,408 INFO:     Epoch: 21
2022-11-18 01:57:17,198 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8782431578094309, 'Total loss': 0.8782431578094309} | train loss {'Reaction outcome loss': 0.8126179129493479, 'Total loss': 0.8126179129493479}
2022-11-18 01:57:17,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:17,199 INFO:     Epoch: 22
2022-11-18 01:57:17,959 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8774391317909415, 'Total loss': 0.8774391317909415} | train loss {'Reaction outcome loss': 0.8106765895473714, 'Total loss': 0.8106765895473714}
2022-11-18 01:57:17,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:17,959 INFO:     Epoch: 23
2022-11-18 01:57:18,706 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8688448220491409, 'Total loss': 0.8688448220491409} | train loss {'Reaction outcome loss': 0.8101352368082319, 'Total loss': 0.8101352368082319}
2022-11-18 01:57:18,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:18,706 INFO:     Epoch: 24
2022-11-18 01:57:19,489 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8725429448214445, 'Total loss': 0.8725429448214445} | train loss {'Reaction outcome loss': 0.8068432727638556, 'Total loss': 0.8068432727638556}
2022-11-18 01:57:19,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:19,489 INFO:     Epoch: 25
2022-11-18 01:57:20,289 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8732079355554148, 'Total loss': 0.8732079355554148} | train loss {'Reaction outcome loss': 0.8091982329378322, 'Total loss': 0.8091982329378322}
2022-11-18 01:57:20,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:20,290 INFO:     Epoch: 26
2022-11-18 01:57:21,054 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8876652494072914, 'Total loss': 0.8876652494072914} | train loss {'Reaction outcome loss': 0.8133745956177614, 'Total loss': 0.8133745956177614}
2022-11-18 01:57:21,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:21,056 INFO:     Epoch: 27
2022-11-18 01:57:21,830 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8500499562783674, 'Total loss': 0.8500499562783674} | train loss {'Reaction outcome loss': 0.8134550982592057, 'Total loss': 0.8134550982592057}
2022-11-18 01:57:21,830 INFO:     Found new best model at epoch 27
2022-11-18 01:57:21,831 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:21,831 INFO:     Epoch: 28
2022-11-18 01:57:22,583 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8723109913143244, 'Total loss': 0.8723109913143244} | train loss {'Reaction outcome loss': 0.8119995317897019, 'Total loss': 0.8119995317897019}
2022-11-18 01:57:22,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:22,583 INFO:     Epoch: 29
2022-11-18 01:57:23,373 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8805378824472427, 'Total loss': 0.8805378824472427} | train loss {'Reaction outcome loss': 0.8075413711216985, 'Total loss': 0.8075413711216985}
2022-11-18 01:57:23,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:23,374 INFO:     Epoch: 30
2022-11-18 01:57:24,151 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8392190533605489, 'Total loss': 0.8392190533605489} | train loss {'Reaction outcome loss': 0.8095036574772426, 'Total loss': 0.8095036574772426}
2022-11-18 01:57:24,151 INFO:     Found new best model at epoch 30
2022-11-18 01:57:24,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:24,152 INFO:     Epoch: 31
2022-11-18 01:57:24,935 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8749061890623786, 'Total loss': 0.8749061890623786} | train loss {'Reaction outcome loss': 0.8044230856457535, 'Total loss': 0.8044230856457535}
2022-11-18 01:57:24,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:24,935 INFO:     Epoch: 32
2022-11-18 01:57:25,705 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8647505850954489, 'Total loss': 0.8647505850954489} | train loss {'Reaction outcome loss': 0.8082462381343453, 'Total loss': 0.8082462381343453}
2022-11-18 01:57:25,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:25,706 INFO:     Epoch: 33
2022-11-18 01:57:26,504 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8518318513577635, 'Total loss': 0.8518318513577635} | train loss {'Reaction outcome loss': 0.8095866655816837, 'Total loss': 0.8095866655816837}
2022-11-18 01:57:26,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:26,504 INFO:     Epoch: 34
2022-11-18 01:57:27,244 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8481884321028536, 'Total loss': 0.8481884321028536} | train loss {'Reaction outcome loss': 0.8122585138496088, 'Total loss': 0.8122585138496088}
2022-11-18 01:57:27,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:27,244 INFO:     Epoch: 35
2022-11-18 01:57:28,028 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.868942220102657, 'Total loss': 0.868942220102657} | train loss {'Reaction outcome loss': 0.8094377618663166, 'Total loss': 0.8094377618663166}
2022-11-18 01:57:28,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:28,028 INFO:     Epoch: 36
2022-11-18 01:57:28,817 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8696322380141779, 'Total loss': 0.8696322380141779} | train loss {'Reaction outcome loss': 0.8119768963784587, 'Total loss': 0.8119768963784587}
2022-11-18 01:57:28,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:28,817 INFO:     Epoch: 37
2022-11-18 01:57:29,640 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8702754628929225, 'Total loss': 0.8702754628929225} | train loss {'Reaction outcome loss': 0.8094973600640589, 'Total loss': 0.8094973600640589}
2022-11-18 01:57:29,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:29,641 INFO:     Epoch: 38
2022-11-18 01:57:30,452 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.855057305233045, 'Total loss': 0.855057305233045} | train loss {'Reaction outcome loss': 0.8079816394922684, 'Total loss': 0.8079816394922684}
2022-11-18 01:57:30,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:30,452 INFO:     Epoch: 39
2022-11-18 01:57:31,319 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8825136456977237, 'Total loss': 0.8825136456977237} | train loss {'Reaction outcome loss': 0.8091590245159305, 'Total loss': 0.8091590245159305}
2022-11-18 01:57:31,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:31,319 INFO:     Epoch: 40
2022-11-18 01:57:32,136 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8525958765636791, 'Total loss': 0.8525958765636791} | train loss {'Reaction outcome loss': 0.8068955607560216, 'Total loss': 0.8068955607560216}
2022-11-18 01:57:32,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:32,136 INFO:     Epoch: 41
2022-11-18 01:57:32,966 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8565087684176185, 'Total loss': 0.8565087684176185} | train loss {'Reaction outcome loss': 0.8079775343135912, 'Total loss': 0.8079775343135912}
2022-11-18 01:57:32,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:32,967 INFO:     Epoch: 42
2022-11-18 01:57:33,791 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8490189063278112, 'Total loss': 0.8490189063278112} | train loss {'Reaction outcome loss': 0.8091699335039878, 'Total loss': 0.8091699335039878}
2022-11-18 01:57:33,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:33,791 INFO:     Epoch: 43
2022-11-18 01:57:34,584 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8712122921239246, 'Total loss': 0.8712122921239246} | train loss {'Reaction outcome loss': 0.8060818218455023, 'Total loss': 0.8060818218455023}
2022-11-18 01:57:34,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:34,584 INFO:     Epoch: 44
2022-11-18 01:57:35,362 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8513672439889475, 'Total loss': 0.8513672439889475} | train loss {'Reaction outcome loss': 0.809495083653197, 'Total loss': 0.809495083653197}
2022-11-18 01:57:35,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:35,363 INFO:     Epoch: 45
2022-11-18 01:57:36,138 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8529710078781302, 'Total loss': 0.8529710078781302} | train loss {'Reaction outcome loss': 0.8070875114324142, 'Total loss': 0.8070875114324142}
2022-11-18 01:57:36,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:36,140 INFO:     Epoch: 46
2022-11-18 01:57:36,951 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.854819656773047, 'Total loss': 0.854819656773047} | train loss {'Reaction outcome loss': 0.8110373035985596, 'Total loss': 0.8110373035985596}
2022-11-18 01:57:36,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:36,951 INFO:     Epoch: 47
2022-11-18 01:57:37,701 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.856353223323822, 'Total loss': 0.856353223323822} | train loss {'Reaction outcome loss': 0.8069359821932657, 'Total loss': 0.8069359821932657}
2022-11-18 01:57:37,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:37,701 INFO:     Epoch: 48
2022-11-18 01:57:38,504 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8914624770933931, 'Total loss': 0.8914624770933931} | train loss {'Reaction outcome loss': 0.8049708697260642, 'Total loss': 0.8049708697260642}
2022-11-18 01:57:38,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:38,504 INFO:     Epoch: 49
2022-11-18 01:57:39,292 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.852448361841115, 'Total loss': 0.852448361841115} | train loss {'Reaction outcome loss': 0.8121792264738862, 'Total loss': 0.8121792264738862}
2022-11-18 01:57:39,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:39,292 INFO:     Epoch: 50
2022-11-18 01:57:40,123 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8593585477633909, 'Total loss': 0.8593585477633909} | train loss {'Reaction outcome loss': 0.8058044007238077, 'Total loss': 0.8058044007238077}
2022-11-18 01:57:40,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:40,124 INFO:     Epoch: 51
2022-11-18 01:57:40,909 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8626397042111917, 'Total loss': 0.8626397042111917} | train loss {'Reaction outcome loss': 0.8074807274098299, 'Total loss': 0.8074807274098299}
2022-11-18 01:57:40,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:40,909 INFO:     Epoch: 52
2022-11-18 01:57:41,676 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8573182059282606, 'Total loss': 0.8573182059282606} | train loss {'Reaction outcome loss': 0.8072789431834707, 'Total loss': 0.8072789431834707}
2022-11-18 01:57:41,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:41,676 INFO:     Epoch: 53
2022-11-18 01:57:42,466 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.872099635953253, 'Total loss': 0.872099635953253} | train loss {'Reaction outcome loss': 0.8113270752283992, 'Total loss': 0.8113270752283992}
2022-11-18 01:57:42,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:42,467 INFO:     Epoch: 54
2022-11-18 01:57:43,275 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8455028066580946, 'Total loss': 0.8455028066580946} | train loss {'Reaction outcome loss': 0.8070540496281216, 'Total loss': 0.8070540496281216}
2022-11-18 01:57:43,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:43,275 INFO:     Epoch: 55
2022-11-18 01:57:44,045 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8775077143853361, 'Total loss': 0.8775077143853361} | train loss {'Reaction outcome loss': 0.8074587953333952, 'Total loss': 0.8074587953333952}
2022-11-18 01:57:44,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:44,045 INFO:     Epoch: 56
2022-11-18 01:57:44,840 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8530035432089459, 'Total loss': 0.8530035432089459} | train loss {'Reaction outcome loss': 0.8102325679088126, 'Total loss': 0.8102325679088126}
2022-11-18 01:57:44,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:44,840 INFO:     Epoch: 57
2022-11-18 01:57:45,670 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8741928311911497, 'Total loss': 0.8741928311911497} | train loss {'Reaction outcome loss': 0.8090910018706808, 'Total loss': 0.8090910018706808}
2022-11-18 01:57:45,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:45,671 INFO:     Epoch: 58
2022-11-18 01:57:46,476 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8747973787513647, 'Total loss': 0.8747973787513647} | train loss {'Reaction outcome loss': 0.8125883444231383, 'Total loss': 0.8125883444231383}
2022-11-18 01:57:46,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:46,476 INFO:     Epoch: 59
2022-11-18 01:57:47,261 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8663047105073929, 'Total loss': 0.8663047105073929} | train loss {'Reaction outcome loss': 0.8108938057203682, 'Total loss': 0.8108938057203682}
2022-11-18 01:57:47,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:47,261 INFO:     Epoch: 60
2022-11-18 01:57:48,025 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8694778450510718, 'Total loss': 0.8694778450510718} | train loss {'Reaction outcome loss': 0.8137887420702954, 'Total loss': 0.8137887420702954}
2022-11-18 01:57:48,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:48,025 INFO:     Epoch: 61
2022-11-18 01:57:48,850 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8885913315144452, 'Total loss': 0.8885913315144452} | train loss {'Reaction outcome loss': 0.8080013121877397, 'Total loss': 0.8080013121877397}
2022-11-18 01:57:48,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:48,850 INFO:     Epoch: 62
2022-11-18 01:57:49,662 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8711508377031847, 'Total loss': 0.8711508377031847} | train loss {'Reaction outcome loss': 0.8098627665821387, 'Total loss': 0.8098627665821387}
2022-11-18 01:57:49,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:49,662 INFO:     Epoch: 63
2022-11-18 01:57:50,480 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8720214095982638, 'Total loss': 0.8720214095982638} | train loss {'Reaction outcome loss': 0.8051951368244327, 'Total loss': 0.8051951368244327}
2022-11-18 01:57:50,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:50,480 INFO:     Epoch: 64
2022-11-18 01:57:51,296 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8581371903419495, 'Total loss': 0.8581371903419495} | train loss {'Reaction outcome loss': 0.8081692555729224, 'Total loss': 0.8081692555729224}
2022-11-18 01:57:51,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:51,296 INFO:     Epoch: 65
2022-11-18 01:57:52,104 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8505349626595323, 'Total loss': 0.8505349626595323} | train loss {'Reaction outcome loss': 0.806913392154538, 'Total loss': 0.806913392154538}
2022-11-18 01:57:52,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:52,104 INFO:     Epoch: 66
2022-11-18 01:57:52,911 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8730276877229864, 'Total loss': 0.8730276877229864} | train loss {'Reaction outcome loss': 0.8120191825895894, 'Total loss': 0.8120191825895894}
2022-11-18 01:57:52,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:52,911 INFO:     Epoch: 67
2022-11-18 01:57:53,708 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8713253113356504, 'Total loss': 0.8713253113356504} | train loss {'Reaction outcome loss': 0.8084266613940804, 'Total loss': 0.8084266613940804}
2022-11-18 01:57:53,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:53,708 INFO:     Epoch: 68
2022-11-18 01:57:54,549 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8980084908279505, 'Total loss': 0.8980084908279505} | train loss {'Reaction outcome loss': 0.8093913648809705, 'Total loss': 0.8093913648809705}
2022-11-18 01:57:54,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:54,551 INFO:     Epoch: 69
2022-11-18 01:57:55,331 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8557083816690878, 'Total loss': 0.8557083816690878} | train loss {'Reaction outcome loss': 0.8076853173119681, 'Total loss': 0.8076853173119681}
2022-11-18 01:57:55,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:55,332 INFO:     Epoch: 70
2022-11-18 01:57:56,124 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8620708679611032, 'Total loss': 0.8620708679611032} | train loss {'Reaction outcome loss': 0.8054461233469905, 'Total loss': 0.8054461233469905}
2022-11-18 01:57:56,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:56,124 INFO:     Epoch: 71
2022-11-18 01:57:56,940 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8579973862929777, 'Total loss': 0.8579973862929777} | train loss {'Reaction outcome loss': 0.806781353634231, 'Total loss': 0.806781353634231}
2022-11-18 01:57:56,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:56,941 INFO:     Epoch: 72
2022-11-18 01:57:57,755 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8778549798510291, 'Total loss': 0.8778549798510291} | train loss {'Reaction outcome loss': 0.8117947957953628, 'Total loss': 0.8117947957953628}
2022-11-18 01:57:57,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:57,756 INFO:     Epoch: 73
2022-11-18 01:57:58,555 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8673981387506832, 'Total loss': 0.8673981387506832} | train loss {'Reaction outcome loss': 0.8071824556710768, 'Total loss': 0.8071824556710768}
2022-11-18 01:57:58,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:58,556 INFO:     Epoch: 74
2022-11-18 01:57:59,365 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8512444550340826, 'Total loss': 0.8512444550340826} | train loss {'Reaction outcome loss': 0.808846605553919, 'Total loss': 0.808846605553919}
2022-11-18 01:57:59,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:57:59,365 INFO:     Epoch: 75
2022-11-18 01:58:00,171 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8648364435542714, 'Total loss': 0.8648364435542714} | train loss {'Reaction outcome loss': 0.8053959555771886, 'Total loss': 0.8053959555771886}
2022-11-18 01:58:00,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:00,172 INFO:     Epoch: 76
2022-11-18 01:58:00,977 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8425016362558712, 'Total loss': 0.8425016362558712} | train loss {'Reaction outcome loss': 0.8079290969031198, 'Total loss': 0.8079290969031198}
2022-11-18 01:58:00,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:00,977 INFO:     Epoch: 77
2022-11-18 01:58:01,817 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8742512410337274, 'Total loss': 0.8742512410337274} | train loss {'Reaction outcome loss': 0.80740336848765, 'Total loss': 0.80740336848765}
2022-11-18 01:58:01,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:01,818 INFO:     Epoch: 78
2022-11-18 01:58:02,617 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8874025202610276, 'Total loss': 0.8874025202610276} | train loss {'Reaction outcome loss': 0.806715151728416, 'Total loss': 0.806715151728416}
2022-11-18 01:58:02,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:02,618 INFO:     Epoch: 79
2022-11-18 01:58:03,438 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8402118828486312, 'Total loss': 0.8402118828486312} | train loss {'Reaction outcome loss': 0.8083133217023344, 'Total loss': 0.8083133217023344}
2022-11-18 01:58:03,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:03,438 INFO:     Epoch: 80
2022-11-18 01:58:04,278 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8659013963558457, 'Total loss': 0.8659013963558457} | train loss {'Reaction outcome loss': 0.8068709742049782, 'Total loss': 0.8068709742049782}
2022-11-18 01:58:04,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:04,279 INFO:     Epoch: 81
2022-11-18 01:58:05,130 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8738663372668353, 'Total loss': 0.8738663372668353} | train loss {'Reaction outcome loss': 0.8073849545449626, 'Total loss': 0.8073849545449626}
2022-11-18 01:58:05,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:05,130 INFO:     Epoch: 82
2022-11-18 01:58:05,951 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8586703098633073, 'Total loss': 0.8586703098633073} | train loss {'Reaction outcome loss': 0.8077412498240568, 'Total loss': 0.8077412498240568}
2022-11-18 01:58:05,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:05,951 INFO:     Epoch: 83
2022-11-18 01:58:06,740 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8754769733006303, 'Total loss': 0.8754769733006303} | train loss {'Reaction outcome loss': 0.8045062472625655, 'Total loss': 0.8045062472625655}
2022-11-18 01:58:06,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:06,740 INFO:     Epoch: 84
2022-11-18 01:58:07,551 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8770632527091287, 'Total loss': 0.8770632527091287} | train loss {'Reaction outcome loss': 0.808625133426822, 'Total loss': 0.808625133426822}
2022-11-18 01:58:07,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:07,551 INFO:     Epoch: 85
2022-11-18 01:58:08,382 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8591553948142312, 'Total loss': 0.8591553948142312} | train loss {'Reaction outcome loss': 0.8121343533603512, 'Total loss': 0.8121343533603512}
2022-11-18 01:58:08,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:08,382 INFO:     Epoch: 86
2022-11-18 01:58:09,201 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.871267085725611, 'Total loss': 0.871267085725611} | train loss {'Reaction outcome loss': 0.8081581903963673, 'Total loss': 0.8081581903963673}
2022-11-18 01:58:09,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:09,201 INFO:     Epoch: 87
2022-11-18 01:58:10,000 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8659680390899832, 'Total loss': 0.8659680390899832} | train loss {'Reaction outcome loss': 0.8101732733298321, 'Total loss': 0.8101732733298321}
2022-11-18 01:58:10,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:10,000 INFO:     Epoch: 88
2022-11-18 01:58:10,786 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8620088235898451, 'Total loss': 0.8620088235898451} | train loss {'Reaction outcome loss': 0.8082714437830205, 'Total loss': 0.8082714437830205}
2022-11-18 01:58:10,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:10,787 INFO:     Epoch: 89
2022-11-18 01:58:11,614 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8753964900970459, 'Total loss': 0.8753964900970459} | train loss {'Reaction outcome loss': 0.8131309075014932, 'Total loss': 0.8131309075014932}
2022-11-18 01:58:11,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:11,614 INFO:     Epoch: 90
2022-11-18 01:58:12,420 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8508268757299944, 'Total loss': 0.8508268757299944} | train loss {'Reaction outcome loss': 0.8060805047044949, 'Total loss': 0.8060805047044949}
2022-11-18 01:58:12,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:12,420 INFO:     Epoch: 91
2022-11-18 01:58:13,229 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8746853823011572, 'Total loss': 0.8746853823011572} | train loss {'Reaction outcome loss': 0.8086496314223932, 'Total loss': 0.8086496314223932}
2022-11-18 01:58:13,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:13,229 INFO:     Epoch: 92
2022-11-18 01:58:14,071 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8714779757640578, 'Total loss': 0.8714779757640578} | train loss {'Reaction outcome loss': 0.8082573467371416, 'Total loss': 0.8082573467371416}
2022-11-18 01:58:14,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:14,071 INFO:     Epoch: 93
2022-11-18 01:58:14,870 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8489541953260248, 'Total loss': 0.8489541953260248} | train loss {'Reaction outcome loss': 0.805420331322417, 'Total loss': 0.805420331322417}
2022-11-18 01:58:14,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:14,870 INFO:     Epoch: 94
2022-11-18 01:58:15,682 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8563621586019342, 'Total loss': 0.8563621586019342} | train loss {'Reaction outcome loss': 0.8050669919471352, 'Total loss': 0.8050669919471352}
2022-11-18 01:58:15,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:15,682 INFO:     Epoch: 95
2022-11-18 01:58:16,475 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8614054281603206, 'Total loss': 0.8614054281603206} | train loss {'Reaction outcome loss': 0.8014425429762626, 'Total loss': 0.8014425429762626}
2022-11-18 01:58:16,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:16,476 INFO:     Epoch: 96
2022-11-18 01:58:17,245 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8691233979030089, 'Total loss': 0.8691233979030089} | train loss {'Reaction outcome loss': 0.8043958166424109, 'Total loss': 0.8043958166424109}
2022-11-18 01:58:17,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:17,245 INFO:     Epoch: 97
2022-11-18 01:58:18,067 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8542706085876985, 'Total loss': 0.8542706085876985} | train loss {'Reaction outcome loss': 0.80658576610137, 'Total loss': 0.80658576610137}
2022-11-18 01:58:18,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:18,067 INFO:     Epoch: 98
2022-11-18 01:58:18,877 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8977415521036495, 'Total loss': 0.8977415521036495} | train loss {'Reaction outcome loss': 0.807265313790769, 'Total loss': 0.807265313790769}
2022-11-18 01:58:18,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:18,877 INFO:     Epoch: 99
2022-11-18 01:58:19,694 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8588771494952115, 'Total loss': 0.8588771494952115} | train loss {'Reaction outcome loss': 0.8022636227461757, 'Total loss': 0.8022636227461757}
2022-11-18 01:58:19,694 INFO:     Best model found after epoch 31 of 100.
2022-11-18 01:58:19,694 INFO:   Done with stage: TRAINING
2022-11-18 01:58:19,694 INFO:   Starting stage: EVALUATION
2022-11-18 01:58:19,825 INFO:   Done with stage: EVALUATION
2022-11-18 01:58:19,825 INFO:   Leaving out SEQ value Fold_8
2022-11-18 01:58:19,838 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 01:58:19,839 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:58:20,516 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:58:20,516 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:58:20,586 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:58:20,586 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:58:20,586 INFO:     No hyperparam tuning for this model
2022-11-18 01:58:20,586 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:58:20,587 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:58:20,587 INFO:     None feature selector for col prot
2022-11-18 01:58:20,588 INFO:     None feature selector for col prot
2022-11-18 01:58:20,588 INFO:     None feature selector for col prot
2022-11-18 01:58:20,588 INFO:     None feature selector for col chem
2022-11-18 01:58:20,588 INFO:     None feature selector for col chem
2022-11-18 01:58:20,588 INFO:     None feature selector for col chem
2022-11-18 01:58:20,589 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:58:20,589 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:58:20,590 INFO:     Number of params in model 168571
2022-11-18 01:58:20,596 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:58:20,596 INFO:   Starting stage: TRAINING
2022-11-18 01:58:20,654 INFO:     Val loss before train {'Reaction outcome loss': 0.9691082659092817, 'Total loss': 0.9691082659092817}
2022-11-18 01:58:20,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:20,654 INFO:     Epoch: 0
2022-11-18 01:58:21,478 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8417480885982513, 'Total loss': 0.8417480885982513} | train loss {'Reaction outcome loss': 0.887651820937472, 'Total loss': 0.887651820937472}
2022-11-18 01:58:21,478 INFO:     Found new best model at epoch 0
2022-11-18 01:58:21,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:21,479 INFO:     Epoch: 1
2022-11-18 01:58:22,299 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8428414274345745, 'Total loss': 0.8428414274345745} | train loss {'Reaction outcome loss': 0.8562691432814444, 'Total loss': 0.8562691432814444}
2022-11-18 01:58:22,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:22,299 INFO:     Epoch: 2
2022-11-18 01:58:23,160 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8040836582129652, 'Total loss': 0.8040836582129652} | train loss {'Reaction outcome loss': 0.8547359506689733, 'Total loss': 0.8547359506689733}
2022-11-18 01:58:23,161 INFO:     Found new best model at epoch 2
2022-11-18 01:58:23,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:23,162 INFO:     Epoch: 3
2022-11-18 01:58:24,009 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7974931814453818, 'Total loss': 0.7974931814453818} | train loss {'Reaction outcome loss': 0.8440790994753761, 'Total loss': 0.8440790994753761}
2022-11-18 01:58:24,009 INFO:     Found new best model at epoch 3
2022-11-18 01:58:24,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:24,010 INFO:     Epoch: 4
2022-11-18 01:58:24,853 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8221628523685716, 'Total loss': 0.8221628523685716} | train loss {'Reaction outcome loss': 0.8425284214918652, 'Total loss': 0.8425284214918652}
2022-11-18 01:58:24,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:24,853 INFO:     Epoch: 5
2022-11-18 01:58:25,667 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7910012555393305, 'Total loss': 0.7910012555393305} | train loss {'Reaction outcome loss': 0.8401397794725434, 'Total loss': 0.8401397794725434}
2022-11-18 01:58:25,667 INFO:     Found new best model at epoch 5
2022-11-18 01:58:25,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:25,668 INFO:     Epoch: 6
2022-11-18 01:58:26,460 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7949653775854544, 'Total loss': 0.7949653775854544} | train loss {'Reaction outcome loss': 0.8331229373091652, 'Total loss': 0.8331229373091652}
2022-11-18 01:58:26,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:26,460 INFO:     Epoch: 7
2022-11-18 01:58:27,300 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7928372418338602, 'Total loss': 0.7928372418338602} | train loss {'Reaction outcome loss': 0.8346387709701254, 'Total loss': 0.8346387709701254}
2022-11-18 01:58:27,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:27,300 INFO:     Epoch: 8
2022-11-18 01:58:28,109 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8069738637317311, 'Total loss': 0.8069738637317311} | train loss {'Reaction outcome loss': 0.8282583185261295, 'Total loss': 0.8282583185261295}
2022-11-18 01:58:28,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:28,109 INFO:     Epoch: 9
2022-11-18 01:58:28,973 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7871913835406303, 'Total loss': 0.7871913835406303} | train loss {'Reaction outcome loss': 0.8268487914916007, 'Total loss': 0.8268487914916007}
2022-11-18 01:58:28,973 INFO:     Found new best model at epoch 9
2022-11-18 01:58:28,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:28,974 INFO:     Epoch: 10
2022-11-18 01:58:29,808 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7934709198095582, 'Total loss': 0.7934709198095582} | train loss {'Reaction outcome loss': 0.8335774095068055, 'Total loss': 0.8335774095068055}
2022-11-18 01:58:29,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:29,808 INFO:     Epoch: 11
2022-11-18 01:58:30,611 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8026403324170546, 'Total loss': 0.8026403324170546} | train loss {'Reaction outcome loss': 0.8270390667021275, 'Total loss': 0.8270390667021275}
2022-11-18 01:58:30,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:30,612 INFO:     Epoch: 12
2022-11-18 01:58:31,428 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8058300417932597, 'Total loss': 0.8058300417932597} | train loss {'Reaction outcome loss': 0.8292165629325374, 'Total loss': 0.8292165629325374}
2022-11-18 01:58:31,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:31,428 INFO:     Epoch: 13
2022-11-18 01:58:32,263 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.782857745885849, 'Total loss': 0.782857745885849} | train loss {'Reaction outcome loss': 0.8269279430950841, 'Total loss': 0.8269279430950841}
2022-11-18 01:58:32,263 INFO:     Found new best model at epoch 13
2022-11-18 01:58:32,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:32,264 INFO:     Epoch: 14
2022-11-18 01:58:33,095 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8031622022390366, 'Total loss': 0.8031622022390366} | train loss {'Reaction outcome loss': 0.8261779761843143, 'Total loss': 0.8261779761843143}
2022-11-18 01:58:33,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:33,095 INFO:     Epoch: 15
2022-11-18 01:58:33,899 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8248043967918917, 'Total loss': 0.8248043967918917} | train loss {'Reaction outcome loss': 0.824611168234579, 'Total loss': 0.824611168234579}
2022-11-18 01:58:33,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:33,900 INFO:     Epoch: 16
2022-11-18 01:58:34,692 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7909020564772866, 'Total loss': 0.7909020564772866} | train loss {'Reaction outcome loss': 0.8291701766992768, 'Total loss': 0.8291701766992768}
2022-11-18 01:58:34,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:34,693 INFO:     Epoch: 17
2022-11-18 01:58:35,531 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7855931235985323, 'Total loss': 0.7855931235985323} | train loss {'Reaction outcome loss': 0.8305233939280433, 'Total loss': 0.8305233939280433}
2022-11-18 01:58:35,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:35,533 INFO:     Epoch: 18
2022-11-18 01:58:36,357 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7908449443903837, 'Total loss': 0.7908449443903837} | train loss {'Reaction outcome loss': 0.8273675063204381, 'Total loss': 0.8273675063204381}
2022-11-18 01:58:36,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:36,357 INFO:     Epoch: 19
2022-11-18 01:58:37,149 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7978056174787608, 'Total loss': 0.7978056174787608} | train loss {'Reaction outcome loss': 0.8208036093461898, 'Total loss': 0.8208036093461898}
2022-11-18 01:58:37,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:37,149 INFO:     Epoch: 20
2022-11-18 01:58:37,987 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7974307062951002, 'Total loss': 0.7974307062951002} | train loss {'Reaction outcome loss': 0.823747930507506, 'Total loss': 0.823747930507506}
2022-11-18 01:58:37,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:37,987 INFO:     Epoch: 21
2022-11-18 01:58:38,815 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8130959590727632, 'Total loss': 0.8130959590727632} | train loss {'Reaction outcome loss': 0.8243904355312547, 'Total loss': 0.8243904355312547}
2022-11-18 01:58:38,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:38,815 INFO:     Epoch: 22
2022-11-18 01:58:39,628 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7888087887655605, 'Total loss': 0.7888087887655605} | train loss {'Reaction outcome loss': 0.8225427731390922, 'Total loss': 0.8225427731390922}
2022-11-18 01:58:39,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:39,628 INFO:     Epoch: 23
2022-11-18 01:58:40,430 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7827736843716014, 'Total loss': 0.7827736843716014} | train loss {'Reaction outcome loss': 0.8257909055438734, 'Total loss': 0.8257909055438734}
2022-11-18 01:58:40,431 INFO:     Found new best model at epoch 23
2022-11-18 01:58:40,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:40,432 INFO:     Epoch: 24
2022-11-18 01:58:41,305 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8100212155417963, 'Total loss': 0.8100212155417963} | train loss {'Reaction outcome loss': 0.8217132258559426, 'Total loss': 0.8217132258559426}
2022-11-18 01:58:41,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:41,306 INFO:     Epoch: 25
2022-11-18 01:58:42,121 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7825538631189953, 'Total loss': 0.7825538631189953} | train loss {'Reaction outcome loss': 0.8280836145483679, 'Total loss': 0.8280836145483679}
2022-11-18 01:58:42,122 INFO:     Found new best model at epoch 25
2022-11-18 01:58:42,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:42,123 INFO:     Epoch: 26
2022-11-18 01:58:42,959 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.781451518562707, 'Total loss': 0.781451518562707} | train loss {'Reaction outcome loss': 0.8236454802174722, 'Total loss': 0.8236454802174722}
2022-11-18 01:58:42,959 INFO:     Found new best model at epoch 26
2022-11-18 01:58:42,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:42,960 INFO:     Epoch: 27
2022-11-18 01:58:43,779 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7845582040873441, 'Total loss': 0.7845582040873441} | train loss {'Reaction outcome loss': 0.8199147711838445, 'Total loss': 0.8199147711838445}
2022-11-18 01:58:43,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:43,779 INFO:     Epoch: 28
2022-11-18 01:58:44,550 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7935251654549078, 'Total loss': 0.7935251654549078} | train loss {'Reaction outcome loss': 0.8205860456632029, 'Total loss': 0.8205860456632029}
2022-11-18 01:58:44,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:44,551 INFO:     Epoch: 29
2022-11-18 01:58:45,389 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7953668182546442, 'Total loss': 0.7953668182546442} | train loss {'Reaction outcome loss': 0.8251053931251648, 'Total loss': 0.8251053931251648}
2022-11-18 01:58:45,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:45,390 INFO:     Epoch: 30
2022-11-18 01:58:46,209 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7992014329541813, 'Total loss': 0.7992014329541813} | train loss {'Reaction outcome loss': 0.823185448324488, 'Total loss': 0.823185448324488}
2022-11-18 01:58:46,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:46,209 INFO:     Epoch: 31
2022-11-18 01:58:47,048 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8002143651247025, 'Total loss': 0.8002143651247025} | train loss {'Reaction outcome loss': 0.8215347244854896, 'Total loss': 0.8215347244854896}
2022-11-18 01:58:47,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:47,048 INFO:     Epoch: 32
2022-11-18 01:58:47,867 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8017965765161947, 'Total loss': 0.8017965765161947} | train loss {'Reaction outcome loss': 0.8204219379732686, 'Total loss': 0.8204219379732686}
2022-11-18 01:58:47,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:47,867 INFO:     Epoch: 33
2022-11-18 01:58:48,690 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7870797183025967, 'Total loss': 0.7870797183025967} | train loss {'Reaction outcome loss': 0.8251834586262703, 'Total loss': 0.8251834586262703}
2022-11-18 01:58:48,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:48,690 INFO:     Epoch: 34
2022-11-18 01:58:49,499 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7900175519964912, 'Total loss': 0.7900175519964912} | train loss {'Reaction outcome loss': 0.81864559073602, 'Total loss': 0.81864559073602}
2022-11-18 01:58:49,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:49,499 INFO:     Epoch: 35
2022-11-18 01:58:50,319 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8104732984846289, 'Total loss': 0.8104732984846289} | train loss {'Reaction outcome loss': 0.822750132410757, 'Total loss': 0.822750132410757}
2022-11-18 01:58:50,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:50,319 INFO:     Epoch: 36
2022-11-18 01:58:51,115 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7918144417080012, 'Total loss': 0.7918144417080012} | train loss {'Reaction outcome loss': 0.8220578539035013, 'Total loss': 0.8220578539035013}
2022-11-18 01:58:51,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:51,116 INFO:     Epoch: 37
2022-11-18 01:58:51,920 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7979953783479604, 'Total loss': 0.7979953783479604} | train loss {'Reaction outcome loss': 0.822297363752319, 'Total loss': 0.822297363752319}
2022-11-18 01:58:51,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:51,920 INFO:     Epoch: 38
2022-11-18 01:58:52,711 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7854958583008159, 'Total loss': 0.7854958583008159} | train loss {'Reaction outcome loss': 0.8263023774470052, 'Total loss': 0.8263023774470052}
2022-11-18 01:58:52,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:52,712 INFO:     Epoch: 39
2022-11-18 01:58:53,492 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7924555072730238, 'Total loss': 0.7924555072730238} | train loss {'Reaction outcome loss': 0.824098736648598, 'Total loss': 0.824098736648598}
2022-11-18 01:58:53,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:53,493 INFO:     Epoch: 40
2022-11-18 01:58:54,306 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.786842025139115, 'Total loss': 0.786842025139115} | train loss {'Reaction outcome loss': 0.8240224032873108, 'Total loss': 0.8240224032873108}
2022-11-18 01:58:54,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:54,307 INFO:     Epoch: 41
2022-11-18 01:58:55,113 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8056336526166309, 'Total loss': 0.8056336526166309} | train loss {'Reaction outcome loss': 0.8209043498481473, 'Total loss': 0.8209043498481473}
2022-11-18 01:58:55,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:55,113 INFO:     Epoch: 42
2022-11-18 01:58:55,932 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8055015280842781, 'Total loss': 0.8055015280842781} | train loss {'Reaction outcome loss': 0.8210495984362017, 'Total loss': 0.8210495984362017}
2022-11-18 01:58:55,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:55,932 INFO:     Epoch: 43
2022-11-18 01:58:56,766 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7818707789887082, 'Total loss': 0.7818707789887082} | train loss {'Reaction outcome loss': 0.8195353196032585, 'Total loss': 0.8195353196032585}
2022-11-18 01:58:56,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:56,766 INFO:     Epoch: 44
2022-11-18 01:58:57,576 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8082200092348185, 'Total loss': 0.8082200092348185} | train loss {'Reaction outcome loss': 0.821359658073033, 'Total loss': 0.821359658073033}
2022-11-18 01:58:57,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:57,576 INFO:     Epoch: 45
2022-11-18 01:58:58,385 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7868986678394404, 'Total loss': 0.7868986678394404} | train loss {'Reaction outcome loss': 0.8223389772878539, 'Total loss': 0.8223389772878539}
2022-11-18 01:58:58,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:58,386 INFO:     Epoch: 46
2022-11-18 01:58:59,214 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7878355370326475, 'Total loss': 0.7878355370326475} | train loss {'Reaction outcome loss': 0.8198690904724982, 'Total loss': 0.8198690904724982}
2022-11-18 01:58:59,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:58:59,214 INFO:     Epoch: 47
2022-11-18 01:59:00,007 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7758760960264639, 'Total loss': 0.7758760960264639} | train loss {'Reaction outcome loss': 0.8211123529941805, 'Total loss': 0.8211123529941805}
2022-11-18 01:59:00,007 INFO:     Found new best model at epoch 47
2022-11-18 01:59:00,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:00,008 INFO:     Epoch: 48
2022-11-18 01:59:00,823 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7835013629360632, 'Total loss': 0.7835013629360632} | train loss {'Reaction outcome loss': 0.8192548044626752, 'Total loss': 0.8192548044626752}
2022-11-18 01:59:00,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:00,824 INFO:     Epoch: 49
2022-11-18 01:59:01,621 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.805223093114116, 'Total loss': 0.805223093114116} | train loss {'Reaction outcome loss': 0.8221685095660148, 'Total loss': 0.8221685095660148}
2022-11-18 01:59:01,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:01,621 INFO:     Epoch: 50
2022-11-18 01:59:02,441 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7823026234453375, 'Total loss': 0.7823026234453375} | train loss {'Reaction outcome loss': 0.8173555112894504, 'Total loss': 0.8173555112894504}
2022-11-18 01:59:02,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:02,441 INFO:     Epoch: 51
2022-11-18 01:59:03,228 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7915639186447317, 'Total loss': 0.7915639186447317} | train loss {'Reaction outcome loss': 0.8204343923397602, 'Total loss': 0.8204343923397602}
2022-11-18 01:59:03,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:03,228 INFO:     Epoch: 52
2022-11-18 01:59:04,051 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8099693899804895, 'Total loss': 0.8099693899804895} | train loss {'Reaction outcome loss': 0.8221063599471123, 'Total loss': 0.8221063599471123}
2022-11-18 01:59:04,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:04,051 INFO:     Epoch: 53
2022-11-18 01:59:04,847 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.791381801393899, 'Total loss': 0.791381801393899} | train loss {'Reaction outcome loss': 0.8217552053111215, 'Total loss': 0.8217552053111215}
2022-11-18 01:59:04,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:04,847 INFO:     Epoch: 54
2022-11-18 01:59:05,650 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7949986362999136, 'Total loss': 0.7949986362999136} | train loss {'Reaction outcome loss': 0.8222001131263471, 'Total loss': 0.8222001131263471}
2022-11-18 01:59:05,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:05,650 INFO:     Epoch: 55
2022-11-18 01:59:06,474 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7922606393694878, 'Total loss': 0.7922606393694878} | train loss {'Reaction outcome loss': 0.8236981712041362, 'Total loss': 0.8236981712041362}
2022-11-18 01:59:06,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:06,474 INFO:     Epoch: 56
2022-11-18 01:59:07,272 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7874490239403464, 'Total loss': 0.7874490239403464} | train loss {'Reaction outcome loss': 0.8281338458820697, 'Total loss': 0.8281338458820697}
2022-11-18 01:59:07,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:07,274 INFO:     Epoch: 57
2022-11-18 01:59:08,098 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7890765416351232, 'Total loss': 0.7890765416351232} | train loss {'Reaction outcome loss': 0.8194644757576527, 'Total loss': 0.8194644757576527}
2022-11-18 01:59:08,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:08,098 INFO:     Epoch: 58
2022-11-18 01:59:08,886 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7882041876966303, 'Total loss': 0.7882041876966303} | train loss {'Reaction outcome loss': 0.8166586416623285, 'Total loss': 0.8166586416623285}
2022-11-18 01:59:08,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:08,886 INFO:     Epoch: 59
2022-11-18 01:59:09,695 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7825625870715488, 'Total loss': 0.7825625870715488} | train loss {'Reaction outcome loss': 0.821791929463225, 'Total loss': 0.821791929463225}
2022-11-18 01:59:09,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:09,695 INFO:     Epoch: 60
2022-11-18 01:59:10,502 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7785924544388597, 'Total loss': 0.7785924544388597} | train loss {'Reaction outcome loss': 0.8234247490763664, 'Total loss': 0.8234247490763664}
2022-11-18 01:59:10,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:10,502 INFO:     Epoch: 61
2022-11-18 01:59:11,316 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7834057658910751, 'Total loss': 0.7834057658910751} | train loss {'Reaction outcome loss': 0.8232891337285119, 'Total loss': 0.8232891337285119}
2022-11-18 01:59:11,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:11,317 INFO:     Epoch: 62
2022-11-18 01:59:12,129 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7905955368822272, 'Total loss': 0.7905955368822272} | train loss {'Reaction outcome loss': 0.8177433494598635, 'Total loss': 0.8177433494598635}
2022-11-18 01:59:12,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:12,129 INFO:     Epoch: 63
2022-11-18 01:59:12,940 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7817723107608882, 'Total loss': 0.7817723107608882} | train loss {'Reaction outcome loss': 0.8175240764694829, 'Total loss': 0.8175240764694829}
2022-11-18 01:59:12,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:12,940 INFO:     Epoch: 64
2022-11-18 01:59:13,755 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7932577377015894, 'Total loss': 0.7932577377015894} | train loss {'Reaction outcome loss': 0.8207870051264763, 'Total loss': 0.8207870051264763}
2022-11-18 01:59:13,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:13,756 INFO:     Epoch: 65
2022-11-18 01:59:14,596 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7894623726606369, 'Total loss': 0.7894623726606369} | train loss {'Reaction outcome loss': 0.8244089011944109, 'Total loss': 0.8244089011944109}
2022-11-18 01:59:14,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:14,597 INFO:     Epoch: 66
2022-11-18 01:59:15,387 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7767762006683783, 'Total loss': 0.7767762006683783} | train loss {'Reaction outcome loss': 0.8202782118272397, 'Total loss': 0.8202782118272397}
2022-11-18 01:59:15,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:15,388 INFO:     Epoch: 67
2022-11-18 01:59:16,189 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.777639741924676, 'Total loss': 0.777639741924676} | train loss {'Reaction outcome loss': 0.8219826817512512, 'Total loss': 0.8219826817512512}
2022-11-18 01:59:16,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:16,189 INFO:     Epoch: 68
2022-11-18 01:59:17,024 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7961687140844085, 'Total loss': 0.7961687140844085} | train loss {'Reaction outcome loss': 0.8179006044182086, 'Total loss': 0.8179006044182086}
2022-11-18 01:59:17,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:17,025 INFO:     Epoch: 69
2022-11-18 01:59:17,871 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8084990917281671, 'Total loss': 0.8084990917281671} | train loss {'Reaction outcome loss': 0.8225197238066504, 'Total loss': 0.8225197238066504}
2022-11-18 01:59:17,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:17,872 INFO:     Epoch: 70
2022-11-18 01:59:18,686 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7942088056694377, 'Total loss': 0.7942088056694377} | train loss {'Reaction outcome loss': 0.8234200597770752, 'Total loss': 0.8234200597770752}
2022-11-18 01:59:18,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:18,686 INFO:     Epoch: 71
2022-11-18 01:59:19,497 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.780109511857683, 'Total loss': 0.780109511857683} | train loss {'Reaction outcome loss': 0.8218836718268933, 'Total loss': 0.8218836718268933}
2022-11-18 01:59:19,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:19,497 INFO:     Epoch: 72
2022-11-18 01:59:20,288 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7956013991074129, 'Total loss': 0.7956013991074129} | train loss {'Reaction outcome loss': 0.8153349510844676, 'Total loss': 0.8153349510844676}
2022-11-18 01:59:20,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:20,288 INFO:     Epoch: 73
2022-11-18 01:59:21,075 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7833920656280084, 'Total loss': 0.7833920656280084} | train loss {'Reaction outcome loss': 0.8159216537831291, 'Total loss': 0.8159216537831291}
2022-11-18 01:59:21,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:21,075 INFO:     Epoch: 74
2022-11-18 01:59:21,879 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8094175146384672, 'Total loss': 0.8094175146384672} | train loss {'Reaction outcome loss': 0.8229667127372757, 'Total loss': 0.8229667127372757}
2022-11-18 01:59:21,879 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:21,880 INFO:     Epoch: 75
2022-11-18 01:59:22,688 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8165840459140864, 'Total loss': 0.8165840459140864} | train loss {'Reaction outcome loss': 0.8210877693228184, 'Total loss': 0.8210877693228184}
2022-11-18 01:59:22,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:22,688 INFO:     Epoch: 76
2022-11-18 01:59:23,491 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7877632128921422, 'Total loss': 0.7877632128921422} | train loss {'Reaction outcome loss': 0.821591236898976, 'Total loss': 0.821591236898976}
2022-11-18 01:59:23,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:23,491 INFO:     Epoch: 77
2022-11-18 01:59:24,325 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7860806117003615, 'Total loss': 0.7860806117003615} | train loss {'Reaction outcome loss': 0.8223493797404151, 'Total loss': 0.8223493797404151}
2022-11-18 01:59:24,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:24,325 INFO:     Epoch: 78
2022-11-18 01:59:25,090 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7902733155272224, 'Total loss': 0.7902733155272224} | train loss {'Reaction outcome loss': 0.8211972558450314, 'Total loss': 0.8211972558450314}
2022-11-18 01:59:25,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:25,090 INFO:     Epoch: 79
2022-11-18 01:59:25,873 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7929630516604944, 'Total loss': 0.7929630516604944} | train loss {'Reaction outcome loss': 0.8234593128004382, 'Total loss': 0.8234593128004382}
2022-11-18 01:59:25,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:25,874 INFO:     Epoch: 80
2022-11-18 01:59:26,685 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7923865507949482, 'Total loss': 0.7923865507949482} | train loss {'Reaction outcome loss': 0.8239987593504691, 'Total loss': 0.8239987593504691}
2022-11-18 01:59:26,685 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:26,685 INFO:     Epoch: 81
2022-11-18 01:59:27,488 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8001187443733215, 'Total loss': 0.8001187443733215} | train loss {'Reaction outcome loss': 0.816180509304808, 'Total loss': 0.816180509304808}
2022-11-18 01:59:27,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:27,488 INFO:     Epoch: 82
2022-11-18 01:59:28,240 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7983490032228556, 'Total loss': 0.7983490032228556} | train loss {'Reaction outcome loss': 0.8253139970043013, 'Total loss': 0.8253139970043013}
2022-11-18 01:59:28,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:28,240 INFO:     Epoch: 83
2022-11-18 01:59:29,055 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7997743467038329, 'Total loss': 0.7997743467038329} | train loss {'Reaction outcome loss': 0.816545893828715, 'Total loss': 0.816545893828715}
2022-11-18 01:59:29,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:29,055 INFO:     Epoch: 84
2022-11-18 01:59:29,877 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7802706042473967, 'Total loss': 0.7802706042473967} | train loss {'Reaction outcome loss': 0.8194340675348236, 'Total loss': 0.8194340675348236}
2022-11-18 01:59:29,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:29,877 INFO:     Epoch: 85
2022-11-18 01:59:30,726 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7915370173074983, 'Total loss': 0.7915370173074983} | train loss {'Reaction outcome loss': 0.824129895457337, 'Total loss': 0.824129895457337}
2022-11-18 01:59:30,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:30,726 INFO:     Epoch: 86
2022-11-18 01:59:31,559 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7970492203127254, 'Total loss': 0.7970492203127254} | train loss {'Reaction outcome loss': 0.8199791356680854, 'Total loss': 0.8199791356680854}
2022-11-18 01:59:31,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:31,559 INFO:     Epoch: 87
2022-11-18 01:59:32,349 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.79249792071906, 'Total loss': 0.79249792071906} | train loss {'Reaction outcome loss': 0.8186111582383033, 'Total loss': 0.8186111582383033}
2022-11-18 01:59:32,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:32,349 INFO:     Epoch: 88
2022-11-18 01:59:33,181 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7797933918508616, 'Total loss': 0.7797933918508616} | train loss {'Reaction outcome loss': 0.8181130378957717, 'Total loss': 0.8181130378957717}
2022-11-18 01:59:33,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:33,182 INFO:     Epoch: 89
2022-11-18 01:59:33,973 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7907672300934792, 'Total loss': 0.7907672300934792} | train loss {'Reaction outcome loss': 0.8199473942720121, 'Total loss': 0.8199473942720121}
2022-11-18 01:59:33,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:33,973 INFO:     Epoch: 90
2022-11-18 01:59:34,750 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8186151453039863, 'Total loss': 0.8186151453039863} | train loss {'Reaction outcome loss': 0.819677488818284, 'Total loss': 0.819677488818284}
2022-11-18 01:59:34,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:34,750 INFO:     Epoch: 91
2022-11-18 01:59:35,571 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8088431730866432, 'Total loss': 0.8088431730866432} | train loss {'Reaction outcome loss': 0.8254737989796747, 'Total loss': 0.8254737989796747}
2022-11-18 01:59:35,571 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:35,571 INFO:     Epoch: 92
2022-11-18 01:59:36,395 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7923942309888926, 'Total loss': 0.7923942309888926} | train loss {'Reaction outcome loss': 0.8205503182065103, 'Total loss': 0.8205503182065103}
2022-11-18 01:59:36,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:36,395 INFO:     Epoch: 93
2022-11-18 01:59:37,197 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7711972960016944, 'Total loss': 0.7711972960016944} | train loss {'Reaction outcome loss': 0.821451187494301, 'Total loss': 0.821451187494301}
2022-11-18 01:59:37,198 INFO:     Found new best model at epoch 93
2022-11-18 01:59:37,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:37,198 INFO:     Epoch: 94
2022-11-18 01:59:38,034 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7889221615412019, 'Total loss': 0.7889221615412019} | train loss {'Reaction outcome loss': 0.8220301996315679, 'Total loss': 0.8220301996315679}
2022-11-18 01:59:38,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:38,035 INFO:     Epoch: 95
2022-11-18 01:59:38,864 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7769818156957626, 'Total loss': 0.7769818156957626} | train loss {'Reaction outcome loss': 0.8232933191522476, 'Total loss': 0.8232933191522476}
2022-11-18 01:59:38,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:38,864 INFO:     Epoch: 96
2022-11-18 01:59:39,662 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7735849977894262, 'Total loss': 0.7735849977894262} | train loss {'Reaction outcome loss': 0.8206970621981928, 'Total loss': 0.8206970621981928}
2022-11-18 01:59:39,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:39,662 INFO:     Epoch: 97
2022-11-18 01:59:40,488 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7896254523233934, 'Total loss': 0.7896254523233934} | train loss {'Reaction outcome loss': 0.8227107039382381, 'Total loss': 0.8227107039382381}
2022-11-18 01:59:40,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:40,488 INFO:     Epoch: 98
2022-11-18 01:59:41,287 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8081564605236053, 'Total loss': 0.8081564605236053} | train loss {'Reaction outcome loss': 0.8207185019648844, 'Total loss': 0.8207185019648844}
2022-11-18 01:59:41,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:41,288 INFO:     Epoch: 99
2022-11-18 01:59:42,124 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7918810797008601, 'Total loss': 0.7918810797008601} | train loss {'Reaction outcome loss': 0.8183211269638231, 'Total loss': 0.8183211269638231}
2022-11-18 01:59:42,124 INFO:     Best model found after epoch 94 of 100.
2022-11-18 01:59:42,124 INFO:   Done with stage: TRAINING
2022-11-18 01:59:42,124 INFO:   Starting stage: EVALUATION
2022-11-18 01:59:42,245 INFO:   Done with stage: EVALUATION
2022-11-18 01:59:42,245 INFO:   Leaving out SEQ value Fold_9
2022-11-18 01:59:42,259 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 01:59:42,259 INFO:   Starting stage: FEATURE SCALING
2022-11-18 01:59:42,935 INFO:   Done with stage: FEATURE SCALING
2022-11-18 01:59:42,935 INFO:   Starting stage: SCALING TARGETS
2022-11-18 01:59:43,005 INFO:   Done with stage: SCALING TARGETS
2022-11-18 01:59:43,005 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:59:43,005 INFO:     No hyperparam tuning for this model
2022-11-18 01:59:43,005 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 01:59:43,005 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 01:59:43,006 INFO:     None feature selector for col prot
2022-11-18 01:59:43,006 INFO:     None feature selector for col prot
2022-11-18 01:59:43,006 INFO:     None feature selector for col prot
2022-11-18 01:59:43,007 INFO:     None feature selector for col chem
2022-11-18 01:59:43,007 INFO:     None feature selector for col chem
2022-11-18 01:59:43,007 INFO:     None feature selector for col chem
2022-11-18 01:59:43,007 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 01:59:43,007 INFO:   Starting stage: BUILD MODEL
2022-11-18 01:59:43,009 INFO:     Number of params in model 168571
2022-11-18 01:59:43,012 INFO:   Done with stage: BUILD MODEL
2022-11-18 01:59:43,012 INFO:   Starting stage: TRAINING
2022-11-18 01:59:43,070 INFO:     Val loss before train {'Reaction outcome loss': 1.0247766836123033, 'Total loss': 1.0247766836123033}
2022-11-18 01:59:43,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:43,070 INFO:     Epoch: 0
2022-11-18 01:59:43,920 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8742449039762671, 'Total loss': 0.8742449039762671} | train loss {'Reaction outcome loss': 0.8786808929881271, 'Total loss': 0.8786808929881271}
2022-11-18 01:59:43,920 INFO:     Found new best model at epoch 0
2022-11-18 01:59:43,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:43,921 INFO:     Epoch: 1
2022-11-18 01:59:44,681 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8672587207772515, 'Total loss': 0.8672587207772515} | train loss {'Reaction outcome loss': 0.8431580172509563, 'Total loss': 0.8431580172509563}
2022-11-18 01:59:44,682 INFO:     Found new best model at epoch 1
2022-11-18 01:59:44,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:44,683 INFO:     Epoch: 2
2022-11-18 01:59:45,515 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.853845399889079, 'Total loss': 0.853845399889079} | train loss {'Reaction outcome loss': 0.8378533129789392, 'Total loss': 0.8378533129789392}
2022-11-18 01:59:45,515 INFO:     Found new best model at epoch 2
2022-11-18 01:59:45,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:45,516 INFO:     Epoch: 3
2022-11-18 01:59:46,321 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8662527501583099, 'Total loss': 0.8662527501583099} | train loss {'Reaction outcome loss': 0.8339497921418171, 'Total loss': 0.8339497921418171}
2022-11-18 01:59:46,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:46,322 INFO:     Epoch: 4
2022-11-18 01:59:47,124 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8644930693236265, 'Total loss': 0.8644930693236265} | train loss {'Reaction outcome loss': 0.8288932480374162, 'Total loss': 0.8288932480374162}
2022-11-18 01:59:47,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:47,124 INFO:     Epoch: 5
2022-11-18 01:59:47,931 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8652508462017233, 'Total loss': 0.8652508462017233} | train loss {'Reaction outcome loss': 0.8240977484352735, 'Total loss': 0.8240977484352735}
2022-11-18 01:59:47,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:47,932 INFO:     Epoch: 6
2022-11-18 01:59:48,717 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8449108871546659, 'Total loss': 0.8449108871546659} | train loss {'Reaction outcome loss': 0.8250529476574489, 'Total loss': 0.8250529476574489}
2022-11-18 01:59:48,717 INFO:     Found new best model at epoch 6
2022-11-18 01:59:48,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:48,718 INFO:     Epoch: 7
2022-11-18 01:59:49,560 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.846991000358354, 'Total loss': 0.846991000358354} | train loss {'Reaction outcome loss': 0.821174989427839, 'Total loss': 0.821174989427839}
2022-11-18 01:59:49,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:49,560 INFO:     Epoch: 8
2022-11-18 01:59:50,358 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8673567446795377, 'Total loss': 0.8673567446795377} | train loss {'Reaction outcome loss': 0.8248925695613939, 'Total loss': 0.8248925695613939}
2022-11-18 01:59:50,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:50,359 INFO:     Epoch: 9
2022-11-18 01:59:51,149 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8498467816547914, 'Total loss': 0.8498467816547914} | train loss {'Reaction outcome loss': 0.8211220518666871, 'Total loss': 0.8211220518666871}
2022-11-18 01:59:51,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:51,149 INFO:     Epoch: 10
2022-11-18 01:59:51,980 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8511520976370032, 'Total loss': 0.8511520976370032} | train loss {'Reaction outcome loss': 0.8176590645799832, 'Total loss': 0.8176590645799832}
2022-11-18 01:59:51,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:51,980 INFO:     Epoch: 11
2022-11-18 01:59:52,749 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8498619429089806, 'Total loss': 0.8498619429089806} | train loss {'Reaction outcome loss': 0.8234276187663175, 'Total loss': 0.8234276187663175}
2022-11-18 01:59:52,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:52,749 INFO:     Epoch: 12
2022-11-18 01:59:53,547 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8347477858716791, 'Total loss': 0.8347477858716791} | train loss {'Reaction outcome loss': 0.8223834209296168, 'Total loss': 0.8223834209296168}
2022-11-18 01:59:53,547 INFO:     Found new best model at epoch 12
2022-11-18 01:59:53,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:53,548 INFO:     Epoch: 13
2022-11-18 01:59:54,333 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8586557358503342, 'Total loss': 0.8586557358503342} | train loss {'Reaction outcome loss': 0.8127408964293343, 'Total loss': 0.8127408964293343}
2022-11-18 01:59:54,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:54,334 INFO:     Epoch: 14
2022-11-18 01:59:55,143 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8466817560521039, 'Total loss': 0.8466817560521039} | train loss {'Reaction outcome loss': 0.8236055198980837, 'Total loss': 0.8236055198980837}
2022-11-18 01:59:55,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:55,144 INFO:     Epoch: 15
2022-11-18 01:59:55,971 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8460191522132267, 'Total loss': 0.8460191522132267} | train loss {'Reaction outcome loss': 0.8206430182165029, 'Total loss': 0.8206430182165029}
2022-11-18 01:59:55,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:55,971 INFO:     Epoch: 16
2022-11-18 01:59:56,841 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8320772011171688, 'Total loss': 0.8320772011171688} | train loss {'Reaction outcome loss': 0.818660138577831, 'Total loss': 0.818660138577831}
2022-11-18 01:59:56,842 INFO:     Found new best model at epoch 16
2022-11-18 01:59:56,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:56,843 INFO:     Epoch: 17
2022-11-18 01:59:57,640 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8502720337022435, 'Total loss': 0.8502720337022435} | train loss {'Reaction outcome loss': 0.8215850247412312, 'Total loss': 0.8215850247412312}
2022-11-18 01:59:57,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:57,640 INFO:     Epoch: 18
2022-11-18 01:59:58,450 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8383229950612242, 'Total loss': 0.8383229950612242} | train loss {'Reaction outcome loss': 0.8153905456163445, 'Total loss': 0.8153905456163445}
2022-11-18 01:59:58,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:58,451 INFO:     Epoch: 19
2022-11-18 01:59:59,249 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8459817198189822, 'Total loss': 0.8459817198189822} | train loss {'Reaction outcome loss': 0.8155061517442975, 'Total loss': 0.8155061517442975}
2022-11-18 01:59:59,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 01:59:59,250 INFO:     Epoch: 20
2022-11-18 02:00:00,061 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8453766635873101, 'Total loss': 0.8453766635873101} | train loss {'Reaction outcome loss': 0.8152157520761295, 'Total loss': 0.8152157520761295}
2022-11-18 02:00:00,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:00,061 INFO:     Epoch: 21
2022-11-18 02:00:00,837 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8488208231600848, 'Total loss': 0.8488208231600848} | train loss {'Reaction outcome loss': 0.8178862842978264, 'Total loss': 0.8178862842978264}
2022-11-18 02:00:00,837 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:00,837 INFO:     Epoch: 22
2022-11-18 02:00:01,668 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8510428057475523, 'Total loss': 0.8510428057475523} | train loss {'Reaction outcome loss': 0.8179118596777624, 'Total loss': 0.8179118596777624}
2022-11-18 02:00:01,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:01,669 INFO:     Epoch: 23
2022-11-18 02:00:02,485 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.838272518732331, 'Total loss': 0.838272518732331} | train loss {'Reaction outcome loss': 0.8203408412787379, 'Total loss': 0.8203408412787379}
2022-11-18 02:00:02,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:02,486 INFO:     Epoch: 24
2022-11-18 02:00:03,311 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8456781926480207, 'Total loss': 0.8456781926480207} | train loss {'Reaction outcome loss': 0.8125750488164474, 'Total loss': 0.8125750488164474}
2022-11-18 02:00:03,311 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:03,311 INFO:     Epoch: 25
2022-11-18 02:00:04,075 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8567166490988298, 'Total loss': 0.8567166490988298} | train loss {'Reaction outcome loss': 0.8181084148737849, 'Total loss': 0.8181084148737849}
2022-11-18 02:00:04,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:04,075 INFO:     Epoch: 26
2022-11-18 02:00:04,859 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8296935802156274, 'Total loss': 0.8296935802156274} | train loss {'Reaction outcome loss': 0.8162441279206957, 'Total loss': 0.8162441279206957}
2022-11-18 02:00:04,859 INFO:     Found new best model at epoch 26
2022-11-18 02:00:04,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:04,860 INFO:     Epoch: 27
2022-11-18 02:00:05,644 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.862963317470117, 'Total loss': 0.862963317470117} | train loss {'Reaction outcome loss': 0.8148308753967285, 'Total loss': 0.8148308753967285}
2022-11-18 02:00:05,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:05,644 INFO:     Epoch: 28
2022-11-18 02:00:06,464 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8475958799773996, 'Total loss': 0.8475958799773996} | train loss {'Reaction outcome loss': 0.8183491268936469, 'Total loss': 0.8183491268936469}
2022-11-18 02:00:06,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:06,464 INFO:     Epoch: 29
2022-11-18 02:00:07,231 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8499314297329296, 'Total loss': 0.8499314297329296} | train loss {'Reaction outcome loss': 0.8177790915479466, 'Total loss': 0.8177790915479466}
2022-11-18 02:00:07,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:07,231 INFO:     Epoch: 30
2022-11-18 02:00:08,011 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8671956461938944, 'Total loss': 0.8671956461938944} | train loss {'Reaction outcome loss': 0.8135798564979009, 'Total loss': 0.8135798564979009}
2022-11-18 02:00:08,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:08,011 INFO:     Epoch: 31
2022-11-18 02:00:08,805 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8456219400871884, 'Total loss': 0.8456219400871884} | train loss {'Reaction outcome loss': 0.8155520599715563, 'Total loss': 0.8155520599715563}
2022-11-18 02:00:08,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:08,805 INFO:     Epoch: 32
2022-11-18 02:00:09,589 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8450656072659926, 'Total loss': 0.8450656072659926} | train loss {'Reaction outcome loss': 0.8138150475463088, 'Total loss': 0.8138150475463088}
2022-11-18 02:00:09,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:09,591 INFO:     Epoch: 33
2022-11-18 02:00:10,373 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8555468849160455, 'Total loss': 0.8555468849160455} | train loss {'Reaction outcome loss': 0.8173090086907756, 'Total loss': 0.8173090086907756}
2022-11-18 02:00:10,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:10,374 INFO:     Epoch: 34
2022-11-18 02:00:11,149 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8614001098004255, 'Total loss': 0.8614001098004255} | train loss {'Reaction outcome loss': 0.8187740396480171, 'Total loss': 0.8187740396480171}
2022-11-18 02:00:11,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:11,150 INFO:     Epoch: 35
2022-11-18 02:00:11,958 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8452671048316088, 'Total loss': 0.8452671048316088} | train loss {'Reaction outcome loss': 0.8140639985094265, 'Total loss': 0.8140639985094265}
2022-11-18 02:00:11,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:11,958 INFO:     Epoch: 36
2022-11-18 02:00:12,725 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.838075306605209, 'Total loss': 0.838075306605209} | train loss {'Reaction outcome loss': 0.8153524688311986, 'Total loss': 0.8153524688311986}
2022-11-18 02:00:12,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:12,725 INFO:     Epoch: 37
2022-11-18 02:00:13,511 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8679711642590436, 'Total loss': 0.8679711642590436} | train loss {'Reaction outcome loss': 0.8090121204755745, 'Total loss': 0.8090121204755745}
2022-11-18 02:00:13,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:13,511 INFO:     Epoch: 38
2022-11-18 02:00:14,287 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8396036502989855, 'Total loss': 0.8396036502989855} | train loss {'Reaction outcome loss': 0.8127771108734364, 'Total loss': 0.8127771108734364}
2022-11-18 02:00:14,288 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:14,288 INFO:     Epoch: 39
2022-11-18 02:00:15,055 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8586503301154483, 'Total loss': 0.8586503301154483} | train loss {'Reaction outcome loss': 0.8075593626012607, 'Total loss': 0.8075593626012607}
2022-11-18 02:00:15,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:15,055 INFO:     Epoch: 40
2022-11-18 02:00:15,829 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8520315343683417, 'Total loss': 0.8520315343683417} | train loss {'Reaction outcome loss': 0.8112763601906445, 'Total loss': 0.8112763601906445}
2022-11-18 02:00:15,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:15,830 INFO:     Epoch: 41
2022-11-18 02:00:16,593 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8474957543340597, 'Total loss': 0.8474957543340597} | train loss {'Reaction outcome loss': 0.8112746531866035, 'Total loss': 0.8112746531866035}
2022-11-18 02:00:16,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:16,594 INFO:     Epoch: 42
2022-11-18 02:00:17,357 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8382895229892298, 'Total loss': 0.8382895229892298} | train loss {'Reaction outcome loss': 0.8114116592066628, 'Total loss': 0.8114116592066628}
2022-11-18 02:00:17,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:17,358 INFO:     Epoch: 43
2022-11-18 02:00:18,101 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8387643315575339, 'Total loss': 0.8387643315575339} | train loss {'Reaction outcome loss': 0.8119420462725114, 'Total loss': 0.8119420462725114}
2022-11-18 02:00:18,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:18,101 INFO:     Epoch: 44
2022-11-18 02:00:18,919 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8366230380806056, 'Total loss': 0.8366230380806056} | train loss {'Reaction outcome loss': 0.8070989835019015, 'Total loss': 0.8070989835019015}
2022-11-18 02:00:18,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:18,919 INFO:     Epoch: 45
2022-11-18 02:00:19,703 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8565682714635675, 'Total loss': 0.8565682714635675} | train loss {'Reaction outcome loss': 0.8157107944391212, 'Total loss': 0.8157107944391212}
2022-11-18 02:00:19,703 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:19,703 INFO:     Epoch: 46
2022-11-18 02:00:20,467 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.840503379702568, 'Total loss': 0.840503379702568} | train loss {'Reaction outcome loss': 0.8088791822900577, 'Total loss': 0.8088791822900577}
2022-11-18 02:00:20,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:20,467 INFO:     Epoch: 47
2022-11-18 02:00:21,246 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.825288550420241, 'Total loss': 0.825288550420241} | train loss {'Reaction outcome loss': 0.8080486355995645, 'Total loss': 0.8080486355995645}
2022-11-18 02:00:21,247 INFO:     Found new best model at epoch 47
2022-11-18 02:00:21,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:21,247 INFO:     Epoch: 48
2022-11-18 02:00:22,019 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8451793288642709, 'Total loss': 0.8451793288642709} | train loss {'Reaction outcome loss': 0.8142749264532206, 'Total loss': 0.8142749264532206}
2022-11-18 02:00:22,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:22,019 INFO:     Epoch: 49
2022-11-18 02:00:22,778 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8387285484509035, 'Total loss': 0.8387285484509035} | train loss {'Reaction outcome loss': 0.8102556866042468, 'Total loss': 0.8102556866042468}
2022-11-18 02:00:22,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:22,778 INFO:     Epoch: 50
2022-11-18 02:00:23,568 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8330878954042088, 'Total loss': 0.8330878954042088} | train loss {'Reaction outcome loss': 0.8096720430315757, 'Total loss': 0.8096720430315757}
2022-11-18 02:00:23,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:23,569 INFO:     Epoch: 51
2022-11-18 02:00:24,355 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.847909382798455, 'Total loss': 0.847909382798455} | train loss {'Reaction outcome loss': 0.806302128762615, 'Total loss': 0.806302128762615}
2022-11-18 02:00:24,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:24,356 INFO:     Epoch: 52
2022-11-18 02:00:25,151 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8533771722154184, 'Total loss': 0.8533771722154184} | train loss {'Reaction outcome loss': 0.8088079051095612, 'Total loss': 0.8088079051095612}
2022-11-18 02:00:25,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:25,151 INFO:     Epoch: 53
2022-11-18 02:00:25,927 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8296008875424211, 'Total loss': 0.8296008875424211} | train loss {'Reaction outcome loss': 0.8137337386608123, 'Total loss': 0.8137337386608123}
2022-11-18 02:00:25,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:25,928 INFO:     Epoch: 54
2022-11-18 02:00:26,696 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8562108108943159, 'Total loss': 0.8562108108943159} | train loss {'Reaction outcome loss': 0.8081118638418159, 'Total loss': 0.8081118638418159}
2022-11-18 02:00:26,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:26,696 INFO:     Epoch: 55
2022-11-18 02:00:27,454 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8288213583556089, 'Total loss': 0.8288213583556089} | train loss {'Reaction outcome loss': 0.8085315551684827, 'Total loss': 0.8085315551684827}
2022-11-18 02:00:27,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:27,454 INFO:     Epoch: 56
2022-11-18 02:00:28,228 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.836056416684931, 'Total loss': 0.836056416684931} | train loss {'Reaction outcome loss': 0.8118478864431381, 'Total loss': 0.8118478864431381}
2022-11-18 02:00:28,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:28,230 INFO:     Epoch: 57
2022-11-18 02:00:28,984 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8488175977360118, 'Total loss': 0.8488175977360118} | train loss {'Reaction outcome loss': 0.8118765170476875, 'Total loss': 0.8118765170476875}
2022-11-18 02:00:28,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:28,984 INFO:     Epoch: 58
2022-11-18 02:00:29,763 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.834346702830358, 'Total loss': 0.834346702830358} | train loss {'Reaction outcome loss': 0.8085524734185666, 'Total loss': 0.8085524734185666}
2022-11-18 02:00:29,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:29,763 INFO:     Epoch: 59
2022-11-18 02:00:30,515 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8763338747349653, 'Total loss': 0.8763338747349653} | train loss {'Reaction outcome loss': 0.8110401735013845, 'Total loss': 0.8110401735013845}
2022-11-18 02:00:30,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:30,515 INFO:     Epoch: 60
2022-11-18 02:00:31,287 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8406612873077393, 'Total loss': 0.8406612873077393} | train loss {'Reaction outcome loss': 0.807408170858208, 'Total loss': 0.807408170858208}
2022-11-18 02:00:31,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:31,288 INFO:     Epoch: 61
2022-11-18 02:00:32,078 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8488619137894023, 'Total loss': 0.8488619137894023} | train loss {'Reaction outcome loss': 0.811222015959876, 'Total loss': 0.811222015959876}
2022-11-18 02:00:32,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:32,078 INFO:     Epoch: 62
2022-11-18 02:00:32,882 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.831159620122476, 'Total loss': 0.831159620122476} | train loss {'Reaction outcome loss': 0.8070920316540465, 'Total loss': 0.8070920316540465}
2022-11-18 02:00:32,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:32,882 INFO:     Epoch: 63
2022-11-18 02:00:33,657 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8578268777240406, 'Total loss': 0.8578268777240406} | train loss {'Reaction outcome loss': 0.8104306427799925, 'Total loss': 0.8104306427799925}
2022-11-18 02:00:33,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:33,657 INFO:     Epoch: 64
2022-11-18 02:00:34,444 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8289573192596436, 'Total loss': 0.8289573192596436} | train loss {'Reaction outcome loss': 0.810528765041001, 'Total loss': 0.810528765041001}
2022-11-18 02:00:34,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:34,444 INFO:     Epoch: 65
2022-11-18 02:00:35,250 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8462709100408987, 'Total loss': 0.8462709100408987} | train loss {'Reaction outcome loss': 0.8047278438295636, 'Total loss': 0.8047278438295636}
2022-11-18 02:00:35,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:35,251 INFO:     Epoch: 66
2022-11-18 02:00:36,060 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8290209384127096, 'Total loss': 0.8290209384127096} | train loss {'Reaction outcome loss': 0.8129951868738446, 'Total loss': 0.8129951868738446}
2022-11-18 02:00:36,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:36,060 INFO:     Epoch: 67
2022-11-18 02:00:36,836 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8408413156867027, 'Total loss': 0.8408413156867027} | train loss {'Reaction outcome loss': 0.8014334791777086, 'Total loss': 0.8014334791777086}
2022-11-18 02:00:36,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:36,836 INFO:     Epoch: 68
2022-11-18 02:00:37,621 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8521859537471425, 'Total loss': 0.8521859537471425} | train loss {'Reaction outcome loss': 0.8086405514454355, 'Total loss': 0.8086405514454355}
2022-11-18 02:00:37,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:37,621 INFO:     Epoch: 69
2022-11-18 02:00:38,368 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8246865519745783, 'Total loss': 0.8246865519745783} | train loss {'Reaction outcome loss': 0.8103478494955569, 'Total loss': 0.8103478494955569}
2022-11-18 02:00:38,368 INFO:     Found new best model at epoch 69
2022-11-18 02:00:38,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:38,369 INFO:     Epoch: 70
2022-11-18 02:00:39,155 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8498497361486609, 'Total loss': 0.8498497361486609} | train loss {'Reaction outcome loss': 0.8109462273364164, 'Total loss': 0.8109462273364164}
2022-11-18 02:00:39,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:39,155 INFO:     Epoch: 71
2022-11-18 02:00:39,929 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8899067518385974, 'Total loss': 0.8899067518385974} | train loss {'Reaction outcome loss': 0.8071589090386215, 'Total loss': 0.8071589090386215}
2022-11-18 02:00:39,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:39,930 INFO:     Epoch: 72
2022-11-18 02:00:40,739 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8462444191629236, 'Total loss': 0.8462444191629236} | train loss {'Reaction outcome loss': 0.8124422952836874, 'Total loss': 0.8124422952836874}
2022-11-18 02:00:40,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:40,741 INFO:     Epoch: 73
2022-11-18 02:00:41,538 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8425550074739889, 'Total loss': 0.8425550074739889} | train loss {'Reaction outcome loss': 0.8062096836615582, 'Total loss': 0.8062096836615582}
2022-11-18 02:00:41,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:41,538 INFO:     Epoch: 74
2022-11-18 02:00:42,324 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8342530266805128, 'Total loss': 0.8342530266805128} | train loss {'Reaction outcome loss': 0.8077556696473336, 'Total loss': 0.8077556696473336}
2022-11-18 02:00:42,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:42,324 INFO:     Epoch: 75
2022-11-18 02:00:43,087 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8969008922576904, 'Total loss': 0.8969008922576904} | train loss {'Reaction outcome loss': 0.8069927405337898, 'Total loss': 0.8069927405337898}
2022-11-18 02:00:43,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:43,087 INFO:     Epoch: 76
2022-11-18 02:00:43,877 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8619686148383401, 'Total loss': 0.8619686148383401} | train loss {'Reaction outcome loss': 0.8074977809069108, 'Total loss': 0.8074977809069108}
2022-11-18 02:00:43,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:43,877 INFO:     Epoch: 77
2022-11-18 02:00:44,636 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8423429497263648, 'Total loss': 0.8423429497263648} | train loss {'Reaction outcome loss': 0.8101504532658323, 'Total loss': 0.8101504532658323}
2022-11-18 02:00:44,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:44,636 INFO:     Epoch: 78
2022-11-18 02:00:45,385 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.837281150574034, 'Total loss': 0.837281150574034} | train loss {'Reaction outcome loss': 0.809740774850456, 'Total loss': 0.809740774850456}
2022-11-18 02:00:45,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:45,385 INFO:     Epoch: 79
2022-11-18 02:00:46,204 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8563171144236218, 'Total loss': 0.8563171144236218} | train loss {'Reaction outcome loss': 0.8074369393441142, 'Total loss': 0.8074369393441142}
2022-11-18 02:00:46,204 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:46,204 INFO:     Epoch: 80
2022-11-18 02:00:46,968 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8479861637408083, 'Total loss': 0.8479861637408083} | train loss {'Reaction outcome loss': 0.8082870291203869, 'Total loss': 0.8082870291203869}
2022-11-18 02:00:46,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:46,969 INFO:     Epoch: 81
2022-11-18 02:00:47,740 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8558580863543532, 'Total loss': 0.8558580863543532} | train loss {'Reaction outcome loss': 0.8117502382823399, 'Total loss': 0.8117502382823399}
2022-11-18 02:00:47,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:47,740 INFO:     Epoch: 82
2022-11-18 02:00:48,564 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.83609850095077, 'Total loss': 0.83609850095077} | train loss {'Reaction outcome loss': 0.8100700313947639, 'Total loss': 0.8100700313947639}
2022-11-18 02:00:48,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:48,565 INFO:     Epoch: 83
2022-11-18 02:00:49,332 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8380566429008137, 'Total loss': 0.8380566429008137} | train loss {'Reaction outcome loss': 0.8057715704246443, 'Total loss': 0.8057715704246443}
2022-11-18 02:00:49,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:49,333 INFO:     Epoch: 84
2022-11-18 02:00:50,105 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8553731888532639, 'Total loss': 0.8553731888532639} | train loss {'Reaction outcome loss': 0.8053847284949556, 'Total loss': 0.8053847284949556}
2022-11-18 02:00:50,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:50,106 INFO:     Epoch: 85
2022-11-18 02:00:50,882 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8521853475408121, 'Total loss': 0.8521853475408121} | train loss {'Reaction outcome loss': 0.8079238378271765, 'Total loss': 0.8079238378271765}
2022-11-18 02:00:50,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:50,882 INFO:     Epoch: 86
2022-11-18 02:00:51,641 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.862750845876607, 'Total loss': 0.862750845876607} | train loss {'Reaction outcome loss': 0.8099120013567866, 'Total loss': 0.8099120013567866}
2022-11-18 02:00:51,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:51,642 INFO:     Epoch: 87
2022-11-18 02:00:52,425 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8442367592995818, 'Total loss': 0.8442367592995818} | train loss {'Reaction outcome loss': 0.8104226508919073, 'Total loss': 0.8104226508919073}
2022-11-18 02:00:52,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:52,426 INFO:     Epoch: 88
2022-11-18 02:00:53,208 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.836219923062758, 'Total loss': 0.836219923062758} | train loss {'Reaction outcome loss': 0.807542961653398, 'Total loss': 0.807542961653398}
2022-11-18 02:00:53,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:53,208 INFO:     Epoch: 89
2022-11-18 02:00:53,960 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8275956999171864, 'Total loss': 0.8275956999171864} | train loss {'Reaction outcome loss': 0.8089296722898678, 'Total loss': 0.8089296722898678}
2022-11-18 02:00:53,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:53,961 INFO:     Epoch: 90
2022-11-18 02:00:54,709 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8580107878554951, 'Total loss': 0.8580107878554951} | train loss {'Reaction outcome loss': 0.8084524979396742, 'Total loss': 0.8084524979396742}
2022-11-18 02:00:54,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:54,710 INFO:     Epoch: 91
2022-11-18 02:00:55,473 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.846139829267155, 'Total loss': 0.846139829267155} | train loss {'Reaction outcome loss': 0.8072034866225962, 'Total loss': 0.8072034866225962}
2022-11-18 02:00:55,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:55,474 INFO:     Epoch: 92
2022-11-18 02:00:56,243 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8531906360929663, 'Total loss': 0.8531906360929663} | train loss {'Reaction outcome loss': 0.8058261684009007, 'Total loss': 0.8058261684009007}
2022-11-18 02:00:56,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:56,244 INFO:     Epoch: 93
2022-11-18 02:00:57,020 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8318626718087629, 'Total loss': 0.8318626718087629} | train loss {'Reaction outcome loss': 0.805199820776375, 'Total loss': 0.805199820776375}
2022-11-18 02:00:57,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:57,020 INFO:     Epoch: 94
2022-11-18 02:00:57,781 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8509731313044374, 'Total loss': 0.8509731313044374} | train loss {'Reaction outcome loss': 0.8106869926258009, 'Total loss': 0.8106869926258009}
2022-11-18 02:00:57,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:57,781 INFO:     Epoch: 95
2022-11-18 02:00:58,564 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8595244478095662, 'Total loss': 0.8595244478095662} | train loss {'Reaction outcome loss': 0.8088815910475594, 'Total loss': 0.8088815910475594}
2022-11-18 02:00:58,565 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:58,565 INFO:     Epoch: 96
2022-11-18 02:00:59,339 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8496667878194288, 'Total loss': 0.8496667878194288} | train loss {'Reaction outcome loss': 0.8078406267020167, 'Total loss': 0.8078406267020167}
2022-11-18 02:00:59,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:00:59,340 INFO:     Epoch: 97
2022-11-18 02:01:00,149 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8395789983597669, 'Total loss': 0.8395789983597669} | train loss {'Reaction outcome loss': 0.810548712647691, 'Total loss': 0.810548712647691}
2022-11-18 02:01:00,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:00,149 INFO:     Epoch: 98
2022-11-18 02:01:00,929 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8457068712873892, 'Total loss': 0.8457068712873892} | train loss {'Reaction outcome loss': 0.8100498019432535, 'Total loss': 0.8100498019432535}
2022-11-18 02:01:00,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:00,929 INFO:     Epoch: 99
2022-11-18 02:01:01,692 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8299854306334798, 'Total loss': 0.8299854306334798} | train loss {'Reaction outcome loss': 0.8100873370559848, 'Total loss': 0.8100873370559848}
2022-11-18 02:01:01,692 INFO:     Best model found after epoch 70 of 100.
2022-11-18 02:01:01,692 INFO:   Done with stage: TRAINING
2022-11-18 02:01:01,692 INFO:   Starting stage: EVALUATION
2022-11-18 02:01:01,834 INFO:   Done with stage: EVALUATION
2022-11-18 02:01:01,845 INFO:   Leaving out SEQ value Fold_0
2022-11-18 02:01:01,859 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-18 02:01:01,859 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:01:02,520 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:01:02,520 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:01:02,589 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:01:02,589 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:01:02,589 INFO:     No hyperparam tuning for this model
2022-11-18 02:01:02,589 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:01:02,589 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:01:02,590 INFO:     None feature selector for col prot
2022-11-18 02:01:02,590 INFO:     None feature selector for col prot
2022-11-18 02:01:02,590 INFO:     None feature selector for col prot
2022-11-18 02:01:02,591 INFO:     None feature selector for col chem
2022-11-18 02:01:02,591 INFO:     None feature selector for col chem
2022-11-18 02:01:02,591 INFO:     None feature selector for col chem
2022-11-18 02:01:02,591 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:01:02,591 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:01:02,592 INFO:     Number of params in model 168571
2022-11-18 02:01:02,596 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:01:02,596 INFO:   Starting stage: TRAINING
2022-11-18 02:01:02,652 INFO:     Val loss before train {'Reaction outcome loss': 1.0232360848160678, 'Total loss': 1.0232360848160678}
2022-11-18 02:01:02,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:02,653 INFO:     Epoch: 0
2022-11-18 02:01:03,443 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8466561630714772, 'Total loss': 0.8466561630714772} | train loss {'Reaction outcome loss': 0.8827924642895089, 'Total loss': 0.8827924642895089}
2022-11-18 02:01:03,443 INFO:     Found new best model at epoch 0
2022-11-18 02:01:03,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:03,444 INFO:     Epoch: 1
2022-11-18 02:01:04,243 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8599222870760186, 'Total loss': 0.8599222870760186} | train loss {'Reaction outcome loss': 0.8473494663590291, 'Total loss': 0.8473494663590291}
2022-11-18 02:01:04,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:04,243 INFO:     Epoch: 2
2022-11-18 02:01:05,068 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8444035968115163, 'Total loss': 0.8444035968115163} | train loss {'Reaction outcome loss': 0.8444898110188421, 'Total loss': 0.8444898110188421}
2022-11-18 02:01:05,068 INFO:     Found new best model at epoch 2
2022-11-18 02:01:05,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:05,069 INFO:     Epoch: 3
2022-11-18 02:01:05,851 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.842608300752418, 'Total loss': 0.842608300752418} | train loss {'Reaction outcome loss': 0.8403285625772398, 'Total loss': 0.8403285625772398}
2022-11-18 02:01:05,851 INFO:     Found new best model at epoch 3
2022-11-18 02:01:05,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:05,852 INFO:     Epoch: 4
2022-11-18 02:01:06,617 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8407534832178161, 'Total loss': 0.8407534832178161} | train loss {'Reaction outcome loss': 0.8394987141011191, 'Total loss': 0.8394987141011191}
2022-11-18 02:01:06,617 INFO:     Found new best model at epoch 4
2022-11-18 02:01:06,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:06,618 INFO:     Epoch: 5
2022-11-18 02:01:07,403 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8643473899641703, 'Total loss': 0.8643473899641703} | train loss {'Reaction outcome loss': 0.8346346305286299, 'Total loss': 0.8346346305286299}
2022-11-18 02:01:07,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:07,403 INFO:     Epoch: 6
2022-11-18 02:01:08,153 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8447962264681972, 'Total loss': 0.8447962264681972} | train loss {'Reaction outcome loss': 0.8290811819864101, 'Total loss': 0.8290811819864101}
2022-11-18 02:01:08,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:08,153 INFO:     Epoch: 7
2022-11-18 02:01:08,936 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8263956945995952, 'Total loss': 0.8263956945995952} | train loss {'Reaction outcome loss': 0.8315829135111121, 'Total loss': 0.8315829135111121}
2022-11-18 02:01:08,937 INFO:     Found new best model at epoch 7
2022-11-18 02:01:08,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:08,937 INFO:     Epoch: 8
2022-11-18 02:01:09,728 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8499207295650659, 'Total loss': 0.8499207295650659} | train loss {'Reaction outcome loss': 0.8322538643098268, 'Total loss': 0.8322538643098268}
2022-11-18 02:01:09,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:09,728 INFO:     Epoch: 9
2022-11-18 02:01:10,491 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8399620873983517, 'Total loss': 0.8399620873983517} | train loss {'Reaction outcome loss': 0.8254637550867971, 'Total loss': 0.8254637550867971}
2022-11-18 02:01:10,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:10,491 INFO:     Epoch: 10
2022-11-18 02:01:11,249 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8248866242031718, 'Total loss': 0.8248866242031718} | train loss {'Reaction outcome loss': 0.8220470790736011, 'Total loss': 0.8220470790736011}
2022-11-18 02:01:11,249 INFO:     Found new best model at epoch 10
2022-11-18 02:01:11,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:11,250 INFO:     Epoch: 11
2022-11-18 02:01:12,020 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8439179547997409, 'Total loss': 0.8439179547997409} | train loss {'Reaction outcome loss': 0.8253090944690783, 'Total loss': 0.8253090944690783}
2022-11-18 02:01:12,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:12,021 INFO:     Epoch: 12
2022-11-18 02:01:12,812 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8537469984487046, 'Total loss': 0.8537469984487046} | train loss {'Reaction outcome loss': 0.822735208101937, 'Total loss': 0.822735208101937}
2022-11-18 02:01:12,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:12,812 INFO:     Epoch: 13
2022-11-18 02:01:13,599 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8139288404653239, 'Total loss': 0.8139288404653239} | train loss {'Reaction outcome loss': 0.8253744531606064, 'Total loss': 0.8253744531606064}
2022-11-18 02:01:13,599 INFO:     Found new best model at epoch 13
2022-11-18 02:01:13,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:13,600 INFO:     Epoch: 14
2022-11-18 02:01:14,366 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8257014127664788, 'Total loss': 0.8257014127664788} | train loss {'Reaction outcome loss': 0.8207869168187751, 'Total loss': 0.8207869168187751}
2022-11-18 02:01:14,366 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:14,366 INFO:     Epoch: 15
2022-11-18 02:01:15,126 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.851124204868494, 'Total loss': 0.851124204868494} | train loss {'Reaction outcome loss': 0.8200307352865328, 'Total loss': 0.8200307352865328}
2022-11-18 02:01:15,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:15,126 INFO:     Epoch: 16
2022-11-18 02:01:15,932 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8338485997776652, 'Total loss': 0.8338485997776652} | train loss {'Reaction outcome loss': 0.825913917456494, 'Total loss': 0.825913917456494}
2022-11-18 02:01:15,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:15,932 INFO:     Epoch: 17
2022-11-18 02:01:16,707 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8163995340813038, 'Total loss': 0.8163995340813038} | train loss {'Reaction outcome loss': 0.8216219649451678, 'Total loss': 0.8216219649451678}
2022-11-18 02:01:16,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:16,707 INFO:     Epoch: 18
2022-11-18 02:01:17,507 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8371954158295033, 'Total loss': 0.8371954158295033} | train loss {'Reaction outcome loss': 0.821894391149771, 'Total loss': 0.821894391149771}
2022-11-18 02:01:17,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:17,507 INFO:     Epoch: 19
2022-11-18 02:01:18,298 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8349930983643199, 'Total loss': 0.8349930983643199} | train loss {'Reaction outcome loss': 0.8194705978280208, 'Total loss': 0.8194705978280208}
2022-11-18 02:01:18,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:18,300 INFO:     Epoch: 20
2022-11-18 02:01:19,097 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.82321690126907, 'Total loss': 0.82321690126907} | train loss {'Reaction outcome loss': 0.820862360542915, 'Total loss': 0.820862360542915}
2022-11-18 02:01:19,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:19,097 INFO:     Epoch: 21
2022-11-18 02:01:19,915 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.817725040884905, 'Total loss': 0.817725040884905} | train loss {'Reaction outcome loss': 0.8203227327006762, 'Total loss': 0.8203227327006762}
2022-11-18 02:01:19,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:19,916 INFO:     Epoch: 22
2022-11-18 02:01:20,731 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8178070076676303, 'Total loss': 0.8178070076676303} | train loss {'Reaction outcome loss': 0.8195552632945483, 'Total loss': 0.8195552632945483}
2022-11-18 02:01:20,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:20,731 INFO:     Epoch: 23
2022-11-18 02:01:21,528 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8247964389102403, 'Total loss': 0.8247964389102403} | train loss {'Reaction outcome loss': 0.8226121026472967, 'Total loss': 0.8226121026472967}
2022-11-18 02:01:21,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:21,529 INFO:     Epoch: 24
2022-11-18 02:01:22,309 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8398010571335637, 'Total loss': 0.8398010571335637} | train loss {'Reaction outcome loss': 0.8173258717431396, 'Total loss': 0.8173258717431396}
2022-11-18 02:01:22,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:22,309 INFO:     Epoch: 25
2022-11-18 02:01:23,084 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8503380625746971, 'Total loss': 0.8503380625746971} | train loss {'Reaction outcome loss': 0.8223672917143243, 'Total loss': 0.8223672917143243}
2022-11-18 02:01:23,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:23,084 INFO:     Epoch: 26
2022-11-18 02:01:23,883 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8343606189239857, 'Total loss': 0.8343606189239857} | train loss {'Reaction outcome loss': 0.8243428184116472, 'Total loss': 0.8243428184116472}
2022-11-18 02:01:23,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:23,884 INFO:     Epoch: 27
2022-11-18 02:01:24,663 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8171867825264154, 'Total loss': 0.8171867825264154} | train loss {'Reaction outcome loss': 0.8188173830753467, 'Total loss': 0.8188173830753467}
2022-11-18 02:01:24,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:24,664 INFO:     Epoch: 28
2022-11-18 02:01:25,459 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8122734780921492, 'Total loss': 0.8122734780921492} | train loss {'Reaction outcome loss': 0.8178110329098389, 'Total loss': 0.8178110329098389}
2022-11-18 02:01:25,459 INFO:     Found new best model at epoch 28
2022-11-18 02:01:25,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:25,460 INFO:     Epoch: 29
2022-11-18 02:01:26,237 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8144082628017248, 'Total loss': 0.8144082628017248} | train loss {'Reaction outcome loss': 0.8198170473829645, 'Total loss': 0.8198170473829645}
2022-11-18 02:01:26,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:26,237 INFO:     Epoch: 30
2022-11-18 02:01:26,998 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8194851348566454, 'Total loss': 0.8194851348566454} | train loss {'Reaction outcome loss': 0.8207468957197471, 'Total loss': 0.8207468957197471}
2022-11-18 02:01:26,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:26,998 INFO:     Epoch: 31
2022-11-18 02:01:27,782 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8364240811314694, 'Total loss': 0.8364240811314694} | train loss {'Reaction outcome loss': 0.8227026027734162, 'Total loss': 0.8227026027734162}
2022-11-18 02:01:27,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:27,782 INFO:     Epoch: 32
2022-11-18 02:01:28,559 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8143394520116407, 'Total loss': 0.8143394520116407} | train loss {'Reaction outcome loss': 0.8173770307883864, 'Total loss': 0.8173770307883864}
2022-11-18 02:01:28,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:28,560 INFO:     Epoch: 33
2022-11-18 02:01:29,344 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8340133435504381, 'Total loss': 0.8340133435504381} | train loss {'Reaction outcome loss': 0.8157885229734124, 'Total loss': 0.8157885229734124}
2022-11-18 02:01:29,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:29,345 INFO:     Epoch: 34
2022-11-18 02:01:30,112 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8144136001897413, 'Total loss': 0.8144136001897413} | train loss {'Reaction outcome loss': 0.8143804630295175, 'Total loss': 0.8143804630295175}
2022-11-18 02:01:30,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:30,112 INFO:     Epoch: 35
2022-11-18 02:01:30,856 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8199468095635258, 'Total loss': 0.8199468095635258} | train loss {'Reaction outcome loss': 0.8134423880303492, 'Total loss': 0.8134423880303492}
2022-11-18 02:01:30,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:30,857 INFO:     Epoch: 36
2022-11-18 02:01:31,612 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8408141954000606, 'Total loss': 0.8408141954000606} | train loss {'Reaction outcome loss': 0.8188216856024304, 'Total loss': 0.8188216856024304}
2022-11-18 02:01:31,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:31,612 INFO:     Epoch: 37
2022-11-18 02:01:32,382 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8095647055049275, 'Total loss': 0.8095647055049275} | train loss {'Reaction outcome loss': 0.8185092648033236, 'Total loss': 0.8185092648033236}
2022-11-18 02:01:32,382 INFO:     Found new best model at epoch 37
2022-11-18 02:01:32,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:32,383 INFO:     Epoch: 38
2022-11-18 02:01:33,164 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8316469074681748, 'Total loss': 0.8316469074681748} | train loss {'Reaction outcome loss': 0.815170912713301, 'Total loss': 0.815170912713301}
2022-11-18 02:01:33,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:33,164 INFO:     Epoch: 39
2022-11-18 02:01:33,932 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8309454176315042, 'Total loss': 0.8309454176315042} | train loss {'Reaction outcome loss': 0.8169936394838037, 'Total loss': 0.8169936394838037}
2022-11-18 02:01:33,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:33,933 INFO:     Epoch: 40
2022-11-18 02:01:34,724 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8382374124471531, 'Total loss': 0.8382374124471531} | train loss {'Reaction outcome loss': 0.8143803024145423, 'Total loss': 0.8143803024145423}
2022-11-18 02:01:34,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:34,724 INFO:     Epoch: 41
2022-11-18 02:01:35,508 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8183265065037927, 'Total loss': 0.8183265065037927} | train loss {'Reaction outcome loss': 0.8168826133745616, 'Total loss': 0.8168826133745616}
2022-11-18 02:01:35,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:35,508 INFO:     Epoch: 42
2022-11-18 02:01:36,305 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.836856272331504, 'Total loss': 0.836856272331504} | train loss {'Reaction outcome loss': 0.8130723245319773, 'Total loss': 0.8130723245319773}
2022-11-18 02:01:36,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:36,306 INFO:     Epoch: 43
2022-11-18 02:01:37,076 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8405614578446676, 'Total loss': 0.8405614578446676} | train loss {'Reaction outcome loss': 0.8120129775316989, 'Total loss': 0.8120129775316989}
2022-11-18 02:01:37,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:37,076 INFO:     Epoch: 44
2022-11-18 02:01:37,855 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8273387606753859, 'Total loss': 0.8273387606753859} | train loss {'Reaction outcome loss': 0.8174304347790655, 'Total loss': 0.8174304347790655}
2022-11-18 02:01:37,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:37,856 INFO:     Epoch: 45
2022-11-18 02:01:38,605 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8163979885190032, 'Total loss': 0.8163979885190032} | train loss {'Reaction outcome loss': 0.812049817599234, 'Total loss': 0.812049817599234}
2022-11-18 02:01:38,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:38,605 INFO:     Epoch: 46
2022-11-18 02:01:39,357 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8496924784294394, 'Total loss': 0.8496924784294394} | train loss {'Reaction outcome loss': 0.8123723545768222, 'Total loss': 0.8123723545768222}
2022-11-18 02:01:39,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:39,358 INFO:     Epoch: 47
2022-11-18 02:01:40,132 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8396610028521959, 'Total loss': 0.8396610028521959} | train loss {'Reaction outcome loss': 0.8158302691872003, 'Total loss': 0.8158302691872003}
2022-11-18 02:01:40,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:40,132 INFO:     Epoch: 48
2022-11-18 02:01:40,911 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8142739659131959, 'Total loss': 0.8142739659131959} | train loss {'Reaction outcome loss': 0.8118136883026263, 'Total loss': 0.8118136883026263}
2022-11-18 02:01:40,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:40,911 INFO:     Epoch: 49
2022-11-18 02:01:41,679 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8332626736441324, 'Total loss': 0.8332626736441324} | train loss {'Reaction outcome loss': 0.8112147549381021, 'Total loss': 0.8112147549381021}
2022-11-18 02:01:41,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:41,680 INFO:     Epoch: 50
2022-11-18 02:01:42,469 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8189706538998803, 'Total loss': 0.8189706538998803} | train loss {'Reaction outcome loss': 0.816634288454642, 'Total loss': 0.816634288454642}
2022-11-18 02:01:42,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:42,470 INFO:     Epoch: 51
2022-11-18 02:01:43,251 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8170802336792613, 'Total loss': 0.8170802336792613} | train loss {'Reaction outcome loss': 0.8232780306554232, 'Total loss': 0.8232780306554232}
2022-11-18 02:01:43,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:43,253 INFO:     Epoch: 52
2022-11-18 02:01:44,003 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8166967574940172, 'Total loss': 0.8166967574940172} | train loss {'Reaction outcome loss': 0.8145292413527848, 'Total loss': 0.8145292413527848}
2022-11-18 02:01:44,004 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:44,004 INFO:     Epoch: 53
2022-11-18 02:01:44,785 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8114482143590617, 'Total loss': 0.8114482143590617} | train loss {'Reaction outcome loss': 0.8138448324848394, 'Total loss': 0.8138448324848394}
2022-11-18 02:01:44,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:44,785 INFO:     Epoch: 54
2022-11-18 02:01:45,565 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8410015438878259, 'Total loss': 0.8410015438878259} | train loss {'Reaction outcome loss': 0.8154764588250488, 'Total loss': 0.8154764588250488}
2022-11-18 02:01:45,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:45,566 INFO:     Epoch: 55
2022-11-18 02:01:46,324 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.826652069424474, 'Total loss': 0.826652069424474} | train loss {'Reaction outcome loss': 0.8133404405146348, 'Total loss': 0.8133404405146348}
2022-11-18 02:01:46,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:46,325 INFO:     Epoch: 56
2022-11-18 02:01:47,101 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8117440315180047, 'Total loss': 0.8117440315180047} | train loss {'Reaction outcome loss': 0.8171855238128881, 'Total loss': 0.8171855238128881}
2022-11-18 02:01:47,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:47,101 INFO:     Epoch: 57
2022-11-18 02:01:47,863 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.814945308275001, 'Total loss': 0.814945308275001} | train loss {'Reaction outcome loss': 0.8104795797682199, 'Total loss': 0.8104795797682199}
2022-11-18 02:01:47,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:47,863 INFO:     Epoch: 58
2022-11-18 02:01:48,648 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8309135326119357, 'Total loss': 0.8309135326119357} | train loss {'Reaction outcome loss': 0.8126356220636212, 'Total loss': 0.8126356220636212}
2022-11-18 02:01:48,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:48,648 INFO:     Epoch: 59
2022-11-18 02:01:49,405 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.819189541561659, 'Total loss': 0.819189541561659} | train loss {'Reaction outcome loss': 0.8117378528733723, 'Total loss': 0.8117378528733723}
2022-11-18 02:01:49,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:49,406 INFO:     Epoch: 60
2022-11-18 02:01:50,177 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8222471108270246, 'Total loss': 0.8222471108270246} | train loss {'Reaction outcome loss': 0.8163693769544852, 'Total loss': 0.8163693769544852}
2022-11-18 02:01:50,177 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:50,177 INFO:     Epoch: 61
2022-11-18 02:01:50,945 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8377700773782508, 'Total loss': 0.8377700773782508} | train loss {'Reaction outcome loss': 0.8161063002514057, 'Total loss': 0.8161063002514057}
2022-11-18 02:01:50,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:50,946 INFO:     Epoch: 62
2022-11-18 02:01:51,713 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8159734267134999, 'Total loss': 0.8159734267134999} | train loss {'Reaction outcome loss': 0.8109216362726493, 'Total loss': 0.8109216362726493}
2022-11-18 02:01:51,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:51,713 INFO:     Epoch: 63
2022-11-18 02:01:52,470 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8164603426012882, 'Total loss': 0.8164603426012882} | train loss {'Reaction outcome loss': 0.8132394388562343, 'Total loss': 0.8132394388562343}
2022-11-18 02:01:52,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:52,470 INFO:     Epoch: 64
2022-11-18 02:01:53,233 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8186151080353316, 'Total loss': 0.8186151080353316} | train loss {'Reaction outcome loss': 0.8144356276168198, 'Total loss': 0.8144356276168198}
2022-11-18 02:01:53,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:53,234 INFO:     Epoch: 65
2022-11-18 02:01:54,019 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.815256864525551, 'Total loss': 0.815256864525551} | train loss {'Reaction outcome loss': 0.8116491385659234, 'Total loss': 0.8116491385659234}
2022-11-18 02:01:54,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:54,019 INFO:     Epoch: 66
2022-11-18 02:01:54,812 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8273805047190467, 'Total loss': 0.8273805047190467} | train loss {'Reaction outcome loss': 0.8128560068177395, 'Total loss': 0.8128560068177395}
2022-11-18 02:01:54,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:54,812 INFO:     Epoch: 67
2022-11-18 02:01:55,585 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.815286667541016, 'Total loss': 0.815286667541016} | train loss {'Reaction outcome loss': 0.8161664622851083, 'Total loss': 0.8161664622851083}
2022-11-18 02:01:55,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:55,585 INFO:     Epoch: 68
2022-11-18 02:01:56,333 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.826080777617388, 'Total loss': 0.826080777617388} | train loss {'Reaction outcome loss': 0.811711604233648, 'Total loss': 0.811711604233648}
2022-11-18 02:01:56,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:56,334 INFO:     Epoch: 69
2022-11-18 02:01:57,116 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8419793359068937, 'Total loss': 0.8419793359068937} | train loss {'Reaction outcome loss': 0.811451822641443, 'Total loss': 0.811451822641443}
2022-11-18 02:01:57,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:57,116 INFO:     Epoch: 70
2022-11-18 02:01:57,870 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8151174804498983, 'Total loss': 0.8151174804498983} | train loss {'Reaction outcome loss': 0.8150170152304602, 'Total loss': 0.8150170152304602}
2022-11-18 02:01:57,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:57,870 INFO:     Epoch: 71
2022-11-18 02:01:58,626 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.811006507208181, 'Total loss': 0.811006507208181} | train loss {'Reaction outcome loss': 0.8125919876772849, 'Total loss': 0.8125919876772849}
2022-11-18 02:01:58,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:58,627 INFO:     Epoch: 72
2022-11-18 02:01:59,396 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8227297206257664, 'Total loss': 0.8227297206257664} | train loss {'Reaction outcome loss': 0.8154047786212358, 'Total loss': 0.8154047786212358}
2022-11-18 02:01:59,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:01:59,396 INFO:     Epoch: 73
2022-11-18 02:02:00,187 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8352490746697714, 'Total loss': 0.8352490746697714} | train loss {'Reaction outcome loss': 0.8088246679208317, 'Total loss': 0.8088246679208317}
2022-11-18 02:02:00,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:00,187 INFO:     Epoch: 74
2022-11-18 02:02:00,955 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8414324674495431, 'Total loss': 0.8414324674495431} | train loss {'Reaction outcome loss': 0.8130744146030457, 'Total loss': 0.8130744146030457}
2022-11-18 02:02:00,955 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:00,955 INFO:     Epoch: 75
2022-11-18 02:02:01,715 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8191285008607909, 'Total loss': 0.8191285008607909} | train loss {'Reaction outcome loss': 0.8111362007797741, 'Total loss': 0.8111362007797741}
2022-11-18 02:02:01,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:01,717 INFO:     Epoch: 76
2022-11-18 02:02:02,486 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8810392070648282, 'Total loss': 0.8810392070648282} | train loss {'Reaction outcome loss': 0.8143134732715419, 'Total loss': 0.8143134732715419}
2022-11-18 02:02:02,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:02,486 INFO:     Epoch: 77
2022-11-18 02:02:03,257 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8289922385714775, 'Total loss': 0.8289922385714775} | train loss {'Reaction outcome loss': 0.8132080479112805, 'Total loss': 0.8132080479112805}
2022-11-18 02:02:03,257 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:03,258 INFO:     Epoch: 78
2022-11-18 02:02:04,013 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8419255538042202, 'Total loss': 0.8419255538042202} | train loss {'Reaction outcome loss': 0.8144069905163812, 'Total loss': 0.8144069905163812}
2022-11-18 02:02:04,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:04,013 INFO:     Epoch: 79
2022-11-18 02:02:04,762 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8213806193928386, 'Total loss': 0.8213806193928386} | train loss {'Reaction outcome loss': 0.8095253294364351, 'Total loss': 0.8095253294364351}
2022-11-18 02:02:04,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:04,762 INFO:     Epoch: 80
2022-11-18 02:02:05,525 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8203353965005209, 'Total loss': 0.8203353965005209} | train loss {'Reaction outcome loss': 0.812174626671877, 'Total loss': 0.812174626671877}
2022-11-18 02:02:05,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:05,525 INFO:     Epoch: 81
2022-11-18 02:02:06,291 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8135828431262526, 'Total loss': 0.8135828431262526} | train loss {'Reaction outcome loss': 0.8074322850977789, 'Total loss': 0.8074322850977789}
2022-11-18 02:02:06,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:06,292 INFO:     Epoch: 82
2022-11-18 02:02:07,067 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8288305831509967, 'Total loss': 0.8288305831509967} | train loss {'Reaction outcome loss': 0.8185179145609747, 'Total loss': 0.8185179145609747}
2022-11-18 02:02:07,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:07,067 INFO:     Epoch: 83
2022-11-18 02:02:07,882 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.804330799468728, 'Total loss': 0.804330799468728} | train loss {'Reaction outcome loss': 0.8121208980923793, 'Total loss': 0.8121208980923793}
2022-11-18 02:02:07,882 INFO:     Found new best model at epoch 83
2022-11-18 02:02:07,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:07,883 INFO:     Epoch: 84
2022-11-18 02:02:08,677 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8324220540911652, 'Total loss': 0.8324220540911652} | train loss {'Reaction outcome loss': 0.8078188791138227, 'Total loss': 0.8078188791138227}
2022-11-18 02:02:08,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:08,677 INFO:     Epoch: 85
2022-11-18 02:02:09,463 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8419820430666901, 'Total loss': 0.8419820430666901} | train loss {'Reaction outcome loss': 0.8101603354586929, 'Total loss': 0.8101603354586929}
2022-11-18 02:02:09,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:09,463 INFO:     Epoch: 86
2022-11-18 02:02:10,231 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.848956726318182, 'Total loss': 0.848956726318182} | train loss {'Reaction outcome loss': 0.8110593918894158, 'Total loss': 0.8110593918894158}
2022-11-18 02:02:10,231 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:10,231 INFO:     Epoch: 87
2022-11-18 02:02:10,999 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8259284108184105, 'Total loss': 0.8259284108184105} | train loss {'Reaction outcome loss': 0.8107265286514016, 'Total loss': 0.8107265286514016}
2022-11-18 02:02:10,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:10,999 INFO:     Epoch: 88
2022-11-18 02:02:11,775 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8453578581643659, 'Total loss': 0.8453578581643659} | train loss {'Reaction outcome loss': 0.8123337277134911, 'Total loss': 0.8123337277134911}
2022-11-18 02:02:11,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:11,776 INFO:     Epoch: 89
2022-11-18 02:02:12,507 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8270896590033243, 'Total loss': 0.8270896590033243} | train loss {'Reaction outcome loss': 0.8068759925052768, 'Total loss': 0.8068759925052768}
2022-11-18 02:02:12,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:12,507 INFO:     Epoch: 90
2022-11-18 02:02:13,286 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8184577989023786, 'Total loss': 0.8184577989023786} | train loss {'Reaction outcome loss': 0.8147780869583614, 'Total loss': 0.8147780869583614}
2022-11-18 02:02:13,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:13,286 INFO:     Epoch: 91
2022-11-18 02:02:14,073 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.816781955402951, 'Total loss': 0.816781955402951} | train loss {'Reaction outcome loss': 0.8142040522127855, 'Total loss': 0.8142040522127855}
2022-11-18 02:02:14,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:14,075 INFO:     Epoch: 92
2022-11-18 02:02:14,863 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8355901269025581, 'Total loss': 0.8355901269025581} | train loss {'Reaction outcome loss': 0.8069341258435953, 'Total loss': 0.8069341258435953}
2022-11-18 02:02:14,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:14,863 INFO:     Epoch: 93
2022-11-18 02:02:15,646 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.806977721147759, 'Total loss': 0.806977721147759} | train loss {'Reaction outcome loss': 0.8088240266823378, 'Total loss': 0.8088240266823378}
2022-11-18 02:02:15,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:15,646 INFO:     Epoch: 94
2022-11-18 02:02:16,409 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8260614317516948, 'Total loss': 0.8260614317516948} | train loss {'Reaction outcome loss': 0.8141460366180686, 'Total loss': 0.8141460366180686}
2022-11-18 02:02:16,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:16,410 INFO:     Epoch: 95
2022-11-18 02:02:17,193 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8185267060302025, 'Total loss': 0.8185267060302025} | train loss {'Reaction outcome loss': 0.8092427402734756, 'Total loss': 0.8092427402734756}
2022-11-18 02:02:17,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:17,193 INFO:     Epoch: 96
2022-11-18 02:02:17,984 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8305902134540469, 'Total loss': 0.8305902134540469} | train loss {'Reaction outcome loss': 0.8097384124994278, 'Total loss': 0.8097384124994278}
2022-11-18 02:02:17,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:17,984 INFO:     Epoch: 97
2022-11-18 02:02:18,731 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.822712205870207, 'Total loss': 0.822712205870207} | train loss {'Reaction outcome loss': 0.8094789698475697, 'Total loss': 0.8094789698475697}
2022-11-18 02:02:18,732 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:18,732 INFO:     Epoch: 98
2022-11-18 02:02:19,529 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8095254766386609, 'Total loss': 0.8095254766386609} | train loss {'Reaction outcome loss': 0.8103839233517647, 'Total loss': 0.8103839233517647}
2022-11-18 02:02:19,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:19,529 INFO:     Epoch: 99
2022-11-18 02:02:20,334 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.82729930863824, 'Total loss': 0.82729930863824} | train loss {'Reaction outcome loss': 0.8092984277449671, 'Total loss': 0.8092984277449671}
2022-11-18 02:02:20,335 INFO:     Best model found after epoch 84 of 100.
2022-11-18 02:02:20,335 INFO:   Done with stage: TRAINING
2022-11-18 02:02:20,335 INFO:   Starting stage: EVALUATION
2022-11-18 02:02:20,473 INFO:   Done with stage: EVALUATION
2022-11-18 02:02:20,473 INFO:   Leaving out SEQ value Fold_1
2022-11-18 02:02:20,486 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 02:02:20,486 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:02:21,168 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:02:21,168 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:02:21,238 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:02:21,238 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:02:21,238 INFO:     No hyperparam tuning for this model
2022-11-18 02:02:21,238 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:02:21,238 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:02:21,239 INFO:     None feature selector for col prot
2022-11-18 02:02:21,239 INFO:     None feature selector for col prot
2022-11-18 02:02:21,239 INFO:     None feature selector for col prot
2022-11-18 02:02:21,240 INFO:     None feature selector for col chem
2022-11-18 02:02:21,240 INFO:     None feature selector for col chem
2022-11-18 02:02:21,240 INFO:     None feature selector for col chem
2022-11-18 02:02:21,240 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:02:21,240 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:02:21,241 INFO:     Number of params in model 168571
2022-11-18 02:02:21,245 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:02:21,245 INFO:   Starting stage: TRAINING
2022-11-18 02:02:21,303 INFO:     Val loss before train {'Reaction outcome loss': 0.9917415827512741, 'Total loss': 0.9917415827512741}
2022-11-18 02:02:21,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:21,303 INFO:     Epoch: 0
2022-11-18 02:02:22,115 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8388386355205015, 'Total loss': 0.8388386355205015} | train loss {'Reaction outcome loss': 0.8923726534356876, 'Total loss': 0.8923726534356876}
2022-11-18 02:02:22,115 INFO:     Found new best model at epoch 0
2022-11-18 02:02:22,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:22,116 INFO:     Epoch: 1
2022-11-18 02:02:22,920 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8233743946660649, 'Total loss': 0.8233743946660649} | train loss {'Reaction outcome loss': 0.8658729614043722, 'Total loss': 0.8658729614043722}
2022-11-18 02:02:22,921 INFO:     Found new best model at epoch 1
2022-11-18 02:02:22,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:22,922 INFO:     Epoch: 2
2022-11-18 02:02:23,696 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8486797802827575, 'Total loss': 0.8486797802827575} | train loss {'Reaction outcome loss': 0.8567202812554885, 'Total loss': 0.8567202812554885}
2022-11-18 02:02:23,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:23,696 INFO:     Epoch: 3
2022-11-18 02:02:24,502 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8165103339336135, 'Total loss': 0.8165103339336135} | train loss {'Reaction outcome loss': 0.8497441403719843, 'Total loss': 0.8497441403719843}
2022-11-18 02:02:24,503 INFO:     Found new best model at epoch 3
2022-11-18 02:02:24,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:24,504 INFO:     Epoch: 4
2022-11-18 02:02:25,334 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8180960416793823, 'Total loss': 0.8180960416793823} | train loss {'Reaction outcome loss': 0.8488322352876468, 'Total loss': 0.8488322352876468}
2022-11-18 02:02:25,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:25,334 INFO:     Epoch: 5
2022-11-18 02:02:26,136 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8330571427941322, 'Total loss': 0.8330571427941322} | train loss {'Reaction outcome loss': 0.8399834930896759, 'Total loss': 0.8399834930896759}
2022-11-18 02:02:26,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:26,137 INFO:     Epoch: 6
2022-11-18 02:02:26,949 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8256015213714405, 'Total loss': 0.8256015213714405} | train loss {'Reaction outcome loss': 0.8434121027284739, 'Total loss': 0.8434121027284739}
2022-11-18 02:02:26,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:26,949 INFO:     Epoch: 7
2022-11-18 02:02:27,745 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8138002909042619, 'Total loss': 0.8138002909042619} | train loss {'Reaction outcome loss': 0.8393046838896615, 'Total loss': 0.8393046838896615}
2022-11-18 02:02:27,745 INFO:     Found new best model at epoch 7
2022-11-18 02:02:27,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:27,746 INFO:     Epoch: 8
2022-11-18 02:02:28,567 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8140717751600526, 'Total loss': 0.8140717751600526} | train loss {'Reaction outcome loss': 0.8390459546021053, 'Total loss': 0.8390459546021053}
2022-11-18 02:02:28,568 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:28,568 INFO:     Epoch: 9
2022-11-18 02:02:29,373 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8287765437906439, 'Total loss': 0.8287765437906439} | train loss {'Reaction outcome loss': 0.8399750316629604, 'Total loss': 0.8399750316629604}
2022-11-18 02:02:29,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:29,373 INFO:     Epoch: 10
2022-11-18 02:02:30,234 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8168577836318449, 'Total loss': 0.8168577836318449} | train loss {'Reaction outcome loss': 0.8337397072996412, 'Total loss': 0.8337397072996412}
2022-11-18 02:02:30,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:30,235 INFO:     Epoch: 11
2022-11-18 02:02:31,069 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8301997584375468, 'Total loss': 0.8301997584375468} | train loss {'Reaction outcome loss': 0.8362717927718649, 'Total loss': 0.8362717927718649}
2022-11-18 02:02:31,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:31,070 INFO:     Epoch: 12
2022-11-18 02:02:31,904 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8184977261857553, 'Total loss': 0.8184977261857553} | train loss {'Reaction outcome loss': 0.8351262020821474, 'Total loss': 0.8351262020821474}
2022-11-18 02:02:31,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:31,905 INFO:     Epoch: 13
2022-11-18 02:02:32,687 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8226301168853586, 'Total loss': 0.8226301168853586} | train loss {'Reaction outcome loss': 0.8382743769762467, 'Total loss': 0.8382743769762467}
2022-11-18 02:02:32,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:32,688 INFO:     Epoch: 14
2022-11-18 02:02:33,491 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8208870576186613, 'Total loss': 0.8208870576186613} | train loss {'Reaction outcome loss': 0.8306093284061977, 'Total loss': 0.8306093284061977}
2022-11-18 02:02:33,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:33,491 INFO:     Epoch: 15
2022-11-18 02:02:34,326 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8128417073325678, 'Total loss': 0.8128417073325678} | train loss {'Reaction outcome loss': 0.8316284323225216, 'Total loss': 0.8316284323225216}
2022-11-18 02:02:34,326 INFO:     Found new best model at epoch 15
2022-11-18 02:02:34,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:34,327 INFO:     Epoch: 16
2022-11-18 02:02:35,140 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8220840807665478, 'Total loss': 0.8220840807665478} | train loss {'Reaction outcome loss': 0.8320709561815067, 'Total loss': 0.8320709561815067}
2022-11-18 02:02:35,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:35,141 INFO:     Epoch: 17
2022-11-18 02:02:35,926 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8131182166663083, 'Total loss': 0.8131182166663083} | train loss {'Reaction outcome loss': 0.8305718129994918, 'Total loss': 0.8305718129994918}
2022-11-18 02:02:35,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:35,926 INFO:     Epoch: 18
2022-11-18 02:02:36,714 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7974002378230746, 'Total loss': 0.7974002378230746} | train loss {'Reaction outcome loss': 0.8349110655638636, 'Total loss': 0.8349110655638636}
2022-11-18 02:02:36,715 INFO:     Found new best model at epoch 18
2022-11-18 02:02:36,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:36,715 INFO:     Epoch: 19
2022-11-18 02:02:37,537 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.809019839221781, 'Total loss': 0.809019839221781} | train loss {'Reaction outcome loss': 0.8332064499052203, 'Total loss': 0.8332064499052203}
2022-11-18 02:02:37,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:37,537 INFO:     Epoch: 20
2022-11-18 02:02:38,318 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8033248477361419, 'Total loss': 0.8033248477361419} | train loss {'Reaction outcome loss': 0.8322441388149651, 'Total loss': 0.8322441388149651}
2022-11-18 02:02:38,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:38,318 INFO:     Epoch: 21
2022-11-18 02:02:39,130 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8230918801643632, 'Total loss': 0.8230918801643632} | train loss {'Reaction outcome loss': 0.8318477113636172, 'Total loss': 0.8318477113636172}
2022-11-18 02:02:39,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:39,130 INFO:     Epoch: 22
2022-11-18 02:02:39,922 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8027676763859662, 'Total loss': 0.8027676763859662} | train loss {'Reaction outcome loss': 0.8320635047494148, 'Total loss': 0.8320635047494148}
2022-11-18 02:02:39,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:39,922 INFO:     Epoch: 23
2022-11-18 02:02:40,705 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8174939778718081, 'Total loss': 0.8174939778718081} | train loss {'Reaction outcome loss': 0.836339148696588, 'Total loss': 0.836339148696588}
2022-11-18 02:02:40,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:40,705 INFO:     Epoch: 24
2022-11-18 02:02:41,533 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7968720610846173, 'Total loss': 0.7968720610846173} | train loss {'Reaction outcome loss': 0.829596690742337, 'Total loss': 0.829596690742337}
2022-11-18 02:02:41,533 INFO:     Found new best model at epoch 24
2022-11-18 02:02:41,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:41,534 INFO:     Epoch: 25
2022-11-18 02:02:42,378 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8248404630205848, 'Total loss': 0.8248404630205848} | train loss {'Reaction outcome loss': 0.8368878040994917, 'Total loss': 0.8368878040994917}
2022-11-18 02:02:42,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:42,378 INFO:     Epoch: 26
2022-11-18 02:02:43,202 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8235548402775418, 'Total loss': 0.8235548402775418} | train loss {'Reaction outcome loss': 0.8309910753551795, 'Total loss': 0.8309910753551795}
2022-11-18 02:02:43,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:43,203 INFO:     Epoch: 27
2022-11-18 02:02:44,023 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8555876179174944, 'Total loss': 0.8555876179174944} | train loss {'Reaction outcome loss': 0.8320955862804335, 'Total loss': 0.8320955862804335}
2022-11-18 02:02:44,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:44,023 INFO:     Epoch: 28
2022-11-18 02:02:44,803 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.836224453015761, 'Total loss': 0.836224453015761} | train loss {'Reaction outcome loss': 0.8303331449323771, 'Total loss': 0.8303331449323771}
2022-11-18 02:02:44,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:44,805 INFO:     Epoch: 29
2022-11-18 02:02:45,613 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8299909911372445, 'Total loss': 0.8299909911372445} | train loss {'Reaction outcome loss': 0.8342722168990544, 'Total loss': 0.8342722168990544}
2022-11-18 02:02:45,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:45,614 INFO:     Epoch: 30
2022-11-18 02:02:46,382 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8014704138040543, 'Total loss': 0.8014704138040543} | train loss {'Reaction outcome loss': 0.8355490152933159, 'Total loss': 0.8355490152933159}
2022-11-18 02:02:46,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:46,382 INFO:     Epoch: 31
2022-11-18 02:02:47,209 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8294254284013401, 'Total loss': 0.8294254284013401} | train loss {'Reaction outcome loss': 0.8334335098461229, 'Total loss': 0.8334335098461229}
2022-11-18 02:02:47,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:47,210 INFO:     Epoch: 32
2022-11-18 02:02:48,003 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8222494247284803, 'Total loss': 0.8222494247284803} | train loss {'Reaction outcome loss': 0.8270238971223637, 'Total loss': 0.8270238971223637}
2022-11-18 02:02:48,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:48,004 INFO:     Epoch: 33
2022-11-18 02:02:48,798 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7996682240204378, 'Total loss': 0.7996682240204378} | train loss {'Reaction outcome loss': 0.8281544001734986, 'Total loss': 0.8281544001734986}
2022-11-18 02:02:48,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:48,799 INFO:     Epoch: 34
2022-11-18 02:02:49,654 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7988778677853671, 'Total loss': 0.7988778677853671} | train loss {'Reaction outcome loss': 0.8253387024207991, 'Total loss': 0.8253387024207991}
2022-11-18 02:02:49,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:49,654 INFO:     Epoch: 35
2022-11-18 02:02:50,452 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8315347771752964, 'Total loss': 0.8315347771752964} | train loss {'Reaction outcome loss': 0.8319076792317994, 'Total loss': 0.8319076792317994}
2022-11-18 02:02:50,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:50,452 INFO:     Epoch: 36
2022-11-18 02:02:51,246 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8619844297116454, 'Total loss': 0.8619844297116454} | train loss {'Reaction outcome loss': 0.8277536813093691, 'Total loss': 0.8277536813093691}
2022-11-18 02:02:51,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:51,247 INFO:     Epoch: 37
2022-11-18 02:02:52,057 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8131701011549343, 'Total loss': 0.8131701011549343} | train loss {'Reaction outcome loss': 0.8289968193793783, 'Total loss': 0.8289968193793783}
2022-11-18 02:02:52,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:52,057 INFO:     Epoch: 38
2022-11-18 02:02:52,845 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.806262156502767, 'Total loss': 0.806262156502767} | train loss {'Reaction outcome loss': 0.8271685928714518, 'Total loss': 0.8271685928714518}
2022-11-18 02:02:52,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:52,845 INFO:     Epoch: 39
2022-11-18 02:02:53,686 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8093621263449843, 'Total loss': 0.8093621263449843} | train loss {'Reaction outcome loss': 0.8274963417831732, 'Total loss': 0.8274963417831732}
2022-11-18 02:02:53,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:53,686 INFO:     Epoch: 40
2022-11-18 02:02:54,482 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8139009827917273, 'Total loss': 0.8139009827917273} | train loss {'Reaction outcome loss': 0.8296000997630917, 'Total loss': 0.8296000997630917}
2022-11-18 02:02:54,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:54,482 INFO:     Epoch: 41
2022-11-18 02:02:55,268 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.816430542956699, 'Total loss': 0.816430542956699} | train loss {'Reaction outcome loss': 0.8302890762990834, 'Total loss': 0.8302890762990834}
2022-11-18 02:02:55,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:55,268 INFO:     Epoch: 42
2022-11-18 02:02:56,065 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8304802965034138, 'Total loss': 0.8304802965034138} | train loss {'Reaction outcome loss': 0.8281945447532498, 'Total loss': 0.8281945447532498}
2022-11-18 02:02:56,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:56,066 INFO:     Epoch: 43
2022-11-18 02:02:56,842 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8374128355221315, 'Total loss': 0.8374128355221315} | train loss {'Reaction outcome loss': 0.8316886759534174, 'Total loss': 0.8316886759534174}
2022-11-18 02:02:56,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:56,842 INFO:     Epoch: 44
2022-11-18 02:02:57,687 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8209505595944144, 'Total loss': 0.8209505595944144} | train loss {'Reaction outcome loss': 0.8274900727126063, 'Total loss': 0.8274900727126063}
2022-11-18 02:02:57,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:57,688 INFO:     Epoch: 45
2022-11-18 02:02:58,473 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8213779093189673, 'Total loss': 0.8213779093189673} | train loss {'Reaction outcome loss': 0.83202031005402, 'Total loss': 0.83202031005402}
2022-11-18 02:02:58,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:58,473 INFO:     Epoch: 46
2022-11-18 02:02:59,303 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8210892230272293, 'Total loss': 0.8210892230272293} | train loss {'Reaction outcome loss': 0.8233707740598796, 'Total loss': 0.8233707740598796}
2022-11-18 02:02:59,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:02:59,304 INFO:     Epoch: 47
2022-11-18 02:03:00,126 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8400885320522569, 'Total loss': 0.8400885320522569} | train loss {'Reaction outcome loss': 0.8301478252118948, 'Total loss': 0.8301478252118948}
2022-11-18 02:03:00,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:00,126 INFO:     Epoch: 48
2022-11-18 02:03:00,919 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7899353140118447, 'Total loss': 0.7899353140118447} | train loss {'Reaction outcome loss': 0.8261224215127984, 'Total loss': 0.8261224215127984}
2022-11-18 02:03:00,919 INFO:     Found new best model at epoch 48
2022-11-18 02:03:00,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:00,920 INFO:     Epoch: 49
2022-11-18 02:03:01,691 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7969711470333013, 'Total loss': 0.7969711470333013} | train loss {'Reaction outcome loss': 0.8278865864082259, 'Total loss': 0.8278865864082259}
2022-11-18 02:03:01,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:01,691 INFO:     Epoch: 50
2022-11-18 02:03:02,461 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8183667199178175, 'Total loss': 0.8183667199178175} | train loss {'Reaction outcome loss': 0.827140536843514, 'Total loss': 0.827140536843514}
2022-11-18 02:03:02,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:02,461 INFO:     Epoch: 51
2022-11-18 02:03:03,269 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8182212696834044, 'Total loss': 0.8182212696834044} | train loss {'Reaction outcome loss': 0.8227264727864947, 'Total loss': 0.8227264727864947}
2022-11-18 02:03:03,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:03,270 INFO:     Epoch: 52
2022-11-18 02:03:04,087 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.794676352630962, 'Total loss': 0.794676352630962} | train loss {'Reaction outcome loss': 0.8220592264009982, 'Total loss': 0.8220592264009982}
2022-11-18 02:03:04,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:04,088 INFO:     Epoch: 53
2022-11-18 02:03:04,885 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8030804165384986, 'Total loss': 0.8030804165384986} | train loss {'Reaction outcome loss': 0.8229096977078185, 'Total loss': 0.8229096977078185}
2022-11-18 02:03:04,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:04,885 INFO:     Epoch: 54
2022-11-18 02:03:05,693 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8176279670812867, 'Total loss': 0.8176279670812867} | train loss {'Reaction outcome loss': 0.8224613696944957, 'Total loss': 0.8224613696944957}
2022-11-18 02:03:05,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:05,693 INFO:     Epoch: 55
2022-11-18 02:03:06,494 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7866687883030284, 'Total loss': 0.7866687883030284} | train loss {'Reaction outcome loss': 0.8234507670207899, 'Total loss': 0.8234507670207899}
2022-11-18 02:03:06,494 INFO:     Found new best model at epoch 55
2022-11-18 02:03:06,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:06,495 INFO:     Epoch: 56
2022-11-18 02:03:07,294 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8337177810343829, 'Total loss': 0.8337177810343829} | train loss {'Reaction outcome loss': 0.8235899650928925, 'Total loss': 0.8235899650928925}
2022-11-18 02:03:07,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:07,294 INFO:     Epoch: 57
2022-11-18 02:03:08,087 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8164865787733685, 'Total loss': 0.8164865787733685} | train loss {'Reaction outcome loss': 0.8237640620494375, 'Total loss': 0.8237640620494375}
2022-11-18 02:03:08,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:08,087 INFO:     Epoch: 58
2022-11-18 02:03:08,878 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8306041671471163, 'Total loss': 0.8306041671471163} | train loss {'Reaction outcome loss': 0.8189301302238386, 'Total loss': 0.8189301302238386}
2022-11-18 02:03:08,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:08,878 INFO:     Epoch: 59
2022-11-18 02:03:09,694 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8102441673929041, 'Total loss': 0.8102441673929041} | train loss {'Reaction outcome loss': 0.8270167360500413, 'Total loss': 0.8270167360500413}
2022-11-18 02:03:09,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:09,694 INFO:     Epoch: 60
2022-11-18 02:03:10,491 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.791888773610646, 'Total loss': 0.791888773610646} | train loss {'Reaction outcome loss': 0.8174111293286693, 'Total loss': 0.8174111293286693}
2022-11-18 02:03:10,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:10,491 INFO:     Epoch: 61
2022-11-18 02:03:11,290 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8000679727305066, 'Total loss': 0.8000679727305066} | train loss {'Reaction outcome loss': 0.8153120807238987, 'Total loss': 0.8153120807238987}
2022-11-18 02:03:11,290 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:11,291 INFO:     Epoch: 62
2022-11-18 02:03:12,065 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8088608600876548, 'Total loss': 0.8088608600876548} | train loss {'Reaction outcome loss': 0.82373436300122, 'Total loss': 0.82373436300122}
2022-11-18 02:03:12,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:12,065 INFO:     Epoch: 63
2022-11-18 02:03:12,895 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8213271390308033, 'Total loss': 0.8213271390308033} | train loss {'Reaction outcome loss': 0.8244968883845271, 'Total loss': 0.8244968883845271}
2022-11-18 02:03:12,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:12,895 INFO:     Epoch: 64
2022-11-18 02:03:13,724 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.810687966644764, 'Total loss': 0.810687966644764} | train loss {'Reaction outcome loss': 0.8233096239518146, 'Total loss': 0.8233096239518146}
2022-11-18 02:03:13,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:13,725 INFO:     Epoch: 65
2022-11-18 02:03:14,540 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8259524323723533, 'Total loss': 0.8259524323723533} | train loss {'Reaction outcome loss': 0.8154898546179946, 'Total loss': 0.8154898546179946}
2022-11-18 02:03:14,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:14,541 INFO:     Epoch: 66
2022-11-18 02:03:15,321 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8345648118040778, 'Total loss': 0.8345648118040778} | train loss {'Reaction outcome loss': 0.8205626405015284, 'Total loss': 0.8205626405015284}
2022-11-18 02:03:15,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:15,322 INFO:     Epoch: 67
2022-11-18 02:03:16,131 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7942649674686518, 'Total loss': 0.7942649674686518} | train loss {'Reaction outcome loss': 0.8214844820450763, 'Total loss': 0.8214844820450763}
2022-11-18 02:03:16,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:16,133 INFO:     Epoch: 68
2022-11-18 02:03:16,961 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8300352665511045, 'Total loss': 0.8300352665511045} | train loss {'Reaction outcome loss': 0.8190024086407253, 'Total loss': 0.8190024086407253}
2022-11-18 02:03:16,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:16,961 INFO:     Epoch: 69
2022-11-18 02:03:17,742 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7983370572328568, 'Total loss': 0.7983370572328568} | train loss {'Reaction outcome loss': 0.8164716289967907, 'Total loss': 0.8164716289967907}
2022-11-18 02:03:17,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:17,743 INFO:     Epoch: 70
2022-11-18 02:03:18,539 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8168258721178229, 'Total loss': 0.8168258721178229} | train loss {'Reaction outcome loss': 0.8164069799744353, 'Total loss': 0.8164069799744353}
2022-11-18 02:03:18,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:18,539 INFO:     Epoch: 71
2022-11-18 02:03:19,324 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7970646890726957, 'Total loss': 0.7970646890726957} | train loss {'Reaction outcome loss': 0.8157230996355719, 'Total loss': 0.8157230996355719}
2022-11-18 02:03:19,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:19,325 INFO:     Epoch: 72
2022-11-18 02:03:20,146 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8182684846899726, 'Total loss': 0.8182684846899726} | train loss {'Reaction outcome loss': 0.8177815089420396, 'Total loss': 0.8177815089420396}
2022-11-18 02:03:20,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:20,147 INFO:     Epoch: 73
2022-11-18 02:03:20,907 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8341190090233629, 'Total loss': 0.8341190090233629} | train loss {'Reaction outcome loss': 0.8130116078318382, 'Total loss': 0.8130116078318382}
2022-11-18 02:03:20,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:20,908 INFO:     Epoch: 74
2022-11-18 02:03:21,704 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8180669471621513, 'Total loss': 0.8180669471621513} | train loss {'Reaction outcome loss': 0.8144881815326457, 'Total loss': 0.8144881815326457}
2022-11-18 02:03:21,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:21,705 INFO:     Epoch: 75
2022-11-18 02:03:22,500 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8229952874508771, 'Total loss': 0.8229952874508771} | train loss {'Reaction outcome loss': 0.8154984485129921, 'Total loss': 0.8154984485129921}
2022-11-18 02:03:22,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:22,501 INFO:     Epoch: 76
2022-11-18 02:03:23,309 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8032418943264268, 'Total loss': 0.8032418943264268} | train loss {'Reaction outcome loss': 0.8108635850706879, 'Total loss': 0.8108635850706879}
2022-11-18 02:03:23,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:23,309 INFO:     Epoch: 77
2022-11-18 02:03:24,113 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8242536681619558, 'Total loss': 0.8242536681619558} | train loss {'Reaction outcome loss': 0.8153307744434901, 'Total loss': 0.8153307744434901}
2022-11-18 02:03:24,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:24,113 INFO:     Epoch: 78
2022-11-18 02:03:24,907 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7810885973952033, 'Total loss': 0.7810885973952033} | train loss {'Reaction outcome loss': 0.8120522685196935, 'Total loss': 0.8120522685196935}
2022-11-18 02:03:24,907 INFO:     Found new best model at epoch 78
2022-11-18 02:03:24,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:24,908 INFO:     Epoch: 79
2022-11-18 02:03:25,727 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7734486951746724, 'Total loss': 0.7734486951746724} | train loss {'Reaction outcome loss': 0.805255728716753, 'Total loss': 0.805255728716753}
2022-11-18 02:03:25,727 INFO:     Found new best model at epoch 79
2022-11-18 02:03:25,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:25,728 INFO:     Epoch: 80
2022-11-18 02:03:26,549 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7978780140930956, 'Total loss': 0.7978780140930956} | train loss {'Reaction outcome loss': 0.8047607432822792, 'Total loss': 0.8047607432822792}
2022-11-18 02:03:26,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:26,549 INFO:     Epoch: 81
2022-11-18 02:03:27,378 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7899704948067665, 'Total loss': 0.7899704948067665} | train loss {'Reaction outcome loss': 0.8081986179157179, 'Total loss': 0.8081986179157179}
2022-11-18 02:03:27,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:27,379 INFO:     Epoch: 82
2022-11-18 02:03:28,155 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7847583598711274, 'Total loss': 0.7847583598711274} | train loss {'Reaction outcome loss': 0.8051308569859486, 'Total loss': 0.8051308569859486}
2022-11-18 02:03:28,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:28,155 INFO:     Epoch: 83
2022-11-18 02:03:28,938 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7878740267320112, 'Total loss': 0.7878740267320112} | train loss {'Reaction outcome loss': 0.798395688193185, 'Total loss': 0.798395688193185}
2022-11-18 02:03:28,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:28,938 INFO:     Epoch: 84
2022-11-18 02:03:29,702 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7883307824588635, 'Total loss': 0.7883307824588635} | train loss {'Reaction outcome loss': 0.8045435050312354, 'Total loss': 0.8045435050312354}
2022-11-18 02:03:29,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:29,702 INFO:     Epoch: 85
2022-11-18 02:03:30,501 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7981681058352644, 'Total loss': 0.7981681058352644} | train loss {'Reaction outcome loss': 0.8049003778671732, 'Total loss': 0.8049003778671732}
2022-11-18 02:03:30,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:30,501 INFO:     Epoch: 86
2022-11-18 02:03:31,328 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7753025035966526, 'Total loss': 0.7753025035966526} | train loss {'Reaction outcome loss': 0.7973601759696494, 'Total loss': 0.7973601759696494}
2022-11-18 02:03:31,329 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:31,329 INFO:     Epoch: 87
2022-11-18 02:03:32,131 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.79219108752229, 'Total loss': 0.79219108752229} | train loss {'Reaction outcome loss': 0.7993474523631894, 'Total loss': 0.7993474523631894}
2022-11-18 02:03:32,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:32,131 INFO:     Epoch: 88
2022-11-18 02:03:32,949 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7769681296565316, 'Total loss': 0.7769681296565316} | train loss {'Reaction outcome loss': 0.7953010740328809, 'Total loss': 0.7953010740328809}
2022-11-18 02:03:32,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:32,949 INFO:     Epoch: 89
2022-11-18 02:03:33,734 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7989356687123125, 'Total loss': 0.7989356687123125} | train loss {'Reaction outcome loss': 0.7925169230723867, 'Total loss': 0.7925169230723867}
2022-11-18 02:03:33,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:33,735 INFO:     Epoch: 90
2022-11-18 02:03:34,542 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7843731011856686, 'Total loss': 0.7843731011856686} | train loss {'Reaction outcome loss': 0.7935158666299313, 'Total loss': 0.7935158666299313}
2022-11-18 02:03:34,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:34,543 INFO:     Epoch: 91
2022-11-18 02:03:35,346 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.768769998442043, 'Total loss': 0.768769998442043} | train loss {'Reaction outcome loss': 0.7878540675250851, 'Total loss': 0.7878540675250851}
2022-11-18 02:03:35,346 INFO:     Found new best model at epoch 91
2022-11-18 02:03:35,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:35,347 INFO:     Epoch: 92
2022-11-18 02:03:36,127 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7800756360996853, 'Total loss': 0.7800756360996853} | train loss {'Reaction outcome loss': 0.7786072709122482, 'Total loss': 0.7786072709122482}
2022-11-18 02:03:36,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:36,128 INFO:     Epoch: 93
2022-11-18 02:03:36,914 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7549110312353481, 'Total loss': 0.7549110312353481} | train loss {'Reaction outcome loss': 0.7826657066539843, 'Total loss': 0.7826657066539843}
2022-11-18 02:03:36,914 INFO:     Found new best model at epoch 93
2022-11-18 02:03:36,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:36,915 INFO:     Epoch: 94
2022-11-18 02:03:37,676 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7964355320754376, 'Total loss': 0.7964355320754376} | train loss {'Reaction outcome loss': 0.7737823208984064, 'Total loss': 0.7737823208984064}
2022-11-18 02:03:37,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:37,676 INFO:     Epoch: 95
2022-11-18 02:03:38,485 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7645922499624166, 'Total loss': 0.7645922499624166} | train loss {'Reaction outcome loss': 0.7764900173459734, 'Total loss': 0.7764900173459734}
2022-11-18 02:03:38,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:38,485 INFO:     Epoch: 96
2022-11-18 02:03:39,314 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7262784544039856, 'Total loss': 0.7262784544039856} | train loss {'Reaction outcome loss': 0.7600380123878012, 'Total loss': 0.7600380123878012}
2022-11-18 02:03:39,314 INFO:     Found new best model at epoch 96
2022-11-18 02:03:39,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:39,315 INFO:     Epoch: 97
2022-11-18 02:03:40,141 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7389809794046662, 'Total loss': 0.7389809794046662} | train loss {'Reaction outcome loss': 0.7535759436840914, 'Total loss': 0.7535759436840914}
2022-11-18 02:03:40,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:40,141 INFO:     Epoch: 98
2022-11-18 02:03:40,958 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7414274588227272, 'Total loss': 0.7414274588227272} | train loss {'Reaction outcome loss': 0.7482724188541879, 'Total loss': 0.7482724188541879}
2022-11-18 02:03:40,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:40,959 INFO:     Epoch: 99
2022-11-18 02:03:41,811 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7058606967329979, 'Total loss': 0.7058606967329979} | train loss {'Reaction outcome loss': 0.7288833951463505, 'Total loss': 0.7288833951463505}
2022-11-18 02:03:41,811 INFO:     Found new best model at epoch 99
2022-11-18 02:03:41,812 INFO:     Best model found after epoch 100 of 100.
2022-11-18 02:03:41,812 INFO:   Done with stage: TRAINING
2022-11-18 02:03:41,812 INFO:   Starting stage: EVALUATION
2022-11-18 02:03:41,942 INFO:   Done with stage: EVALUATION
2022-11-18 02:03:41,942 INFO:   Leaving out SEQ value Fold_2
2022-11-18 02:03:41,955 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-18 02:03:41,955 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:03:42,617 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:03:42,617 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:03:42,686 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:03:42,686 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:03:42,686 INFO:     No hyperparam tuning for this model
2022-11-18 02:03:42,686 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:03:42,687 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:03:42,687 INFO:     None feature selector for col prot
2022-11-18 02:03:42,688 INFO:     None feature selector for col prot
2022-11-18 02:03:42,688 INFO:     None feature selector for col prot
2022-11-18 02:03:42,688 INFO:     None feature selector for col chem
2022-11-18 02:03:42,688 INFO:     None feature selector for col chem
2022-11-18 02:03:42,689 INFO:     None feature selector for col chem
2022-11-18 02:03:42,689 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:03:42,689 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:03:42,690 INFO:     Number of params in model 168571
2022-11-18 02:03:42,694 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:03:42,694 INFO:   Starting stage: TRAINING
2022-11-18 02:03:42,750 INFO:     Val loss before train {'Reaction outcome loss': 0.973735825266949, 'Total loss': 0.973735825266949}
2022-11-18 02:03:42,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:42,751 INFO:     Epoch: 0
2022-11-18 02:03:43,533 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8181298707806787, 'Total loss': 0.8181298707806787} | train loss {'Reaction outcome loss': 0.8794278362002529, 'Total loss': 0.8794278362002529}
2022-11-18 02:03:43,533 INFO:     Found new best model at epoch 0
2022-11-18 02:03:43,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:43,534 INFO:     Epoch: 1
2022-11-18 02:03:44,333 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8001314082811045, 'Total loss': 0.8001314082811045} | train loss {'Reaction outcome loss': 0.8522010709418625, 'Total loss': 0.8522010709418625}
2022-11-18 02:03:44,333 INFO:     Found new best model at epoch 1
2022-11-18 02:03:44,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:44,334 INFO:     Epoch: 2
2022-11-18 02:03:45,129 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.822724676409433, 'Total loss': 0.822724676409433} | train loss {'Reaction outcome loss': 0.8526361474736792, 'Total loss': 0.8526361474736792}
2022-11-18 02:03:45,130 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:45,130 INFO:     Epoch: 3
2022-11-18 02:03:45,917 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.802519537681757, 'Total loss': 0.802519537681757} | train loss {'Reaction outcome loss': 0.846212920228966, 'Total loss': 0.846212920228966}
2022-11-18 02:03:45,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:45,917 INFO:     Epoch: 4
2022-11-18 02:03:46,686 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8079684390578159, 'Total loss': 0.8079684390578159} | train loss {'Reaction outcome loss': 0.8443292385486306, 'Total loss': 0.8443292385486306}
2022-11-18 02:03:46,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:46,686 INFO:     Epoch: 5
2022-11-18 02:03:47,509 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7955423447974893, 'Total loss': 0.7955423447974893} | train loss {'Reaction outcome loss': 0.8378711880230513, 'Total loss': 0.8378711880230513}
2022-11-18 02:03:47,510 INFO:     Found new best model at epoch 5
2022-11-18 02:03:47,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:47,511 INFO:     Epoch: 6
2022-11-18 02:03:48,305 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7948407849600149, 'Total loss': 0.7948407849600149} | train loss {'Reaction outcome loss': 0.839992386762236, 'Total loss': 0.839992386762236}
2022-11-18 02:03:48,305 INFO:     Found new best model at epoch 6
2022-11-18 02:03:48,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:48,306 INFO:     Epoch: 7
2022-11-18 02:03:49,114 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7843981260477111, 'Total loss': 0.7843981260477111} | train loss {'Reaction outcome loss': 0.8363102072330771, 'Total loss': 0.8363102072330771}
2022-11-18 02:03:49,114 INFO:     Found new best model at epoch 7
2022-11-18 02:03:49,115 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:49,115 INFO:     Epoch: 8
2022-11-18 02:03:49,921 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8411618630553401, 'Total loss': 0.8411618630553401} | train loss {'Reaction outcome loss': 0.8288153401408039, 'Total loss': 0.8288153401408039}
2022-11-18 02:03:49,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:49,921 INFO:     Epoch: 9
2022-11-18 02:03:50,719 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8024152884649676, 'Total loss': 0.8024152884649676} | train loss {'Reaction outcome loss': 0.8335012709263896, 'Total loss': 0.8335012709263896}
2022-11-18 02:03:50,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:50,720 INFO:     Epoch: 10
2022-11-18 02:03:51,530 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.805001571427944, 'Total loss': 0.805001571427944} | train loss {'Reaction outcome loss': 0.8268221913546813, 'Total loss': 0.8268221913546813}
2022-11-18 02:03:51,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:51,530 INFO:     Epoch: 11
2022-11-18 02:03:52,327 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.793099660513013, 'Total loss': 0.793099660513013} | train loss {'Reaction outcome loss': 0.8305824495485572, 'Total loss': 0.8305824495485572}
2022-11-18 02:03:52,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:52,328 INFO:     Epoch: 12
2022-11-18 02:03:53,154 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7841247126113536, 'Total loss': 0.7841247126113536} | train loss {'Reaction outcome loss': 0.8267671761454128, 'Total loss': 0.8267671761454128}
2022-11-18 02:03:53,154 INFO:     Found new best model at epoch 12
2022-11-18 02:03:53,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:53,155 INFO:     Epoch: 13
2022-11-18 02:03:53,985 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7900344452192617, 'Total loss': 0.7900344452192617} | train loss {'Reaction outcome loss': 0.8203890798766105, 'Total loss': 0.8203890798766105}
2022-11-18 02:03:53,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:53,986 INFO:     Epoch: 14
2022-11-18 02:03:54,791 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7878078977729, 'Total loss': 0.7878078977729} | train loss {'Reaction outcome loss': 0.8261333617274879, 'Total loss': 0.8261333617274879}
2022-11-18 02:03:54,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:54,791 INFO:     Epoch: 15
2022-11-18 02:03:55,596 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7863895740619925, 'Total loss': 0.7863895740619925} | train loss {'Reaction outcome loss': 0.8218082051540985, 'Total loss': 0.8218082051540985}
2022-11-18 02:03:55,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:55,596 INFO:     Epoch: 16
2022-11-18 02:03:56,389 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7858668648919394, 'Total loss': 0.7858668648919394} | train loss {'Reaction outcome loss': 0.8186474927380437, 'Total loss': 0.8186474927380437}
2022-11-18 02:03:56,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:56,389 INFO:     Epoch: 17
2022-11-18 02:03:57,187 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7858997091304424, 'Total loss': 0.7858997091304424} | train loss {'Reaction outcome loss': 0.8228223576653199, 'Total loss': 0.8228223576653199}
2022-11-18 02:03:57,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:57,187 INFO:     Epoch: 18
2022-11-18 02:03:57,987 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.784579909818117, 'Total loss': 0.784579909818117} | train loss {'Reaction outcome loss': 0.8220970354607848, 'Total loss': 0.8220970354607848}
2022-11-18 02:03:57,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:57,987 INFO:     Epoch: 19
2022-11-18 02:03:58,790 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7800581074038218, 'Total loss': 0.7800581074038218} | train loss {'Reaction outcome loss': 0.8199645874441647, 'Total loss': 0.8199645874441647}
2022-11-18 02:03:58,790 INFO:     Found new best model at epoch 19
2022-11-18 02:03:58,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:58,791 INFO:     Epoch: 20
2022-11-18 02:03:59,594 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7843188296916873, 'Total loss': 0.7843188296916873} | train loss {'Reaction outcome loss': 0.8149676429199391, 'Total loss': 0.8149676429199391}
2022-11-18 02:03:59,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:03:59,595 INFO:     Epoch: 21
2022-11-18 02:04:00,421 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7927667318388473, 'Total loss': 0.7927667318388473} | train loss {'Reaction outcome loss': 0.821687968172988, 'Total loss': 0.821687968172988}
2022-11-18 02:04:00,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:00,422 INFO:     Epoch: 22
2022-11-18 02:04:01,194 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7831046768399172, 'Total loss': 0.7831046768399172} | train loss {'Reaction outcome loss': 0.8197307790644833, 'Total loss': 0.8197307790644833}
2022-11-18 02:04:01,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:01,194 INFO:     Epoch: 23
2022-11-18 02:04:01,971 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7825260903946188, 'Total loss': 0.7825260903946188} | train loss {'Reaction outcome loss': 0.8145283938187068, 'Total loss': 0.8145283938187068}
2022-11-18 02:04:01,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:01,972 INFO:     Epoch: 24
2022-11-18 02:04:02,787 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7845118960668874, 'Total loss': 0.7845118960668874} | train loss {'Reaction outcome loss': 0.8195915897605849, 'Total loss': 0.8195915897605849}
2022-11-18 02:04:02,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:02,787 INFO:     Epoch: 25
2022-11-18 02:04:03,613 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8081657533035722, 'Total loss': 0.8081657533035722} | train loss {'Reaction outcome loss': 0.8172350089813842, 'Total loss': 0.8172350089813842}
2022-11-18 02:04:03,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:03,613 INFO:     Epoch: 26
2022-11-18 02:04:04,447 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7764610960039982, 'Total loss': 0.7764610960039982} | train loss {'Reaction outcome loss': 0.8210671649115985, 'Total loss': 0.8210671649115985}
2022-11-18 02:04:04,447 INFO:     Found new best model at epoch 26
2022-11-18 02:04:04,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:04,448 INFO:     Epoch: 27
2022-11-18 02:04:05,228 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7781512875889622, 'Total loss': 0.7781512875889622} | train loss {'Reaction outcome loss': 0.8205467403912153, 'Total loss': 0.8205467403912153}
2022-11-18 02:04:05,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:05,228 INFO:     Epoch: 28
2022-11-18 02:04:06,015 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.77795737288719, 'Total loss': 0.77795737288719} | train loss {'Reaction outcome loss': 0.8199074303761857, 'Total loss': 0.8199074303761857}
2022-11-18 02:04:06,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:06,017 INFO:     Epoch: 29
2022-11-18 02:04:06,821 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7755803126235341, 'Total loss': 0.7755803126235341} | train loss {'Reaction outcome loss': 0.8139697473312988, 'Total loss': 0.8139697473312988}
2022-11-18 02:04:06,822 INFO:     Found new best model at epoch 29
2022-11-18 02:04:06,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:06,822 INFO:     Epoch: 30
2022-11-18 02:04:07,600 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7783395772756532, 'Total loss': 0.7783395772756532} | train loss {'Reaction outcome loss': 0.8207586515145223, 'Total loss': 0.8207586515145223}
2022-11-18 02:04:07,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:07,600 INFO:     Epoch: 31
2022-11-18 02:04:08,381 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7923551194889601, 'Total loss': 0.7923551194889601} | train loss {'Reaction outcome loss': 0.8166859622617237, 'Total loss': 0.8166859622617237}
2022-11-18 02:04:08,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:08,381 INFO:     Epoch: 32
2022-11-18 02:04:09,174 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7737853721130726, 'Total loss': 0.7737853721130726} | train loss {'Reaction outcome loss': 0.8178467799405582, 'Total loss': 0.8178467799405582}
2022-11-18 02:04:09,174 INFO:     Found new best model at epoch 32
2022-11-18 02:04:09,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:09,175 INFO:     Epoch: 33
2022-11-18 02:04:09,953 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7855111415996108, 'Total loss': 0.7855111415996108} | train loss {'Reaction outcome loss': 0.8176638564613999, 'Total loss': 0.8176638564613999}
2022-11-18 02:04:09,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:09,953 INFO:     Epoch: 34
2022-11-18 02:04:10,753 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7962576760802158, 'Total loss': 0.7962576760802158} | train loss {'Reaction outcome loss': 0.8206896425270643, 'Total loss': 0.8206896425270643}
2022-11-18 02:04:10,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:10,753 INFO:     Epoch: 35
2022-11-18 02:04:11,542 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7859775555688281, 'Total loss': 0.7859775555688281} | train loss {'Reaction outcome loss': 0.8209596386209863, 'Total loss': 0.8209596386209863}
2022-11-18 02:04:11,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:11,542 INFO:     Epoch: 36
2022-11-18 02:04:12,342 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7945365614669267, 'Total loss': 0.7945365614669267} | train loss {'Reaction outcome loss': 0.818164977748863, 'Total loss': 0.818164977748863}
2022-11-18 02:04:12,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:12,342 INFO:     Epoch: 37
2022-11-18 02:04:13,168 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.775804670744164, 'Total loss': 0.775804670744164} | train loss {'Reaction outcome loss': 0.8200807940275943, 'Total loss': 0.8200807940275943}
2022-11-18 02:04:13,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:13,169 INFO:     Epoch: 38
2022-11-18 02:04:13,972 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7939197573550912, 'Total loss': 0.7939197573550912} | train loss {'Reaction outcome loss': 0.8243668553282003, 'Total loss': 0.8243668553282003}
2022-11-18 02:04:13,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:13,972 INFO:     Epoch: 39
2022-11-18 02:04:14,784 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7848778103673181, 'Total loss': 0.7848778103673181} | train loss {'Reaction outcome loss': 0.8199606806528373, 'Total loss': 0.8199606806528373}
2022-11-18 02:04:14,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:14,785 INFO:     Epoch: 40
2022-11-18 02:04:15,614 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.77784327434939, 'Total loss': 0.77784327434939} | train loss {'Reaction outcome loss': 0.8169455003054416, 'Total loss': 0.8169455003054416}
2022-11-18 02:04:15,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:15,614 INFO:     Epoch: 41
2022-11-18 02:04:16,430 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8009366143581479, 'Total loss': 0.8009366143581479} | train loss {'Reaction outcome loss': 0.8155789049189599, 'Total loss': 0.8155789049189599}
2022-11-18 02:04:16,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:16,430 INFO:     Epoch: 42
2022-11-18 02:04:17,244 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7940790389859399, 'Total loss': 0.7940790389859399} | train loss {'Reaction outcome loss': 0.818041096212434, 'Total loss': 0.818041096212434}
2022-11-18 02:04:17,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:17,244 INFO:     Epoch: 43
2022-11-18 02:04:18,054 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7959914262904677, 'Total loss': 0.7959914262904677} | train loss {'Reaction outcome loss': 0.819317920408288, 'Total loss': 0.819317920408288}
2022-11-18 02:04:18,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:18,054 INFO:     Epoch: 44
2022-11-18 02:04:18,888 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7787241367406623, 'Total loss': 0.7787241367406623} | train loss {'Reaction outcome loss': 0.8156790741887249, 'Total loss': 0.8156790741887249}
2022-11-18 02:04:18,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:18,889 INFO:     Epoch: 45
2022-11-18 02:04:19,668 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7893790055152982, 'Total loss': 0.7893790055152982} | train loss {'Reaction outcome loss': 0.8209578819939347, 'Total loss': 0.8209578819939347}
2022-11-18 02:04:19,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:19,670 INFO:     Epoch: 46
2022-11-18 02:04:20,452 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7819772570632225, 'Total loss': 0.7819772570632225} | train loss {'Reaction outcome loss': 0.8238913828476531, 'Total loss': 0.8238913828476531}
2022-11-18 02:04:20,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:20,452 INFO:     Epoch: 47
2022-11-18 02:04:21,279 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7859250265498494, 'Total loss': 0.7859250265498494} | train loss {'Reaction outcome loss': 0.8181084087881886, 'Total loss': 0.8181084087881886}
2022-11-18 02:04:21,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:21,280 INFO:     Epoch: 48
2022-11-18 02:04:22,111 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7819723216600196, 'Total loss': 0.7819723216600196} | train loss {'Reaction outcome loss': 0.8174798484952723, 'Total loss': 0.8174798484952723}
2022-11-18 02:04:22,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:22,111 INFO:     Epoch: 49
2022-11-18 02:04:22,930 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7859840129697045, 'Total loss': 0.7859840129697045} | train loss {'Reaction outcome loss': 0.8175657605294322, 'Total loss': 0.8175657605294322}
2022-11-18 02:04:22,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:22,931 INFO:     Epoch: 50
2022-11-18 02:04:23,763 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7803692284018494, 'Total loss': 0.7803692284018494} | train loss {'Reaction outcome loss': 0.8132048896590217, 'Total loss': 0.8132048896590217}
2022-11-18 02:04:23,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:23,763 INFO:     Epoch: 51
2022-11-18 02:04:24,563 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7826883723569471, 'Total loss': 0.7826883723569471} | train loss {'Reaction outcome loss': 0.8143892073240436, 'Total loss': 0.8143892073240436}
2022-11-18 02:04:24,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:24,563 INFO:     Epoch: 52
2022-11-18 02:04:25,375 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7923259582630423, 'Total loss': 0.7923259582630423} | train loss {'Reaction outcome loss': 0.8140608799017843, 'Total loss': 0.8140608799017843}
2022-11-18 02:04:25,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:25,375 INFO:     Epoch: 53
2022-11-18 02:04:26,175 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7810509329618409, 'Total loss': 0.7810509329618409} | train loss {'Reaction outcome loss': 0.8173564987593009, 'Total loss': 0.8173564987593009}
2022-11-18 02:04:26,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:26,176 INFO:     Epoch: 54
2022-11-18 02:04:26,951 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7708086322906406, 'Total loss': 0.7708086322906406} | train loss {'Reaction outcome loss': 0.818405916944879, 'Total loss': 0.818405916944879}
2022-11-18 02:04:26,951 INFO:     Found new best model at epoch 54
2022-11-18 02:04:26,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:26,952 INFO:     Epoch: 55
2022-11-18 02:04:27,788 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.786123257736827, 'Total loss': 0.786123257736827} | train loss {'Reaction outcome loss': 0.8181761444592085, 'Total loss': 0.8181761444592085}
2022-11-18 02:04:27,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:27,789 INFO:     Epoch: 56
2022-11-18 02:04:28,575 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8147359026032824, 'Total loss': 0.8147359026032824} | train loss {'Reaction outcome loss': 0.8162469392428633, 'Total loss': 0.8162469392428633}
2022-11-18 02:04:28,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:28,576 INFO:     Epoch: 57
2022-11-18 02:04:29,390 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7936844160390455, 'Total loss': 0.7936844160390455} | train loss {'Reaction outcome loss': 0.8188071566038444, 'Total loss': 0.8188071566038444}
2022-11-18 02:04:29,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:29,390 INFO:     Epoch: 58
2022-11-18 02:04:30,202 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7902421396832133, 'Total loss': 0.7902421396832133} | train loss {'Reaction outcome loss': 0.8154494955402906, 'Total loss': 0.8154494955402906}
2022-11-18 02:04:30,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:30,202 INFO:     Epoch: 59
2022-11-18 02:04:30,949 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7791728224865225, 'Total loss': 0.7791728224865225} | train loss {'Reaction outcome loss': 0.8111074306681508, 'Total loss': 0.8111074306681508}
2022-11-18 02:04:30,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:30,949 INFO:     Epoch: 60
2022-11-18 02:04:31,725 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7942951446355775, 'Total loss': 0.7942951446355775} | train loss {'Reaction outcome loss': 0.8138412698859074, 'Total loss': 0.8138412698859074}
2022-11-18 02:04:31,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:31,725 INFO:     Epoch: 61
2022-11-18 02:04:32,525 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7898407245791236, 'Total loss': 0.7898407245791236} | train loss {'Reaction outcome loss': 0.8137042743505024, 'Total loss': 0.8137042743505024}
2022-11-18 02:04:32,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:32,525 INFO:     Epoch: 62
2022-11-18 02:04:33,371 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8331867109897525, 'Total loss': 0.8331867109897525} | train loss {'Reaction outcome loss': 0.8185403599846558, 'Total loss': 0.8185403599846558}
2022-11-18 02:04:33,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:33,371 INFO:     Epoch: 63
2022-11-18 02:04:34,166 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7864422617956649, 'Total loss': 0.7864422617956649} | train loss {'Reaction outcome loss': 0.8127001163656594, 'Total loss': 0.8127001163656594}
2022-11-18 02:04:34,166 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:34,166 INFO:     Epoch: 64
2022-11-18 02:04:34,964 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7989898143812667, 'Total loss': 0.7989898143812667} | train loss {'Reaction outcome loss': 0.8112589940428734, 'Total loss': 0.8112589940428734}
2022-11-18 02:04:34,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:34,964 INFO:     Epoch: 65
2022-11-18 02:04:35,762 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8016794400159702, 'Total loss': 0.8016794400159702} | train loss {'Reaction outcome loss': 0.8164160969804545, 'Total loss': 0.8164160969804545}
2022-11-18 02:04:35,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:35,762 INFO:     Epoch: 66
2022-11-18 02:04:36,552 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7893023400805718, 'Total loss': 0.7893023400805718} | train loss {'Reaction outcome loss': 0.8133072106808913, 'Total loss': 0.8133072106808913}
2022-11-18 02:04:36,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:36,552 INFO:     Epoch: 67
2022-11-18 02:04:37,379 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7903591061747351, 'Total loss': 0.7903591061747351} | train loss {'Reaction outcome loss': 0.8153428925109691, 'Total loss': 0.8153428925109691}
2022-11-18 02:04:37,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:37,379 INFO:     Epoch: 68
2022-11-18 02:04:38,177 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.774226026479588, 'Total loss': 0.774226026479588} | train loss {'Reaction outcome loss': 0.8164537186261083, 'Total loss': 0.8164537186261083}
2022-11-18 02:04:38,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:38,178 INFO:     Epoch: 69
2022-11-18 02:04:38,987 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7989566894464715, 'Total loss': 0.7989566894464715} | train loss {'Reaction outcome loss': 0.8148684682416134, 'Total loss': 0.8148684682416134}
2022-11-18 02:04:38,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:38,988 INFO:     Epoch: 70
2022-11-18 02:04:39,789 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7776554864506389, 'Total loss': 0.7776554864506389} | train loss {'Reaction outcome loss': 0.8177000831385128, 'Total loss': 0.8177000831385128}
2022-11-18 02:04:39,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:39,789 INFO:     Epoch: 71
2022-11-18 02:04:40,584 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7742728355319001, 'Total loss': 0.7742728355319001} | train loss {'Reaction outcome loss': 0.8188183184285633, 'Total loss': 0.8188183184285633}
2022-11-18 02:04:40,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:40,584 INFO:     Epoch: 72
2022-11-18 02:04:41,393 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7850046656852545, 'Total loss': 0.7850046656852545} | train loss {'Reaction outcome loss': 0.8171695020110881, 'Total loss': 0.8171695020110881}
2022-11-18 02:04:41,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:41,393 INFO:     Epoch: 73
2022-11-18 02:04:42,162 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7743248495944711, 'Total loss': 0.7743248495944711} | train loss {'Reaction outcome loss': 0.8108279323968731, 'Total loss': 0.8108279323968731}
2022-11-18 02:04:42,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:42,163 INFO:     Epoch: 74
2022-11-18 02:04:42,951 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7825900011284407, 'Total loss': 0.7825900011284407} | train loss {'Reaction outcome loss': 0.8122902760495905, 'Total loss': 0.8122902760495905}
2022-11-18 02:04:42,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:42,951 INFO:     Epoch: 75
2022-11-18 02:04:43,772 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7755753654380177, 'Total loss': 0.7755753654380177} | train loss {'Reaction outcome loss': 0.8170504324504586, 'Total loss': 0.8170504324504586}
2022-11-18 02:04:43,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:43,772 INFO:     Epoch: 76
2022-11-18 02:04:44,618 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7851382383080416, 'Total loss': 0.7851382383080416} | train loss {'Reaction outcome loss': 0.8129106227491723, 'Total loss': 0.8129106227491723}
2022-11-18 02:04:44,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:44,618 INFO:     Epoch: 77
2022-11-18 02:04:45,408 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.785538024680559, 'Total loss': 0.785538024680559} | train loss {'Reaction outcome loss': 0.815196154303238, 'Total loss': 0.815196154303238}
2022-11-18 02:04:45,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:45,408 INFO:     Epoch: 78
2022-11-18 02:04:46,245 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7920732435791992, 'Total loss': 0.7920732435791992} | train loss {'Reaction outcome loss': 0.815534131448777, 'Total loss': 0.815534131448777}
2022-11-18 02:04:46,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:46,246 INFO:     Epoch: 79
2022-11-18 02:04:47,075 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.784824806590413, 'Total loss': 0.784824806590413} | train loss {'Reaction outcome loss': 0.8148510425550038, 'Total loss': 0.8148510425550038}
2022-11-18 02:04:47,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:47,075 INFO:     Epoch: 80
2022-11-18 02:04:47,847 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7733826664991157, 'Total loss': 0.7733826664991157} | train loss {'Reaction outcome loss': 0.8138071156916071, 'Total loss': 0.8138071156916071}
2022-11-18 02:04:47,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:47,847 INFO:     Epoch: 81
2022-11-18 02:04:48,667 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7870857812637506, 'Total loss': 0.7870857812637506} | train loss {'Reaction outcome loss': 0.8201971653787816, 'Total loss': 0.8201971653787816}
2022-11-18 02:04:48,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:48,668 INFO:     Epoch: 82
2022-11-18 02:04:49,449 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7843690722487694, 'Total loss': 0.7843690722487694} | train loss {'Reaction outcome loss': 0.8136854674972471, 'Total loss': 0.8136854674972471}
2022-11-18 02:04:49,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:49,449 INFO:     Epoch: 83
2022-11-18 02:04:50,252 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7906821051309275, 'Total loss': 0.7906821051309275} | train loss {'Reaction outcome loss': 0.8173371486243655, 'Total loss': 0.8173371486243655}
2022-11-18 02:04:50,253 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:50,253 INFO:     Epoch: 84
2022-11-18 02:04:51,060 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7909252193084982, 'Total loss': 0.7909252193084982} | train loss {'Reaction outcome loss': 0.8170458820999645, 'Total loss': 0.8170458820999645}
2022-11-18 02:04:51,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:51,060 INFO:     Epoch: 85
2022-11-18 02:04:51,847 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7887135647064032, 'Total loss': 0.7887135647064032} | train loss {'Reaction outcome loss': 0.814936095573863, 'Total loss': 0.814936095573863}
2022-11-18 02:04:51,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:51,847 INFO:     Epoch: 86
2022-11-18 02:04:52,622 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8157107067662616, 'Total loss': 0.8157107067662616} | train loss {'Reaction outcome loss': 0.8150910625203711, 'Total loss': 0.8150910625203711}
2022-11-18 02:04:52,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:52,622 INFO:     Epoch: 87
2022-11-18 02:04:53,408 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7812143106793248, 'Total loss': 0.7812143106793248} | train loss {'Reaction outcome loss': 0.8171840829194569, 'Total loss': 0.8171840829194569}
2022-11-18 02:04:53,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:53,408 INFO:     Epoch: 88
2022-11-18 02:04:54,193 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7832948745683183, 'Total loss': 0.7832948745683183} | train loss {'Reaction outcome loss': 0.8149645970981629, 'Total loss': 0.8149645970981629}
2022-11-18 02:04:54,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:54,193 INFO:     Epoch: 89
2022-11-18 02:04:55,013 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7796952703664469, 'Total loss': 0.7796952703664469} | train loss {'Reaction outcome loss': 0.8153670504689217, 'Total loss': 0.8153670504689217}
2022-11-18 02:04:55,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:55,014 INFO:     Epoch: 90
2022-11-18 02:04:55,826 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7960552053396092, 'Total loss': 0.7960552053396092} | train loss {'Reaction outcome loss': 0.8189816907292506, 'Total loss': 0.8189816907292506}
2022-11-18 02:04:55,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:55,827 INFO:     Epoch: 91
2022-11-18 02:04:56,639 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8042968289796696, 'Total loss': 0.8042968289796696} | train loss {'Reaction outcome loss': 0.8171304427698011, 'Total loss': 0.8171304427698011}
2022-11-18 02:04:56,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:56,640 INFO:     Epoch: 92
2022-11-18 02:04:57,433 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7842928164227064, 'Total loss': 0.7842928164227064} | train loss {'Reaction outcome loss': 0.8163104230751757, 'Total loss': 0.8163104230751757}
2022-11-18 02:04:57,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:57,433 INFO:     Epoch: 93
2022-11-18 02:04:58,210 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7869146729624549, 'Total loss': 0.7869146729624549} | train loss {'Reaction outcome loss': 0.8155444597855943, 'Total loss': 0.8155444597855943}
2022-11-18 02:04:58,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:58,210 INFO:     Epoch: 94
2022-11-18 02:04:59,021 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7834768898265306, 'Total loss': 0.7834768898265306} | train loss {'Reaction outcome loss': 0.817463580702172, 'Total loss': 0.817463580702172}
2022-11-18 02:04:59,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:59,021 INFO:     Epoch: 95
2022-11-18 02:04:59,839 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7968223836532858, 'Total loss': 0.7968223836532858} | train loss {'Reaction outcome loss': 0.8146212082661566, 'Total loss': 0.8146212082661566}
2022-11-18 02:04:59,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:04:59,839 INFO:     Epoch: 96
2022-11-18 02:05:00,634 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7973710686661476, 'Total loss': 0.7973710686661476} | train loss {'Reaction outcome loss': 0.8209641198398637, 'Total loss': 0.8209641198398637}
2022-11-18 02:05:00,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:00,634 INFO:     Epoch: 97
2022-11-18 02:05:01,479 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7731648531070975, 'Total loss': 0.7731648531070975} | train loss {'Reaction outcome loss': 0.8163243309884775, 'Total loss': 0.8163243309884775}
2022-11-18 02:05:01,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:01,479 INFO:     Epoch: 98
2022-11-18 02:05:02,334 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7829687948836836, 'Total loss': 0.7829687948836836} | train loss {'Reaction outcome loss': 0.8169849381827917, 'Total loss': 0.8169849381827917}
2022-11-18 02:05:02,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:02,335 INFO:     Epoch: 99
2022-11-18 02:05:03,202 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7828824332980222, 'Total loss': 0.7828824332980222} | train loss {'Reaction outcome loss': 0.8118306911382519, 'Total loss': 0.8118306911382519}
2022-11-18 02:05:03,202 INFO:     Best model found after epoch 55 of 100.
2022-11-18 02:05:03,202 INFO:   Done with stage: TRAINING
2022-11-18 02:05:03,202 INFO:   Starting stage: EVALUATION
2022-11-18 02:05:03,344 INFO:   Done with stage: EVALUATION
2022-11-18 02:05:03,344 INFO:   Leaving out SEQ value Fold_3
2022-11-18 02:05:03,357 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 02:05:03,357 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:05:04,025 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:05:04,025 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:05:04,095 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:05:04,095 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:05:04,095 INFO:     No hyperparam tuning for this model
2022-11-18 02:05:04,095 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:05:04,095 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:05:04,096 INFO:     None feature selector for col prot
2022-11-18 02:05:04,096 INFO:     None feature selector for col prot
2022-11-18 02:05:04,096 INFO:     None feature selector for col prot
2022-11-18 02:05:04,097 INFO:     None feature selector for col chem
2022-11-18 02:05:04,097 INFO:     None feature selector for col chem
2022-11-18 02:05:04,097 INFO:     None feature selector for col chem
2022-11-18 02:05:04,097 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:05:04,097 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:05:04,099 INFO:     Number of params in model 168571
2022-11-18 02:05:04,102 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:05:04,102 INFO:   Starting stage: TRAINING
2022-11-18 02:05:04,159 INFO:     Val loss before train {'Reaction outcome loss': 1.000305945223028, 'Total loss': 1.000305945223028}
2022-11-18 02:05:04,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:04,160 INFO:     Epoch: 0
2022-11-18 02:05:04,994 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8462865853851492, 'Total loss': 0.8462865853851492} | train loss {'Reaction outcome loss': 0.8832698365863488, 'Total loss': 0.8832698365863488}
2022-11-18 02:05:04,994 INFO:     Found new best model at epoch 0
2022-11-18 02:05:04,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:04,995 INFO:     Epoch: 1
2022-11-18 02:05:05,761 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8357167453928427, 'Total loss': 0.8357167453928427} | train loss {'Reaction outcome loss': 0.8480895069180703, 'Total loss': 0.8480895069180703}
2022-11-18 02:05:05,761 INFO:     Found new best model at epoch 1
2022-11-18 02:05:05,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:05,762 INFO:     Epoch: 2
2022-11-18 02:05:06,559 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8194736614823341, 'Total loss': 0.8194736614823341} | train loss {'Reaction outcome loss': 0.8430515943741311, 'Total loss': 0.8430515943741311}
2022-11-18 02:05:06,559 INFO:     Found new best model at epoch 2
2022-11-18 02:05:06,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:06,560 INFO:     Epoch: 3
2022-11-18 02:05:07,348 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8260330591689456, 'Total loss': 0.8260330591689456} | train loss {'Reaction outcome loss': 0.8395224332809448, 'Total loss': 0.8395224332809448}
2022-11-18 02:05:07,348 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:07,348 INFO:     Epoch: 4
2022-11-18 02:05:08,144 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8088440089063211, 'Total loss': 0.8088440089063211} | train loss {'Reaction outcome loss': 0.8359431157306749, 'Total loss': 0.8359431157306749}
2022-11-18 02:05:08,144 INFO:     Found new best model at epoch 4
2022-11-18 02:05:08,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:08,145 INFO:     Epoch: 5
2022-11-18 02:05:08,963 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8303296403451399, 'Total loss': 0.8303296403451399} | train loss {'Reaction outcome loss': 0.8317462270357171, 'Total loss': 0.8317462270357171}
2022-11-18 02:05:08,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:08,964 INFO:     Epoch: 6
2022-11-18 02:05:09,761 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8230480727824298, 'Total loss': 0.8230480727824298} | train loss {'Reaction outcome loss': 0.8257074699109914, 'Total loss': 0.8257074699109914}
2022-11-18 02:05:09,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:09,762 INFO:     Epoch: 7
2022-11-18 02:05:10,557 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8347817754203622, 'Total loss': 0.8347817754203622} | train loss {'Reaction outcome loss': 0.8337570241519383, 'Total loss': 0.8337570241519383}
2022-11-18 02:05:10,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:10,558 INFO:     Epoch: 8
2022-11-18 02:05:11,343 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8263834308494221, 'Total loss': 0.8263834308494221} | train loss {'Reaction outcome loss': 0.8253584844725472, 'Total loss': 0.8253584844725472}
2022-11-18 02:05:11,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:11,343 INFO:     Epoch: 9
2022-11-18 02:05:12,125 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8001317361539061, 'Total loss': 0.8001317361539061} | train loss {'Reaction outcome loss': 0.8224437565827857, 'Total loss': 0.8224437565827857}
2022-11-18 02:05:12,125 INFO:     Found new best model at epoch 9
2022-11-18 02:05:12,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:12,126 INFO:     Epoch: 10
2022-11-18 02:05:12,943 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8061000433835116, 'Total loss': 0.8061000433835116} | train loss {'Reaction outcome loss': 0.8279109114286851, 'Total loss': 0.8279109114286851}
2022-11-18 02:05:12,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:12,943 INFO:     Epoch: 11
2022-11-18 02:05:13,735 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8261107836257328, 'Total loss': 0.8261107836257328} | train loss {'Reaction outcome loss': 0.8221744862138008, 'Total loss': 0.8221744862138008}
2022-11-18 02:05:13,735 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:13,735 INFO:     Epoch: 12
2022-11-18 02:05:14,494 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8069920309565284, 'Total loss': 0.8069920309565284} | train loss {'Reaction outcome loss': 0.8204876000783882, 'Total loss': 0.8204876000783882}
2022-11-18 02:05:14,494 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:14,494 INFO:     Epoch: 13
2022-11-18 02:05:15,297 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8052230937914415, 'Total loss': 0.8052230937914415} | train loss {'Reaction outcome loss': 0.8171002798542685, 'Total loss': 0.8171002798542685}
2022-11-18 02:05:15,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:15,298 INFO:     Epoch: 14
2022-11-18 02:05:16,104 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8148976398462598, 'Total loss': 0.8148976398462598} | train loss {'Reaction outcome loss': 0.8200875101040821, 'Total loss': 0.8200875101040821}
2022-11-18 02:05:16,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:16,104 INFO:     Epoch: 15
2022-11-18 02:05:16,866 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8126967508684505, 'Total loss': 0.8126967508684505} | train loss {'Reaction outcome loss': 0.8166270867902405, 'Total loss': 0.8166270867902405}
2022-11-18 02:05:16,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:16,866 INFO:     Epoch: 16
2022-11-18 02:05:17,617 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8052548915147781, 'Total loss': 0.8052548915147781} | train loss {'Reaction outcome loss': 0.8180492296510813, 'Total loss': 0.8180492296510813}
2022-11-18 02:05:17,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:17,617 INFO:     Epoch: 17
2022-11-18 02:05:18,379 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7989476634697481, 'Total loss': 0.7989476634697481} | train loss {'Reaction outcome loss': 0.815646080338225, 'Total loss': 0.815646080338225}
2022-11-18 02:05:18,379 INFO:     Found new best model at epoch 17
2022-11-18 02:05:18,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:18,380 INFO:     Epoch: 18
2022-11-18 02:05:19,142 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8368447937748649, 'Total loss': 0.8368447937748649} | train loss {'Reaction outcome loss': 0.8183741850512368, 'Total loss': 0.8183741850512368}
2022-11-18 02:05:19,142 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:19,142 INFO:     Epoch: 19
2022-11-18 02:05:19,905 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8070473731918768, 'Total loss': 0.8070473731918768} | train loss {'Reaction outcome loss': 0.8139508562428611, 'Total loss': 0.8139508562428611}
2022-11-18 02:05:19,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:19,905 INFO:     Epoch: 20
2022-11-18 02:05:20,677 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8104184469716116, 'Total loss': 0.8104184469716116} | train loss {'Reaction outcome loss': 0.8121306657791137, 'Total loss': 0.8121306657791137}
2022-11-18 02:05:20,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:20,677 INFO:     Epoch: 21
2022-11-18 02:05:21,445 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8242779286070303, 'Total loss': 0.8242779286070303} | train loss {'Reaction outcome loss': 0.8128352733290926, 'Total loss': 0.8128352733290926}
2022-11-18 02:05:21,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:21,445 INFO:     Epoch: 22
2022-11-18 02:05:22,222 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8109032538804141, 'Total loss': 0.8109032538804141} | train loss {'Reaction outcome loss': 0.8135785703756371, 'Total loss': 0.8135785703756371}
2022-11-18 02:05:22,224 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:22,224 INFO:     Epoch: 23
2022-11-18 02:05:22,990 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8189898377115076, 'Total loss': 0.8189898377115076} | train loss {'Reaction outcome loss': 0.8187866287572043, 'Total loss': 0.8187866287572043}
2022-11-18 02:05:22,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:22,990 INFO:     Epoch: 24
2022-11-18 02:05:23,753 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8063098706982352, 'Total loss': 0.8063098706982352} | train loss {'Reaction outcome loss': 0.8141995788836965, 'Total loss': 0.8141995788836965}
2022-11-18 02:05:23,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:23,753 INFO:     Epoch: 25
2022-11-18 02:05:24,512 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7900005775419149, 'Total loss': 0.7900005775419149} | train loss {'Reaction outcome loss': 0.814986909773885, 'Total loss': 0.814986909773885}
2022-11-18 02:05:24,512 INFO:     Found new best model at epoch 25
2022-11-18 02:05:24,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:24,513 INFO:     Epoch: 26
2022-11-18 02:05:25,294 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8096876252781261, 'Total loss': 0.8096876252781261} | train loss {'Reaction outcome loss': 0.8139353893241104, 'Total loss': 0.8139353893241104}
2022-11-18 02:05:25,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:25,294 INFO:     Epoch: 27
2022-11-18 02:05:26,074 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8025126375935294, 'Total loss': 0.8025126375935294} | train loss {'Reaction outcome loss': 0.814008733326075, 'Total loss': 0.814008733326075}
2022-11-18 02:05:26,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:26,074 INFO:     Epoch: 28
2022-11-18 02:05:26,863 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8120446130633354, 'Total loss': 0.8120446130633354} | train loss {'Reaction outcome loss': 0.815551264675296, 'Total loss': 0.815551264675296}
2022-11-18 02:05:26,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:26,863 INFO:     Epoch: 29
2022-11-18 02:05:27,636 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8231177113272927, 'Total loss': 0.8231177113272927} | train loss {'Reaction outcome loss': 0.8131839343479701, 'Total loss': 0.8131839343479701}
2022-11-18 02:05:27,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:27,636 INFO:     Epoch: 30
2022-11-18 02:05:28,396 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7964440387758341, 'Total loss': 0.7964440387758341} | train loss {'Reaction outcome loss': 0.8186093323084773, 'Total loss': 0.8186093323084773}
2022-11-18 02:05:28,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:28,397 INFO:     Epoch: 31
2022-11-18 02:05:29,145 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8147412911057472, 'Total loss': 0.8147412911057472} | train loss {'Reaction outcome loss': 0.8119568763947, 'Total loss': 0.8119568763947}
2022-11-18 02:05:29,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:29,146 INFO:     Epoch: 32
2022-11-18 02:05:29,937 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8112969520417127, 'Total loss': 0.8112969520417127} | train loss {'Reaction outcome loss': 0.8133319831624323, 'Total loss': 0.8133319831624323}
2022-11-18 02:05:29,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:29,938 INFO:     Epoch: 33
2022-11-18 02:05:30,730 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7940376841209151, 'Total loss': 0.7940376841209151} | train loss {'Reaction outcome loss': 0.8127326027471192, 'Total loss': 0.8127326027471192}
2022-11-18 02:05:30,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:30,730 INFO:     Epoch: 34
2022-11-18 02:05:31,499 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7923342368819497, 'Total loss': 0.7923342368819497} | train loss {'Reaction outcome loss': 0.8138370843566194, 'Total loss': 0.8138370843566194}
2022-11-18 02:05:31,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:31,499 INFO:     Epoch: 35
2022-11-18 02:05:32,277 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8244993408972566, 'Total loss': 0.8244993408972566} | train loss {'Reaction outcome loss': 0.8118079173321626, 'Total loss': 0.8118079173321626}
2022-11-18 02:05:32,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:32,277 INFO:     Epoch: 36
2022-11-18 02:05:33,051 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8210854137485678, 'Total loss': 0.8210854137485678} | train loss {'Reaction outcome loss': 0.8116703134410236, 'Total loss': 0.8116703134410236}
2022-11-18 02:05:33,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:33,051 INFO:     Epoch: 37
2022-11-18 02:05:33,834 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8049434606324543, 'Total loss': 0.8049434606324543} | train loss {'Reaction outcome loss': 0.8131341480478949, 'Total loss': 0.8131341480478949}
2022-11-18 02:05:33,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:33,834 INFO:     Epoch: 38
2022-11-18 02:05:34,605 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8040957030924883, 'Total loss': 0.8040957030924883} | train loss {'Reaction outcome loss': 0.8111332803356405, 'Total loss': 0.8111332803356405}
2022-11-18 02:05:34,605 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:34,606 INFO:     Epoch: 39
2022-11-18 02:05:35,386 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8235562585971572, 'Total loss': 0.8235562585971572} | train loss {'Reaction outcome loss': 0.8150531364946949, 'Total loss': 0.8150531364946949}
2022-11-18 02:05:35,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:35,387 INFO:     Epoch: 40
2022-11-18 02:05:36,166 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8213562294840813, 'Total loss': 0.8213562294840813} | train loss {'Reaction outcome loss': 0.8150077778465894, 'Total loss': 0.8150077778465894}
2022-11-18 02:05:36,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:36,167 INFO:     Epoch: 41
2022-11-18 02:05:36,928 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.808123795146292, 'Total loss': 0.808123795146292} | train loss {'Reaction outcome loss': 0.8115403631511999, 'Total loss': 0.8115403631511999}
2022-11-18 02:05:36,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:36,928 INFO:     Epoch: 42
2022-11-18 02:05:37,694 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8254122855988416, 'Total loss': 0.8254122855988416} | train loss {'Reaction outcome loss': 0.8120886448694735, 'Total loss': 0.8120886448694735}
2022-11-18 02:05:37,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:37,695 INFO:     Epoch: 43
2022-11-18 02:05:38,462 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7922573949803006, 'Total loss': 0.7922573949803006} | train loss {'Reaction outcome loss': 0.8122543469983704, 'Total loss': 0.8122543469983704}
2022-11-18 02:05:38,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:38,463 INFO:     Epoch: 44
2022-11-18 02:05:39,230 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8016050437634642, 'Total loss': 0.8016050437634642} | train loss {'Reaction outcome loss': 0.8116663049678413, 'Total loss': 0.8116663049678413}
2022-11-18 02:05:39,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:39,231 INFO:     Epoch: 45
2022-11-18 02:05:40,024 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7993238547986204, 'Total loss': 0.7993238547986204} | train loss {'Reaction outcome loss': 0.81220211751607, 'Total loss': 0.81220211751607}
2022-11-18 02:05:40,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:40,024 INFO:     Epoch: 46
2022-11-18 02:05:40,770 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8006095550954342, 'Total loss': 0.8006095550954342} | train loss {'Reaction outcome loss': 0.8114191055297851, 'Total loss': 0.8114191055297851}
2022-11-18 02:05:40,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:40,771 INFO:     Epoch: 47
2022-11-18 02:05:41,557 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8237825056368654, 'Total loss': 0.8237825056368654} | train loss {'Reaction outcome loss': 0.8132982654230935, 'Total loss': 0.8132982654230935}
2022-11-18 02:05:41,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:41,558 INFO:     Epoch: 48
2022-11-18 02:05:42,341 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7979104898192666, 'Total loss': 0.7979104898192666} | train loss {'Reaction outcome loss': 0.8157610838510552, 'Total loss': 0.8157610838510552}
2022-11-18 02:05:42,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:42,341 INFO:     Epoch: 49
2022-11-18 02:05:43,095 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8534534146839922, 'Total loss': 0.8534534146839922} | train loss {'Reaction outcome loss': 0.8133495661677147, 'Total loss': 0.8133495661677147}
2022-11-18 02:05:43,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:43,096 INFO:     Epoch: 50
2022-11-18 02:05:43,876 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8282202753153715, 'Total loss': 0.8282202753153715} | train loss {'Reaction outcome loss': 0.8132241224756046, 'Total loss': 0.8132241224756046}
2022-11-18 02:05:43,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:43,876 INFO:     Epoch: 51
2022-11-18 02:05:44,648 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8135056949474595, 'Total loss': 0.8135056949474595} | train loss {'Reaction outcome loss': 0.8159590290517224, 'Total loss': 0.8159590290517224}
2022-11-18 02:05:44,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:44,649 INFO:     Epoch: 52
2022-11-18 02:05:45,437 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.790248413654891, 'Total loss': 0.790248413654891} | train loss {'Reaction outcome loss': 0.8080404652624714, 'Total loss': 0.8080404652624714}
2022-11-18 02:05:45,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:45,438 INFO:     Epoch: 53
2022-11-18 02:05:46,246 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8321419696916234, 'Total loss': 0.8321419696916234} | train loss {'Reaction outcome loss': 0.8119878987876736, 'Total loss': 0.8119878987876736}
2022-11-18 02:05:46,246 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:46,246 INFO:     Epoch: 54
2022-11-18 02:05:47,044 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7857144163413481, 'Total loss': 0.7857144163413481} | train loss {'Reaction outcome loss': 0.8121651274817331, 'Total loss': 0.8121651274817331}
2022-11-18 02:05:47,044 INFO:     Found new best model at epoch 54
2022-11-18 02:05:47,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:47,045 INFO:     Epoch: 55
2022-11-18 02:05:47,844 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8144418177279559, 'Total loss': 0.8144418177279559} | train loss {'Reaction outcome loss': 0.8102281858726423, 'Total loss': 0.8102281858726423}
2022-11-18 02:05:47,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:47,845 INFO:     Epoch: 56
2022-11-18 02:05:48,647 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8254536078734831, 'Total loss': 0.8254536078734831} | train loss {'Reaction outcome loss': 0.8104794969364089, 'Total loss': 0.8104794969364089}
2022-11-18 02:05:48,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:48,647 INFO:     Epoch: 57
2022-11-18 02:05:49,473 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8219853124835275, 'Total loss': 0.8219853124835275} | train loss {'Reaction outcome loss': 0.8120810754445135, 'Total loss': 0.8120810754445135}
2022-11-18 02:05:49,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:49,473 INFO:     Epoch: 58
2022-11-18 02:05:50,268 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8331409381194548, 'Total loss': 0.8331409381194548} | train loss {'Reaction outcome loss': 0.8136587338788169, 'Total loss': 0.8136587338788169}
2022-11-18 02:05:50,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:50,269 INFO:     Epoch: 59
2022-11-18 02:05:51,049 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.806391834535382, 'Total loss': 0.806391834535382} | train loss {'Reaction outcome loss': 0.8124774435345008, 'Total loss': 0.8124774435345008}
2022-11-18 02:05:51,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:51,050 INFO:     Epoch: 60
2022-11-18 02:05:51,843 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8193483894521539, 'Total loss': 0.8193483894521539} | train loss {'Reaction outcome loss': 0.806839651355938, 'Total loss': 0.806839651355938}
2022-11-18 02:05:51,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:51,843 INFO:     Epoch: 61
2022-11-18 02:05:52,623 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8048256540840323, 'Total loss': 0.8048256540840323} | train loss {'Reaction outcome loss': 0.8145125549666735, 'Total loss': 0.8145125549666735}
2022-11-18 02:05:52,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:52,623 INFO:     Epoch: 62
2022-11-18 02:05:53,442 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8171389055523005, 'Total loss': 0.8171389055523005} | train loss {'Reaction outcome loss': 0.8104578841705712, 'Total loss': 0.8104578841705712}
2022-11-18 02:05:53,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:53,444 INFO:     Epoch: 63
2022-11-18 02:05:54,221 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8000079020857811, 'Total loss': 0.8000079020857811} | train loss {'Reaction outcome loss': 0.8072848504903365, 'Total loss': 0.8072848504903365}
2022-11-18 02:05:54,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:54,221 INFO:     Epoch: 64
2022-11-18 02:05:55,061 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8244529082016512, 'Total loss': 0.8244529082016512} | train loss {'Reaction outcome loss': 0.810096219729404, 'Total loss': 0.810096219729404}
2022-11-18 02:05:55,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:55,061 INFO:     Epoch: 65
2022-11-18 02:05:55,907 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8085929927500811, 'Total loss': 0.8085929927500811} | train loss {'Reaction outcome loss': 0.8141462059653535, 'Total loss': 0.8141462059653535}
2022-11-18 02:05:55,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:55,908 INFO:     Epoch: 66
2022-11-18 02:05:56,715 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.813856608488343, 'Total loss': 0.813856608488343} | train loss {'Reaction outcome loss': 0.8125009513631158, 'Total loss': 0.8125009513631158}
2022-11-18 02:05:56,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:56,715 INFO:     Epoch: 67
2022-11-18 02:05:57,530 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8064409257336096, 'Total loss': 0.8064409257336096} | train loss {'Reaction outcome loss': 0.8106496686838112, 'Total loss': 0.8106496686838112}
2022-11-18 02:05:57,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:57,530 INFO:     Epoch: 68
2022-11-18 02:05:58,340 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8196111341769045, 'Total loss': 0.8196111341769045} | train loss {'Reaction outcome loss': 0.8153794225381346, 'Total loss': 0.8153794225381346}
2022-11-18 02:05:58,340 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:58,341 INFO:     Epoch: 69
2022-11-18 02:05:59,132 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8166326101530682, 'Total loss': 0.8166326101530682} | train loss {'Reaction outcome loss': 0.8130662554380845, 'Total loss': 0.8130662554380845}
2022-11-18 02:05:59,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:59,133 INFO:     Epoch: 70
2022-11-18 02:05:59,953 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8070348128676414, 'Total loss': 0.8070348128676414} | train loss {'Reaction outcome loss': 0.8110057160562398, 'Total loss': 0.8110057160562398}
2022-11-18 02:05:59,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:05:59,954 INFO:     Epoch: 71
2022-11-18 02:06:00,733 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8127460520375859, 'Total loss': 0.8127460520375859} | train loss {'Reaction outcome loss': 0.8156201693476463, 'Total loss': 0.8156201693476463}
2022-11-18 02:06:00,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:00,733 INFO:     Epoch: 72
2022-11-18 02:06:01,515 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8249201679771597, 'Total loss': 0.8249201679771597} | train loss {'Reaction outcome loss': 0.8104208640906275, 'Total loss': 0.8104208640906275}
2022-11-18 02:06:01,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:01,515 INFO:     Epoch: 73
2022-11-18 02:06:02,289 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8065343546596441, 'Total loss': 0.8065343546596441} | train loss {'Reaction outcome loss': 0.8111151273153266, 'Total loss': 0.8111151273153266}
2022-11-18 02:06:02,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:02,289 INFO:     Epoch: 74
2022-11-18 02:06:03,067 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.809462306174365, 'Total loss': 0.809462306174365} | train loss {'Reaction outcome loss': 0.8135171710228434, 'Total loss': 0.8135171710228434}
2022-11-18 02:06:03,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:03,067 INFO:     Epoch: 75
2022-11-18 02:06:03,846 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7966854436831041, 'Total loss': 0.7966854436831041} | train loss {'Reaction outcome loss': 0.8100781890810752, 'Total loss': 0.8100781890810752}
2022-11-18 02:06:03,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:03,846 INFO:     Epoch: 76
2022-11-18 02:06:04,599 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8047285987572237, 'Total loss': 0.8047285987572237} | train loss {'Reaction outcome loss': 0.8095413717688347, 'Total loss': 0.8095413717688347}
2022-11-18 02:06:04,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:04,600 INFO:     Epoch: 77
2022-11-18 02:06:05,396 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8142281994223595, 'Total loss': 0.8142281994223595} | train loss {'Reaction outcome loss': 0.814418661716033, 'Total loss': 0.814418661716033}
2022-11-18 02:06:05,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:05,396 INFO:     Epoch: 78
2022-11-18 02:06:06,182 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8050364635207437, 'Total loss': 0.8050364635207437} | train loss {'Reaction outcome loss': 0.8105718359655264, 'Total loss': 0.8105718359655264}
2022-11-18 02:06:06,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:06,182 INFO:     Epoch: 79
2022-11-18 02:06:06,962 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8281873870979656, 'Total loss': 0.8281873870979656} | train loss {'Reaction outcome loss': 0.8115576234399056, 'Total loss': 0.8115576234399056}
2022-11-18 02:06:06,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:06,963 INFO:     Epoch: 80
2022-11-18 02:06:07,739 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7989251810041341, 'Total loss': 0.7989251810041341} | train loss {'Reaction outcome loss': 0.8190957396614308, 'Total loss': 0.8190957396614308}
2022-11-18 02:06:07,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:07,739 INFO:     Epoch: 81
2022-11-18 02:06:08,525 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8063089793378656, 'Total loss': 0.8063089793378656} | train loss {'Reaction outcome loss': 0.8092056167368986, 'Total loss': 0.8092056167368986}
2022-11-18 02:06:08,525 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:08,525 INFO:     Epoch: 82
2022-11-18 02:06:09,322 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8049238148060712, 'Total loss': 0.8049238148060712} | train loss {'Reaction outcome loss': 0.8124116682276434, 'Total loss': 0.8124116682276434}
2022-11-18 02:06:09,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:09,322 INFO:     Epoch: 83
2022-11-18 02:06:10,093 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8162315873937174, 'Total loss': 0.8162315873937174} | train loss {'Reaction outcome loss': 0.8153771222854147, 'Total loss': 0.8153771222854147}
2022-11-18 02:06:10,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:10,094 INFO:     Epoch: 84
2022-11-18 02:06:10,875 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8047815371643413, 'Total loss': 0.8047815371643413} | train loss {'Reaction outcome loss': 0.8101412815707071, 'Total loss': 0.8101412815707071}
2022-11-18 02:06:10,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:10,875 INFO:     Epoch: 85
2022-11-18 02:06:11,650 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8261980068954554, 'Total loss': 0.8261980068954554} | train loss {'Reaction outcome loss': 0.8094069169492137, 'Total loss': 0.8094069169492137}
2022-11-18 02:06:11,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:11,650 INFO:     Epoch: 86
2022-11-18 02:06:12,399 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8248943368142302, 'Total loss': 0.8248943368142302} | train loss {'Reaction outcome loss': 0.8118587300485495, 'Total loss': 0.8118587300485495}
2022-11-18 02:06:12,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:12,400 INFO:     Epoch: 87
2022-11-18 02:06:13,175 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.799542791464112, 'Total loss': 0.799542791464112} | train loss {'Reaction outcome loss': 0.8094412141916704, 'Total loss': 0.8094412141916704}
2022-11-18 02:06:13,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:13,175 INFO:     Epoch: 88
2022-11-18 02:06:13,942 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.836537248708985, 'Total loss': 0.836537248708985} | train loss {'Reaction outcome loss': 0.8120278780557671, 'Total loss': 0.8120278780557671}
2022-11-18 02:06:13,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:13,942 INFO:     Epoch: 89
2022-11-18 02:06:14,749 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8069011826406826, 'Total loss': 0.8069011826406826} | train loss {'Reaction outcome loss': 0.8119536818290244, 'Total loss': 0.8119536818290244}
2022-11-18 02:06:14,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:14,749 INFO:     Epoch: 90
2022-11-18 02:06:15,541 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.787510318342935, 'Total loss': 0.787510318342935} | train loss {'Reaction outcome loss': 0.8098294616961966, 'Total loss': 0.8098294616961966}
2022-11-18 02:06:15,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:15,541 INFO:     Epoch: 91
2022-11-18 02:06:16,321 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8022621531378139, 'Total loss': 0.8022621531378139} | train loss {'Reaction outcome loss': 0.8094902438776833, 'Total loss': 0.8094902438776833}
2022-11-18 02:06:16,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:16,322 INFO:     Epoch: 92
2022-11-18 02:06:17,100 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8285350562496618, 'Total loss': 0.8285350562496618} | train loss {'Reaction outcome loss': 0.8073948740959167, 'Total loss': 0.8073948740959167}
2022-11-18 02:06:17,100 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:17,101 INFO:     Epoch: 93
2022-11-18 02:06:17,887 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8076714345000007, 'Total loss': 0.8076714345000007} | train loss {'Reaction outcome loss': 0.8114662711717644, 'Total loss': 0.8114662711717644}
2022-11-18 02:06:17,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:17,887 INFO:     Epoch: 94
2022-11-18 02:06:18,664 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8328938768668608, 'Total loss': 0.8328938768668608} | train loss {'Reaction outcome loss': 0.8061789530880598, 'Total loss': 0.8061789530880598}
2022-11-18 02:06:18,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:18,665 INFO:     Epoch: 95
2022-11-18 02:06:19,419 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8106243366544897, 'Total loss': 0.8106243366544897} | train loss {'Reaction outcome loss': 0.8084883643656361, 'Total loss': 0.8084883643656361}
2022-11-18 02:06:19,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:19,419 INFO:     Epoch: 96
2022-11-18 02:06:20,190 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8073397414250807, 'Total loss': 0.8073397414250807} | train loss {'Reaction outcome loss': 0.8145094439691427, 'Total loss': 0.8145094439691427}
2022-11-18 02:06:20,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:20,190 INFO:     Epoch: 97
2022-11-18 02:06:20,970 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7949675460430708, 'Total loss': 0.7949675460430708} | train loss {'Reaction outcome loss': 0.8116806705387272, 'Total loss': 0.8116806705387272}
2022-11-18 02:06:20,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:20,970 INFO:     Epoch: 98
2022-11-18 02:06:21,740 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8081481138413603, 'Total loss': 0.8081481138413603} | train loss {'Reaction outcome loss': 0.8055794425156652, 'Total loss': 0.8055794425156652}
2022-11-18 02:06:21,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:21,740 INFO:     Epoch: 99
2022-11-18 02:06:22,521 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8230504149740393, 'Total loss': 0.8230504149740393} | train loss {'Reaction outcome loss': 0.8169742846975521, 'Total loss': 0.8169742846975521}
2022-11-18 02:06:22,521 INFO:     Best model found after epoch 55 of 100.
2022-11-18 02:06:22,522 INFO:   Done with stage: TRAINING
2022-11-18 02:06:22,522 INFO:   Starting stage: EVALUATION
2022-11-18 02:06:22,655 INFO:   Done with stage: EVALUATION
2022-11-18 02:06:22,655 INFO:   Leaving out SEQ value Fold_4
2022-11-18 02:06:22,668 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 02:06:22,668 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:06:23,342 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:06:23,342 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:06:23,412 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:06:23,412 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:06:23,412 INFO:     No hyperparam tuning for this model
2022-11-18 02:06:23,412 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:06:23,412 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:06:23,413 INFO:     None feature selector for col prot
2022-11-18 02:06:23,413 INFO:     None feature selector for col prot
2022-11-18 02:06:23,413 INFO:     None feature selector for col prot
2022-11-18 02:06:23,414 INFO:     None feature selector for col chem
2022-11-18 02:06:23,414 INFO:     None feature selector for col chem
2022-11-18 02:06:23,414 INFO:     None feature selector for col chem
2022-11-18 02:06:23,414 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:06:23,414 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:06:23,416 INFO:     Number of params in model 168571
2022-11-18 02:06:23,419 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:06:23,419 INFO:   Starting stage: TRAINING
2022-11-18 02:06:23,478 INFO:     Val loss before train {'Reaction outcome loss': 0.9945213767615232, 'Total loss': 0.9945213767615232}
2022-11-18 02:06:23,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:23,478 INFO:     Epoch: 0
2022-11-18 02:06:24,259 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8423494222489271, 'Total loss': 0.8423494222489271} | train loss {'Reaction outcome loss': 0.8848887005074304, 'Total loss': 0.8848887005074304}
2022-11-18 02:06:24,261 INFO:     Found new best model at epoch 0
2022-11-18 02:06:24,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:24,262 INFO:     Epoch: 1
2022-11-18 02:06:25,034 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8240658038041808, 'Total loss': 0.8240658038041808} | train loss {'Reaction outcome loss': 0.8508576233136026, 'Total loss': 0.8508576233136026}
2022-11-18 02:06:25,035 INFO:     Found new best model at epoch 1
2022-11-18 02:06:25,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:25,036 INFO:     Epoch: 2
2022-11-18 02:06:25,812 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8177962723103437, 'Total loss': 0.8177962723103437} | train loss {'Reaction outcome loss': 0.8473365510161589, 'Total loss': 0.8473365510161589}
2022-11-18 02:06:25,812 INFO:     Found new best model at epoch 2
2022-11-18 02:06:25,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:25,813 INFO:     Epoch: 3
2022-11-18 02:06:26,614 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8234006897969679, 'Total loss': 0.8234006897969679} | train loss {'Reaction outcome loss': 0.8511915637655296, 'Total loss': 0.8511915637655296}
2022-11-18 02:06:26,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:26,614 INFO:     Epoch: 4
2022-11-18 02:06:27,404 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8299730379473079, 'Total loss': 0.8299730379473079} | train loss {'Reaction outcome loss': 0.8354371367437154, 'Total loss': 0.8354371367437154}
2022-11-18 02:06:27,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:27,405 INFO:     Epoch: 5
2022-11-18 02:06:28,188 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8059564307332039, 'Total loss': 0.8059564307332039} | train loss {'Reaction outcome loss': 0.8375772327064019, 'Total loss': 0.8375772327064019}
2022-11-18 02:06:28,189 INFO:     Found new best model at epoch 5
2022-11-18 02:06:28,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:28,190 INFO:     Epoch: 6
2022-11-18 02:06:28,999 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8003161996603012, 'Total loss': 0.8003161996603012} | train loss {'Reaction outcome loss': 0.8329720612585183, 'Total loss': 0.8329720612585183}
2022-11-18 02:06:29,000 INFO:     Found new best model at epoch 6
2022-11-18 02:06:29,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:29,000 INFO:     Epoch: 7
2022-11-18 02:06:29,767 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8399766209450635, 'Total loss': 0.8399766209450635} | train loss {'Reaction outcome loss': 0.8290429525529808, 'Total loss': 0.8290429525529808}
2022-11-18 02:06:29,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:29,767 INFO:     Epoch: 8
2022-11-18 02:06:30,531 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8184782964262095, 'Total loss': 0.8184782964262095} | train loss {'Reaction outcome loss': 0.832483245896907, 'Total loss': 0.832483245896907}
2022-11-18 02:06:30,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:30,532 INFO:     Epoch: 9
2022-11-18 02:06:31,304 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7980205203321847, 'Total loss': 0.7980205203321847} | train loss {'Reaction outcome loss': 0.8290729259672435, 'Total loss': 0.8290729259672435}
2022-11-18 02:06:31,304 INFO:     Found new best model at epoch 9
2022-11-18 02:06:31,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:31,305 INFO:     Epoch: 10
2022-11-18 02:06:32,084 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8050887950442054, 'Total loss': 0.8050887950442054} | train loss {'Reaction outcome loss': 0.8273390669692383, 'Total loss': 0.8273390669692383}
2022-11-18 02:06:32,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:32,084 INFO:     Epoch: 11
2022-11-18 02:06:32,855 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.814368951049718, 'Total loss': 0.814368951049718} | train loss {'Reaction outcome loss': 0.8293829881227933, 'Total loss': 0.8293829881227933}
2022-11-18 02:06:32,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:32,856 INFO:     Epoch: 12
2022-11-18 02:06:33,637 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7994867339730263, 'Total loss': 0.7994867339730263} | train loss {'Reaction outcome loss': 0.8249443493150024, 'Total loss': 0.8249443493150024}
2022-11-18 02:06:33,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:33,638 INFO:     Epoch: 13
2022-11-18 02:06:34,432 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8021906912326813, 'Total loss': 0.8021906912326813} | train loss {'Reaction outcome loss': 0.8230699853979142, 'Total loss': 0.8230699853979142}
2022-11-18 02:06:34,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:34,433 INFO:     Epoch: 14
2022-11-18 02:06:35,222 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8289519914171912, 'Total loss': 0.8289519914171912} | train loss {'Reaction outcome loss': 0.8301823816077429, 'Total loss': 0.8301823816077429}
2022-11-18 02:06:35,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:35,222 INFO:     Epoch: 15
2022-11-18 02:06:36,013 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8013846738771959, 'Total loss': 0.8013846738771959} | train loss {'Reaction outcome loss': 0.8350420537506521, 'Total loss': 0.8350420537506521}
2022-11-18 02:06:36,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:36,013 INFO:     Epoch: 16
2022-11-18 02:06:36,800 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.808072648265145, 'Total loss': 0.808072648265145} | train loss {'Reaction outcome loss': 0.8211622830585912, 'Total loss': 0.8211622830585912}
2022-11-18 02:06:36,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:36,800 INFO:     Epoch: 17
2022-11-18 02:06:37,557 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8087379559874535, 'Total loss': 0.8087379559874535} | train loss {'Reaction outcome loss': 0.8251338302485856, 'Total loss': 0.8251338302485856}
2022-11-18 02:06:37,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:37,557 INFO:     Epoch: 18
2022-11-18 02:06:38,330 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.810304619371891, 'Total loss': 0.810304619371891} | train loss {'Reaction outcome loss': 0.8206495996790859, 'Total loss': 0.8206495996790859}
2022-11-18 02:06:38,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:38,330 INFO:     Epoch: 19
2022-11-18 02:06:39,106 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8109425712715496, 'Total loss': 0.8109425712715496} | train loss {'Reaction outcome loss': 0.8236930685246039, 'Total loss': 0.8236930685246039}
2022-11-18 02:06:39,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:39,106 INFO:     Epoch: 20
2022-11-18 02:06:39,875 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8211153705011714, 'Total loss': 0.8211153705011714} | train loss {'Reaction outcome loss': 0.8287113067592203, 'Total loss': 0.8287113067592203}
2022-11-18 02:06:39,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:39,875 INFO:     Epoch: 21
2022-11-18 02:06:40,660 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8241383853283796, 'Total loss': 0.8241383853283796} | train loss {'Reaction outcome loss': 0.828176249135361, 'Total loss': 0.828176249135361}
2022-11-18 02:06:40,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:40,660 INFO:     Epoch: 22
2022-11-18 02:06:41,440 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8097894286567514, 'Total loss': 0.8097894286567514} | train loss {'Reaction outcome loss': 0.8260192766122008, 'Total loss': 0.8260192766122008}
2022-11-18 02:06:41,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:41,440 INFO:     Epoch: 23
2022-11-18 02:06:42,224 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7940085801211271, 'Total loss': 0.7940085801211271} | train loss {'Reaction outcome loss': 0.8220206417052852, 'Total loss': 0.8220206417052852}
2022-11-18 02:06:42,225 INFO:     Found new best model at epoch 23
2022-11-18 02:06:42,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:42,225 INFO:     Epoch: 24
2022-11-18 02:06:43,009 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8123071898113597, 'Total loss': 0.8123071898113597} | train loss {'Reaction outcome loss': 0.821035892434931, 'Total loss': 0.821035892434931}
2022-11-18 02:06:43,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:43,010 INFO:     Epoch: 25
2022-11-18 02:06:43,796 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8243753165006638, 'Total loss': 0.8243753165006638} | train loss {'Reaction outcome loss': 0.8198151598092516, 'Total loss': 0.8198151598092516}
2022-11-18 02:06:43,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:43,796 INFO:     Epoch: 26
2022-11-18 02:06:44,606 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8071505732157014, 'Total loss': 0.8071505732157014} | train loss {'Reaction outcome loss': 0.8299584722953287, 'Total loss': 0.8299584722953287}
2022-11-18 02:06:44,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:44,606 INFO:     Epoch: 27
2022-11-18 02:06:45,399 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8064981272274797, 'Total loss': 0.8064981272274797} | train loss {'Reaction outcome loss': 0.8222499885464366, 'Total loss': 0.8222499885464366}
2022-11-18 02:06:45,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:45,399 INFO:     Epoch: 28
2022-11-18 02:06:46,193 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8075984201648019, 'Total loss': 0.8075984201648019} | train loss {'Reaction outcome loss': 0.8220521282811879, 'Total loss': 0.8220521282811879}
2022-11-18 02:06:46,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:46,194 INFO:     Epoch: 29
2022-11-18 02:06:46,980 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.806454059752551, 'Total loss': 0.806454059752551} | train loss {'Reaction outcome loss': 0.8172129316006594, 'Total loss': 0.8172129316006594}
2022-11-18 02:06:46,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:46,980 INFO:     Epoch: 30
2022-11-18 02:06:47,766 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8468355292623694, 'Total loss': 0.8468355292623694} | train loss {'Reaction outcome loss': 0.8236396917206074, 'Total loss': 0.8236396917206074}
2022-11-18 02:06:47,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:47,767 INFO:     Epoch: 31
2022-11-18 02:06:48,563 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7841020355170424, 'Total loss': 0.7841020355170424} | train loss {'Reaction outcome loss': 0.8213971388726099, 'Total loss': 0.8213971388726099}
2022-11-18 02:06:48,563 INFO:     Found new best model at epoch 31
2022-11-18 02:06:48,564 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:48,564 INFO:     Epoch: 32
2022-11-18 02:06:49,363 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8201056359843775, 'Total loss': 0.8201056359843775} | train loss {'Reaction outcome loss': 0.831217257841396, 'Total loss': 0.831217257841396}
2022-11-18 02:06:49,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:49,363 INFO:     Epoch: 33
2022-11-18 02:06:50,176 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8242076594721187, 'Total loss': 0.8242076594721187} | train loss {'Reaction outcome loss': 0.8183048021365033, 'Total loss': 0.8183048021365033}
2022-11-18 02:06:50,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:50,176 INFO:     Epoch: 34
2022-11-18 02:06:50,959 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7921098843216896, 'Total loss': 0.7921098843216896} | train loss {'Reaction outcome loss': 0.8222901885084778, 'Total loss': 0.8222901885084778}
2022-11-18 02:06:50,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:50,960 INFO:     Epoch: 35
2022-11-18 02:06:51,773 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8040110678835348, 'Total loss': 0.8040110678835348} | train loss {'Reaction outcome loss': 0.8171829891952909, 'Total loss': 0.8171829891952909}
2022-11-18 02:06:51,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:51,774 INFO:     Epoch: 36
2022-11-18 02:06:52,551 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8080167783932253, 'Total loss': 0.8080167783932253} | train loss {'Reaction outcome loss': 0.8186756143203149, 'Total loss': 0.8186756143203149}
2022-11-18 02:06:52,551 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:52,551 INFO:     Epoch: 37
2022-11-18 02:06:53,333 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7893952131271362, 'Total loss': 0.7893952131271362} | train loss {'Reaction outcome loss': 0.8138188126870254, 'Total loss': 0.8138188126870254}
2022-11-18 02:06:53,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:53,334 INFO:     Epoch: 38
2022-11-18 02:06:54,116 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7841102203184908, 'Total loss': 0.7841102203184908} | train loss {'Reaction outcome loss': 0.8157933459349489, 'Total loss': 0.8157933459349489}
2022-11-18 02:06:54,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:54,117 INFO:     Epoch: 39
2022-11-18 02:06:54,910 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8137547089294954, 'Total loss': 0.8137547089294954} | train loss {'Reaction outcome loss': 0.8230039803122702, 'Total loss': 0.8230039803122702}
2022-11-18 02:06:54,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:54,912 INFO:     Epoch: 40
2022-11-18 02:06:55,704 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8049701431935484, 'Total loss': 0.8049701431935484} | train loss {'Reaction outcome loss': 0.8253037185080139, 'Total loss': 0.8253037185080139}
2022-11-18 02:06:55,704 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:55,704 INFO:     Epoch: 41
2022-11-18 02:06:56,490 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8012255504727364, 'Total loss': 0.8012255504727364} | train loss {'Reaction outcome loss': 0.8149405702013477, 'Total loss': 0.8149405702013477}
2022-11-18 02:06:56,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:56,490 INFO:     Epoch: 42
2022-11-18 02:06:57,260 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7885171682997183, 'Total loss': 0.7885171682997183} | train loss {'Reaction outcome loss': 0.8182517890988091, 'Total loss': 0.8182517890988091}
2022-11-18 02:06:57,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:57,260 INFO:     Epoch: 43
2022-11-18 02:06:58,037 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8035081618211486, 'Total loss': 0.8035081618211486} | train loss {'Reaction outcome loss': 0.8152460417887459, 'Total loss': 0.8152460417887459}
2022-11-18 02:06:58,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:58,037 INFO:     Epoch: 44
2022-11-18 02:06:58,830 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.805171823637052, 'Total loss': 0.805171823637052} | train loss {'Reaction outcome loss': 0.8266793287958694, 'Total loss': 0.8266793287958694}
2022-11-18 02:06:58,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:58,831 INFO:     Epoch: 45
2022-11-18 02:06:59,589 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7948892184279182, 'Total loss': 0.7948892184279182} | train loss {'Reaction outcome loss': 0.8276279708031218, 'Total loss': 0.8276279708031218}
2022-11-18 02:06:59,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:06:59,589 INFO:     Epoch: 46
2022-11-18 02:07:00,374 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8030958737839352, 'Total loss': 0.8030958737839352} | train loss {'Reaction outcome loss': 0.8127107054055461, 'Total loss': 0.8127107054055461}
2022-11-18 02:07:00,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:00,375 INFO:     Epoch: 47
2022-11-18 02:07:01,167 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8040228933095932, 'Total loss': 0.8040228933095932} | train loss {'Reaction outcome loss': 0.8177979301947814, 'Total loss': 0.8177979301947814}
2022-11-18 02:07:01,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:01,168 INFO:     Epoch: 48
2022-11-18 02:07:01,990 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7894548976963217, 'Total loss': 0.7894548976963217} | train loss {'Reaction outcome loss': 0.8156562249670144, 'Total loss': 0.8156562249670144}
2022-11-18 02:07:01,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:01,990 INFO:     Epoch: 49
2022-11-18 02:07:02,787 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7880290245467966, 'Total loss': 0.7880290245467966} | train loss {'Reaction outcome loss': 0.8169140551495648, 'Total loss': 0.8169140551495648}
2022-11-18 02:07:02,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:02,787 INFO:     Epoch: 50
2022-11-18 02:07:03,600 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8304587338458408, 'Total loss': 0.8304587338458408} | train loss {'Reaction outcome loss': 0.8143858747926318, 'Total loss': 0.8143858747926318}
2022-11-18 02:07:03,601 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:03,601 INFO:     Epoch: 51
2022-11-18 02:07:04,432 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.797218066724864, 'Total loss': 0.797218066724864} | train loss {'Reaction outcome loss': 0.819531690615874, 'Total loss': 0.819531690615874}
2022-11-18 02:07:04,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:04,432 INFO:     Epoch: 52
2022-11-18 02:07:05,234 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7937709438529882, 'Total loss': 0.7937709438529882} | train loss {'Reaction outcome loss': 0.8241883621283388, 'Total loss': 0.8241883621283388}
2022-11-18 02:07:05,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:05,235 INFO:     Epoch: 53
2022-11-18 02:07:06,047 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.809872648932717, 'Total loss': 0.809872648932717} | train loss {'Reaction outcome loss': 0.8137308234869227, 'Total loss': 0.8137308234869227}
2022-11-18 02:07:06,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:06,047 INFO:     Epoch: 54
2022-11-18 02:07:06,877 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7841437716375698, 'Total loss': 0.7841437716375698} | train loss {'Reaction outcome loss': 0.8250580454162257, 'Total loss': 0.8250580454162257}
2022-11-18 02:07:06,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:06,877 INFO:     Epoch: 55
2022-11-18 02:07:07,670 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7992652248252522, 'Total loss': 0.7992652248252522} | train loss {'Reaction outcome loss': 0.821308051405648, 'Total loss': 0.821308051405648}
2022-11-18 02:07:07,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:07,671 INFO:     Epoch: 56
2022-11-18 02:07:08,470 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8097959960048849, 'Total loss': 0.8097959960048849} | train loss {'Reaction outcome loss': 0.8225468042408407, 'Total loss': 0.8225468042408407}
2022-11-18 02:07:08,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:08,470 INFO:     Epoch: 57
2022-11-18 02:07:09,276 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.801491917534308, 'Total loss': 0.801491917534308} | train loss {'Reaction outcome loss': 0.8176282676849288, 'Total loss': 0.8176282676849288}
2022-11-18 02:07:09,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:09,276 INFO:     Epoch: 58
2022-11-18 02:07:10,075 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.790399244563146, 'Total loss': 0.790399244563146} | train loss {'Reaction outcome loss': 0.8200898823226511, 'Total loss': 0.8200898823226511}
2022-11-18 02:07:10,075 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:10,075 INFO:     Epoch: 59
2022-11-18 02:07:10,894 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7949790829284624, 'Total loss': 0.7949790829284624} | train loss {'Reaction outcome loss': 0.8270494183789381, 'Total loss': 0.8270494183789381}
2022-11-18 02:07:10,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:10,894 INFO:     Epoch: 60
2022-11-18 02:07:11,665 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7974755953658711, 'Total loss': 0.7974755953658711} | train loss {'Reaction outcome loss': 0.8220013780632482, 'Total loss': 0.8220013780632482}
2022-11-18 02:07:11,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:11,666 INFO:     Epoch: 61
2022-11-18 02:07:12,454 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8041247264905409, 'Total loss': 0.8041247264905409} | train loss {'Reaction outcome loss': 0.8196416853169198, 'Total loss': 0.8196416853169198}
2022-11-18 02:07:12,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:12,455 INFO:     Epoch: 62
2022-11-18 02:07:13,236 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8036323650316759, 'Total loss': 0.8036323650316759} | train loss {'Reaction outcome loss': 0.8156597011002452, 'Total loss': 0.8156597011002452}
2022-11-18 02:07:13,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:13,237 INFO:     Epoch: 63
2022-11-18 02:07:14,015 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7855963625691154, 'Total loss': 0.7855963625691154} | train loss {'Reaction outcome loss': 0.8101871589176085, 'Total loss': 0.8101871589176085}
2022-11-18 02:07:14,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:14,015 INFO:     Epoch: 64
2022-11-18 02:07:14,857 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8074128411032937, 'Total loss': 0.8074128411032937} | train loss {'Reaction outcome loss': 0.8199167340873224, 'Total loss': 0.8199167340873224}
2022-11-18 02:07:14,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:14,857 INFO:     Epoch: 65
2022-11-18 02:07:15,669 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7854565422643315, 'Total loss': 0.7854565422643315} | train loss {'Reaction outcome loss': 0.8213991636206747, 'Total loss': 0.8213991636206747}
2022-11-18 02:07:15,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:15,669 INFO:     Epoch: 66
2022-11-18 02:07:16,495 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8027361245317892, 'Total loss': 0.8027361245317892} | train loss {'Reaction outcome loss': 0.8240534704223819, 'Total loss': 0.8240534704223819}
2022-11-18 02:07:16,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:16,495 INFO:     Epoch: 67
2022-11-18 02:07:17,343 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.791933348910375, 'Total loss': 0.791933348910375} | train loss {'Reaction outcome loss': 0.8230243110463686, 'Total loss': 0.8230243110463686}
2022-11-18 02:07:17,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:17,344 INFO:     Epoch: 68
2022-11-18 02:07:18,152 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8011843609538946, 'Total loss': 0.8011843609538946} | train loss {'Reaction outcome loss': 0.8183184287205398, 'Total loss': 0.8183184287205398}
2022-11-18 02:07:18,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:18,152 INFO:     Epoch: 69
2022-11-18 02:07:18,979 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8263421641154722, 'Total loss': 0.8263421641154722} | train loss {'Reaction outcome loss': 0.8125176832140216, 'Total loss': 0.8125176832140216}
2022-11-18 02:07:18,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:18,979 INFO:     Epoch: 70
2022-11-18 02:07:19,812 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8037981871854175, 'Total loss': 0.8037981871854175} | train loss {'Reaction outcome loss': 0.8225850290373752, 'Total loss': 0.8225850290373752}
2022-11-18 02:07:19,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:19,812 INFO:     Epoch: 71
2022-11-18 02:07:20,649 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7892936657775532, 'Total loss': 0.7892936657775532} | train loss {'Reaction outcome loss': 0.8191446975657815, 'Total loss': 0.8191446975657815}
2022-11-18 02:07:20,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:20,649 INFO:     Epoch: 72
2022-11-18 02:07:21,446 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7821746461770751, 'Total loss': 0.7821746461770751} | train loss {'Reaction outcome loss': 0.824221336769189, 'Total loss': 0.824221336769189}
2022-11-18 02:07:21,446 INFO:     Found new best model at epoch 72
2022-11-18 02:07:21,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:21,447 INFO:     Epoch: 73
2022-11-18 02:07:22,255 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7827154181220315, 'Total loss': 0.7827154181220315} | train loss {'Reaction outcome loss': 0.818699381974062, 'Total loss': 0.818699381974062}
2022-11-18 02:07:22,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:22,255 INFO:     Epoch: 74
2022-11-18 02:07:23,055 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7983404736627232, 'Total loss': 0.7983404736627232} | train loss {'Reaction outcome loss': 0.8158090641865363, 'Total loss': 0.8158090641865363}
2022-11-18 02:07:23,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:23,056 INFO:     Epoch: 75
2022-11-18 02:07:23,822 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7897045585242185, 'Total loss': 0.7897045585242185} | train loss {'Reaction outcome loss': 0.8192486306916364, 'Total loss': 0.8192486306916364}
2022-11-18 02:07:23,822 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:23,822 INFO:     Epoch: 76
2022-11-18 02:07:24,664 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8016280050982129, 'Total loss': 0.8016280050982129} | train loss {'Reaction outcome loss': 0.816430694781817, 'Total loss': 0.816430694781817}
2022-11-18 02:07:24,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:24,665 INFO:     Epoch: 77
2022-11-18 02:07:25,466 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7886565144766461, 'Total loss': 0.7886565144766461} | train loss {'Reaction outcome loss': 0.8219950065197732, 'Total loss': 0.8219950065197732}
2022-11-18 02:07:25,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:25,466 INFO:     Epoch: 78
2022-11-18 02:07:26,264 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8007350320165808, 'Total loss': 0.8007350320165808} | train loss {'Reaction outcome loss': 0.8234070893000012, 'Total loss': 0.8234070893000012}
2022-11-18 02:07:26,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:26,266 INFO:     Epoch: 79
2022-11-18 02:07:27,102 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8178914622827009, 'Total loss': 0.8178914622827009} | train loss {'Reaction outcome loss': 0.8218799066929682, 'Total loss': 0.8218799066929682}
2022-11-18 02:07:27,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:27,102 INFO:     Epoch: 80
2022-11-18 02:07:27,920 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7825807123021646, 'Total loss': 0.7825807123021646} | train loss {'Reaction outcome loss': 0.8166004036843535, 'Total loss': 0.8166004036843535}
2022-11-18 02:07:27,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:27,920 INFO:     Epoch: 81
2022-11-18 02:07:28,731 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7960056892850182, 'Total loss': 0.7960056892850182} | train loss {'Reaction outcome loss': 0.8148376878939176, 'Total loss': 0.8148376878939176}
2022-11-18 02:07:28,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:28,731 INFO:     Epoch: 82
2022-11-18 02:07:29,550 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8088780885392969, 'Total loss': 0.8088780885392969} | train loss {'Reaction outcome loss': 0.8193024278049045, 'Total loss': 0.8193024278049045}
2022-11-18 02:07:29,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:29,550 INFO:     Epoch: 83
2022-11-18 02:07:30,361 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7968976477330382, 'Total loss': 0.7968976477330382} | train loss {'Reaction outcome loss': 0.8151491630656517, 'Total loss': 0.8151491630656517}
2022-11-18 02:07:30,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:30,361 INFO:     Epoch: 84
2022-11-18 02:07:31,184 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7833697477524931, 'Total loss': 0.7833697477524931} | train loss {'Reaction outcome loss': 0.8145294396531003, 'Total loss': 0.8145294396531003}
2022-11-18 02:07:31,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:31,185 INFO:     Epoch: 85
2022-11-18 02:07:31,998 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7878967151045799, 'Total loss': 0.7878967151045799} | train loss {'Reaction outcome loss': 0.8211308588624483, 'Total loss': 0.8211308588624483}
2022-11-18 02:07:31,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:31,998 INFO:     Epoch: 86
2022-11-18 02:07:32,826 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7888127775354818, 'Total loss': 0.7888127775354818} | train loss {'Reaction outcome loss': 0.8203038549133641, 'Total loss': 0.8203038549133641}
2022-11-18 02:07:32,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:32,827 INFO:     Epoch: 87
2022-11-18 02:07:33,637 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8037000386552378, 'Total loss': 0.8037000386552378} | train loss {'Reaction outcome loss': 0.8210918833369668, 'Total loss': 0.8210918833369668}
2022-11-18 02:07:33,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:33,637 INFO:     Epoch: 88
2022-11-18 02:07:34,466 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7875367450443181, 'Total loss': 0.7875367450443181} | train loss {'Reaction outcome loss': 0.8212203016647925, 'Total loss': 0.8212203016647925}
2022-11-18 02:07:34,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:34,467 INFO:     Epoch: 89
2022-11-18 02:07:35,343 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8085636245933446, 'Total loss': 0.8085636245933446} | train loss {'Reaction outcome loss': 0.8173177743006331, 'Total loss': 0.8173177743006331}
2022-11-18 02:07:35,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:35,343 INFO:     Epoch: 90
2022-11-18 02:07:36,133 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7818268198858608, 'Total loss': 0.7818268198858608} | train loss {'Reaction outcome loss': 0.8211645060463956, 'Total loss': 0.8211645060463956}
2022-11-18 02:07:36,134 INFO:     Found new best model at epoch 90
2022-11-18 02:07:36,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:36,134 INFO:     Epoch: 91
2022-11-18 02:07:36,954 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8099583590572531, 'Total loss': 0.8099583590572531} | train loss {'Reaction outcome loss': 0.8172368384022944, 'Total loss': 0.8172368384022944}
2022-11-18 02:07:36,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:36,954 INFO:     Epoch: 92
2022-11-18 02:07:37,777 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7949054539203644, 'Total loss': 0.7949054539203644} | train loss {'Reaction outcome loss': 0.8162902120938186, 'Total loss': 0.8162902120938186}
2022-11-18 02:07:37,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:37,778 INFO:     Epoch: 93
2022-11-18 02:07:38,557 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7824743349443782, 'Total loss': 0.7824743349443782} | train loss {'Reaction outcome loss': 0.823705318485677, 'Total loss': 0.823705318485677}
2022-11-18 02:07:38,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:38,557 INFO:     Epoch: 94
2022-11-18 02:07:39,393 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7983843074603514, 'Total loss': 0.7983843074603514} | train loss {'Reaction outcome loss': 0.8126236543602307, 'Total loss': 0.8126236543602307}
2022-11-18 02:07:39,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:39,394 INFO:     Epoch: 95
2022-11-18 02:07:40,217 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7922427789731459, 'Total loss': 0.7922427789731459} | train loss {'Reaction outcome loss': 0.815726678381082, 'Total loss': 0.815726678381082}
2022-11-18 02:07:40,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:40,217 INFO:     Epoch: 96
2022-11-18 02:07:41,059 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7948336364193396, 'Total loss': 0.7948336364193396} | train loss {'Reaction outcome loss': 0.8176958921708559, 'Total loss': 0.8176958921708559}
2022-11-18 02:07:41,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:41,060 INFO:     Epoch: 97
2022-11-18 02:07:41,901 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7839688035574827, 'Total loss': 0.7839688035574827} | train loss {'Reaction outcome loss': 0.8179917481505437, 'Total loss': 0.8179917481505437}
2022-11-18 02:07:41,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:41,901 INFO:     Epoch: 98
2022-11-18 02:07:42,726 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7881662811745297, 'Total loss': 0.7881662811745297} | train loss {'Reaction outcome loss': 0.8204579300243362, 'Total loss': 0.8204579300243362}
2022-11-18 02:07:42,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:42,726 INFO:     Epoch: 99
2022-11-18 02:07:43,529 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.793866675008427, 'Total loss': 0.793866675008427} | train loss {'Reaction outcome loss': 0.818192374247771, 'Total loss': 0.818192374247771}
2022-11-18 02:07:43,529 INFO:     Best model found after epoch 91 of 100.
2022-11-18 02:07:43,529 INFO:   Done with stage: TRAINING
2022-11-18 02:07:43,529 INFO:   Starting stage: EVALUATION
2022-11-18 02:07:43,655 INFO:   Done with stage: EVALUATION
2022-11-18 02:07:43,655 INFO:   Leaving out SEQ value Fold_5
2022-11-18 02:07:43,668 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 02:07:43,668 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:07:44,339 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:07:44,339 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:07:44,408 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:07:44,409 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:07:44,409 INFO:     No hyperparam tuning for this model
2022-11-18 02:07:44,409 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:07:44,409 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:07:44,410 INFO:     None feature selector for col prot
2022-11-18 02:07:44,410 INFO:     None feature selector for col prot
2022-11-18 02:07:44,410 INFO:     None feature selector for col prot
2022-11-18 02:07:44,411 INFO:     None feature selector for col chem
2022-11-18 02:07:44,411 INFO:     None feature selector for col chem
2022-11-18 02:07:44,411 INFO:     None feature selector for col chem
2022-11-18 02:07:44,411 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:07:44,411 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:07:44,412 INFO:     Number of params in model 168571
2022-11-18 02:07:44,416 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:07:44,416 INFO:   Starting stage: TRAINING
2022-11-18 02:07:44,473 INFO:     Val loss before train {'Reaction outcome loss': 1.0001607008955695, 'Total loss': 1.0001607008955695}
2022-11-18 02:07:44,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:44,474 INFO:     Epoch: 0
2022-11-18 02:07:45,265 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8580544943159277, 'Total loss': 0.8580544943159277} | train loss {'Reaction outcome loss': 0.8663603063476714, 'Total loss': 0.8663603063476714}
2022-11-18 02:07:45,266 INFO:     Found new best model at epoch 0
2022-11-18 02:07:45,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:45,267 INFO:     Epoch: 1
2022-11-18 02:07:46,067 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8456514545462348, 'Total loss': 0.8456514545462348} | train loss {'Reaction outcome loss': 0.8372203592618226, 'Total loss': 0.8372203592618226}
2022-11-18 02:07:46,067 INFO:     Found new best model at epoch 1
2022-11-18 02:07:46,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:46,068 INFO:     Epoch: 2
2022-11-18 02:07:46,882 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8375454633073374, 'Total loss': 0.8375454633073374} | train loss {'Reaction outcome loss': 0.8349926492221925, 'Total loss': 0.8349926492221925}
2022-11-18 02:07:46,882 INFO:     Found new best model at epoch 2
2022-11-18 02:07:46,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:46,883 INFO:     Epoch: 3
2022-11-18 02:07:47,670 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8300216888839548, 'Total loss': 0.8300216888839548} | train loss {'Reaction outcome loss': 0.8329403223055094, 'Total loss': 0.8329403223055094}
2022-11-18 02:07:47,670 INFO:     Found new best model at epoch 3
2022-11-18 02:07:47,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:47,671 INFO:     Epoch: 4
2022-11-18 02:07:48,509 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8450904718854211, 'Total loss': 0.8450904718854211} | train loss {'Reaction outcome loss': 0.831490808170334, 'Total loss': 0.831490808170334}
2022-11-18 02:07:48,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:48,510 INFO:     Epoch: 5
2022-11-18 02:07:49,316 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8611177084120837, 'Total loss': 0.8611177084120837} | train loss {'Reaction outcome loss': 0.8299492234401857, 'Total loss': 0.8299492234401857}
2022-11-18 02:07:49,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:49,317 INFO:     Epoch: 6
2022-11-18 02:07:50,099 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8445934639735655, 'Total loss': 0.8445934639735655} | train loss {'Reaction outcome loss': 0.8329179045642435, 'Total loss': 0.8329179045642435}
2022-11-18 02:07:50,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:50,099 INFO:     Epoch: 7
2022-11-18 02:07:50,901 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8378619450059804, 'Total loss': 0.8378619450059804} | train loss {'Reaction outcome loss': 0.8262692321891244, 'Total loss': 0.8262692321891244}
2022-11-18 02:07:50,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:50,901 INFO:     Epoch: 8
2022-11-18 02:07:51,696 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8348167403177782, 'Total loss': 0.8348167403177782} | train loss {'Reaction outcome loss': 0.8213669515331747, 'Total loss': 0.8213669515331747}
2022-11-18 02:07:51,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:51,696 INFO:     Epoch: 9
2022-11-18 02:07:52,520 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8357838134873997, 'Total loss': 0.8357838134873997} | train loss {'Reaction outcome loss': 0.8189894008612343, 'Total loss': 0.8189894008612343}
2022-11-18 02:07:52,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:52,520 INFO:     Epoch: 10
2022-11-18 02:07:53,333 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8270238427953287, 'Total loss': 0.8270238427953287} | train loss {'Reaction outcome loss': 0.8151872247336847, 'Total loss': 0.8151872247336847}
2022-11-18 02:07:53,333 INFO:     Found new best model at epoch 10
2022-11-18 02:07:53,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:53,334 INFO:     Epoch: 11
2022-11-18 02:07:54,156 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.839224442162297, 'Total loss': 0.839224442162297} | train loss {'Reaction outcome loss': 0.8154862228373767, 'Total loss': 0.8154862228373767}
2022-11-18 02:07:54,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:54,156 INFO:     Epoch: 12
2022-11-18 02:07:54,921 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.824597725814039, 'Total loss': 0.824597725814039} | train loss {'Reaction outcome loss': 0.8199484001407739, 'Total loss': 0.8199484001407739}
2022-11-18 02:07:54,921 INFO:     Found new best model at epoch 12
2022-11-18 02:07:54,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:54,922 INFO:     Epoch: 13
2022-11-18 02:07:55,719 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8227802040902051, 'Total loss': 0.8227802040902051} | train loss {'Reaction outcome loss': 0.8177363501507261, 'Total loss': 0.8177363501507261}
2022-11-18 02:07:55,719 INFO:     Found new best model at epoch 13
2022-11-18 02:07:55,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:55,720 INFO:     Epoch: 14
2022-11-18 02:07:56,552 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.831697397611358, 'Total loss': 0.831697397611358} | train loss {'Reaction outcome loss': 0.8159637573035622, 'Total loss': 0.8159637573035622}
2022-11-18 02:07:56,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:56,552 INFO:     Epoch: 15
2022-11-18 02:07:57,366 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8318344374949281, 'Total loss': 0.8318344374949281} | train loss {'Reaction outcome loss': 0.8177485846073521, 'Total loss': 0.8177485846073521}
2022-11-18 02:07:57,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:57,368 INFO:     Epoch: 16
2022-11-18 02:07:58,227 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8330416936766017, 'Total loss': 0.8330416936766017} | train loss {'Reaction outcome loss': 0.8141701468813275, 'Total loss': 0.8141701468813275}
2022-11-18 02:07:58,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:58,228 INFO:     Epoch: 17
2022-11-18 02:07:59,026 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8379828022284941, 'Total loss': 0.8379828022284941} | train loss {'Reaction outcome loss': 0.8092555575042601, 'Total loss': 0.8092555575042601}
2022-11-18 02:07:59,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:59,026 INFO:     Epoch: 18
2022-11-18 02:07:59,835 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8160628391937776, 'Total loss': 0.8160628391937776} | train loss {'Reaction outcome loss': 0.8084338090801046, 'Total loss': 0.8084338090801046}
2022-11-18 02:07:59,835 INFO:     Found new best model at epoch 18
2022-11-18 02:07:59,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:07:59,836 INFO:     Epoch: 19
2022-11-18 02:08:00,596 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8340699083425782, 'Total loss': 0.8340699083425782} | train loss {'Reaction outcome loss': 0.8081126009163103, 'Total loss': 0.8081126009163103}
2022-11-18 02:08:00,596 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:00,596 INFO:     Epoch: 20
2022-11-18 02:08:01,374 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8359959382902492, 'Total loss': 0.8359959382902492} | train loss {'Reaction outcome loss': 0.8090954695635961, 'Total loss': 0.8090954695635961}
2022-11-18 02:08:01,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:01,375 INFO:     Epoch: 21
2022-11-18 02:08:02,158 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8307623334906318, 'Total loss': 0.8307623334906318} | train loss {'Reaction outcome loss': 0.8080426446701351, 'Total loss': 0.8080426446701351}
2022-11-18 02:08:02,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:02,158 INFO:     Epoch: 22
2022-11-18 02:08:02,968 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8233484849333763, 'Total loss': 0.8233484849333763} | train loss {'Reaction outcome loss': 0.8100844841405206, 'Total loss': 0.8100844841405206}
2022-11-18 02:08:02,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:02,968 INFO:     Epoch: 23
2022-11-18 02:08:03,758 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8290514959530397, 'Total loss': 0.8290514959530397} | train loss {'Reaction outcome loss': 0.8128460800116845, 'Total loss': 0.8128460800116845}
2022-11-18 02:08:03,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:03,759 INFO:     Epoch: 24
2022-11-18 02:08:04,555 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8396000103517012, 'Total loss': 0.8396000103517012} | train loss {'Reaction outcome loss': 0.8051317346768703, 'Total loss': 0.8051317346768703}
2022-11-18 02:08:04,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:04,555 INFO:     Epoch: 25
2022-11-18 02:08:05,367 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8379572907632048, 'Total loss': 0.8379572907632048} | train loss {'Reaction outcome loss': 0.807631834255539, 'Total loss': 0.807631834255539}
2022-11-18 02:08:05,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:05,367 INFO:     Epoch: 26
2022-11-18 02:08:06,194 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8398192758587274, 'Total loss': 0.8398192758587274} | train loss {'Reaction outcome loss': 0.8079788261338284, 'Total loss': 0.8079788261338284}
2022-11-18 02:08:06,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:06,194 INFO:     Epoch: 27
2022-11-18 02:08:06,978 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8321861340240999, 'Total loss': 0.8321861340240999} | train loss {'Reaction outcome loss': 0.8116219253675175, 'Total loss': 0.8116219253675175}
2022-11-18 02:08:06,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:06,978 INFO:     Epoch: 28
2022-11-18 02:08:07,754 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8528722741387107, 'Total loss': 0.8528722741387107} | train loss {'Reaction outcome loss': 0.810543025372482, 'Total loss': 0.810543025372482}
2022-11-18 02:08:07,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:07,754 INFO:     Epoch: 29
2022-11-18 02:08:08,538 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8339713303880258, 'Total loss': 0.8339713303880258} | train loss {'Reaction outcome loss': 0.8070697535870046, 'Total loss': 0.8070697535870046}
2022-11-18 02:08:08,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:08,539 INFO:     Epoch: 30
2022-11-18 02:08:09,318 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8179360722953622, 'Total loss': 0.8179360722953622} | train loss {'Reaction outcome loss': 0.8120898488562117, 'Total loss': 0.8120898488562117}
2022-11-18 02:08:09,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:09,319 INFO:     Epoch: 31
2022-11-18 02:08:10,118 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8276581276546825, 'Total loss': 0.8276581276546825} | train loss {'Reaction outcome loss': 0.8029078423735584, 'Total loss': 0.8029078423735584}
2022-11-18 02:08:10,118 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:10,118 INFO:     Epoch: 32
2022-11-18 02:08:10,898 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8085649501193654, 'Total loss': 0.8085649501193654} | train loss {'Reaction outcome loss': 0.8048991491558098, 'Total loss': 0.8048991491558098}
2022-11-18 02:08:10,898 INFO:     Found new best model at epoch 32
2022-11-18 02:08:10,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:10,899 INFO:     Epoch: 33
2022-11-18 02:08:11,752 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8240338245576079, 'Total loss': 0.8240338245576079} | train loss {'Reaction outcome loss': 0.8102496374956509, 'Total loss': 0.8102496374956509}
2022-11-18 02:08:11,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:11,753 INFO:     Epoch: 34
2022-11-18 02:08:12,557 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.820745434273373, 'Total loss': 0.820745434273373} | train loss {'Reaction outcome loss': 0.8065816585110267, 'Total loss': 0.8065816585110267}
2022-11-18 02:08:12,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:12,557 INFO:     Epoch: 35
2022-11-18 02:08:13,374 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8025870119983499, 'Total loss': 0.8025870119983499} | train loss {'Reaction outcome loss': 0.808894039904661, 'Total loss': 0.808894039904661}
2022-11-18 02:08:13,374 INFO:     Found new best model at epoch 35
2022-11-18 02:08:13,375 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:13,375 INFO:     Epoch: 36
2022-11-18 02:08:14,179 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8273439691825346, 'Total loss': 0.8273439691825346} | train loss {'Reaction outcome loss': 0.8107955775521545, 'Total loss': 0.8107955775521545}
2022-11-18 02:08:14,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:14,180 INFO:     Epoch: 37
2022-11-18 02:08:14,959 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8078332136977803, 'Total loss': 0.8078332136977803} | train loss {'Reaction outcome loss': 0.805652693939595, 'Total loss': 0.805652693939595}
2022-11-18 02:08:14,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:14,959 INFO:     Epoch: 38
2022-11-18 02:08:15,798 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8199618499387394, 'Total loss': 0.8199618499387394} | train loss {'Reaction outcome loss': 0.8051418779711974, 'Total loss': 0.8051418779711974}
2022-11-18 02:08:15,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:15,799 INFO:     Epoch: 39
2022-11-18 02:08:16,639 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8283973850987174, 'Total loss': 0.8283973850987174} | train loss {'Reaction outcome loss': 0.7974268779882535, 'Total loss': 0.7974268779882535}
2022-11-18 02:08:16,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:16,639 INFO:     Epoch: 40
2022-11-18 02:08:17,451 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8328623886812817, 'Total loss': 0.8328623886812817} | train loss {'Reaction outcome loss': 0.8011003440690909, 'Total loss': 0.8011003440690909}
2022-11-18 02:08:17,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:17,452 INFO:     Epoch: 41
2022-11-18 02:08:18,235 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.817982364107262, 'Total loss': 0.817982364107262} | train loss {'Reaction outcome loss': 0.799263870547175, 'Total loss': 0.799263870547175}
2022-11-18 02:08:18,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:18,235 INFO:     Epoch: 42
2022-11-18 02:08:19,080 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8338391889225353, 'Total loss': 0.8338391889225353} | train loss {'Reaction outcome loss': 0.8068751134129188, 'Total loss': 0.8068751134129188}
2022-11-18 02:08:19,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:19,081 INFO:     Epoch: 43
2022-11-18 02:08:19,918 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8343190293420445, 'Total loss': 0.8343190293420445} | train loss {'Reaction outcome loss': 0.8014012109412838, 'Total loss': 0.8014012109412838}
2022-11-18 02:08:19,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:19,918 INFO:     Epoch: 44
2022-11-18 02:08:20,699 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8051392734050751, 'Total loss': 0.8051392734050751} | train loss {'Reaction outcome loss': 0.8033547477442243, 'Total loss': 0.8033547477442243}
2022-11-18 02:08:20,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:20,699 INFO:     Epoch: 45
2022-11-18 02:08:21,477 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7961835502223535, 'Total loss': 0.7961835502223535} | train loss {'Reaction outcome loss': 0.7936960386210367, 'Total loss': 0.7936960386210367}
2022-11-18 02:08:21,477 INFO:     Found new best model at epoch 45
2022-11-18 02:08:21,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:21,478 INFO:     Epoch: 46
2022-11-18 02:08:22,266 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8032382394779812, 'Total loss': 0.8032382394779812} | train loss {'Reaction outcome loss': 0.79951056777707, 'Total loss': 0.79951056777707}
2022-11-18 02:08:22,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:22,266 INFO:     Epoch: 47
2022-11-18 02:08:23,071 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8672171641479839, 'Total loss': 0.8672171641479839} | train loss {'Reaction outcome loss': 0.7948541219990987, 'Total loss': 0.7948541219990987}
2022-11-18 02:08:23,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:23,071 INFO:     Epoch: 48
2022-11-18 02:08:23,934 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8211955333297903, 'Total loss': 0.8211955333297903} | train loss {'Reaction outcome loss': 0.8021712429851655, 'Total loss': 0.8021712429851655}
2022-11-18 02:08:23,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:23,935 INFO:     Epoch: 49
2022-11-18 02:08:24,719 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8157225210558284, 'Total loss': 0.8157225210558284} | train loss {'Reaction outcome loss': 0.8034963675356104, 'Total loss': 0.8034963675356104}
2022-11-18 02:08:24,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:24,719 INFO:     Epoch: 50
2022-11-18 02:08:25,582 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8116599165580489, 'Total loss': 0.8116599165580489} | train loss {'Reaction outcome loss': 0.7970989087091284, 'Total loss': 0.7970989087091284}
2022-11-18 02:08:25,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:25,582 INFO:     Epoch: 51
2022-11-18 02:08:26,418 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8098329800096425, 'Total loss': 0.8098329800096425} | train loss {'Reaction outcome loss': 0.795045488140723, 'Total loss': 0.795045488140723}
2022-11-18 02:08:26,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:26,418 INFO:     Epoch: 52
2022-11-18 02:08:27,219 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8317384028976614, 'Total loss': 0.8317384028976614} | train loss {'Reaction outcome loss': 0.7968840453064876, 'Total loss': 0.7968840453064876}
2022-11-18 02:08:27,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:27,220 INFO:     Epoch: 53
2022-11-18 02:08:28,055 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8154826841571114, 'Total loss': 0.8154826841571114} | train loss {'Reaction outcome loss': 0.8101538353362064, 'Total loss': 0.8101538353362064}
2022-11-18 02:08:28,057 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:28,057 INFO:     Epoch: 54
2022-11-18 02:08:28,860 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8141746094281023, 'Total loss': 0.8141746094281023} | train loss {'Reaction outcome loss': 0.8018215260042353, 'Total loss': 0.8018215260042353}
2022-11-18 02:08:28,861 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:28,861 INFO:     Epoch: 55
2022-11-18 02:08:29,680 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8399085239930586, 'Total loss': 0.8399085239930586} | train loss {'Reaction outcome loss': 0.7946151012351156, 'Total loss': 0.7946151012351156}
2022-11-18 02:08:29,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:29,680 INFO:     Epoch: 56
2022-11-18 02:08:30,496 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8035306415774606, 'Total loss': 0.8035306415774606} | train loss {'Reaction outcome loss': 0.7942129363897841, 'Total loss': 0.7942129363897841}
2022-11-18 02:08:30,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:30,496 INFO:     Epoch: 57
2022-11-18 02:08:31,284 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8155057152563875, 'Total loss': 0.8155057152563875} | train loss {'Reaction outcome loss': 0.7853093847089451, 'Total loss': 0.7853093847089451}
2022-11-18 02:08:31,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:31,284 INFO:     Epoch: 58
2022-11-18 02:08:32,097 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8084443848241459, 'Total loss': 0.8084443848241459} | train loss {'Reaction outcome loss': 0.7872840462908571, 'Total loss': 0.7872840462908571}
2022-11-18 02:08:32,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:32,098 INFO:     Epoch: 59
2022-11-18 02:08:32,881 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8055184232917699, 'Total loss': 0.8055184232917699} | train loss {'Reaction outcome loss': 0.7839878859066287, 'Total loss': 0.7839878859066287}
2022-11-18 02:08:32,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:32,881 INFO:     Epoch: 60
2022-11-18 02:08:33,663 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.817374664274129, 'Total loss': 0.817374664274129} | train loss {'Reaction outcome loss': 0.792064634532581, 'Total loss': 0.792064634532581}
2022-11-18 02:08:33,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:33,663 INFO:     Epoch: 61
2022-11-18 02:08:34,465 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7986366220495917, 'Total loss': 0.7986366220495917} | train loss {'Reaction outcome loss': 0.7922630820438447, 'Total loss': 0.7922630820438447}
2022-11-18 02:08:34,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:34,467 INFO:     Epoch: 62
2022-11-18 02:08:35,256 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8324291096492247, 'Total loss': 0.8324291096492247} | train loss {'Reaction outcome loss': 0.7886574670732746, 'Total loss': 0.7886574670732746}
2022-11-18 02:08:35,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:35,256 INFO:     Epoch: 63
2022-11-18 02:08:36,032 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7928073839707808, 'Total loss': 0.7928073839707808} | train loss {'Reaction outcome loss': 0.780810735486297, 'Total loss': 0.780810735486297}
2022-11-18 02:08:36,032 INFO:     Found new best model at epoch 63
2022-11-18 02:08:36,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:36,033 INFO:     Epoch: 64
2022-11-18 02:08:36,834 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8417117690498178, 'Total loss': 0.8417117690498178} | train loss {'Reaction outcome loss': 0.7821434066604506, 'Total loss': 0.7821434066604506}
2022-11-18 02:08:36,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:36,834 INFO:     Epoch: 65
2022-11-18 02:08:37,616 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8151493207974867, 'Total loss': 0.8151493207974867} | train loss {'Reaction outcome loss': 0.7858220506534885, 'Total loss': 0.7858220506534885}
2022-11-18 02:08:37,616 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:37,616 INFO:     Epoch: 66
2022-11-18 02:08:38,418 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8122955188155174, 'Total loss': 0.8122955188155174} | train loss {'Reaction outcome loss': 0.7775175199817549, 'Total loss': 0.7775175199817549}
2022-11-18 02:08:38,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:38,418 INFO:     Epoch: 67
2022-11-18 02:08:39,191 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7767850004813888, 'Total loss': 0.7767850004813888} | train loss {'Reaction outcome loss': 0.7758546178398827, 'Total loss': 0.7758546178398827}
2022-11-18 02:08:39,191 INFO:     Found new best model at epoch 67
2022-11-18 02:08:39,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:39,192 INFO:     Epoch: 68
2022-11-18 02:08:40,030 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7872199659997766, 'Total loss': 0.7872199659997766} | train loss {'Reaction outcome loss': 0.7718578736007455, 'Total loss': 0.7718578736007455}
2022-11-18 02:08:40,030 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:40,031 INFO:     Epoch: 69
2022-11-18 02:08:40,846 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8012951361862096, 'Total loss': 0.8012951361862096} | train loss {'Reaction outcome loss': 0.77748486423782, 'Total loss': 0.77748486423782}
2022-11-18 02:08:40,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:40,847 INFO:     Epoch: 70
2022-11-18 02:08:41,627 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7893371094356884, 'Total loss': 0.7893371094356884} | train loss {'Reaction outcome loss': 0.7739815795228548, 'Total loss': 0.7739815795228548}
2022-11-18 02:08:41,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:41,628 INFO:     Epoch: 71
2022-11-18 02:08:42,420 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8009653518145735, 'Total loss': 0.8009653518145735} | train loss {'Reaction outcome loss': 0.770264170551107, 'Total loss': 0.770264170551107}
2022-11-18 02:08:42,420 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:42,420 INFO:     Epoch: 72
2022-11-18 02:08:43,220 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8037685853513804, 'Total loss': 0.8037685853513804} | train loss {'Reaction outcome loss': 0.7761108895786378, 'Total loss': 0.7761108895786378}
2022-11-18 02:08:43,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:43,221 INFO:     Epoch: 73
2022-11-18 02:08:44,026 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8210588097572327, 'Total loss': 0.8210588097572327} | train loss {'Reaction outcome loss': 0.7792879478168874, 'Total loss': 0.7792879478168874}
2022-11-18 02:08:44,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:44,026 INFO:     Epoch: 74
2022-11-18 02:08:44,844 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7737040248784152, 'Total loss': 0.7737040248784152} | train loss {'Reaction outcome loss': 0.7678420603999242, 'Total loss': 0.7678420603999242}
2022-11-18 02:08:44,845 INFO:     Found new best model at epoch 74
2022-11-18 02:08:44,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:44,845 INFO:     Epoch: 75
2022-11-18 02:08:45,609 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7821972525932572, 'Total loss': 0.7821972525932572} | train loss {'Reaction outcome loss': 0.7652642787226781, 'Total loss': 0.7652642787226781}
2022-11-18 02:08:45,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:45,609 INFO:     Epoch: 76
2022-11-18 02:08:46,390 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.78279444236647, 'Total loss': 0.78279444236647} | train loss {'Reaction outcome loss': 0.7704573733362592, 'Total loss': 0.7704573733362592}
2022-11-18 02:08:46,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:46,390 INFO:     Epoch: 77
2022-11-18 02:08:47,136 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7560180154713717, 'Total loss': 0.7560180154713717} | train loss {'Reaction outcome loss': 0.7724881049713143, 'Total loss': 0.7724881049713143}
2022-11-18 02:08:47,137 INFO:     Found new best model at epoch 77
2022-11-18 02:08:47,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:47,138 INFO:     Epoch: 78
2022-11-18 02:08:47,926 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7619833566925742, 'Total loss': 0.7619833566925742} | train loss {'Reaction outcome loss': 0.7527620546248278, 'Total loss': 0.7527620546248278}
2022-11-18 02:08:47,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:47,926 INFO:     Epoch: 79
2022-11-18 02:08:48,708 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8041464733806524, 'Total loss': 0.8041464733806524} | train loss {'Reaction outcome loss': 0.7459493190170783, 'Total loss': 0.7459493190170783}
2022-11-18 02:08:48,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:48,708 INFO:     Epoch: 80
2022-11-18 02:08:49,481 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8566079566424544, 'Total loss': 0.8566079566424544} | train loss {'Reaction outcome loss': 0.7437379365628548, 'Total loss': 0.7437379365628548}
2022-11-18 02:08:49,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:49,481 INFO:     Epoch: 81
2022-11-18 02:08:50,254 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7355951991948214, 'Total loss': 0.7355951991948214} | train loss {'Reaction outcome loss': 0.7477058853335709, 'Total loss': 0.7477058853335709}
2022-11-18 02:08:50,254 INFO:     Found new best model at epoch 81
2022-11-18 02:08:50,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:50,255 INFO:     Epoch: 82
2022-11-18 02:08:51,037 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8077755340121009, 'Total loss': 0.8077755340121009} | train loss {'Reaction outcome loss': 0.7322426205463255, 'Total loss': 0.7322426205463255}
2022-11-18 02:08:51,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:51,037 INFO:     Epoch: 83
2022-11-18 02:08:51,819 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7190011651678518, 'Total loss': 0.7190011651678518} | train loss {'Reaction outcome loss': 0.7363066895288012, 'Total loss': 0.7363066895288012}
2022-11-18 02:08:51,819 INFO:     Found new best model at epoch 83
2022-11-18 02:08:51,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:51,820 INFO:     Epoch: 84
2022-11-18 02:08:52,597 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7947929758917202, 'Total loss': 0.7947929758917202} | train loss {'Reaction outcome loss': 0.7260431621359428, 'Total loss': 0.7260431621359428}
2022-11-18 02:08:52,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:52,597 INFO:     Epoch: 85
2022-11-18 02:08:53,395 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.744589932940223, 'Total loss': 0.744589932940223} | train loss {'Reaction outcome loss': 0.7133305723729887, 'Total loss': 0.7133305723729887}
2022-11-18 02:08:53,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:53,395 INFO:     Epoch: 86
2022-11-18 02:08:54,205 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.6743376139890064, 'Total loss': 0.6743376139890064} | train loss {'Reaction outcome loss': 0.7007547385296841, 'Total loss': 0.7007547385296841}
2022-11-18 02:08:54,205 INFO:     Found new best model at epoch 86
2022-11-18 02:08:54,206 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:54,206 INFO:     Epoch: 87
2022-11-18 02:08:55,002 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.6727065511725165, 'Total loss': 0.6727065511725165} | train loss {'Reaction outcome loss': 0.6815122309242666, 'Total loss': 0.6815122309242666}
2022-11-18 02:08:55,002 INFO:     Found new best model at epoch 87
2022-11-18 02:08:55,003 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:55,003 INFO:     Epoch: 88
2022-11-18 02:08:55,792 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.6473002616654743, 'Total loss': 0.6473002616654743} | train loss {'Reaction outcome loss': 0.6820312958014639, 'Total loss': 0.6820312958014639}
2022-11-18 02:08:55,792 INFO:     Found new best model at epoch 88
2022-11-18 02:08:55,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:55,793 INFO:     Epoch: 89
2022-11-18 02:08:56,589 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.757091948254542, 'Total loss': 0.757091948254542} | train loss {'Reaction outcome loss': 0.6496710504809591, 'Total loss': 0.6496710504809591}
2022-11-18 02:08:56,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:56,589 INFO:     Epoch: 90
2022-11-18 02:08:57,367 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.6213004142045975, 'Total loss': 0.6213004142045975} | train loss {'Reaction outcome loss': 0.6425504282659847, 'Total loss': 0.6425504282659847}
2022-11-18 02:08:57,367 INFO:     Found new best model at epoch 90
2022-11-18 02:08:57,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:57,368 INFO:     Epoch: 91
2022-11-18 02:08:58,189 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5984344800764864, 'Total loss': 0.5984344800764864} | train loss {'Reaction outcome loss': 0.6209532479163606, 'Total loss': 0.6209532479163606}
2022-11-18 02:08:58,189 INFO:     Found new best model at epoch 91
2022-11-18 02:08:58,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:58,190 INFO:     Epoch: 92
2022-11-18 02:08:58,981 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.58060738037933, 'Total loss': 0.58060738037933} | train loss {'Reaction outcome loss': 0.6171234576747968, 'Total loss': 0.6171234576747968}
2022-11-18 02:08:58,981 INFO:     Found new best model at epoch 92
2022-11-18 02:08:58,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:58,982 INFO:     Epoch: 93
2022-11-18 02:08:59,788 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5797481360760602, 'Total loss': 0.5797481360760602} | train loss {'Reaction outcome loss': 0.6216610707493446, 'Total loss': 0.6216610707493446}
2022-11-18 02:08:59,789 INFO:     Found new best model at epoch 93
2022-11-18 02:08:59,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:08:59,790 INFO:     Epoch: 94
2022-11-18 02:09:00,578 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7336890392682769, 'Total loss': 0.7336890392682769} | train loss {'Reaction outcome loss': 0.603984396708639, 'Total loss': 0.603984396708639}
2022-11-18 02:09:00,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:00,578 INFO:     Epoch: 95
2022-11-18 02:09:01,363 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.6009698970751329, 'Total loss': 0.6009698970751329} | train loss {'Reaction outcome loss': 0.6000717857000437, 'Total loss': 0.6000717857000437}
2022-11-18 02:09:01,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:01,363 INFO:     Epoch: 96
2022-11-18 02:09:02,121 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.6109438762068748, 'Total loss': 0.6109438762068748} | train loss {'Reaction outcome loss': 0.5853540877460951, 'Total loss': 0.5853540877460951}
2022-11-18 02:09:02,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:02,121 INFO:     Epoch: 97
2022-11-18 02:09:02,921 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7411782179366458, 'Total loss': 0.7411782179366458} | train loss {'Reaction outcome loss': 0.591171196959762, 'Total loss': 0.591171196959762}
2022-11-18 02:09:02,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:02,921 INFO:     Epoch: 98
2022-11-18 02:09:03,686 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5856398980725895, 'Total loss': 0.5856398980725895} | train loss {'Reaction outcome loss': 0.6064157303166293, 'Total loss': 0.6064157303166293}
2022-11-18 02:09:03,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:03,687 INFO:     Epoch: 99
2022-11-18 02:09:04,474 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.6097213145006787, 'Total loss': 0.6097213145006787} | train loss {'Reaction outcome loss': 0.5898194477633245, 'Total loss': 0.5898194477633245}
2022-11-18 02:09:04,474 INFO:     Best model found after epoch 94 of 100.
2022-11-18 02:09:04,475 INFO:   Done with stage: TRAINING
2022-11-18 02:09:04,475 INFO:   Starting stage: EVALUATION
2022-11-18 02:09:04,601 INFO:   Done with stage: EVALUATION
2022-11-18 02:09:04,601 INFO:   Leaving out SEQ value Fold_6
2022-11-18 02:09:04,614 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 02:09:04,614 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:09:05,279 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:09:05,279 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:09:05,349 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:09:05,349 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:09:05,349 INFO:     No hyperparam tuning for this model
2022-11-18 02:09:05,350 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:09:05,350 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:09:05,350 INFO:     None feature selector for col prot
2022-11-18 02:09:05,351 INFO:     None feature selector for col prot
2022-11-18 02:09:05,351 INFO:     None feature selector for col prot
2022-11-18 02:09:05,351 INFO:     None feature selector for col chem
2022-11-18 02:09:05,351 INFO:     None feature selector for col chem
2022-11-18 02:09:05,352 INFO:     None feature selector for col chem
2022-11-18 02:09:05,352 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:09:05,352 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:09:05,353 INFO:     Number of params in model 168571
2022-11-18 02:09:05,357 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:09:05,357 INFO:   Starting stage: TRAINING
2022-11-18 02:09:05,414 INFO:     Val loss before train {'Reaction outcome loss': 0.9878306795250286, 'Total loss': 0.9878306795250286}
2022-11-18 02:09:05,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:05,414 INFO:     Epoch: 0
2022-11-18 02:09:06,184 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8359453204003248, 'Total loss': 0.8359453204003248} | train loss {'Reaction outcome loss': 0.876841199253836, 'Total loss': 0.876841199253836}
2022-11-18 02:09:06,184 INFO:     Found new best model at epoch 0
2022-11-18 02:09:06,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:06,185 INFO:     Epoch: 1
2022-11-18 02:09:06,960 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.856502270156687, 'Total loss': 0.856502270156687} | train loss {'Reaction outcome loss': 0.8432754422387769, 'Total loss': 0.8432754422387769}
2022-11-18 02:09:06,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:06,960 INFO:     Epoch: 2
2022-11-18 02:09:07,737 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8400628986683759, 'Total loss': 0.8400628986683759} | train loss {'Reaction outcome loss': 0.8412783973880352, 'Total loss': 0.8412783973880352}
2022-11-18 02:09:07,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:07,737 INFO:     Epoch: 3
2022-11-18 02:09:08,514 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8511946898969737, 'Total loss': 0.8511946898969737} | train loss {'Reaction outcome loss': 0.8354405179139106, 'Total loss': 0.8354405179139106}
2022-11-18 02:09:08,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:08,514 INFO:     Epoch: 4
2022-11-18 02:09:09,302 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8121292462403124, 'Total loss': 0.8121292462403124} | train loss {'Reaction outcome loss': 0.8357103241066779, 'Total loss': 0.8357103241066779}
2022-11-18 02:09:09,302 INFO:     Found new best model at epoch 4
2022-11-18 02:09:09,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:09,303 INFO:     Epoch: 5
2022-11-18 02:09:10,082 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8197273842313073, 'Total loss': 0.8197273842313073} | train loss {'Reaction outcome loss': 0.8310944449997717, 'Total loss': 0.8310944449997717}
2022-11-18 02:09:10,083 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:10,083 INFO:     Epoch: 6
2022-11-18 02:09:10,862 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8464059748432853, 'Total loss': 0.8464059748432853} | train loss {'Reaction outcome loss': 0.8274654182455232, 'Total loss': 0.8274654182455232}
2022-11-18 02:09:10,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:10,862 INFO:     Epoch: 7
2022-11-18 02:09:11,626 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8202488761056553, 'Total loss': 0.8202488761056553} | train loss {'Reaction outcome loss': 0.8243562490228684, 'Total loss': 0.8243562490228684}
2022-11-18 02:09:11,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:11,627 INFO:     Epoch: 8
2022-11-18 02:09:12,408 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8205410844900392, 'Total loss': 0.8205410844900392} | train loss {'Reaction outcome loss': 0.8257838840926847, 'Total loss': 0.8257838840926847}
2022-11-18 02:09:12,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:12,408 INFO:     Epoch: 9
2022-11-18 02:09:13,203 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8352546481923624, 'Total loss': 0.8352546481923624} | train loss {'Reaction outcome loss': 0.8189503041005903, 'Total loss': 0.8189503041005903}
2022-11-18 02:09:13,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:13,204 INFO:     Epoch: 10
2022-11-18 02:09:13,980 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8301654065197165, 'Total loss': 0.8301654065197165} | train loss {'Reaction outcome loss': 0.82085339256352, 'Total loss': 0.82085339256352}
2022-11-18 02:09:13,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:13,980 INFO:     Epoch: 11
2022-11-18 02:09:14,782 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.817647398872809, 'Total loss': 0.817647398872809} | train loss {'Reaction outcome loss': 0.8205466999882652, 'Total loss': 0.8205466999882652}
2022-11-18 02:09:14,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:14,782 INFO:     Epoch: 12
2022-11-18 02:09:15,585 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8273523260246624, 'Total loss': 0.8273523260246624} | train loss {'Reaction outcome loss': 0.8202722279294845, 'Total loss': 0.8202722279294845}
2022-11-18 02:09:15,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:15,585 INFO:     Epoch: 13
2022-11-18 02:09:16,352 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8128818002614108, 'Total loss': 0.8128818002614108} | train loss {'Reaction outcome loss': 0.8190330276566167, 'Total loss': 0.8190330276566167}
2022-11-18 02:09:16,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:16,352 INFO:     Epoch: 14
2022-11-18 02:09:17,121 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8178055611523715, 'Total loss': 0.8178055611523715} | train loss {'Reaction outcome loss': 0.8194849486913411, 'Total loss': 0.8194849486913411}
2022-11-18 02:09:17,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:17,121 INFO:     Epoch: 15
2022-11-18 02:09:17,884 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8283070806752552, 'Total loss': 0.8283070806752552} | train loss {'Reaction outcome loss': 0.817589535347877, 'Total loss': 0.817589535347877}
2022-11-18 02:09:17,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:17,885 INFO:     Epoch: 16
2022-11-18 02:09:18,644 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8083506511016325, 'Total loss': 0.8083506511016325} | train loss {'Reaction outcome loss': 0.8131512616190218, 'Total loss': 0.8131512616190218}
2022-11-18 02:09:18,645 INFO:     Found new best model at epoch 16
2022-11-18 02:09:18,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:18,646 INFO:     Epoch: 17
2022-11-18 02:09:19,427 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8221713284199889, 'Total loss': 0.8221713284199889} | train loss {'Reaction outcome loss': 0.8159050822498337, 'Total loss': 0.8159050822498337}
2022-11-18 02:09:19,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:19,427 INFO:     Epoch: 18
2022-11-18 02:09:20,224 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.80234644562006, 'Total loss': 0.80234644562006} | train loss {'Reaction outcome loss': 0.8158764483467225, 'Total loss': 0.8158764483467225}
2022-11-18 02:09:20,224 INFO:     Found new best model at epoch 18
2022-11-18 02:09:20,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:20,225 INFO:     Epoch: 19
2022-11-18 02:09:21,000 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8178144706921144, 'Total loss': 0.8178144706921144} | train loss {'Reaction outcome loss': 0.8125128522515297, 'Total loss': 0.8125128522515297}
2022-11-18 02:09:21,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:21,000 INFO:     Epoch: 20
2022-11-18 02:09:21,764 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8315253758972342, 'Total loss': 0.8315253758972342} | train loss {'Reaction outcome loss': 0.8155917208040914, 'Total loss': 0.8155917208040914}
2022-11-18 02:09:21,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:21,764 INFO:     Epoch: 21
2022-11-18 02:09:22,557 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8263537023555149, 'Total loss': 0.8263537023555149} | train loss {'Reaction outcome loss': 0.8159606612978443, 'Total loss': 0.8159606612978443}
2022-11-18 02:09:22,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:22,557 INFO:     Epoch: 22
2022-11-18 02:09:23,351 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8073628070679578, 'Total loss': 0.8073628070679578} | train loss {'Reaction outcome loss': 0.8139215249928736, 'Total loss': 0.8139215249928736}
2022-11-18 02:09:23,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:23,351 INFO:     Epoch: 23
2022-11-18 02:09:24,123 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7997661978006363, 'Total loss': 0.7997661978006363} | train loss {'Reaction outcome loss': 0.8181459438656608, 'Total loss': 0.8181459438656608}
2022-11-18 02:09:24,123 INFO:     Found new best model at epoch 23
2022-11-18 02:09:24,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:24,124 INFO:     Epoch: 24
2022-11-18 02:09:24,894 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8184435259212147, 'Total loss': 0.8184435259212147} | train loss {'Reaction outcome loss': 0.8129272569091089, 'Total loss': 0.8129272569091089}
2022-11-18 02:09:24,894 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:24,894 INFO:     Epoch: 25
2022-11-18 02:09:25,683 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8221977583386681, 'Total loss': 0.8221977583386681} | train loss {'Reaction outcome loss': 0.808068698091853, 'Total loss': 0.808068698091853}
2022-11-18 02:09:25,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:25,684 INFO:     Epoch: 26
2022-11-18 02:09:26,455 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8013782758604396, 'Total loss': 0.8013782758604396} | train loss {'Reaction outcome loss': 0.8191473988756057, 'Total loss': 0.8191473988756057}
2022-11-18 02:09:26,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:26,456 INFO:     Epoch: 27
2022-11-18 02:09:27,251 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8201564780690453, 'Total loss': 0.8201564780690453} | train loss {'Reaction outcome loss': 0.8123428547574628, 'Total loss': 0.8123428547574628}
2022-11-18 02:09:27,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:27,252 INFO:     Epoch: 28
2022-11-18 02:09:28,022 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.819280207157135, 'Total loss': 0.819280207157135} | train loss {'Reaction outcome loss': 0.8126191638650433, 'Total loss': 0.8126191638650433}
2022-11-18 02:09:28,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:28,023 INFO:     Epoch: 29
2022-11-18 02:09:28,828 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8043894970958884, 'Total loss': 0.8043894970958884} | train loss {'Reaction outcome loss': 0.8161923033335516, 'Total loss': 0.8161923033335516}
2022-11-18 02:09:28,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:28,828 INFO:     Epoch: 30
2022-11-18 02:09:29,621 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8089847740801898, 'Total loss': 0.8089847740801898} | train loss {'Reaction outcome loss': 0.8153318661835885, 'Total loss': 0.8153318661835885}
2022-11-18 02:09:29,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:29,622 INFO:     Epoch: 31
2022-11-18 02:09:30,425 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8245607106523081, 'Total loss': 0.8245607106523081} | train loss {'Reaction outcome loss': 0.8176439834698555, 'Total loss': 0.8176439834698555}
2022-11-18 02:09:30,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:30,427 INFO:     Epoch: 32
2022-11-18 02:09:31,229 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8188349144025282, 'Total loss': 0.8188349144025282} | train loss {'Reaction outcome loss': 0.8150434352217182, 'Total loss': 0.8150434352217182}
2022-11-18 02:09:31,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:31,229 INFO:     Epoch: 33
2022-11-18 02:09:31,998 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8100733675739982, 'Total loss': 0.8100733675739982} | train loss {'Reaction outcome loss': 0.8146036364618809, 'Total loss': 0.8146036364618809}
2022-11-18 02:09:31,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:31,999 INFO:     Epoch: 34
2022-11-18 02:09:32,796 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8215123631737449, 'Total loss': 0.8215123631737449} | train loss {'Reaction outcome loss': 0.8146525871369147, 'Total loss': 0.8146525871369147}
2022-11-18 02:09:32,796 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:32,796 INFO:     Epoch: 35
2022-11-18 02:09:33,585 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8649680350314487, 'Total loss': 0.8649680350314487} | train loss {'Reaction outcome loss': 0.8095330321981061, 'Total loss': 0.8095330321981061}
2022-11-18 02:09:33,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:33,586 INFO:     Epoch: 36
2022-11-18 02:09:34,392 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7996080422943289, 'Total loss': 0.7996080422943289} | train loss {'Reaction outcome loss': 0.8143655995447789, 'Total loss': 0.8143655995447789}
2022-11-18 02:09:34,392 INFO:     Found new best model at epoch 36
2022-11-18 02:09:34,393 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:34,393 INFO:     Epoch: 37
2022-11-18 02:09:35,168 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8028491213917732, 'Total loss': 0.8028491213917732} | train loss {'Reaction outcome loss': 0.8117736598416683, 'Total loss': 0.8117736598416683}
2022-11-18 02:09:35,169 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:35,169 INFO:     Epoch: 38
2022-11-18 02:09:35,958 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8191914720968767, 'Total loss': 0.8191914720968767} | train loss {'Reaction outcome loss': 0.8138526175171137, 'Total loss': 0.8138526175171137}
2022-11-18 02:09:35,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:35,958 INFO:     Epoch: 39
2022-11-18 02:09:36,735 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8262553905898874, 'Total loss': 0.8262553905898874} | train loss {'Reaction outcome loss': 0.8083182790827367, 'Total loss': 0.8083182790827367}
2022-11-18 02:09:36,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:36,736 INFO:     Epoch: 40
2022-11-18 02:09:37,529 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8105361244895242, 'Total loss': 0.8105361244895242} | train loss {'Reaction outcome loss': 0.8120472672725877, 'Total loss': 0.8120472672725877}
2022-11-18 02:09:37,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:37,530 INFO:     Epoch: 41
2022-11-18 02:09:38,316 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8254021379080686, 'Total loss': 0.8254021379080686} | train loss {'Reaction outcome loss': 0.8108483929066889, 'Total loss': 0.8108483929066889}
2022-11-18 02:09:38,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:38,316 INFO:     Epoch: 42
2022-11-18 02:09:39,105 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8319498341191899, 'Total loss': 0.8319498341191899} | train loss {'Reaction outcome loss': 0.8168305570800458, 'Total loss': 0.8168305570800458}
2022-11-18 02:09:39,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:39,105 INFO:     Epoch: 43
2022-11-18 02:09:39,886 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8069269914518703, 'Total loss': 0.8069269914518703} | train loss {'Reaction outcome loss': 0.8122895118449965, 'Total loss': 0.8122895118449965}
2022-11-18 02:09:39,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:39,886 INFO:     Epoch: 44
2022-11-18 02:09:40,694 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8046273324977268, 'Total loss': 0.8046273324977268} | train loss {'Reaction outcome loss': 0.8118197406011243, 'Total loss': 0.8118197406011243}
2022-11-18 02:09:40,694 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:40,694 INFO:     Epoch: 45
2022-11-18 02:09:41,471 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.80929104171016, 'Total loss': 0.80929104171016} | train loss {'Reaction outcome loss': 0.8152334800650997, 'Total loss': 0.8152334800650997}
2022-11-18 02:09:41,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:41,471 INFO:     Epoch: 46
2022-11-18 02:09:42,249 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8382063182917509, 'Total loss': 0.8382063182917509} | train loss {'Reaction outcome loss': 0.8107169165966972, 'Total loss': 0.8107169165966972}
2022-11-18 02:09:42,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:42,250 INFO:     Epoch: 47
2022-11-18 02:09:43,038 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7977004037661986, 'Total loss': 0.7977004037661986} | train loss {'Reaction outcome loss': 0.8110116984575025, 'Total loss': 0.8110116984575025}
2022-11-18 02:09:43,039 INFO:     Found new best model at epoch 47
2022-11-18 02:09:43,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:43,040 INFO:     Epoch: 48
2022-11-18 02:09:43,799 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8075043091719801, 'Total loss': 0.8075043091719801} | train loss {'Reaction outcome loss': 0.8152604986342692, 'Total loss': 0.8152604986342692}
2022-11-18 02:09:43,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:43,800 INFO:     Epoch: 49
2022-11-18 02:09:44,586 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8086146969686855, 'Total loss': 0.8086146969686855} | train loss {'Reaction outcome loss': 0.8114909253293469, 'Total loss': 0.8114909253293469}
2022-11-18 02:09:44,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:44,586 INFO:     Epoch: 50
2022-11-18 02:09:45,359 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8157372623682022, 'Total loss': 0.8157372623682022} | train loss {'Reaction outcome loss': 0.8086842816443213, 'Total loss': 0.8086842816443213}
2022-11-18 02:09:45,359 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:45,359 INFO:     Epoch: 51
2022-11-18 02:09:46,141 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8335741419683803, 'Total loss': 0.8335741419683803} | train loss {'Reaction outcome loss': 0.8120302559146958, 'Total loss': 0.8120302559146958}
2022-11-18 02:09:46,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:46,141 INFO:     Epoch: 52
2022-11-18 02:09:46,920 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8262751772999763, 'Total loss': 0.8262751772999763} | train loss {'Reaction outcome loss': 0.8141187545993636, 'Total loss': 0.8141187545993636}
2022-11-18 02:09:46,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:46,921 INFO:     Epoch: 53
2022-11-18 02:09:47,716 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8118648325855081, 'Total loss': 0.8118648325855081} | train loss {'Reaction outcome loss': 0.811807292363336, 'Total loss': 0.811807292363336}
2022-11-18 02:09:47,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:47,716 INFO:     Epoch: 54
2022-11-18 02:09:48,518 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8013511564243924, 'Total loss': 0.8013511564243924} | train loss {'Reaction outcome loss': 0.8124079377420487, 'Total loss': 0.8124079377420487}
2022-11-18 02:09:48,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:48,518 INFO:     Epoch: 55
2022-11-18 02:09:49,298 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8159253482114185, 'Total loss': 0.8159253482114185} | train loss {'Reaction outcome loss': 0.8083125987360554, 'Total loss': 0.8083125987360554}
2022-11-18 02:09:49,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:49,299 INFO:     Epoch: 56
2022-11-18 02:09:50,097 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8044855703007091, 'Total loss': 0.8044855703007091} | train loss {'Reaction outcome loss': 0.8166578967244394, 'Total loss': 0.8166578967244394}
2022-11-18 02:09:50,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:50,097 INFO:     Epoch: 57
2022-11-18 02:09:50,899 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8150426813147285, 'Total loss': 0.8150426813147285} | train loss {'Reaction outcome loss': 0.8123020927511877, 'Total loss': 0.8123020927511877}
2022-11-18 02:09:50,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:50,899 INFO:     Epoch: 58
2022-11-18 02:09:51,678 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8053377020088109, 'Total loss': 0.8053377020088109} | train loss {'Reaction outcome loss': 0.8153523498725507, 'Total loss': 0.8153523498725507}
2022-11-18 02:09:51,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:51,679 INFO:     Epoch: 59
2022-11-18 02:09:52,486 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8038756420666521, 'Total loss': 0.8038756420666521} | train loss {'Reaction outcome loss': 0.8115744978910492, 'Total loss': 0.8115744978910492}
2022-11-18 02:09:52,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:52,486 INFO:     Epoch: 60
2022-11-18 02:09:53,296 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7989068681543524, 'Total loss': 0.7989068681543524} | train loss {'Reaction outcome loss': 0.8107741834415544, 'Total loss': 0.8107741834415544}
2022-11-18 02:09:53,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:53,296 INFO:     Epoch: 61
2022-11-18 02:09:54,095 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8268800242380663, 'Total loss': 0.8268800242380663} | train loss {'Reaction outcome loss': 0.8121754489839077, 'Total loss': 0.8121754489839077}
2022-11-18 02:09:54,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:54,095 INFO:     Epoch: 62
2022-11-18 02:09:54,897 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.802967871454629, 'Total loss': 0.802967871454629} | train loss {'Reaction outcome loss': 0.8159025542197689, 'Total loss': 0.8159025542197689}
2022-11-18 02:09:54,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:54,897 INFO:     Epoch: 63
2022-11-18 02:09:55,674 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8163015490228479, 'Total loss': 0.8163015490228479} | train loss {'Reaction outcome loss': 0.809392329425581, 'Total loss': 0.809392329425581}
2022-11-18 02:09:55,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:55,675 INFO:     Epoch: 64
2022-11-18 02:09:56,452 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7969763617623936, 'Total loss': 0.7969763617623936} | train loss {'Reaction outcome loss': 0.8156657845022217, 'Total loss': 0.8156657845022217}
2022-11-18 02:09:56,452 INFO:     Found new best model at epoch 64
2022-11-18 02:09:56,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:56,453 INFO:     Epoch: 65
2022-11-18 02:09:57,229 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.809885827655142, 'Total loss': 0.809885827655142} | train loss {'Reaction outcome loss': 0.8108474279363309, 'Total loss': 0.8108474279363309}
2022-11-18 02:09:57,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:57,229 INFO:     Epoch: 66
2022-11-18 02:09:58,009 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8141109083186496, 'Total loss': 0.8141109083186496} | train loss {'Reaction outcome loss': 0.8089649237452015, 'Total loss': 0.8089649237452015}
2022-11-18 02:09:58,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:58,009 INFO:     Epoch: 67
2022-11-18 02:09:58,777 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8148273175412958, 'Total loss': 0.8148273175412958} | train loss {'Reaction outcome loss': 0.8173999525606632, 'Total loss': 0.8173999525606632}
2022-11-18 02:09:58,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:58,777 INFO:     Epoch: 68
2022-11-18 02:09:59,555 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8031916015527465, 'Total loss': 0.8031916015527465} | train loss {'Reaction outcome loss': 0.8125789968236801, 'Total loss': 0.8125789968236801}
2022-11-18 02:09:59,555 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:09:59,555 INFO:     Epoch: 69
2022-11-18 02:10:00,356 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8109600909731605, 'Total loss': 0.8109600909731605} | train loss {'Reaction outcome loss': 0.8127805409171889, 'Total loss': 0.8127805409171889}
2022-11-18 02:10:00,356 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:00,356 INFO:     Epoch: 70
2022-11-18 02:10:01,141 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8048814270984043, 'Total loss': 0.8048814270984043} | train loss {'Reaction outcome loss': 0.8104551316749665, 'Total loss': 0.8104551316749665}
2022-11-18 02:10:01,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:01,141 INFO:     Epoch: 71
2022-11-18 02:10:01,939 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8084364418279041, 'Total loss': 0.8084364418279041} | train loss {'Reaction outcome loss': 0.8113060702960337, 'Total loss': 0.8113060702960337}
2022-11-18 02:10:01,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:01,941 INFO:     Epoch: 72
2022-11-18 02:10:02,715 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8017063228921457, 'Total loss': 0.8017063228921457} | train loss {'Reaction outcome loss': 0.8092935827951278, 'Total loss': 0.8092935827951278}
2022-11-18 02:10:02,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:02,715 INFO:     Epoch: 73
2022-11-18 02:10:03,518 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.814273672347719, 'Total loss': 0.814273672347719} | train loss {'Reaction outcome loss': 0.8098734868389945, 'Total loss': 0.8098734868389945}
2022-11-18 02:10:03,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:03,519 INFO:     Epoch: 74
2022-11-18 02:10:04,330 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8005611463026567, 'Total loss': 0.8005611463026567} | train loss {'Reaction outcome loss': 0.8100994869826301, 'Total loss': 0.8100994869826301}
2022-11-18 02:10:04,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:04,330 INFO:     Epoch: 75
2022-11-18 02:10:05,147 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8102805722843517, 'Total loss': 0.8102805722843517} | train loss {'Reaction outcome loss': 0.8127592790030664, 'Total loss': 0.8127592790030664}
2022-11-18 02:10:05,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:05,147 INFO:     Epoch: 76
2022-11-18 02:10:06,002 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8034875182942911, 'Total loss': 0.8034875182942911} | train loss {'Reaction outcome loss': 0.814255533679839, 'Total loss': 0.814255533679839}
2022-11-18 02:10:06,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:06,003 INFO:     Epoch: 77
2022-11-18 02:10:06,807 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.814106744798747, 'Total loss': 0.814106744798747} | train loss {'Reaction outcome loss': 0.8089769503041622, 'Total loss': 0.8089769503041622}
2022-11-18 02:10:06,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:06,807 INFO:     Epoch: 78
2022-11-18 02:10:07,654 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8112963783470067, 'Total loss': 0.8112963783470067} | train loss {'Reaction outcome loss': 0.8105776023960882, 'Total loss': 0.8105776023960882}
2022-11-18 02:10:07,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:07,655 INFO:     Epoch: 79
2022-11-18 02:10:08,454 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8123108033429493, 'Total loss': 0.8123108033429493} | train loss {'Reaction outcome loss': 0.8106849993909558, 'Total loss': 0.8106849993909558}
2022-11-18 02:10:08,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:08,455 INFO:     Epoch: 80
2022-11-18 02:10:09,254 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7996232922781598, 'Total loss': 0.7996232922781598} | train loss {'Reaction outcome loss': 0.8169298650276277, 'Total loss': 0.8169298650276277}
2022-11-18 02:10:09,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:09,254 INFO:     Epoch: 81
2022-11-18 02:10:10,070 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8056256100535393, 'Total loss': 0.8056256100535393} | train loss {'Reaction outcome loss': 0.8083636504748175, 'Total loss': 0.8083636504748175}
2022-11-18 02:10:10,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:10,071 INFO:     Epoch: 82
2022-11-18 02:10:10,879 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8141312633048404, 'Total loss': 0.8141312633048404} | train loss {'Reaction outcome loss': 0.8134438336616562, 'Total loss': 0.8134438336616562}
2022-11-18 02:10:10,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:10,880 INFO:     Epoch: 83
2022-11-18 02:10:11,743 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8061836741187356, 'Total loss': 0.8061836741187356} | train loss {'Reaction outcome loss': 0.8096345565732448, 'Total loss': 0.8096345565732448}
2022-11-18 02:10:11,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:11,743 INFO:     Epoch: 84
2022-11-18 02:10:12,546 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8235471709208055, 'Total loss': 0.8235471709208055} | train loss {'Reaction outcome loss': 0.8191206027423182, 'Total loss': 0.8191206027423182}
2022-11-18 02:10:12,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:12,547 INFO:     Epoch: 85
2022-11-18 02:10:13,325 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8222043006257578, 'Total loss': 0.8222043006257578} | train loss {'Reaction outcome loss': 0.8118205138992879, 'Total loss': 0.8118205138992879}
2022-11-18 02:10:13,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:13,325 INFO:     Epoch: 86
2022-11-18 02:10:14,120 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8360844789580866, 'Total loss': 0.8360844789580866} | train loss {'Reaction outcome loss': 0.8140322538393159, 'Total loss': 0.8140322538393159}
2022-11-18 02:10:14,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:14,120 INFO:     Epoch: 87
2022-11-18 02:10:14,920 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8099208968606862, 'Total loss': 0.8099208968606862} | train loss {'Reaction outcome loss': 0.8075511429098344, 'Total loss': 0.8075511429098344}
2022-11-18 02:10:14,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:14,920 INFO:     Epoch: 88
2022-11-18 02:10:15,715 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8184160576625303, 'Total loss': 0.8184160576625303} | train loss {'Reaction outcome loss': 0.8096192850460929, 'Total loss': 0.8096192850460929}
2022-11-18 02:10:15,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:15,715 INFO:     Epoch: 89
2022-11-18 02:10:16,531 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8091925023631616, 'Total loss': 0.8091925023631616} | train loss {'Reaction outcome loss': 0.8135961518893319, 'Total loss': 0.8135961518893319}
2022-11-18 02:10:16,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:16,532 INFO:     Epoch: 90
2022-11-18 02:10:17,336 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8095811009407043, 'Total loss': 0.8095811009407043} | train loss {'Reaction outcome loss': 0.8093742534758583, 'Total loss': 0.8093742534758583}
2022-11-18 02:10:17,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:17,337 INFO:     Epoch: 91
2022-11-18 02:10:18,141 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7978769208897244, 'Total loss': 0.7978769208897244} | train loss {'Reaction outcome loss': 0.8127624036804322, 'Total loss': 0.8127624036804322}
2022-11-18 02:10:18,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:18,141 INFO:     Epoch: 92
2022-11-18 02:10:18,935 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8179548260840502, 'Total loss': 0.8179548260840502} | train loss {'Reaction outcome loss': 0.8093627226208487, 'Total loss': 0.8093627226208487}
2022-11-18 02:10:18,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:18,935 INFO:     Epoch: 93
2022-11-18 02:10:19,786 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8058541958982294, 'Total loss': 0.8058541958982294} | train loss {'Reaction outcome loss': 0.8078689449016125, 'Total loss': 0.8078689449016125}
2022-11-18 02:10:19,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:19,787 INFO:     Epoch: 94
2022-11-18 02:10:20,603 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8152524036439982, 'Total loss': 0.8152524036439982} | train loss {'Reaction outcome loss': 0.8115315615169464, 'Total loss': 0.8115315615169464}
2022-11-18 02:10:20,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:20,604 INFO:     Epoch: 95
2022-11-18 02:10:21,389 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8037848255851052, 'Total loss': 0.8037848255851052} | train loss {'Reaction outcome loss': 0.8143583123962725, 'Total loss': 0.8143583123962725}
2022-11-18 02:10:21,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:21,389 INFO:     Epoch: 96
2022-11-18 02:10:22,191 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8528550240126523, 'Total loss': 0.8528550240126523} | train loss {'Reaction outcome loss': 0.8113509720611957, 'Total loss': 0.8113509720611957}
2022-11-18 02:10:22,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:22,191 INFO:     Epoch: 97
2022-11-18 02:10:22,970 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8195422278209166, 'Total loss': 0.8195422278209166} | train loss {'Reaction outcome loss': 0.8157736145921292, 'Total loss': 0.8157736145921292}
2022-11-18 02:10:22,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:22,970 INFO:     Epoch: 98
2022-11-18 02:10:23,750 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8152209398421374, 'Total loss': 0.8152209398421374} | train loss {'Reaction outcome loss': 0.813807854368802, 'Total loss': 0.813807854368802}
2022-11-18 02:10:23,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:23,750 INFO:     Epoch: 99
2022-11-18 02:10:24,556 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8072648210959001, 'Total loss': 0.8072648210959001} | train loss {'Reaction outcome loss': 0.8080363719453735, 'Total loss': 0.8080363719453735}
2022-11-18 02:10:24,556 INFO:     Best model found after epoch 65 of 100.
2022-11-18 02:10:24,556 INFO:   Done with stage: TRAINING
2022-11-18 02:10:24,556 INFO:   Starting stage: EVALUATION
2022-11-18 02:10:24,677 INFO:   Done with stage: EVALUATION
2022-11-18 02:10:24,677 INFO:   Leaving out SEQ value Fold_7
2022-11-18 02:10:24,690 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 02:10:24,690 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:10:25,378 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:10:25,378 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:10:25,450 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:10:25,450 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:10:25,450 INFO:     No hyperparam tuning for this model
2022-11-18 02:10:25,450 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:10:25,450 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:10:25,451 INFO:     None feature selector for col prot
2022-11-18 02:10:25,451 INFO:     None feature selector for col prot
2022-11-18 02:10:25,451 INFO:     None feature selector for col prot
2022-11-18 02:10:25,452 INFO:     None feature selector for col chem
2022-11-18 02:10:25,452 INFO:     None feature selector for col chem
2022-11-18 02:10:25,452 INFO:     None feature selector for col chem
2022-11-18 02:10:25,452 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:10:25,452 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:10:25,454 INFO:     Number of params in model 168571
2022-11-18 02:10:25,457 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:10:25,457 INFO:   Starting stage: TRAINING
2022-11-18 02:10:25,515 INFO:     Val loss before train {'Reaction outcome loss': 1.0462910329753703, 'Total loss': 1.0462910329753703}
2022-11-18 02:10:25,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:25,516 INFO:     Epoch: 0
2022-11-18 02:10:26,315 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.842494245279919, 'Total loss': 0.842494245279919} | train loss {'Reaction outcome loss': 0.8705616803058693, 'Total loss': 0.8705616803058693}
2022-11-18 02:10:26,315 INFO:     Found new best model at epoch 0
2022-11-18 02:10:26,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:26,316 INFO:     Epoch: 1
2022-11-18 02:10:27,171 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8798544230786237, 'Total loss': 0.8798544230786237} | train loss {'Reaction outcome loss': 0.8429343520152953, 'Total loss': 0.8429343520152953}
2022-11-18 02:10:27,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:27,172 INFO:     Epoch: 2
2022-11-18 02:10:27,993 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8421698598699137, 'Total loss': 0.8421698598699137} | train loss {'Reaction outcome loss': 0.8286742487501714, 'Total loss': 0.8286742487501714}
2022-11-18 02:10:27,993 INFO:     Found new best model at epoch 2
2022-11-18 02:10:27,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:27,994 INFO:     Epoch: 3
2022-11-18 02:10:28,810 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8456910692832686, 'Total loss': 0.8456910692832686} | train loss {'Reaction outcome loss': 0.8243178522154209, 'Total loss': 0.8243178522154209}
2022-11-18 02:10:28,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:28,810 INFO:     Epoch: 4
2022-11-18 02:10:29,662 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8329937837340615, 'Total loss': 0.8329937837340615} | train loss {'Reaction outcome loss': 0.8132743641974465, 'Total loss': 0.8132743641974465}
2022-11-18 02:10:29,662 INFO:     Found new best model at epoch 4
2022-11-18 02:10:29,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:29,663 INFO:     Epoch: 5
2022-11-18 02:10:30,512 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8208167634227059, 'Total loss': 0.8208167634227059} | train loss {'Reaction outcome loss': 0.8111593442097786, 'Total loss': 0.8111593442097786}
2022-11-18 02:10:30,512 INFO:     Found new best model at epoch 5
2022-11-18 02:10:30,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:30,513 INFO:     Epoch: 6
2022-11-18 02:10:31,301 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8478273769671266, 'Total loss': 0.8478273769671266} | train loss {'Reaction outcome loss': 0.8103228698094045, 'Total loss': 0.8103228698094045}
2022-11-18 02:10:31,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:31,301 INFO:     Epoch: 7
2022-11-18 02:10:32,114 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8227911645715887, 'Total loss': 0.8227911645715887} | train loss {'Reaction outcome loss': 0.8033807454330306, 'Total loss': 0.8033807454330306}
2022-11-18 02:10:32,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:32,114 INFO:     Epoch: 8
2022-11-18 02:10:32,920 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8421299274672162, 'Total loss': 0.8421299274672162} | train loss {'Reaction outcome loss': 0.8037749190003641, 'Total loss': 0.8037749190003641}
2022-11-18 02:10:32,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:32,922 INFO:     Epoch: 9
2022-11-18 02:10:33,750 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8332133178006519, 'Total loss': 0.8332133178006519} | train loss {'Reaction outcome loss': 0.8067720387010805, 'Total loss': 0.8067720387010805}
2022-11-18 02:10:33,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:33,751 INFO:     Epoch: 10
2022-11-18 02:10:34,592 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8344208273020658, 'Total loss': 0.8344208273020658} | train loss {'Reaction outcome loss': 0.8064701575185022, 'Total loss': 0.8064701575185022}
2022-11-18 02:10:34,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:34,593 INFO:     Epoch: 11
2022-11-18 02:10:35,386 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8318277062340216, 'Total loss': 0.8318277062340216} | train loss {'Reaction outcome loss': 0.8000350384221923, 'Total loss': 0.8000350384221923}
2022-11-18 02:10:35,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:35,387 INFO:     Epoch: 12
2022-11-18 02:10:36,209 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8384414965456183, 'Total loss': 0.8384414965456183} | train loss {'Reaction outcome loss': 0.8052911008557966, 'Total loss': 0.8052911008557966}
2022-11-18 02:10:36,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:36,209 INFO:     Epoch: 13
2022-11-18 02:10:37,036 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8336767574602907, 'Total loss': 0.8336767574602907} | train loss {'Reaction outcome loss': 0.8067072361948029, 'Total loss': 0.8067072361948029}
2022-11-18 02:10:37,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:37,037 INFO:     Epoch: 14
2022-11-18 02:10:37,845 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8283257064494219, 'Total loss': 0.8283257064494219} | train loss {'Reaction outcome loss': 0.8059202817178541, 'Total loss': 0.8059202817178541}
2022-11-18 02:10:37,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:37,846 INFO:     Epoch: 15
2022-11-18 02:10:38,697 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8165278935974295, 'Total loss': 0.8165278935974295} | train loss {'Reaction outcome loss': 0.7986275024952427, 'Total loss': 0.7986275024952427}
2022-11-18 02:10:38,697 INFO:     Found new best model at epoch 15
2022-11-18 02:10:38,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:38,698 INFO:     Epoch: 16
2022-11-18 02:10:39,543 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8382331444458528, 'Total loss': 0.8382331444458528} | train loss {'Reaction outcome loss': 0.8058443862584329, 'Total loss': 0.8058443862584329}
2022-11-18 02:10:39,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:39,544 INFO:     Epoch: 17
2022-11-18 02:10:40,323 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8320020992647518, 'Total loss': 0.8320020992647518} | train loss {'Reaction outcome loss': 0.8052480875724747, 'Total loss': 0.8052480875724747}
2022-11-18 02:10:40,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:40,324 INFO:     Epoch: 18
2022-11-18 02:10:41,160 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8241000859574839, 'Total loss': 0.8241000859574839} | train loss {'Reaction outcome loss': 0.8025228925529988, 'Total loss': 0.8025228925529988}
2022-11-18 02:10:41,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:41,160 INFO:     Epoch: 19
2022-11-18 02:10:41,961 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8281756409189918, 'Total loss': 0.8281756409189918} | train loss {'Reaction outcome loss': 0.804765515510113, 'Total loss': 0.804765515510113}
2022-11-18 02:10:41,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:41,961 INFO:     Epoch: 20
2022-11-18 02:10:42,758 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8270355341109362, 'Total loss': 0.8270355341109362} | train loss {'Reaction outcome loss': 0.8048630668030631, 'Total loss': 0.8048630668030631}
2022-11-18 02:10:42,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:42,759 INFO:     Epoch: 21
2022-11-18 02:10:43,596 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8398151390931823, 'Total loss': 0.8398151390931823} | train loss {'Reaction outcome loss': 0.8004830459192875, 'Total loss': 0.8004830459192875}
2022-11-18 02:10:43,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:43,597 INFO:     Epoch: 22
2022-11-18 02:10:44,422 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8200652274218473, 'Total loss': 0.8200652274218473} | train loss {'Reaction outcome loss': 0.8007721773559048, 'Total loss': 0.8007721773559048}
2022-11-18 02:10:44,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:44,422 INFO:     Epoch: 23
2022-11-18 02:10:45,252 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8326024027033285, 'Total loss': 0.8326024027033285} | train loss {'Reaction outcome loss': 0.8001491829993264, 'Total loss': 0.8001491829993264}
2022-11-18 02:10:45,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:45,252 INFO:     Epoch: 24
2022-11-18 02:10:46,067 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.816231448541988, 'Total loss': 0.816231448541988} | train loss {'Reaction outcome loss': 0.8038881674649254, 'Total loss': 0.8038881674649254}
2022-11-18 02:10:46,067 INFO:     Found new best model at epoch 24
2022-11-18 02:10:46,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:46,068 INFO:     Epoch: 25
2022-11-18 02:10:46,870 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8266999301585284, 'Total loss': 0.8266999301585284} | train loss {'Reaction outcome loss': 0.8048742822101039, 'Total loss': 0.8048742822101039}
2022-11-18 02:10:46,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:46,870 INFO:     Epoch: 26
2022-11-18 02:10:47,667 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8251995241100137, 'Total loss': 0.8251995241100137} | train loss {'Reaction outcome loss': 0.8009840044523439, 'Total loss': 0.8009840044523439}
2022-11-18 02:10:47,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:47,668 INFO:     Epoch: 27
2022-11-18 02:10:48,460 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8375577073205601, 'Total loss': 0.8375577073205601} | train loss {'Reaction outcome loss': 0.8030685202008293, 'Total loss': 0.8030685202008293}
2022-11-18 02:10:48,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:48,461 INFO:     Epoch: 28
2022-11-18 02:10:49,263 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8244095329533924, 'Total loss': 0.8244095329533924} | train loss {'Reaction outcome loss': 0.8044352172122847, 'Total loss': 0.8044352172122847}
2022-11-18 02:10:49,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:49,263 INFO:     Epoch: 29
2022-11-18 02:10:50,054 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8227171532132409, 'Total loss': 0.8227171532132409} | train loss {'Reaction outcome loss': 0.8001515336575047, 'Total loss': 0.8001515336575047}
2022-11-18 02:10:50,054 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:50,055 INFO:     Epoch: 30
2022-11-18 02:10:50,841 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8337565958499908, 'Total loss': 0.8337565958499908} | train loss {'Reaction outcome loss': 0.799325318826783, 'Total loss': 0.799325318826783}
2022-11-18 02:10:50,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:50,841 INFO:     Epoch: 31
2022-11-18 02:10:51,670 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8260651406916705, 'Total loss': 0.8260651406916705} | train loss {'Reaction outcome loss': 0.8026947222890393, 'Total loss': 0.8026947222890393}
2022-11-18 02:10:51,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:51,671 INFO:     Epoch: 32
2022-11-18 02:10:52,471 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8788027099587701, 'Total loss': 0.8788027099587701} | train loss {'Reaction outcome loss': 0.7973189195317607, 'Total loss': 0.7973189195317607}
2022-11-18 02:10:52,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:52,471 INFO:     Epoch: 33
2022-11-18 02:10:53,262 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8130819621411237, 'Total loss': 0.8130819621411237} | train loss {'Reaction outcome loss': 0.8019797967806939, 'Total loss': 0.8019797967806939}
2022-11-18 02:10:53,262 INFO:     Found new best model at epoch 33
2022-11-18 02:10:53,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:53,263 INFO:     Epoch: 34
2022-11-18 02:10:54,119 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8673705539920114, 'Total loss': 0.8673705539920114} | train loss {'Reaction outcome loss': 0.7996303770811327, 'Total loss': 0.7996303770811327}
2022-11-18 02:10:54,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:54,120 INFO:     Epoch: 35
2022-11-18 02:10:54,953 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.836589748209173, 'Total loss': 0.836589748209173} | train loss {'Reaction outcome loss': 0.7960320553712307, 'Total loss': 0.7960320553712307}
2022-11-18 02:10:54,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:54,954 INFO:     Epoch: 36
2022-11-18 02:10:55,753 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8361267549070445, 'Total loss': 0.8361267549070445} | train loss {'Reaction outcome loss': 0.8015827120191628, 'Total loss': 0.8015827120191628}
2022-11-18 02:10:55,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:55,754 INFO:     Epoch: 37
2022-11-18 02:10:56,561 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.819475457072258, 'Total loss': 0.819475457072258} | train loss {'Reaction outcome loss': 0.8040373300112063, 'Total loss': 0.8040373300112063}
2022-11-18 02:10:56,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:56,562 INFO:     Epoch: 38
2022-11-18 02:10:57,362 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8354798060926524, 'Total loss': 0.8354798060926524} | train loss {'Reaction outcome loss': 0.8004597073360797, 'Total loss': 0.8004597073360797}
2022-11-18 02:10:57,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:57,362 INFO:     Epoch: 39
2022-11-18 02:10:58,164 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8214460672302679, 'Total loss': 0.8214460672302679} | train loss {'Reaction outcome loss': 0.8019964202277122, 'Total loss': 0.8019964202277122}
2022-11-18 02:10:58,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:58,164 INFO:     Epoch: 40
2022-11-18 02:10:58,978 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8422613814473152, 'Total loss': 0.8422613814473152} | train loss {'Reaction outcome loss': 0.8006125519112233, 'Total loss': 0.8006125519112233}
2022-11-18 02:10:58,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:58,978 INFO:     Epoch: 41
2022-11-18 02:10:59,824 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8261546858332374, 'Total loss': 0.8261546858332374} | train loss {'Reaction outcome loss': 0.7986581020297543, 'Total loss': 0.7986581020297543}
2022-11-18 02:10:59,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:10:59,824 INFO:     Epoch: 42
2022-11-18 02:11:00,630 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8576855916868557, 'Total loss': 0.8576855916868557} | train loss {'Reaction outcome loss': 0.7980457954108715, 'Total loss': 0.7980457954108715}
2022-11-18 02:11:00,630 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:00,630 INFO:     Epoch: 43
2022-11-18 02:11:01,474 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8290242701768875, 'Total loss': 0.8290242701768875} | train loss {'Reaction outcome loss': 0.8015428609665363, 'Total loss': 0.8015428609665363}
2022-11-18 02:11:01,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:01,474 INFO:     Epoch: 44
2022-11-18 02:11:02,285 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8245107870210301, 'Total loss': 0.8245107870210301} | train loss {'Reaction outcome loss': 0.7987291790665157, 'Total loss': 0.7987291790665157}
2022-11-18 02:11:02,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:02,286 INFO:     Epoch: 45
2022-11-18 02:11:03,105 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.820473507724025, 'Total loss': 0.820473507724025} | train loss {'Reaction outcome loss': 0.801944529217097, 'Total loss': 0.801944529217097}
2022-11-18 02:11:03,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:03,106 INFO:     Epoch: 46
2022-11-18 02:11:03,906 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8399070819670503, 'Total loss': 0.8399070819670503} | train loss {'Reaction outcome loss': 0.7929072347619841, 'Total loss': 0.7929072347619841}
2022-11-18 02:11:03,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:03,907 INFO:     Epoch: 47
2022-11-18 02:11:04,713 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8283642022447153, 'Total loss': 0.8283642022447153} | train loss {'Reaction outcome loss': 0.8028278930052635, 'Total loss': 0.8028278930052635}
2022-11-18 02:11:04,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:04,713 INFO:     Epoch: 48
2022-11-18 02:11:05,533 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8209919733079997, 'Total loss': 0.8209919733079997} | train loss {'Reaction outcome loss': 0.8043545682824427, 'Total loss': 0.8043545682824427}
2022-11-18 02:11:05,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:05,533 INFO:     Epoch: 49
2022-11-18 02:11:06,386 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8217828287319704, 'Total loss': 0.8217828287319704} | train loss {'Reaction outcome loss': 0.7965774789692894, 'Total loss': 0.7965774789692894}
2022-11-18 02:11:06,386 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:06,386 INFO:     Epoch: 50
2022-11-18 02:11:07,155 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8175974664362994, 'Total loss': 0.8175974664362994} | train loss {'Reaction outcome loss': 0.8020723748110956, 'Total loss': 0.8020723748110956}
2022-11-18 02:11:07,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:07,156 INFO:     Epoch: 51
2022-11-18 02:11:07,987 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8329840580170805, 'Total loss': 0.8329840580170805} | train loss {'Reaction outcome loss': 0.7977942629687248, 'Total loss': 0.7977942629687248}
2022-11-18 02:11:07,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:07,987 INFO:     Epoch: 52
2022-11-18 02:11:08,809 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.849089965224266, 'Total loss': 0.849089965224266} | train loss {'Reaction outcome loss': 0.7977267822190639, 'Total loss': 0.7977267822190639}
2022-11-18 02:11:08,809 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:08,809 INFO:     Epoch: 53
2022-11-18 02:11:09,643 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.821076208894903, 'Total loss': 0.821076208894903} | train loss {'Reaction outcome loss': 0.7979012068000532, 'Total loss': 0.7979012068000532}
2022-11-18 02:11:09,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:09,643 INFO:     Epoch: 54
2022-11-18 02:11:10,467 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8243788839741186, 'Total loss': 0.8243788839741186} | train loss {'Reaction outcome loss': 0.795074688811456, 'Total loss': 0.795074688811456}
2022-11-18 02:11:10,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:10,468 INFO:     Epoch: 55
2022-11-18 02:11:11,286 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8266921395605261, 'Total loss': 0.8266921395605261} | train loss {'Reaction outcome loss': 0.7931177687020071, 'Total loss': 0.7931177687020071}
2022-11-18 02:11:11,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:11,286 INFO:     Epoch: 56
2022-11-18 02:11:12,128 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8311566575007006, 'Total loss': 0.8311566575007006} | train loss {'Reaction outcome loss': 0.8022263209906316, 'Total loss': 0.8022263209906316}
2022-11-18 02:11:12,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:12,128 INFO:     Epoch: 57
2022-11-18 02:11:12,965 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8189855285666205, 'Total loss': 0.8189855285666205} | train loss {'Reaction outcome loss': 0.7958953660582343, 'Total loss': 0.7958953660582343}
2022-11-18 02:11:12,965 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:12,965 INFO:     Epoch: 58
2022-11-18 02:11:13,802 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.825601380657066, 'Total loss': 0.825601380657066} | train loss {'Reaction outcome loss': 0.7963067063641164, 'Total loss': 0.7963067063641164}
2022-11-18 02:11:13,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:13,802 INFO:     Epoch: 59
2022-11-18 02:11:14,652 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.847017727792263, 'Total loss': 0.847017727792263} | train loss {'Reaction outcome loss': 0.797354664533369, 'Total loss': 0.797354664533369}
2022-11-18 02:11:14,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:14,652 INFO:     Epoch: 60
2022-11-18 02:11:15,492 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8159034645015543, 'Total loss': 0.8159034645015543} | train loss {'Reaction outcome loss': 0.8024311345671454, 'Total loss': 0.8024311345671454}
2022-11-18 02:11:15,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:15,493 INFO:     Epoch: 61
2022-11-18 02:11:16,292 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.814692734317346, 'Total loss': 0.814692734317346} | train loss {'Reaction outcome loss': 0.7962948324218873, 'Total loss': 0.7962948324218873}
2022-11-18 02:11:16,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:16,292 INFO:     Epoch: 62
2022-11-18 02:11:17,112 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8184412128546021, 'Total loss': 0.8184412128546021} | train loss {'Reaction outcome loss': 0.7946944995032202, 'Total loss': 0.7946944995032202}
2022-11-18 02:11:17,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:17,113 INFO:     Epoch: 63
2022-11-18 02:11:17,948 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8322411680763419, 'Total loss': 0.8322411680763419} | train loss {'Reaction outcome loss': 0.7963513975902912, 'Total loss': 0.7963513975902912}
2022-11-18 02:11:17,948 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:17,948 INFO:     Epoch: 64
2022-11-18 02:11:18,762 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8496651446277445, 'Total loss': 0.8496651446277445} | train loss {'Reaction outcome loss': 0.7978071227910057, 'Total loss': 0.7978071227910057}
2022-11-18 02:11:18,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:18,762 INFO:     Epoch: 65
2022-11-18 02:11:19,585 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8360152115876024, 'Total loss': 0.8360152115876024} | train loss {'Reaction outcome loss': 0.8024951974230428, 'Total loss': 0.8024951974230428}
2022-11-18 02:11:19,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:19,585 INFO:     Epoch: 66
2022-11-18 02:11:20,429 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8219234577634118, 'Total loss': 0.8219234577634118} | train loss {'Reaction outcome loss': 0.798917667038979, 'Total loss': 0.798917667038979}
2022-11-18 02:11:20,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:20,429 INFO:     Epoch: 67
2022-11-18 02:11:21,243 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8223566209728067, 'Total loss': 0.8223566209728067} | train loss {'Reaction outcome loss': 0.7966055046887167, 'Total loss': 0.7966055046887167}
2022-11-18 02:11:21,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:21,243 INFO:     Epoch: 68
2022-11-18 02:11:22,050 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8136007812890139, 'Total loss': 0.8136007812890139} | train loss {'Reaction outcome loss': 0.7982173479132114, 'Total loss': 0.7982173479132114}
2022-11-18 02:11:22,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:22,050 INFO:     Epoch: 69
2022-11-18 02:11:22,864 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8238790421323343, 'Total loss': 0.8238790421323343} | train loss {'Reaction outcome loss': 0.7948671540906352, 'Total loss': 0.7948671540906352}
2022-11-18 02:11:22,865 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:22,865 INFO:     Epoch: 70
2022-11-18 02:11:23,714 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8329927799376574, 'Total loss': 0.8329927799376574} | train loss {'Reaction outcome loss': 0.7958943557835394, 'Total loss': 0.7958943557835394}
2022-11-18 02:11:23,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:23,715 INFO:     Epoch: 71
2022-11-18 02:11:24,509 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8162382665005598, 'Total loss': 0.8162382665005598} | train loss {'Reaction outcome loss': 0.8010428832663644, 'Total loss': 0.8010428832663644}
2022-11-18 02:11:24,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:24,509 INFO:     Epoch: 72
2022-11-18 02:11:25,278 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8335574343800545, 'Total loss': 0.8335574343800545} | train loss {'Reaction outcome loss': 0.7894281342385276, 'Total loss': 0.7894281342385276}
2022-11-18 02:11:25,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:25,279 INFO:     Epoch: 73
2022-11-18 02:11:26,070 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8204191462560133, 'Total loss': 0.8204191462560133} | train loss {'Reaction outcome loss': 0.7980477904840824, 'Total loss': 0.7980477904840824}
2022-11-18 02:11:26,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:26,070 INFO:     Epoch: 74
2022-11-18 02:11:26,879 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8095082532275807, 'Total loss': 0.8095082532275807} | train loss {'Reaction outcome loss': 0.79722908355536, 'Total loss': 0.79722908355536}
2022-11-18 02:11:26,879 INFO:     Found new best model at epoch 74
2022-11-18 02:11:26,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:26,880 INFO:     Epoch: 75
2022-11-18 02:11:27,706 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8204010806300424, 'Total loss': 0.8204010806300424} | train loss {'Reaction outcome loss': 0.7896553159000412, 'Total loss': 0.7896553159000412}
2022-11-18 02:11:27,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:27,706 INFO:     Epoch: 76
2022-11-18 02:11:28,527 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.835105839100751, 'Total loss': 0.835105839100751} | train loss {'Reaction outcome loss': 0.7899274088201984, 'Total loss': 0.7899274088201984}
2022-11-18 02:11:28,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:28,528 INFO:     Epoch: 77
2022-11-18 02:11:29,346 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8055844334038821, 'Total loss': 0.8055844334038821} | train loss {'Reaction outcome loss': 0.797563916012164, 'Total loss': 0.797563916012164}
2022-11-18 02:11:29,346 INFO:     Found new best model at epoch 77
2022-11-18 02:11:29,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:29,347 INFO:     Epoch: 78
2022-11-18 02:11:30,184 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.818067342042923, 'Total loss': 0.818067342042923} | train loss {'Reaction outcome loss': 0.7926567237704031, 'Total loss': 0.7926567237704031}
2022-11-18 02:11:30,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:30,184 INFO:     Epoch: 79
2022-11-18 02:11:31,007 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8363192054358396, 'Total loss': 0.8363192054358396} | train loss {'Reaction outcome loss': 0.7878912267906051, 'Total loss': 0.7878912267906051}
2022-11-18 02:11:31,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:31,007 INFO:     Epoch: 80
2022-11-18 02:11:31,829 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.810721561990001, 'Total loss': 0.810721561990001} | train loss {'Reaction outcome loss': 0.7922777407352002, 'Total loss': 0.7922777407352002}
2022-11-18 02:11:31,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:31,829 INFO:     Epoch: 81
2022-11-18 02:11:32,632 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8063670762560584, 'Total loss': 0.8063670762560584} | train loss {'Reaction outcome loss': 0.7865279093384743, 'Total loss': 0.7865279093384743}
2022-11-18 02:11:32,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:32,632 INFO:     Epoch: 82
2022-11-18 02:11:33,451 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8198797635056756, 'Total loss': 0.8198797635056756} | train loss {'Reaction outcome loss': 0.7970442717834827, 'Total loss': 0.7970442717834827}
2022-11-18 02:11:33,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:33,452 INFO:     Epoch: 83
2022-11-18 02:11:34,271 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8130708282644098, 'Total loss': 0.8130708282644098} | train loss {'Reaction outcome loss': 0.7897107073616597, 'Total loss': 0.7897107073616597}
2022-11-18 02:11:34,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:34,272 INFO:     Epoch: 84
2022-11-18 02:11:35,059 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8124513314528898, 'Total loss': 0.8124513314528898} | train loss {'Reaction outcome loss': 0.7880950963064548, 'Total loss': 0.7880950963064548}
2022-11-18 02:11:35,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:35,061 INFO:     Epoch: 85
2022-11-18 02:11:35,873 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8002804822542451, 'Total loss': 0.8002804822542451} | train loss {'Reaction outcome loss': 0.7868545222426614, 'Total loss': 0.7868545222426614}
2022-11-18 02:11:35,873 INFO:     Found new best model at epoch 85
2022-11-18 02:11:35,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:35,874 INFO:     Epoch: 86
2022-11-18 02:11:36,705 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8248714791102842, 'Total loss': 0.8248714791102842} | train loss {'Reaction outcome loss': 0.7867480682269219, 'Total loss': 0.7867480682269219}
2022-11-18 02:11:36,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:36,705 INFO:     Epoch: 87
2022-11-18 02:11:37,542 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8151933157985861, 'Total loss': 0.8151933157985861} | train loss {'Reaction outcome loss': 0.7835868995997214, 'Total loss': 0.7835868995997214}
2022-11-18 02:11:37,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:37,542 INFO:     Epoch: 88
2022-11-18 02:11:38,366 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7992295643145387, 'Total loss': 0.7992295643145387} | train loss {'Reaction outcome loss': 0.7857540067165129, 'Total loss': 0.7857540067165129}
2022-11-18 02:11:38,366 INFO:     Found new best model at epoch 88
2022-11-18 02:11:38,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:38,367 INFO:     Epoch: 89
2022-11-18 02:11:39,200 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8125301254066554, 'Total loss': 0.8125301254066554} | train loss {'Reaction outcome loss': 0.7878023982048035, 'Total loss': 0.7878023982048035}
2022-11-18 02:11:39,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:39,200 INFO:     Epoch: 90
2022-11-18 02:11:39,997 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7925778099081733, 'Total loss': 0.7925778099081733} | train loss {'Reaction outcome loss': 0.7872922664448139, 'Total loss': 0.7872922664448139}
2022-11-18 02:11:39,998 INFO:     Found new best model at epoch 90
2022-11-18 02:11:39,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:39,998 INFO:     Epoch: 91
2022-11-18 02:11:40,864 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8273315897042101, 'Total loss': 0.8273315897042101} | train loss {'Reaction outcome loss': 0.7833812608113212, 'Total loss': 0.7833812608113212}
2022-11-18 02:11:40,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:40,864 INFO:     Epoch: 92
2022-11-18 02:11:41,633 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8052557876164262, 'Total loss': 0.8052557876164262} | train loss {'Reaction outcome loss': 0.7816018628016594, 'Total loss': 0.7816018628016594}
2022-11-18 02:11:41,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:41,634 INFO:     Epoch: 93
2022-11-18 02:11:42,456 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8330896483226256, 'Total loss': 0.8330896483226256} | train loss {'Reaction outcome loss': 0.7850018514981193, 'Total loss': 0.7850018514981193}
2022-11-18 02:11:42,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:42,456 INFO:     Epoch: 94
2022-11-18 02:11:43,287 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.802160760218447, 'Total loss': 0.802160760218447} | train loss {'Reaction outcome loss': 0.7816995623851976, 'Total loss': 0.7816995623851976}
2022-11-18 02:11:43,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:43,287 INFO:     Epoch: 95
2022-11-18 02:11:44,107 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8097449954260479, 'Total loss': 0.8097449954260479} | train loss {'Reaction outcome loss': 0.7779504215765384, 'Total loss': 0.7779504215765384}
2022-11-18 02:11:44,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:44,107 INFO:     Epoch: 96
2022-11-18 02:11:44,936 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.810441713441502, 'Total loss': 0.810441713441502} | train loss {'Reaction outcome loss': 0.7745609415634986, 'Total loss': 0.7745609415634986}
2022-11-18 02:11:44,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:44,936 INFO:     Epoch: 97
2022-11-18 02:11:45,772 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8247803828933022, 'Total loss': 0.8247803828933022} | train loss {'Reaction outcome loss': 0.7786241370824075, 'Total loss': 0.7786241370824075}
2022-11-18 02:11:45,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:45,772 INFO:     Epoch: 98
2022-11-18 02:11:46,598 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8055022582411766, 'Total loss': 0.8055022582411766} | train loss {'Reaction outcome loss': 0.7876817646526522, 'Total loss': 0.7876817646526522}
2022-11-18 02:11:46,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:46,599 INFO:     Epoch: 99
2022-11-18 02:11:47,458 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7878573692657731, 'Total loss': 0.7878573692657731} | train loss {'Reaction outcome loss': 0.7802860214104576, 'Total loss': 0.7802860214104576}
2022-11-18 02:11:47,458 INFO:     Found new best model at epoch 99
2022-11-18 02:11:47,459 INFO:     Best model found after epoch 100 of 100.
2022-11-18 02:11:47,459 INFO:   Done with stage: TRAINING
2022-11-18 02:11:47,459 INFO:   Starting stage: EVALUATION
2022-11-18 02:11:47,578 INFO:   Done with stage: EVALUATION
2022-11-18 02:11:47,578 INFO:   Leaving out SEQ value Fold_8
2022-11-18 02:11:47,591 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 02:11:47,592 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:11:48,273 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:11:48,274 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:11:48,343 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:11:48,343 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:11:48,343 INFO:     No hyperparam tuning for this model
2022-11-18 02:11:48,343 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:11:48,343 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:11:48,344 INFO:     None feature selector for col prot
2022-11-18 02:11:48,344 INFO:     None feature selector for col prot
2022-11-18 02:11:48,344 INFO:     None feature selector for col prot
2022-11-18 02:11:48,345 INFO:     None feature selector for col chem
2022-11-18 02:11:48,345 INFO:     None feature selector for col chem
2022-11-18 02:11:48,345 INFO:     None feature selector for col chem
2022-11-18 02:11:48,345 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:11:48,345 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:11:48,347 INFO:     Number of params in model 168571
2022-11-18 02:11:48,350 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:11:48,350 INFO:   Starting stage: TRAINING
2022-11-18 02:11:48,408 INFO:     Val loss before train {'Reaction outcome loss': 0.9777518863027747, 'Total loss': 0.9777518863027747}
2022-11-18 02:11:48,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:48,409 INFO:     Epoch: 0
2022-11-18 02:11:49,213 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8317535086111589, 'Total loss': 0.8317535086111589} | train loss {'Reaction outcome loss': 0.8861313470669331, 'Total loss': 0.8861313470669331}
2022-11-18 02:11:49,213 INFO:     Found new best model at epoch 0
2022-11-18 02:11:49,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:49,214 INFO:     Epoch: 1
2022-11-18 02:11:50,025 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8657429733059623, 'Total loss': 0.8657429733059623} | train loss {'Reaction outcome loss': 0.8472018821104881, 'Total loss': 0.8472018821104881}
2022-11-18 02:11:50,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:50,025 INFO:     Epoch: 2
2022-11-18 02:11:50,834 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8349001549861648, 'Total loss': 0.8349001549861648} | train loss {'Reaction outcome loss': 0.8409105964726017, 'Total loss': 0.8409105964726017}
2022-11-18 02:11:50,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:50,834 INFO:     Epoch: 3
2022-11-18 02:11:51,635 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8339582830667496, 'Total loss': 0.8339582830667496} | train loss {'Reaction outcome loss': 0.8403190939176467, 'Total loss': 0.8403190939176467}
2022-11-18 02:11:51,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:51,635 INFO:     Epoch: 4
2022-11-18 02:11:52,423 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8242971192706715, 'Total loss': 0.8242971192706715} | train loss {'Reaction outcome loss': 0.8322537374352256, 'Total loss': 0.8322537374352256}
2022-11-18 02:11:52,423 INFO:     Found new best model at epoch 4
2022-11-18 02:11:52,424 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:52,424 INFO:     Epoch: 5
2022-11-18 02:11:53,276 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8128089660947974, 'Total loss': 0.8128089660947974} | train loss {'Reaction outcome loss': 0.8317301662698868, 'Total loss': 0.8317301662698868}
2022-11-18 02:11:53,277 INFO:     Found new best model at epoch 5
2022-11-18 02:11:53,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:53,277 INFO:     Epoch: 6
2022-11-18 02:11:54,124 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8201914443211122, 'Total loss': 0.8201914443211122} | train loss {'Reaction outcome loss': 0.826625736730714, 'Total loss': 0.826625736730714}
2022-11-18 02:11:54,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:54,125 INFO:     Epoch: 7
2022-11-18 02:11:54,901 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8156229799444025, 'Total loss': 0.8156229799444025} | train loss {'Reaction outcome loss': 0.8260761646013106, 'Total loss': 0.8260761646013106}
2022-11-18 02:11:54,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:54,901 INFO:     Epoch: 8
2022-11-18 02:11:55,683 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8151046173139052, 'Total loss': 0.8151046173139052} | train loss {'Reaction outcome loss': 0.8187680577318515, 'Total loss': 0.8187680577318515}
2022-11-18 02:11:55,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:55,683 INFO:     Epoch: 9
2022-11-18 02:11:56,480 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.819897937503728, 'Total loss': 0.819897937503728} | train loss {'Reaction outcome loss': 0.8228145963963001, 'Total loss': 0.8228145963963001}
2022-11-18 02:11:56,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:56,480 INFO:     Epoch: 10
2022-11-18 02:11:57,262 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8098636344075203, 'Total loss': 0.8098636344075203} | train loss {'Reaction outcome loss': 0.8229556625648853, 'Total loss': 0.8229556625648853}
2022-11-18 02:11:57,262 INFO:     Found new best model at epoch 10
2022-11-18 02:11:57,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:57,263 INFO:     Epoch: 11
2022-11-18 02:11:58,056 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8171355060555718, 'Total loss': 0.8171355060555718} | train loss {'Reaction outcome loss': 0.8179698974615143, 'Total loss': 0.8179698974615143}
2022-11-18 02:11:58,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:58,056 INFO:     Epoch: 12
2022-11-18 02:11:58,849 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8162300525741144, 'Total loss': 0.8162300525741144} | train loss {'Reaction outcome loss': 0.8238657214228184, 'Total loss': 0.8238657214228184}
2022-11-18 02:11:58,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:58,850 INFO:     Epoch: 13
2022-11-18 02:11:59,629 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8176386288621209, 'Total loss': 0.8176386288621209} | train loss {'Reaction outcome loss': 0.8233858115009723, 'Total loss': 0.8233858115009723}
2022-11-18 02:11:59,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:11:59,629 INFO:     Epoch: 14
2022-11-18 02:12:00,427 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8120598379861225, 'Total loss': 0.8120598379861225} | train loss {'Reaction outcome loss': 0.8210209913311466, 'Total loss': 0.8210209913311466}
2022-11-18 02:12:00,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:00,427 INFO:     Epoch: 15
2022-11-18 02:12:01,202 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8107556511055339, 'Total loss': 0.8107556511055339} | train loss {'Reaction outcome loss': 0.8218358826012381, 'Total loss': 0.8218358826012381}
2022-11-18 02:12:01,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:01,202 INFO:     Epoch: 16
2022-11-18 02:12:02,000 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8019626824693247, 'Total loss': 0.8019626824693247} | train loss {'Reaction outcome loss': 0.8215011114314679, 'Total loss': 0.8215011114314679}
2022-11-18 02:12:02,000 INFO:     Found new best model at epoch 16
2022-11-18 02:12:02,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:02,001 INFO:     Epoch: 17
2022-11-18 02:12:02,821 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8139884011311964, 'Total loss': 0.8139884011311964} | train loss {'Reaction outcome loss': 0.8153894249229662, 'Total loss': 0.8153894249229662}
2022-11-18 02:12:02,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:02,821 INFO:     Epoch: 18
2022-11-18 02:12:03,594 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8167521005327051, 'Total loss': 0.8167521005327051} | train loss {'Reaction outcome loss': 0.8197944077753252, 'Total loss': 0.8197944077753252}
2022-11-18 02:12:03,594 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:03,594 INFO:     Epoch: 19
2022-11-18 02:12:04,404 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8186448961496353, 'Total loss': 0.8186448961496353} | train loss {'Reaction outcome loss': 0.8195155454018423, 'Total loss': 0.8195155454018423}
2022-11-18 02:12:04,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:04,404 INFO:     Epoch: 20
2022-11-18 02:12:05,202 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8166598034175959, 'Total loss': 0.8166598034175959} | train loss {'Reaction outcome loss': 0.820751161945443, 'Total loss': 0.820751161945443}
2022-11-18 02:12:05,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:05,202 INFO:     Epoch: 21
2022-11-18 02:12:05,986 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8106998354196548, 'Total loss': 0.8106998354196548} | train loss {'Reaction outcome loss': 0.817491867729733, 'Total loss': 0.817491867729733}
2022-11-18 02:12:05,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:05,988 INFO:     Epoch: 22
2022-11-18 02:12:06,772 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8203672787005251, 'Total loss': 0.8203672787005251} | train loss {'Reaction outcome loss': 0.8136587183802358, 'Total loss': 0.8136587183802358}
2022-11-18 02:12:06,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:06,772 INFO:     Epoch: 23
2022-11-18 02:12:07,522 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8114661100235853, 'Total loss': 0.8114661100235853} | train loss {'Reaction outcome loss': 0.821775837170501, 'Total loss': 0.821775837170501}
2022-11-18 02:12:07,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:07,522 INFO:     Epoch: 24
2022-11-18 02:12:08,321 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8099945323033766, 'Total loss': 0.8099945323033766} | train loss {'Reaction outcome loss': 0.819591689254007, 'Total loss': 0.819591689254007}
2022-11-18 02:12:08,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:08,322 INFO:     Epoch: 25
2022-11-18 02:12:09,134 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8195191208611835, 'Total loss': 0.8195191208611835} | train loss {'Reaction outcome loss': 0.8214190537410397, 'Total loss': 0.8214190537410397}
2022-11-18 02:12:09,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:09,134 INFO:     Epoch: 26
2022-11-18 02:12:09,959 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8255678598176349, 'Total loss': 0.8255678598176349} | train loss {'Reaction outcome loss': 0.8152099752858761, 'Total loss': 0.8152099752858761}
2022-11-18 02:12:09,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:09,960 INFO:     Epoch: 27
2022-11-18 02:12:10,724 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8120835870504379, 'Total loss': 0.8120835870504379} | train loss {'Reaction outcome loss': 0.8172852363317243, 'Total loss': 0.8172852363317243}
2022-11-18 02:12:10,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:10,724 INFO:     Epoch: 28
2022-11-18 02:12:11,531 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8038448393344879, 'Total loss': 0.8038448393344879} | train loss {'Reaction outcome loss': 0.8157597567525602, 'Total loss': 0.8157597567525602}
2022-11-18 02:12:11,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:11,531 INFO:     Epoch: 29
2022-11-18 02:12:12,343 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.823038712143898, 'Total loss': 0.823038712143898} | train loss {'Reaction outcome loss': 0.8224507883912132, 'Total loss': 0.8224507883912132}
2022-11-18 02:12:12,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:12,344 INFO:     Epoch: 30
2022-11-18 02:12:13,134 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8344425084916028, 'Total loss': 0.8344425084916028} | train loss {'Reaction outcome loss': 0.8171296659857035, 'Total loss': 0.8171296659857035}
2022-11-18 02:12:13,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:13,134 INFO:     Epoch: 31
2022-11-18 02:12:13,911 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8049716841090809, 'Total loss': 0.8049716841090809} | train loss {'Reaction outcome loss': 0.82129047198161, 'Total loss': 0.82129047198161}
2022-11-18 02:12:13,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:13,912 INFO:     Epoch: 32
2022-11-18 02:12:14,706 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8129964409904047, 'Total loss': 0.8129964409904047} | train loss {'Reaction outcome loss': 0.8204417622858479, 'Total loss': 0.8204417622858479}
2022-11-18 02:12:14,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:14,707 INFO:     Epoch: 33
2022-11-18 02:12:15,514 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8382218026302077, 'Total loss': 0.8382218026302077} | train loss {'Reaction outcome loss': 0.8155733583675276, 'Total loss': 0.8155733583675276}
2022-11-18 02:12:15,514 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:15,514 INFO:     Epoch: 34
2022-11-18 02:12:16,292 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8048547391187061, 'Total loss': 0.8048547391187061} | train loss {'Reaction outcome loss': 0.8179016910012691, 'Total loss': 0.8179016910012691}
2022-11-18 02:12:16,292 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:16,292 INFO:     Epoch: 35
2022-11-18 02:12:17,075 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8129183771935377, 'Total loss': 0.8129183771935377} | train loss {'Reaction outcome loss': 0.8151902823198226, 'Total loss': 0.8151902823198226}
2022-11-18 02:12:17,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:17,076 INFO:     Epoch: 36
2022-11-18 02:12:17,881 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8199233168905432, 'Total loss': 0.8199233168905432} | train loss {'Reaction outcome loss': 0.8150530568053646, 'Total loss': 0.8150530568053646}
2022-11-18 02:12:17,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:17,881 INFO:     Epoch: 37
2022-11-18 02:12:18,676 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8039484416896646, 'Total loss': 0.8039484416896646} | train loss {'Reaction outcome loss': 0.8171310029443233, 'Total loss': 0.8171310029443233}
2022-11-18 02:12:18,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:18,676 INFO:     Epoch: 38
2022-11-18 02:12:19,450 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8010005246509205, 'Total loss': 0.8010005246509205} | train loss {'Reaction outcome loss': 0.8170806728303432, 'Total loss': 0.8170806728303432}
2022-11-18 02:12:19,450 INFO:     Found new best model at epoch 38
2022-11-18 02:12:19,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:19,451 INFO:     Epoch: 39
2022-11-18 02:12:20,225 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8013353469696912, 'Total loss': 0.8013353469696912} | train loss {'Reaction outcome loss': 0.8189945601888241, 'Total loss': 0.8189945601888241}
2022-11-18 02:12:20,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:20,225 INFO:     Epoch: 40
2022-11-18 02:12:21,020 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8137474493546919, 'Total loss': 0.8137474493546919} | train loss {'Reaction outcome loss': 0.8129340973832915, 'Total loss': 0.8129340973832915}
2022-11-18 02:12:21,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:21,020 INFO:     Epoch: 41
2022-11-18 02:12:21,798 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8188171725381505, 'Total loss': 0.8188171725381505} | train loss {'Reaction outcome loss': 0.8167178791857534, 'Total loss': 0.8167178791857534}
2022-11-18 02:12:21,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:21,798 INFO:     Epoch: 42
2022-11-18 02:12:22,578 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8091702325777574, 'Total loss': 0.8091702325777574} | train loss {'Reaction outcome loss': 0.8183413246466268, 'Total loss': 0.8183413246466268}
2022-11-18 02:12:22,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:22,578 INFO:     Epoch: 43
2022-11-18 02:12:23,357 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8112833655693314, 'Total loss': 0.8112833655693314} | train loss {'Reaction outcome loss': 0.8190382215524873, 'Total loss': 0.8190382215524873}
2022-11-18 02:12:23,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:23,357 INFO:     Epoch: 44
2022-11-18 02:12:24,153 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8130092133175243, 'Total loss': 0.8130092133175243} | train loss {'Reaction outcome loss': 0.8134213643929651, 'Total loss': 0.8134213643929651}
2022-11-18 02:12:24,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:24,153 INFO:     Epoch: 45
2022-11-18 02:12:24,930 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8089786835692145, 'Total loss': 0.8089786835692145} | train loss {'Reaction outcome loss': 0.8168651509669519, 'Total loss': 0.8168651509669519}
2022-11-18 02:12:24,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:24,931 INFO:     Epoch: 46
2022-11-18 02:12:25,702 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8154478106986393, 'Total loss': 0.8154478106986393} | train loss {'Reaction outcome loss': 0.8168931759653553, 'Total loss': 0.8168931759653553}
2022-11-18 02:12:25,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:25,702 INFO:     Epoch: 47
2022-11-18 02:12:26,481 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8177879615263506, 'Total loss': 0.8177879615263506} | train loss {'Reaction outcome loss': 0.8151709833933461, 'Total loss': 0.8151709833933461}
2022-11-18 02:12:26,481 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:26,481 INFO:     Epoch: 48
2022-11-18 02:12:27,265 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8134559745138342, 'Total loss': 0.8134559745138342} | train loss {'Reaction outcome loss': 0.8169272299255094, 'Total loss': 0.8169272299255094}
2022-11-18 02:12:27,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:27,265 INFO:     Epoch: 49
2022-11-18 02:12:28,048 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.803783195939931, 'Total loss': 0.803783195939931} | train loss {'Reaction outcome loss': 0.8168659242651155, 'Total loss': 0.8168659242651155}
2022-11-18 02:12:28,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:28,049 INFO:     Epoch: 50
2022-11-18 02:12:28,850 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8232752294702963, 'Total loss': 0.8232752294702963} | train loss {'Reaction outcome loss': 0.8163066159092611, 'Total loss': 0.8163066159092611}
2022-11-18 02:12:28,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:28,850 INFO:     Epoch: 51
2022-11-18 02:12:29,603 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.823472494428808, 'Total loss': 0.823472494428808} | train loss {'Reaction outcome loss': 0.8180181779448064, 'Total loss': 0.8180181779448064}
2022-11-18 02:12:29,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:29,604 INFO:     Epoch: 52
2022-11-18 02:12:30,389 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8523903516205874, 'Total loss': 0.8523903516205874} | train loss {'Reaction outcome loss': 0.8154390979438059, 'Total loss': 0.8154390979438059}
2022-11-18 02:12:30,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:30,389 INFO:     Epoch: 53
2022-11-18 02:12:31,196 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8077990412712097, 'Total loss': 0.8077990412712097} | train loss {'Reaction outcome loss': 0.8176249038548239, 'Total loss': 0.8176249038548239}
2022-11-18 02:12:31,197 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:31,197 INFO:     Epoch: 54
2022-11-18 02:12:31,981 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7976933412931182, 'Total loss': 0.7976933412931182} | train loss {'Reaction outcome loss': 0.8179608322679996, 'Total loss': 0.8179608322679996}
2022-11-18 02:12:31,981 INFO:     Found new best model at epoch 54
2022-11-18 02:12:31,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:31,982 INFO:     Epoch: 55
2022-11-18 02:12:32,764 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.813783199949698, 'Total loss': 0.813783199949698} | train loss {'Reaction outcome loss': 0.8117664496023809, 'Total loss': 0.8117664496023809}
2022-11-18 02:12:32,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:32,765 INFO:     Epoch: 56
2022-11-18 02:12:33,524 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8621505092490803, 'Total loss': 0.8621505092490803} | train loss {'Reaction outcome loss': 0.8158994506924383, 'Total loss': 0.8158994506924383}
2022-11-18 02:12:33,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:33,525 INFO:     Epoch: 57
2022-11-18 02:12:34,299 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.80536819181659, 'Total loss': 0.80536819181659} | train loss {'Reaction outcome loss': 0.8179162787573953, 'Total loss': 0.8179162787573953}
2022-11-18 02:12:34,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:34,300 INFO:     Epoch: 58
2022-11-18 02:12:35,070 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8082937571135435, 'Total loss': 0.8082937571135435} | train loss {'Reaction outcome loss': 0.8141566958398588, 'Total loss': 0.8141566958398588}
2022-11-18 02:12:35,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:35,071 INFO:     Epoch: 59
2022-11-18 02:12:35,857 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8168014911088076, 'Total loss': 0.8168014911088076} | train loss {'Reaction outcome loss': 0.8127382061173839, 'Total loss': 0.8127382061173839}
2022-11-18 02:12:35,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:35,857 INFO:     Epoch: 60
2022-11-18 02:12:36,653 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8232750296592712, 'Total loss': 0.8232750296592712} | train loss {'Reaction outcome loss': 0.8171144852474812, 'Total loss': 0.8171144852474812}
2022-11-18 02:12:36,654 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:36,654 INFO:     Epoch: 61
2022-11-18 02:12:37,433 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8302949870174582, 'Total loss': 0.8302949870174582} | train loss {'Reaction outcome loss': 0.8174959138756798, 'Total loss': 0.8174959138756798}
2022-11-18 02:12:37,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:37,434 INFO:     Epoch: 62
2022-11-18 02:12:38,200 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8165961896831339, 'Total loss': 0.8165961896831339} | train loss {'Reaction outcome loss': 0.8225261943955575, 'Total loss': 0.8225261943955575}
2022-11-18 02:12:38,201 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:38,201 INFO:     Epoch: 63
2022-11-18 02:12:39,000 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8080632679841735, 'Total loss': 0.8080632679841735} | train loss {'Reaction outcome loss': 0.8156884560181249, 'Total loss': 0.8156884560181249}
2022-11-18 02:12:39,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:39,000 INFO:     Epoch: 64
2022-11-18 02:12:39,778 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8100538917563178, 'Total loss': 0.8100538917563178} | train loss {'Reaction outcome loss': 0.8182203528140822, 'Total loss': 0.8182203528140822}
2022-11-18 02:12:39,778 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:39,778 INFO:     Epoch: 65
2022-11-18 02:12:40,578 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.82550203258341, 'Total loss': 0.82550203258341} | train loss {'Reaction outcome loss': 0.8118759838323439, 'Total loss': 0.8118759838323439}
2022-11-18 02:12:40,578 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:40,578 INFO:     Epoch: 66
2022-11-18 02:12:41,385 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8055836849591949, 'Total loss': 0.8055836849591949} | train loss {'Reaction outcome loss': 0.813953010545623, 'Total loss': 0.813953010545623}
2022-11-18 02:12:41,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:41,385 INFO:     Epoch: 67
2022-11-18 02:12:42,151 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8035087497396902, 'Total loss': 0.8035087497396902} | train loss {'Reaction outcome loss': 0.8178977502449867, 'Total loss': 0.8178977502449867}
2022-11-18 02:12:42,151 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:42,151 INFO:     Epoch: 68
2022-11-18 02:12:42,935 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8105798363685608, 'Total loss': 0.8105798363685608} | train loss {'Reaction outcome loss': 0.8166499498390383, 'Total loss': 0.8166499498390383}
2022-11-18 02:12:42,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:42,936 INFO:     Epoch: 69
2022-11-18 02:12:43,710 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8198260502381758, 'Total loss': 0.8198260502381758} | train loss {'Reaction outcome loss': 0.8162443383086112, 'Total loss': 0.8162443383086112}
2022-11-18 02:12:43,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:43,710 INFO:     Epoch: 70
2022-11-18 02:12:44,499 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8107512674548409, 'Total loss': 0.8107512674548409} | train loss {'Reaction outcome loss': 0.8193697345352942, 'Total loss': 0.8193697345352942}
2022-11-18 02:12:44,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:44,499 INFO:     Epoch: 71
2022-11-18 02:12:45,309 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8148649795488878, 'Total loss': 0.8148649795488878} | train loss {'Reaction outcome loss': 0.8151331682118678, 'Total loss': 0.8151331682118678}
2022-11-18 02:12:45,309 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:45,309 INFO:     Epoch: 72
2022-11-18 02:12:46,099 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.815548640083183, 'Total loss': 0.815548640083183} | train loss {'Reaction outcome loss': 0.814639090890846, 'Total loss': 0.814639090890846}
2022-11-18 02:12:46,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:46,099 INFO:     Epoch: 73
2022-11-18 02:12:46,868 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8076113570820201, 'Total loss': 0.8076113570820201} | train loss {'Reaction outcome loss': 0.8112864892088598, 'Total loss': 0.8112864892088598}
2022-11-18 02:12:46,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:46,869 INFO:     Epoch: 74
2022-11-18 02:12:47,675 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.819078039039265, 'Total loss': 0.819078039039265} | train loss {'Reaction outcome loss': 0.815216862987126, 'Total loss': 0.815216862987126}
2022-11-18 02:12:47,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:47,675 INFO:     Epoch: 75
2022-11-18 02:12:48,457 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8012579963965849, 'Total loss': 0.8012579963965849} | train loss {'Reaction outcome loss': 0.8127644876799276, 'Total loss': 0.8127644876799276}
2022-11-18 02:12:48,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:48,458 INFO:     Epoch: 76
2022-11-18 02:12:49,244 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8049188059839335, 'Total loss': 0.8049188059839335} | train loss {'Reaction outcome loss': 0.8146674116292307, 'Total loss': 0.8146674116292307}
2022-11-18 02:12:49,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:49,244 INFO:     Epoch: 77
2022-11-18 02:12:50,036 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8186613002961333, 'Total loss': 0.8186613002961333} | train loss {'Reaction outcome loss': 0.8144357753617149, 'Total loss': 0.8144357753617149}
2022-11-18 02:12:50,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:50,037 INFO:     Epoch: 78
2022-11-18 02:12:50,807 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8075469522313639, 'Total loss': 0.8075469522313639} | train loss {'Reaction outcome loss': 0.8085350173134958, 'Total loss': 0.8085350173134958}
2022-11-18 02:12:50,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:50,807 INFO:     Epoch: 79
2022-11-18 02:12:51,603 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.81438217244365, 'Total loss': 0.81438217244365} | train loss {'Reaction outcome loss': 0.815667693773585, 'Total loss': 0.815667693773585}
2022-11-18 02:12:51,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:51,603 INFO:     Epoch: 80
2022-11-18 02:12:52,407 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8064486303112723, 'Total loss': 0.8064486303112723} | train loss {'Reaction outcome loss': 0.811831213654049, 'Total loss': 0.811831213654049}
2022-11-18 02:12:52,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:52,408 INFO:     Epoch: 81
2022-11-18 02:12:53,200 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8311627019535411, 'Total loss': 0.8311627019535411} | train loss {'Reaction outcome loss': 0.8156753771247403, 'Total loss': 0.8156753771247403}
2022-11-18 02:12:53,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:53,200 INFO:     Epoch: 82
2022-11-18 02:12:53,978 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8177596012299712, 'Total loss': 0.8177596012299712} | train loss {'Reaction outcome loss': 0.8123341623333192, 'Total loss': 0.8123341623333192}
2022-11-18 02:12:53,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:53,978 INFO:     Epoch: 83
2022-11-18 02:12:54,788 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8276904773983088, 'Total loss': 0.8276904773983088} | train loss {'Reaction outcome loss': 0.8128037498963456, 'Total loss': 0.8128037498963456}
2022-11-18 02:12:54,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:54,788 INFO:     Epoch: 84
2022-11-18 02:12:55,582 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8049917349761183, 'Total loss': 0.8049917349761183} | train loss {'Reaction outcome loss': 0.8121557145589783, 'Total loss': 0.8121557145589783}
2022-11-18 02:12:55,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:55,583 INFO:     Epoch: 85
2022-11-18 02:12:56,390 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8114433139562607, 'Total loss': 0.8114433139562607} | train loss {'Reaction outcome loss': 0.8074760773489552, 'Total loss': 0.8074760773489552}
2022-11-18 02:12:56,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:56,390 INFO:     Epoch: 86
2022-11-18 02:12:57,181 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8098916099830107, 'Total loss': 0.8098916099830107} | train loss {'Reaction outcome loss': 0.812298080373195, 'Total loss': 0.812298080373195}
2022-11-18 02:12:57,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:57,181 INFO:     Epoch: 87
2022-11-18 02:12:57,971 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8074607544324615, 'Total loss': 0.8074607544324615} | train loss {'Reaction outcome loss': 0.8083655313859063, 'Total loss': 0.8083655313859063}
2022-11-18 02:12:57,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:57,972 INFO:     Epoch: 88
2022-11-18 02:12:58,770 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8055287667296149, 'Total loss': 0.8055287667296149} | train loss {'Reaction outcome loss': 0.8096821671652217, 'Total loss': 0.8096821671652217}
2022-11-18 02:12:58,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:58,770 INFO:     Epoch: 89
2022-11-18 02:12:59,532 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8203259022398428, 'Total loss': 0.8203259022398428} | train loss {'Reaction outcome loss': 0.8102395272543353, 'Total loss': 0.8102395272543353}
2022-11-18 02:12:59,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:12:59,532 INFO:     Epoch: 90
2022-11-18 02:13:00,313 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8284026465632699, 'Total loss': 0.8284026465632699} | train loss {'Reaction outcome loss': 0.810335966848558, 'Total loss': 0.810335966848558}
2022-11-18 02:13:00,313 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:00,313 INFO:     Epoch: 91
2022-11-18 02:13:01,080 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8148915727030147, 'Total loss': 0.8148915727030147} | train loss {'Reaction outcome loss': 0.8127876841012509, 'Total loss': 0.8127876841012509}
2022-11-18 02:13:01,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:01,081 INFO:     Epoch: 92
2022-11-18 02:13:01,864 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8153159347447482, 'Total loss': 0.8153159347447482} | train loss {'Reaction outcome loss': 0.8148338991788125, 'Total loss': 0.8148338991788125}
2022-11-18 02:13:01,864 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:01,864 INFO:     Epoch: 93
2022-11-18 02:13:02,650 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.830063788050955, 'Total loss': 0.830063788050955} | train loss {'Reaction outcome loss': 0.8124128870906369, 'Total loss': 0.8124128870906369}
2022-11-18 02:13:02,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:02,651 INFO:     Epoch: 94
2022-11-18 02:13:03,427 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8034811229868368, 'Total loss': 0.8034811229868368} | train loss {'Reaction outcome loss': 0.8166413470622031, 'Total loss': 0.8166413470622031}
2022-11-18 02:13:03,427 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:03,427 INFO:     Epoch: 95
2022-11-18 02:13:04,179 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7976678386330605, 'Total loss': 0.7976678386330605} | train loss {'Reaction outcome loss': 0.8109951044522947, 'Total loss': 0.8109951044522947}
2022-11-18 02:13:04,179 INFO:     Found new best model at epoch 95
2022-11-18 02:13:04,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:04,180 INFO:     Epoch: 96
2022-11-18 02:13:04,985 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8141429221088236, 'Total loss': 0.8141429221088236} | train loss {'Reaction outcome loss': 0.8173087348620738, 'Total loss': 0.8173087348620738}
2022-11-18 02:13:04,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:04,985 INFO:     Epoch: 97
2022-11-18 02:13:05,775 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8031553978269751, 'Total loss': 0.8031553978269751} | train loss {'Reaction outcome loss': 0.8109941284262365, 'Total loss': 0.8109941284262365}
2022-11-18 02:13:05,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:05,775 INFO:     Epoch: 98
2022-11-18 02:13:06,559 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8053789883852005, 'Total loss': 0.8053789883852005} | train loss {'Reaction outcome loss': 0.8080084901903907, 'Total loss': 0.8080084901903907}
2022-11-18 02:13:06,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:06,559 INFO:     Epoch: 99
2022-11-18 02:13:07,346 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8090249354189093, 'Total loss': 0.8090249354189093} | train loss {'Reaction outcome loss': 0.8137322511644133, 'Total loss': 0.8137322511644133}
2022-11-18 02:13:07,346 INFO:     Best model found after epoch 96 of 100.
2022-11-18 02:13:07,346 INFO:   Done with stage: TRAINING
2022-11-18 02:13:07,347 INFO:   Starting stage: EVALUATION
2022-11-18 02:13:07,470 INFO:   Done with stage: EVALUATION
2022-11-18 02:13:07,470 INFO:   Leaving out SEQ value Fold_9
2022-11-18 02:13:07,483 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 02:13:07,483 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:13:08,147 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:13:08,148 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:13:08,220 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:13:08,221 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:13:08,221 INFO:     No hyperparam tuning for this model
2022-11-18 02:13:08,221 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:13:08,221 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:13:08,222 INFO:     None feature selector for col prot
2022-11-18 02:13:08,222 INFO:     None feature selector for col prot
2022-11-18 02:13:08,222 INFO:     None feature selector for col prot
2022-11-18 02:13:08,222 INFO:     None feature selector for col chem
2022-11-18 02:13:08,223 INFO:     None feature selector for col chem
2022-11-18 02:13:08,223 INFO:     None feature selector for col chem
2022-11-18 02:13:08,223 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:13:08,223 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:13:08,224 INFO:     Number of params in model 168571
2022-11-18 02:13:08,228 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:13:08,228 INFO:   Starting stage: TRAINING
2022-11-18 02:13:08,285 INFO:     Val loss before train {'Reaction outcome loss': 1.0440617691386829, 'Total loss': 1.0440617691386829}
2022-11-18 02:13:08,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:08,285 INFO:     Epoch: 0
2022-11-18 02:13:09,058 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8543501591140573, 'Total loss': 0.8543501591140573} | train loss {'Reaction outcome loss': 0.868526355344422, 'Total loss': 0.868526355344422}
2022-11-18 02:13:09,058 INFO:     Found new best model at epoch 0
2022-11-18 02:13:09,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:09,059 INFO:     Epoch: 1
2022-11-18 02:13:09,814 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.838632507757707, 'Total loss': 0.838632507757707} | train loss {'Reaction outcome loss': 0.8321424259214986, 'Total loss': 0.8321424259214986}
2022-11-18 02:13:09,814 INFO:     Found new best model at epoch 1
2022-11-18 02:13:09,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:09,815 INFO:     Epoch: 2
2022-11-18 02:13:10,584 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8507511277090419, 'Total loss': 0.8507511277090419} | train loss {'Reaction outcome loss': 0.8294234071459089, 'Total loss': 0.8294234071459089}
2022-11-18 02:13:10,584 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:10,584 INFO:     Epoch: 3
2022-11-18 02:13:11,380 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8403990742835131, 'Total loss': 0.8403990742835131} | train loss {'Reaction outcome loss': 0.8219874614355516, 'Total loss': 0.8219874614355516}
2022-11-18 02:13:11,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:11,380 INFO:     Epoch: 4
2022-11-18 02:13:12,160 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8379209854386069, 'Total loss': 0.8379209854386069} | train loss {'Reaction outcome loss': 0.8181995419823394, 'Total loss': 0.8181995419823394}
2022-11-18 02:13:12,160 INFO:     Found new best model at epoch 4
2022-11-18 02:13:12,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:12,161 INFO:     Epoch: 5
2022-11-18 02:13:12,961 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8778756396336989, 'Total loss': 0.8778756396336989} | train loss {'Reaction outcome loss': 0.8176303490084045, 'Total loss': 0.8176303490084045}
2022-11-18 02:13:12,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:12,961 INFO:     Epoch: 6
2022-11-18 02:13:13,740 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8403549302708019, 'Total loss': 0.8403549302708019} | train loss {'Reaction outcome loss': 0.8135195525325074, 'Total loss': 0.8135195525325074}
2022-11-18 02:13:13,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:13,740 INFO:     Epoch: 7
2022-11-18 02:13:14,503 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8359962600198659, 'Total loss': 0.8359962600198659} | train loss {'Reaction outcome loss': 0.816959986029839, 'Total loss': 0.816959986029839}
2022-11-18 02:13:14,504 INFO:     Found new best model at epoch 7
2022-11-18 02:13:14,505 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:14,505 INFO:     Epoch: 8
2022-11-18 02:13:15,263 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8549479395151138, 'Total loss': 0.8549479395151138} | train loss {'Reaction outcome loss': 0.8086714667933328, 'Total loss': 0.8086714667933328}
2022-11-18 02:13:15,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:15,263 INFO:     Epoch: 9
2022-11-18 02:13:16,051 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8396307175809686, 'Total loss': 0.8396307175809686} | train loss {'Reaction outcome loss': 0.8048441638751905, 'Total loss': 0.8048441638751905}
2022-11-18 02:13:16,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:16,052 INFO:     Epoch: 10
2022-11-18 02:13:16,803 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8541083322329954, 'Total loss': 0.8541083322329954} | train loss {'Reaction outcome loss': 0.8074036180973053, 'Total loss': 0.8074036180973053}
2022-11-18 02:13:16,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:16,803 INFO:     Epoch: 11
2022-11-18 02:13:17,583 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8715776415033774, 'Total loss': 0.8715776415033774} | train loss {'Reaction outcome loss': 0.8054143437317439, 'Total loss': 0.8054143437317439}
2022-11-18 02:13:17,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:17,583 INFO:     Epoch: 12
2022-11-18 02:13:18,379 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8617940985343673, 'Total loss': 0.8617940985343673} | train loss {'Reaction outcome loss': 0.8043333933061483, 'Total loss': 0.8043333933061483}
2022-11-18 02:13:18,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:18,380 INFO:     Epoch: 13
2022-11-18 02:13:19,162 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8545179218053818, 'Total loss': 0.8545179218053818} | train loss {'Reaction outcome loss': 0.8066875056344636, 'Total loss': 0.8066875056344636}
2022-11-18 02:13:19,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:19,162 INFO:     Epoch: 14
2022-11-18 02:13:19,921 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8650419251485304, 'Total loss': 0.8650419251485304} | train loss {'Reaction outcome loss': 0.804426997778367, 'Total loss': 0.804426997778367}
2022-11-18 02:13:19,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:19,921 INFO:     Epoch: 15
2022-11-18 02:13:20,730 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8534057451920076, 'Total loss': 0.8534057451920076} | train loss {'Reaction outcome loss': 0.8052451677468359, 'Total loss': 0.8052451677468359}
2022-11-18 02:13:20,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:20,730 INFO:     Epoch: 16
2022-11-18 02:13:21,545 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8392978283492002, 'Total loss': 0.8392978283492002} | train loss {'Reaction outcome loss': 0.8033449411392212, 'Total loss': 0.8033449411392212}
2022-11-18 02:13:21,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:21,545 INFO:     Epoch: 17
2022-11-18 02:13:22,349 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8616001213138754, 'Total loss': 0.8616001213138754} | train loss {'Reaction outcome loss': 0.8015423205434059, 'Total loss': 0.8015423205434059}
2022-11-18 02:13:22,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:22,349 INFO:     Epoch: 18
2022-11-18 02:13:23,167 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8494008285078135, 'Total loss': 0.8494008285078135} | train loss {'Reaction outcome loss': 0.8074697201349297, 'Total loss': 0.8074697201349297}
2022-11-18 02:13:23,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:23,168 INFO:     Epoch: 19
2022-11-18 02:13:23,974 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8371804187243636, 'Total loss': 0.8371804187243636} | train loss {'Reaction outcome loss': 0.8015502715597347, 'Total loss': 0.8015502715597347}
2022-11-18 02:13:23,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:23,974 INFO:     Epoch: 20
2022-11-18 02:13:24,798 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8650988326831297, 'Total loss': 0.8650988326831297} | train loss {'Reaction outcome loss': 0.8040013010404548, 'Total loss': 0.8040013010404548}
2022-11-18 02:13:24,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:24,799 INFO:     Epoch: 21
2022-11-18 02:13:25,602 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8276177360252901, 'Total loss': 0.8276177360252901} | train loss {'Reaction outcome loss': 0.8001184051134148, 'Total loss': 0.8001184051134148}
2022-11-18 02:13:25,602 INFO:     Found new best model at epoch 21
2022-11-18 02:13:25,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:25,603 INFO:     Epoch: 22
2022-11-18 02:13:26,405 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8604204783385451, 'Total loss': 0.8604204783385451} | train loss {'Reaction outcome loss': 0.7998886335869224, 'Total loss': 0.7998886335869224}
2022-11-18 02:13:26,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:26,405 INFO:     Epoch: 23
2022-11-18 02:13:27,174 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8291948952458121, 'Total loss': 0.8291948952458121} | train loss {'Reaction outcome loss': 0.8029294950621468, 'Total loss': 0.8029294950621468}
2022-11-18 02:13:27,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:27,176 INFO:     Epoch: 24
2022-11-18 02:13:28,008 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8738388859412887, 'Total loss': 0.8738388859412887} | train loss {'Reaction outcome loss': 0.8045217415507959, 'Total loss': 0.8045217415507959}
2022-11-18 02:13:28,008 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:28,008 INFO:     Epoch: 25
2022-11-18 02:13:28,838 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8317956369031559, 'Total loss': 0.8317956369031559} | train loss {'Reaction outcome loss': 0.7977860245169426, 'Total loss': 0.7977860245169426}
2022-11-18 02:13:28,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:28,838 INFO:     Epoch: 26
2022-11-18 02:13:29,640 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8277913196520372, 'Total loss': 0.8277913196520372} | train loss {'Reaction outcome loss': 0.8024429963559521, 'Total loss': 0.8024429963559521}
2022-11-18 02:13:29,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:29,641 INFO:     Epoch: 27
2022-11-18 02:13:30,411 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8319249579852278, 'Total loss': 0.8319249579852278} | train loss {'Reaction outcome loss': 0.7989715446014793, 'Total loss': 0.7989715446014793}
2022-11-18 02:13:30,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:30,412 INFO:     Epoch: 28
2022-11-18 02:13:31,198 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8356431329792197, 'Total loss': 0.8356431329792197} | train loss {'Reaction outcome loss': 0.8076884869410067, 'Total loss': 0.8076884869410067}
2022-11-18 02:13:31,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:31,198 INFO:     Epoch: 29
2022-11-18 02:13:32,018 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8366066501899199, 'Total loss': 0.8366066501899199} | train loss {'Reaction outcome loss': 0.802202220717255, 'Total loss': 0.802202220717255}
2022-11-18 02:13:32,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:32,018 INFO:     Epoch: 30
2022-11-18 02:13:32,816 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8413274044340308, 'Total loss': 0.8413274044340308} | train loss {'Reaction outcome loss': 0.800265419726469, 'Total loss': 0.800265419726469}
2022-11-18 02:13:32,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:32,816 INFO:     Epoch: 31
2022-11-18 02:13:33,636 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8532676276835528, 'Total loss': 0.8532676276835528} | train loss {'Reaction outcome loss': 0.8015448156668216, 'Total loss': 0.8015448156668216}
2022-11-18 02:13:33,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:33,636 INFO:     Epoch: 32
2022-11-18 02:13:34,433 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.847818486392498, 'Total loss': 0.847818486392498} | train loss {'Reaction outcome loss': 0.796337663275855, 'Total loss': 0.796337663275855}
2022-11-18 02:13:34,433 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:34,433 INFO:     Epoch: 33
2022-11-18 02:13:35,227 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.847264979373325, 'Total loss': 0.847264979373325} | train loss {'Reaction outcome loss': 0.7972874632903508, 'Total loss': 0.7972874632903508}
2022-11-18 02:13:35,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:35,227 INFO:     Epoch: 34
2022-11-18 02:13:35,984 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8495127714493058, 'Total loss': 0.8495127714493058} | train loss {'Reaction outcome loss': 0.8043024151909108, 'Total loss': 0.8043024151909108}
2022-11-18 02:13:35,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:35,985 INFO:     Epoch: 35
2022-11-18 02:13:36,768 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8376848860220476, 'Total loss': 0.8376848860220476} | train loss {'Reaction outcome loss': 0.7981003566664092, 'Total loss': 0.7981003566664092}
2022-11-18 02:13:36,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:36,768 INFO:     Epoch: 36
2022-11-18 02:13:37,571 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8777335753495042, 'Total loss': 0.8777335753495042} | train loss {'Reaction outcome loss': 0.801413826553189, 'Total loss': 0.801413826553189}
2022-11-18 02:13:37,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:37,572 INFO:     Epoch: 37
2022-11-18 02:13:38,397 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8293552432547916, 'Total loss': 0.8293552432547916} | train loss {'Reaction outcome loss': 0.7996436945029668, 'Total loss': 0.7996436945029668}
2022-11-18 02:13:38,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:38,398 INFO:     Epoch: 38
2022-11-18 02:13:39,189 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8463287949562073, 'Total loss': 0.8463287949562073} | train loss {'Reaction outcome loss': 0.8015837962530097, 'Total loss': 0.8015837962530097}
2022-11-18 02:13:39,189 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:39,189 INFO:     Epoch: 39
2022-11-18 02:13:39,984 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8720384565266696, 'Total loss': 0.8720384565266696} | train loss {'Reaction outcome loss': 0.797892301301567, 'Total loss': 0.797892301301567}
2022-11-18 02:13:39,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:39,986 INFO:     Epoch: 40
2022-11-18 02:13:40,769 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8710480237549002, 'Total loss': 0.8710480237549002} | train loss {'Reaction outcome loss': 0.7984611646253236, 'Total loss': 0.7984611646253236}
2022-11-18 02:13:40,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:40,769 INFO:     Epoch: 41
2022-11-18 02:13:41,570 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8556008826602589, 'Total loss': 0.8556008826602589} | train loss {'Reaction outcome loss': 0.8012235294799416, 'Total loss': 0.8012235294799416}
2022-11-18 02:13:41,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:41,570 INFO:     Epoch: 42
2022-11-18 02:13:42,353 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8511209447275508, 'Total loss': 0.8511209447275508} | train loss {'Reaction outcome loss': 0.7994646420284194, 'Total loss': 0.7994646420284194}
2022-11-18 02:13:42,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:42,353 INFO:     Epoch: 43
2022-11-18 02:13:43,162 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8534905300898985, 'Total loss': 0.8534905300898985} | train loss {'Reaction outcome loss': 0.795984060666999, 'Total loss': 0.795984060666999}
2022-11-18 02:13:43,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:43,162 INFO:     Epoch: 44
2022-11-18 02:13:43,919 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8439141830260103, 'Total loss': 0.8439141830260103} | train loss {'Reaction outcome loss': 0.7934885263442993, 'Total loss': 0.7934885263442993}
2022-11-18 02:13:43,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:43,919 INFO:     Epoch: 45
2022-11-18 02:13:44,698 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.830481388352134, 'Total loss': 0.830481388352134} | train loss {'Reaction outcome loss': 0.8000200126852308, 'Total loss': 0.8000200126852308}
2022-11-18 02:13:44,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:44,698 INFO:     Epoch: 46
2022-11-18 02:13:45,486 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8406798636371439, 'Total loss': 0.8406798636371439} | train loss {'Reaction outcome loss': 0.798918434551784, 'Total loss': 0.798918434551784}
2022-11-18 02:13:45,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:45,486 INFO:     Epoch: 47
2022-11-18 02:13:46,251 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8479420664635572, 'Total loss': 0.8479420664635572} | train loss {'Reaction outcome loss': 0.7983314644317238, 'Total loss': 0.7983314644317238}
2022-11-18 02:13:46,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:46,252 INFO:     Epoch: 48
2022-11-18 02:13:47,047 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8356693861159411, 'Total loss': 0.8356693861159411} | train loss {'Reaction outcome loss': 0.8011260701685535, 'Total loss': 0.8011260701685535}
2022-11-18 02:13:47,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:47,048 INFO:     Epoch: 49
2022-11-18 02:13:47,832 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8376269272782586, 'Total loss': 0.8376269272782586} | train loss {'Reaction outcome loss': 0.8011916335748166, 'Total loss': 0.8011916335748166}
2022-11-18 02:13:47,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:47,832 INFO:     Epoch: 50
2022-11-18 02:13:48,634 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8299106440760873, 'Total loss': 0.8299106440760873} | train loss {'Reaction outcome loss': 0.7968709193930335, 'Total loss': 0.7968709193930335}
2022-11-18 02:13:48,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:48,635 INFO:     Epoch: 51
2022-11-18 02:13:49,398 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8342772871255875, 'Total loss': 0.8342772871255875} | train loss {'Reaction outcome loss': 0.7960575792254234, 'Total loss': 0.7960575792254234}
2022-11-18 02:13:49,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:49,399 INFO:     Epoch: 52
2022-11-18 02:13:50,181 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8291479789397933, 'Total loss': 0.8291479789397933} | train loss {'Reaction outcome loss': 0.7991926246759843, 'Total loss': 0.7991926246759843}
2022-11-18 02:13:50,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:50,181 INFO:     Epoch: 53
2022-11-18 02:13:50,943 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8483718789436601, 'Total loss': 0.8483718789436601} | train loss {'Reaction outcome loss': 0.7999837551798139, 'Total loss': 0.7999837551798139}
2022-11-18 02:13:50,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:50,943 INFO:     Epoch: 54
2022-11-18 02:13:51,712 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8380708545446396, 'Total loss': 0.8380708545446396} | train loss {'Reaction outcome loss': 0.800409390123523, 'Total loss': 0.800409390123523}
2022-11-18 02:13:51,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:51,713 INFO:     Epoch: 55
2022-11-18 02:13:52,492 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8438542390411551, 'Total loss': 0.8438542390411551} | train loss {'Reaction outcome loss': 0.7975492148983235, 'Total loss': 0.7975492148983235}
2022-11-18 02:13:52,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:52,493 INFO:     Epoch: 56
2022-11-18 02:13:53,272 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8502408950166269, 'Total loss': 0.8502408950166269} | train loss {'Reaction outcome loss': 0.7962613066848443, 'Total loss': 0.7962613066848443}
2022-11-18 02:13:53,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:53,272 INFO:     Epoch: 57
2022-11-18 02:13:54,056 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8424108936028047, 'Total loss': 0.8424108936028047} | train loss {'Reaction outcome loss': 0.8011635118601274, 'Total loss': 0.8011635118601274}
2022-11-18 02:13:54,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:54,056 INFO:     Epoch: 58
2022-11-18 02:13:54,835 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8584710576317527, 'Total loss': 0.8584710576317527} | train loss {'Reaction outcome loss': 0.7972785787922996, 'Total loss': 0.7972785787922996}
2022-11-18 02:13:54,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:54,836 INFO:     Epoch: 59
2022-11-18 02:13:55,606 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8378916010260582, 'Total loss': 0.8378916010260582} | train loss {'Reaction outcome loss': 0.7961364075845602, 'Total loss': 0.7961364075845602}
2022-11-18 02:13:55,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:55,607 INFO:     Epoch: 60
2022-11-18 02:13:56,402 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8326488204977729, 'Total loss': 0.8326488204977729} | train loss {'Reaction outcome loss': 0.8026518753596714, 'Total loss': 0.8026518753596714}
2022-11-18 02:13:56,402 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:56,402 INFO:     Epoch: 61
2022-11-18 02:13:57,164 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8400664729150858, 'Total loss': 0.8400664729150858} | train loss {'Reaction outcome loss': 0.7982869114194597, 'Total loss': 0.7982869114194597}
2022-11-18 02:13:57,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:57,164 INFO:     Epoch: 62
2022-11-18 02:13:57,962 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8580391813408245, 'Total loss': 0.8580391813408245} | train loss {'Reaction outcome loss': 0.7949889974934714, 'Total loss': 0.7949889974934714}
2022-11-18 02:13:57,962 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:57,962 INFO:     Epoch: 63
2022-11-18 02:13:58,766 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8156471597877416, 'Total loss': 0.8156471597877416} | train loss {'Reaction outcome loss': 0.7954096965643824, 'Total loss': 0.7954096965643824}
2022-11-18 02:13:58,767 INFO:     Found new best model at epoch 63
2022-11-18 02:13:58,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:58,768 INFO:     Epoch: 64
2022-11-18 02:13:59,569 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8268617432225834, 'Total loss': 0.8268617432225834} | train loss {'Reaction outcome loss': 0.7987871159096154, 'Total loss': 0.7987871159096154}
2022-11-18 02:13:59,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:13:59,569 INFO:     Epoch: 65
2022-11-18 02:14:00,361 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8153322515162554, 'Total loss': 0.8153322515162554} | train loss {'Reaction outcome loss': 0.7955017320963801, 'Total loss': 0.7955017320963801}
2022-11-18 02:14:00,361 INFO:     Found new best model at epoch 65
2022-11-18 02:14:00,362 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:00,362 INFO:     Epoch: 66
2022-11-18 02:14:01,140 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8385503739118576, 'Total loss': 0.8385503739118576} | train loss {'Reaction outcome loss': 0.795951298791535, 'Total loss': 0.795951298791535}
2022-11-18 02:14:01,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:01,140 INFO:     Epoch: 67
2022-11-18 02:14:01,933 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8203846385533159, 'Total loss': 0.8203846385533159} | train loss {'Reaction outcome loss': 0.7981462524861705, 'Total loss': 0.7981462524861705}
2022-11-18 02:14:01,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:01,934 INFO:     Epoch: 68
2022-11-18 02:14:02,728 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8433030085130171, 'Total loss': 0.8433030085130171} | train loss {'Reaction outcome loss': 0.798974117089291, 'Total loss': 0.798974117089291}
2022-11-18 02:14:02,728 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:02,728 INFO:     Epoch: 69
2022-11-18 02:14:03,499 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.847628921947696, 'Total loss': 0.847628921947696} | train loss {'Reaction outcome loss': 0.7953826676826088, 'Total loss': 0.7953826676826088}
2022-11-18 02:14:03,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:03,499 INFO:     Epoch: 70
2022-11-18 02:14:04,271 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8277105059136044, 'Total loss': 0.8277105059136044} | train loss {'Reaction outcome loss': 0.7957057008937913, 'Total loss': 0.7957057008937913}
2022-11-18 02:14:04,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:04,272 INFO:     Epoch: 71
2022-11-18 02:14:05,085 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8347836638038809, 'Total loss': 0.8347836638038809} | train loss {'Reaction outcome loss': 0.7991183071720357, 'Total loss': 0.7991183071720357}
2022-11-18 02:14:05,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:05,086 INFO:     Epoch: 72
2022-11-18 02:14:05,875 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8169498795812781, 'Total loss': 0.8169498795812781} | train loss {'Reaction outcome loss': 0.7918353597728574, 'Total loss': 0.7918353597728574}
2022-11-18 02:14:05,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:05,875 INFO:     Epoch: 73
2022-11-18 02:14:06,663 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8270450559529391, 'Total loss': 0.8270450559529391} | train loss {'Reaction outcome loss': 0.8005746247817059, 'Total loss': 0.8005746247817059}
2022-11-18 02:14:06,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:06,663 INFO:     Epoch: 74
2022-11-18 02:14:07,432 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.856440311128443, 'Total loss': 0.856440311128443} | train loss {'Reaction outcome loss': 0.7967549886022295, 'Total loss': 0.7967549886022295}
2022-11-18 02:14:07,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:07,432 INFO:     Epoch: 75
2022-11-18 02:14:08,203 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8491602160713889, 'Total loss': 0.8491602160713889} | train loss {'Reaction outcome loss': 0.8002572914775536, 'Total loss': 0.8002572914775536}
2022-11-18 02:14:08,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:08,203 INFO:     Epoch: 76
2022-11-18 02:14:08,997 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8246752822941, 'Total loss': 0.8246752822941} | train loss {'Reaction outcome loss': 0.7942945375734446, 'Total loss': 0.7942945375734446}
2022-11-18 02:14:08,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:08,997 INFO:     Epoch: 77
2022-11-18 02:14:09,758 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8147243877703493, 'Total loss': 0.8147243877703493} | train loss {'Reaction outcome loss': 0.7979564972069799, 'Total loss': 0.7979564972069799}
2022-11-18 02:14:09,758 INFO:     Found new best model at epoch 77
2022-11-18 02:14:09,759 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:09,759 INFO:     Epoch: 78
2022-11-18 02:14:10,546 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8592465973713181, 'Total loss': 0.8592465973713181} | train loss {'Reaction outcome loss': 0.7951758692459184, 'Total loss': 0.7951758692459184}
2022-11-18 02:14:10,547 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:10,547 INFO:     Epoch: 79
2022-11-18 02:14:11,325 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8558577468449419, 'Total loss': 0.8558577468449419} | train loss {'Reaction outcome loss': 0.7915152013301849, 'Total loss': 0.7915152013301849}
2022-11-18 02:14:11,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:11,326 INFO:     Epoch: 80
2022-11-18 02:14:12,095 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8423757268623873, 'Total loss': 0.8423757268623873} | train loss {'Reaction outcome loss': 0.7990317956525452, 'Total loss': 0.7990317956525452}
2022-11-18 02:14:12,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:12,095 INFO:     Epoch: 81
2022-11-18 02:14:12,879 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8459828705950216, 'Total loss': 0.8459828705950216} | train loss {'Reaction outcome loss': 0.7999481122104489, 'Total loss': 0.7999481122104489}
2022-11-18 02:14:12,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:12,880 INFO:     Epoch: 82
2022-11-18 02:14:13,646 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8382328606464646, 'Total loss': 0.8382328606464646} | train loss {'Reaction outcome loss': 0.7939517696293033, 'Total loss': 0.7939517696293033}
2022-11-18 02:14:13,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:13,646 INFO:     Epoch: 83
2022-11-18 02:14:14,390 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8523128181695938, 'Total loss': 0.8523128181695938} | train loss {'Reaction outcome loss': 0.7971105564613732, 'Total loss': 0.7971105564613732}
2022-11-18 02:14:14,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:14,390 INFO:     Epoch: 84
2022-11-18 02:14:15,164 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8291134847836061, 'Total loss': 0.8291134847836061} | train loss {'Reaction outcome loss': 0.7991203919965394, 'Total loss': 0.7991203919965394}
2022-11-18 02:14:15,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:15,164 INFO:     Epoch: 85
2022-11-18 02:14:15,925 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8440425985238769, 'Total loss': 0.8440425985238769} | train loss {'Reaction outcome loss': 0.7962445200706015, 'Total loss': 0.7962445200706015}
2022-11-18 02:14:15,925 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:15,925 INFO:     Epoch: 86
2022-11-18 02:14:16,718 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8929469626058232, 'Total loss': 0.8929469626058232} | train loss {'Reaction outcome loss': 0.7973692754093482, 'Total loss': 0.7973692754093482}
2022-11-18 02:14:16,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:16,718 INFO:     Epoch: 87
2022-11-18 02:14:17,502 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8344298858534206, 'Total loss': 0.8344298858534206} | train loss {'Reaction outcome loss': 0.7982854650945079, 'Total loss': 0.7982854650945079}
2022-11-18 02:14:17,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:17,503 INFO:     Epoch: 88
2022-11-18 02:14:18,323 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8636086352846839, 'Total loss': 0.8636086352846839} | train loss {'Reaction outcome loss': 0.799235126315331, 'Total loss': 0.799235126315331}
2022-11-18 02:14:18,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:18,323 INFO:     Epoch: 89
2022-11-18 02:14:19,119 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8482034043832258, 'Total loss': 0.8482034043832258} | train loss {'Reaction outcome loss': 0.7963248754034237, 'Total loss': 0.7963248754034237}
2022-11-18 02:14:19,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:19,120 INFO:     Epoch: 90
2022-11-18 02:14:19,902 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8375955108891834, 'Total loss': 0.8375955108891834} | train loss {'Reaction outcome loss': 0.792373719385692, 'Total loss': 0.792373719385692}
2022-11-18 02:14:19,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:19,903 INFO:     Epoch: 91
2022-11-18 02:14:20,669 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8329299207438122, 'Total loss': 0.8329299207438122} | train loss {'Reaction outcome loss': 0.7980189098387348, 'Total loss': 0.7980189098387348}
2022-11-18 02:14:20,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:20,669 INFO:     Epoch: 92
2022-11-18 02:14:21,482 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8341605588793755, 'Total loss': 0.8341605588793755} | train loss {'Reaction outcome loss': 0.7936514361780517, 'Total loss': 0.7936514361780517}
2022-11-18 02:14:21,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:21,483 INFO:     Epoch: 93
2022-11-18 02:14:22,281 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.840376765890555, 'Total loss': 0.840376765890555} | train loss {'Reaction outcome loss': 0.8013322456758849, 'Total loss': 0.8013322456758849}
2022-11-18 02:14:22,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:22,282 INFO:     Epoch: 94
2022-11-18 02:14:23,079 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8281799493865534, 'Total loss': 0.8281799493865534} | train loss {'Reaction outcome loss': 0.7985274226081615, 'Total loss': 0.7985274226081615}
2022-11-18 02:14:23,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:23,079 INFO:     Epoch: 95
2022-11-18 02:14:23,851 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8449400934306058, 'Total loss': 0.8449400934306058} | train loss {'Reaction outcome loss': 0.799559542962483, 'Total loss': 0.799559542962483}
2022-11-18 02:14:23,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:23,851 INFO:     Epoch: 96
2022-11-18 02:14:24,632 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8569402545690536, 'Total loss': 0.8569402545690536} | train loss {'Reaction outcome loss': 0.7984031644402718, 'Total loss': 0.7984031644402718}
2022-11-18 02:14:24,632 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:24,632 INFO:     Epoch: 97
2022-11-18 02:14:25,464 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8319800821217623, 'Total loss': 0.8319800821217623} | train loss {'Reaction outcome loss': 0.7918221631828619, 'Total loss': 0.7918221631828619}
2022-11-18 02:14:25,464 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:25,464 INFO:     Epoch: 98
2022-11-18 02:14:26,293 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.853821720589291, 'Total loss': 0.853821720589291} | train loss {'Reaction outcome loss': 0.7984011417748976, 'Total loss': 0.7984011417748976}
2022-11-18 02:14:26,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:26,293 INFO:     Epoch: 99
2022-11-18 02:14:27,113 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8417604274370454, 'Total loss': 0.8417604274370454} | train loss {'Reaction outcome loss': 0.79408010329519, 'Total loss': 0.79408010329519}
2022-11-18 02:14:27,113 INFO:     Best model found after epoch 78 of 100.
2022-11-18 02:14:27,113 INFO:   Done with stage: TRAINING
2022-11-18 02:14:27,113 INFO:   Starting stage: EVALUATION
2022-11-18 02:14:27,244 INFO:   Done with stage: EVALUATION
2022-11-18 02:14:27,252 INFO:   Leaving out SEQ value Fold_0
2022-11-18 02:14:27,265 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 02:14:27,266 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:14:27,931 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:14:27,931 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:14:28,001 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:14:28,001 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:14:28,001 INFO:     No hyperparam tuning for this model
2022-11-18 02:14:28,001 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:14:28,001 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:14:28,002 INFO:     None feature selector for col prot
2022-11-18 02:14:28,002 INFO:     None feature selector for col prot
2022-11-18 02:14:28,002 INFO:     None feature selector for col prot
2022-11-18 02:14:28,003 INFO:     None feature selector for col chem
2022-11-18 02:14:28,003 INFO:     None feature selector for col chem
2022-11-18 02:14:28,003 INFO:     None feature selector for col chem
2022-11-18 02:14:28,003 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:14:28,003 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:14:28,005 INFO:     Number of params in model 168571
2022-11-18 02:14:28,008 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:14:28,008 INFO:   Starting stage: TRAINING
2022-11-18 02:14:28,066 INFO:     Val loss before train {'Reaction outcome loss': 0.9837540896101431, 'Total loss': 0.9837540896101431}
2022-11-18 02:14:28,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:28,066 INFO:     Epoch: 0
2022-11-18 02:14:28,906 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8224380287257108, 'Total loss': 0.8224380287257108} | train loss {'Reaction outcome loss': 0.8858128984363711, 'Total loss': 0.8858128984363711}
2022-11-18 02:14:28,906 INFO:     Found new best model at epoch 0
2022-11-18 02:14:28,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:28,907 INFO:     Epoch: 1
2022-11-18 02:14:29,720 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8098506094379858, 'Total loss': 0.8098506094379858} | train loss {'Reaction outcome loss': 0.851845227212322, 'Total loss': 0.851845227212322}
2022-11-18 02:14:29,721 INFO:     Found new best model at epoch 1
2022-11-18 02:14:29,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:29,722 INFO:     Epoch: 2
2022-11-18 02:14:30,522 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7963201674548063, 'Total loss': 0.7963201674548063} | train loss {'Reaction outcome loss': 0.8418839863368444, 'Total loss': 0.8418839863368444}
2022-11-18 02:14:30,522 INFO:     Found new best model at epoch 2
2022-11-18 02:14:30,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:30,523 INFO:     Epoch: 3
2022-11-18 02:14:31,360 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7800349003889344, 'Total loss': 0.7800349003889344} | train loss {'Reaction outcome loss': 0.8358282530794339, 'Total loss': 0.8358282530794339}
2022-11-18 02:14:31,360 INFO:     Found new best model at epoch 3
2022-11-18 02:14:31,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:31,361 INFO:     Epoch: 4
2022-11-18 02:14:32,198 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7943527305668051, 'Total loss': 0.7943527305668051} | train loss {'Reaction outcome loss': 0.8320464275321182, 'Total loss': 0.8320464275321182}
2022-11-18 02:14:32,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:32,198 INFO:     Epoch: 5
2022-11-18 02:14:32,993 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7907362140037797, 'Total loss': 0.7907362140037797} | train loss {'Reaction outcome loss': 0.8298173078468868, 'Total loss': 0.8298173078468868}
2022-11-18 02:14:32,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:32,993 INFO:     Epoch: 6
2022-11-18 02:14:33,851 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7949690331112255, 'Total loss': 0.7949690331112255} | train loss {'Reaction outcome loss': 0.8232193862905308, 'Total loss': 0.8232193862905308}
2022-11-18 02:14:33,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:33,852 INFO:     Epoch: 7
2022-11-18 02:14:34,673 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7879634546962652, 'Total loss': 0.7879634546962652} | train loss {'Reaction outcome loss': 0.8263722738441156, 'Total loss': 0.8263722738441156}
2022-11-18 02:14:34,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:34,673 INFO:     Epoch: 8
2022-11-18 02:14:35,486 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7841231619769876, 'Total loss': 0.7841231619769876} | train loss {'Reaction outcome loss': 0.8231158403717742, 'Total loss': 0.8231158403717742}
2022-11-18 02:14:35,486 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:35,486 INFO:     Epoch: 9
2022-11-18 02:14:36,265 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.787877234545621, 'Total loss': 0.787877234545621} | train loss {'Reaction outcome loss': 0.817982626204588, 'Total loss': 0.817982626204588}
2022-11-18 02:14:36,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:36,265 INFO:     Epoch: 10
2022-11-18 02:14:37,048 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7562341906807639, 'Total loss': 0.7562341906807639} | train loss {'Reaction outcome loss': 0.8186842086363811, 'Total loss': 0.8186842086363811}
2022-11-18 02:14:37,048 INFO:     Found new best model at epoch 10
2022-11-18 02:14:37,049 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:37,049 INFO:     Epoch: 11
2022-11-18 02:14:37,840 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7742995016954162, 'Total loss': 0.7742995016954162} | train loss {'Reaction outcome loss': 0.8179067198111086, 'Total loss': 0.8179067198111086}
2022-11-18 02:14:37,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:37,841 INFO:     Epoch: 12
2022-11-18 02:14:38,650 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7520640113136985, 'Total loss': 0.7520640113136985} | train loss {'Reaction outcome loss': 0.8172597819445084, 'Total loss': 0.8172597819445084}
2022-11-18 02:14:38,650 INFO:     Found new best model at epoch 12
2022-11-18 02:14:38,650 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:38,651 INFO:     Epoch: 13
2022-11-18 02:14:39,425 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8142070817676458, 'Total loss': 0.8142070817676458} | train loss {'Reaction outcome loss': 0.8181342349976909, 'Total loss': 0.8181342349976909}
2022-11-18 02:14:39,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:39,426 INFO:     Epoch: 14
2022-11-18 02:14:40,226 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7670207450335677, 'Total loss': 0.7670207450335677} | train loss {'Reaction outcome loss': 0.8160357821960839, 'Total loss': 0.8160357821960839}
2022-11-18 02:14:40,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:40,226 INFO:     Epoch: 15
2022-11-18 02:14:41,009 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7867386259815909, 'Total loss': 0.7867386259815909} | train loss {'Reaction outcome loss': 0.8168005343602628, 'Total loss': 0.8168005343602628}
2022-11-18 02:14:41,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:41,010 INFO:     Epoch: 16
2022-11-18 02:14:41,819 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7786401632157239, 'Total loss': 0.7786401632157239} | train loss {'Reaction outcome loss': 0.8171896479567703, 'Total loss': 0.8171896479567703}
2022-11-18 02:14:41,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:41,819 INFO:     Epoch: 17
2022-11-18 02:14:42,607 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7690530432896181, 'Total loss': 0.7690530432896181} | train loss {'Reaction outcome loss': 0.8161474264397913, 'Total loss': 0.8161474264397913}
2022-11-18 02:14:42,608 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:42,609 INFO:     Epoch: 18
2022-11-18 02:14:43,411 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7843898941170085, 'Total loss': 0.7843898941170085} | train loss {'Reaction outcome loss': 0.8157854156834738, 'Total loss': 0.8157854156834738}
2022-11-18 02:14:43,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:43,412 INFO:     Epoch: 19
2022-11-18 02:14:44,211 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7805152653970502, 'Total loss': 0.7805152653970502} | train loss {'Reaction outcome loss': 0.8123274301996036, 'Total loss': 0.8123274301996036}
2022-11-18 02:14:44,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:44,212 INFO:     Epoch: 20
2022-11-18 02:14:45,062 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7872299348766153, 'Total loss': 0.7872299348766153} | train loss {'Reaction outcome loss': 0.8140897401741573, 'Total loss': 0.8140897401741573}
2022-11-18 02:14:45,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:45,062 INFO:     Epoch: 21
2022-11-18 02:14:45,874 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7608983870595694, 'Total loss': 0.7608983870595694} | train loss {'Reaction outcome loss': 0.8147049753033385, 'Total loss': 0.8147049753033385}
2022-11-18 02:14:45,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:45,874 INFO:     Epoch: 22
2022-11-18 02:14:46,677 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7690869237888943, 'Total loss': 0.7690869237888943} | train loss {'Reaction outcome loss': 0.813984742517374, 'Total loss': 0.813984742517374}
2022-11-18 02:14:46,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:46,677 INFO:     Epoch: 23
2022-11-18 02:14:47,457 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7771796888925813, 'Total loss': 0.7771796888925813} | train loss {'Reaction outcome loss': 0.815938735251524, 'Total loss': 0.815938735251524}
2022-11-18 02:14:47,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:47,457 INFO:     Epoch: 24
2022-11-18 02:14:48,243 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7740935839035294, 'Total loss': 0.7740935839035294} | train loss {'Reaction outcome loss': 0.8184050660960528, 'Total loss': 0.8184050660960528}
2022-11-18 02:14:48,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:48,243 INFO:     Epoch: 25
2022-11-18 02:14:49,061 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7645497816530141, 'Total loss': 0.7645497816530141} | train loss {'Reaction outcome loss': 0.819303803176296, 'Total loss': 0.819303803176296}
2022-11-18 02:14:49,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:49,062 INFO:     Epoch: 26
2022-11-18 02:14:49,914 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7825682291930373, 'Total loss': 0.7825682291930373} | train loss {'Reaction outcome loss': 0.8107038820276455, 'Total loss': 0.8107038820276455}
2022-11-18 02:14:49,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:49,914 INFO:     Epoch: 27
2022-11-18 02:14:50,725 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7691159404136918, 'Total loss': 0.7691159404136918} | train loss {'Reaction outcome loss': 0.8164785797498664, 'Total loss': 0.8164785797498664}
2022-11-18 02:14:50,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:50,725 INFO:     Epoch: 28
2022-11-18 02:14:51,589 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7751595574346456, 'Total loss': 0.7751595574346456} | train loss {'Reaction outcome loss': 0.8145003260398398, 'Total loss': 0.8145003260398398}
2022-11-18 02:14:51,589 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:51,589 INFO:     Epoch: 29
2022-11-18 02:14:52,419 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7765078009529547, 'Total loss': 0.7765078009529547} | train loss {'Reaction outcome loss': 0.8137187414023341, 'Total loss': 0.8137187414023341}
2022-11-18 02:14:52,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:52,420 INFO:     Epoch: 30
2022-11-18 02:14:53,190 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7636900456114248, 'Total loss': 0.7636900456114248} | train loss {'Reaction outcome loss': 0.8088670314574729, 'Total loss': 0.8088670314574729}
2022-11-18 02:14:53,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:53,190 INFO:     Epoch: 31
2022-11-18 02:14:53,974 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7722943696108732, 'Total loss': 0.7722943696108732} | train loss {'Reaction outcome loss': 0.8137426703560109, 'Total loss': 0.8137426703560109}
2022-11-18 02:14:53,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:53,974 INFO:     Epoch: 32
2022-11-18 02:14:54,758 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7713022889061407, 'Total loss': 0.7713022889061407} | train loss {'Reaction outcome loss': 0.8194787505938083, 'Total loss': 0.8194787505938083}
2022-11-18 02:14:54,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:54,758 INFO:     Epoch: 33
2022-11-18 02:14:55,545 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7791647369211371, 'Total loss': 0.7791647369211371} | train loss {'Reaction outcome loss': 0.8171353217290372, 'Total loss': 0.8171353217290372}
2022-11-18 02:14:55,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:55,545 INFO:     Epoch: 34
2022-11-18 02:14:56,323 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7732077396728776, 'Total loss': 0.7732077396728776} | train loss {'Reaction outcome loss': 0.8113246820410903, 'Total loss': 0.8113246820410903}
2022-11-18 02:14:56,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:56,324 INFO:     Epoch: 35
2022-11-18 02:14:57,079 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7658612545241009, 'Total loss': 0.7658612545241009} | train loss {'Reaction outcome loss': 0.8196754048065263, 'Total loss': 0.8196754048065263}
2022-11-18 02:14:57,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:57,079 INFO:     Epoch: 36
2022-11-18 02:14:57,844 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7871843847361478, 'Total loss': 0.7871843847361478} | train loss {'Reaction outcome loss': 0.8127560811383384, 'Total loss': 0.8127560811383384}
2022-11-18 02:14:57,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:57,844 INFO:     Epoch: 37
2022-11-18 02:14:58,628 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7657970481298186, 'Total loss': 0.7657970481298186} | train loss {'Reaction outcome loss': 0.8159416637858566, 'Total loss': 0.8159416637858566}
2022-11-18 02:14:58,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:58,628 INFO:     Epoch: 38
2022-11-18 02:14:59,391 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7625526542013342, 'Total loss': 0.7625526542013342} | train loss {'Reaction outcome loss': 0.8148030710463621, 'Total loss': 0.8148030710463621}
2022-11-18 02:14:59,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:14:59,392 INFO:     Epoch: 39
2022-11-18 02:15:00,178 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7865985638716004, 'Total loss': 0.7865985638716004} | train loss {'Reaction outcome loss': 0.810839975366787, 'Total loss': 0.810839975366787}
2022-11-18 02:15:00,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:00,179 INFO:     Epoch: 40
2022-11-18 02:15:01,001 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7976628657091748, 'Total loss': 0.7976628657091748} | train loss {'Reaction outcome loss': 0.8174206174149805, 'Total loss': 0.8174206174149805}
2022-11-18 02:15:01,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:01,001 INFO:     Epoch: 41
2022-11-18 02:15:01,785 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7643737271428108, 'Total loss': 0.7643737271428108} | train loss {'Reaction outcome loss': 0.8195547851980949, 'Total loss': 0.8195547851980949}
2022-11-18 02:15:01,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:01,786 INFO:     Epoch: 42
2022-11-18 02:15:02,558 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7667198892344128, 'Total loss': 0.7667198892344128} | train loss {'Reaction outcome loss': 0.8121123965905637, 'Total loss': 0.8121123965905637}
2022-11-18 02:15:02,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:02,559 INFO:     Epoch: 43
2022-11-18 02:15:03,319 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7718363966454159, 'Total loss': 0.7718363966454159} | train loss {'Reaction outcome loss': 0.8132832682862574, 'Total loss': 0.8132832682862574}
2022-11-18 02:15:03,320 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:03,320 INFO:     Epoch: 44
2022-11-18 02:15:04,092 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8086899424141104, 'Total loss': 0.8086899424141104} | train loss {'Reaction outcome loss': 0.8174484822214866, 'Total loss': 0.8174484822214866}
2022-11-18 02:15:04,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:04,092 INFO:     Epoch: 45
2022-11-18 02:15:04,858 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7838445014574311, 'Total loss': 0.7838445014574311} | train loss {'Reaction outcome loss': 0.8137451292300711, 'Total loss': 0.8137451292300711}
2022-11-18 02:15:04,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:04,859 INFO:     Epoch: 46
2022-11-18 02:15:05,667 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7686730447140607, 'Total loss': 0.7686730447140607} | train loss {'Reaction outcome loss': 0.8154769994774643, 'Total loss': 0.8154769994774643}
2022-11-18 02:15:05,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:05,668 INFO:     Epoch: 47
2022-11-18 02:15:06,456 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7776720056479628, 'Total loss': 0.7776720056479628} | train loss {'Reaction outcome loss': 0.814202271675577, 'Total loss': 0.814202271675577}
2022-11-18 02:15:06,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:06,456 INFO:     Epoch: 48
2022-11-18 02:15:07,229 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7649332190101797, 'Total loss': 0.7649332190101797} | train loss {'Reaction outcome loss': 0.813515185944888, 'Total loss': 0.813515185944888}
2022-11-18 02:15:07,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:07,230 INFO:     Epoch: 49
2022-11-18 02:15:08,002 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7838034013455565, 'Total loss': 0.7838034013455565} | train loss {'Reaction outcome loss': 0.8127526294211952, 'Total loss': 0.8127526294211952}
2022-11-18 02:15:08,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:08,002 INFO:     Epoch: 50
2022-11-18 02:15:08,789 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.766391862522472, 'Total loss': 0.766391862522472} | train loss {'Reaction outcome loss': 0.8177711151084122, 'Total loss': 0.8177711151084122}
2022-11-18 02:15:08,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:08,790 INFO:     Epoch: 51
2022-11-18 02:15:09,559 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7847179127010432, 'Total loss': 0.7847179127010432} | train loss {'Reaction outcome loss': 0.8149718162964802, 'Total loss': 0.8149718162964802}
2022-11-18 02:15:09,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:09,559 INFO:     Epoch: 52
2022-11-18 02:15:10,352 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7646243084560741, 'Total loss': 0.7646243084560741} | train loss {'Reaction outcome loss': 0.8095520096165794, 'Total loss': 0.8095520096165794}
2022-11-18 02:15:10,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:10,353 INFO:     Epoch: 53
2022-11-18 02:15:11,127 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7737486863678152, 'Total loss': 0.7737486863678152} | train loss {'Reaction outcome loss': 0.8118876625080498, 'Total loss': 0.8118876625080498}
2022-11-18 02:15:11,128 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:11,128 INFO:     Epoch: 54
2022-11-18 02:15:11,907 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7730011093345556, 'Total loss': 0.7730011093345556} | train loss {'Reaction outcome loss': 0.8105790752537396, 'Total loss': 0.8105790752537396}
2022-11-18 02:15:11,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:11,907 INFO:     Epoch: 55
2022-11-18 02:15:12,694 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7561875021254475, 'Total loss': 0.7561875021254475} | train loss {'Reaction outcome loss': 0.8196402976707536, 'Total loss': 0.8196402976707536}
2022-11-18 02:15:12,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:12,695 INFO:     Epoch: 56
2022-11-18 02:15:13,470 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.783890766853636, 'Total loss': 0.783890766853636} | train loss {'Reaction outcome loss': 0.8117072875402411, 'Total loss': 0.8117072875402411}
2022-11-18 02:15:13,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:13,472 INFO:     Epoch: 57
2022-11-18 02:15:14,240 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7841536395929076, 'Total loss': 0.7841536395929076} | train loss {'Reaction outcome loss': 0.8138870712445707, 'Total loss': 0.8138870712445707}
2022-11-18 02:15:14,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:14,240 INFO:     Epoch: 58
2022-11-18 02:15:15,019 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7796193591573022, 'Total loss': 0.7796193591573022} | train loss {'Reaction outcome loss': 0.8100985676658397, 'Total loss': 0.8100985676658397}
2022-11-18 02:15:15,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:15,020 INFO:     Epoch: 59
2022-11-18 02:15:15,801 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7681318494406614, 'Total loss': 0.7681318494406614} | train loss {'Reaction outcome loss': 0.8179977067879268, 'Total loss': 0.8179977067879268}
2022-11-18 02:15:15,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:15,801 INFO:     Epoch: 60
2022-11-18 02:15:16,581 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7731219767169519, 'Total loss': 0.7731219767169519} | train loss {'Reaction outcome loss': 0.8132887404792163, 'Total loss': 0.8132887404792163}
2022-11-18 02:15:16,581 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:16,581 INFO:     Epoch: 61
2022-11-18 02:15:17,352 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7868594181808558, 'Total loss': 0.7868594181808558} | train loss {'Reaction outcome loss': 0.8133623528237246, 'Total loss': 0.8133623528237246}
2022-11-18 02:15:17,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:17,353 INFO:     Epoch: 62
2022-11-18 02:15:18,147 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7731710442087867, 'Total loss': 0.7731710442087867} | train loss {'Reaction outcome loss': 0.8128153052865242, 'Total loss': 0.8128153052865242}
2022-11-18 02:15:18,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:18,147 INFO:     Epoch: 63
2022-11-18 02:15:18,921 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7732333717021075, 'Total loss': 0.7732333717021075} | train loss {'Reaction outcome loss': 0.8151506648988139, 'Total loss': 0.8151506648988139}
2022-11-18 02:15:18,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:18,921 INFO:     Epoch: 64
2022-11-18 02:15:19,674 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7950541458346627, 'Total loss': 0.7950541458346627} | train loss {'Reaction outcome loss': 0.8141771815261062, 'Total loss': 0.8141771815261062}
2022-11-18 02:15:19,675 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:19,675 INFO:     Epoch: 65
2022-11-18 02:15:20,437 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7659100781787526, 'Total loss': 0.7659100781787526} | train loss {'Reaction outcome loss': 0.8124154447292795, 'Total loss': 0.8124154447292795}
2022-11-18 02:15:20,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:20,437 INFO:     Epoch: 66
2022-11-18 02:15:21,230 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7815732949159362, 'Total loss': 0.7815732949159362} | train loss {'Reaction outcome loss': 0.812788630991566, 'Total loss': 0.812788630991566}
2022-11-18 02:15:21,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:21,230 INFO:     Epoch: 67
2022-11-18 02:15:22,024 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7655822451819073, 'Total loss': 0.7655822451819073} | train loss {'Reaction outcome loss': 0.8128399383048622, 'Total loss': 0.8128399383048622}
2022-11-18 02:15:22,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:22,024 INFO:     Epoch: 68
2022-11-18 02:15:22,787 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7782200303944674, 'Total loss': 0.7782200303944674} | train loss {'Reaction outcome loss': 0.8171307179392601, 'Total loss': 0.8171307179392601}
2022-11-18 02:15:22,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:22,787 INFO:     Epoch: 69
2022-11-18 02:15:23,548 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7874649255113169, 'Total loss': 0.7874649255113169} | train loss {'Reaction outcome loss': 0.8086650384932148, 'Total loss': 0.8086650384932148}
2022-11-18 02:15:23,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:23,548 INFO:     Epoch: 70
2022-11-18 02:15:24,323 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8038404136896133, 'Total loss': 0.8038404136896133} | train loss {'Reaction outcome loss': 0.8168210589155859, 'Total loss': 0.8168210589155859}
2022-11-18 02:15:24,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:24,324 INFO:     Epoch: 71
2022-11-18 02:15:25,156 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7753124433484945, 'Total loss': 0.7753124433484945} | train loss {'Reaction outcome loss': 0.8127568867741799, 'Total loss': 0.8127568867741799}
2022-11-18 02:15:25,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:25,156 INFO:     Epoch: 72
2022-11-18 02:15:25,988 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8013947409662333, 'Total loss': 0.8013947409662333} | train loss {'Reaction outcome loss': 0.8142134022955991, 'Total loss': 0.8142134022955991}
2022-11-18 02:15:25,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:25,989 INFO:     Epoch: 73
2022-11-18 02:15:26,791 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7922550345009024, 'Total loss': 0.7922550345009024} | train loss {'Reaction outcome loss': 0.8130412265962484, 'Total loss': 0.8130412265962484}
2022-11-18 02:15:26,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:26,791 INFO:     Epoch: 74
2022-11-18 02:15:27,565 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7703139958056536, 'Total loss': 0.7703139958056536} | train loss {'Reaction outcome loss': 0.8087523467686711, 'Total loss': 0.8087523467686711}
2022-11-18 02:15:27,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:27,566 INFO:     Epoch: 75
2022-11-18 02:15:28,365 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7801080251281912, 'Total loss': 0.7801080251281912} | train loss {'Reaction outcome loss': 0.8160497519434715, 'Total loss': 0.8160497519434715}
2022-11-18 02:15:28,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:28,365 INFO:     Epoch: 76
2022-11-18 02:15:29,143 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7488620355725288, 'Total loss': 0.7488620355725288} | train loss {'Reaction outcome loss': 0.8159704225403922, 'Total loss': 0.8159704225403922}
2022-11-18 02:15:29,143 INFO:     Found new best model at epoch 76
2022-11-18 02:15:29,144 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:29,144 INFO:     Epoch: 77
2022-11-18 02:15:30,007 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7616194447671826, 'Total loss': 0.7616194447671826} | train loss {'Reaction outcome loss': 0.8136676020768224, 'Total loss': 0.8136676020768224}
2022-11-18 02:15:30,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:30,007 INFO:     Epoch: 78
2022-11-18 02:15:30,801 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7763032621958039, 'Total loss': 0.7763032621958039} | train loss {'Reaction outcome loss': 0.8102490433624813, 'Total loss': 0.8102490433624813}
2022-11-18 02:15:30,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:30,801 INFO:     Epoch: 79
2022-11-18 02:15:31,617 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7880956876006994, 'Total loss': 0.7880956876006994} | train loss {'Reaction outcome loss': 0.8113526456210078, 'Total loss': 0.8113526456210078}
2022-11-18 02:15:31,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:31,618 INFO:     Epoch: 80
2022-11-18 02:15:32,396 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7656797407702967, 'Total loss': 0.7656797407702967} | train loss {'Reaction outcome loss': 0.8082890763574717, 'Total loss': 0.8082890763574717}
2022-11-18 02:15:32,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:32,397 INFO:     Epoch: 81
2022-11-18 02:15:33,223 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.764349980110472, 'Total loss': 0.764349980110472} | train loss {'Reaction outcome loss': 0.8125120424494452, 'Total loss': 0.8125120424494452}
2022-11-18 02:15:33,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:33,223 INFO:     Epoch: 82
2022-11-18 02:15:34,036 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7724932059645653, 'Total loss': 0.7724932059645653} | train loss {'Reaction outcome loss': 0.8144863544678201, 'Total loss': 0.8144863544678201}
2022-11-18 02:15:34,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:34,037 INFO:     Epoch: 83
2022-11-18 02:15:34,814 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7673852274363692, 'Total loss': 0.7673852274363692} | train loss {'Reaction outcome loss': 0.807961049250194, 'Total loss': 0.807961049250194}
2022-11-18 02:15:34,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:34,815 INFO:     Epoch: 84
2022-11-18 02:15:35,635 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7950594540346753, 'Total loss': 0.7950594540346753} | train loss {'Reaction outcome loss': 0.8101898048605237, 'Total loss': 0.8101898048605237}
2022-11-18 02:15:35,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:35,636 INFO:     Epoch: 85
2022-11-18 02:15:36,467 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7734749466180801, 'Total loss': 0.7734749466180801} | train loss {'Reaction outcome loss': 0.8098664725313381, 'Total loss': 0.8098664725313381}
2022-11-18 02:15:36,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:36,467 INFO:     Epoch: 86
2022-11-18 02:15:37,259 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7644980702210556, 'Total loss': 0.7644980702210556} | train loss {'Reaction outcome loss': 0.8072042355732042, 'Total loss': 0.8072042355732042}
2022-11-18 02:15:37,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:37,259 INFO:     Epoch: 87
2022-11-18 02:15:38,039 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7821658565239473, 'Total loss': 0.7821658565239473} | train loss {'Reaction outcome loss': 0.8128552299373004, 'Total loss': 0.8128552299373004}
2022-11-18 02:15:38,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:38,039 INFO:     Epoch: 88
2022-11-18 02:15:38,826 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7613184716213833, 'Total loss': 0.7613184716213833} | train loss {'Reaction outcome loss': 0.8123455436862245, 'Total loss': 0.8123455436862245}
2022-11-18 02:15:38,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:38,826 INFO:     Epoch: 89
2022-11-18 02:15:39,665 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7830066667361693, 'Total loss': 0.7830066667361693} | train loss {'Reaction outcome loss': 0.8131940096008534, 'Total loss': 0.8131940096008534}
2022-11-18 02:15:39,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:39,665 INFO:     Epoch: 90
2022-11-18 02:15:40,431 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7587009614164179, 'Total loss': 0.7587009614164179} | train loss {'Reaction outcome loss': 0.804155135033082, 'Total loss': 0.804155135033082}
2022-11-18 02:15:40,431 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:40,431 INFO:     Epoch: 91
2022-11-18 02:15:41,205 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7798406258225441, 'Total loss': 0.7798406258225441} | train loss {'Reaction outcome loss': 0.8140404591754992, 'Total loss': 0.8140404591754992}
2022-11-18 02:15:41,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:41,205 INFO:     Epoch: 92
2022-11-18 02:15:42,036 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7634015753865242, 'Total loss': 0.7634015753865242} | train loss {'Reaction outcome loss': 0.8134923947100736, 'Total loss': 0.8134923947100736}
2022-11-18 02:15:42,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:42,036 INFO:     Epoch: 93
2022-11-18 02:15:42,860 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7693810943852771, 'Total loss': 0.7693810943852771} | train loss {'Reaction outcome loss': 0.8116616806205438, 'Total loss': 0.8116616806205438}
2022-11-18 02:15:42,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:42,860 INFO:     Epoch: 94
2022-11-18 02:15:43,669 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7664630297910083, 'Total loss': 0.7664630297910083} | train loss {'Reaction outcome loss': 0.8131966907150892, 'Total loss': 0.8131966907150892}
2022-11-18 02:15:43,669 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:43,669 INFO:     Epoch: 95
2022-11-18 02:15:44,521 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7734889808026227, 'Total loss': 0.7734889808026227} | train loss {'Reaction outcome loss': 0.8120340719514964, 'Total loss': 0.8120340719514964}
2022-11-18 02:15:44,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:44,523 INFO:     Epoch: 96
2022-11-18 02:15:45,331 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7763811512426897, 'Total loss': 0.7763811512426897} | train loss {'Reaction outcome loss': 0.8156857868846582, 'Total loss': 0.8156857868846582}
2022-11-18 02:15:45,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:45,331 INFO:     Epoch: 97
2022-11-18 02:15:46,172 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7568838508291678, 'Total loss': 0.7568838508291678} | train loss {'Reaction outcome loss': 0.8135511189090963, 'Total loss': 0.8135511189090963}
2022-11-18 02:15:46,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:46,172 INFO:     Epoch: 98
2022-11-18 02:15:46,989 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7777972052043135, 'Total loss': 0.7777972052043135} | train loss {'Reaction outcome loss': 0.8084811562178086, 'Total loss': 0.8084811562178086}
2022-11-18 02:15:46,989 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:46,989 INFO:     Epoch: 99
2022-11-18 02:15:47,795 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7677786214785143, 'Total loss': 0.7677786214785143} | train loss {'Reaction outcome loss': 0.8086763377092323, 'Total loss': 0.8086763377092323}
2022-11-18 02:15:47,795 INFO:     Best model found after epoch 77 of 100.
2022-11-18 02:15:47,795 INFO:   Done with stage: TRAINING
2022-11-18 02:15:47,795 INFO:   Starting stage: EVALUATION
2022-11-18 02:15:47,926 INFO:   Done with stage: EVALUATION
2022-11-18 02:15:47,926 INFO:   Leaving out SEQ value Fold_1
2022-11-18 02:15:47,945 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 02:15:47,946 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:15:48,631 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:15:48,631 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:15:48,705 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:15:48,705 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:15:48,705 INFO:     No hyperparam tuning for this model
2022-11-18 02:15:48,705 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:15:48,705 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:15:48,706 INFO:     None feature selector for col prot
2022-11-18 02:15:48,706 INFO:     None feature selector for col prot
2022-11-18 02:15:48,707 INFO:     None feature selector for col prot
2022-11-18 02:15:48,707 INFO:     None feature selector for col chem
2022-11-18 02:15:48,707 INFO:     None feature selector for col chem
2022-11-18 02:15:48,707 INFO:     None feature selector for col chem
2022-11-18 02:15:48,708 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:15:48,708 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:15:48,709 INFO:     Number of params in model 168571
2022-11-18 02:15:48,712 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:15:48,713 INFO:   Starting stage: TRAINING
2022-11-18 02:15:48,770 INFO:     Val loss before train {'Reaction outcome loss': 1.0355984338305213, 'Total loss': 1.0355984338305213}
2022-11-18 02:15:48,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:48,770 INFO:     Epoch: 0
2022-11-18 02:15:49,566 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8751658336682753, 'Total loss': 0.8751658336682753} | train loss {'Reaction outcome loss': 0.8829382896302682, 'Total loss': 0.8829382896302682}
2022-11-18 02:15:49,566 INFO:     Found new best model at epoch 0
2022-11-18 02:15:49,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:49,567 INFO:     Epoch: 1
2022-11-18 02:15:50,379 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8574980226430026, 'Total loss': 0.8574980226430026} | train loss {'Reaction outcome loss': 0.8578308151077162, 'Total loss': 0.8578308151077162}
2022-11-18 02:15:50,380 INFO:     Found new best model at epoch 1
2022-11-18 02:15:50,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:50,381 INFO:     Epoch: 2
2022-11-18 02:15:51,216 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8615859855305065, 'Total loss': 0.8615859855305065} | train loss {'Reaction outcome loss': 0.860307189134451, 'Total loss': 0.860307189134451}
2022-11-18 02:15:51,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:51,217 INFO:     Epoch: 3
2022-11-18 02:15:52,047 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8759009946476329, 'Total loss': 0.8759009946476329} | train loss {'Reaction outcome loss': 0.8478193813972628, 'Total loss': 0.8478193813972628}
2022-11-18 02:15:52,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:52,047 INFO:     Epoch: 4
2022-11-18 02:15:52,862 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8580011955716393, 'Total loss': 0.8580011955716393} | train loss {'Reaction outcome loss': 0.8379438710116182, 'Total loss': 0.8379438710116182}
2022-11-18 02:15:52,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:52,863 INFO:     Epoch: 5
2022-11-18 02:15:53,657 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8612356375564229, 'Total loss': 0.8612356375564229} | train loss {'Reaction outcome loss': 0.8413442592871817, 'Total loss': 0.8413442592871817}
2022-11-18 02:15:53,657 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:53,657 INFO:     Epoch: 6
2022-11-18 02:15:54,465 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8688455007293008, 'Total loss': 0.8688455007293008} | train loss {'Reaction outcome loss': 0.8393370678670976, 'Total loss': 0.8393370678670976}
2022-11-18 02:15:54,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:54,465 INFO:     Epoch: 7
2022-11-18 02:15:55,281 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8702774779363112, 'Total loss': 0.8702774779363112} | train loss {'Reaction outcome loss': 0.8269194408587599, 'Total loss': 0.8269194408587599}
2022-11-18 02:15:55,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:55,282 INFO:     Epoch: 8
2022-11-18 02:15:56,102 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8598955774849112, 'Total loss': 0.8598955774849112} | train loss {'Reaction outcome loss': 0.8249153590154069, 'Total loss': 0.8249153590154069}
2022-11-18 02:15:56,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:56,102 INFO:     Epoch: 9
2022-11-18 02:15:56,903 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8786563859744505, 'Total loss': 0.8786563859744505} | train loss {'Reaction outcome loss': 0.8268186296769965, 'Total loss': 0.8268186296769965}
2022-11-18 02:15:56,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:56,903 INFO:     Epoch: 10
2022-11-18 02:15:57,733 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8427092412656004, 'Total loss': 0.8427092412656004} | train loss {'Reaction outcome loss': 0.8300191427049367, 'Total loss': 0.8300191427049367}
2022-11-18 02:15:57,733 INFO:     Found new best model at epoch 10
2022-11-18 02:15:57,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:57,734 INFO:     Epoch: 11
2022-11-18 02:15:58,566 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8491012934934009, 'Total loss': 0.8491012934934009} | train loss {'Reaction outcome loss': 0.8259622774007711, 'Total loss': 0.8259622774007711}
2022-11-18 02:15:58,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:58,566 INFO:     Epoch: 12
2022-11-18 02:15:59,363 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8411317664113912, 'Total loss': 0.8411317664113912} | train loss {'Reaction outcome loss': 0.8315982612279745, 'Total loss': 0.8315982612279745}
2022-11-18 02:15:59,363 INFO:     Found new best model at epoch 12
2022-11-18 02:15:59,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:15:59,364 INFO:     Epoch: 13
2022-11-18 02:16:00,182 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8523074104027315, 'Total loss': 0.8523074104027315} | train loss {'Reaction outcome loss': 0.8272952217804758, 'Total loss': 0.8272952217804758}
2022-11-18 02:16:00,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:00,182 INFO:     Epoch: 14
2022-11-18 02:16:00,952 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8553095724094998, 'Total loss': 0.8553095724094998} | train loss {'Reaction outcome loss': 0.8221254469713701, 'Total loss': 0.8221254469713701}
2022-11-18 02:16:00,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:00,952 INFO:     Epoch: 15
2022-11-18 02:16:01,761 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8690840534188531, 'Total loss': 0.8690840534188531} | train loss {'Reaction outcome loss': 0.8252338289249281, 'Total loss': 0.8252338289249281}
2022-11-18 02:16:01,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:01,761 INFO:     Epoch: 16
2022-11-18 02:16:02,598 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8482330231504007, 'Total loss': 0.8482330231504007} | train loss {'Reaction outcome loss': 0.8381162378710774, 'Total loss': 0.8381162378710774}
2022-11-18 02:16:02,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:02,599 INFO:     Epoch: 17
2022-11-18 02:16:03,393 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8524609316479076, 'Total loss': 0.8524609316479076} | train loss {'Reaction outcome loss': 0.8224507818217219, 'Total loss': 0.8224507818217219}
2022-11-18 02:16:03,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:03,394 INFO:     Epoch: 18
2022-11-18 02:16:04,209 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8783880478956483, 'Total loss': 0.8783880478956483} | train loss {'Reaction outcome loss': 0.821402434757364, 'Total loss': 0.821402434757364}
2022-11-18 02:16:04,209 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:04,209 INFO:     Epoch: 19
2022-11-18 02:16:05,023 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8415844128890471, 'Total loss': 0.8415844128890471} | train loss {'Reaction outcome loss': 0.8355237871770435, 'Total loss': 0.8355237871770435}
2022-11-18 02:16:05,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:05,023 INFO:     Epoch: 20
2022-11-18 02:16:05,844 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8794558637521483, 'Total loss': 0.8794558637521483} | train loss {'Reaction outcome loss': 0.8296839787892485, 'Total loss': 0.8296839787892485}
2022-11-18 02:16:05,844 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:05,844 INFO:     Epoch: 21
2022-11-18 02:16:06,679 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8608077493580905, 'Total loss': 0.8608077493580905} | train loss {'Reaction outcome loss': 0.8274047940607495, 'Total loss': 0.8274047940607495}
2022-11-18 02:16:06,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:06,679 INFO:     Epoch: 22
2022-11-18 02:16:07,467 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.895902849056504, 'Total loss': 0.895902849056504} | train loss {'Reaction outcome loss': 0.8273940870636388, 'Total loss': 0.8273940870636388}
2022-11-18 02:16:07,467 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:07,467 INFO:     Epoch: 23
2022-11-18 02:16:08,262 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8610521961342205, 'Total loss': 0.8610521961342205} | train loss {'Reaction outcome loss': 0.8215171937879763, 'Total loss': 0.8215171937879763}
2022-11-18 02:16:08,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:08,262 INFO:     Epoch: 24
2022-11-18 02:16:09,091 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8628724711862478, 'Total loss': 0.8628724711862478} | train loss {'Reaction outcome loss': 0.8261988680613669, 'Total loss': 0.8261988680613669}
2022-11-18 02:16:09,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:09,091 INFO:     Epoch: 25
2022-11-18 02:16:09,843 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8476236929947679, 'Total loss': 0.8476236929947679} | train loss {'Reaction outcome loss': 0.8205769801670723, 'Total loss': 0.8205769801670723}
2022-11-18 02:16:09,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:09,843 INFO:     Epoch: 26
2022-11-18 02:16:10,626 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8421309305862947, 'Total loss': 0.8421309305862947} | train loss {'Reaction outcome loss': 0.8221514012046188, 'Total loss': 0.8221514012046188}
2022-11-18 02:16:10,626 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:10,626 INFO:     Epoch: 27
2022-11-18 02:16:11,473 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8451369296420704, 'Total loss': 0.8451369296420704} | train loss {'Reaction outcome loss': 0.8250830542703389, 'Total loss': 0.8250830542703389}
2022-11-18 02:16:11,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:11,473 INFO:     Epoch: 28
2022-11-18 02:16:12,308 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8506480184468356, 'Total loss': 0.8506480184468356} | train loss {'Reaction outcome loss': 0.8179817155667162, 'Total loss': 0.8179817155667162}
2022-11-18 02:16:12,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:12,308 INFO:     Epoch: 29
2022-11-18 02:16:13,126 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8541301170533354, 'Total loss': 0.8541301170533354} | train loss {'Reaction outcome loss': 0.8283599838312821, 'Total loss': 0.8283599838312821}
2022-11-18 02:16:13,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:13,127 INFO:     Epoch: 30
2022-11-18 02:16:13,960 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8467036912387068, 'Total loss': 0.8467036912387068} | train loss {'Reaction outcome loss': 0.8297144454500454, 'Total loss': 0.8297144454500454}
2022-11-18 02:16:13,960 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:13,960 INFO:     Epoch: 31
2022-11-18 02:16:14,772 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8422480598092079, 'Total loss': 0.8422480598092079} | train loss {'Reaction outcome loss': 0.8265761694444819, 'Total loss': 0.8265761694444819}
2022-11-18 02:16:14,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:14,772 INFO:     Epoch: 32
2022-11-18 02:16:15,634 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8530544747005809, 'Total loss': 0.8530544747005809} | train loss {'Reaction outcome loss': 0.8282547779532097, 'Total loss': 0.8282547779532097}
2022-11-18 02:16:15,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:15,635 INFO:     Epoch: 33
2022-11-18 02:16:16,454 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8505309115756642, 'Total loss': 0.8505309115756642} | train loss {'Reaction outcome loss': 0.8278510319559198, 'Total loss': 0.8278510319559198}
2022-11-18 02:16:16,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:16,454 INFO:     Epoch: 34
2022-11-18 02:16:17,295 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8447281325405295, 'Total loss': 0.8447281325405295} | train loss {'Reaction outcome loss': 0.8215926913808473, 'Total loss': 0.8215926913808473}
2022-11-18 02:16:17,295 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:17,295 INFO:     Epoch: 35
2022-11-18 02:16:18,099 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8673181174830957, 'Total loss': 0.8673181174830957} | train loss {'Reaction outcome loss': 0.8227732599626186, 'Total loss': 0.8227732599626186}
2022-11-18 02:16:18,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:18,099 INFO:     Epoch: 36
2022-11-18 02:16:18,914 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.848151448098096, 'Total loss': 0.848151448098096} | train loss {'Reaction outcome loss': 0.8193332236184765, 'Total loss': 0.8193332236184765}
2022-11-18 02:16:18,914 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:18,914 INFO:     Epoch: 37
2022-11-18 02:16:19,745 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8422968617894433, 'Total loss': 0.8422968617894433} | train loss {'Reaction outcome loss': 0.8169674267125154, 'Total loss': 0.8169674267125154}
2022-11-18 02:16:19,745 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:19,745 INFO:     Epoch: 38
2022-11-18 02:16:20,572 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8588230515068228, 'Total loss': 0.8588230515068228} | train loss {'Reaction outcome loss': 0.8211642671451878, 'Total loss': 0.8211642671451878}
2022-11-18 02:16:20,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:20,573 INFO:     Epoch: 39
2022-11-18 02:16:21,404 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8534126349470832, 'Total loss': 0.8534126349470832} | train loss {'Reaction outcome loss': 0.824761068109076, 'Total loss': 0.824761068109076}
2022-11-18 02:16:21,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:21,404 INFO:     Epoch: 40
2022-11-18 02:16:22,218 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8329070955514908, 'Total loss': 0.8329070955514908} | train loss {'Reaction outcome loss': 0.8164171720081977, 'Total loss': 0.8164171720081977}
2022-11-18 02:16:22,219 INFO:     Found new best model at epoch 40
2022-11-18 02:16:22,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:22,220 INFO:     Epoch: 41
2022-11-18 02:16:23,027 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8426599353551865, 'Total loss': 0.8426599353551865} | train loss {'Reaction outcome loss': 0.8237630853406813, 'Total loss': 0.8237630853406813}
2022-11-18 02:16:23,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:23,027 INFO:     Epoch: 42
2022-11-18 02:16:23,829 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8620861010117964, 'Total loss': 0.8620861010117964} | train loss {'Reaction outcome loss': 0.8274397858482624, 'Total loss': 0.8274397858482624}
2022-11-18 02:16:23,829 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:23,830 INFO:     Epoch: 43
2022-11-18 02:16:24,624 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8521878888661211, 'Total loss': 0.8521878888661211} | train loss {'Reaction outcome loss': 0.8216376863269188, 'Total loss': 0.8216376863269188}
2022-11-18 02:16:24,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:24,624 INFO:     Epoch: 44
2022-11-18 02:16:25,413 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8433235287666321, 'Total loss': 0.8433235287666321} | train loss {'Reaction outcome loss': 0.832219085350693, 'Total loss': 0.832219085350693}
2022-11-18 02:16:25,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:25,414 INFO:     Epoch: 45
2022-11-18 02:16:26,237 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8621070981025696, 'Total loss': 0.8621070981025696} | train loss {'Reaction outcome loss': 0.8280535091755361, 'Total loss': 0.8280535091755361}
2022-11-18 02:16:26,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:26,237 INFO:     Epoch: 46
2022-11-18 02:16:27,044 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.838805461471731, 'Total loss': 0.838805461471731} | train loss {'Reaction outcome loss': 0.827877348221024, 'Total loss': 0.827877348221024}
2022-11-18 02:16:27,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:27,044 INFO:     Epoch: 47
2022-11-18 02:16:27,857 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8477928272702477, 'Total loss': 0.8477928272702477} | train loss {'Reaction outcome loss': 0.8260563353777897, 'Total loss': 0.8260563353777897}
2022-11-18 02:16:27,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:27,857 INFO:     Epoch: 48
2022-11-18 02:16:28,651 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.837628671052781, 'Total loss': 0.837628671052781} | train loss {'Reaction outcome loss': 0.8265986102312682, 'Total loss': 0.8265986102312682}
2022-11-18 02:16:28,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:28,652 INFO:     Epoch: 49
2022-11-18 02:16:29,474 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8499693132259629, 'Total loss': 0.8499693132259629} | train loss {'Reaction outcome loss': 0.819855762517404, 'Total loss': 0.819855762517404}
2022-11-18 02:16:29,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:29,474 INFO:     Epoch: 50
2022-11-18 02:16:30,272 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8495298989794471, 'Total loss': 0.8495298989794471} | train loss {'Reaction outcome loss': 0.8225368859796871, 'Total loss': 0.8225368859796871}
2022-11-18 02:16:30,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:30,272 INFO:     Epoch: 51
2022-11-18 02:16:31,089 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8497989109971307, 'Total loss': 0.8497989109971307} | train loss {'Reaction outcome loss': 0.8329920138907336, 'Total loss': 0.8329920138907336}
2022-11-18 02:16:31,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:31,089 INFO:     Epoch: 52
2022-11-18 02:16:31,901 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8500374562361024, 'Total loss': 0.8500374562361024} | train loss {'Reaction outcome loss': 0.8268392087235624, 'Total loss': 0.8268392087235624}
2022-11-18 02:16:31,901 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:31,901 INFO:     Epoch: 53
2022-11-18 02:16:32,689 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8752072575417432, 'Total loss': 0.8752072575417432} | train loss {'Reaction outcome loss': 0.8261496021680022, 'Total loss': 0.8261496021680022}
2022-11-18 02:16:32,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:32,689 INFO:     Epoch: 54
2022-11-18 02:16:33,487 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8389121429486708, 'Total loss': 0.8389121429486708} | train loss {'Reaction outcome loss': 0.8208786307679496, 'Total loss': 0.8208786307679496}
2022-11-18 02:16:33,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:33,488 INFO:     Epoch: 55
2022-11-18 02:16:34,281 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8481354171579535, 'Total loss': 0.8481354171579535} | train loss {'Reaction outcome loss': 0.8183511910650895, 'Total loss': 0.8183511910650895}
2022-11-18 02:16:34,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:34,282 INFO:     Epoch: 56
2022-11-18 02:16:35,117 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8492301099679687, 'Total loss': 0.8492301099679687} | train loss {'Reaction outcome loss': 0.8180888609485588, 'Total loss': 0.8180888609485588}
2022-11-18 02:16:35,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:35,117 INFO:     Epoch: 57
2022-11-18 02:16:35,928 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8283420740203424, 'Total loss': 0.8283420740203424} | train loss {'Reaction outcome loss': 0.8178812918905546, 'Total loss': 0.8178812918905546}
2022-11-18 02:16:35,928 INFO:     Found new best model at epoch 57
2022-11-18 02:16:35,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:35,929 INFO:     Epoch: 58
2022-11-18 02:16:36,732 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8348674245856025, 'Total loss': 0.8348674245856025} | train loss {'Reaction outcome loss': 0.8256343238749485, 'Total loss': 0.8256343238749485}
2022-11-18 02:16:36,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:36,733 INFO:     Epoch: 59
2022-11-18 02:16:37,524 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8532155555757609, 'Total loss': 0.8532155555757609} | train loss {'Reaction outcome loss': 0.8189314607425258, 'Total loss': 0.8189314607425258}
2022-11-18 02:16:37,524 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:37,524 INFO:     Epoch: 60
2022-11-18 02:16:38,345 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8494124432856386, 'Total loss': 0.8494124432856386} | train loss {'Reaction outcome loss': 0.8213457349944211, 'Total loss': 0.8213457349944211}
2022-11-18 02:16:38,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:38,345 INFO:     Epoch: 61
2022-11-18 02:16:39,170 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8417558900334619, 'Total loss': 0.8417558900334619} | train loss {'Reaction outcome loss': 0.8230173309080997, 'Total loss': 0.8230173309080997}
2022-11-18 02:16:39,170 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:39,170 INFO:     Epoch: 62
2022-11-18 02:16:39,980 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8461480465802279, 'Total loss': 0.8461480465802279} | train loss {'Reaction outcome loss': 0.8203558118237175, 'Total loss': 0.8203558118237175}
2022-11-18 02:16:39,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:39,980 INFO:     Epoch: 63
2022-11-18 02:16:40,792 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8688906898552721, 'Total loss': 0.8688906898552721} | train loss {'Reaction outcome loss': 0.8160184329820548, 'Total loss': 0.8160184329820548}
2022-11-18 02:16:40,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:40,792 INFO:     Epoch: 64
2022-11-18 02:16:41,625 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8347990465435114, 'Total loss': 0.8347990465435114} | train loss {'Reaction outcome loss': 0.8215770687953181, 'Total loss': 0.8215770687953181}
2022-11-18 02:16:41,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:41,625 INFO:     Epoch: 65
2022-11-18 02:16:42,428 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8464842262593183, 'Total loss': 0.8464842262593183} | train loss {'Reaction outcome loss': 0.8209553134103535, 'Total loss': 0.8209553134103535}
2022-11-18 02:16:42,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:42,428 INFO:     Epoch: 66
2022-11-18 02:16:43,249 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8406725607135079, 'Total loss': 0.8406725607135079} | train loss {'Reaction outcome loss': 0.8196435615360013, 'Total loss': 0.8196435615360013}
2022-11-18 02:16:43,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:43,249 INFO:     Epoch: 67
2022-11-18 02:16:44,045 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8470100137320432, 'Total loss': 0.8470100137320432} | train loss {'Reaction outcome loss': 0.8196269925306683, 'Total loss': 0.8196269925306683}
2022-11-18 02:16:44,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:44,045 INFO:     Epoch: 68
2022-11-18 02:16:44,846 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8470507338643074, 'Total loss': 0.8470507338643074} | train loss {'Reaction outcome loss': 0.8289129609762416, 'Total loss': 0.8289129609762416}
2022-11-18 02:16:44,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:44,846 INFO:     Epoch: 69
2022-11-18 02:16:45,672 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8380764329975302, 'Total loss': 0.8380764329975302} | train loss {'Reaction outcome loss': 0.825794564688254, 'Total loss': 0.825794564688254}
2022-11-18 02:16:45,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:45,673 INFO:     Epoch: 70
2022-11-18 02:16:46,505 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8418795581568371, 'Total loss': 0.8418795581568371} | train loss {'Reaction outcome loss': 0.8168385787471103, 'Total loss': 0.8168385787471103}
2022-11-18 02:16:46,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:46,507 INFO:     Epoch: 71
2022-11-18 02:16:47,336 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8311066830700095, 'Total loss': 0.8311066830700095} | train loss {'Reaction outcome loss': 0.8236900301356065, 'Total loss': 0.8236900301356065}
2022-11-18 02:16:47,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:47,336 INFO:     Epoch: 72
2022-11-18 02:16:48,191 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8574875220656395, 'Total loss': 0.8574875220656395} | train loss {'Reaction outcome loss': 0.82320082127324, 'Total loss': 0.82320082127324}
2022-11-18 02:16:48,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:48,192 INFO:     Epoch: 73
2022-11-18 02:16:48,981 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8395858671177517, 'Total loss': 0.8395858671177517} | train loss {'Reaction outcome loss': 0.8214996802481079, 'Total loss': 0.8214996802481079}
2022-11-18 02:16:48,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:48,982 INFO:     Epoch: 74
2022-11-18 02:16:49,796 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8356734893538735, 'Total loss': 0.8356734893538735} | train loss {'Reaction outcome loss': 0.8175535542882888, 'Total loss': 0.8175535542882888}
2022-11-18 02:16:49,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:49,797 INFO:     Epoch: 75
2022-11-18 02:16:50,580 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8419751044024121, 'Total loss': 0.8419751044024121} | train loss {'Reaction outcome loss': 0.8214932933510074, 'Total loss': 0.8214932933510074}
2022-11-18 02:16:50,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:50,581 INFO:     Epoch: 76
2022-11-18 02:16:51,406 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8635962971232154, 'Total loss': 0.8635962971232154} | train loss {'Reaction outcome loss': 0.8209454413608983, 'Total loss': 0.8209454413608983}
2022-11-18 02:16:51,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:51,406 INFO:     Epoch: 77
2022-11-18 02:16:52,187 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8598060282793912, 'Total loss': 0.8598060282793912} | train loss {'Reaction outcome loss': 0.815770807898479, 'Total loss': 0.815770807898479}
2022-11-18 02:16:52,187 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:52,187 INFO:     Epoch: 78
2022-11-18 02:16:53,007 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8485047221183777, 'Total loss': 0.8485047221183777} | train loss {'Reaction outcome loss': 0.8190763865405248, 'Total loss': 0.8190763865405248}
2022-11-18 02:16:53,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:53,008 INFO:     Epoch: 79
2022-11-18 02:16:53,804 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.84175844355063, 'Total loss': 0.84175844355063} | train loss {'Reaction outcome loss': 0.8236535880488423, 'Total loss': 0.8236535880488423}
2022-11-18 02:16:53,805 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:53,805 INFO:     Epoch: 80
2022-11-18 02:16:54,668 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8360220451246608, 'Total loss': 0.8360220451246608} | train loss {'Reaction outcome loss': 0.8280750043720368, 'Total loss': 0.8280750043720368}
2022-11-18 02:16:54,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:54,668 INFO:     Epoch: 81
2022-11-18 02:16:55,501 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8526700179685246, 'Total loss': 0.8526700179685246} | train loss {'Reaction outcome loss': 0.825641689030265, 'Total loss': 0.825641689030265}
2022-11-18 02:16:55,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:55,502 INFO:     Epoch: 82
2022-11-18 02:16:56,333 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8721839623017744, 'Total loss': 0.8721839623017744} | train loss {'Reaction outcome loss': 0.8228903545541801, 'Total loss': 0.8228903545541801}
2022-11-18 02:16:56,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:56,333 INFO:     Epoch: 83
2022-11-18 02:16:57,143 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8383663161234423, 'Total loss': 0.8383663161234423} | train loss {'Reaction outcome loss': 0.8193553278320714, 'Total loss': 0.8193553278320714}
2022-11-18 02:16:57,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:57,143 INFO:     Epoch: 84
2022-11-18 02:16:57,961 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8337774723768234, 'Total loss': 0.8337774723768234} | train loss {'Reaction outcome loss': 0.8173262113742983, 'Total loss': 0.8173262113742983}
2022-11-18 02:16:57,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:57,961 INFO:     Epoch: 85
2022-11-18 02:16:58,747 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8448253646492958, 'Total loss': 0.8448253646492958} | train loss {'Reaction outcome loss': 0.8232380247067826, 'Total loss': 0.8232380247067826}
2022-11-18 02:16:58,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:58,748 INFO:     Epoch: 86
2022-11-18 02:16:59,570 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8515773090449247, 'Total loss': 0.8515773090449247} | train loss {'Reaction outcome loss': 0.8216238953323982, 'Total loss': 0.8216238953323982}
2022-11-18 02:16:59,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:16:59,571 INFO:     Epoch: 87
2022-11-18 02:17:00,352 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8770508210767399, 'Total loss': 0.8770508210767399} | train loss {'Reaction outcome loss': 0.8269578851910255, 'Total loss': 0.8269578851910255}
2022-11-18 02:17:00,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:00,353 INFO:     Epoch: 88
2022-11-18 02:17:01,134 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8464003679427233, 'Total loss': 0.8464003679427233} | train loss {'Reaction outcome loss': 0.8216546793215671, 'Total loss': 0.8216546793215671}
2022-11-18 02:17:01,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:01,134 INFO:     Epoch: 89
2022-11-18 02:17:01,930 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8474259092049166, 'Total loss': 0.8474259092049166} | train loss {'Reaction outcome loss': 0.8247512036006943, 'Total loss': 0.8247512036006943}
2022-11-18 02:17:01,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:01,930 INFO:     Epoch: 90
2022-11-18 02:17:02,730 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8591233505444094, 'Total loss': 0.8591233505444094} | train loss {'Reaction outcome loss': 0.8176603181521419, 'Total loss': 0.8176603181521419}
2022-11-18 02:17:02,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:02,730 INFO:     Epoch: 91
2022-11-18 02:17:03,526 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8474434966390784, 'Total loss': 0.8474434966390784} | train loss {'Reaction outcome loss': 0.8192707413603902, 'Total loss': 0.8192707413603902}
2022-11-18 02:17:03,526 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:03,526 INFO:     Epoch: 92
2022-11-18 02:17:04,305 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8371011113578622, 'Total loss': 0.8371011113578622} | train loss {'Reaction outcome loss': 0.821465616827069, 'Total loss': 0.821465616827069}
2022-11-18 02:17:04,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:04,306 INFO:     Epoch: 93
2022-11-18 02:17:05,086 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8594981343908743, 'Total loss': 0.8594981343908743} | train loss {'Reaction outcome loss': 0.8187882760275713, 'Total loss': 0.8187882760275713}
2022-11-18 02:17:05,087 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:05,087 INFO:     Epoch: 94
2022-11-18 02:17:05,897 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8509599153291095, 'Total loss': 0.8509599153291095} | train loss {'Reaction outcome loss': 0.8141723151812669, 'Total loss': 0.8141723151812669}
2022-11-18 02:17:05,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:05,897 INFO:     Epoch: 95
2022-11-18 02:17:06,733 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8597210821780291, 'Total loss': 0.8597210821780291} | train loss {'Reaction outcome loss': 0.8187345650031982, 'Total loss': 0.8187345650031982}
2022-11-18 02:17:06,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:06,733 INFO:     Epoch: 96
2022-11-18 02:17:07,535 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8403789732943882, 'Total loss': 0.8403789732943882} | train loss {'Reaction outcome loss': 0.816944232112483, 'Total loss': 0.816944232112483}
2022-11-18 02:17:07,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:07,536 INFO:     Epoch: 97
2022-11-18 02:17:08,376 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8467945829033852, 'Total loss': 0.8467945829033852} | train loss {'Reaction outcome loss': 0.8226793747440524, 'Total loss': 0.8226793747440524}
2022-11-18 02:17:08,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:08,376 INFO:     Epoch: 98
2022-11-18 02:17:09,210 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.854711414738135, 'Total loss': 0.854711414738135} | train loss {'Reaction outcome loss': 0.8220212236650077, 'Total loss': 0.8220212236650077}
2022-11-18 02:17:09,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:09,210 INFO:     Epoch: 99
2022-11-18 02:17:10,015 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.854685362089764, 'Total loss': 0.854685362089764} | train loss {'Reaction outcome loss': 0.8171464225903213, 'Total loss': 0.8171464225903213}
2022-11-18 02:17:10,015 INFO:     Best model found after epoch 58 of 100.
2022-11-18 02:17:10,015 INFO:   Done with stage: TRAINING
2022-11-18 02:17:10,015 INFO:   Starting stage: EVALUATION
2022-11-18 02:17:10,144 INFO:   Done with stage: EVALUATION
2022-11-18 02:17:10,145 INFO:   Leaving out SEQ value Fold_2
2022-11-18 02:17:10,158 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 02:17:10,158 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:17:10,830 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:17:10,830 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:17:10,900 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:17:10,900 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:17:10,900 INFO:     No hyperparam tuning for this model
2022-11-18 02:17:10,900 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:17:10,900 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:17:10,901 INFO:     None feature selector for col prot
2022-11-18 02:17:10,901 INFO:     None feature selector for col prot
2022-11-18 02:17:10,901 INFO:     None feature selector for col prot
2022-11-18 02:17:10,902 INFO:     None feature selector for col chem
2022-11-18 02:17:10,902 INFO:     None feature selector for col chem
2022-11-18 02:17:10,902 INFO:     None feature selector for col chem
2022-11-18 02:17:10,902 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:17:10,902 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:17:10,904 INFO:     Number of params in model 168571
2022-11-18 02:17:10,907 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:17:10,907 INFO:   Starting stage: TRAINING
2022-11-18 02:17:10,965 INFO:     Val loss before train {'Reaction outcome loss': 0.9872418642044067, 'Total loss': 0.9872418642044067}
2022-11-18 02:17:10,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:10,966 INFO:     Epoch: 0
2022-11-18 02:17:11,753 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8217755305496129, 'Total loss': 0.8217755305496129} | train loss {'Reaction outcome loss': 0.87398469813016, 'Total loss': 0.87398469813016}
2022-11-18 02:17:11,753 INFO:     Found new best model at epoch 0
2022-11-18 02:17:11,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:11,754 INFO:     Epoch: 1
2022-11-18 02:17:12,592 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8442238935015418, 'Total loss': 0.8442238935015418} | train loss {'Reaction outcome loss': 0.8426857635682943, 'Total loss': 0.8426857635682943}
2022-11-18 02:17:12,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:12,593 INFO:     Epoch: 2
2022-11-18 02:17:13,435 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8247934119267897, 'Total loss': 0.8247934119267897} | train loss {'Reaction outcome loss': 0.8415562858386916, 'Total loss': 0.8415562858386916}
2022-11-18 02:17:13,435 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:13,435 INFO:     Epoch: 3
2022-11-18 02:17:14,251 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8063144846396013, 'Total loss': 0.8063144846396013} | train loss {'Reaction outcome loss': 0.8356185866861927, 'Total loss': 0.8356185866861927}
2022-11-18 02:17:14,251 INFO:     Found new best model at epoch 3
2022-11-18 02:17:14,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:14,252 INFO:     Epoch: 4
2022-11-18 02:17:15,024 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8067907372658903, 'Total loss': 0.8067907372658903} | train loss {'Reaction outcome loss': 0.8281737647494491, 'Total loss': 0.8281737647494491}
2022-11-18 02:17:15,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:15,025 INFO:     Epoch: 5
2022-11-18 02:17:15,843 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8130262067372148, 'Total loss': 0.8130262067372148} | train loss {'Reaction outcome loss': 0.8247948599104978, 'Total loss': 0.8247948599104978}
2022-11-18 02:17:15,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:15,843 INFO:     Epoch: 6
2022-11-18 02:17:16,683 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8403119885108687, 'Total loss': 0.8403119885108687} | train loss {'Reaction outcome loss': 0.82103487362667, 'Total loss': 0.82103487362667}
2022-11-18 02:17:16,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:16,683 INFO:     Epoch: 7
2022-11-18 02:17:17,507 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.815096958794377, 'Total loss': 0.815096958794377} | train loss {'Reaction outcome loss': 0.827236197311051, 'Total loss': 0.827236197311051}
2022-11-18 02:17:17,509 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:17,509 INFO:     Epoch: 8
2022-11-18 02:17:18,340 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7800141268155791, 'Total loss': 0.7800141268155791} | train loss {'Reaction outcome loss': 0.8199188238503982, 'Total loss': 0.8199188238503982}
2022-11-18 02:17:18,341 INFO:     Found new best model at epoch 8
2022-11-18 02:17:18,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:18,341 INFO:     Epoch: 9
2022-11-18 02:17:19,133 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7926806766878475, 'Total loss': 0.7926806766878475} | train loss {'Reaction outcome loss': 0.8212924401370847, 'Total loss': 0.8212924401370847}
2022-11-18 02:17:19,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:19,133 INFO:     Epoch: 10
2022-11-18 02:17:19,912 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8317231332713907, 'Total loss': 0.8317231332713907} | train loss {'Reaction outcome loss': 0.819505087575134, 'Total loss': 0.819505087575134}
2022-11-18 02:17:19,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:19,912 INFO:     Epoch: 11
2022-11-18 02:17:20,731 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7994101914492521, 'Total loss': 0.7994101914492521} | train loss {'Reaction outcome loss': 0.8219885732446398, 'Total loss': 0.8219885732446398}
2022-11-18 02:17:20,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:20,731 INFO:     Epoch: 12
2022-11-18 02:17:21,516 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7840801362286914, 'Total loss': 0.7840801362286914} | train loss {'Reaction outcome loss': 0.8202879551722079, 'Total loss': 0.8202879551722079}
2022-11-18 02:17:21,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:21,516 INFO:     Epoch: 13
2022-11-18 02:17:22,325 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7957906506278298, 'Total loss': 0.7957906506278298} | train loss {'Reaction outcome loss': 0.8179821273502038, 'Total loss': 0.8179821273502038}
2022-11-18 02:17:22,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:22,326 INFO:     Epoch: 14
2022-11-18 02:17:23,122 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7991936640305952, 'Total loss': 0.7991936640305952} | train loss {'Reaction outcome loss': 0.8169411242008209, 'Total loss': 0.8169411242008209}
2022-11-18 02:17:23,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:23,123 INFO:     Epoch: 15
2022-11-18 02:17:23,895 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7837391312826764, 'Total loss': 0.7837391312826764} | train loss {'Reaction outcome loss': 0.8175220055239542, 'Total loss': 0.8175220055239542}
2022-11-18 02:17:23,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:23,896 INFO:     Epoch: 16
2022-11-18 02:17:24,698 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7832803265614943, 'Total loss': 0.7832803265614943} | train loss {'Reaction outcome loss': 0.8150859048171919, 'Total loss': 0.8150859048171919}
2022-11-18 02:17:24,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:24,698 INFO:     Epoch: 17
2022-11-18 02:17:25,468 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7887846204367551, 'Total loss': 0.7887846204367551} | train loss {'Reaction outcome loss': 0.8179273307323456, 'Total loss': 0.8179273307323456}
2022-11-18 02:17:25,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:25,469 INFO:     Epoch: 18
2022-11-18 02:17:26,264 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7872451001947577, 'Total loss': 0.7872451001947577} | train loss {'Reaction outcome loss': 0.8154833802155086, 'Total loss': 0.8154833802155086}
2022-11-18 02:17:26,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:26,264 INFO:     Epoch: 19
2022-11-18 02:17:27,032 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8190217207778584, 'Total loss': 0.8190217207778584} | train loss {'Reaction outcome loss': 0.8169123316297726, 'Total loss': 0.8169123316297726}
2022-11-18 02:17:27,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:27,032 INFO:     Epoch: 20
2022-11-18 02:17:27,801 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8066537590189413, 'Total loss': 0.8066537590189413} | train loss {'Reaction outcome loss': 0.8124212721172644, 'Total loss': 0.8124212721172644}
2022-11-18 02:17:27,801 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:27,801 INFO:     Epoch: 21
2022-11-18 02:17:28,575 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.785831443965435, 'Total loss': 0.785831443965435} | train loss {'Reaction outcome loss': 0.8127031755690672, 'Total loss': 0.8127031755690672}
2022-11-18 02:17:28,575 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:28,575 INFO:     Epoch: 22
2022-11-18 02:17:29,344 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7742673978209496, 'Total loss': 0.7742673978209496} | train loss {'Reaction outcome loss': 0.8191952900010713, 'Total loss': 0.8191952900010713}
2022-11-18 02:17:29,344 INFO:     Found new best model at epoch 22
2022-11-18 02:17:29,345 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:29,345 INFO:     Epoch: 23
2022-11-18 02:17:30,124 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7822909233244982, 'Total loss': 0.7822909233244982} | train loss {'Reaction outcome loss': 0.8124048672160323, 'Total loss': 0.8124048672160323}
2022-11-18 02:17:30,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:30,124 INFO:     Epoch: 24
2022-11-18 02:17:30,914 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7965491359884088, 'Total loss': 0.7965491359884088} | train loss {'Reaction outcome loss': 0.8117190829345158, 'Total loss': 0.8117190829345158}
2022-11-18 02:17:30,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:30,915 INFO:     Epoch: 25
2022-11-18 02:17:31,710 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7911608171733943, 'Total loss': 0.7911608171733943} | train loss {'Reaction outcome loss': 0.811926288872349, 'Total loss': 0.811926288872349}
2022-11-18 02:17:31,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:31,710 INFO:     Epoch: 26
2022-11-18 02:17:32,483 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8007289943369952, 'Total loss': 0.8007289943369952} | train loss {'Reaction outcome loss': 0.8118950706355426, 'Total loss': 0.8118950706355426}
2022-11-18 02:17:32,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:32,483 INFO:     Epoch: 27
2022-11-18 02:17:33,286 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7760897847739133, 'Total loss': 0.7760897847739133} | train loss {'Reaction outcome loss': 0.8119887737595305, 'Total loss': 0.8119887737595305}
2022-11-18 02:17:33,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:33,286 INFO:     Epoch: 28
2022-11-18 02:17:34,077 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7843324636871164, 'Total loss': 0.7843324636871164} | train loss {'Reaction outcome loss': 0.8130597985520654, 'Total loss': 0.8130597985520654}
2022-11-18 02:17:34,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:34,077 INFO:     Epoch: 29
2022-11-18 02:17:34,869 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8121828193014319, 'Total loss': 0.8121828193014319} | train loss {'Reaction outcome loss': 0.811564555460093, 'Total loss': 0.811564555460093}
2022-11-18 02:17:34,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:34,870 INFO:     Epoch: 30
2022-11-18 02:17:35,637 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7991797070611607, 'Total loss': 0.7991797070611607} | train loss {'Reaction outcome loss': 0.8064881169066137, 'Total loss': 0.8064881169066137}
2022-11-18 02:17:35,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:35,638 INFO:     Epoch: 31
2022-11-18 02:17:36,413 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7848004712299868, 'Total loss': 0.7848004712299868} | train loss {'Reaction outcome loss': 0.8080373563328568, 'Total loss': 0.8080373563328568}
2022-11-18 02:17:36,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:36,414 INFO:     Epoch: 32
2022-11-18 02:17:37,199 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7865003083239902, 'Total loss': 0.7865003083239902} | train loss {'Reaction outcome loss': 0.8127554883762281, 'Total loss': 0.8127554883762281}
2022-11-18 02:17:37,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:37,200 INFO:     Epoch: 33
2022-11-18 02:17:37,981 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7924884395165877, 'Total loss': 0.7924884395165877} | train loss {'Reaction outcome loss': 0.8115254022637192, 'Total loss': 0.8115254022637192}
2022-11-18 02:17:37,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:37,981 INFO:     Epoch: 34
2022-11-18 02:17:38,751 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7866996750235558, 'Total loss': 0.7866996750235558} | train loss {'Reaction outcome loss': 0.8065148561584706, 'Total loss': 0.8065148561584706}
2022-11-18 02:17:38,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:38,751 INFO:     Epoch: 35
2022-11-18 02:17:39,531 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8154955865307287, 'Total loss': 0.8154955865307287} | train loss {'Reaction outcome loss': 0.8105986024652209, 'Total loss': 0.8105986024652209}
2022-11-18 02:17:39,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:39,532 INFO:     Epoch: 36
2022-11-18 02:17:40,318 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8056025728583336, 'Total loss': 0.8056025728583336} | train loss {'Reaction outcome loss': 0.8149230673605082, 'Total loss': 0.8149230673605082}
2022-11-18 02:17:40,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:40,318 INFO:     Epoch: 37
2022-11-18 02:17:41,104 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7789596888152036, 'Total loss': 0.7789596888152036} | train loss {'Reaction outcome loss': 0.8109025399295651, 'Total loss': 0.8109025399295651}
2022-11-18 02:17:41,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:41,104 INFO:     Epoch: 38
2022-11-18 02:17:41,895 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7897894233465195, 'Total loss': 0.7897894233465195} | train loss {'Reaction outcome loss': 0.8077310627820541, 'Total loss': 0.8077310627820541}
2022-11-18 02:17:41,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:41,895 INFO:     Epoch: 39
2022-11-18 02:17:42,740 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7790149321610277, 'Total loss': 0.7790149321610277} | train loss {'Reaction outcome loss': 0.8124628830929191, 'Total loss': 0.8124628830929191}
2022-11-18 02:17:42,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:42,740 INFO:     Epoch: 40
2022-11-18 02:17:43,549 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.77446279742501, 'Total loss': 0.77446279742501} | train loss {'Reaction outcome loss': 0.8080248468992661, 'Total loss': 0.8080248468992661}
2022-11-18 02:17:43,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:43,549 INFO:     Epoch: 41
2022-11-18 02:17:44,339 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7812454788522287, 'Total loss': 0.7812454788522287} | train loss {'Reaction outcome loss': 0.8118080333787567, 'Total loss': 0.8118080333787567}
2022-11-18 02:17:44,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:44,339 INFO:     Epoch: 42
2022-11-18 02:17:45,116 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7723308488387953, 'Total loss': 0.7723308488387953} | train loss {'Reaction outcome loss': 0.8100281018383649, 'Total loss': 0.8100281018383649}
2022-11-18 02:17:45,116 INFO:     Found new best model at epoch 42
2022-11-18 02:17:45,117 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:45,117 INFO:     Epoch: 43
2022-11-18 02:17:45,896 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7640291147611358, 'Total loss': 0.7640291147611358} | train loss {'Reaction outcome loss': 0.8141114241006423, 'Total loss': 0.8141114241006423}
2022-11-18 02:17:45,896 INFO:     Found new best model at epoch 43
2022-11-18 02:17:45,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:45,897 INFO:     Epoch: 44
2022-11-18 02:17:46,710 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7707449014891278, 'Total loss': 0.7707449014891278} | train loss {'Reaction outcome loss': 0.8116878803895444, 'Total loss': 0.8116878803895444}
2022-11-18 02:17:46,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:46,710 INFO:     Epoch: 45
2022-11-18 02:17:47,507 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7886800237677314, 'Total loss': 0.7886800237677314} | train loss {'Reaction outcome loss': 0.8069249553339822, 'Total loss': 0.8069249553339822}
2022-11-18 02:17:47,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:47,508 INFO:     Epoch: 46
2022-11-18 02:17:48,341 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7768706415187229, 'Total loss': 0.7768706415187229} | train loss {'Reaction outcome loss': 0.8090929560515345, 'Total loss': 0.8090929560515345}
2022-11-18 02:17:48,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:48,342 INFO:     Epoch: 47
2022-11-18 02:17:49,163 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7761974802071397, 'Total loss': 0.7761974802071397} | train loss {'Reaction outcome loss': 0.8097968161106109, 'Total loss': 0.8097968161106109}
2022-11-18 02:17:49,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:49,163 INFO:     Epoch: 48
2022-11-18 02:17:49,934 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7866076671264388, 'Total loss': 0.7866076671264388} | train loss {'Reaction outcome loss': 0.8103244920166172, 'Total loss': 0.8103244920166172}
2022-11-18 02:17:49,934 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:49,935 INFO:     Epoch: 49
2022-11-18 02:17:50,708 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7736999013207175, 'Total loss': 0.7736999013207175} | train loss {'Reaction outcome loss': 0.8078877616901787, 'Total loss': 0.8078877616901787}
2022-11-18 02:17:50,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:50,708 INFO:     Epoch: 50
2022-11-18 02:17:51,476 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7881973710927096, 'Total loss': 0.7881973710927096} | train loss {'Reaction outcome loss': 0.8080638386765305, 'Total loss': 0.8080638386765305}
2022-11-18 02:17:51,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:51,476 INFO:     Epoch: 51
2022-11-18 02:17:52,250 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7860702520067041, 'Total loss': 0.7860702520067041} | train loss {'Reaction outcome loss': 0.8080043528761183, 'Total loss': 0.8080043528761183}
2022-11-18 02:17:52,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:52,250 INFO:     Epoch: 52
2022-11-18 02:17:53,024 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7825962941754948, 'Total loss': 0.7825962941754948} | train loss {'Reaction outcome loss': 0.8120021818851938, 'Total loss': 0.8120021818851938}
2022-11-18 02:17:53,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:53,024 INFO:     Epoch: 53
2022-11-18 02:17:53,804 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7649659656665542, 'Total loss': 0.7649659656665542} | train loss {'Reaction outcome loss': 0.8080232963270071, 'Total loss': 0.8080232963270071}
2022-11-18 02:17:53,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:53,805 INFO:     Epoch: 54
2022-11-18 02:17:54,559 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8024927242235704, 'Total loss': 0.8024927242235704} | train loss {'Reaction outcome loss': 0.8068387012092435, 'Total loss': 0.8068387012092435}
2022-11-18 02:17:54,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:54,561 INFO:     Epoch: 55
2022-11-18 02:17:55,372 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7885618819431826, 'Total loss': 0.7885618819431826} | train loss {'Reaction outcome loss': 0.8137922404980172, 'Total loss': 0.8137922404980172}
2022-11-18 02:17:55,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:55,372 INFO:     Epoch: 56
2022-11-18 02:17:56,160 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7722717835144564, 'Total loss': 0.7722717835144564} | train loss {'Reaction outcome loss': 0.8095295554521132, 'Total loss': 0.8095295554521132}
2022-11-18 02:17:56,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:56,161 INFO:     Epoch: 57
2022-11-18 02:17:56,918 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8009590493007139, 'Total loss': 0.8009590493007139} | train loss {'Reaction outcome loss': 0.8103252834203292, 'Total loss': 0.8103252834203292}
2022-11-18 02:17:56,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:56,919 INFO:     Epoch: 58
2022-11-18 02:17:57,689 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7635267024690454, 'Total loss': 0.7635267024690454} | train loss {'Reaction outcome loss': 0.8101423933797953, 'Total loss': 0.8101423933797953}
2022-11-18 02:17:57,689 INFO:     Found new best model at epoch 58
2022-11-18 02:17:57,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:57,690 INFO:     Epoch: 59
2022-11-18 02:17:58,469 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7888864989985119, 'Total loss': 0.7888864989985119} | train loss {'Reaction outcome loss': 0.8083242966204274, 'Total loss': 0.8083242966204274}
2022-11-18 02:17:58,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:58,470 INFO:     Epoch: 60
2022-11-18 02:17:59,256 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7635992833159186, 'Total loss': 0.7635992833159186} | train loss {'Reaction outcome loss': 0.8099136672457871, 'Total loss': 0.8099136672457871}
2022-11-18 02:17:59,256 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:17:59,256 INFO:     Epoch: 61
2022-11-18 02:18:00,016 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7895233048634096, 'Total loss': 0.7895233048634096} | train loss {'Reaction outcome loss': 0.810974165249844, 'Total loss': 0.810974165249844}
2022-11-18 02:18:00,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:00,017 INFO:     Epoch: 62
2022-11-18 02:18:00,808 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.766526342115619, 'Total loss': 0.766526342115619} | train loss {'Reaction outcome loss': 0.807063410111836, 'Total loss': 0.807063410111836}
2022-11-18 02:18:00,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:00,808 INFO:     Epoch: 63
2022-11-18 02:18:01,586 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7708627811887048, 'Total loss': 0.7708627811887048} | train loss {'Reaction outcome loss': 0.8075893601592706, 'Total loss': 0.8075893601592706}
2022-11-18 02:18:01,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:01,586 INFO:     Epoch: 64
2022-11-18 02:18:02,327 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7630429460921071, 'Total loss': 0.7630429460921071} | train loss {'Reaction outcome loss': 0.8072036665313098, 'Total loss': 0.8072036665313098}
2022-11-18 02:18:02,327 INFO:     Found new best model at epoch 64
2022-11-18 02:18:02,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:02,328 INFO:     Epoch: 65
2022-11-18 02:18:03,091 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7700130986896428, 'Total loss': 0.7700130986896428} | train loss {'Reaction outcome loss': 0.8062998702331465, 'Total loss': 0.8062998702331465}
2022-11-18 02:18:03,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:03,092 INFO:     Epoch: 66
2022-11-18 02:18:03,877 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7951725071126764, 'Total loss': 0.7951725071126764} | train loss {'Reaction outcome loss': 0.8093849623689846, 'Total loss': 0.8093849623689846}
2022-11-18 02:18:03,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:03,878 INFO:     Epoch: 67
2022-11-18 02:18:04,656 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7751940387216482, 'Total loss': 0.7751940387216482} | train loss {'Reaction outcome loss': 0.8174748098363682, 'Total loss': 0.8174748098363682}
2022-11-18 02:18:04,656 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:04,656 INFO:     Epoch: 68
2022-11-18 02:18:05,440 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7827502021735365, 'Total loss': 0.7827502021735365} | train loss {'Reaction outcome loss': 0.8059177077546411, 'Total loss': 0.8059177077546411}
2022-11-18 02:18:05,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:05,441 INFO:     Epoch: 69
2022-11-18 02:18:06,223 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8151625069704923, 'Total loss': 0.8151625069704923} | train loss {'Reaction outcome loss': 0.8077277619011548, 'Total loss': 0.8077277619011548}
2022-11-18 02:18:06,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:06,223 INFO:     Epoch: 70
2022-11-18 02:18:06,987 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7653147695078091, 'Total loss': 0.7653147695078091} | train loss {'Reaction outcome loss': 0.8134454446179527, 'Total loss': 0.8134454446179527}
2022-11-18 02:18:06,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:06,988 INFO:     Epoch: 71
2022-11-18 02:18:07,769 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8046806678175926, 'Total loss': 0.8046806678175926} | train loss {'Reaction outcome loss': 0.8128560072305251, 'Total loss': 0.8128560072305251}
2022-11-18 02:18:07,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:07,770 INFO:     Epoch: 72
2022-11-18 02:18:08,539 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7652983164245432, 'Total loss': 0.7652983164245432} | train loss {'Reaction outcome loss': 0.8112567789700567, 'Total loss': 0.8112567789700567}
2022-11-18 02:18:08,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:08,539 INFO:     Epoch: 73
2022-11-18 02:18:09,315 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7759315317327325, 'Total loss': 0.7759315317327325} | train loss {'Reaction outcome loss': 0.8070583598954337, 'Total loss': 0.8070583598954337}
2022-11-18 02:18:09,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:09,316 INFO:     Epoch: 74
2022-11-18 02:18:10,092 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7988635850223628, 'Total loss': 0.7988635850223628} | train loss {'Reaction outcome loss': 0.8158310735712246, 'Total loss': 0.8158310735712246}
2022-11-18 02:18:10,093 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:10,093 INFO:     Epoch: 75
2022-11-18 02:18:10,885 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7870371748100627, 'Total loss': 0.7870371748100627} | train loss {'Reaction outcome loss': 0.8107855852769346, 'Total loss': 0.8107855852769346}
2022-11-18 02:18:10,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:10,885 INFO:     Epoch: 76
2022-11-18 02:18:11,658 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7751918895678087, 'Total loss': 0.7751918895678087} | train loss {'Reaction outcome loss': 0.809087291907291, 'Total loss': 0.809087291907291}
2022-11-18 02:18:11,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:11,658 INFO:     Epoch: 77
2022-11-18 02:18:12,421 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7847199094566432, 'Total loss': 0.7847199094566432} | train loss {'Reaction outcome loss': 0.8094699218565103, 'Total loss': 0.8094699218565103}
2022-11-18 02:18:12,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:12,421 INFO:     Epoch: 78
2022-11-18 02:18:13,222 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7969294441017237, 'Total loss': 0.7969294441017237} | train loss {'Reaction outcome loss': 0.8103932754117615, 'Total loss': 0.8103932754117615}
2022-11-18 02:18:13,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:13,222 INFO:     Epoch: 79
2022-11-18 02:18:13,999 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7778763147917661, 'Total loss': 0.7778763147917661} | train loss {'Reaction outcome loss': 0.8094901499699573, 'Total loss': 0.8094901499699573}
2022-11-18 02:18:13,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:13,999 INFO:     Epoch: 80
2022-11-18 02:18:14,773 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8022042201323942, 'Total loss': 0.8022042201323942} | train loss {'Reaction outcome loss': 0.8094287294514325, 'Total loss': 0.8094287294514325}
2022-11-18 02:18:14,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:14,773 INFO:     Epoch: 81
2022-11-18 02:18:15,548 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7830955331975763, 'Total loss': 0.7830955331975763} | train loss {'Reaction outcome loss': 0.8125429507420987, 'Total loss': 0.8125429507420987}
2022-11-18 02:18:15,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:15,548 INFO:     Epoch: 82
2022-11-18 02:18:16,318 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7830622975121845, 'Total loss': 0.7830622975121845} | train loss {'Reaction outcome loss': 0.8091141746968639, 'Total loss': 0.8091141746968639}
2022-11-18 02:18:16,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:16,318 INFO:     Epoch: 83
2022-11-18 02:18:17,088 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8001909073103558, 'Total loss': 0.8001909073103558} | train loss {'Reaction outcome loss': 0.8086512813762743, 'Total loss': 0.8086512813762743}
2022-11-18 02:18:17,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:17,089 INFO:     Epoch: 84
2022-11-18 02:18:17,870 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7784120684320276, 'Total loss': 0.7784120684320276} | train loss {'Reaction outcome loss': 0.8119208529287455, 'Total loss': 0.8119208529287455}
2022-11-18 02:18:17,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:17,870 INFO:     Epoch: 85
2022-11-18 02:18:18,624 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7894318533891981, 'Total loss': 0.7894318533891981} | train loss {'Reaction outcome loss': 0.8092660075547744, 'Total loss': 0.8092660075547744}
2022-11-18 02:18:18,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:18,625 INFO:     Epoch: 86
2022-11-18 02:18:19,398 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7837495587088845, 'Total loss': 0.7837495587088845} | train loss {'Reaction outcome loss': 0.8116061081691665, 'Total loss': 0.8116061081691665}
2022-11-18 02:18:19,399 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:19,399 INFO:     Epoch: 87
2022-11-18 02:18:20,184 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7829521826722405, 'Total loss': 0.7829521826722405} | train loss {'Reaction outcome loss': 0.8076239341375779, 'Total loss': 0.8076239341375779}
2022-11-18 02:18:20,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:20,184 INFO:     Epoch: 88
2022-11-18 02:18:20,947 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7994172850793059, 'Total loss': 0.7994172850793059} | train loss {'Reaction outcome loss': 0.8096749167661278, 'Total loss': 0.8096749167661278}
2022-11-18 02:18:20,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:20,948 INFO:     Epoch: 89
2022-11-18 02:18:21,738 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.791127622127533, 'Total loss': 0.791127622127533} | train loss {'Reaction outcome loss': 0.8112809220138861, 'Total loss': 0.8112809220138861}
2022-11-18 02:18:21,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:21,738 INFO:     Epoch: 90
2022-11-18 02:18:22,519 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7726293571970679, 'Total loss': 0.7726293571970679} | train loss {'Reaction outcome loss': 0.8105585444946678, 'Total loss': 0.8105585444946678}
2022-11-18 02:18:22,520 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:22,520 INFO:     Epoch: 91
2022-11-18 02:18:23,305 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7707009037787264, 'Total loss': 0.7707009037787264} | train loss {'Reaction outcome loss': 0.8111019523776307, 'Total loss': 0.8111019523776307}
2022-11-18 02:18:23,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:23,305 INFO:     Epoch: 92
2022-11-18 02:18:24,073 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7893418100747195, 'Total loss': 0.7893418100747195} | train loss {'Reaction outcome loss': 0.8106226231370653, 'Total loss': 0.8106226231370653}
2022-11-18 02:18:24,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:24,073 INFO:     Epoch: 93
2022-11-18 02:18:24,827 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8002301197160374, 'Total loss': 0.8002301197160374} | train loss {'Reaction outcome loss': 0.8077992563344994, 'Total loss': 0.8077992563344994}
2022-11-18 02:18:24,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:24,827 INFO:     Epoch: 94
2022-11-18 02:18:25,599 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.794281702149998, 'Total loss': 0.794281702149998} | train loss {'Reaction outcome loss': 0.813562853725589, 'Total loss': 0.813562853725589}
2022-11-18 02:18:25,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:25,600 INFO:     Epoch: 95
2022-11-18 02:18:26,394 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7724580825729803, 'Total loss': 0.7724580825729803} | train loss {'Reaction outcome loss': 0.8071860262325832, 'Total loss': 0.8071860262325832}
2022-11-18 02:18:26,394 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:26,394 INFO:     Epoch: 96
2022-11-18 02:18:27,177 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7834188165989789, 'Total loss': 0.7834188165989789} | train loss {'Reaction outcome loss': 0.8120167610596637, 'Total loss': 0.8120167610596637}
2022-11-18 02:18:27,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:27,178 INFO:     Epoch: 97
2022-11-18 02:18:27,995 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7884495129639452, 'Total loss': 0.7884495129639452} | train loss {'Reaction outcome loss': 0.8103679183794528, 'Total loss': 0.8103679183794528}
2022-11-18 02:18:27,995 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:27,995 INFO:     Epoch: 98
2022-11-18 02:18:28,826 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7891567356207154, 'Total loss': 0.7891567356207154} | train loss {'Reaction outcome loss': 0.8064685939526072, 'Total loss': 0.8064685939526072}
2022-11-18 02:18:28,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:28,826 INFO:     Epoch: 99
2022-11-18 02:18:29,649 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7774931314316663, 'Total loss': 0.7774931314316663} | train loss {'Reaction outcome loss': 0.8079001781891804, 'Total loss': 0.8079001781891804}
2022-11-18 02:18:29,649 INFO:     Best model found after epoch 65 of 100.
2022-11-18 02:18:29,649 INFO:   Done with stage: TRAINING
2022-11-18 02:18:29,649 INFO:   Starting stage: EVALUATION
2022-11-18 02:18:29,780 INFO:   Done with stage: EVALUATION
2022-11-18 02:18:29,780 INFO:   Leaving out SEQ value Fold_3
2022-11-18 02:18:29,794 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-18 02:18:29,794 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:18:30,456 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:18:30,456 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:18:30,526 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:18:30,526 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:18:30,526 INFO:     No hyperparam tuning for this model
2022-11-18 02:18:30,526 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:18:30,526 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:18:30,527 INFO:     None feature selector for col prot
2022-11-18 02:18:30,527 INFO:     None feature selector for col prot
2022-11-18 02:18:30,527 INFO:     None feature selector for col prot
2022-11-18 02:18:30,528 INFO:     None feature selector for col chem
2022-11-18 02:18:30,528 INFO:     None feature selector for col chem
2022-11-18 02:18:30,528 INFO:     None feature selector for col chem
2022-11-18 02:18:30,528 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:18:30,528 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:18:30,529 INFO:     Number of params in model 168571
2022-11-18 02:18:30,533 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:18:30,533 INFO:   Starting stage: TRAINING
2022-11-18 02:18:30,590 INFO:     Val loss before train {'Reaction outcome loss': 1.0224860643231592, 'Total loss': 1.0224860643231592}
2022-11-18 02:18:30,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:30,590 INFO:     Epoch: 0
2022-11-18 02:18:31,366 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8565677494503731, 'Total loss': 0.8565677494503731} | train loss {'Reaction outcome loss': 0.8729868073199616, 'Total loss': 0.8729868073199616}
2022-11-18 02:18:31,367 INFO:     Found new best model at epoch 0
2022-11-18 02:18:31,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:31,367 INFO:     Epoch: 1
2022-11-18 02:18:32,129 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.862150076516839, 'Total loss': 0.862150076516839} | train loss {'Reaction outcome loss': 0.8445856130269708, 'Total loss': 0.8445856130269708}
2022-11-18 02:18:32,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:32,129 INFO:     Epoch: 2
2022-11-18 02:18:32,923 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8430036084596501, 'Total loss': 0.8430036084596501} | train loss {'Reaction outcome loss': 0.8327403483820743, 'Total loss': 0.8327403483820743}
2022-11-18 02:18:32,923 INFO:     Found new best model at epoch 2
2022-11-18 02:18:32,924 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:32,924 INFO:     Epoch: 3
2022-11-18 02:18:33,754 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8524056388888248, 'Total loss': 0.8524056388888248} | train loss {'Reaction outcome loss': 0.8325063973420956, 'Total loss': 0.8325063973420956}
2022-11-18 02:18:33,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:33,754 INFO:     Epoch: 4
2022-11-18 02:18:34,576 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8286153909771942, 'Total loss': 0.8286153909771942} | train loss {'Reaction outcome loss': 0.8293845720711301, 'Total loss': 0.8293845720711301}
2022-11-18 02:18:34,576 INFO:     Found new best model at epoch 4
2022-11-18 02:18:34,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:34,577 INFO:     Epoch: 5
2022-11-18 02:18:35,383 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8308437438898308, 'Total loss': 0.8308437438898308} | train loss {'Reaction outcome loss': 0.8239136545873079, 'Total loss': 0.8239136545873079}
2022-11-18 02:18:35,383 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:35,383 INFO:     Epoch: 6
2022-11-18 02:18:36,190 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8276043582794278, 'Total loss': 0.8276043582794278} | train loss {'Reaction outcome loss': 0.824240825398535, 'Total loss': 0.824240825398535}
2022-11-18 02:18:36,190 INFO:     Found new best model at epoch 6
2022-11-18 02:18:36,191 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:36,191 INFO:     Epoch: 7
2022-11-18 02:18:37,014 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8672598323156667, 'Total loss': 0.8672598323156667} | train loss {'Reaction outcome loss': 0.8150669377846796, 'Total loss': 0.8150669377846796}
2022-11-18 02:18:37,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:37,015 INFO:     Epoch: 8
2022-11-18 02:18:37,802 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8227675002674724, 'Total loss': 0.8227675002674724} | train loss {'Reaction outcome loss': 0.8215512417134692, 'Total loss': 0.8215512417134692}
2022-11-18 02:18:37,803 INFO:     Found new best model at epoch 8
2022-11-18 02:18:37,804 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:37,805 INFO:     Epoch: 9
2022-11-18 02:18:38,603 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8213096926378649, 'Total loss': 0.8213096926378649} | train loss {'Reaction outcome loss': 0.818116017663088, 'Total loss': 0.818116017663088}
2022-11-18 02:18:38,604 INFO:     Found new best model at epoch 9
2022-11-18 02:18:38,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:38,605 INFO:     Epoch: 10
2022-11-18 02:18:39,410 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8258621623349744, 'Total loss': 0.8258621623349744} | train loss {'Reaction outcome loss': 0.8103186584642676, 'Total loss': 0.8103186584642676}
2022-11-18 02:18:39,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:39,410 INFO:     Epoch: 11
2022-11-18 02:18:40,174 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8204576678054277, 'Total loss': 0.8204576678054277} | train loss {'Reaction outcome loss': 0.8181563807559795, 'Total loss': 0.8181563807559795}
2022-11-18 02:18:40,174 INFO:     Found new best model at epoch 11
2022-11-18 02:18:40,175 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:40,175 INFO:     Epoch: 12
2022-11-18 02:18:40,945 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8267396889453711, 'Total loss': 0.8267396889453711} | train loss {'Reaction outcome loss': 0.8162302666755973, 'Total loss': 0.8162302666755973}
2022-11-18 02:18:40,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:40,945 INFO:     Epoch: 13
2022-11-18 02:18:41,736 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8272071986697441, 'Total loss': 0.8272071986697441} | train loss {'Reaction outcome loss': 0.8160632974544509, 'Total loss': 0.8160632974544509}
2022-11-18 02:18:41,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:41,737 INFO:     Epoch: 14
2022-11-18 02:18:42,529 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.827614832063054, 'Total loss': 0.827614832063054} | train loss {'Reaction outcome loss': 0.821716921007047, 'Total loss': 0.821716921007047}
2022-11-18 02:18:42,529 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:42,529 INFO:     Epoch: 15
2022-11-18 02:18:43,339 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8223629288895186, 'Total loss': 0.8223629288895186} | train loss {'Reaction outcome loss': 0.8121827752863775, 'Total loss': 0.8121827752863775}
2022-11-18 02:18:43,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:43,339 INFO:     Epoch: 16
2022-11-18 02:18:44,147 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8177702662556671, 'Total loss': 0.8177702662556671} | train loss {'Reaction outcome loss': 0.8141887019403645, 'Total loss': 0.8141887019403645}
2022-11-18 02:18:44,147 INFO:     Found new best model at epoch 16
2022-11-18 02:18:44,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:44,148 INFO:     Epoch: 17
2022-11-18 02:18:44,970 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8352841436862946, 'Total loss': 0.8352841436862946} | train loss {'Reaction outcome loss': 0.8110121168562623, 'Total loss': 0.8110121168562623}
2022-11-18 02:18:44,970 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:44,970 INFO:     Epoch: 18
2022-11-18 02:18:45,780 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8302165852036587, 'Total loss': 0.8302165852036587} | train loss {'Reaction outcome loss': 0.8193571668912153, 'Total loss': 0.8193571668912153}
2022-11-18 02:18:45,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:45,780 INFO:     Epoch: 19
2022-11-18 02:18:46,566 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8135675961195037, 'Total loss': 0.8135675961195037} | train loss {'Reaction outcome loss': 0.8168913171183868, 'Total loss': 0.8168913171183868}
2022-11-18 02:18:46,566 INFO:     Found new best model at epoch 19
2022-11-18 02:18:46,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:46,567 INFO:     Epoch: 20
2022-11-18 02:18:47,325 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8376551540785058, 'Total loss': 0.8376551540785058} | train loss {'Reaction outcome loss': 0.814920645268237, 'Total loss': 0.814920645268237}
2022-11-18 02:18:47,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:47,325 INFO:     Epoch: 21
2022-11-18 02:18:48,138 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8206941811151283, 'Total loss': 0.8206941811151283} | train loss {'Reaction outcome loss': 0.8162265121936798, 'Total loss': 0.8162265121936798}
2022-11-18 02:18:48,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:48,138 INFO:     Epoch: 22
2022-11-18 02:18:48,977 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8251628439093746, 'Total loss': 0.8251628439093746} | train loss {'Reaction outcome loss': 0.8154582301857042, 'Total loss': 0.8154582301857042}
2022-11-18 02:18:48,977 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:48,977 INFO:     Epoch: 23
2022-11-18 02:18:49,787 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8159160849659942, 'Total loss': 0.8159160849659942} | train loss {'Reaction outcome loss': 0.8171570437853454, 'Total loss': 0.8171570437853454}
2022-11-18 02:18:49,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:49,788 INFO:     Epoch: 24
2022-11-18 02:18:50,574 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8214513056500014, 'Total loss': 0.8214513056500014} | train loss {'Reaction outcome loss': 0.8112752863862476, 'Total loss': 0.8112752863862476}
2022-11-18 02:18:50,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:50,576 INFO:     Epoch: 25
2022-11-18 02:18:51,377 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8175274729728699, 'Total loss': 0.8175274729728699} | train loss {'Reaction outcome loss': 0.8097598436670225, 'Total loss': 0.8097598436670225}
2022-11-18 02:18:51,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:51,378 INFO:     Epoch: 26
2022-11-18 02:18:52,195 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8226434553778449, 'Total loss': 0.8226434553778449} | train loss {'Reaction outcome loss': 0.812359664650237, 'Total loss': 0.812359664650237}
2022-11-18 02:18:52,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:52,196 INFO:     Epoch: 27
2022-11-18 02:18:52,990 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.823180005993954, 'Total loss': 0.823180005993954} | train loss {'Reaction outcome loss': 0.8136641936468296, 'Total loss': 0.8136641936468296}
2022-11-18 02:18:52,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:52,991 INFO:     Epoch: 28
2022-11-18 02:18:53,826 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8275247819201891, 'Total loss': 0.8275247819201891} | train loss {'Reaction outcome loss': 0.8127983137965202, 'Total loss': 0.8127983137965202}
2022-11-18 02:18:53,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:53,827 INFO:     Epoch: 29
2022-11-18 02:18:54,631 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8132319471170736, 'Total loss': 0.8132319471170736} | train loss {'Reaction outcome loss': 0.817059794898893, 'Total loss': 0.817059794898893}
2022-11-18 02:18:54,631 INFO:     Found new best model at epoch 29
2022-11-18 02:18:54,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:54,632 INFO:     Epoch: 30
2022-11-18 02:18:55,446 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.815771025973697, 'Total loss': 0.815771025973697} | train loss {'Reaction outcome loss': 0.8127462441315416, 'Total loss': 0.8127462441315416}
2022-11-18 02:18:55,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:55,447 INFO:     Epoch: 31
2022-11-18 02:18:56,258 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8184219453223917, 'Total loss': 0.8184219453223917} | train loss {'Reaction outcome loss': 0.814387952450846, 'Total loss': 0.814387952450846}
2022-11-18 02:18:56,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:56,258 INFO:     Epoch: 32
2022-11-18 02:18:57,070 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8186942290428073, 'Total loss': 0.8186942290428073} | train loss {'Reaction outcome loss': 0.8105014521078985, 'Total loss': 0.8105014521078985}
2022-11-18 02:18:57,071 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:57,072 INFO:     Epoch: 33
2022-11-18 02:18:57,897 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8222907046939052, 'Total loss': 0.8222907046939052} | train loss {'Reaction outcome loss': 0.8144050019442058, 'Total loss': 0.8144050019442058}
2022-11-18 02:18:57,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:57,897 INFO:     Epoch: 34
2022-11-18 02:18:58,692 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8260147668594537, 'Total loss': 0.8260147668594537} | train loss {'Reaction outcome loss': 0.8093938125205822, 'Total loss': 0.8093938125205822}
2022-11-18 02:18:58,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:58,693 INFO:     Epoch: 35
2022-11-18 02:18:59,522 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8191462339356889, 'Total loss': 0.8191462339356889} | train loss {'Reaction outcome loss': 0.8095924904356238, 'Total loss': 0.8095924904356238}
2022-11-18 02:18:59,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:18:59,522 INFO:     Epoch: 36
2022-11-18 02:19:00,323 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8461340897998144, 'Total loss': 0.8461340897998144} | train loss {'Reaction outcome loss': 0.8081552817440424, 'Total loss': 0.8081552817440424}
2022-11-18 02:19:00,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:00,324 INFO:     Epoch: 37
2022-11-18 02:19:01,128 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8133252609607785, 'Total loss': 0.8133252609607785} | train loss {'Reaction outcome loss': 0.8112248653759722, 'Total loss': 0.8112248653759722}
2022-11-18 02:19:01,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:01,129 INFO:     Epoch: 38
2022-11-18 02:19:01,887 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8205351961213488, 'Total loss': 0.8205351961213488} | train loss {'Reaction outcome loss': 0.8112439326331263, 'Total loss': 0.8112439326331263}
2022-11-18 02:19:01,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:01,887 INFO:     Epoch: 39
2022-11-18 02:19:02,697 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8188143899274427, 'Total loss': 0.8188143899274427} | train loss {'Reaction outcome loss': 0.8141347941805105, 'Total loss': 0.8141347941805105}
2022-11-18 02:19:02,697 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:02,697 INFO:     Epoch: 40
2022-11-18 02:19:03,530 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8275783755058466, 'Total loss': 0.8275783755058466} | train loss {'Reaction outcome loss': 0.8108601063245633, 'Total loss': 0.8108601063245633}
2022-11-18 02:19:03,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:03,531 INFO:     Epoch: 41
2022-11-18 02:19:04,349 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8293392069117967, 'Total loss': 0.8293392069117967} | train loss {'Reaction outcome loss': 0.8063912955952472, 'Total loss': 0.8063912955952472}
2022-11-18 02:19:04,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:04,349 INFO:     Epoch: 42
2022-11-18 02:19:05,152 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8211567762286164, 'Total loss': 0.8211567762286164} | train loss {'Reaction outcome loss': 0.809471145821888, 'Total loss': 0.809471145821888}
2022-11-18 02:19:05,152 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:05,152 INFO:     Epoch: 43
2022-11-18 02:19:05,943 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8284452467463738, 'Total loss': 0.8284452467463738} | train loss {'Reaction outcome loss': 0.807547858259717, 'Total loss': 0.807547858259717}
2022-11-18 02:19:05,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:05,943 INFO:     Epoch: 44
2022-11-18 02:19:06,736 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8207055344138035, 'Total loss': 0.8207055344138035} | train loss {'Reaction outcome loss': 0.8081240526965408, 'Total loss': 0.8081240526965408}
2022-11-18 02:19:06,737 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:06,737 INFO:     Epoch: 45
2022-11-18 02:19:07,509 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8314448380193045, 'Total loss': 0.8314448380193045} | train loss {'Reaction outcome loss': 0.8051195077475954, 'Total loss': 0.8051195077475954}
2022-11-18 02:19:07,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:07,510 INFO:     Epoch: 46
2022-11-18 02:19:08,271 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8233932450760243, 'Total loss': 0.8233932450760243} | train loss {'Reaction outcome loss': 0.8102007604769019, 'Total loss': 0.8102007604769019}
2022-11-18 02:19:08,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:08,271 INFO:     Epoch: 47
2022-11-18 02:19:09,039 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8170696559340455, 'Total loss': 0.8170696559340455} | train loss {'Reaction outcome loss': 0.809086130473946, 'Total loss': 0.809086130473946}
2022-11-18 02:19:09,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:09,039 INFO:     Epoch: 48
2022-11-18 02:19:09,848 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8331158438394236, 'Total loss': 0.8331158438394236} | train loss {'Reaction outcome loss': 0.8077032365759865, 'Total loss': 0.8077032365759865}
2022-11-18 02:19:09,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:09,849 INFO:     Epoch: 49
2022-11-18 02:19:10,610 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8242825574653093, 'Total loss': 0.8242825574653093} | train loss {'Reaction outcome loss': 0.8098950894152532, 'Total loss': 0.8098950894152532}
2022-11-18 02:19:10,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:10,610 INFO:     Epoch: 50
2022-11-18 02:19:11,360 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.840162385341733, 'Total loss': 0.840162385341733} | train loss {'Reaction outcome loss': 0.8047189099378274, 'Total loss': 0.8047189099378274}
2022-11-18 02:19:11,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:11,360 INFO:     Epoch: 51
2022-11-18 02:19:12,139 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.827704056057819, 'Total loss': 0.827704056057819} | train loss {'Reaction outcome loss': 0.8046825013932635, 'Total loss': 0.8046825013932635}
2022-11-18 02:19:12,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:12,139 INFO:     Epoch: 52
2022-11-18 02:19:12,903 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8169142160304758, 'Total loss': 0.8169142160304758} | train loss {'Reaction outcome loss': 0.8064094632863998, 'Total loss': 0.8064094632863998}
2022-11-18 02:19:12,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:12,903 INFO:     Epoch: 53
2022-11-18 02:19:13,706 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8151347325291745, 'Total loss': 0.8151347325291745} | train loss {'Reaction outcome loss': 0.8036209798005761, 'Total loss': 0.8036209798005761}
2022-11-18 02:19:13,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:13,706 INFO:     Epoch: 54
2022-11-18 02:19:14,473 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8091130547745283, 'Total loss': 0.8091130547745283} | train loss {'Reaction outcome loss': 0.80774781559823, 'Total loss': 0.80774781559823}
2022-11-18 02:19:14,473 INFO:     Found new best model at epoch 54
2022-11-18 02:19:14,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:14,474 INFO:     Epoch: 55
2022-11-18 02:19:15,240 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8186055054498274, 'Total loss': 0.8186055054498274} | train loss {'Reaction outcome loss': 0.8091811872408038, 'Total loss': 0.8091811872408038}
2022-11-18 02:19:15,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:15,240 INFO:     Epoch: 56
2022-11-18 02:19:16,002 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.827764863191649, 'Total loss': 0.827764863191649} | train loss {'Reaction outcome loss': 0.8078610065286277, 'Total loss': 0.8078610065286277}
2022-11-18 02:19:16,002 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:16,002 INFO:     Epoch: 57
2022-11-18 02:19:16,786 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8123930664949639, 'Total loss': 0.8123930664949639} | train loss {'Reaction outcome loss': 0.8039459117123338, 'Total loss': 0.8039459117123338}
2022-11-18 02:19:16,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:16,786 INFO:     Epoch: 58
2022-11-18 02:19:17,542 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8256177624990774, 'Total loss': 0.8256177624990774} | train loss {'Reaction outcome loss': 0.8020772097296403, 'Total loss': 0.8020772097296403}
2022-11-18 02:19:17,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:17,542 INFO:     Epoch: 59
2022-11-18 02:19:18,330 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8098032322040823, 'Total loss': 0.8098032322040823} | train loss {'Reaction outcome loss': 0.7995542314697485, 'Total loss': 0.7995542314697485}
2022-11-18 02:19:18,330 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:18,330 INFO:     Epoch: 60
2022-11-18 02:19:19,112 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8162719420222349, 'Total loss': 0.8162719420222349} | train loss {'Reaction outcome loss': 0.8093422146849945, 'Total loss': 0.8093422146849945}
2022-11-18 02:19:19,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:19,112 INFO:     Epoch: 61
2022-11-18 02:19:19,883 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8071919596472452, 'Total loss': 0.8071919596472452} | train loss {'Reaction outcome loss': 0.8073199332737532, 'Total loss': 0.8073199332737532}
2022-11-18 02:19:19,883 INFO:     Found new best model at epoch 61
2022-11-18 02:19:19,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:19,884 INFO:     Epoch: 62
2022-11-18 02:19:20,639 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8281191712202027, 'Total loss': 0.8281191712202027} | train loss {'Reaction outcome loss': 0.8029702028534451, 'Total loss': 0.8029702028534451}
2022-11-18 02:19:20,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:20,640 INFO:     Epoch: 63
2022-11-18 02:19:21,425 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8209037954031035, 'Total loss': 0.8209037954031035} | train loss {'Reaction outcome loss': 0.8056608127033125, 'Total loss': 0.8056608127033125}
2022-11-18 02:19:21,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:21,429 INFO:     Epoch: 64
2022-11-18 02:19:22,195 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8185636858607448, 'Total loss': 0.8185636858607448} | train loss {'Reaction outcome loss': 0.811124039233708, 'Total loss': 0.811124039233708}
2022-11-18 02:19:22,195 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:22,195 INFO:     Epoch: 65
2022-11-18 02:19:22,998 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8104624429414439, 'Total loss': 0.8104624429414439} | train loss {'Reaction outcome loss': 0.8048971884074758, 'Total loss': 0.8048971884074758}
2022-11-18 02:19:22,998 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:22,998 INFO:     Epoch: 66
2022-11-18 02:19:23,809 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8265109845372134, 'Total loss': 0.8265109845372134} | train loss {'Reaction outcome loss': 0.8047272599622851, 'Total loss': 0.8047272599622851}
2022-11-18 02:19:23,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:23,810 INFO:     Epoch: 67
2022-11-18 02:19:24,583 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8119840836802195, 'Total loss': 0.8119840836802195} | train loss {'Reaction outcome loss': 0.8089069687440748, 'Total loss': 0.8089069687440748}
2022-11-18 02:19:24,583 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:24,583 INFO:     Epoch: 68
2022-11-18 02:19:25,331 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8213096323401429, 'Total loss': 0.8213096323401429} | train loss {'Reaction outcome loss': 0.8059823952737402, 'Total loss': 0.8059823952737402}
2022-11-18 02:19:25,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:25,332 INFO:     Epoch: 69
2022-11-18 02:19:26,095 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8223475675250209, 'Total loss': 0.8223475675250209} | train loss {'Reaction outcome loss': 0.8048943152926007, 'Total loss': 0.8048943152926007}
2022-11-18 02:19:26,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:26,095 INFO:     Epoch: 70
2022-11-18 02:19:26,849 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8182768177154452, 'Total loss': 0.8182768177154452} | train loss {'Reaction outcome loss': 0.8091841495183648, 'Total loss': 0.8091841495183648}
2022-11-18 02:19:26,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:26,849 INFO:     Epoch: 71
2022-11-18 02:19:27,624 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8054291266341542, 'Total loss': 0.8054291266341542} | train loss {'Reaction outcome loss': 0.8031591538523064, 'Total loss': 0.8031591538523064}
2022-11-18 02:19:27,624 INFO:     Found new best model at epoch 71
2022-11-18 02:19:27,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:27,625 INFO:     Epoch: 72
2022-11-18 02:19:28,374 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8088607989078345, 'Total loss': 0.8088607989078345} | train loss {'Reaction outcome loss': 0.8051917921812808, 'Total loss': 0.8051917921812808}
2022-11-18 02:19:28,374 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:28,374 INFO:     Epoch: 73
2022-11-18 02:19:29,149 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8082354519256326, 'Total loss': 0.8082354519256326} | train loss {'Reaction outcome loss': 0.8038487962034883, 'Total loss': 0.8038487962034883}
2022-11-18 02:19:29,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:29,149 INFO:     Epoch: 74
2022-11-18 02:19:29,952 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8132177660631579, 'Total loss': 0.8132177660631579} | train loss {'Reaction outcome loss': 0.8011604570707337, 'Total loss': 0.8011604570707337}
2022-11-18 02:19:29,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:29,953 INFO:     Epoch: 75
2022-11-18 02:19:30,755 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8183095843292946, 'Total loss': 0.8183095843292946} | train loss {'Reaction outcome loss': 0.8068369629441715, 'Total loss': 0.8068369629441715}
2022-11-18 02:19:30,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:30,755 INFO:     Epoch: 76
2022-11-18 02:19:31,528 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8070814831312313, 'Total loss': 0.8070814831312313} | train loss {'Reaction outcome loss': 0.8046549592838913, 'Total loss': 0.8046549592838913}
2022-11-18 02:19:31,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:31,528 INFO:     Epoch: 77
2022-11-18 02:19:32,323 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8006741044133209, 'Total loss': 0.8006741044133209} | train loss {'Reaction outcome loss': 0.8052385865909154, 'Total loss': 0.8052385865909154}
2022-11-18 02:19:32,323 INFO:     Found new best model at epoch 77
2022-11-18 02:19:32,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:32,324 INFO:     Epoch: 78
2022-11-18 02:19:33,101 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8084126121776049, 'Total loss': 0.8084126121776049} | train loss {'Reaction outcome loss': 0.8106922313082413, 'Total loss': 0.8106922313082413}
2022-11-18 02:19:33,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:33,101 INFO:     Epoch: 79
2022-11-18 02:19:33,905 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8216014469778815, 'Total loss': 0.8216014469778815} | train loss {'Reaction outcome loss': 0.8060332915333451, 'Total loss': 0.8060332915333451}
2022-11-18 02:19:33,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:33,905 INFO:     Epoch: 80
2022-11-18 02:19:34,706 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8058466980623644, 'Total loss': 0.8058466980623644} | train loss {'Reaction outcome loss': 0.8078321891485668, 'Total loss': 0.8078321891485668}
2022-11-18 02:19:34,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:34,707 INFO:     Epoch: 81
2022-11-18 02:19:35,518 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8072366312492726, 'Total loss': 0.8072366312492726} | train loss {'Reaction outcome loss': 0.806211739289956, 'Total loss': 0.806211739289956}
2022-11-18 02:19:35,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:35,518 INFO:     Epoch: 82
2022-11-18 02:19:36,306 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8078027624030446, 'Total loss': 0.8078027624030446} | train loss {'Reaction outcome loss': 0.8064712220039524, 'Total loss': 0.8064712220039524}
2022-11-18 02:19:36,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:36,306 INFO:     Epoch: 83
2022-11-18 02:19:37,126 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8116340048091356, 'Total loss': 0.8116340048091356} | train loss {'Reaction outcome loss': 0.8078625728605223, 'Total loss': 0.8078625728605223}
2022-11-18 02:19:37,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:37,126 INFO:     Epoch: 84
2022-11-18 02:19:37,931 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8202347256416498, 'Total loss': 0.8202347256416498} | train loss {'Reaction outcome loss': 0.8022629147181746, 'Total loss': 0.8022629147181746}
2022-11-18 02:19:37,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:37,932 INFO:     Epoch: 85
2022-11-18 02:19:38,724 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8359620827575063, 'Total loss': 0.8359620827575063} | train loss {'Reaction outcome loss': 0.806272992100872, 'Total loss': 0.806272992100872}
2022-11-18 02:19:38,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:38,725 INFO:     Epoch: 86
2022-11-18 02:19:39,497 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8181634060172147, 'Total loss': 0.8181634060172147} | train loss {'Reaction outcome loss': 0.8042983212431923, 'Total loss': 0.8042983212431923}
2022-11-18 02:19:39,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:39,497 INFO:     Epoch: 87
2022-11-18 02:19:40,266 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8079172289648722, 'Total loss': 0.8079172289648722} | train loss {'Reaction outcome loss': 0.8056633626339865, 'Total loss': 0.8056633626339865}
2022-11-18 02:19:40,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:40,267 INFO:     Epoch: 88
2022-11-18 02:19:41,070 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8165138627207557, 'Total loss': 0.8165138627207557} | train loss {'Reaction outcome loss': 0.8074135532388922, 'Total loss': 0.8074135532388922}
2022-11-18 02:19:41,070 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:41,070 INFO:     Epoch: 89
2022-11-18 02:19:41,871 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8315207417621169, 'Total loss': 0.8315207417621169} | train loss {'Reaction outcome loss': 0.8017535507678986, 'Total loss': 0.8017535507678986}
2022-11-18 02:19:41,871 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:41,871 INFO:     Epoch: 90
2022-11-18 02:19:42,711 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8100361962651097, 'Total loss': 0.8100361962651097} | train loss {'Reaction outcome loss': 0.8112683283989547, 'Total loss': 0.8112683283989547}
2022-11-18 02:19:42,711 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:42,711 INFO:     Epoch: 91
2022-11-18 02:19:43,556 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8105170373306718, 'Total loss': 0.8105170373306718} | train loss {'Reaction outcome loss': 0.8035599762787584, 'Total loss': 0.8035599762787584}
2022-11-18 02:19:43,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:43,556 INFO:     Epoch: 92
2022-11-18 02:19:44,367 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8497444911058559, 'Total loss': 0.8497444911058559} | train loss {'Reaction outcome loss': 0.8071972528686289, 'Total loss': 0.8071972528686289}
2022-11-18 02:19:44,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:44,368 INFO:     Epoch: 93
2022-11-18 02:19:45,184 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8168758417284766, 'Total loss': 0.8168758417284766} | train loss {'Reaction outcome loss': 0.8006912103441896, 'Total loss': 0.8006912103441896}
2022-11-18 02:19:45,185 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:45,185 INFO:     Epoch: 94
2022-11-18 02:19:45,943 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8146414368651634, 'Total loss': 0.8146414368651634} | train loss {'Reaction outcome loss': 0.8049571820702709, 'Total loss': 0.8049571820702709}
2022-11-18 02:19:45,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:45,944 INFO:     Epoch: 95
2022-11-18 02:19:46,763 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8153490146925283, 'Total loss': 0.8153490146925283} | train loss {'Reaction outcome loss': 0.8057211442071883, 'Total loss': 0.8057211442071883}
2022-11-18 02:19:46,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:46,763 INFO:     Epoch: 96
2022-11-18 02:19:47,549 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8135663686796676, 'Total loss': 0.8135663686796676} | train loss {'Reaction outcome loss': 0.8042164655005346, 'Total loss': 0.8042164655005346}
2022-11-18 02:19:47,549 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:47,549 INFO:     Epoch: 97
2022-11-18 02:19:48,335 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8209741337354793, 'Total loss': 0.8209741337354793} | train loss {'Reaction outcome loss': 0.8060490881077579, 'Total loss': 0.8060490881077579}
2022-11-18 02:19:48,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:48,335 INFO:     Epoch: 98
2022-11-18 02:19:49,090 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8249162054339121, 'Total loss': 0.8249162054339121} | train loss {'Reaction outcome loss': 0.8061806695138822, 'Total loss': 0.8061806695138822}
2022-11-18 02:19:49,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:49,090 INFO:     Epoch: 99
2022-11-18 02:19:49,884 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8040362042050029, 'Total loss': 0.8040362042050029} | train loss {'Reaction outcome loss': 0.8048495148293308, 'Total loss': 0.8048495148293308}
2022-11-18 02:19:49,884 INFO:     Best model found after epoch 78 of 100.
2022-11-18 02:19:49,884 INFO:   Done with stage: TRAINING
2022-11-18 02:19:49,884 INFO:   Starting stage: EVALUATION
2022-11-18 02:19:50,021 INFO:   Done with stage: EVALUATION
2022-11-18 02:19:50,021 INFO:   Leaving out SEQ value Fold_4
2022-11-18 02:19:50,034 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 02:19:50,035 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:19:50,703 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:19:50,703 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:19:50,778 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:19:50,778 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:19:50,778 INFO:     No hyperparam tuning for this model
2022-11-18 02:19:50,778 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:19:50,778 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:19:50,779 INFO:     None feature selector for col prot
2022-11-18 02:19:50,779 INFO:     None feature selector for col prot
2022-11-18 02:19:50,779 INFO:     None feature selector for col prot
2022-11-18 02:19:50,780 INFO:     None feature selector for col chem
2022-11-18 02:19:50,780 INFO:     None feature selector for col chem
2022-11-18 02:19:50,780 INFO:     None feature selector for col chem
2022-11-18 02:19:50,780 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:19:50,780 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:19:50,782 INFO:     Number of params in model 168571
2022-11-18 02:19:50,785 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:19:50,785 INFO:   Starting stage: TRAINING
2022-11-18 02:19:50,843 INFO:     Val loss before train {'Reaction outcome loss': 1.1007375825535168, 'Total loss': 1.1007375825535168}
2022-11-18 02:19:50,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:50,843 INFO:     Epoch: 0
2022-11-18 02:19:51,662 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9411112029444088, 'Total loss': 0.9411112029444088} | train loss {'Reaction outcome loss': 0.8729906346392535, 'Total loss': 0.8729906346392535}
2022-11-18 02:19:51,662 INFO:     Found new best model at epoch 0
2022-11-18 02:19:51,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:51,663 INFO:     Epoch: 1
2022-11-18 02:19:52,452 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.9108083708719774, 'Total loss': 0.9108083708719774} | train loss {'Reaction outcome loss': 0.8350308342018591, 'Total loss': 0.8350308342018591}
2022-11-18 02:19:52,454 INFO:     Found new best model at epoch 1
2022-11-18 02:19:52,455 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:52,455 INFO:     Epoch: 2
2022-11-18 02:19:53,244 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.9100811427289789, 'Total loss': 0.9100811427289789} | train loss {'Reaction outcome loss': 0.8319310521789891, 'Total loss': 0.8319310521789891}
2022-11-18 02:19:53,244 INFO:     Found new best model at epoch 2
2022-11-18 02:19:53,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:53,245 INFO:     Epoch: 3
2022-11-18 02:19:54,038 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.9430818639018319, 'Total loss': 0.9430818639018319} | train loss {'Reaction outcome loss': 0.8326987939083624, 'Total loss': 0.8326987939083624}
2022-11-18 02:19:54,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:54,038 INFO:     Epoch: 4
2022-11-18 02:19:54,831 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.9294651042331349, 'Total loss': 0.9294651042331349} | train loss {'Reaction outcome loss': 0.8308835905799379, 'Total loss': 0.8308835905799379}
2022-11-18 02:19:54,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:54,832 INFO:     Epoch: 5
2022-11-18 02:19:55,635 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8964152078736912, 'Total loss': 0.8964152078736912} | train loss {'Reaction outcome loss': 0.8228557949606706, 'Total loss': 0.8228557949606706}
2022-11-18 02:19:55,636 INFO:     Found new best model at epoch 5
2022-11-18 02:19:55,636 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:55,636 INFO:     Epoch: 6
2022-11-18 02:19:56,459 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.9140250547365709, 'Total loss': 0.9140250547365709} | train loss {'Reaction outcome loss': 0.8339313690961614, 'Total loss': 0.8339313690961614}
2022-11-18 02:19:56,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:56,459 INFO:     Epoch: 7
2022-11-18 02:19:57,297 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8949917250058868, 'Total loss': 0.8949917250058868} | train loss {'Reaction outcome loss': 0.8243845018298037, 'Total loss': 0.8243845018298037}
2022-11-18 02:19:57,297 INFO:     Found new best model at epoch 7
2022-11-18 02:19:57,297 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:57,298 INFO:     Epoch: 8
2022-11-18 02:19:58,079 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.9115070104598999, 'Total loss': 0.9115070104598999} | train loss {'Reaction outcome loss': 0.8206581069148986, 'Total loss': 0.8206581069148986}
2022-11-18 02:19:58,079 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:58,079 INFO:     Epoch: 9
2022-11-18 02:19:58,873 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.9021794199943542, 'Total loss': 0.9021794199943542} | train loss {'Reaction outcome loss': 0.8198408591466756, 'Total loss': 0.8198408591466756}
2022-11-18 02:19:58,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:58,874 INFO:     Epoch: 10
2022-11-18 02:19:59,665 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8873087452216581, 'Total loss': 0.8873087452216581} | train loss {'Reaction outcome loss': 0.827790680443227, 'Total loss': 0.827790680443227}
2022-11-18 02:19:59,665 INFO:     Found new best model at epoch 10
2022-11-18 02:19:59,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:19:59,666 INFO:     Epoch: 11
2022-11-18 02:20:00,505 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.9060135321183638, 'Total loss': 0.9060135321183638} | train loss {'Reaction outcome loss': 0.8149794072274738, 'Total loss': 0.8149794072274738}
2022-11-18 02:20:00,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:00,506 INFO:     Epoch: 12
2022-11-18 02:20:01,303 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8920114392584021, 'Total loss': 0.8920114392584021} | train loss {'Reaction outcome loss': 0.8122538994198386, 'Total loss': 0.8122538994198386}
2022-11-18 02:20:01,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:01,304 INFO:     Epoch: 13
2022-11-18 02:20:02,097 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.906985539604317, 'Total loss': 0.906985539604317} | train loss {'Reaction outcome loss': 0.812277395753303, 'Total loss': 0.812277395753303}
2022-11-18 02:20:02,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:02,097 INFO:     Epoch: 14
2022-11-18 02:20:02,867 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.912120477042415, 'Total loss': 0.912120477042415} | train loss {'Reaction outcome loss': 0.8089264360999289, 'Total loss': 0.8089264360999289}
2022-11-18 02:20:02,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:02,868 INFO:     Epoch: 15
2022-11-18 02:20:03,671 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.9150603508407419, 'Total loss': 0.9150603508407419} | train loss {'Reaction outcome loss': 0.8041418576047488, 'Total loss': 0.8041418576047488}
2022-11-18 02:20:03,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:03,672 INFO:     Epoch: 16
2022-11-18 02:20:04,552 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.88731799274683, 'Total loss': 0.88731799274683} | train loss {'Reaction outcome loss': 0.80839801967325, 'Total loss': 0.80839801967325}
2022-11-18 02:20:04,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:04,553 INFO:     Epoch: 17
2022-11-18 02:20:05,361 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8925549604675986, 'Total loss': 0.8925549604675986} | train loss {'Reaction outcome loss': 0.8079012463449949, 'Total loss': 0.8079012463449949}
2022-11-18 02:20:05,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:05,361 INFO:     Epoch: 18
2022-11-18 02:20:06,148 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.915298119187355, 'Total loss': 0.915298119187355} | train loss {'Reaction outcome loss': 0.8059595540271476, 'Total loss': 0.8059595540271476}
2022-11-18 02:20:06,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:06,148 INFO:     Epoch: 19
2022-11-18 02:20:06,937 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.9151136509396813, 'Total loss': 0.9151136509396813} | train loss {'Reaction outcome loss': 0.8193313010067109, 'Total loss': 0.8193313010067109}
2022-11-18 02:20:06,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:06,937 INFO:     Epoch: 20
2022-11-18 02:20:07,761 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.91381082480604, 'Total loss': 0.91381082480604} | train loss {'Reaction outcome loss': 0.8096918719952647, 'Total loss': 0.8096918719952647}
2022-11-18 02:20:07,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:07,761 INFO:     Epoch: 21
2022-11-18 02:20:08,568 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8895823698152195, 'Total loss': 0.8895823698152195} | train loss {'Reaction outcome loss': 0.8216127375600791, 'Total loss': 0.8216127375600791}
2022-11-18 02:20:08,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:08,569 INFO:     Epoch: 22
2022-11-18 02:20:09,375 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.9130677296356722, 'Total loss': 0.9130677296356722} | train loss {'Reaction outcome loss': 0.816775759342711, 'Total loss': 0.816775759342711}
2022-11-18 02:20:09,376 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:09,376 INFO:     Epoch: 23
2022-11-18 02:20:10,172 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.9122129245237871, 'Total loss': 0.9122129245237871} | train loss {'Reaction outcome loss': 0.8129860957865773, 'Total loss': 0.8129860957865773}
2022-11-18 02:20:10,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:10,172 INFO:     Epoch: 24
2022-11-18 02:20:10,946 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.9202442765235901, 'Total loss': 0.9202442765235901} | train loss {'Reaction outcome loss': 0.8075874297001101, 'Total loss': 0.8075874297001101}
2022-11-18 02:20:10,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:10,947 INFO:     Epoch: 25
2022-11-18 02:20:11,721 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.905579690228809, 'Total loss': 0.905579690228809} | train loss {'Reaction outcome loss': 0.8151358023346195, 'Total loss': 0.8151358023346195}
2022-11-18 02:20:11,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:11,721 INFO:     Epoch: 26
2022-11-18 02:20:12,522 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.9068662280386145, 'Total loss': 0.9068662280386145} | train loss {'Reaction outcome loss': 0.8049309142688026, 'Total loss': 0.8049309142688026}
2022-11-18 02:20:12,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:12,522 INFO:     Epoch: 27
2022-11-18 02:20:13,350 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.9051836580038071, 'Total loss': 0.9051836580038071} | train loss {'Reaction outcome loss': 0.8083358618170626, 'Total loss': 0.8083358618170626}
2022-11-18 02:20:13,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:13,350 INFO:     Epoch: 28
2022-11-18 02:20:14,133 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8936932357874784, 'Total loss': 0.8936932357874784} | train loss {'Reaction outcome loss': 0.8061301053354615, 'Total loss': 0.8061301053354615}
2022-11-18 02:20:14,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:14,133 INFO:     Epoch: 29
2022-11-18 02:20:14,961 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.9137529107657346, 'Total loss': 0.9137529107657346} | train loss {'Reaction outcome loss': 0.8025446855104886, 'Total loss': 0.8025446855104886}
2022-11-18 02:20:14,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:14,962 INFO:     Epoch: 30
2022-11-18 02:20:15,814 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8897980668328025, 'Total loss': 0.8897980668328025} | train loss {'Reaction outcome loss': 0.809491612047319, 'Total loss': 0.809491612047319}
2022-11-18 02:20:15,815 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:15,815 INFO:     Epoch: 31
2022-11-18 02:20:16,661 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8818777521902864, 'Total loss': 0.8818777521902864} | train loss {'Reaction outcome loss': 0.8096582127003534, 'Total loss': 0.8096582127003534}
2022-11-18 02:20:16,661 INFO:     Found new best model at epoch 31
2022-11-18 02:20:16,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:16,662 INFO:     Epoch: 32
2022-11-18 02:20:17,458 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.9206956347281282, 'Total loss': 0.9206956347281282} | train loss {'Reaction outcome loss': 0.8037790222930522, 'Total loss': 0.8037790222930522}
2022-11-18 02:20:17,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:17,458 INFO:     Epoch: 33
2022-11-18 02:20:18,298 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8989346013827757, 'Total loss': 0.8989346013827757} | train loss {'Reaction outcome loss': 0.8095880587573959, 'Total loss': 0.8095880587573959}
2022-11-18 02:20:18,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:18,298 INFO:     Epoch: 34
2022-11-18 02:20:19,124 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.905362683263692, 'Total loss': 0.905362683263692} | train loss {'Reaction outcome loss': 0.8085166113338007, 'Total loss': 0.8085166113338007}
2022-11-18 02:20:19,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:19,124 INFO:     Epoch: 35
2022-11-18 02:20:19,954 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8894949853420258, 'Total loss': 0.8894949853420258} | train loss {'Reaction outcome loss': 0.8230019197290243, 'Total loss': 0.8230019197290243}
2022-11-18 02:20:19,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:19,954 INFO:     Epoch: 36
2022-11-18 02:20:20,752 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8984142379327253, 'Total loss': 0.8984142379327253} | train loss {'Reaction outcome loss': 0.8123890960264785, 'Total loss': 0.8123890960264785}
2022-11-18 02:20:20,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:20,752 INFO:     Epoch: 37
2022-11-18 02:20:21,560 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.9311953085390005, 'Total loss': 0.9311953085390005} | train loss {'Reaction outcome loss': 0.8109207873643651, 'Total loss': 0.8109207873643651}
2022-11-18 02:20:21,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:21,560 INFO:     Epoch: 38
2022-11-18 02:20:22,371 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.886870880018581, 'Total loss': 0.886870880018581} | train loss {'Reaction outcome loss': 0.8140786850018057, 'Total loss': 0.8140786850018057}
2022-11-18 02:20:22,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:22,371 INFO:     Epoch: 39
2022-11-18 02:20:23,198 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8875459838997234, 'Total loss': 0.8875459838997234} | train loss {'Reaction outcome loss': 0.8096124193205042, 'Total loss': 0.8096124193205042}
2022-11-18 02:20:23,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:23,198 INFO:     Epoch: 40
2022-11-18 02:20:23,992 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.9086292860182849, 'Total loss': 0.9086292860182849} | train loss {'Reaction outcome loss': 0.8016113839772067, 'Total loss': 0.8016113839772067}
2022-11-18 02:20:23,993 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:23,994 INFO:     Epoch: 41
2022-11-18 02:20:24,820 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.9128365625034679, 'Total loss': 0.9128365625034679} | train loss {'Reaction outcome loss': 0.8067541501375466, 'Total loss': 0.8067541501375466}
2022-11-18 02:20:24,820 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:24,820 INFO:     Epoch: 42
2022-11-18 02:20:25,678 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.9015470458702608, 'Total loss': 0.9015470458702608} | train loss {'Reaction outcome loss': 0.8077184195943207, 'Total loss': 0.8077184195943207}
2022-11-18 02:20:25,678 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:25,678 INFO:     Epoch: 43
2022-11-18 02:20:26,448 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.9262164119969715, 'Total loss': 0.9262164119969715} | train loss {'Reaction outcome loss': 0.8079395486336005, 'Total loss': 0.8079395486336005}
2022-11-18 02:20:26,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:26,448 INFO:     Epoch: 44
2022-11-18 02:20:27,263 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8875334100289778, 'Total loss': 0.8875334100289778} | train loss {'Reaction outcome loss': 0.8098418785010272, 'Total loss': 0.8098418785010272}
2022-11-18 02:20:27,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:27,264 INFO:     Epoch: 45
2022-11-18 02:20:28,081 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.887985654852607, 'Total loss': 0.887985654852607} | train loss {'Reaction outcome loss': 0.8035590194980142, 'Total loss': 0.8035590194980142}
2022-11-18 02:20:28,081 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:28,082 INFO:     Epoch: 46
2022-11-18 02:20:28,936 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8843273865905675, 'Total loss': 0.8843273865905675} | train loss {'Reaction outcome loss': 0.7997684653109385, 'Total loss': 0.7997684653109385}
2022-11-18 02:20:28,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:28,936 INFO:     Epoch: 47
2022-11-18 02:20:29,739 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.939169702204791, 'Total loss': 0.939169702204791} | train loss {'Reaction outcome loss': 0.8073550572520808, 'Total loss': 0.8073550572520808}
2022-11-18 02:20:29,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:29,740 INFO:     Epoch: 48
2022-11-18 02:20:30,516 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.900363645770333, 'Total loss': 0.900363645770333} | train loss {'Reaction outcome loss': 0.8136739506412615, 'Total loss': 0.8136739506412615}
2022-11-18 02:20:30,517 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:30,517 INFO:     Epoch: 49
2022-11-18 02:20:31,327 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.9014277078888633, 'Total loss': 0.9014277078888633} | train loss {'Reaction outcome loss': 0.8131466214714745, 'Total loss': 0.8131466214714745}
2022-11-18 02:20:31,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:31,327 INFO:     Epoch: 50
2022-11-18 02:20:32,119 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.9087233638221567, 'Total loss': 0.9087233638221567} | train loss {'Reaction outcome loss': 0.8271362104637903, 'Total loss': 0.8271362104637903}
2022-11-18 02:20:32,119 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:32,120 INFO:     Epoch: 51
2022-11-18 02:20:32,931 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.9031690833243456, 'Total loss': 0.9031690833243456} | train loss {'Reaction outcome loss': 0.8092005137007247, 'Total loss': 0.8092005137007247}
2022-11-18 02:20:32,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:32,931 INFO:     Epoch: 52
2022-11-18 02:20:33,714 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8973043181679465, 'Total loss': 0.8973043181679465} | train loss {'Reaction outcome loss': 0.8051128481563768, 'Total loss': 0.8051128481563768}
2022-11-18 02:20:33,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:33,714 INFO:     Epoch: 53
2022-11-18 02:20:34,522 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8971067511222579, 'Total loss': 0.8971067511222579} | train loss {'Reaction outcome loss': 0.8008550997551999, 'Total loss': 0.8008550997551999}
2022-11-18 02:20:34,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:34,523 INFO:     Epoch: 54
2022-11-18 02:20:35,346 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8897099887782877, 'Total loss': 0.8897099887782877} | train loss {'Reaction outcome loss': 0.8047541245999124, 'Total loss': 0.8047541245999124}
2022-11-18 02:20:35,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:35,346 INFO:     Epoch: 55
2022-11-18 02:20:36,157 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8819313028996641, 'Total loss': 0.8819313028996641} | train loss {'Reaction outcome loss': 0.8069046531852923, 'Total loss': 0.8069046531852923}
2022-11-18 02:20:36,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:36,157 INFO:     Epoch: 56
2022-11-18 02:20:36,987 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8918092813004147, 'Total loss': 0.8918092813004147} | train loss {'Reaction outcome loss': 0.8030662731482432, 'Total loss': 0.8030662731482432}
2022-11-18 02:20:36,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:36,987 INFO:     Epoch: 57
2022-11-18 02:20:37,815 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.891550287604332, 'Total loss': 0.891550287604332} | train loss {'Reaction outcome loss': 0.8065676546772482, 'Total loss': 0.8065676546772482}
2022-11-18 02:20:37,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:37,816 INFO:     Epoch: 58
2022-11-18 02:20:38,625 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8883701021021063, 'Total loss': 0.8883701021021063} | train loss {'Reaction outcome loss': 0.8076841394428299, 'Total loss': 0.8076841394428299}
2022-11-18 02:20:38,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:38,625 INFO:     Epoch: 59
2022-11-18 02:20:39,439 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.9054529179226268, 'Total loss': 0.9054529179226268} | train loss {'Reaction outcome loss': 0.8079290304348054, 'Total loss': 0.8079290304348054}
2022-11-18 02:20:39,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:39,440 INFO:     Epoch: 60
2022-11-18 02:20:40,262 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8851810206066478, 'Total loss': 0.8851810206066478} | train loss {'Reaction outcome loss': 0.8061707596245565, 'Total loss': 0.8061707596245565}
2022-11-18 02:20:40,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:40,262 INFO:     Epoch: 61
2022-11-18 02:20:41,109 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.9067670418457552, 'Total loss': 0.9067670418457552} | train loss {'Reaction outcome loss': 0.8032245187141634, 'Total loss': 0.8032245187141634}
2022-11-18 02:20:41,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:41,109 INFO:     Epoch: 62
2022-11-18 02:20:41,928 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.9044624431566759, 'Total loss': 0.9044624431566759} | train loss {'Reaction outcome loss': 0.8054422037562861, 'Total loss': 0.8054422037562861}
2022-11-18 02:20:41,929 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:41,929 INFO:     Epoch: 63
2022-11-18 02:20:42,695 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8936197622255846, 'Total loss': 0.8936197622255846} | train loss {'Reaction outcome loss': 0.803463898930955, 'Total loss': 0.803463898930955}
2022-11-18 02:20:42,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:42,696 INFO:     Epoch: 64
2022-11-18 02:20:43,485 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8878334659067068, 'Total loss': 0.8878334659067068} | train loss {'Reaction outcome loss': 0.8091386116226675, 'Total loss': 0.8091386116226675}
2022-11-18 02:20:43,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:43,485 INFO:     Epoch: 65
2022-11-18 02:20:44,275 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8852714381434701, 'Total loss': 0.8852714381434701} | train loss {'Reaction outcome loss': 0.8127067175953977, 'Total loss': 0.8127067175953977}
2022-11-18 02:20:44,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:44,276 INFO:     Epoch: 66
2022-11-18 02:20:45,080 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8837886466221376, 'Total loss': 0.8837886466221376} | train loss {'Reaction outcome loss': 0.809249244238201, 'Total loss': 0.809249244238201}
2022-11-18 02:20:45,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:45,080 INFO:     Epoch: 67
2022-11-18 02:20:45,882 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.9018384651704268, 'Total loss': 0.9018384651704268} | train loss {'Reaction outcome loss': 0.8083610716860304, 'Total loss': 0.8083610716860304}
2022-11-18 02:20:45,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:45,882 INFO:     Epoch: 68
2022-11-18 02:20:46,643 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.895319752395153, 'Total loss': 0.895319752395153} | train loss {'Reaction outcome loss': 0.8071071421086546, 'Total loss': 0.8071071421086546}
2022-11-18 02:20:46,643 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:46,643 INFO:     Epoch: 69
2022-11-18 02:20:47,441 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.884227583015507, 'Total loss': 0.884227583015507} | train loss {'Reaction outcome loss': 0.8030528371572977, 'Total loss': 0.8030528371572977}
2022-11-18 02:20:47,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:47,441 INFO:     Epoch: 70
2022-11-18 02:20:48,240 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.9160223413597454, 'Total loss': 0.9160223413597454} | train loss {'Reaction outcome loss': 0.8191255370856296, 'Total loss': 0.8191255370856296}
2022-11-18 02:20:48,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:48,240 INFO:     Epoch: 71
2022-11-18 02:20:49,028 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.9166537977077744, 'Total loss': 0.9166537977077744} | train loss {'Reaction outcome loss': 0.8177538140100024, 'Total loss': 0.8177538140100024}
2022-11-18 02:20:49,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:49,028 INFO:     Epoch: 72
2022-11-18 02:20:49,815 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8907348303632303, 'Total loss': 0.8907348303632303} | train loss {'Reaction outcome loss': 0.8053868116154844, 'Total loss': 0.8053868116154844}
2022-11-18 02:20:49,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:49,816 INFO:     Epoch: 73
2022-11-18 02:20:50,610 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8974404036998749, 'Total loss': 0.8974404036998749} | train loss {'Reaction outcome loss': 0.8050847194696727, 'Total loss': 0.8050847194696727}
2022-11-18 02:20:50,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:50,610 INFO:     Epoch: 74
2022-11-18 02:20:51,377 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8962320536375046, 'Total loss': 0.8962320536375046} | train loss {'Reaction outcome loss': 0.8133000108877174, 'Total loss': 0.8133000108877174}
2022-11-18 02:20:51,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:51,377 INFO:     Epoch: 75
2022-11-18 02:20:52,153 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.9174336709759452, 'Total loss': 0.9174336709759452} | train loss {'Reaction outcome loss': 0.8150580573661125, 'Total loss': 0.8150580573661125}
2022-11-18 02:20:52,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:52,154 INFO:     Epoch: 76
2022-11-18 02:20:52,975 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8882175623015924, 'Total loss': 0.8882175623015924} | train loss {'Reaction outcome loss': 0.8052385062703237, 'Total loss': 0.8052385062703237}
2022-11-18 02:20:52,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:52,975 INFO:     Epoch: 77
2022-11-18 02:20:53,756 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8915304744785483, 'Total loss': 0.8915304744785483} | train loss {'Reaction outcome loss': 0.8054525081204017, 'Total loss': 0.8054525081204017}
2022-11-18 02:20:53,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:53,756 INFO:     Epoch: 78
2022-11-18 02:20:54,569 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.9026650007475506, 'Total loss': 0.9026650007475506} | train loss {'Reaction outcome loss': 0.8075988734299354, 'Total loss': 0.8075988734299354}
2022-11-18 02:20:54,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:54,570 INFO:     Epoch: 79
2022-11-18 02:20:55,350 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8892077160152522, 'Total loss': 0.8892077160152522} | train loss {'Reaction outcome loss': 0.8031552660803081, 'Total loss': 0.8031552660803081}
2022-11-18 02:20:55,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:55,351 INFO:     Epoch: 80
2022-11-18 02:20:56,123 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8953463536771861, 'Total loss': 0.8953463536771861} | train loss {'Reaction outcome loss': 0.8081584202374524, 'Total loss': 0.8081584202374524}
2022-11-18 02:20:56,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:56,123 INFO:     Epoch: 81
2022-11-18 02:20:56,890 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8869743502952836, 'Total loss': 0.8869743502952836} | train loss {'Reaction outcome loss': 0.8012996846847689, 'Total loss': 0.8012996846847689}
2022-11-18 02:20:56,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:56,890 INFO:     Epoch: 82
2022-11-18 02:20:57,691 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.9066165821118788, 'Total loss': 0.9066165821118788} | train loss {'Reaction outcome loss': 0.8035374998081068, 'Total loss': 0.8035374998081068}
2022-11-18 02:20:57,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:57,693 INFO:     Epoch: 83
2022-11-18 02:20:58,474 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8974560445005243, 'Total loss': 0.8974560445005243} | train loss {'Reaction outcome loss': 0.8069655302203136, 'Total loss': 0.8069655302203136}
2022-11-18 02:20:58,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:58,474 INFO:     Epoch: 84
2022-11-18 02:20:59,259 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8982079449025068, 'Total loss': 0.8982079449025068} | train loss {'Reaction outcome loss': 0.8064772233306637, 'Total loss': 0.8064772233306637}
2022-11-18 02:20:59,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:20:59,259 INFO:     Epoch: 85
2022-11-18 02:21:00,059 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.9031704711643133, 'Total loss': 0.9031704711643133} | train loss {'Reaction outcome loss': 0.804566461427009, 'Total loss': 0.804566461427009}
2022-11-18 02:21:00,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:00,059 INFO:     Epoch: 86
2022-11-18 02:21:00,827 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.9021507637067274, 'Total loss': 0.9021507637067274} | train loss {'Reaction outcome loss': 0.8075902003508347, 'Total loss': 0.8075902003508347}
2022-11-18 02:21:00,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:00,827 INFO:     Epoch: 87
2022-11-18 02:21:01,651 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8941740705208345, 'Total loss': 0.8941740705208345} | train loss {'Reaction outcome loss': 0.8076040085390029, 'Total loss': 0.8076040085390029}
2022-11-18 02:21:01,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:01,651 INFO:     Epoch: 88
2022-11-18 02:21:02,444 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8930051597681913, 'Total loss': 0.8930051597681913} | train loss {'Reaction outcome loss': 0.8052970015326975, 'Total loss': 0.8052970015326975}
2022-11-18 02:21:02,444 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:02,444 INFO:     Epoch: 89
2022-11-18 02:21:03,244 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8873019814491272, 'Total loss': 0.8873019814491272} | train loss {'Reaction outcome loss': 0.8043930172196284, 'Total loss': 0.8043930172196284}
2022-11-18 02:21:03,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:03,245 INFO:     Epoch: 90
2022-11-18 02:21:04,052 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.9748438806696371, 'Total loss': 0.9748438806696371} | train loss {'Reaction outcome loss': 0.8062208944004075, 'Total loss': 0.8062208944004075}
2022-11-18 02:21:04,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:04,053 INFO:     Epoch: 91
2022-11-18 02:21:04,881 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8876855766231363, 'Total loss': 0.8876855766231363} | train loss {'Reaction outcome loss': 0.8060074109538846, 'Total loss': 0.8060074109538846}
2022-11-18 02:21:04,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:04,881 INFO:     Epoch: 92
2022-11-18 02:21:05,706 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8871201425790787, 'Total loss': 0.8871201425790787} | train loss {'Reaction outcome loss': 0.8098079886754997, 'Total loss': 0.8098079886754997}
2022-11-18 02:21:05,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:05,707 INFO:     Epoch: 93
2022-11-18 02:21:06,511 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8854286819696426, 'Total loss': 0.8854286819696426} | train loss {'Reaction outcome loss': 0.802818543334239, 'Total loss': 0.802818543334239}
2022-11-18 02:21:06,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:06,511 INFO:     Epoch: 94
2022-11-18 02:21:07,333 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.9019337472590533, 'Total loss': 0.9019337472590533} | train loss {'Reaction outcome loss': 0.8014863839124137, 'Total loss': 0.8014863839124137}
2022-11-18 02:21:07,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:07,333 INFO:     Epoch: 95
2022-11-18 02:21:08,156 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.886767796494744, 'Total loss': 0.886767796494744} | train loss {'Reaction outcome loss': 0.8039467847540311, 'Total loss': 0.8039467847540311}
2022-11-18 02:21:08,156 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:08,157 INFO:     Epoch: 96
2022-11-18 02:21:08,937 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.90451300076463, 'Total loss': 0.90451300076463} | train loss {'Reaction outcome loss': 0.8063845654368883, 'Total loss': 0.8063845654368883}
2022-11-18 02:21:08,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:08,938 INFO:     Epoch: 97
2022-11-18 02:21:09,736 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8991205028512261, 'Total loss': 0.8991205028512261} | train loss {'Reaction outcome loss': 0.8062362254631181, 'Total loss': 0.8062362254631181}
2022-11-18 02:21:09,736 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:09,736 INFO:     Epoch: 98
2022-11-18 02:21:10,499 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.9072919325395064, 'Total loss': 0.9072919325395064} | train loss {'Reaction outcome loss': 0.8065255900867555, 'Total loss': 0.8065255900867555}
2022-11-18 02:21:10,499 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:10,499 INFO:     Epoch: 99
2022-11-18 02:21:11,311 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.9090376780791716, 'Total loss': 0.9090376780791716} | train loss {'Reaction outcome loss': 0.8061047609639072, 'Total loss': 0.8061047609639072}
2022-11-18 02:21:11,311 INFO:     Best model found after epoch 32 of 100.
2022-11-18 02:21:11,311 INFO:   Done with stage: TRAINING
2022-11-18 02:21:11,311 INFO:   Starting stage: EVALUATION
2022-11-18 02:21:11,436 INFO:   Done with stage: EVALUATION
2022-11-18 02:21:11,436 INFO:   Leaving out SEQ value Fold_5
2022-11-18 02:21:11,449 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 02:21:11,449 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:21:12,132 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:21:12,132 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:21:12,202 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:21:12,202 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:21:12,202 INFO:     No hyperparam tuning for this model
2022-11-18 02:21:12,202 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:21:12,202 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:21:12,203 INFO:     None feature selector for col prot
2022-11-18 02:21:12,203 INFO:     None feature selector for col prot
2022-11-18 02:21:12,203 INFO:     None feature selector for col prot
2022-11-18 02:21:12,204 INFO:     None feature selector for col chem
2022-11-18 02:21:12,204 INFO:     None feature selector for col chem
2022-11-18 02:21:12,204 INFO:     None feature selector for col chem
2022-11-18 02:21:12,204 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:21:12,204 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:21:12,206 INFO:     Number of params in model 168571
2022-11-18 02:21:12,209 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:21:12,209 INFO:   Starting stage: TRAINING
2022-11-18 02:21:12,267 INFO:     Val loss before train {'Reaction outcome loss': 1.0158752284266732, 'Total loss': 1.0158752284266732}
2022-11-18 02:21:12,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:12,267 INFO:     Epoch: 0
2022-11-18 02:21:13,061 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8521888215433467, 'Total loss': 0.8521888215433467} | train loss {'Reaction outcome loss': 0.8741167283009904, 'Total loss': 0.8741167283009904}
2022-11-18 02:21:13,061 INFO:     Found new best model at epoch 0
2022-11-18 02:21:13,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:13,062 INFO:     Epoch: 1
2022-11-18 02:21:13,871 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.819459732960571, 'Total loss': 0.819459732960571} | train loss {'Reaction outcome loss': 0.8402428931070243, 'Total loss': 0.8402428931070243}
2022-11-18 02:21:13,872 INFO:     Found new best model at epoch 1
2022-11-18 02:21:13,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:13,872 INFO:     Epoch: 2
2022-11-18 02:21:14,705 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8317953842607412, 'Total loss': 0.8317953842607412} | train loss {'Reaction outcome loss': 0.8404234451079658, 'Total loss': 0.8404234451079658}
2022-11-18 02:21:14,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:14,706 INFO:     Epoch: 3
2022-11-18 02:21:15,512 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8048661886291071, 'Total loss': 0.8048661886291071} | train loss {'Reaction outcome loss': 0.8352553163945433, 'Total loss': 0.8352553163945433}
2022-11-18 02:21:15,512 INFO:     Found new best model at epoch 3
2022-11-18 02:21:15,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:15,513 INFO:     Epoch: 4
2022-11-18 02:21:16,335 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8199681450020183, 'Total loss': 0.8199681450020183} | train loss {'Reaction outcome loss': 0.829830134747482, 'Total loss': 0.829830134747482}
2022-11-18 02:21:16,336 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:16,336 INFO:     Epoch: 5
2022-11-18 02:21:17,148 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8048034499992024, 'Total loss': 0.8048034499992024} | train loss {'Reaction outcome loss': 0.8233881451581654, 'Total loss': 0.8233881451581654}
2022-11-18 02:21:17,148 INFO:     Found new best model at epoch 5
2022-11-18 02:21:17,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:17,149 INFO:     Epoch: 6
2022-11-18 02:21:17,922 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8223803476853804, 'Total loss': 0.8223803476853804} | train loss {'Reaction outcome loss': 0.8161712338325948, 'Total loss': 0.8161712338325948}
2022-11-18 02:21:17,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:17,922 INFO:     Epoch: 7
2022-11-18 02:21:18,726 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8156748888167468, 'Total loss': 0.8156748888167468} | train loss {'Reaction outcome loss': 0.820601681707359, 'Total loss': 0.820601681707359}
2022-11-18 02:21:18,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:18,726 INFO:     Epoch: 8
2022-11-18 02:21:19,527 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7983388243751093, 'Total loss': 0.7983388243751093} | train loss {'Reaction outcome loss': 0.8170112639303632, 'Total loss': 0.8170112639303632}
2022-11-18 02:21:19,527 INFO:     Found new best model at epoch 8
2022-11-18 02:21:19,528 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:19,528 INFO:     Epoch: 9
2022-11-18 02:21:20,339 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8039726845242761, 'Total loss': 0.8039726845242761} | train loss {'Reaction outcome loss': 0.827256893098113, 'Total loss': 0.827256893098113}
2022-11-18 02:21:20,339 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:20,339 INFO:     Epoch: 10
2022-11-18 02:21:21,108 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.809469956565987, 'Total loss': 0.809469956565987} | train loss {'Reaction outcome loss': 0.8127968831342242, 'Total loss': 0.8127968831342242}
2022-11-18 02:21:21,108 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:21,108 INFO:     Epoch: 11
2022-11-18 02:21:21,886 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8026831583543257, 'Total loss': 0.8026831583543257} | train loss {'Reaction outcome loss': 0.819287835707066, 'Total loss': 0.819287835707066}
2022-11-18 02:21:21,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:21,886 INFO:     Epoch: 12
2022-11-18 02:21:22,684 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8060066103935242, 'Total loss': 0.8060066103935242} | train loss {'Reaction outcome loss': 0.816201716948014, 'Total loss': 0.816201716948014}
2022-11-18 02:21:22,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:22,684 INFO:     Epoch: 13
2022-11-18 02:21:23,499 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7937173816290769, 'Total loss': 0.7937173816290769} | train loss {'Reaction outcome loss': 0.8145040331581826, 'Total loss': 0.8145040331581826}
2022-11-18 02:21:23,499 INFO:     Found new best model at epoch 13
2022-11-18 02:21:23,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:23,500 INFO:     Epoch: 14
2022-11-18 02:21:24,269 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7918548672036692, 'Total loss': 0.7918548672036692} | train loss {'Reaction outcome loss': 0.8171744228223798, 'Total loss': 0.8171744228223798}
2022-11-18 02:21:24,269 INFO:     Found new best model at epoch 14
2022-11-18 02:21:24,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:24,270 INFO:     Epoch: 15
2022-11-18 02:21:25,094 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7905521670525725, 'Total loss': 0.7905521670525725} | train loss {'Reaction outcome loss': 0.8183471273314132, 'Total loss': 0.8183471273314132}
2022-11-18 02:21:25,094 INFO:     Found new best model at epoch 15
2022-11-18 02:21:25,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:25,095 INFO:     Epoch: 16
2022-11-18 02:21:25,913 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7925063182007183, 'Total loss': 0.7925063182007183} | train loss {'Reaction outcome loss': 0.808311575216803, 'Total loss': 0.808311575216803}
2022-11-18 02:21:25,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:25,915 INFO:     Epoch: 17
2022-11-18 02:21:26,729 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7973745011470534, 'Total loss': 0.7973745011470534} | train loss {'Reaction outcome loss': 0.8167694155503864, 'Total loss': 0.8167694155503864}
2022-11-18 02:21:26,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:26,729 INFO:     Epoch: 18
2022-11-18 02:21:27,553 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7911952828819101, 'Total loss': 0.7911952828819101} | train loss {'Reaction outcome loss': 0.8136469306733444, 'Total loss': 0.8136469306733444}
2022-11-18 02:21:27,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:27,553 INFO:     Epoch: 19
2022-11-18 02:21:28,352 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7982439662922513, 'Total loss': 0.7982439662922513} | train loss {'Reaction outcome loss': 0.8199247425866996, 'Total loss': 0.8199247425866996}
2022-11-18 02:21:28,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:28,352 INFO:     Epoch: 20
2022-11-18 02:21:29,147 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8222189748829062, 'Total loss': 0.8222189748829062} | train loss {'Reaction outcome loss': 0.8166562736275708, 'Total loss': 0.8166562736275708}
2022-11-18 02:21:29,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:29,148 INFO:     Epoch: 21
2022-11-18 02:21:29,943 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8103051673282277, 'Total loss': 0.8103051673282277} | train loss {'Reaction outcome loss': 0.8114837414098655, 'Total loss': 0.8114837414098655}
2022-11-18 02:21:29,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:29,943 INFO:     Epoch: 22
2022-11-18 02:21:30,755 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.825591737573797, 'Total loss': 0.825591737573797} | train loss {'Reaction outcome loss': 0.8142685972244633, 'Total loss': 0.8142685972244633}
2022-11-18 02:21:30,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:30,756 INFO:     Epoch: 23
2022-11-18 02:21:31,534 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7902769229628823, 'Total loss': 0.7902769229628823} | train loss {'Reaction outcome loss': 0.8120857697990742, 'Total loss': 0.8120857697990742}
2022-11-18 02:21:31,534 INFO:     Found new best model at epoch 23
2022-11-18 02:21:31,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:31,535 INFO:     Epoch: 24
2022-11-18 02:21:32,360 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8067281036214395, 'Total loss': 0.8067281036214395} | train loss {'Reaction outcome loss': 0.81471432305058, 'Total loss': 0.81471432305058}
2022-11-18 02:21:32,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:32,361 INFO:     Epoch: 25
2022-11-18 02:21:33,179 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7959736992012371, 'Total loss': 0.7959736992012371} | train loss {'Reaction outcome loss': 0.817417517968035, 'Total loss': 0.817417517968035}
2022-11-18 02:21:33,179 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:33,179 INFO:     Epoch: 26
2022-11-18 02:21:33,980 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8008304692127488, 'Total loss': 0.8008304692127488} | train loss {'Reaction outcome loss': 0.8166005518513653, 'Total loss': 0.8166005518513653}
2022-11-18 02:21:33,980 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:33,980 INFO:     Epoch: 27
2022-11-18 02:21:34,807 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7889186218380928, 'Total loss': 0.7889186218380928} | train loss {'Reaction outcome loss': 0.8147394187778596, 'Total loss': 0.8147394187778596}
2022-11-18 02:21:34,807 INFO:     Found new best model at epoch 27
2022-11-18 02:21:34,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:34,808 INFO:     Epoch: 28
2022-11-18 02:21:35,637 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8129019466313449, 'Total loss': 0.8129019466313449} | train loss {'Reaction outcome loss': 0.8100110667226045, 'Total loss': 0.8100110667226045}
2022-11-18 02:21:35,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:35,637 INFO:     Epoch: 29
2022-11-18 02:21:36,429 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7865862135182727, 'Total loss': 0.7865862135182727} | train loss {'Reaction outcome loss': 0.8100701719522476, 'Total loss': 0.8100701719522476}
2022-11-18 02:21:36,430 INFO:     Found new best model at epoch 29
2022-11-18 02:21:36,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:36,431 INFO:     Epoch: 30
2022-11-18 02:21:37,235 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8014574308287014, 'Total loss': 0.8014574308287014} | train loss {'Reaction outcome loss': 0.8131799352796454, 'Total loss': 0.8131799352796454}
2022-11-18 02:21:37,235 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:37,235 INFO:     Epoch: 31
2022-11-18 02:21:38,041 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.792725795371966, 'Total loss': 0.792725795371966} | train loss {'Reaction outcome loss': 0.8133926149080639, 'Total loss': 0.8133926149080639}
2022-11-18 02:21:38,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:38,042 INFO:     Epoch: 32
2022-11-18 02:21:38,816 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8170059072700414, 'Total loss': 0.8170059072700414} | train loss {'Reaction outcome loss': 0.8131023790189612, 'Total loss': 0.8131023790189612}
2022-11-18 02:21:38,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:38,816 INFO:     Epoch: 33
2022-11-18 02:21:39,647 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7958502112464472, 'Total loss': 0.7958502112464472} | train loss {'Reaction outcome loss': 0.8141661413044099, 'Total loss': 0.8141661413044099}
2022-11-18 02:21:39,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:39,647 INFO:     Epoch: 34
2022-11-18 02:21:40,473 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7913174818862568, 'Total loss': 0.7913174818862568} | train loss {'Reaction outcome loss': 0.8232546529547888, 'Total loss': 0.8232546529547888}
2022-11-18 02:21:40,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:40,473 INFO:     Epoch: 35
2022-11-18 02:21:41,291 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7982542670585893, 'Total loss': 0.7982542670585893} | train loss {'Reaction outcome loss': 0.8139870502507156, 'Total loss': 0.8139870502507156}
2022-11-18 02:21:41,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:41,292 INFO:     Epoch: 36
2022-11-18 02:21:42,110 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7865767038681291, 'Total loss': 0.7865767038681291} | train loss {'Reaction outcome loss': 0.8145977298499119, 'Total loss': 0.8145977298499119}
2022-11-18 02:21:42,110 INFO:     Found new best model at epoch 36
2022-11-18 02:21:42,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:42,111 INFO:     Epoch: 37
2022-11-18 02:21:42,904 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7973525442860343, 'Total loss': 0.7973525442860343} | train loss {'Reaction outcome loss': 0.8106147756702021, 'Total loss': 0.8106147756702021}
2022-11-18 02:21:42,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:42,905 INFO:     Epoch: 38
2022-11-18 02:21:43,691 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.793822628530589, 'Total loss': 0.793822628530589} | train loss {'Reaction outcome loss': 0.8212502668743674, 'Total loss': 0.8212502668743674}
2022-11-18 02:21:43,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:43,691 INFO:     Epoch: 39
2022-11-18 02:21:44,490 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7836006432771683, 'Total loss': 0.7836006432771683} | train loss {'Reaction outcome loss': 0.8099493064921395, 'Total loss': 0.8099493064921395}
2022-11-18 02:21:44,491 INFO:     Found new best model at epoch 39
2022-11-18 02:21:44,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:44,492 INFO:     Epoch: 40
2022-11-18 02:21:45,277 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7882630181583491, 'Total loss': 0.7882630181583491} | train loss {'Reaction outcome loss': 0.8136958639148758, 'Total loss': 0.8136958639148758}
2022-11-18 02:21:45,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:45,277 INFO:     Epoch: 41
2022-11-18 02:21:46,085 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.799178039485758, 'Total loss': 0.799178039485758} | train loss {'Reaction outcome loss': 0.813335637211317, 'Total loss': 0.813335637211317}
2022-11-18 02:21:46,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:46,085 INFO:     Epoch: 42
2022-11-18 02:21:46,914 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8106004175814715, 'Total loss': 0.8106004175814715} | train loss {'Reaction outcome loss': 0.8110125628318864, 'Total loss': 0.8110125628318864}
2022-11-18 02:21:46,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:46,915 INFO:     Epoch: 43
2022-11-18 02:21:47,705 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7924521192908287, 'Total loss': 0.7924521192908287} | train loss {'Reaction outcome loss': 0.8150481810936561, 'Total loss': 0.8150481810936561}
2022-11-18 02:21:47,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:47,705 INFO:     Epoch: 44
2022-11-18 02:21:48,535 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7977282228794965, 'Total loss': 0.7977282228794965} | train loss {'Reaction outcome loss': 0.8130421044855465, 'Total loss': 0.8130421044855465}
2022-11-18 02:21:48,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:48,535 INFO:     Epoch: 45
2022-11-18 02:21:49,346 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.798474981026216, 'Total loss': 0.798474981026216} | train loss {'Reaction outcome loss': 0.8135162361478998, 'Total loss': 0.8135162361478998}
2022-11-18 02:21:49,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:49,346 INFO:     Epoch: 46
2022-11-18 02:21:50,146 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7848729003559459, 'Total loss': 0.7848729003559459} | train loss {'Reaction outcome loss': 0.8103391704289055, 'Total loss': 0.8103391704289055}
2022-11-18 02:21:50,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:50,146 INFO:     Epoch: 47
2022-11-18 02:21:50,951 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7926130951805548, 'Total loss': 0.7926130951805548} | train loss {'Reaction outcome loss': 0.8113124845964224, 'Total loss': 0.8113124845964224}
2022-11-18 02:21:50,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:50,951 INFO:     Epoch: 48
2022-11-18 02:21:51,740 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7846280945972963, 'Total loss': 0.7846280945972963} | train loss {'Reaction outcome loss': 0.8220503704267957, 'Total loss': 0.8220503704267957}
2022-11-18 02:21:51,740 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:51,740 INFO:     Epoch: 49
2022-11-18 02:21:52,530 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8019103015011008, 'Total loss': 0.8019103015011008} | train loss {'Reaction outcome loss': 0.8170394966235528, 'Total loss': 0.8170394966235528}
2022-11-18 02:21:52,530 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:52,530 INFO:     Epoch: 50
2022-11-18 02:21:53,341 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7865618148987944, 'Total loss': 0.7865618148987944} | train loss {'Reaction outcome loss': 0.8089186698801605, 'Total loss': 0.8089186698801605}
2022-11-18 02:21:53,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:53,341 INFO:     Epoch: 51
2022-11-18 02:21:54,142 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7797441523183476, 'Total loss': 0.7797441523183476} | train loss {'Reaction outcome loss': 0.8172241894581057, 'Total loss': 0.8172241894581057}
2022-11-18 02:21:54,142 INFO:     Found new best model at epoch 51
2022-11-18 02:21:54,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:54,143 INFO:     Epoch: 52
2022-11-18 02:21:54,958 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7911101566119627, 'Total loss': 0.7911101566119627} | train loss {'Reaction outcome loss': 0.8135163592785476, 'Total loss': 0.8135163592785476}
2022-11-18 02:21:54,958 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:54,958 INFO:     Epoch: 53
2022-11-18 02:21:55,784 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8086803711273454, 'Total loss': 0.8086803711273454} | train loss {'Reaction outcome loss': 0.8126639548372402, 'Total loss': 0.8126639548372402}
2022-11-18 02:21:55,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:55,784 INFO:     Epoch: 54
2022-11-18 02:21:56,623 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8225420367988673, 'Total loss': 0.8225420367988673} | train loss {'Reaction outcome loss': 0.8149543358201561, 'Total loss': 0.8149543358201561}
2022-11-18 02:21:56,623 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:56,623 INFO:     Epoch: 55
2022-11-18 02:21:57,446 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7968303500251337, 'Total loss': 0.7968303500251337} | train loss {'Reaction outcome loss': 0.8111259308662492, 'Total loss': 0.8111259308662492}
2022-11-18 02:21:57,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:57,448 INFO:     Epoch: 56
2022-11-18 02:21:58,271 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8036178980361331, 'Total loss': 0.8036178980361331} | train loss {'Reaction outcome loss': 0.808609250435221, 'Total loss': 0.808609250435221}
2022-11-18 02:21:58,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:58,271 INFO:     Epoch: 57
2022-11-18 02:21:59,099 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7970379238778894, 'Total loss': 0.7970379238778894} | train loss {'Reaction outcome loss': 0.8133644293918301, 'Total loss': 0.8133644293918301}
2022-11-18 02:21:59,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:59,099 INFO:     Epoch: 58
2022-11-18 02:21:59,897 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7987005087462339, 'Total loss': 0.7987005087462339} | train loss {'Reaction outcome loss': 0.8193893330058588, 'Total loss': 0.8193893330058588}
2022-11-18 02:21:59,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:21:59,897 INFO:     Epoch: 59
2022-11-18 02:22:00,758 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8017176762223244, 'Total loss': 0.8017176762223244} | train loss {'Reaction outcome loss': 0.8147197052052146, 'Total loss': 0.8147197052052146}
2022-11-18 02:22:00,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:00,758 INFO:     Epoch: 60
2022-11-18 02:22:01,566 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8090990002859723, 'Total loss': 0.8090990002859723} | train loss {'Reaction outcome loss': 0.812732062479745, 'Total loss': 0.812732062479745}
2022-11-18 02:22:01,566 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:01,566 INFO:     Epoch: 61
2022-11-18 02:22:02,350 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.793804447081956, 'Total loss': 0.793804447081956} | train loss {'Reaction outcome loss': 0.8060420202581506, 'Total loss': 0.8060420202581506}
2022-11-18 02:22:02,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:02,350 INFO:     Epoch: 62
2022-11-18 02:22:03,154 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8288191374052655, 'Total loss': 0.8288191374052655} | train loss {'Reaction outcome loss': 0.8103995353345447, 'Total loss': 0.8103995353345447}
2022-11-18 02:22:03,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:03,154 INFO:     Epoch: 63
2022-11-18 02:22:03,973 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.82660788026723, 'Total loss': 0.82660788026723} | train loss {'Reaction outcome loss': 0.8208572264866307, 'Total loss': 0.8208572264866307}
2022-11-18 02:22:03,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:03,974 INFO:     Epoch: 64
2022-11-18 02:22:04,788 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8012254251675173, 'Total loss': 0.8012254251675173} | train loss {'Reaction outcome loss': 0.8311125914818844, 'Total loss': 0.8311125914818844}
2022-11-18 02:22:04,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:04,788 INFO:     Epoch: 65
2022-11-18 02:22:05,572 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7957986539060419, 'Total loss': 0.7957986539060419} | train loss {'Reaction outcome loss': 0.815412413736104, 'Total loss': 0.815412413736104}
2022-11-18 02:22:05,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:05,572 INFO:     Epoch: 66
2022-11-18 02:22:06,387 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7825613990426064, 'Total loss': 0.7825613990426064} | train loss {'Reaction outcome loss': 0.8137118692098841, 'Total loss': 0.8137118692098841}
2022-11-18 02:22:06,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:06,387 INFO:     Epoch: 67
2022-11-18 02:22:07,192 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7998913377523422, 'Total loss': 0.7998913377523422} | train loss {'Reaction outcome loss': 0.8141373463487818, 'Total loss': 0.8141373463487818}
2022-11-18 02:22:07,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:07,192 INFO:     Epoch: 68
2022-11-18 02:22:08,020 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8044317967512391, 'Total loss': 0.8044317967512391} | train loss {'Reaction outcome loss': 0.809669030822723, 'Total loss': 0.809669030822723}
2022-11-18 02:22:08,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:08,020 INFO:     Epoch: 69
2022-11-18 02:22:08,818 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8020844175056978, 'Total loss': 0.8020844175056978} | train loss {'Reaction outcome loss': 0.8141762439297279, 'Total loss': 0.8141762439297279}
2022-11-18 02:22:08,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:08,819 INFO:     Epoch: 70
2022-11-18 02:22:09,657 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7778064838864587, 'Total loss': 0.7778064838864587} | train loss {'Reaction outcome loss': 0.8093398112637794, 'Total loss': 0.8093398112637794}
2022-11-18 02:22:09,657 INFO:     Found new best model at epoch 70
2022-11-18 02:22:09,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:09,658 INFO:     Epoch: 71
2022-11-18 02:22:10,483 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7947131070223722, 'Total loss': 0.7947131070223722} | train loss {'Reaction outcome loss': 0.809423563813391, 'Total loss': 0.809423563813391}
2022-11-18 02:22:10,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:10,484 INFO:     Epoch: 72
2022-11-18 02:22:11,267 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8066860857335004, 'Total loss': 0.8066860857335004} | train loss {'Reaction outcome loss': 0.8128350067597169, 'Total loss': 0.8128350067597169}
2022-11-18 02:22:11,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:11,267 INFO:     Epoch: 73
2022-11-18 02:22:12,101 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7896162799813531, 'Total loss': 0.7896162799813531} | train loss {'Reaction outcome loss': 0.8147069654966655, 'Total loss': 0.8147069654966655}
2022-11-18 02:22:12,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:12,101 INFO:     Epoch: 74
2022-11-18 02:22:12,926 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8071118356152014, 'Total loss': 0.8071118356152014} | train loss {'Reaction outcome loss': 0.8177244091323512, 'Total loss': 0.8177244091323512}
2022-11-18 02:22:12,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:12,926 INFO:     Epoch: 75
2022-11-18 02:22:13,713 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8265210064974698, 'Total loss': 0.8265210064974698} | train loss {'Reaction outcome loss': 0.8084621246044452, 'Total loss': 0.8084621246044452}
2022-11-18 02:22:13,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:13,713 INFO:     Epoch: 76
2022-11-18 02:22:14,533 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7997854209759019, 'Total loss': 0.7997854209759019} | train loss {'Reaction outcome loss': 0.8097755531309104, 'Total loss': 0.8097755531309104}
2022-11-18 02:22:14,533 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:14,533 INFO:     Epoch: 77
2022-11-18 02:22:15,303 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7792585160244595, 'Total loss': 0.7792585160244595} | train loss {'Reaction outcome loss': 0.8085400666664486, 'Total loss': 0.8085400666664486}
2022-11-18 02:22:15,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:15,304 INFO:     Epoch: 78
2022-11-18 02:22:16,123 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8081056306307967, 'Total loss': 0.8081056306307967} | train loss {'Reaction outcome loss': 0.815414457186031, 'Total loss': 0.815414457186031}
2022-11-18 02:22:16,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:16,125 INFO:     Epoch: 79
2022-11-18 02:22:16,911 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.815211602232673, 'Total loss': 0.815211602232673} | train loss {'Reaction outcome loss': 0.8154622488900235, 'Total loss': 0.8154622488900235}
2022-11-18 02:22:16,911 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:16,911 INFO:     Epoch: 80
2022-11-18 02:22:17,724 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7853317816149105, 'Total loss': 0.7853317816149105} | train loss {'Reaction outcome loss': 0.8204928199771927, 'Total loss': 0.8204928199771927}
2022-11-18 02:22:17,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:17,724 INFO:     Epoch: 81
2022-11-18 02:22:18,560 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8032122552394867, 'Total loss': 0.8032122552394867} | train loss {'Reaction outcome loss': 0.8197944876153459, 'Total loss': 0.8197944876153459}
2022-11-18 02:22:18,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:18,560 INFO:     Epoch: 82
2022-11-18 02:22:19,410 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7969906045631929, 'Total loss': 0.7969906045631929} | train loss {'Reaction outcome loss': 0.819178814830085, 'Total loss': 0.819178814830085}
2022-11-18 02:22:19,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:19,410 INFO:     Epoch: 83
2022-11-18 02:22:20,218 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7916236573999579, 'Total loss': 0.7916236573999579} | train loss {'Reaction outcome loss': 0.8167944679617399, 'Total loss': 0.8167944679617399}
2022-11-18 02:22:20,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:20,218 INFO:     Epoch: 84
2022-11-18 02:22:21,037 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7875654954801906, 'Total loss': 0.7875654954801906} | train loss {'Reaction outcome loss': 0.8081600202722588, 'Total loss': 0.8081600202722588}
2022-11-18 02:22:21,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:21,037 INFO:     Epoch: 85
2022-11-18 02:22:21,854 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8070263327522711, 'Total loss': 0.8070263327522711} | train loss {'Reaction outcome loss': 0.8171077395981623, 'Total loss': 0.8171077395981623}
2022-11-18 02:22:21,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:21,854 INFO:     Epoch: 86
2022-11-18 02:22:22,702 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.81390081346035, 'Total loss': 0.81390081346035} | train loss {'Reaction outcome loss': 0.8175931039609408, 'Total loss': 0.8175931039609408}
2022-11-18 02:22:22,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:22,702 INFO:     Epoch: 87
2022-11-18 02:22:23,546 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7869327833706682, 'Total loss': 0.7869327833706682} | train loss {'Reaction outcome loss': 0.8130657931088436, 'Total loss': 0.8130657931088436}
2022-11-18 02:22:23,546 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:23,546 INFO:     Epoch: 88
2022-11-18 02:22:24,389 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8116974580017003, 'Total loss': 0.8116974580017003} | train loss {'Reaction outcome loss': 0.8068743313734348, 'Total loss': 0.8068743313734348}
2022-11-18 02:22:24,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:24,389 INFO:     Epoch: 89
2022-11-18 02:22:25,232 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7881195768713951, 'Total loss': 0.7881195768713951} | train loss {'Reaction outcome loss': 0.8178748516177359, 'Total loss': 0.8178748516177359}
2022-11-18 02:22:25,232 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:25,232 INFO:     Epoch: 90
2022-11-18 02:22:26,059 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7916776090860367, 'Total loss': 0.7916776090860367} | train loss {'Reaction outcome loss': 0.8102742242909636, 'Total loss': 0.8102742242909636}
2022-11-18 02:22:26,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:26,059 INFO:     Epoch: 91
2022-11-18 02:22:26,902 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8188237690112807, 'Total loss': 0.8188237690112807} | train loss {'Reaction outcome loss': 0.8107903065227786, 'Total loss': 0.8107903065227786}
2022-11-18 02:22:26,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:26,902 INFO:     Epoch: 92
2022-11-18 02:22:27,699 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8033101728016679, 'Total loss': 0.8033101728016679} | train loss {'Reaction outcome loss': 0.8131701326080663, 'Total loss': 0.8131701326080663}
2022-11-18 02:22:27,699 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:27,699 INFO:     Epoch: 93
2022-11-18 02:22:28,469 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8024112826043909, 'Total loss': 0.8024112826043909} | train loss {'Reaction outcome loss': 0.8163929375318381, 'Total loss': 0.8163929375318381}
2022-11-18 02:22:28,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:28,469 INFO:     Epoch: 94
2022-11-18 02:22:29,261 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7841529825871641, 'Total loss': 0.7841529825871641} | train loss {'Reaction outcome loss': 0.8082920622970411, 'Total loss': 0.8082920622970411}
2022-11-18 02:22:29,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:29,263 INFO:     Epoch: 95
2022-11-18 02:22:30,085 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8065858754244718, 'Total loss': 0.8065858754244718} | train loss {'Reaction outcome loss': 0.8126829295505879, 'Total loss': 0.8126829295505879}
2022-11-18 02:22:30,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:30,086 INFO:     Epoch: 96
2022-11-18 02:22:30,890 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7920961380004883, 'Total loss': 0.7920961380004883} | train loss {'Reaction outcome loss': 0.8146824720900069, 'Total loss': 0.8146824720900069}
2022-11-18 02:22:30,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:30,890 INFO:     Epoch: 97
2022-11-18 02:22:31,722 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7851241799918088, 'Total loss': 0.7851241799918088} | train loss {'Reaction outcome loss': 0.8092867497973114, 'Total loss': 0.8092867497973114}
2022-11-18 02:22:31,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:31,722 INFO:     Epoch: 98
2022-11-18 02:22:32,496 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7938096394593065, 'Total loss': 0.7938096394593065} | train loss {'Reaction outcome loss': 0.8070522268050113, 'Total loss': 0.8070522268050113}
2022-11-18 02:22:32,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:32,496 INFO:     Epoch: 99
2022-11-18 02:22:33,318 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8335874717343937, 'Total loss': 0.8335874717343937} | train loss {'Reaction outcome loss': 0.8176281753821895, 'Total loss': 0.8176281753821895}
2022-11-18 02:22:33,318 INFO:     Best model found after epoch 71 of 100.
2022-11-18 02:22:33,318 INFO:   Done with stage: TRAINING
2022-11-18 02:22:33,318 INFO:   Starting stage: EVALUATION
2022-11-18 02:22:33,444 INFO:   Done with stage: EVALUATION
2022-11-18 02:22:33,444 INFO:   Leaving out SEQ value Fold_6
2022-11-18 02:22:33,457 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 02:22:33,457 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:22:34,141 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:22:34,141 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:22:34,212 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:22:34,212 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:22:34,212 INFO:     No hyperparam tuning for this model
2022-11-18 02:22:34,212 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:22:34,212 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:22:34,213 INFO:     None feature selector for col prot
2022-11-18 02:22:34,213 INFO:     None feature selector for col prot
2022-11-18 02:22:34,213 INFO:     None feature selector for col prot
2022-11-18 02:22:34,214 INFO:     None feature selector for col chem
2022-11-18 02:22:34,214 INFO:     None feature selector for col chem
2022-11-18 02:22:34,214 INFO:     None feature selector for col chem
2022-11-18 02:22:34,214 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:22:34,214 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:22:34,215 INFO:     Number of params in model 168571
2022-11-18 02:22:34,219 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:22:34,219 INFO:   Starting stage: TRAINING
2022-11-18 02:22:34,277 INFO:     Val loss before train {'Reaction outcome loss': 1.0133752761916681, 'Total loss': 1.0133752761916681}
2022-11-18 02:22:34,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:34,277 INFO:     Epoch: 0
2022-11-18 02:22:35,099 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8488719111139124, 'Total loss': 0.8488719111139124} | train loss {'Reaction outcome loss': 0.8716388856351134, 'Total loss': 0.8716388856351134}
2022-11-18 02:22:35,099 INFO:     Found new best model at epoch 0
2022-11-18 02:22:35,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:35,100 INFO:     Epoch: 1
2022-11-18 02:22:35,926 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8588930124586279, 'Total loss': 0.8588930124586279} | train loss {'Reaction outcome loss': 0.845409054746512, 'Total loss': 0.845409054746512}
2022-11-18 02:22:35,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:35,927 INFO:     Epoch: 2
2022-11-18 02:22:36,769 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8679429902271791, 'Total loss': 0.8679429902271791} | train loss {'Reaction outcome loss': 0.8489005393103549, 'Total loss': 0.8489005393103549}
2022-11-18 02:22:36,769 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:36,769 INFO:     Epoch: 3
2022-11-18 02:22:37,556 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8651712279428135, 'Total loss': 0.8651712279428135} | train loss {'Reaction outcome loss': 0.8387128539413575, 'Total loss': 0.8387128539413575}
2022-11-18 02:22:37,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:37,556 INFO:     Epoch: 4
2022-11-18 02:22:38,368 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.863907506520098, 'Total loss': 0.863907506520098} | train loss {'Reaction outcome loss': 0.8368888865356986, 'Total loss': 0.8368888865356986}
2022-11-18 02:22:38,368 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:38,369 INFO:     Epoch: 5
2022-11-18 02:22:39,163 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8352825546806509, 'Total loss': 0.8352825546806509} | train loss {'Reaction outcome loss': 0.8287809486331245, 'Total loss': 0.8287809486331245}
2022-11-18 02:22:39,163 INFO:     Found new best model at epoch 5
2022-11-18 02:22:39,164 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:39,164 INFO:     Epoch: 6
2022-11-18 02:22:39,951 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8610825457356193, 'Total loss': 0.8610825457356193} | train loss {'Reaction outcome loss': 0.8319761832716012, 'Total loss': 0.8319761832716012}
2022-11-18 02:22:39,952 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:39,952 INFO:     Epoch: 7
2022-11-18 02:22:40,767 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8442610332911665, 'Total loss': 0.8442610332911665} | train loss {'Reaction outcome loss': 0.8301965400033634, 'Total loss': 0.8301965400033634}
2022-11-18 02:22:40,768 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:40,768 INFO:     Epoch: 8
2022-11-18 02:22:41,555 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8302572708238255, 'Total loss': 0.8302572708238255} | train loss {'Reaction outcome loss': 0.8381698253425026, 'Total loss': 0.8381698253425026}
2022-11-18 02:22:41,555 INFO:     Found new best model at epoch 8
2022-11-18 02:22:41,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:41,556 INFO:     Epoch: 9
2022-11-18 02:22:42,332 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8291029781103134, 'Total loss': 0.8291029781103134} | train loss {'Reaction outcome loss': 0.8262240519287133, 'Total loss': 0.8262240519287133}
2022-11-18 02:22:42,332 INFO:     Found new best model at epoch 9
2022-11-18 02:22:42,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:42,333 INFO:     Epoch: 10
2022-11-18 02:22:43,196 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8279319195584818, 'Total loss': 0.8279319195584818} | train loss {'Reaction outcome loss': 0.8250541854725193, 'Total loss': 0.8250541854725193}
2022-11-18 02:22:43,196 INFO:     Found new best model at epoch 10
2022-11-18 02:22:43,196 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:43,197 INFO:     Epoch: 11
2022-11-18 02:22:44,036 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8376702991398898, 'Total loss': 0.8376702991398898} | train loss {'Reaction outcome loss': 0.8233462732571822, 'Total loss': 0.8233462732571822}
2022-11-18 02:22:44,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:44,037 INFO:     Epoch: 12
2022-11-18 02:22:44,874 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8429005322131243, 'Total loss': 0.8429005322131243} | train loss {'Reaction outcome loss': 0.8268238803153096, 'Total loss': 0.8268238803153096}
2022-11-18 02:22:44,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:44,874 INFO:     Epoch: 13
2022-11-18 02:22:45,713 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8433078615502878, 'Total loss': 0.8433078615502878} | train loss {'Reaction outcome loss': 0.8221792099688218, 'Total loss': 0.8221792099688218}
2022-11-18 02:22:45,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:45,713 INFO:     Epoch: 14
2022-11-18 02:22:46,545 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8282135183160956, 'Total loss': 0.8282135183160956} | train loss {'Reaction outcome loss': 0.8327134184026526, 'Total loss': 0.8327134184026526}
2022-11-18 02:22:46,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:46,545 INFO:     Epoch: 15
2022-11-18 02:22:47,330 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.824424413794821, 'Total loss': 0.824424413794821} | train loss {'Reaction outcome loss': 0.8223825927205414, 'Total loss': 0.8223825927205414}
2022-11-18 02:22:47,330 INFO:     Found new best model at epoch 15
2022-11-18 02:22:47,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:47,331 INFO:     Epoch: 16
2022-11-18 02:22:48,166 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8457063646479086, 'Total loss': 0.8457063646479086} | train loss {'Reaction outcome loss': 0.8216519252008755, 'Total loss': 0.8216519252008755}
2022-11-18 02:22:48,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:48,167 INFO:     Epoch: 17
2022-11-18 02:22:48,981 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.868148834867911, 'Total loss': 0.868148834867911} | train loss {'Reaction outcome loss': 0.8308000530791186, 'Total loss': 0.8308000530791186}
2022-11-18 02:22:48,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:48,981 INFO:     Epoch: 18
2022-11-18 02:22:49,811 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8300455883145332, 'Total loss': 0.8300455883145332} | train loss {'Reaction outcome loss': 0.8273506433616283, 'Total loss': 0.8273506433616283}
2022-11-18 02:22:49,811 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:49,811 INFO:     Epoch: 19
2022-11-18 02:22:50,634 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8290718224915591, 'Total loss': 0.8290718224915591} | train loss {'Reaction outcome loss': 0.8183618734481364, 'Total loss': 0.8183618734481364}
2022-11-18 02:22:50,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:50,634 INFO:     Epoch: 20
2022-11-18 02:22:51,458 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8644996773112904, 'Total loss': 0.8644996773112904} | train loss {'Reaction outcome loss': 0.8156937034385889, 'Total loss': 0.8156937034385889}
2022-11-18 02:22:51,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:51,459 INFO:     Epoch: 21
2022-11-18 02:22:52,225 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.835708311335607, 'Total loss': 0.835708311335607} | train loss {'Reaction outcome loss': 0.8194675834977675, 'Total loss': 0.8194675834977675}
2022-11-18 02:22:52,225 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:52,225 INFO:     Epoch: 22
2022-11-18 02:22:53,063 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.81522148237987, 'Total loss': 0.81522148237987} | train loss {'Reaction outcome loss': 0.8199088286291732, 'Total loss': 0.8199088286291732}
2022-11-18 02:22:53,063 INFO:     Found new best model at epoch 22
2022-11-18 02:22:53,064 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:53,064 INFO:     Epoch: 23
2022-11-18 02:22:53,895 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8391325555064462, 'Total loss': 0.8391325555064462} | train loss {'Reaction outcome loss': 0.8195274664081542, 'Total loss': 0.8195274664081542}
2022-11-18 02:22:53,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:53,895 INFO:     Epoch: 24
2022-11-18 02:22:54,706 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8524932380427014, 'Total loss': 0.8524932380427014} | train loss {'Reaction outcome loss': 0.8214847316384798, 'Total loss': 0.8214847316384798}
2022-11-18 02:22:54,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:54,707 INFO:     Epoch: 25
2022-11-18 02:22:55,508 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8311708569526672, 'Total loss': 0.8311708569526672} | train loss {'Reaction outcome loss': 0.8158522446145896, 'Total loss': 0.8158522446145896}
2022-11-18 02:22:55,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:55,508 INFO:     Epoch: 26
2022-11-18 02:22:56,317 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8574875830249353, 'Total loss': 0.8574875830249353} | train loss {'Reaction outcome loss': 0.8232449102498259, 'Total loss': 0.8232449102498259}
2022-11-18 02:22:56,317 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:56,317 INFO:     Epoch: 27
2022-11-18 02:22:57,165 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8494025875221599, 'Total loss': 0.8494025875221599} | train loss {'Reaction outcome loss': 0.8172651383316951, 'Total loss': 0.8172651383316951}
2022-11-18 02:22:57,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:57,165 INFO:     Epoch: 28
2022-11-18 02:22:57,956 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8360201039097526, 'Total loss': 0.8360201039097526} | train loss {'Reaction outcome loss': 0.821485991540708, 'Total loss': 0.821485991540708}
2022-11-18 02:22:57,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:57,956 INFO:     Epoch: 29
2022-11-18 02:22:58,771 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8372176086360757, 'Total loss': 0.8372176086360757} | train loss {'Reaction outcome loss': 0.8216195941454003, 'Total loss': 0.8216195941454003}
2022-11-18 02:22:58,772 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:58,772 INFO:     Epoch: 30
2022-11-18 02:22:59,577 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.839668103239753, 'Total loss': 0.839668103239753} | train loss {'Reaction outcome loss': 0.8297808297008638, 'Total loss': 0.8297808297008638}
2022-11-18 02:22:59,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:22:59,578 INFO:     Epoch: 31
2022-11-18 02:23:00,390 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8445045941255309, 'Total loss': 0.8445045941255309} | train loss {'Reaction outcome loss': 0.818119061017326, 'Total loss': 0.818119061017326}
2022-11-18 02:23:00,391 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:00,391 INFO:     Epoch: 32
2022-11-18 02:23:01,240 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8262759961865165, 'Total loss': 0.8262759961865165} | train loss {'Reaction outcome loss': 0.8141816159491597, 'Total loss': 0.8141816159491597}
2022-11-18 02:23:01,240 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:01,241 INFO:     Epoch: 33
2022-11-18 02:23:02,048 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8422090336680412, 'Total loss': 0.8422090336680412} | train loss {'Reaction outcome loss': 0.8157279778588639, 'Total loss': 0.8157279778588639}
2022-11-18 02:23:02,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:02,048 INFO:     Epoch: 34
2022-11-18 02:23:02,868 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8276034796779806, 'Total loss': 0.8276034796779806} | train loss {'Reaction outcome loss': 0.8240949900044121, 'Total loss': 0.8240949900044121}
2022-11-18 02:23:02,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:02,868 INFO:     Epoch: 35
2022-11-18 02:23:03,655 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8329779505729675, 'Total loss': 0.8329779505729675} | train loss {'Reaction outcome loss': 0.8164126175617882, 'Total loss': 0.8164126175617882}
2022-11-18 02:23:03,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:03,655 INFO:     Epoch: 36
2022-11-18 02:23:04,437 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.826089012351903, 'Total loss': 0.826089012351903} | train loss {'Reaction outcome loss': 0.8106327425190795, 'Total loss': 0.8106327425190795}
2022-11-18 02:23:04,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:04,437 INFO:     Epoch: 37
2022-11-18 02:23:05,265 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8446721556511793, 'Total loss': 0.8446721556511793} | train loss {'Reaction outcome loss': 0.817348759545971, 'Total loss': 0.817348759545971}
2022-11-18 02:23:05,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:05,265 INFO:     Epoch: 38
2022-11-18 02:23:06,085 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.830295359546488, 'Total loss': 0.830295359546488} | train loss {'Reaction outcome loss': 0.8166237074112602, 'Total loss': 0.8166237074112602}
2022-11-18 02:23:06,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:06,086 INFO:     Epoch: 39
2022-11-18 02:23:06,885 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8211278014562347, 'Total loss': 0.8211278014562347} | train loss {'Reaction outcome loss': 0.819723589579586, 'Total loss': 0.819723589579586}
2022-11-18 02:23:06,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:06,886 INFO:     Epoch: 40
2022-11-18 02:23:07,663 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8267461718483404, 'Total loss': 0.8267461718483404} | train loss {'Reaction outcome loss': 0.8205195018637036, 'Total loss': 0.8205195018637036}
2022-11-18 02:23:07,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:07,663 INFO:     Epoch: 41
2022-11-18 02:23:08,441 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8362404385750944, 'Total loss': 0.8362404385750944} | train loss {'Reaction outcome loss': 0.8177369788349399, 'Total loss': 0.8177369788349399}
2022-11-18 02:23:08,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:08,441 INFO:     Epoch: 42
2022-11-18 02:23:09,248 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8279718377373435, 'Total loss': 0.8279718377373435} | train loss {'Reaction outcome loss': 0.8187633617686839, 'Total loss': 0.8187633617686839}
2022-11-18 02:23:09,249 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:09,249 INFO:     Epoch: 43
2022-11-18 02:23:10,084 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.832690726627003, 'Total loss': 0.832690726627003} | train loss {'Reaction outcome loss': 0.821118497534802, 'Total loss': 0.821118497534802}
2022-11-18 02:23:10,084 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:10,084 INFO:     Epoch: 44
2022-11-18 02:23:10,876 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.827297182245688, 'Total loss': 0.827297182245688} | train loss {'Reaction outcome loss': 0.8245086929334803, 'Total loss': 0.8245086929334803}
2022-11-18 02:23:10,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:10,876 INFO:     Epoch: 45
2022-11-18 02:23:11,704 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8286620927127925, 'Total loss': 0.8286620927127925} | train loss {'Reaction outcome loss': 0.8226257008820893, 'Total loss': 0.8226257008820893}
2022-11-18 02:23:11,705 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:11,705 INFO:     Epoch: 46
2022-11-18 02:23:12,508 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8273656246337023, 'Total loss': 0.8273656246337023} | train loss {'Reaction outcome loss': 0.8209041691260782, 'Total loss': 0.8209041691260782}
2022-11-18 02:23:12,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:12,508 INFO:     Epoch: 47
2022-11-18 02:23:13,308 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.822147863832387, 'Total loss': 0.822147863832387} | train loss {'Reaction outcome loss': 0.8174394056623281, 'Total loss': 0.8174394056623281}
2022-11-18 02:23:13,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:13,308 INFO:     Epoch: 48
2022-11-18 02:23:14,147 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8162993714213371, 'Total loss': 0.8162993714213371} | train loss {'Reaction outcome loss': 0.8119672567315912, 'Total loss': 0.8119672567315912}
2022-11-18 02:23:14,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:14,148 INFO:     Epoch: 49
2022-11-18 02:23:14,941 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8389725061980161, 'Total loss': 0.8389725061980161} | train loss {'Reaction outcome loss': 0.8134257661608549, 'Total loss': 0.8134257661608549}
2022-11-18 02:23:14,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:14,941 INFO:     Epoch: 50
2022-11-18 02:23:15,723 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8334108672358773, 'Total loss': 0.8334108672358773} | train loss {'Reaction outcome loss': 0.816642234561897, 'Total loss': 0.816642234561897}
2022-11-18 02:23:15,723 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:15,723 INFO:     Epoch: 51
2022-11-18 02:23:16,557 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8317177004434846, 'Total loss': 0.8317177004434846} | train loss {'Reaction outcome loss': 0.8134159265530978, 'Total loss': 0.8134159265530978}
2022-11-18 02:23:16,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:16,558 INFO:     Epoch: 52
2022-11-18 02:23:17,367 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8264238644729961, 'Total loss': 0.8264238644729961} | train loss {'Reaction outcome loss': 0.822056373965885, 'Total loss': 0.822056373965885}
2022-11-18 02:23:17,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:17,367 INFO:     Epoch: 53
2022-11-18 02:23:18,180 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8168663545088335, 'Total loss': 0.8168663545088335} | train loss {'Reaction outcome loss': 0.8116890344663188, 'Total loss': 0.8116890344663188}
2022-11-18 02:23:18,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:18,180 INFO:     Epoch: 54
2022-11-18 02:23:18,990 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8332855958830226, 'Total loss': 0.8332855958830226} | train loss {'Reaction outcome loss': 0.8147438433971482, 'Total loss': 0.8147438433971482}
2022-11-18 02:23:18,991 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:18,991 INFO:     Epoch: 55
2022-11-18 02:23:19,827 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.81854586167769, 'Total loss': 0.81854586167769} | train loss {'Reaction outcome loss': 0.8105593899845595, 'Total loss': 0.8105593899845595}
2022-11-18 02:23:19,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:19,827 INFO:     Epoch: 56
2022-11-18 02:23:20,615 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8266520364718004, 'Total loss': 0.8266520364718004} | train loss {'Reaction outcome loss': 0.8132600292020481, 'Total loss': 0.8132600292020481}
2022-11-18 02:23:20,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:20,615 INFO:     Epoch: 57
2022-11-18 02:23:21,409 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8363382308320566, 'Total loss': 0.8363382308320566} | train loss {'Reaction outcome loss': 0.8094008697973571, 'Total loss': 0.8094008697973571}
2022-11-18 02:23:21,409 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:21,409 INFO:     Epoch: 58
2022-11-18 02:23:22,266 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.821975284002044, 'Total loss': 0.821975284002044} | train loss {'Reaction outcome loss': 0.8110620510964258, 'Total loss': 0.8110620510964258}
2022-11-18 02:23:22,267 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:22,267 INFO:     Epoch: 59
2022-11-18 02:23:23,055 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.827236691659147, 'Total loss': 0.827236691659147} | train loss {'Reaction outcome loss': 0.8086962425395062, 'Total loss': 0.8086962425395062}
2022-11-18 02:23:23,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:23,055 INFO:     Epoch: 60
2022-11-18 02:23:23,892 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8046285225586458, 'Total loss': 0.8046285225586458} | train loss {'Reaction outcome loss': 0.8072617069671029, 'Total loss': 0.8072617069671029}
2022-11-18 02:23:23,893 INFO:     Found new best model at epoch 60
2022-11-18 02:23:23,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:23,894 INFO:     Epoch: 61
2022-11-18 02:23:24,734 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8592312410473824, 'Total loss': 0.8592312410473824} | train loss {'Reaction outcome loss': 0.8043742024222849, 'Total loss': 0.8043742024222849}
2022-11-18 02:23:24,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:24,734 INFO:     Epoch: 62
2022-11-18 02:23:25,540 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8021809201348912, 'Total loss': 0.8021809201348912} | train loss {'Reaction outcome loss': 0.8084126347713625, 'Total loss': 0.8084126347713625}
2022-11-18 02:23:25,540 INFO:     Found new best model at epoch 62
2022-11-18 02:23:25,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:25,541 INFO:     Epoch: 63
2022-11-18 02:23:26,342 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8557162867351011, 'Total loss': 0.8557162867351011} | train loss {'Reaction outcome loss': 0.8208074271678925, 'Total loss': 0.8208074271678925}
2022-11-18 02:23:26,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:26,342 INFO:     Epoch: 64
2022-11-18 02:23:27,141 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8133825964548371, 'Total loss': 0.8133825964548371} | train loss {'Reaction outcome loss': 0.8127235006465603, 'Total loss': 0.8127235006465603}
2022-11-18 02:23:27,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:27,141 INFO:     Epoch: 65
2022-11-18 02:23:27,944 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8391498923301697, 'Total loss': 0.8391498923301697} | train loss {'Reaction outcome loss': 0.8044188023216812, 'Total loss': 0.8044188023216812}
2022-11-18 02:23:27,945 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:27,945 INFO:     Epoch: 66
2022-11-18 02:23:28,741 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8081107830459421, 'Total loss': 0.8081107830459421} | train loss {'Reaction outcome loss': 0.8030993420223476, 'Total loss': 0.8030993420223476}
2022-11-18 02:23:28,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:28,742 INFO:     Epoch: 67
2022-11-18 02:23:29,542 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8317173732952639, 'Total loss': 0.8317173732952639} | train loss {'Reaction outcome loss': 0.8189295029591935, 'Total loss': 0.8189295029591935}
2022-11-18 02:23:29,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:29,542 INFO:     Epoch: 68
2022-11-18 02:23:30,371 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.823198030618104, 'Total loss': 0.823198030618104} | train loss {'Reaction outcome loss': 0.8226939197252636, 'Total loss': 0.8226939197252636}
2022-11-18 02:23:30,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:30,372 INFO:     Epoch: 69
2022-11-18 02:23:31,156 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8381693999875676, 'Total loss': 0.8381693999875676} | train loss {'Reaction outcome loss': 0.8093702946959237, 'Total loss': 0.8093702946959237}
2022-11-18 02:23:31,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:31,157 INFO:     Epoch: 70
2022-11-18 02:23:31,964 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8166561296040361, 'Total loss': 0.8166561296040361} | train loss {'Reaction outcome loss': 0.8044248305954914, 'Total loss': 0.8044248305954914}
2022-11-18 02:23:31,964 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:31,964 INFO:     Epoch: 71
2022-11-18 02:23:32,756 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8222498507662253, 'Total loss': 0.8222498507662253} | train loss {'Reaction outcome loss': 0.8086838029656815, 'Total loss': 0.8086838029656815}
2022-11-18 02:23:32,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:32,756 INFO:     Epoch: 72
2022-11-18 02:23:33,593 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8201724453405901, 'Total loss': 0.8201724453405901} | train loss {'Reaction outcome loss': 0.8044639006445584, 'Total loss': 0.8044639006445584}
2022-11-18 02:23:33,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:33,593 INFO:     Epoch: 73
2022-11-18 02:23:34,430 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8116130564700473, 'Total loss': 0.8116130564700473} | train loss {'Reaction outcome loss': 0.8075148494620072, 'Total loss': 0.8075148494620072}
2022-11-18 02:23:34,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:34,430 INFO:     Epoch: 74
2022-11-18 02:23:35,254 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8208985721523111, 'Total loss': 0.8208985721523111} | train loss {'Reaction outcome loss': 0.8065064238150593, 'Total loss': 0.8065064238150593}
2022-11-18 02:23:35,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:35,255 INFO:     Epoch: 75
2022-11-18 02:23:36,051 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8275969529693777, 'Total loss': 0.8275969529693777} | train loss {'Reaction outcome loss': 0.8137742455912987, 'Total loss': 0.8137742455912987}
2022-11-18 02:23:36,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:36,051 INFO:     Epoch: 76
2022-11-18 02:23:36,857 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.812834310260686, 'Total loss': 0.812834310260686} | train loss {'Reaction outcome loss': 0.8026971401955917, 'Total loss': 0.8026971401955917}
2022-11-18 02:23:36,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:36,857 INFO:     Epoch: 77
2022-11-18 02:23:37,662 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.830200003629381, 'Total loss': 0.830200003629381} | train loss {'Reaction outcome loss': 0.8087779376429585, 'Total loss': 0.8087779376429585}
2022-11-18 02:23:37,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:37,663 INFO:     Epoch: 78
2022-11-18 02:23:38,423 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8270071812651374, 'Total loss': 0.8270071812651374} | train loss {'Reaction outcome loss': 0.8129577107033749, 'Total loss': 0.8129577107033749}
2022-11-18 02:23:38,423 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:38,423 INFO:     Epoch: 79
2022-11-18 02:23:39,213 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8232196853919462, 'Total loss': 0.8232196853919462} | train loss {'Reaction outcome loss': 0.8003062743407029, 'Total loss': 0.8003062743407029}
2022-11-18 02:23:39,213 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:39,213 INFO:     Epoch: 80
2022-11-18 02:23:40,029 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8111382567069747, 'Total loss': 0.8111382567069747} | train loss {'Reaction outcome loss': 0.8031044992267603, 'Total loss': 0.8031044992267603}
2022-11-18 02:23:40,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:40,030 INFO:     Epoch: 81
2022-11-18 02:23:40,814 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.804894594983621, 'Total loss': 0.804894594983621} | train loss {'Reaction outcome loss': 0.7991152294130943, 'Total loss': 0.7991152294130943}
2022-11-18 02:23:40,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:40,814 INFO:     Epoch: 82
2022-11-18 02:23:41,632 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7915599088777195, 'Total loss': 0.7915599088777195} | train loss {'Reaction outcome loss': 0.8028244191577077, 'Total loss': 0.8028244191577077}
2022-11-18 02:23:41,632 INFO:     Found new best model at epoch 82
2022-11-18 02:23:41,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:41,633 INFO:     Epoch: 83
2022-11-18 02:23:42,408 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7966746904633262, 'Total loss': 0.7966746904633262} | train loss {'Reaction outcome loss': 0.8005175243927399, 'Total loss': 0.8005175243927399}
2022-11-18 02:23:42,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:42,408 INFO:     Epoch: 84
2022-11-18 02:23:43,211 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8037917573343624, 'Total loss': 0.8037917573343624} | train loss {'Reaction outcome loss': 0.8023033067282395, 'Total loss': 0.8023033067282395}
2022-11-18 02:23:43,211 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:43,211 INFO:     Epoch: 85
2022-11-18 02:23:44,010 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8064986968582327, 'Total loss': 0.8064986968582327} | train loss {'Reaction outcome loss': 0.7995897641307429, 'Total loss': 0.7995897641307429}
2022-11-18 02:23:44,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:44,010 INFO:     Epoch: 86
2022-11-18 02:23:44,800 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8126984116705981, 'Total loss': 0.8126984116705981} | train loss {'Reaction outcome loss': 0.8007928730263884, 'Total loss': 0.8007928730263884}
2022-11-18 02:23:44,800 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:44,800 INFO:     Epoch: 87
2022-11-18 02:23:45,648 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7960301793434403, 'Total loss': 0.7960301793434403} | train loss {'Reaction outcome loss': 0.7980208658737692, 'Total loss': 0.7980208658737692}
2022-11-18 02:23:45,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:45,648 INFO:     Epoch: 88
2022-11-18 02:23:46,461 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7954251583326947, 'Total loss': 0.7954251583326947} | train loss {'Reaction outcome loss': 0.7899952842156414, 'Total loss': 0.7899952842156414}
2022-11-18 02:23:46,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:46,461 INFO:     Epoch: 89
2022-11-18 02:23:47,271 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8114346631548621, 'Total loss': 0.8114346631548621} | train loss {'Reaction outcome loss': 0.798723366217092, 'Total loss': 0.798723366217092}
2022-11-18 02:23:47,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:47,272 INFO:     Epoch: 90
2022-11-18 02:23:48,063 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8014064769853245, 'Total loss': 0.8014064769853245} | train loss {'Reaction outcome loss': 0.7921500025611175, 'Total loss': 0.7921500025611175}
2022-11-18 02:23:48,063 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:48,063 INFO:     Epoch: 91
2022-11-18 02:23:48,875 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8047544929114255, 'Total loss': 0.8047544929114255} | train loss {'Reaction outcome loss': 0.7989347117391192, 'Total loss': 0.7989347117391192}
2022-11-18 02:23:48,876 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:48,876 INFO:     Epoch: 92
2022-11-18 02:23:49,667 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8128238516775045, 'Total loss': 0.8128238516775045} | train loss {'Reaction outcome loss': 0.7978019191909899, 'Total loss': 0.7978019191909899}
2022-11-18 02:23:49,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:49,668 INFO:     Epoch: 93
2022-11-18 02:23:50,459 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.834315612912178, 'Total loss': 0.834315612912178} | train loss {'Reaction outcome loss': 0.787719499244381, 'Total loss': 0.787719499244381}
2022-11-18 02:23:50,459 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:50,460 INFO:     Epoch: 94
2022-11-18 02:23:51,259 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8050590408119288, 'Total loss': 0.8050590408119288} | train loss {'Reaction outcome loss': 0.7867866824965487, 'Total loss': 0.7867866824965487}
2022-11-18 02:23:51,259 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:51,259 INFO:     Epoch: 95
2022-11-18 02:23:52,067 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8068451861088927, 'Total loss': 0.8068451861088927} | train loss {'Reaction outcome loss': 0.7924706880380268, 'Total loss': 0.7924706880380268}
2022-11-18 02:23:52,067 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:52,068 INFO:     Epoch: 96
2022-11-18 02:23:52,890 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7891609580679373, 'Total loss': 0.7891609580679373} | train loss {'Reaction outcome loss': 0.7899814260150739, 'Total loss': 0.7899814260150739}
2022-11-18 02:23:52,890 INFO:     Found new best model at epoch 96
2022-11-18 02:23:52,891 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:52,891 INFO:     Epoch: 97
2022-11-18 02:23:53,687 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7902157381176949, 'Total loss': 0.7902157381176949} | train loss {'Reaction outcome loss': 0.7886342795995566, 'Total loss': 0.7886342795995566}
2022-11-18 02:23:53,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:53,687 INFO:     Epoch: 98
2022-11-18 02:23:54,502 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7823219814083793, 'Total loss': 0.7823219814083793} | train loss {'Reaction outcome loss': 0.7850158513798887, 'Total loss': 0.7850158513798887}
2022-11-18 02:23:54,502 INFO:     Found new best model at epoch 98
2022-11-18 02:23:54,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:54,503 INFO:     Epoch: 99
2022-11-18 02:23:55,296 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7839619463140314, 'Total loss': 0.7839619463140314} | train loss {'Reaction outcome loss': 0.7824610421275683, 'Total loss': 0.7824610421275683}
2022-11-18 02:23:55,296 INFO:     Best model found after epoch 99 of 100.
2022-11-18 02:23:55,296 INFO:   Done with stage: TRAINING
2022-11-18 02:23:55,296 INFO:   Starting stage: EVALUATION
2022-11-18 02:23:55,422 INFO:   Done with stage: EVALUATION
2022-11-18 02:23:55,422 INFO:   Leaving out SEQ value Fold_7
2022-11-18 02:23:55,435 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 02:23:55,436 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:23:56,100 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:23:56,100 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:23:56,170 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:23:56,171 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:23:56,171 INFO:     No hyperparam tuning for this model
2022-11-18 02:23:56,171 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:23:56,171 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:23:56,171 INFO:     None feature selector for col prot
2022-11-18 02:23:56,172 INFO:     None feature selector for col prot
2022-11-18 02:23:56,172 INFO:     None feature selector for col prot
2022-11-18 02:23:56,172 INFO:     None feature selector for col chem
2022-11-18 02:23:56,172 INFO:     None feature selector for col chem
2022-11-18 02:23:56,172 INFO:     None feature selector for col chem
2022-11-18 02:23:56,173 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:23:56,173 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:23:56,174 INFO:     Number of params in model 168571
2022-11-18 02:23:56,177 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:23:56,178 INFO:   Starting stage: TRAINING
2022-11-18 02:23:56,236 INFO:     Val loss before train {'Reaction outcome loss': 1.0068273733962665, 'Total loss': 1.0068273733962665}
2022-11-18 02:23:56,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:56,236 INFO:     Epoch: 0
2022-11-18 02:23:57,023 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.841340796513991, 'Total loss': 0.841340796513991} | train loss {'Reaction outcome loss': 0.8797292821109295, 'Total loss': 0.8797292821109295}
2022-11-18 02:23:57,023 INFO:     Found new best model at epoch 0
2022-11-18 02:23:57,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:57,024 INFO:     Epoch: 1
2022-11-18 02:23:57,814 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8494601330973885, 'Total loss': 0.8494601330973885} | train loss {'Reaction outcome loss': 0.8359036526132014, 'Total loss': 0.8359036526132014}
2022-11-18 02:23:57,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:57,814 INFO:     Epoch: 2
2022-11-18 02:23:58,595 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8464086353778839, 'Total loss': 0.8464086353778839} | train loss {'Reaction outcome loss': 0.8309748701510891, 'Total loss': 0.8309748701510891}
2022-11-18 02:23:58,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:58,596 INFO:     Epoch: 3
2022-11-18 02:23:59,360 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8504785387353464, 'Total loss': 0.8504785387353464} | train loss {'Reaction outcome loss': 0.8242587117898849, 'Total loss': 0.8242587117898849}
2022-11-18 02:23:59,360 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:23:59,360 INFO:     Epoch: 4
2022-11-18 02:24:00,161 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8346283557740125, 'Total loss': 0.8346283557740125} | train loss {'Reaction outcome loss': 0.8229899629950523, 'Total loss': 0.8229899629950523}
2022-11-18 02:24:00,161 INFO:     Found new best model at epoch 4
2022-11-18 02:24:00,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:00,162 INFO:     Epoch: 5
2022-11-18 02:24:00,953 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8409165462309663, 'Total loss': 0.8409165462309663} | train loss {'Reaction outcome loss': 0.8168190366798832, 'Total loss': 0.8168190366798832}
2022-11-18 02:24:00,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:00,953 INFO:     Epoch: 6
2022-11-18 02:24:01,775 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8389555845748294, 'Total loss': 0.8389555845748294} | train loss {'Reaction outcome loss': 0.8127861906203532, 'Total loss': 0.8127861906203532}
2022-11-18 02:24:01,775 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:01,775 INFO:     Epoch: 7
2022-11-18 02:24:02,586 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8416571454568342, 'Total loss': 0.8416571454568342} | train loss {'Reaction outcome loss': 0.8156949608556686, 'Total loss': 0.8156949608556686}
2022-11-18 02:24:02,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:02,587 INFO:     Epoch: 8
2022-11-18 02:24:03,388 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8280070112510161, 'Total loss': 0.8280070112510161} | train loss {'Reaction outcome loss': 0.8096745145176688, 'Total loss': 0.8096745145176688}
2022-11-18 02:24:03,388 INFO:     Found new best model at epoch 8
2022-11-18 02:24:03,389 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:03,389 INFO:     Epoch: 9
2022-11-18 02:24:04,192 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8394747945395383, 'Total loss': 0.8394747945395383} | train loss {'Reaction outcome loss': 0.8134811221351547, 'Total loss': 0.8134811221351547}
2022-11-18 02:24:04,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:04,193 INFO:     Epoch: 10
2022-11-18 02:24:04,969 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8285410329699516, 'Total loss': 0.8285410329699516} | train loss {'Reaction outcome loss': 0.8110595936736753, 'Total loss': 0.8110595936736753}
2022-11-18 02:24:04,969 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:04,969 INFO:     Epoch: 11
2022-11-18 02:24:05,757 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8619305640459061, 'Total loss': 0.8619305640459061} | train loss {'Reaction outcome loss': 0.8076106600703732, 'Total loss': 0.8076106600703732}
2022-11-18 02:24:05,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:05,757 INFO:     Epoch: 12
2022-11-18 02:24:06,541 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.829951333051378, 'Total loss': 0.829951333051378} | train loss {'Reaction outcome loss': 0.8071793325005039, 'Total loss': 0.8071793325005039}
2022-11-18 02:24:06,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:06,541 INFO:     Epoch: 13
2022-11-18 02:24:07,322 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8296332630244169, 'Total loss': 0.8296332630244169} | train loss {'Reaction outcome loss': 0.8072605252025589, 'Total loss': 0.8072605252025589}
2022-11-18 02:24:07,322 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:07,323 INFO:     Epoch: 14
2022-11-18 02:24:08,116 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8306354175914418, 'Total loss': 0.8306354175914418} | train loss {'Reaction outcome loss': 0.807762059232881, 'Total loss': 0.807762059232881}
2022-11-18 02:24:08,116 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:08,116 INFO:     Epoch: 15
2022-11-18 02:24:08,882 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8336591083895076, 'Total loss': 0.8336591083895076} | train loss {'Reaction outcome loss': 0.8057868743255254, 'Total loss': 0.8057868743255254}
2022-11-18 02:24:08,883 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:08,883 INFO:     Epoch: 16
2022-11-18 02:24:09,665 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8354493623430078, 'Total loss': 0.8354493623430078} | train loss {'Reaction outcome loss': 0.805742148670458, 'Total loss': 0.805742148670458}
2022-11-18 02:24:09,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:09,666 INFO:     Epoch: 17
2022-11-18 02:24:10,448 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.828304415399378, 'Total loss': 0.828304415399378} | train loss {'Reaction outcome loss': 0.809231071582725, 'Total loss': 0.809231071582725}
2022-11-18 02:24:10,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:10,449 INFO:     Epoch: 18
2022-11-18 02:24:11,236 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8341453481804241, 'Total loss': 0.8341453481804241} | train loss {'Reaction outcome loss': 0.8043388575315475, 'Total loss': 0.8043388575315475}
2022-11-18 02:24:11,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:11,236 INFO:     Epoch: 19
2022-11-18 02:24:12,033 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8269191248850389, 'Total loss': 0.8269191248850389} | train loss {'Reaction outcome loss': 0.8121931725932706, 'Total loss': 0.8121931725932706}
2022-11-18 02:24:12,033 INFO:     Found new best model at epoch 19
2022-11-18 02:24:12,034 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:12,034 INFO:     Epoch: 20
2022-11-18 02:24:12,826 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8607236295938492, 'Total loss': 0.8607236295938492} | train loss {'Reaction outcome loss': 0.8054264244293013, 'Total loss': 0.8054264244293013}
2022-11-18 02:24:12,826 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:12,826 INFO:     Epoch: 21
2022-11-18 02:24:13,638 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.837263326075944, 'Total loss': 0.837263326075944} | train loss {'Reaction outcome loss': 0.8051822485942994, 'Total loss': 0.8051822485942994}
2022-11-18 02:24:13,638 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:13,638 INFO:     Epoch: 22
2022-11-18 02:24:14,403 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8528998013247143, 'Total loss': 0.8528998013247143} | train loss {'Reaction outcome loss': 0.810267718568925, 'Total loss': 0.810267718568925}
2022-11-18 02:24:14,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:14,403 INFO:     Epoch: 23
2022-11-18 02:24:15,198 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8405200676484541, 'Total loss': 0.8405200676484541} | train loss {'Reaction outcome loss': 0.8047858504278045, 'Total loss': 0.8047858504278045}
2022-11-18 02:24:15,198 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:15,198 INFO:     Epoch: 24
2022-11-18 02:24:15,970 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8353906212882563, 'Total loss': 0.8353906212882563} | train loss {'Reaction outcome loss': 0.8083628565073013, 'Total loss': 0.8083628565073013}
2022-11-18 02:24:15,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:15,971 INFO:     Epoch: 25
2022-11-18 02:24:16,751 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8460620628161863, 'Total loss': 0.8460620628161863} | train loss {'Reaction outcome loss': 0.805509349030833, 'Total loss': 0.805509349030833}
2022-11-18 02:24:16,752 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:16,752 INFO:     Epoch: 26
2022-11-18 02:24:17,537 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8335275981913913, 'Total loss': 0.8335275981913913} | train loss {'Reaction outcome loss': 0.8074194476489098, 'Total loss': 0.8074194476489098}
2022-11-18 02:24:17,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:17,537 INFO:     Epoch: 27
2022-11-18 02:24:18,318 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8395928422158415, 'Total loss': 0.8395928422158415} | train loss {'Reaction outcome loss': 0.8066698148125603, 'Total loss': 0.8066698148125603}
2022-11-18 02:24:18,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:18,318 INFO:     Epoch: 28
2022-11-18 02:24:19,106 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8375205898826773, 'Total loss': 0.8375205898826773} | train loss {'Reaction outcome loss': 0.8059038851530321, 'Total loss': 0.8059038851530321}
2022-11-18 02:24:19,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:19,106 INFO:     Epoch: 29
2022-11-18 02:24:19,906 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8305958238514987, 'Total loss': 0.8305958238514987} | train loss {'Reaction outcome loss': 0.8062061729931063, 'Total loss': 0.8062061729931063}
2022-11-18 02:24:19,906 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:19,907 INFO:     Epoch: 30
2022-11-18 02:24:20,687 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8321775069290941, 'Total loss': 0.8321775069290941} | train loss {'Reaction outcome loss': 0.8064240760380222, 'Total loss': 0.8064240760380222}
2022-11-18 02:24:20,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:20,688 INFO:     Epoch: 31
2022-11-18 02:24:21,502 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8285971730947495, 'Total loss': 0.8285971730947495} | train loss {'Reaction outcome loss': 0.8067289634097007, 'Total loss': 0.8067289634097007}
2022-11-18 02:24:21,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:21,503 INFO:     Epoch: 32
2022-11-18 02:24:22,277 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8370106592774391, 'Total loss': 0.8370106592774391} | train loss {'Reaction outcome loss': 0.8077897767145787, 'Total loss': 0.8077897767145787}
2022-11-18 02:24:22,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:22,278 INFO:     Epoch: 33
2022-11-18 02:24:23,095 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8253895389762792, 'Total loss': 0.8253895389762792} | train loss {'Reaction outcome loss': 0.8031042354001153, 'Total loss': 0.8031042354001153}
2022-11-18 02:24:23,095 INFO:     Found new best model at epoch 33
2022-11-18 02:24:23,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:23,096 INFO:     Epoch: 34
2022-11-18 02:24:23,899 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8248795406384901, 'Total loss': 0.8248795406384901} | train loss {'Reaction outcome loss': 0.8059216073203471, 'Total loss': 0.8059216073203471}
2022-11-18 02:24:23,899 INFO:     Found new best model at epoch 34
2022-11-18 02:24:23,899 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:23,900 INFO:     Epoch: 35
2022-11-18 02:24:24,676 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8233681077306921, 'Total loss': 0.8233681077306921} | train loss {'Reaction outcome loss': 0.8024394247801073, 'Total loss': 0.8024394247801073}
2022-11-18 02:24:24,676 INFO:     Found new best model at epoch 35
2022-11-18 02:24:24,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:24,677 INFO:     Epoch: 36
2022-11-18 02:24:25,457 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8359713730486956, 'Total loss': 0.8359713730486956} | train loss {'Reaction outcome loss': 0.8041673013039173, 'Total loss': 0.8041673013039173}
2022-11-18 02:24:25,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:25,457 INFO:     Epoch: 37
2022-11-18 02:24:26,242 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8483245074748993, 'Total loss': 0.8483245074748993} | train loss {'Reaction outcome loss': 0.8044748413226297, 'Total loss': 0.8044748413226297}
2022-11-18 02:24:26,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:26,242 INFO:     Epoch: 38
2022-11-18 02:24:27,041 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8293932026082819, 'Total loss': 0.8293932026082819} | train loss {'Reaction outcome loss': 0.8056764529357033, 'Total loss': 0.8056764529357033}
2022-11-18 02:24:27,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:27,041 INFO:     Epoch: 39
2022-11-18 02:24:27,824 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8240752003409646, 'Total loss': 0.8240752003409646} | train loss {'Reaction outcome loss': 0.8017588530576998, 'Total loss': 0.8017588530576998}
2022-11-18 02:24:27,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:27,824 INFO:     Epoch: 40
2022-11-18 02:24:28,627 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8352310068228028, 'Total loss': 0.8352310068228028} | train loss {'Reaction outcome loss': 0.8044850557081161, 'Total loss': 0.8044850557081161}
2022-11-18 02:24:28,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:28,627 INFO:     Epoch: 41
2022-11-18 02:24:29,436 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8298299874771725, 'Total loss': 0.8298299874771725} | train loss {'Reaction outcome loss': 0.806726811273444, 'Total loss': 0.806726811273444}
2022-11-18 02:24:29,436 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:29,436 INFO:     Epoch: 42
2022-11-18 02:24:30,269 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8379598964344371, 'Total loss': 0.8379598964344371} | train loss {'Reaction outcome loss': 0.8040881758976367, 'Total loss': 0.8040881758976367}
2022-11-18 02:24:30,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:30,269 INFO:     Epoch: 43
2022-11-18 02:24:31,052 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8344765291972593, 'Total loss': 0.8344765291972593} | train loss {'Reaction outcome loss': 0.8034948217532327, 'Total loss': 0.8034948217532327}
2022-11-18 02:24:31,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:31,052 INFO:     Epoch: 44
2022-11-18 02:24:31,817 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8252914615652778, 'Total loss': 0.8252914615652778} | train loss {'Reaction outcome loss': 0.8038444318357976, 'Total loss': 0.8038444318357976}
2022-11-18 02:24:31,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:31,817 INFO:     Epoch: 45
2022-11-18 02:24:32,582 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8291474011811343, 'Total loss': 0.8291474011811343} | train loss {'Reaction outcome loss': 0.8084947284190885, 'Total loss': 0.8084947284190885}
2022-11-18 02:24:32,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:32,582 INFO:     Epoch: 46
2022-11-18 02:24:33,354 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8317807723175396, 'Total loss': 0.8317807723175396} | train loss {'Reaction outcome loss': 0.8048660380225028, 'Total loss': 0.8048660380225028}
2022-11-18 02:24:33,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:33,354 INFO:     Epoch: 47
2022-11-18 02:24:34,160 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8491536582058127, 'Total loss': 0.8491536582058127} | train loss {'Reaction outcome loss': 0.8044916546392825, 'Total loss': 0.8044916546392825}
2022-11-18 02:24:34,161 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:34,161 INFO:     Epoch: 48
2022-11-18 02:24:34,933 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8349797034805472, 'Total loss': 0.8349797034805472} | train loss {'Reaction outcome loss': 0.8046159837995807, 'Total loss': 0.8046159837995807}
2022-11-18 02:24:34,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:34,933 INFO:     Epoch: 49
2022-11-18 02:24:35,760 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8621293746612289, 'Total loss': 0.8621293746612289} | train loss {'Reaction outcome loss': 0.8039670188821131, 'Total loss': 0.8039670188821131}
2022-11-18 02:24:35,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:35,760 INFO:     Epoch: 50
2022-11-18 02:24:36,571 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.833997601812536, 'Total loss': 0.833997601812536} | train loss {'Reaction outcome loss': 0.8089620014352183, 'Total loss': 0.8089620014352183}
2022-11-18 02:24:36,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:36,572 INFO:     Epoch: 51
2022-11-18 02:24:37,358 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8358059403571215, 'Total loss': 0.8358059403571215} | train loss {'Reaction outcome loss': 0.8073334543695373, 'Total loss': 0.8073334543695373}
2022-11-18 02:24:37,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:37,358 INFO:     Epoch: 52
2022-11-18 02:24:38,111 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8347663723609664, 'Total loss': 0.8347663723609664} | train loss {'Reaction outcome loss': 0.8039976754976857, 'Total loss': 0.8039976754976857}
2022-11-18 02:24:38,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:38,111 INFO:     Epoch: 53
2022-11-18 02:24:38,919 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8224252103404566, 'Total loss': 0.8224252103404566} | train loss {'Reaction outcome loss': 0.7975324891026943, 'Total loss': 0.7975324891026943}
2022-11-18 02:24:38,919 INFO:     Found new best model at epoch 53
2022-11-18 02:24:38,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:38,920 INFO:     Epoch: 54
2022-11-18 02:24:39,706 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8343948857350783, 'Total loss': 0.8343948857350783} | train loss {'Reaction outcome loss': 0.8073173018713151, 'Total loss': 0.8073173018713151}
2022-11-18 02:24:39,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:39,707 INFO:     Epoch: 55
2022-11-18 02:24:40,476 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8233542103659023, 'Total loss': 0.8233542103659023} | train loss {'Reaction outcome loss': 0.8048708769342592, 'Total loss': 0.8048708769342592}
2022-11-18 02:24:40,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:40,477 INFO:     Epoch: 56
2022-11-18 02:24:41,262 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8288336010141806, 'Total loss': 0.8288336010141806} | train loss {'Reaction outcome loss': 0.8033011963050212, 'Total loss': 0.8033011963050212}
2022-11-18 02:24:41,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:41,262 INFO:     Epoch: 57
2022-11-18 02:24:42,047 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8201392983848398, 'Total loss': 0.8201392983848398} | train loss {'Reaction outcome loss': 0.8034929309881502, 'Total loss': 0.8034929309881502}
2022-11-18 02:24:42,048 INFO:     Found new best model at epoch 57
2022-11-18 02:24:42,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:42,048 INFO:     Epoch: 58
2022-11-18 02:24:42,816 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8329029950228605, 'Total loss': 0.8329029950228605} | train loss {'Reaction outcome loss': 0.8045847856950376, 'Total loss': 0.8045847856950376}
2022-11-18 02:24:42,816 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:42,816 INFO:     Epoch: 59
2022-11-18 02:24:43,611 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8243811658837579, 'Total loss': 0.8243811658837579} | train loss {'Reaction outcome loss': 0.8058339131455268, 'Total loss': 0.8058339131455268}
2022-11-18 02:24:43,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:43,611 INFO:     Epoch: 60
2022-11-18 02:24:44,408 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8321064155210148, 'Total loss': 0.8321064155210148} | train loss {'Reaction outcome loss': 0.8027073940442454, 'Total loss': 0.8027073940442454}
2022-11-18 02:24:44,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:44,408 INFO:     Epoch: 61
2022-11-18 02:24:45,193 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8349695673043077, 'Total loss': 0.8349695673043077} | train loss {'Reaction outcome loss': 0.8020435075365728, 'Total loss': 0.8020435075365728}
2022-11-18 02:24:45,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:45,193 INFO:     Epoch: 62
2022-11-18 02:24:45,997 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8460936898534949, 'Total loss': 0.8460936898534949} | train loss {'Reaction outcome loss': 0.8059276701702226, 'Total loss': 0.8059276701702226}
2022-11-18 02:24:45,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:45,997 INFO:     Epoch: 63
2022-11-18 02:24:46,779 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.82151633026925, 'Total loss': 0.82151633026925} | train loss {'Reaction outcome loss': 0.8084250316023827, 'Total loss': 0.8084250316023827}
2022-11-18 02:24:46,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:46,780 INFO:     Epoch: 64
2022-11-18 02:24:47,592 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8547757078300823, 'Total loss': 0.8547757078300823} | train loss {'Reaction outcome loss': 0.8036448736825297, 'Total loss': 0.8036448736825297}
2022-11-18 02:24:47,592 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:47,592 INFO:     Epoch: 65
2022-11-18 02:24:48,367 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8413793553005565, 'Total loss': 0.8413793553005565} | train loss {'Reaction outcome loss': 0.8010008738886926, 'Total loss': 0.8010008738886926}
2022-11-18 02:24:48,367 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:48,367 INFO:     Epoch: 66
2022-11-18 02:24:49,140 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8274570618840781, 'Total loss': 0.8274570618840781} | train loss {'Reaction outcome loss': 0.7986806158817583, 'Total loss': 0.7986806158817583}
2022-11-18 02:24:49,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:49,141 INFO:     Epoch: 67
2022-11-18 02:24:49,938 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.841408327899196, 'Total loss': 0.841408327899196} | train loss {'Reaction outcome loss': 0.8031578551857702, 'Total loss': 0.8031578551857702}
2022-11-18 02:24:49,938 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:49,938 INFO:     Epoch: 68
2022-11-18 02:24:50,739 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8421529680490494, 'Total loss': 0.8421529680490494} | train loss {'Reaction outcome loss': 0.8036916255950928, 'Total loss': 0.8036916255950928}
2022-11-18 02:24:50,739 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:50,739 INFO:     Epoch: 69
2022-11-18 02:24:51,518 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8369629125703465, 'Total loss': 0.8369629125703465} | train loss {'Reaction outcome loss': 0.8026661685397548, 'Total loss': 0.8026661685397548}
2022-11-18 02:24:51,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:51,519 INFO:     Epoch: 70
2022-11-18 02:24:52,333 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8325426456603137, 'Total loss': 0.8325426456603137} | train loss {'Reaction outcome loss': 0.8042137992958869, 'Total loss': 0.8042137992958869}
2022-11-18 02:24:52,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:52,333 INFO:     Epoch: 71
2022-11-18 02:24:53,124 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8488202298229391, 'Total loss': 0.8488202298229391} | train loss {'Reaction outcome loss': 0.8046872051012132, 'Total loss': 0.8046872051012132}
2022-11-18 02:24:53,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:53,125 INFO:     Epoch: 72
2022-11-18 02:24:53,902 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8228276304223321, 'Total loss': 0.8228276304223321} | train loss {'Reaction outcome loss': 0.8032451055703624, 'Total loss': 0.8032451055703624}
2022-11-18 02:24:53,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:53,902 INFO:     Epoch: 73
2022-11-18 02:24:54,690 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8487317216667262, 'Total loss': 0.8487317216667262} | train loss {'Reaction outcome loss': 0.8083155718782256, 'Total loss': 0.8083155718782256}
2022-11-18 02:24:54,690 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:54,690 INFO:     Epoch: 74
2022-11-18 02:24:55,465 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8343025181781162, 'Total loss': 0.8343025181781162} | train loss {'Reaction outcome loss': 0.8080590580019259, 'Total loss': 0.8080590580019259}
2022-11-18 02:24:55,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:55,466 INFO:     Epoch: 75
2022-11-18 02:24:56,236 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8411350121552293, 'Total loss': 0.8411350121552293} | train loss {'Reaction outcome loss': 0.8064215942736594, 'Total loss': 0.8064215942736594}
2022-11-18 02:24:56,236 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:56,236 INFO:     Epoch: 76
2022-11-18 02:24:57,023 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8284911181439053, 'Total loss': 0.8284911181439053} | train loss {'Reaction outcome loss': 0.7993351203058997, 'Total loss': 0.7993351203058997}
2022-11-18 02:24:57,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:57,023 INFO:     Epoch: 77
2022-11-18 02:24:57,802 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8268483484333212, 'Total loss': 0.8268483484333212} | train loss {'Reaction outcome loss': 0.8002225214675549, 'Total loss': 0.8002225214675549}
2022-11-18 02:24:57,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:57,803 INFO:     Epoch: 78
2022-11-18 02:24:58,576 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8307682424783707, 'Total loss': 0.8307682424783707} | train loss {'Reaction outcome loss': 0.8004584652521918, 'Total loss': 0.8004584652521918}
2022-11-18 02:24:58,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:58,576 INFO:     Epoch: 79
2022-11-18 02:24:59,368 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8360157798637043, 'Total loss': 0.8360157798637043} | train loss {'Reaction outcome loss': 0.805759547819053, 'Total loss': 0.805759547819053}
2022-11-18 02:24:59,369 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:24:59,369 INFO:     Epoch: 80
2022-11-18 02:25:00,184 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8554432554678484, 'Total loss': 0.8554432554678484} | train loss {'Reaction outcome loss': 0.8036019946298292, 'Total loss': 0.8036019946298292}
2022-11-18 02:25:00,184 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:00,184 INFO:     Epoch: 81
2022-11-18 02:25:00,981 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8286896165121685, 'Total loss': 0.8286896165121685} | train loss {'Reaction outcome loss': 0.7989409898798312, 'Total loss': 0.7989409898798312}
2022-11-18 02:25:00,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:00,981 INFO:     Epoch: 82
2022-11-18 02:25:01,781 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8407285352322188, 'Total loss': 0.8407285352322188} | train loss {'Reaction outcome loss': 0.8041909691547194, 'Total loss': 0.8041909691547194}
2022-11-18 02:25:01,781 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:01,781 INFO:     Epoch: 83
2022-11-18 02:25:02,555 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8198521028865468, 'Total loss': 0.8198521028865468} | train loss {'Reaction outcome loss': 0.8039106650938911, 'Total loss': 0.8039106650938911}
2022-11-18 02:25:02,555 INFO:     Found new best model at epoch 83
2022-11-18 02:25:02,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:02,556 INFO:     Epoch: 84
2022-11-18 02:25:03,361 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.845268115401268, 'Total loss': 0.845268115401268} | train loss {'Reaction outcome loss': 0.8023347711611178, 'Total loss': 0.8023347711611178}
2022-11-18 02:25:03,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:03,361 INFO:     Epoch: 85
2022-11-18 02:25:04,175 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8068925921212543, 'Total loss': 0.8068925921212543} | train loss {'Reaction outcome loss': 0.8043390726370196, 'Total loss': 0.8043390726370196}
2022-11-18 02:25:04,175 INFO:     Found new best model at epoch 85
2022-11-18 02:25:04,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:04,176 INFO:     Epoch: 86
2022-11-18 02:25:04,978 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8435373604297638, 'Total loss': 0.8435373604297638} | train loss {'Reaction outcome loss': 0.8032993353422611, 'Total loss': 0.8032993353422611}
2022-11-18 02:25:04,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:04,979 INFO:     Epoch: 87
2022-11-18 02:25:05,748 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8200246373360808, 'Total loss': 0.8200246373360808} | train loss {'Reaction outcome loss': 0.8018948150978934, 'Total loss': 0.8018948150978934}
2022-11-18 02:25:05,748 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:05,749 INFO:     Epoch: 88
2022-11-18 02:25:06,569 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8512534702366049, 'Total loss': 0.8512534702366049} | train loss {'Reaction outcome loss': 0.8025578420248723, 'Total loss': 0.8025578420248723}
2022-11-18 02:25:06,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:06,570 INFO:     Epoch: 89
2022-11-18 02:25:07,357 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8286329792304472, 'Total loss': 0.8286329792304472} | train loss {'Reaction outcome loss': 0.8045247356978155, 'Total loss': 0.8045247356978155}
2022-11-18 02:25:07,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:07,358 INFO:     Epoch: 90
2022-11-18 02:25:08,128 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8191667131402276, 'Total loss': 0.8191667131402276} | train loss {'Reaction outcome loss': 0.8025456032445354, 'Total loss': 0.8025456032445354}
2022-11-18 02:25:08,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:08,129 INFO:     Epoch: 91
2022-11-18 02:25:08,922 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8278751407157291, 'Total loss': 0.8278751407157291} | train loss {'Reaction outcome loss': 0.8000563870995275, 'Total loss': 0.8000563870995275}
2022-11-18 02:25:08,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:08,923 INFO:     Epoch: 92
2022-11-18 02:25:09,709 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8290500288659876, 'Total loss': 0.8290500288659876} | train loss {'Reaction outcome loss': 0.8003832694263228, 'Total loss': 0.8003832694263228}
2022-11-18 02:25:09,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:09,709 INFO:     Epoch: 93
2022-11-18 02:25:10,479 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8230447701432488, 'Total loss': 0.8230447701432488} | train loss {'Reaction outcome loss': 0.8024740372934649, 'Total loss': 0.8024740372934649}
2022-11-18 02:25:10,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:10,479 INFO:     Epoch: 94
2022-11-18 02:25:11,285 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8217875043099577, 'Total loss': 0.8217875043099577} | train loss {'Reaction outcome loss': 0.805244326471321, 'Total loss': 0.805244326471321}
2022-11-18 02:25:11,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:11,286 INFO:     Epoch: 95
2022-11-18 02:25:12,076 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8317498354749246, 'Total loss': 0.8317498354749246} | train loss {'Reaction outcome loss': 0.8032035594505649, 'Total loss': 0.8032035594505649}
2022-11-18 02:25:12,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:12,077 INFO:     Epoch: 96
2022-11-18 02:25:12,855 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8291616663336754, 'Total loss': 0.8291616663336754} | train loss {'Reaction outcome loss': 0.8020080253481865, 'Total loss': 0.8020080253481865}
2022-11-18 02:25:12,856 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:12,856 INFO:     Epoch: 97
2022-11-18 02:25:13,625 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8597423840652813, 'Total loss': 0.8597423840652813} | train loss {'Reaction outcome loss': 0.7994463822293666, 'Total loss': 0.7994463822293666}
2022-11-18 02:25:13,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:13,625 INFO:     Epoch: 98
2022-11-18 02:25:14,442 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8353358480063352, 'Total loss': 0.8353358480063352} | train loss {'Reaction outcome loss': 0.8054431043565273, 'Total loss': 0.8054431043565273}
2022-11-18 02:25:14,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:14,443 INFO:     Epoch: 99
2022-11-18 02:25:15,228 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8449350121346387, 'Total loss': 0.8449350121346387} | train loss {'Reaction outcome loss': 0.8025746225349365, 'Total loss': 0.8025746225349365}
2022-11-18 02:25:15,228 INFO:     Best model found after epoch 86 of 100.
2022-11-18 02:25:15,228 INFO:   Done with stage: TRAINING
2022-11-18 02:25:15,228 INFO:   Starting stage: EVALUATION
2022-11-18 02:25:15,351 INFO:   Done with stage: EVALUATION
2022-11-18 02:25:15,351 INFO:   Leaving out SEQ value Fold_8
2022-11-18 02:25:15,364 INFO:   examples: 20,544| examples in train: 15,585 | examples in val: 2,751| examples in test: 2,208
2022-11-18 02:25:15,365 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:25:16,028 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:25:16,028 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:25:16,096 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:25:16,097 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:25:16,097 INFO:     No hyperparam tuning for this model
2022-11-18 02:25:16,097 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:25:16,097 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:25:16,098 INFO:     None feature selector for col prot
2022-11-18 02:25:16,098 INFO:     None feature selector for col prot
2022-11-18 02:25:16,098 INFO:     None feature selector for col prot
2022-11-18 02:25:16,098 INFO:     None feature selector for col chem
2022-11-18 02:25:16,098 INFO:     None feature selector for col chem
2022-11-18 02:25:16,098 INFO:     None feature selector for col chem
2022-11-18 02:25:16,099 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:25:16,099 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:25:16,101 INFO:     Number of params in model 168571
2022-11-18 02:25:16,104 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:25:16,104 INFO:   Starting stage: TRAINING
2022-11-18 02:25:16,160 INFO:     Val loss before train {'Reaction outcome loss': 0.9772533247637194, 'Total loss': 0.9772533247637194}
2022-11-18 02:25:16,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:16,160 INFO:     Epoch: 0
2022-11-18 02:25:16,911 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8267939873906069, 'Total loss': 0.8267939873906069} | train loss {'Reaction outcome loss': 0.8722297988954137, 'Total loss': 0.8722297988954137}
2022-11-18 02:25:16,911 INFO:     Found new best model at epoch 0
2022-11-18 02:25:16,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:16,912 INFO:     Epoch: 1
2022-11-18 02:25:17,676 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8130237966082817, 'Total loss': 0.8130237966082817} | train loss {'Reaction outcome loss': 0.8384469389671185, 'Total loss': 0.8384469389671185}
2022-11-18 02:25:17,676 INFO:     Found new best model at epoch 1
2022-11-18 02:25:17,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:17,677 INFO:     Epoch: 2
2022-11-18 02:25:18,466 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8287272931531419, 'Total loss': 0.8287272931531419} | train loss {'Reaction outcome loss': 0.8352722723464496, 'Total loss': 0.8352722723464496}
2022-11-18 02:25:18,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:18,467 INFO:     Epoch: 3
2022-11-18 02:25:19,228 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.841521541739619, 'Total loss': 0.841521541739619} | train loss {'Reaction outcome loss': 0.8388370462372655, 'Total loss': 0.8388370462372655}
2022-11-18 02:25:19,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:19,228 INFO:     Epoch: 4
2022-11-18 02:25:19,999 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8115833658118581, 'Total loss': 0.8115833658118581} | train loss {'Reaction outcome loss': 0.8294587169514328, 'Total loss': 0.8294587169514328}
2022-11-18 02:25:19,999 INFO:     Found new best model at epoch 4
2022-11-18 02:25:20,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:20,000 INFO:     Epoch: 5
2022-11-18 02:25:20,769 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8189340746679972, 'Total loss': 0.8189340746679972} | train loss {'Reaction outcome loss': 0.8270413145178654, 'Total loss': 0.8270413145178654}
2022-11-18 02:25:20,770 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:20,770 INFO:     Epoch: 6
2022-11-18 02:25:21,519 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8220237999461418, 'Total loss': 0.8220237999461418} | train loss {'Reaction outcome loss': 0.8244286627798784, 'Total loss': 0.8244286627798784}
2022-11-18 02:25:21,519 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:21,519 INFO:     Epoch: 7
2022-11-18 02:25:22,287 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8249664902687073, 'Total loss': 0.8249664902687073} | train loss {'Reaction outcome loss': 0.8234941943502817, 'Total loss': 0.8234941943502817}
2022-11-18 02:25:22,287 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:22,287 INFO:     Epoch: 8
2022-11-18 02:25:23,067 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7979415357112885, 'Total loss': 0.7979415357112885} | train loss {'Reaction outcome loss': 0.8219336494803429, 'Total loss': 0.8219336494803429}
2022-11-18 02:25:23,068 INFO:     Found new best model at epoch 8
2022-11-18 02:25:23,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:23,069 INFO:     Epoch: 9
2022-11-18 02:25:23,834 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8099202825579532, 'Total loss': 0.8099202825579532} | train loss {'Reaction outcome loss': 0.8199268258253082, 'Total loss': 0.8199268258253082}
2022-11-18 02:25:23,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:23,835 INFO:     Epoch: 10
2022-11-18 02:25:24,593 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8021283718042596, 'Total loss': 0.8021283718042596} | train loss {'Reaction outcome loss': 0.8198134758677639, 'Total loss': 0.8198134758677639}
2022-11-18 02:25:24,593 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:24,593 INFO:     Epoch: 11
2022-11-18 02:25:25,346 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8044737334861312, 'Total loss': 0.8044737334861312} | train loss {'Reaction outcome loss': 0.8202380693105401, 'Total loss': 0.8202380693105401}
2022-11-18 02:25:25,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:25,347 INFO:     Epoch: 12
2022-11-18 02:25:26,124 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.827872380267742, 'Total loss': 0.827872380267742} | train loss {'Reaction outcome loss': 0.8127748184516782, 'Total loss': 0.8127748184516782}
2022-11-18 02:25:26,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:26,124 INFO:     Epoch: 13
2022-11-18 02:25:26,880 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8121960974016855, 'Total loss': 0.8121960974016855} | train loss {'Reaction outcome loss': 0.8123004536648266, 'Total loss': 0.8123004536648266}
2022-11-18 02:25:26,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:26,880 INFO:     Epoch: 14
2022-11-18 02:25:27,664 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7996977803319, 'Total loss': 0.7996977803319} | train loss {'Reaction outcome loss': 0.8111549834491777, 'Total loss': 0.8111549834491777}
2022-11-18 02:25:27,664 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:27,664 INFO:     Epoch: 15
2022-11-18 02:25:28,454 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8041995541993961, 'Total loss': 0.8041995541993961} | train loss {'Reaction outcome loss': 0.8142519175517754, 'Total loss': 0.8142519175517754}
2022-11-18 02:25:28,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:28,454 INFO:     Epoch: 16
2022-11-18 02:25:29,241 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8020861225072727, 'Total loss': 0.8020861225072727} | train loss {'Reaction outcome loss': 0.8119138841990565, 'Total loss': 0.8119138841990565}
2022-11-18 02:25:29,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:29,241 INFO:     Epoch: 17
2022-11-18 02:25:30,039 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7960649624813435, 'Total loss': 0.7960649624813435} | train loss {'Reaction outcome loss': 0.8107767411675609, 'Total loss': 0.8107767411675609}
2022-11-18 02:25:30,039 INFO:     Found new best model at epoch 17
2022-11-18 02:25:30,040 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:30,040 INFO:     Epoch: 18
2022-11-18 02:25:30,824 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8005653716797052, 'Total loss': 0.8005653716797052} | train loss {'Reaction outcome loss': 0.8105005805121094, 'Total loss': 0.8105005805121094}
2022-11-18 02:25:30,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:30,825 INFO:     Epoch: 19
2022-11-18 02:25:31,621 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7993075417917829, 'Total loss': 0.7993075417917829} | train loss {'Reaction outcome loss': 0.8058465311883903, 'Total loss': 0.8058465311883903}
2022-11-18 02:25:31,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:31,621 INFO:     Epoch: 20
2022-11-18 02:25:32,452 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7998729736305946, 'Total loss': 0.7998729736305946} | train loss {'Reaction outcome loss': 0.8097840157932923, 'Total loss': 0.8097840157932923}
2022-11-18 02:25:32,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:32,452 INFO:     Epoch: 21
2022-11-18 02:25:33,268 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7959231297637142, 'Total loss': 0.7959231297637142} | train loss {'Reaction outcome loss': 0.8150931722560867, 'Total loss': 0.8150931722560867}
2022-11-18 02:25:33,269 INFO:     Found new best model at epoch 21
2022-11-18 02:25:33,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:33,269 INFO:     Epoch: 22
2022-11-18 02:25:34,042 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8016773961311163, 'Total loss': 0.8016773961311163} | train loss {'Reaction outcome loss': 0.8083586347151975, 'Total loss': 0.8083586347151975}
2022-11-18 02:25:34,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:34,042 INFO:     Epoch: 23
2022-11-18 02:25:34,859 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8018265740815983, 'Total loss': 0.8018265740815983} | train loss {'Reaction outcome loss': 0.8108934121298008, 'Total loss': 0.8108934121298008}
2022-11-18 02:25:34,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:34,859 INFO:     Epoch: 24
2022-11-18 02:25:35,666 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7999416652113892, 'Total loss': 0.7999416652113892} | train loss {'Reaction outcome loss': 0.8138159716227016, 'Total loss': 0.8138159716227016}
2022-11-18 02:25:35,667 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:35,668 INFO:     Epoch: 25
2022-11-18 02:25:36,442 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7847174475359362, 'Total loss': 0.7847174475359362} | train loss {'Reaction outcome loss': 0.8073117520476951, 'Total loss': 0.8073117520476951}
2022-11-18 02:25:36,443 INFO:     Found new best model at epoch 25
2022-11-18 02:25:36,443 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:36,443 INFO:     Epoch: 26
2022-11-18 02:25:37,239 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7922865325628325, 'Total loss': 0.7922865325628325} | train loss {'Reaction outcome loss': 0.8106548780056296, 'Total loss': 0.8106548780056296}
2022-11-18 02:25:37,239 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:37,240 INFO:     Epoch: 27
2022-11-18 02:25:38,032 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7897725645885911, 'Total loss': 0.7897725645885911} | train loss {'Reaction outcome loss': 0.8089870226676347, 'Total loss': 0.8089870226676347}
2022-11-18 02:25:38,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:38,032 INFO:     Epoch: 28
2022-11-18 02:25:38,819 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7876650282116824, 'Total loss': 0.7876650282116824} | train loss {'Reaction outcome loss': 0.8093445721219797, 'Total loss': 0.8093445721219797}
2022-11-18 02:25:38,819 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:38,819 INFO:     Epoch: 29
2022-11-18 02:25:39,633 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8045139132544051, 'Total loss': 0.8045139132544051} | train loss {'Reaction outcome loss': 0.8032837413617822, 'Total loss': 0.8032837413617822}
2022-11-18 02:25:39,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:39,633 INFO:     Epoch: 30
2022-11-18 02:25:40,453 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7919604112935621, 'Total loss': 0.7919604112935621} | train loss {'Reaction outcome loss': 0.8054610482249104, 'Total loss': 0.8054610482249104}
2022-11-18 02:25:40,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:40,453 INFO:     Epoch: 31
2022-11-18 02:25:41,229 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7977948230366374, 'Total loss': 0.7977948230366374} | train loss {'Reaction outcome loss': 0.8106660134479647, 'Total loss': 0.8106660134479647}
2022-11-18 02:25:41,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:41,229 INFO:     Epoch: 32
2022-11-18 02:25:42,024 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8049283166264378, 'Total loss': 0.8049283166264378} | train loss {'Reaction outcome loss': 0.8058641728807668, 'Total loss': 0.8058641728807668}
2022-11-18 02:25:42,025 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:42,025 INFO:     Epoch: 33
2022-11-18 02:25:42,892 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8204922731532607, 'Total loss': 0.8204922731532607} | train loss {'Reaction outcome loss': 0.8048105824921952, 'Total loss': 0.8048105824921952}
2022-11-18 02:25:42,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:42,893 INFO:     Epoch: 34
2022-11-18 02:25:43,701 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7972120711969775, 'Total loss': 0.7972120711969775} | train loss {'Reaction outcome loss': 0.8053906182529497, 'Total loss': 0.8053906182529497}
2022-11-18 02:25:43,702 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:43,702 INFO:     Epoch: 35
2022-11-18 02:25:44,454 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.79798057328823, 'Total loss': 0.79798057328823} | train loss {'Reaction outcome loss': 0.8049282955585934, 'Total loss': 0.8049282955585934}
2022-11-18 02:25:44,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:44,454 INFO:     Epoch: 36
2022-11-18 02:25:45,218 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7920152246952057, 'Total loss': 0.7920152246952057} | train loss {'Reaction outcome loss': 0.8091353698343527, 'Total loss': 0.8091353698343527}
2022-11-18 02:25:45,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:45,218 INFO:     Epoch: 37
2022-11-18 02:25:45,979 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8000081722126451, 'Total loss': 0.8000081722126451} | train loss {'Reaction outcome loss': 0.8092828821696219, 'Total loss': 0.8092828821696219}
2022-11-18 02:25:45,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:45,979 INFO:     Epoch: 38
2022-11-18 02:25:46,784 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7952819016090659, 'Total loss': 0.7952819016090659} | train loss {'Reaction outcome loss': 0.8085918475369938, 'Total loss': 0.8085918475369938}
2022-11-18 02:25:46,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:46,784 INFO:     Epoch: 39
2022-11-18 02:25:47,641 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8041616719822551, 'Total loss': 0.8041616719822551} | train loss {'Reaction outcome loss': 0.8070793712481124, 'Total loss': 0.8070793712481124}
2022-11-18 02:25:47,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:47,641 INFO:     Epoch: 40
2022-11-18 02:25:48,484 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7979862329571746, 'Total loss': 0.7979862329571746} | train loss {'Reaction outcome loss': 0.8067726094703205, 'Total loss': 0.8067726094703205}
2022-11-18 02:25:48,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:48,484 INFO:     Epoch: 41
2022-11-18 02:25:49,286 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8111358666142752, 'Total loss': 0.8111358666142752} | train loss {'Reaction outcome loss': 0.8087461486947342, 'Total loss': 0.8087461486947342}
2022-11-18 02:25:49,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:49,286 INFO:     Epoch: 42
2022-11-18 02:25:50,112 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7858293347580488, 'Total loss': 0.7858293347580488} | train loss {'Reaction outcome loss': 0.8052302982474937, 'Total loss': 0.8052302982474937}
2022-11-18 02:25:50,113 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:50,113 INFO:     Epoch: 43
2022-11-18 02:25:50,912 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8187914982784626, 'Total loss': 0.8187914982784626} | train loss {'Reaction outcome loss': 0.8086558289703776, 'Total loss': 0.8086558289703776}
2022-11-18 02:25:50,912 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:50,912 INFO:     Epoch: 44
2022-11-18 02:25:51,706 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7824549016564392, 'Total loss': 0.7824549016564392} | train loss {'Reaction outcome loss': 0.8030717465721193, 'Total loss': 0.8030717465721193}
2022-11-18 02:25:51,706 INFO:     Found new best model at epoch 44
2022-11-18 02:25:51,706 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:51,707 INFO:     Epoch: 45
2022-11-18 02:25:52,487 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8253454843232798, 'Total loss': 0.8253454843232798} | train loss {'Reaction outcome loss': 0.807312865482002, 'Total loss': 0.807312865482002}
2022-11-18 02:25:52,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:52,488 INFO:     Epoch: 46
2022-11-18 02:25:53,302 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7941561687824338, 'Total loss': 0.7941561687824338} | train loss {'Reaction outcome loss': 0.8098787985375671, 'Total loss': 0.8098787985375671}
2022-11-18 02:25:53,303 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:53,303 INFO:     Epoch: 47
2022-11-18 02:25:54,097 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8016145631324413, 'Total loss': 0.8016145631324413} | train loss {'Reaction outcome loss': 0.8034823097166468, 'Total loss': 0.8034823097166468}
2022-11-18 02:25:54,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:54,098 INFO:     Epoch: 48
2022-11-18 02:25:54,920 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7996391965899357, 'Total loss': 0.7996391965899357} | train loss {'Reaction outcome loss': 0.8080665198017339, 'Total loss': 0.8080665198017339}
2022-11-18 02:25:54,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:54,921 INFO:     Epoch: 49
2022-11-18 02:25:55,709 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7924468558888103, 'Total loss': 0.7924468558888103} | train loss {'Reaction outcome loss': 0.8036265629725378, 'Total loss': 0.8036265629725378}
2022-11-18 02:25:55,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:55,710 INFO:     Epoch: 50
2022-11-18 02:25:56,521 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.79568358424098, 'Total loss': 0.79568358424098} | train loss {'Reaction outcome loss': 0.8087032289534318, 'Total loss': 0.8087032289534318}
2022-11-18 02:25:56,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:56,522 INFO:     Epoch: 51
2022-11-18 02:25:57,284 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8330825393976167, 'Total loss': 0.8330825393976167} | train loss {'Reaction outcome loss': 0.8063658938788977, 'Total loss': 0.8063658938788977}
2022-11-18 02:25:57,284 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:57,285 INFO:     Epoch: 52
2022-11-18 02:25:58,106 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.789468783278798, 'Total loss': 0.789468783278798} | train loss {'Reaction outcome loss': 0.805157658628753, 'Total loss': 0.805157658628753}
2022-11-18 02:25:58,106 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:58,106 INFO:     Epoch: 53
2022-11-18 02:25:58,952 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7801952646222226, 'Total loss': 0.7801952646222226} | train loss {'Reaction outcome loss': 0.8096878424775406, 'Total loss': 0.8096878424775406}
2022-11-18 02:25:58,952 INFO:     Found new best model at epoch 53
2022-11-18 02:25:58,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:58,953 INFO:     Epoch: 54
2022-11-18 02:25:59,795 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7813271533611209, 'Total loss': 0.7813271533611209} | train loss {'Reaction outcome loss': 0.8038958451542698, 'Total loss': 0.8038958451542698}
2022-11-18 02:25:59,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:25:59,795 INFO:     Epoch: 55
2022-11-18 02:26:00,613 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8108701629694118, 'Total loss': 0.8108701629694118} | train loss {'Reaction outcome loss': 0.8028498238227406, 'Total loss': 0.8028498238227406}
2022-11-18 02:26:00,613 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:00,613 INFO:     Epoch: 56
2022-11-18 02:26:01,397 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7866977078970089, 'Total loss': 0.7866977078970089} | train loss {'Reaction outcome loss': 0.8045790334705447, 'Total loss': 0.8045790334705447}
2022-11-18 02:26:01,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:01,397 INFO:     Epoch: 57
2022-11-18 02:26:02,181 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.785269092681796, 'Total loss': 0.785269092681796} | train loss {'Reaction outcome loss': 0.8063862714611116, 'Total loss': 0.8063862714611116}
2022-11-18 02:26:02,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:02,181 INFO:     Epoch: 58
2022-11-18 02:26:02,978 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8010080068610436, 'Total loss': 0.8010080068610436} | train loss {'Reaction outcome loss': 0.8106446853670918, 'Total loss': 0.8106446853670918}
2022-11-18 02:26:02,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:02,978 INFO:     Epoch: 59
2022-11-18 02:26:03,756 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.795442170875017, 'Total loss': 0.795442170875017} | train loss {'Reaction outcome loss': 0.8081549381623503, 'Total loss': 0.8081549381623503}
2022-11-18 02:26:03,756 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:03,757 INFO:     Epoch: 60
2022-11-18 02:26:04,531 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8135032210239145, 'Total loss': 0.8135032210239145} | train loss {'Reaction outcome loss': 0.8033108112753414, 'Total loss': 0.8033108112753414}
2022-11-18 02:26:04,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:04,532 INFO:     Epoch: 61
2022-11-18 02:26:05,332 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8024025289125221, 'Total loss': 0.8024025289125221} | train loss {'Reaction outcome loss': 0.8082712797112153, 'Total loss': 0.8082712797112153}
2022-11-18 02:26:05,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:05,332 INFO:     Epoch: 62
2022-11-18 02:26:06,092 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8229706509168758, 'Total loss': 0.8229706509168758} | train loss {'Reaction outcome loss': 0.8058416779901161, 'Total loss': 0.8058416779901161}
2022-11-18 02:26:06,092 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:06,092 INFO:     Epoch: 63
2022-11-18 02:26:06,906 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7875718224880307, 'Total loss': 0.7875718224880307} | train loss {'Reaction outcome loss': 0.8071193428801708, 'Total loss': 0.8071193428801708}
2022-11-18 02:26:06,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:06,908 INFO:     Epoch: 64
2022-11-18 02:26:07,698 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7895204133765642, 'Total loss': 0.7895204133765642} | train loss {'Reaction outcome loss': 0.8019996066806746, 'Total loss': 0.8019996066806746}
2022-11-18 02:26:07,698 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:07,699 INFO:     Epoch: 65
2022-11-18 02:26:08,507 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8344612357228302, 'Total loss': 0.8344612357228302} | train loss {'Reaction outcome loss': 0.8047611293245535, 'Total loss': 0.8047611293245535}
2022-11-18 02:26:08,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:08,508 INFO:     Epoch: 66
2022-11-18 02:26:09,300 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7916017542051714, 'Total loss': 0.7916017542051714} | train loss {'Reaction outcome loss': 0.8024109168375124, 'Total loss': 0.8024109168375124}
2022-11-18 02:26:09,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:09,300 INFO:     Epoch: 67
2022-11-18 02:26:10,091 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.801433110652968, 'Total loss': 0.801433110652968} | train loss {'Reaction outcome loss': 0.8064304220139004, 'Total loss': 0.8064304220139004}
2022-11-18 02:26:10,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:10,091 INFO:     Epoch: 68
2022-11-18 02:26:10,872 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7924102288345958, 'Total loss': 0.7924102288345958} | train loss {'Reaction outcome loss': 0.8064161763816583, 'Total loss': 0.8064161763816583}
2022-11-18 02:26:10,872 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:10,872 INFO:     Epoch: 69
2022-11-18 02:26:11,658 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8429242448751316, 'Total loss': 0.8429242448751316} | train loss {'Reaction outcome loss': 0.8071633330622657, 'Total loss': 0.8071633330622657}
2022-11-18 02:26:11,658 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:11,658 INFO:     Epoch: 70
2022-11-18 02:26:12,451 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8280277085858722, 'Total loss': 0.8280277085858722} | train loss {'Reaction outcome loss': 0.8060603036743695, 'Total loss': 0.8060603036743695}
2022-11-18 02:26:12,451 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:12,451 INFO:     Epoch: 71
2022-11-18 02:26:13,219 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8050661502882491, 'Total loss': 0.8050661502882491} | train loss {'Reaction outcome loss': 0.8047260582202771, 'Total loss': 0.8047260582202771}
2022-11-18 02:26:13,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:13,220 INFO:     Epoch: 72
2022-11-18 02:26:14,062 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7842697639798009, 'Total loss': 0.7842697639798009} | train loss {'Reaction outcome loss': 0.8082002413565995, 'Total loss': 0.8082002413565995}
2022-11-18 02:26:14,062 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:14,062 INFO:     Epoch: 73
2022-11-18 02:26:14,851 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8385356429011322, 'Total loss': 0.8385356429011322} | train loss {'Reaction outcome loss': 0.808203429472251, 'Total loss': 0.808203429472251}
2022-11-18 02:26:14,851 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:14,851 INFO:     Epoch: 74
2022-11-18 02:26:15,625 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7860443855440894, 'Total loss': 0.7860443855440894} | train loss {'Reaction outcome loss': 0.809296617620304, 'Total loss': 0.809296617620304}
2022-11-18 02:26:15,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:15,625 INFO:     Epoch: 75
2022-11-18 02:26:16,442 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7808514722557955, 'Total loss': 0.7808514722557955} | train loss {'Reaction outcome loss': 0.8066184633090848, 'Total loss': 0.8066184633090848}
2022-11-18 02:26:16,442 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:16,442 INFO:     Epoch: 76
2022-11-18 02:26:17,241 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7759761436041012, 'Total loss': 0.7759761436041012} | train loss {'Reaction outcome loss': 0.8059038191300923, 'Total loss': 0.8059038191300923}
2022-11-18 02:26:17,241 INFO:     Found new best model at epoch 76
2022-11-18 02:26:17,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:17,242 INFO:     Epoch: 77
2022-11-18 02:26:18,040 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7789892949337183, 'Total loss': 0.7789892949337183} | train loss {'Reaction outcome loss': 0.8041032771350908, 'Total loss': 0.8041032771350908}
2022-11-18 02:26:18,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:18,041 INFO:     Epoch: 78
2022-11-18 02:26:18,838 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7908799606700276, 'Total loss': 0.7908799606700276} | train loss {'Reaction outcome loss': 0.801688514649868, 'Total loss': 0.801688514649868}
2022-11-18 02:26:18,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:18,838 INFO:     Epoch: 79
2022-11-18 02:26:19,617 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7877010813979215, 'Total loss': 0.7877010813979215} | train loss {'Reaction outcome loss': 0.8041223763930992, 'Total loss': 0.8041223763930992}
2022-11-18 02:26:19,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:19,617 INFO:     Epoch: 80
2022-11-18 02:26:20,437 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.789504993100499, 'Total loss': 0.789504993100499} | train loss {'Reaction outcome loss': 0.7999736936610253, 'Total loss': 0.7999736936610253}
2022-11-18 02:26:20,437 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:20,437 INFO:     Epoch: 81
2022-11-18 02:26:21,243 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7923542392808337, 'Total loss': 0.7923542392808337} | train loss {'Reaction outcome loss': 0.8044100678602203, 'Total loss': 0.8044100678602203}
2022-11-18 02:26:21,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:21,243 INFO:     Epoch: 82
2022-11-18 02:26:22,032 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7791026116803635, 'Total loss': 0.7791026116803635} | train loss {'Reaction outcome loss': 0.8042706773906457, 'Total loss': 0.8042706773906457}
2022-11-18 02:26:22,032 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:22,032 INFO:     Epoch: 83
2022-11-18 02:26:22,853 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8146688917348551, 'Total loss': 0.8146688917348551} | train loss {'Reaction outcome loss': 0.8055340001573328, 'Total loss': 0.8055340001573328}
2022-11-18 02:26:22,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:22,853 INFO:     Epoch: 84
2022-11-18 02:26:23,646 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7811984849530597, 'Total loss': 0.7811984849530597} | train loss {'Reaction outcome loss': 0.8074112170543827, 'Total loss': 0.8074112170543827}
2022-11-18 02:26:23,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:23,647 INFO:     Epoch: 85
2022-11-18 02:26:24,453 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7854413958482964, 'Total loss': 0.7854413958482964} | train loss {'Reaction outcome loss': 0.8065364313174467, 'Total loss': 0.8065364313174467}
2022-11-18 02:26:24,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:24,453 INFO:     Epoch: 86
2022-11-18 02:26:25,262 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7859574992989384, 'Total loss': 0.7859574992989384} | train loss {'Reaction outcome loss': 0.8051929116004803, 'Total loss': 0.8051929116004803}
2022-11-18 02:26:25,263 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:25,263 INFO:     Epoch: 87
2022-11-18 02:26:26,065 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7796814192173093, 'Total loss': 0.7796814192173093} | train loss {'Reaction outcome loss': 0.8005980937207331, 'Total loss': 0.8005980937207331}
2022-11-18 02:26:26,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:26,065 INFO:     Epoch: 88
2022-11-18 02:26:26,908 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8033289888570475, 'Total loss': 0.8033289888570475} | train loss {'Reaction outcome loss': 0.7993999116244863, 'Total loss': 0.7993999116244863}
2022-11-18 02:26:26,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:26,908 INFO:     Epoch: 89
2022-11-18 02:26:27,719 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7861272055049275, 'Total loss': 0.7861272055049275} | train loss {'Reaction outcome loss': 0.8039961683212734, 'Total loss': 0.8039961683212734}
2022-11-18 02:26:27,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:27,719 INFO:     Epoch: 90
2022-11-18 02:26:28,512 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7916678675385409, 'Total loss': 0.7916678675385409} | train loss {'Reaction outcome loss': 0.8034823252285113, 'Total loss': 0.8034823252285113}
2022-11-18 02:26:28,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:28,513 INFO:     Epoch: 91
2022-11-18 02:26:29,304 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7907279286273691, 'Total loss': 0.7907279286273691} | train loss {'Reaction outcome loss': 0.8017036771920861, 'Total loss': 0.8017036771920861}
2022-11-18 02:26:29,304 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:29,304 INFO:     Epoch: 92
2022-11-18 02:26:30,140 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7901840722838114, 'Total loss': 0.7901840722838114} | train loss {'Reaction outcome loss': 0.8004086729688723, 'Total loss': 0.8004086729688723}
2022-11-18 02:26:30,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:30,140 INFO:     Epoch: 93
2022-11-18 02:26:30,936 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7857632082562114, 'Total loss': 0.7857632082562114} | train loss {'Reaction outcome loss': 0.8005840768579577, 'Total loss': 0.8005840768579577}
2022-11-18 02:26:30,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:30,936 INFO:     Epoch: 94
2022-11-18 02:26:31,755 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7900756971780644, 'Total loss': 0.7900756971780644} | train loss {'Reaction outcome loss': 0.8052632894183769, 'Total loss': 0.8052632894183769}
2022-11-18 02:26:31,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:31,755 INFO:     Epoch: 95
2022-11-18 02:26:32,531 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8010663036690202, 'Total loss': 0.8010663036690202} | train loss {'Reaction outcome loss': 0.8054296944717891, 'Total loss': 0.8054296944717891}
2022-11-18 02:26:32,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:32,531 INFO:     Epoch: 96
2022-11-18 02:26:33,328 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.795662771130717, 'Total loss': 0.795662771130717} | train loss {'Reaction outcome loss': 0.8013198525934923, 'Total loss': 0.8013198525934923}
2022-11-18 02:26:33,328 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:33,328 INFO:     Epoch: 97
2022-11-18 02:26:34,158 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7891917415829592, 'Total loss': 0.7891917415829592} | train loss {'Reaction outcome loss': 0.8008640595391149, 'Total loss': 0.8008640595391149}
2022-11-18 02:26:34,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:34,158 INFO:     Epoch: 98
2022-11-18 02:26:34,922 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7840046612329261, 'Total loss': 0.7840046612329261} | train loss {'Reaction outcome loss': 0.7987238551016713, 'Total loss': 0.7987238551016713}
2022-11-18 02:26:34,922 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:34,922 INFO:     Epoch: 99
2022-11-18 02:26:35,744 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8058376437009767, 'Total loss': 0.8058376437009767} | train loss {'Reaction outcome loss': 0.7963171509689972, 'Total loss': 0.7963171509689972}
2022-11-18 02:26:35,744 INFO:     Best model found after epoch 77 of 100.
2022-11-18 02:26:35,744 INFO:   Done with stage: TRAINING
2022-11-18 02:26:35,744 INFO:   Starting stage: EVALUATION
2022-11-18 02:26:35,881 INFO:   Done with stage: EVALUATION
2022-11-18 02:26:35,881 INFO:   Leaving out SEQ value Fold_9
2022-11-18 02:26:35,895 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 02:26:35,895 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:26:36,564 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:26:36,564 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:26:36,635 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:26:36,636 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:26:36,636 INFO:     No hyperparam tuning for this model
2022-11-18 02:26:36,636 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:26:36,636 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:26:36,637 INFO:     None feature selector for col prot
2022-11-18 02:26:36,637 INFO:     None feature selector for col prot
2022-11-18 02:26:36,637 INFO:     None feature selector for col prot
2022-11-18 02:26:36,638 INFO:     None feature selector for col chem
2022-11-18 02:26:36,638 INFO:     None feature selector for col chem
2022-11-18 02:26:36,638 INFO:     None feature selector for col chem
2022-11-18 02:26:36,638 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:26:36,638 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:26:36,639 INFO:     Number of params in model 168571
2022-11-18 02:26:36,643 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:26:36,643 INFO:   Starting stage: TRAINING
2022-11-18 02:26:36,701 INFO:     Val loss before train {'Reaction outcome loss': 1.032197972590273, 'Total loss': 1.032197972590273}
2022-11-18 02:26:36,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:36,701 INFO:     Epoch: 0
2022-11-18 02:26:37,514 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8790385790846564, 'Total loss': 0.8790385790846564} | train loss {'Reaction outcome loss': 0.8889799084394209, 'Total loss': 0.8889799084394209}
2022-11-18 02:26:37,514 INFO:     Found new best model at epoch 0
2022-11-18 02:26:37,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:37,515 INFO:     Epoch: 1
2022-11-18 02:26:38,314 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8847735700282183, 'Total loss': 0.8847735700282183} | train loss {'Reaction outcome loss': 0.8529126461475126, 'Total loss': 0.8529126461475126}
2022-11-18 02:26:38,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:38,316 INFO:     Epoch: 2
2022-11-18 02:26:39,103 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8541048893874342, 'Total loss': 0.8541048893874342} | train loss {'Reaction outcome loss': 0.8464930257008921, 'Total loss': 0.8464930257008921}
2022-11-18 02:26:39,103 INFO:     Found new best model at epoch 2
2022-11-18 02:26:39,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:39,104 INFO:     Epoch: 3
2022-11-18 02:26:39,917 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.869816159660166, 'Total loss': 0.869816159660166} | train loss {'Reaction outcome loss': 0.8436191388435902, 'Total loss': 0.8436191388435902}
2022-11-18 02:26:39,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:39,917 INFO:     Epoch: 4
2022-11-18 02:26:40,722 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.9242538911375132, 'Total loss': 0.9242538911375132} | train loss {'Reaction outcome loss': 0.8315033630257652, 'Total loss': 0.8315033630257652}
2022-11-18 02:26:40,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:40,723 INFO:     Epoch: 5
2022-11-18 02:26:41,510 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8640758828683333, 'Total loss': 0.8640758828683333} | train loss {'Reaction outcome loss': 0.8394505399609765, 'Total loss': 0.8394505399609765}
2022-11-18 02:26:41,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:41,511 INFO:     Epoch: 6
2022-11-18 02:26:42,345 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.844717573035847, 'Total loss': 0.844717573035847} | train loss {'Reaction outcome loss': 0.8320965824588653, 'Total loss': 0.8320965824588653}
2022-11-18 02:26:42,345 INFO:     Found new best model at epoch 6
2022-11-18 02:26:42,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:42,346 INFO:     Epoch: 7
2022-11-18 02:26:43,150 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8588065599853342, 'Total loss': 0.8588065599853342} | train loss {'Reaction outcome loss': 0.8290815085412995, 'Total loss': 0.8290815085412995}
2022-11-18 02:26:43,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:43,150 INFO:     Epoch: 8
2022-11-18 02:26:43,959 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.9030780521306124, 'Total loss': 0.9030780521306124} | train loss {'Reaction outcome loss': 0.8247650071017204, 'Total loss': 0.8247650071017204}
2022-11-18 02:26:43,959 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:43,959 INFO:     Epoch: 9
2022-11-18 02:26:44,746 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8488248464736071, 'Total loss': 0.8488248464736071} | train loss {'Reaction outcome loss': 0.830258663863905, 'Total loss': 0.830258663863905}
2022-11-18 02:26:44,747 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:44,747 INFO:     Epoch: 10
2022-11-18 02:26:45,553 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8528995920311321, 'Total loss': 0.8528995920311321} | train loss {'Reaction outcome loss': 0.826950495642039, 'Total loss': 0.826950495642039}
2022-11-18 02:26:45,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:45,554 INFO:     Epoch: 11
2022-11-18 02:26:46,377 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.843651600859382, 'Total loss': 0.843651600859382} | train loss {'Reaction outcome loss': 0.8265212001579423, 'Total loss': 0.8265212001579423}
2022-11-18 02:26:46,377 INFO:     Found new best model at epoch 11
2022-11-18 02:26:46,378 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:46,378 INFO:     Epoch: 12
2022-11-18 02:26:47,221 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8412154831669547, 'Total loss': 0.8412154831669547} | train loss {'Reaction outcome loss': 0.8269874042560977, 'Total loss': 0.8269874042560977}
2022-11-18 02:26:47,221 INFO:     Found new best model at epoch 12
2022-11-18 02:26:47,222 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:47,222 INFO:     Epoch: 13
2022-11-18 02:26:48,065 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8611271002075889, 'Total loss': 0.8611271002075889} | train loss {'Reaction outcome loss': 0.8263437038948459, 'Total loss': 0.8263437038948459}
2022-11-18 02:26:48,065 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:48,065 INFO:     Epoch: 14
2022-11-18 02:26:48,886 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8374452753500505, 'Total loss': 0.8374452753500505} | train loss {'Reaction outcome loss': 0.8194443871898036, 'Total loss': 0.8194443871898036}
2022-11-18 02:26:48,886 INFO:     Found new best model at epoch 14
2022-11-18 02:26:48,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:48,887 INFO:     Epoch: 15
2022-11-18 02:26:49,670 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.842699637467211, 'Total loss': 0.842699637467211} | train loss {'Reaction outcome loss': 0.8269532265201691, 'Total loss': 0.8269532265201691}
2022-11-18 02:26:49,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:49,670 INFO:     Epoch: 16
2022-11-18 02:26:50,458 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8458682887933471, 'Total loss': 0.8458682887933471} | train loss {'Reaction outcome loss': 0.8248288644657981, 'Total loss': 0.8248288644657981}
2022-11-18 02:26:50,458 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:50,458 INFO:     Epoch: 17
2022-11-18 02:26:51,306 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8342671299522574, 'Total loss': 0.8342671299522574} | train loss {'Reaction outcome loss': 0.8247148298448131, 'Total loss': 0.8247148298448131}
2022-11-18 02:26:51,306 INFO:     Found new best model at epoch 17
2022-11-18 02:26:51,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:51,307 INFO:     Epoch: 18
2022-11-18 02:26:52,109 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8433995626189492, 'Total loss': 0.8433995626189492} | train loss {'Reaction outcome loss': 0.8209013541138941, 'Total loss': 0.8209013541138941}
2022-11-18 02:26:52,109 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:52,109 INFO:     Epoch: 19
2022-11-18 02:26:52,943 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8377036635171283, 'Total loss': 0.8377036635171283} | train loss {'Reaction outcome loss': 0.824879112142709, 'Total loss': 0.824879112142709}
2022-11-18 02:26:52,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:52,943 INFO:     Epoch: 20
2022-11-18 02:26:53,777 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8451027301224795, 'Total loss': 0.8451027301224795} | train loss {'Reaction outcome loss': 0.8195541588168952, 'Total loss': 0.8195541588168952}
2022-11-18 02:26:53,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:53,777 INFO:     Epoch: 21
2022-11-18 02:26:54,621 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.856288727034222, 'Total loss': 0.856288727034222} | train loss {'Reaction outcome loss': 0.8283715752824661, 'Total loss': 0.8283715752824661}
2022-11-18 02:26:54,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:54,621 INFO:     Epoch: 22
2022-11-18 02:26:55,406 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.849293593655933, 'Total loss': 0.849293593655933} | train loss {'Reaction outcome loss': 0.8199786697664568, 'Total loss': 0.8199786697664568}
2022-11-18 02:26:55,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:55,407 INFO:     Epoch: 23
2022-11-18 02:26:56,221 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8487417034127496, 'Total loss': 0.8487417034127496} | train loss {'Reaction outcome loss': 0.8229867377348484, 'Total loss': 0.8229867377348484}
2022-11-18 02:26:56,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:56,222 INFO:     Epoch: 24
2022-11-18 02:26:57,028 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.84036250886592, 'Total loss': 0.84036250886592} | train loss {'Reaction outcome loss': 0.8241414919255241, 'Total loss': 0.8241414919255241}
2022-11-18 02:26:57,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:57,030 INFO:     Epoch: 25
2022-11-18 02:26:57,867 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8817036869851026, 'Total loss': 0.8817036869851026} | train loss {'Reaction outcome loss': 0.8247421794841366, 'Total loss': 0.8247421794841366}
2022-11-18 02:26:57,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:57,868 INFO:     Epoch: 26
2022-11-18 02:26:58,673 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8618193600665439, 'Total loss': 0.8618193600665439} | train loss {'Reaction outcome loss': 0.8184849275576491, 'Total loss': 0.8184849275576491}
2022-11-18 02:26:58,673 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:58,673 INFO:     Epoch: 27
2022-11-18 02:26:59,497 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8335507241162387, 'Total loss': 0.8335507241162387} | train loss {'Reaction outcome loss': 0.8258540201932192, 'Total loss': 0.8258540201932192}
2022-11-18 02:26:59,497 INFO:     Found new best model at epoch 27
2022-11-18 02:26:59,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:26:59,498 INFO:     Epoch: 28
2022-11-18 02:27:00,325 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8759669498963789, 'Total loss': 0.8759669498963789} | train loss {'Reaction outcome loss': 0.8220358639955521, 'Total loss': 0.8220358639955521}
2022-11-18 02:27:00,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:00,326 INFO:     Epoch: 29
2022-11-18 02:27:01,153 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8650754351507534, 'Total loss': 0.8650754351507534} | train loss {'Reaction outcome loss': 0.8228555152252797, 'Total loss': 0.8228555152252797}
2022-11-18 02:27:01,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:01,153 INFO:     Epoch: 30
2022-11-18 02:27:01,990 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8391016559167341, 'Total loss': 0.8391016559167341} | train loss {'Reaction outcome loss': 0.8219771690426334, 'Total loss': 0.8219771690426334}
2022-11-18 02:27:01,990 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:01,990 INFO:     Epoch: 31
2022-11-18 02:27:02,784 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8436795500191775, 'Total loss': 0.8436795500191775} | train loss {'Reaction outcome loss': 0.8244463228169949, 'Total loss': 0.8244463228169949}
2022-11-18 02:27:02,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:02,785 INFO:     Epoch: 32
2022-11-18 02:27:03,612 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8368673744526777, 'Total loss': 0.8368673744526777} | train loss {'Reaction outcome loss': 0.8230456738702713, 'Total loss': 0.8230456738702713}
2022-11-18 02:27:03,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:03,612 INFO:     Epoch: 33
2022-11-18 02:27:04,404 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8696102201938629, 'Total loss': 0.8696102201938629} | train loss {'Reaction outcome loss': 0.8232581530126833, 'Total loss': 0.8232581530126833}
2022-11-18 02:27:04,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:04,404 INFO:     Epoch: 34
2022-11-18 02:27:05,192 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8447880765253847, 'Total loss': 0.8447880765253847} | train loss {'Reaction outcome loss': 0.8215438609402026, 'Total loss': 0.8215438609402026}
2022-11-18 02:27:05,192 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:05,193 INFO:     Epoch: 35
2022-11-18 02:27:06,010 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8815628574653105, 'Total loss': 0.8815628574653105} | train loss {'Reaction outcome loss': 0.8232826679464309, 'Total loss': 0.8232826679464309}
2022-11-18 02:27:06,010 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:06,010 INFO:     Epoch: 36
2022-11-18 02:27:06,813 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8476081924004988, 'Total loss': 0.8476081924004988} | train loss {'Reaction outcome loss': 0.827992903849771, 'Total loss': 0.827992903849771}
2022-11-18 02:27:06,813 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:06,813 INFO:     Epoch: 37
2022-11-18 02:27:07,615 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8656388209624724, 'Total loss': 0.8656388209624724} | train loss {'Reaction outcome loss': 0.8247116032627321, 'Total loss': 0.8247116032627321}
2022-11-18 02:27:07,615 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:07,615 INFO:     Epoch: 38
2022-11-18 02:27:08,396 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8591235828670588, 'Total loss': 0.8591235828670588} | train loss {'Reaction outcome loss': 0.8317127758937497, 'Total loss': 0.8317127758937497}
2022-11-18 02:27:08,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:08,397 INFO:     Epoch: 39
2022-11-18 02:27:09,215 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8695944642478769, 'Total loss': 0.8695944642478769} | train loss {'Reaction outcome loss': 0.8209881495323873, 'Total loss': 0.8209881495323873}
2022-11-18 02:27:09,216 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:09,217 INFO:     Epoch: 40
2022-11-18 02:27:10,036 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8563376489010724, 'Total loss': 0.8563376489010724} | train loss {'Reaction outcome loss': 0.8265090403297255, 'Total loss': 0.8265090403297255}
2022-11-18 02:27:10,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:10,036 INFO:     Epoch: 41
2022-11-18 02:27:10,836 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8535521504553881, 'Total loss': 0.8535521504553881} | train loss {'Reaction outcome loss': 0.8224988448764047, 'Total loss': 0.8224988448764047}
2022-11-18 02:27:10,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:10,836 INFO:     Epoch: 42
2022-11-18 02:27:11,627 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.837960650975054, 'Total loss': 0.837960650975054} | train loss {'Reaction outcome loss': 0.8262611775388641, 'Total loss': 0.8262611775388641}
2022-11-18 02:27:11,627 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:11,627 INFO:     Epoch: 43
2022-11-18 02:27:12,432 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8478101817044345, 'Total loss': 0.8478101817044345} | train loss {'Reaction outcome loss': 0.8213467398478139, 'Total loss': 0.8213467398478139}
2022-11-18 02:27:12,432 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:12,432 INFO:     Epoch: 44
2022-11-18 02:27:13,242 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8542927036231215, 'Total loss': 0.8542927036231215} | train loss {'Reaction outcome loss': 0.8206140174260063, 'Total loss': 0.8206140174260063}
2022-11-18 02:27:13,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:13,242 INFO:     Epoch: 45
2022-11-18 02:27:14,088 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8281561705199155, 'Total loss': 0.8281561705199155} | train loss {'Reaction outcome loss': 0.8231700220175328, 'Total loss': 0.8231700220175328}
2022-11-18 02:27:14,088 INFO:     Found new best model at epoch 45
2022-11-18 02:27:14,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:14,089 INFO:     Epoch: 46
2022-11-18 02:27:14,888 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8356580463322726, 'Total loss': 0.8356580463322726} | train loss {'Reaction outcome loss': 0.8202083585483413, 'Total loss': 0.8202083585483413}
2022-11-18 02:27:14,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:14,889 INFO:     Epoch: 47
2022-11-18 02:27:15,664 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8785373324697668, 'Total loss': 0.8785373324697668} | train loss {'Reaction outcome loss': 0.8186507344005569, 'Total loss': 0.8186507344005569}
2022-11-18 02:27:15,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:15,665 INFO:     Epoch: 48
2022-11-18 02:27:16,465 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8750765323638916, 'Total loss': 0.8750765323638916} | train loss {'Reaction outcome loss': 0.8194477607405954, 'Total loss': 0.8194477607405954}
2022-11-18 02:27:16,465 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:16,465 INFO:     Epoch: 49
2022-11-18 02:27:17,250 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8436900160529397, 'Total loss': 0.8436900160529397} | train loss {'Reaction outcome loss': 0.8204472486170069, 'Total loss': 0.8204472486170069}
2022-11-18 02:27:17,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:17,250 INFO:     Epoch: 50
2022-11-18 02:27:18,049 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8494083244692195, 'Total loss': 0.8494083244692195} | train loss {'Reaction outcome loss': 0.8231953544722449, 'Total loss': 0.8231953544722449}
2022-11-18 02:27:18,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:18,050 INFO:     Epoch: 51
2022-11-18 02:27:18,838 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8503586148673837, 'Total loss': 0.8503586148673837} | train loss {'Reaction outcome loss': 0.8235897803979535, 'Total loss': 0.8235897803979535}
2022-11-18 02:27:18,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:18,838 INFO:     Epoch: 52
2022-11-18 02:27:19,639 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8446977619420398, 'Total loss': 0.8446977619420398} | train loss {'Reaction outcome loss': 0.8220701647862312, 'Total loss': 0.8220701647862312}
2022-11-18 02:27:19,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:19,639 INFO:     Epoch: 53
2022-11-18 02:27:20,447 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8461456163363024, 'Total loss': 0.8461456163363024} | train loss {'Reaction outcome loss': 0.8251939506059692, 'Total loss': 0.8251939506059692}
2022-11-18 02:27:20,448 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:20,448 INFO:     Epoch: 54
2022-11-18 02:27:21,280 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8503312434662472, 'Total loss': 0.8503312434662472} | train loss {'Reaction outcome loss': 0.8233065267484034, 'Total loss': 0.8233065267484034}
2022-11-18 02:27:21,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:21,280 INFO:     Epoch: 55
2022-11-18 02:27:22,124 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8709026277065277, 'Total loss': 0.8709026277065277} | train loss {'Reaction outcome loss': 0.8234980612272217, 'Total loss': 0.8234980612272217}
2022-11-18 02:27:22,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:22,124 INFO:     Epoch: 56
2022-11-18 02:27:22,975 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8517835580489852, 'Total loss': 0.8517835580489852} | train loss {'Reaction outcome loss': 0.8187542358233083, 'Total loss': 0.8187542358233083}
2022-11-18 02:27:22,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:22,975 INFO:     Epoch: 57
2022-11-18 02:27:23,781 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.850293101912195, 'Total loss': 0.850293101912195} | train loss {'Reaction outcome loss': 0.8239137500284179, 'Total loss': 0.8239137500284179}
2022-11-18 02:27:23,782 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:23,782 INFO:     Epoch: 58
2022-11-18 02:27:24,553 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.847271478311582, 'Total loss': 0.847271478311582} | train loss {'Reaction outcome loss': 0.8271215304491981, 'Total loss': 0.8271215304491981}
2022-11-18 02:27:24,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:24,554 INFO:     Epoch: 59
2022-11-18 02:27:25,396 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8329695158384063, 'Total loss': 0.8329695158384063} | train loss {'Reaction outcome loss': 0.822415572140486, 'Total loss': 0.822415572140486}
2022-11-18 02:27:25,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:25,396 INFO:     Epoch: 60
2022-11-18 02:27:26,238 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8520417145707391, 'Total loss': 0.8520417145707391} | train loss {'Reaction outcome loss': 0.8230498251655409, 'Total loss': 0.8230498251655409}
2022-11-18 02:27:26,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:26,238 INFO:     Epoch: 61
2022-11-18 02:27:27,035 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8731452246958559, 'Total loss': 0.8731452246958559} | train loss {'Reaction outcome loss': 0.8220314647882215, 'Total loss': 0.8220314647882215}
2022-11-18 02:27:27,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:27,036 INFO:     Epoch: 62
2022-11-18 02:27:27,834 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8391462388363752, 'Total loss': 0.8391462388363752} | train loss {'Reaction outcome loss': 0.8247632384300232, 'Total loss': 0.8247632384300232}
2022-11-18 02:27:27,835 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:27,835 INFO:     Epoch: 63
2022-11-18 02:27:28,648 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8331589509140361, 'Total loss': 0.8331589509140361} | train loss {'Reaction outcome loss': 0.821975739132012, 'Total loss': 0.821975739132012}
2022-11-18 02:27:28,648 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:28,648 INFO:     Epoch: 64
2022-11-18 02:27:29,477 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8726221919059753, 'Total loss': 0.8726221919059753} | train loss {'Reaction outcome loss': 0.8205546281270443, 'Total loss': 0.8205546281270443}
2022-11-18 02:27:29,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:29,477 INFO:     Epoch: 65
2022-11-18 02:27:30,269 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8290967534888875, 'Total loss': 0.8290967534888875} | train loss {'Reaction outcome loss': 0.8196106824663377, 'Total loss': 0.8196106824663377}
2022-11-18 02:27:30,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:30,269 INFO:     Epoch: 66
2022-11-18 02:27:31,032 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8242903067307039, 'Total loss': 0.8242903067307039} | train loss {'Reaction outcome loss': 0.8192984193202949, 'Total loss': 0.8192984193202949}
2022-11-18 02:27:31,032 INFO:     Found new best model at epoch 66
2022-11-18 02:27:31,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:31,033 INFO:     Epoch: 67
2022-11-18 02:27:31,828 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8456475836309519, 'Total loss': 0.8456475836309519} | train loss {'Reaction outcome loss': 0.8222965910550086, 'Total loss': 0.8222965910550086}
2022-11-18 02:27:31,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:31,828 INFO:     Epoch: 68
2022-11-18 02:27:32,645 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8600233901630748, 'Total loss': 0.8600233901630748} | train loss {'Reaction outcome loss': 0.8215120362658654, 'Total loss': 0.8215120362658654}
2022-11-18 02:27:32,646 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:32,646 INFO:     Epoch: 69
2022-11-18 02:27:33,469 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8363908061927016, 'Total loss': 0.8363908061927016} | train loss {'Reaction outcome loss': 0.8191909991925762, 'Total loss': 0.8191909991925762}
2022-11-18 02:27:33,469 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:33,469 INFO:     Epoch: 70
2022-11-18 02:27:34,300 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8859328397295692, 'Total loss': 0.8859328397295692} | train loss {'Reaction outcome loss': 0.823195859549507, 'Total loss': 0.823195859549507}
2022-11-18 02:27:34,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:34,300 INFO:     Epoch: 71
2022-11-18 02:27:35,143 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8405987227504904, 'Total loss': 0.8405987227504904} | train loss {'Reaction outcome loss': 0.8232919606229951, 'Total loss': 0.8232919606229951}
2022-11-18 02:27:35,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:35,143 INFO:     Epoch: 72
2022-11-18 02:27:35,963 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8537635640664534, 'Total loss': 0.8537635640664534} | train loss {'Reaction outcome loss': 0.8259830850987665, 'Total loss': 0.8259830850987665}
2022-11-18 02:27:35,963 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:35,963 INFO:     Epoch: 73
2022-11-18 02:27:36,777 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8504772965203632, 'Total loss': 0.8504772965203632} | train loss {'Reaction outcome loss': 0.8214195948694983, 'Total loss': 0.8214195948694983}
2022-11-18 02:27:36,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:36,777 INFO:     Epoch: 74
2022-11-18 02:27:37,572 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8490881730209697, 'Total loss': 0.8490881730209697} | train loss {'Reaction outcome loss': 0.8246193184487282, 'Total loss': 0.8246193184487282}
2022-11-18 02:27:37,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:37,573 INFO:     Epoch: 75
2022-11-18 02:27:38,411 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8347358866171404, 'Total loss': 0.8347358866171404} | train loss {'Reaction outcome loss': 0.8179764968733634, 'Total loss': 0.8179764968733634}
2022-11-18 02:27:38,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:38,412 INFO:     Epoch: 76
2022-11-18 02:27:39,237 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8625551990487359, 'Total loss': 0.8625551990487359} | train loss {'Reaction outcome loss': 0.8224081781602675, 'Total loss': 0.8224081781602675}
2022-11-18 02:27:39,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:39,237 INFO:     Epoch: 77
2022-11-18 02:27:40,058 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8477960134094412, 'Total loss': 0.8477960134094412} | train loss {'Reaction outcome loss': 0.8250006705282196, 'Total loss': 0.8250006705282196}
2022-11-18 02:27:40,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:40,060 INFO:     Epoch: 78
2022-11-18 02:27:40,832 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8551553054289385, 'Total loss': 0.8551553054289385} | train loss {'Reaction outcome loss': 0.8255049396426447, 'Total loss': 0.8255049396426447}
2022-11-18 02:27:40,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:40,832 INFO:     Epoch: 79
2022-11-18 02:27:41,640 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.845701394433325, 'Total loss': 0.845701394433325} | train loss {'Reaction outcome loss': 0.8250696606213047, 'Total loss': 0.8250696606213047}
2022-11-18 02:27:41,640 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:41,640 INFO:     Epoch: 80
2022-11-18 02:27:42,416 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8513759015636011, 'Total loss': 0.8513759015636011} | train loss {'Reaction outcome loss': 0.8194145943608976, 'Total loss': 0.8194145943608976}
2022-11-18 02:27:42,416 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:42,416 INFO:     Epoch: 81
2022-11-18 02:27:43,229 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8505683602257208, 'Total loss': 0.8505683602257208} | train loss {'Reaction outcome loss': 0.8225959944388559, 'Total loss': 0.8225959944388559}
2022-11-18 02:27:43,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:43,229 INFO:     Epoch: 82
2022-11-18 02:27:44,051 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8412635841152885, 'Total loss': 0.8412635841152885} | train loss {'Reaction outcome loss': 0.8213414738495504, 'Total loss': 0.8213414738495504}
2022-11-18 02:27:44,051 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:44,051 INFO:     Epoch: 83
2022-11-18 02:27:44,849 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8453812389211222, 'Total loss': 0.8453812389211222} | train loss {'Reaction outcome loss': 0.8202659985230815, 'Total loss': 0.8202659985230815}
2022-11-18 02:27:44,849 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:44,850 INFO:     Epoch: 84
2022-11-18 02:27:45,651 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8486248376694593, 'Total loss': 0.8486248376694593} | train loss {'Reaction outcome loss': 0.8214029924523446, 'Total loss': 0.8214029924523446}
2022-11-18 02:27:45,651 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:45,651 INFO:     Epoch: 85
2022-11-18 02:27:46,446 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.854722033847462, 'Total loss': 0.854722033847462} | train loss {'Reaction outcome loss': 0.8216330088194339, 'Total loss': 0.8216330088194339}
2022-11-18 02:27:46,447 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:46,447 INFO:     Epoch: 86
2022-11-18 02:27:47,230 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8420216386968439, 'Total loss': 0.8420216386968439} | train loss {'Reaction outcome loss': 0.8217029174970042, 'Total loss': 0.8217029174970042}
2022-11-18 02:27:47,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:47,230 INFO:     Epoch: 87
2022-11-18 02:27:48,039 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8432648561217568, 'Total loss': 0.8432648561217568} | train loss {'Reaction outcome loss': 0.8258165243652559, 'Total loss': 0.8258165243652559}
2022-11-18 02:27:48,039 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:48,039 INFO:     Epoch: 88
2022-11-18 02:27:48,868 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8382896835153754, 'Total loss': 0.8382896835153754} | train loss {'Reaction outcome loss': 0.8231340375158095, 'Total loss': 0.8231340375158095}
2022-11-18 02:27:48,868 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:48,868 INFO:     Epoch: 89
2022-11-18 02:27:49,731 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8441496477885679, 'Total loss': 0.8441496477885679} | train loss {'Reaction outcome loss': 0.8209201789671375, 'Total loss': 0.8209201789671375}
2022-11-18 02:27:49,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:49,731 INFO:     Epoch: 90
2022-11-18 02:27:50,516 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8418304845690727, 'Total loss': 0.8418304845690727} | train loss {'Reaction outcome loss': 0.8201002208215575, 'Total loss': 0.8201002208215575}
2022-11-18 02:27:50,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:50,517 INFO:     Epoch: 91
2022-11-18 02:27:51,315 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8506247780539773, 'Total loss': 0.8506247780539773} | train loss {'Reaction outcome loss': 0.8253323917667712, 'Total loss': 0.8253323917667712}
2022-11-18 02:27:51,316 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:51,316 INFO:     Epoch: 92
2022-11-18 02:27:52,140 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8385613635182381, 'Total loss': 0.8385613635182381} | train loss {'Reaction outcome loss': 0.8218280032517449, 'Total loss': 0.8218280032517449}
2022-11-18 02:27:52,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:52,140 INFO:     Epoch: 93
2022-11-18 02:27:52,928 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8358765169978142, 'Total loss': 0.8358765169978142} | train loss {'Reaction outcome loss': 0.8235990614179642, 'Total loss': 0.8235990614179642}
2022-11-18 02:27:52,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:52,928 INFO:     Epoch: 94
2022-11-18 02:27:53,751 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8372031233527444, 'Total loss': 0.8372031233527444} | train loss {'Reaction outcome loss': 0.8248613994688757, 'Total loss': 0.8248613994688757}
2022-11-18 02:27:53,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:53,751 INFO:     Epoch: 95
2022-11-18 02:27:54,572 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8602104173465208, 'Total loss': 0.8602104173465208} | train loss {'Reaction outcome loss': 0.821712844554455, 'Total loss': 0.821712844554455}
2022-11-18 02:27:54,572 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:54,573 INFO:     Epoch: 96
2022-11-18 02:27:55,343 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8726474331183867, 'Total loss': 0.8726474331183867} | train loss {'Reaction outcome loss': 0.8248834271104105, 'Total loss': 0.8248834271104105}
2022-11-18 02:27:55,343 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:55,344 INFO:     Epoch: 97
2022-11-18 02:27:56,137 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8507638458501209, 'Total loss': 0.8507638458501209} | train loss {'Reaction outcome loss': 0.8230644053509159, 'Total loss': 0.8230644053509159}
2022-11-18 02:27:56,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:56,137 INFO:     Epoch: 98
2022-11-18 02:27:56,918 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8339630256999623, 'Total loss': 0.8339630256999623} | train loss {'Reaction outcome loss': 0.8207645851277536, 'Total loss': 0.8207645851277536}
2022-11-18 02:27:56,918 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:56,918 INFO:     Epoch: 99
2022-11-18 02:27:57,724 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8444865095344457, 'Total loss': 0.8444865095344457} | train loss {'Reaction outcome loss': 0.820687328014643, 'Total loss': 0.820687328014643}
2022-11-18 02:27:57,725 INFO:     Best model found after epoch 67 of 100.
2022-11-18 02:27:57,725 INFO:   Done with stage: TRAINING
2022-11-18 02:27:57,725 INFO:   Starting stage: EVALUATION
2022-11-18 02:27:57,846 INFO:   Done with stage: EVALUATION
2022-11-18 02:27:57,854 INFO:   Leaving out SEQ value Fold_0
2022-11-18 02:27:57,868 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 02:27:57,868 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:27:58,542 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:27:58,543 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:27:58,613 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:27:58,614 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:27:58,614 INFO:     No hyperparam tuning for this model
2022-11-18 02:27:58,614 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:27:58,614 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:27:58,615 INFO:     None feature selector for col prot
2022-11-18 02:27:58,615 INFO:     None feature selector for col prot
2022-11-18 02:27:58,615 INFO:     None feature selector for col prot
2022-11-18 02:27:58,616 INFO:     None feature selector for col chem
2022-11-18 02:27:58,616 INFO:     None feature selector for col chem
2022-11-18 02:27:58,616 INFO:     None feature selector for col chem
2022-11-18 02:27:58,616 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:27:58,616 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:27:58,617 INFO:     Number of params in model 168571
2022-11-18 02:27:58,621 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:27:58,621 INFO:   Starting stage: TRAINING
2022-11-18 02:27:58,679 INFO:     Val loss before train {'Reaction outcome loss': 0.980840879407796, 'Total loss': 0.980840879407796}
2022-11-18 02:27:58,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:58,680 INFO:     Epoch: 0
2022-11-18 02:27:59,463 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8040836663408713, 'Total loss': 0.8040836663408713} | train loss {'Reaction outcome loss': 0.8886722385400703, 'Total loss': 0.8886722385400703}
2022-11-18 02:27:59,463 INFO:     Found new best model at epoch 0
2022-11-18 02:27:59,463 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:27:59,464 INFO:     Epoch: 1
2022-11-18 02:28:00,279 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8074833384969018, 'Total loss': 0.8074833384969018} | train loss {'Reaction outcome loss': 0.8752241309596459, 'Total loss': 0.8752241309596459}
2022-11-18 02:28:00,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:00,279 INFO:     Epoch: 2
2022-11-18 02:28:01,074 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8215586610815742, 'Total loss': 0.8215586610815742} | train loss {'Reaction outcome loss': 0.8518809813116244, 'Total loss': 0.8518809813116244}
2022-11-18 02:28:01,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:01,074 INFO:     Epoch: 3
2022-11-18 02:28:01,879 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8009303875944831, 'Total loss': 0.8009303875944831} | train loss {'Reaction outcome loss': 0.8536371604392403, 'Total loss': 0.8536371604392403}
2022-11-18 02:28:01,880 INFO:     Found new best model at epoch 3
2022-11-18 02:28:01,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:01,881 INFO:     Epoch: 4
2022-11-18 02:28:02,672 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8041262240572409, 'Total loss': 0.8041262240572409} | train loss {'Reaction outcome loss': 0.8533805234712145, 'Total loss': 0.8533805234712145}
2022-11-18 02:28:02,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:02,672 INFO:     Epoch: 5
2022-11-18 02:28:03,460 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7865249521353028, 'Total loss': 0.7865249521353028} | train loss {'Reaction outcome loss': 0.842558226363379, 'Total loss': 0.842558226363379}
2022-11-18 02:28:03,460 INFO:     Found new best model at epoch 5
2022-11-18 02:28:03,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:03,461 INFO:     Epoch: 6
2022-11-18 02:28:04,285 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.850188751112331, 'Total loss': 0.850188751112331} | train loss {'Reaction outcome loss': 0.8386800817632483, 'Total loss': 0.8386800817632483}
2022-11-18 02:28:04,285 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:04,285 INFO:     Epoch: 7
2022-11-18 02:28:05,090 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7840994982556864, 'Total loss': 0.7840994982556864} | train loss {'Reaction outcome loss': 0.8378621155946602, 'Total loss': 0.8378621155946602}
2022-11-18 02:28:05,090 INFO:     Found new best model at epoch 7
2022-11-18 02:28:05,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:05,091 INFO:     Epoch: 8
2022-11-18 02:28:05,884 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8194160190495577, 'Total loss': 0.8194160190495577} | train loss {'Reaction outcome loss': 0.8340461782598303, 'Total loss': 0.8340461782598303}
2022-11-18 02:28:05,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:05,884 INFO:     Epoch: 9
2022-11-18 02:28:06,713 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7799723988229578, 'Total loss': 0.7799723988229578} | train loss {'Reaction outcome loss': 0.8363530402965391, 'Total loss': 0.8363530402965391}
2022-11-18 02:28:06,713 INFO:     Found new best model at epoch 9
2022-11-18 02:28:06,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:06,714 INFO:     Epoch: 10
2022-11-18 02:28:07,551 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7775540284135125, 'Total loss': 0.7775540284135125} | train loss {'Reaction outcome loss': 0.8338412909131301, 'Total loss': 0.8338412909131301}
2022-11-18 02:28:07,552 INFO:     Found new best model at epoch 10
2022-11-18 02:28:07,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:07,553 INFO:     Epoch: 11
2022-11-18 02:28:08,342 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7970496775074438, 'Total loss': 0.7970496775074438} | train loss {'Reaction outcome loss': 0.8311582463472961, 'Total loss': 0.8311582463472961}
2022-11-18 02:28:08,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:08,342 INFO:     Epoch: 12
2022-11-18 02:28:09,105 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8001564944332297, 'Total loss': 0.8001564944332297} | train loss {'Reaction outcome loss': 0.8367942298954798, 'Total loss': 0.8367942298954798}
2022-11-18 02:28:09,105 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:09,105 INFO:     Epoch: 13
2022-11-18 02:28:09,900 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7838930927894332, 'Total loss': 0.7838930927894332} | train loss {'Reaction outcome loss': 0.8330388433537502, 'Total loss': 0.8330388433537502}
2022-11-18 02:28:09,900 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:09,900 INFO:     Epoch: 14
2022-11-18 02:28:10,719 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.797357704829086, 'Total loss': 0.797357704829086} | train loss {'Reaction outcome loss': 0.8297090789808436, 'Total loss': 0.8297090789808436}
2022-11-18 02:28:10,719 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:10,719 INFO:     Epoch: 15
2022-11-18 02:28:11,536 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7998895428397439, 'Total loss': 0.7998895428397439} | train loss {'Reaction outcome loss': 0.8230948060192922, 'Total loss': 0.8230948060192922}
2022-11-18 02:28:11,537 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:11,538 INFO:     Epoch: 16
2022-11-18 02:28:12,343 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7699460488828745, 'Total loss': 0.7699460488828745} | train loss {'Reaction outcome loss': 0.8286569128001509, 'Total loss': 0.8286569128001509}
2022-11-18 02:28:12,343 INFO:     Found new best model at epoch 16
2022-11-18 02:28:12,344 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:12,344 INFO:     Epoch: 17
2022-11-18 02:28:13,145 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7783979035236619, 'Total loss': 0.7783979035236619} | train loss {'Reaction outcome loss': 0.8281188141479183, 'Total loss': 0.8281188141479183}
2022-11-18 02:28:13,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:13,146 INFO:     Epoch: 18
2022-11-18 02:28:13,996 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7831897085363214, 'Total loss': 0.7831897085363214} | train loss {'Reaction outcome loss': 0.8244626060852155, 'Total loss': 0.8244626060852155}
2022-11-18 02:28:13,996 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:13,996 INFO:     Epoch: 19
2022-11-18 02:28:14,824 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8040235780856826, 'Total loss': 0.8040235780856826} | train loss {'Reaction outcome loss': 0.8271237920653, 'Total loss': 0.8271237920653}
2022-11-18 02:28:14,824 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:14,824 INFO:     Epoch: 20
2022-11-18 02:28:15,635 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7838728305968371, 'Total loss': 0.7838728305968371} | train loss {'Reaction outcome loss': 0.8263126028784615, 'Total loss': 0.8263126028784615}
2022-11-18 02:28:15,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:15,635 INFO:     Epoch: 21
2022-11-18 02:28:16,440 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8005463785745881, 'Total loss': 0.8005463785745881} | train loss {'Reaction outcome loss': 0.8233767936556686, 'Total loss': 0.8233767936556686}
2022-11-18 02:28:16,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:16,440 INFO:     Epoch: 22
2022-11-18 02:28:17,281 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8128907484087077, 'Total loss': 0.8128907484087077} | train loss {'Reaction outcome loss': 0.8296321451905285, 'Total loss': 0.8296321451905285}
2022-11-18 02:28:17,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:17,281 INFO:     Epoch: 23
2022-11-18 02:28:18,121 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7695056711408225, 'Total loss': 0.7695056711408225} | train loss {'Reaction outcome loss': 0.8305043173946349, 'Total loss': 0.8305043173946349}
2022-11-18 02:28:18,122 INFO:     Found new best model at epoch 23
2022-11-18 02:28:18,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:18,123 INFO:     Epoch: 24
2022-11-18 02:28:18,940 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7764989354393699, 'Total loss': 0.7764989354393699} | train loss {'Reaction outcome loss': 0.824175204222019, 'Total loss': 0.824175204222019}
2022-11-18 02:28:18,940 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:18,940 INFO:     Epoch: 25
2022-11-18 02:28:19,753 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7958521070805463, 'Total loss': 0.7958521070805463} | train loss {'Reaction outcome loss': 0.8213860184361457, 'Total loss': 0.8213860184361457}
2022-11-18 02:28:19,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:19,753 INFO:     Epoch: 26
2022-11-18 02:28:20,606 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7775811939076944, 'Total loss': 0.7775811939076944} | train loss {'Reaction outcome loss': 0.8259998865214436, 'Total loss': 0.8259998865214436}
2022-11-18 02:28:20,606 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:20,606 INFO:     Epoch: 27
2022-11-18 02:28:21,422 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7798423022031784, 'Total loss': 0.7798423022031784} | train loss {'Reaction outcome loss': 0.8318559926772408, 'Total loss': 0.8318559926772408}
2022-11-18 02:28:21,422 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:21,422 INFO:     Epoch: 28
2022-11-18 02:28:22,219 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8051345883445307, 'Total loss': 0.8051345883445307} | train loss {'Reaction outcome loss': 0.8337378485000085, 'Total loss': 0.8337378485000085}
2022-11-18 02:28:22,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:22,220 INFO:     Epoch: 29
2022-11-18 02:28:23,023 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.782031045041301, 'Total loss': 0.782031045041301} | train loss {'Reaction outcome loss': 0.8252113574610548, 'Total loss': 0.8252113574610548}
2022-11-18 02:28:23,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:23,024 INFO:     Epoch: 30
2022-11-18 02:28:23,857 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7994144802743738, 'Total loss': 0.7994144802743738} | train loss {'Reaction outcome loss': 0.8232246779719827, 'Total loss': 0.8232246779719827}
2022-11-18 02:28:23,857 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:23,857 INFO:     Epoch: 31
2022-11-18 02:28:24,681 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7915935760194605, 'Total loss': 0.7915935760194605} | train loss {'Reaction outcome loss': 0.8228715999647673, 'Total loss': 0.8228715999647673}
2022-11-18 02:28:24,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:24,681 INFO:     Epoch: 32
2022-11-18 02:28:25,475 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7833505618301305, 'Total loss': 0.7833505618301305} | train loss {'Reaction outcome loss': 0.8333177568941463, 'Total loss': 0.8333177568941463}
2022-11-18 02:28:25,476 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:25,476 INFO:     Epoch: 33
2022-11-18 02:28:26,276 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7760164818980477, 'Total loss': 0.7760164818980477} | train loss {'Reaction outcome loss': 0.8242914627800103, 'Total loss': 0.8242914627800103}
2022-11-18 02:28:26,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:26,276 INFO:     Epoch: 34
2022-11-18 02:28:27,059 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7839305461807684, 'Total loss': 0.7839305461807684} | train loss {'Reaction outcome loss': 0.8260017704625844, 'Total loss': 0.8260017704625844}
2022-11-18 02:28:27,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:27,059 INFO:     Epoch: 35
2022-11-18 02:28:27,873 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7834321802312677, 'Total loss': 0.7834321802312677} | train loss {'Reaction outcome loss': 0.8246798747584887, 'Total loss': 0.8246798747584887}
2022-11-18 02:28:27,874 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:27,874 INFO:     Epoch: 36
2022-11-18 02:28:28,728 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7840257815339349, 'Total loss': 0.7840257815339349} | train loss {'Reaction outcome loss': 0.8264060822816995, 'Total loss': 0.8264060822816995}
2022-11-18 02:28:28,729 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:28,729 INFO:     Epoch: 37
2022-11-18 02:28:29,559 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7881891097534787, 'Total loss': 0.7881891097534787} | train loss {'Reaction outcome loss': 0.824887718869607, 'Total loss': 0.824887718869607}
2022-11-18 02:28:29,560 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:29,560 INFO:     Epoch: 38
2022-11-18 02:28:30,411 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8091224201700904, 'Total loss': 0.8091224201700904} | train loss {'Reaction outcome loss': 0.8284539621368594, 'Total loss': 0.8284539621368594}
2022-11-18 02:28:30,412 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:30,412 INFO:     Epoch: 39
2022-11-18 02:28:31,200 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7810428481210362, 'Total loss': 0.7810428481210362} | train loss {'Reaction outcome loss': 0.8308062164286371, 'Total loss': 0.8308062164286371}
2022-11-18 02:28:31,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:31,200 INFO:     Epoch: 40
2022-11-18 02:28:31,985 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7857295322147283, 'Total loss': 0.7857295322147283} | train loss {'Reaction outcome loss': 0.8253801812527151, 'Total loss': 0.8253801812527151}
2022-11-18 02:28:31,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:31,985 INFO:     Epoch: 41
2022-11-18 02:28:32,764 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7754599303007126, 'Total loss': 0.7754599303007126} | train loss {'Reaction outcome loss': 0.8218100594303869, 'Total loss': 0.8218100594303869}
2022-11-18 02:28:32,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:32,764 INFO:     Epoch: 42
2022-11-18 02:28:33,590 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7864154651761055, 'Total loss': 0.7864154651761055} | train loss {'Reaction outcome loss': 0.8225037713161847, 'Total loss': 0.8225037713161847}
2022-11-18 02:28:33,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:33,591 INFO:     Epoch: 43
2022-11-18 02:28:34,381 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7710745727474039, 'Total loss': 0.7710745727474039} | train loss {'Reaction outcome loss': 0.8251584163802838, 'Total loss': 0.8251584163802838}
2022-11-18 02:28:34,382 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:34,382 INFO:     Epoch: 44
2022-11-18 02:28:35,160 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7927887141704559, 'Total loss': 0.7927887141704559} | train loss {'Reaction outcome loss': 0.8247780927762329, 'Total loss': 0.8247780927762329}
2022-11-18 02:28:35,160 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:35,160 INFO:     Epoch: 45
2022-11-18 02:28:35,996 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7992232177745212, 'Total loss': 0.7992232177745212} | train loss {'Reaction outcome loss': 0.8207950330290356, 'Total loss': 0.8207950330290356}
2022-11-18 02:28:35,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:35,997 INFO:     Epoch: 46
2022-11-18 02:28:36,825 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.778221762993119, 'Total loss': 0.778221762993119} | train loss {'Reaction outcome loss': 0.8268529062087719, 'Total loss': 0.8268529062087719}
2022-11-18 02:28:36,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:36,825 INFO:     Epoch: 47
2022-11-18 02:28:37,614 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7987629669633779, 'Total loss': 0.7987629669633779} | train loss {'Reaction outcome loss': 0.8214094145336615, 'Total loss': 0.8214094145336615}
2022-11-18 02:28:37,614 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:37,614 INFO:     Epoch: 48
2022-11-18 02:28:38,402 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7805332250215791, 'Total loss': 0.7805332250215791} | train loss {'Reaction outcome loss': 0.8257927280447261, 'Total loss': 0.8257927280447261}
2022-11-18 02:28:38,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:38,403 INFO:     Epoch: 49
2022-11-18 02:28:39,222 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7627586586908861, 'Total loss': 0.7627586586908861} | train loss {'Reaction outcome loss': 0.8226245840792714, 'Total loss': 0.8226245840792714}
2022-11-18 02:28:39,222 INFO:     Found new best model at epoch 49
2022-11-18 02:28:39,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:39,223 INFO:     Epoch: 50
2022-11-18 02:28:40,042 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.786057557572018, 'Total loss': 0.786057557572018} | train loss {'Reaction outcome loss': 0.8236625967962057, 'Total loss': 0.8236625967962057}
2022-11-18 02:28:40,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:40,042 INFO:     Epoch: 51
2022-11-18 02:28:40,825 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7820923775434494, 'Total loss': 0.7820923775434494} | train loss {'Reaction outcome loss': 0.8218670498263015, 'Total loss': 0.8218670498263015}
2022-11-18 02:28:40,825 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:40,825 INFO:     Epoch: 52
2022-11-18 02:28:41,597 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7928078933195635, 'Total loss': 0.7928078933195635} | train loss {'Reaction outcome loss': 0.8291200915811515, 'Total loss': 0.8291200915811515}
2022-11-18 02:28:41,597 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:41,597 INFO:     Epoch: 53
2022-11-18 02:28:42,406 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7739234200932763, 'Total loss': 0.7739234200932763} | train loss {'Reaction outcome loss': 0.8261474224961238, 'Total loss': 0.8261474224961238}
2022-11-18 02:28:42,408 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:42,409 INFO:     Epoch: 54
2022-11-18 02:28:43,227 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7834968770092184, 'Total loss': 0.7834968770092184} | train loss {'Reaction outcome loss': 0.8170156497583698, 'Total loss': 0.8170156497583698}
2022-11-18 02:28:43,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:43,227 INFO:     Epoch: 55
2022-11-18 02:28:44,029 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7945998812263663, 'Total loss': 0.7945998812263663} | train loss {'Reaction outcome loss': 0.8202860653400421, 'Total loss': 0.8202860653400421}
2022-11-18 02:28:44,029 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:44,029 INFO:     Epoch: 56
2022-11-18 02:28:44,854 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8101346458901059, 'Total loss': 0.8101346458901059} | train loss {'Reaction outcome loss': 0.8219399284495998, 'Total loss': 0.8219399284495998}
2022-11-18 02:28:44,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:44,854 INFO:     Epoch: 57
2022-11-18 02:28:45,644 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7789547809145667, 'Total loss': 0.7789547809145667} | train loss {'Reaction outcome loss': 0.8226169351382777, 'Total loss': 0.8226169351382777}
2022-11-18 02:28:45,644 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:45,645 INFO:     Epoch: 58
2022-11-18 02:28:46,429 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8161972788247195, 'Total loss': 0.8161972788247195} | train loss {'Reaction outcome loss': 0.8286374525019997, 'Total loss': 0.8286374525019997}
2022-11-18 02:28:46,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:46,429 INFO:     Epoch: 59
2022-11-18 02:28:47,227 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7779983891682192, 'Total loss': 0.7779983891682192} | train loss {'Reaction outcome loss': 0.8243441569660357, 'Total loss': 0.8243441569660357}
2022-11-18 02:28:47,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:47,227 INFO:     Epoch: 60
2022-11-18 02:28:48,044 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7716099558906122, 'Total loss': 0.7716099558906122} | train loss {'Reaction outcome loss': 0.8223630892120393, 'Total loss': 0.8223630892120393}
2022-11-18 02:28:48,044 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:48,044 INFO:     Epoch: 61
2022-11-18 02:28:48,865 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7999249954115261, 'Total loss': 0.7999249954115261} | train loss {'Reaction outcome loss': 0.821674386740696, 'Total loss': 0.821674386740696}
2022-11-18 02:28:48,866 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:48,866 INFO:     Epoch: 62
2022-11-18 02:28:49,672 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7999740568074313, 'Total loss': 0.7999740568074313} | train loss {'Reaction outcome loss': 0.8221617515994469, 'Total loss': 0.8221617515994469}
2022-11-18 02:28:49,672 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:49,673 INFO:     Epoch: 63
2022-11-18 02:28:50,473 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7820084176280282, 'Total loss': 0.7820084176280282} | train loss {'Reaction outcome loss': 0.8180275370596874, 'Total loss': 0.8180275370596874}
2022-11-18 02:28:50,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:50,473 INFO:     Epoch: 64
2022-11-18 02:28:51,273 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7680162232030522, 'Total loss': 0.7680162232030522} | train loss {'Reaction outcome loss': 0.8273671676031491, 'Total loss': 0.8273671676031491}
2022-11-18 02:28:51,273 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:51,273 INFO:     Epoch: 65
2022-11-18 02:28:52,087 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7821793698451736, 'Total loss': 0.7821793698451736} | train loss {'Reaction outcome loss': 0.8247056235427316, 'Total loss': 0.8247056235427316}
2022-11-18 02:28:52,088 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:52,088 INFO:     Epoch: 66
2022-11-18 02:28:52,933 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.771135807714679, 'Total loss': 0.771135807714679} | train loss {'Reaction outcome loss': 0.8189688951742311, 'Total loss': 0.8189688951742311}
2022-11-18 02:28:52,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:52,934 INFO:     Epoch: 67
2022-11-18 02:28:53,710 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8267995539036664, 'Total loss': 0.8267995539036664} | train loss {'Reaction outcome loss': 0.8246249793029508, 'Total loss': 0.8246249793029508}
2022-11-18 02:28:53,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:53,710 INFO:     Epoch: 68
2022-11-18 02:28:54,492 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.78087356551127, 'Total loss': 0.78087356551127} | train loss {'Reaction outcome loss': 0.82544910111408, 'Total loss': 0.82544910111408}
2022-11-18 02:28:54,492 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:54,492 INFO:     Epoch: 69
2022-11-18 02:28:55,268 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7730014568025415, 'Total loss': 0.7730014568025415} | train loss {'Reaction outcome loss': 0.8168985302096256, 'Total loss': 0.8168985302096256}
2022-11-18 02:28:55,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:55,268 INFO:     Epoch: 70
2022-11-18 02:28:56,090 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8046444234522906, 'Total loss': 0.8046444234522906} | train loss {'Reaction outcome loss': 0.8173209436026662, 'Total loss': 0.8173209436026662}
2022-11-18 02:28:56,091 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:56,091 INFO:     Epoch: 71
2022-11-18 02:28:56,886 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7983103421601382, 'Total loss': 0.7983103421601382} | train loss {'Reaction outcome loss': 0.8280225222409978, 'Total loss': 0.8280225222409978}
2022-11-18 02:28:56,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:56,886 INFO:     Epoch: 72
2022-11-18 02:28:57,695 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8026841445402666, 'Total loss': 0.8026841445402666} | train loss {'Reaction outcome loss': 0.8241755700922808, 'Total loss': 0.8241755700922808}
2022-11-18 02:28:57,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:57,695 INFO:     Epoch: 73
2022-11-18 02:28:58,495 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7703367309136824, 'Total loss': 0.7703367309136824} | train loss {'Reaction outcome loss': 0.8189544110042364, 'Total loss': 0.8189544110042364}
2022-11-18 02:28:58,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:58,495 INFO:     Epoch: 74
2022-11-18 02:28:59,277 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7700626030564308, 'Total loss': 0.7700626030564308} | train loss {'Reaction outcome loss': 0.8188490206413424, 'Total loss': 0.8188490206413424}
2022-11-18 02:28:59,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:28:59,277 INFO:     Epoch: 75
2022-11-18 02:29:00,078 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7863194238055836, 'Total loss': 0.7863194238055836} | train loss {'Reaction outcome loss': 0.8213259511389713, 'Total loss': 0.8213259511389713}
2022-11-18 02:29:00,078 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:00,078 INFO:     Epoch: 76
2022-11-18 02:29:00,863 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7714225107973273, 'Total loss': 0.7714225107973273} | train loss {'Reaction outcome loss': 0.8281312709153905, 'Total loss': 0.8281312709153905}
2022-11-18 02:29:00,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:00,863 INFO:     Epoch: 77
2022-11-18 02:29:01,651 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7906432382085107, 'Total loss': 0.7906432382085107} | train loss {'Reaction outcome loss': 0.8223030651629213, 'Total loss': 0.8223030651629213}
2022-11-18 02:29:01,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:01,653 INFO:     Epoch: 78
2022-11-18 02:29:02,449 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7733389924873005, 'Total loss': 0.7733389924873005} | train loss {'Reaction outcome loss': 0.8165516835837229, 'Total loss': 0.8165516835837229}
2022-11-18 02:29:02,449 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:02,449 INFO:     Epoch: 79
2022-11-18 02:29:03,223 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7973026883873072, 'Total loss': 0.7973026883873072} | train loss {'Reaction outcome loss': 0.8197615725791406, 'Total loss': 0.8197615725791406}
2022-11-18 02:29:03,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:03,223 INFO:     Epoch: 80
2022-11-18 02:29:04,050 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8097410852258856, 'Total loss': 0.8097410852258856} | train loss {'Reaction outcome loss': 0.8265648964445601, 'Total loss': 0.8265648964445601}
2022-11-18 02:29:04,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:04,050 INFO:     Epoch: 81
2022-11-18 02:29:04,843 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7731719802726399, 'Total loss': 0.7731719802726399} | train loss {'Reaction outcome loss': 0.8231236921389576, 'Total loss': 0.8231236921389576}
2022-11-18 02:29:04,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:04,843 INFO:     Epoch: 82
2022-11-18 02:29:05,676 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7902112955396826, 'Total loss': 0.7902112955396826} | train loss {'Reaction outcome loss': 0.8229196261056522, 'Total loss': 0.8229196261056522}
2022-11-18 02:29:05,676 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:05,676 INFO:     Epoch: 83
2022-11-18 02:29:06,531 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.790622934021733, 'Total loss': 0.790622934021733} | train loss {'Reaction outcome loss': 0.8188293693278, 'Total loss': 0.8188293693278}
2022-11-18 02:29:06,531 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:06,531 INFO:     Epoch: 84
2022-11-18 02:29:07,331 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7901311306790872, 'Total loss': 0.7901311306790872} | train loss {'Reaction outcome loss': 0.8278735342778658, 'Total loss': 0.8278735342778658}
2022-11-18 02:29:07,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:07,331 INFO:     Epoch: 85
2022-11-18 02:29:08,172 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.798414831134406, 'Total loss': 0.798414831134406} | train loss {'Reaction outcome loss': 0.8276772769356546, 'Total loss': 0.8276772769356546}
2022-11-18 02:29:08,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:08,172 INFO:     Epoch: 86
2022-11-18 02:29:08,981 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8094912435520779, 'Total loss': 0.8094912435520779} | train loss {'Reaction outcome loss': 0.8241762442868731, 'Total loss': 0.8241762442868731}
2022-11-18 02:29:08,982 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:08,982 INFO:     Epoch: 87
2022-11-18 02:29:09,794 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8008618144826456, 'Total loss': 0.8008618144826456} | train loss {'Reaction outcome loss': 0.8255602945441659, 'Total loss': 0.8255602945441659}
2022-11-18 02:29:09,795 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:09,795 INFO:     Epoch: 88
2022-11-18 02:29:10,611 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7747112289071083, 'Total loss': 0.7747112289071083} | train loss {'Reaction outcome loss': 0.822816613956019, 'Total loss': 0.822816613956019}
2022-11-18 02:29:10,612 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:10,612 INFO:     Epoch: 89
2022-11-18 02:29:11,480 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8162780810486187, 'Total loss': 0.8162780810486187} | train loss {'Reaction outcome loss': 0.8325957963582475, 'Total loss': 0.8325957963582475}
2022-11-18 02:29:11,480 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:11,480 INFO:     Epoch: 90
2022-11-18 02:29:12,280 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7972088686444543, 'Total loss': 0.7972088686444543} | train loss {'Reaction outcome loss': 0.8248298425182157, 'Total loss': 0.8248298425182157}
2022-11-18 02:29:12,280 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:12,280 INFO:     Epoch: 91
2022-11-18 02:29:13,084 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8006994703953917, 'Total loss': 0.8006994703953917} | train loss {'Reaction outcome loss': 0.8204734659026026, 'Total loss': 0.8204734659026026}
2022-11-18 02:29:13,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:13,086 INFO:     Epoch: 92
2022-11-18 02:29:13,894 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7979387817057696, 'Total loss': 0.7979387817057696} | train loss {'Reaction outcome loss': 0.8273141857100884, 'Total loss': 0.8273141857100884}
2022-11-18 02:29:13,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:13,895 INFO:     Epoch: 93
2022-11-18 02:29:14,701 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7876585024324331, 'Total loss': 0.7876585024324331} | train loss {'Reaction outcome loss': 0.8211417350510837, 'Total loss': 0.8211417350510837}
2022-11-18 02:29:14,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:14,701 INFO:     Epoch: 94
2022-11-18 02:29:15,489 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7608319995078173, 'Total loss': 0.7608319995078173} | train loss {'Reaction outcome loss': 0.8245103094983197, 'Total loss': 0.8245103094983197}
2022-11-18 02:29:15,489 INFO:     Found new best model at epoch 94
2022-11-18 02:29:15,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:15,490 INFO:     Epoch: 95
2022-11-18 02:29:16,274 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7696658162908121, 'Total loss': 0.7696658162908121} | train loss {'Reaction outcome loss': 0.8261066228754608, 'Total loss': 0.8261066228754608}
2022-11-18 02:29:16,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:16,274 INFO:     Epoch: 96
2022-11-18 02:29:17,134 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7861980301412669, 'Total loss': 0.7861980301412669} | train loss {'Reaction outcome loss': 0.8249255049566508, 'Total loss': 0.8249255049566508}
2022-11-18 02:29:17,134 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:17,135 INFO:     Epoch: 97
2022-11-18 02:29:17,917 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8012761155312712, 'Total loss': 0.8012761155312712} | train loss {'Reaction outcome loss': 0.8250975024844953, 'Total loss': 0.8250975024844953}
2022-11-18 02:29:17,917 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:17,917 INFO:     Epoch: 98
2022-11-18 02:29:18,734 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.767628899352117, 'Total loss': 0.767628899352117} | train loss {'Reaction outcome loss': 0.8205424191256766, 'Total loss': 0.8205424191256766}
2022-11-18 02:29:18,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:18,735 INFO:     Epoch: 99
2022-11-18 02:29:19,529 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7779889946634119, 'Total loss': 0.7779889946634119} | train loss {'Reaction outcome loss': 0.8242945190865983, 'Total loss': 0.8242945190865983}
2022-11-18 02:29:19,530 INFO:     Best model found after epoch 95 of 100.
2022-11-18 02:29:19,530 INFO:   Done with stage: TRAINING
2022-11-18 02:29:19,530 INFO:   Starting stage: EVALUATION
2022-11-18 02:29:19,656 INFO:   Done with stage: EVALUATION
2022-11-18 02:29:19,656 INFO:   Leaving out SEQ value Fold_1
2022-11-18 02:29:19,670 INFO:   examples: 20,544| examples in train: 15,504 | examples in val: 2,736| examples in test: 2,304
2022-11-18 02:29:19,670 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:29:20,344 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:29:20,345 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:29:20,413 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:29:20,414 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:29:20,414 INFO:     No hyperparam tuning for this model
2022-11-18 02:29:20,414 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:29:20,414 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:29:20,414 INFO:     None feature selector for col prot
2022-11-18 02:29:20,415 INFO:     None feature selector for col prot
2022-11-18 02:29:20,415 INFO:     None feature selector for col prot
2022-11-18 02:29:20,415 INFO:     None feature selector for col chem
2022-11-18 02:29:20,415 INFO:     None feature selector for col chem
2022-11-18 02:29:20,415 INFO:     None feature selector for col chem
2022-11-18 02:29:20,416 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:29:20,416 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:29:20,417 INFO:     Number of params in model 168571
2022-11-18 02:29:20,420 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:29:20,421 INFO:   Starting stage: TRAINING
2022-11-18 02:29:20,478 INFO:     Val loss before train {'Reaction outcome loss': 1.0569710093875264, 'Total loss': 1.0569710093875264}
2022-11-18 02:29:20,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:20,478 INFO:     Epoch: 0
2022-11-18 02:29:21,244 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8865055857702743, 'Total loss': 0.8865055857702743} | train loss {'Reaction outcome loss': 0.9009776060227994, 'Total loss': 0.9009776060227994}
2022-11-18 02:29:21,244 INFO:     Found new best model at epoch 0
2022-11-18 02:29:21,245 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:21,245 INFO:     Epoch: 1
2022-11-18 02:29:22,034 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.9539106772389523, 'Total loss': 0.9539106772389523} | train loss {'Reaction outcome loss': 0.8556350595911835, 'Total loss': 0.8556350595911835}
2022-11-18 02:29:22,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:22,035 INFO:     Epoch: 2
2022-11-18 02:29:22,837 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8804743906786275, 'Total loss': 0.8804743906786275} | train loss {'Reaction outcome loss': 0.861295658987736, 'Total loss': 0.861295658987736}
2022-11-18 02:29:22,837 INFO:     Found new best model at epoch 2
2022-11-18 02:29:22,838 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:22,838 INFO:     Epoch: 3
2022-11-18 02:29:23,633 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8528900409853736, 'Total loss': 0.8528900409853736} | train loss {'Reaction outcome loss': 0.8572911206832148, 'Total loss': 0.8572911206832148}
2022-11-18 02:29:23,633 INFO:     Found new best model at epoch 3
2022-11-18 02:29:23,634 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:23,634 INFO:     Epoch: 4
2022-11-18 02:29:24,418 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8752872431000998, 'Total loss': 0.8752872431000998} | train loss {'Reaction outcome loss': 0.8531161442460347, 'Total loss': 0.8531161442460347}
2022-11-18 02:29:24,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:24,419 INFO:     Epoch: 5
2022-11-18 02:29:25,202 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.89063345831494, 'Total loss': 0.89063345831494} | train loss {'Reaction outcome loss': 0.8442026904090442, 'Total loss': 0.8442026904090442}
2022-11-18 02:29:25,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:25,202 INFO:     Epoch: 6
2022-11-18 02:29:25,974 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8830114013926927, 'Total loss': 0.8830114013926927} | train loss {'Reaction outcome loss': 0.8443042655540592, 'Total loss': 0.8443042655540592}
2022-11-18 02:29:25,974 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:25,975 INFO:     Epoch: 7
2022-11-18 02:29:26,774 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8595008683759112, 'Total loss': 0.8595008683759112} | train loss {'Reaction outcome loss': 0.844532428332317, 'Total loss': 0.844532428332317}
2022-11-18 02:29:26,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:26,774 INFO:     Epoch: 8
2022-11-18 02:29:27,566 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.845723771078642, 'Total loss': 0.845723771078642} | train loss {'Reaction outcome loss': 0.8422813503830521, 'Total loss': 0.8422813503830521}
2022-11-18 02:29:27,566 INFO:     Found new best model at epoch 8
2022-11-18 02:29:27,567 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:27,567 INFO:     Epoch: 9
2022-11-18 02:29:28,338 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8463538406893264, 'Total loss': 0.8463538406893264} | train loss {'Reaction outcome loss': 0.8367418686058296, 'Total loss': 0.8367418686058296}
2022-11-18 02:29:28,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:28,338 INFO:     Epoch: 10
2022-11-18 02:29:29,137 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8739451031352199, 'Total loss': 0.8739451031352199} | train loss {'Reaction outcome loss': 0.8412134042737905, 'Total loss': 0.8412134042737905}
2022-11-18 02:29:29,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:29,137 INFO:     Epoch: 11
2022-11-18 02:29:29,915 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.841167803420577, 'Total loss': 0.841167803420577} | train loss {'Reaction outcome loss': 0.8371487738173685, 'Total loss': 0.8371487738173685}
2022-11-18 02:29:29,915 INFO:     Found new best model at epoch 11
2022-11-18 02:29:29,916 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:29,916 INFO:     Epoch: 12
2022-11-18 02:29:30,715 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8601774906003198, 'Total loss': 0.8601774906003198} | train loss {'Reaction outcome loss': 0.8359640657656477, 'Total loss': 0.8359640657656477}
2022-11-18 02:29:30,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:30,715 INFO:     Epoch: 13
2022-11-18 02:29:31,487 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8450835915498955, 'Total loss': 0.8450835915498955} | train loss {'Reaction outcome loss': 0.8431420936996554, 'Total loss': 0.8431420936996554}
2022-11-18 02:29:31,487 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:31,487 INFO:     Epoch: 14
2022-11-18 02:29:32,275 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8437075504036837, 'Total loss': 0.8437075504036837} | train loss {'Reaction outcome loss': 0.8361355733479001, 'Total loss': 0.8361355733479001}
2022-11-18 02:29:32,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:32,276 INFO:     Epoch: 15
2022-11-18 02:29:33,068 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8536212167074514, 'Total loss': 0.8536212167074514} | train loss {'Reaction outcome loss': 0.8359480437673168, 'Total loss': 0.8359480437673168}
2022-11-18 02:29:33,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:33,068 INFO:     Epoch: 16
2022-11-18 02:29:33,832 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8538737629735192, 'Total loss': 0.8538737629735192} | train loss {'Reaction outcome loss': 0.8415942568592574, 'Total loss': 0.8415942568592574}
2022-11-18 02:29:33,832 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:33,832 INFO:     Epoch: 17
2022-11-18 02:29:34,616 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8944674203562182, 'Total loss': 0.8944674203562182} | train loss {'Reaction outcome loss': 0.83550971571678, 'Total loss': 0.83550971571678}
2022-11-18 02:29:34,617 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:34,617 INFO:     Epoch: 18
2022-11-18 02:29:35,405 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8670142355353333, 'Total loss': 0.8670142355353333} | train loss {'Reaction outcome loss': 0.8378198648431173, 'Total loss': 0.8378198648431173}
2022-11-18 02:29:35,406 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:35,406 INFO:     Epoch: 19
2022-11-18 02:29:36,219 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8588220324627188, 'Total loss': 0.8588220324627188} | train loss {'Reaction outcome loss': 0.835793796267529, 'Total loss': 0.835793796267529}
2022-11-18 02:29:36,220 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:36,220 INFO:     Epoch: 20
2022-11-18 02:29:37,013 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8854751074036886, 'Total loss': 0.8854751074036886} | train loss {'Reaction outcome loss': 0.8343991964687536, 'Total loss': 0.8343991964687536}
2022-11-18 02:29:37,013 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:37,013 INFO:     Epoch: 21
2022-11-18 02:29:37,820 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8384272241315176, 'Total loss': 0.8384272241315176} | train loss {'Reaction outcome loss': 0.8365481213777645, 'Total loss': 0.8365481213777645}
2022-11-18 02:29:37,821 INFO:     Found new best model at epoch 21
2022-11-18 02:29:37,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:37,821 INFO:     Epoch: 22
2022-11-18 02:29:38,622 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8516855496306752, 'Total loss': 0.8516855496306752} | train loss {'Reaction outcome loss': 0.8324276203971831, 'Total loss': 0.8324276203971831}
2022-11-18 02:29:38,622 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:38,622 INFO:     Epoch: 23
2022-11-18 02:29:39,403 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8579005529714185, 'Total loss': 0.8579005529714185} | train loss {'Reaction outcome loss': 0.8351953241805481, 'Total loss': 0.8351953241805481}
2022-11-18 02:29:39,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:39,404 INFO:     Epoch: 24
2022-11-18 02:29:40,171 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8517925413542016, 'Total loss': 0.8517925413542016} | train loss {'Reaction outcome loss': 0.8347812250808433, 'Total loss': 0.8347812250808433}
2022-11-18 02:29:40,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:40,172 INFO:     Epoch: 25
2022-11-18 02:29:40,947 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8434642705806467, 'Total loss': 0.8434642705806467} | train loss {'Reaction outcome loss': 0.8299071155948403, 'Total loss': 0.8299071155948403}
2022-11-18 02:29:40,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:40,947 INFO:     Epoch: 26
2022-11-18 02:29:41,755 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8652611222378043, 'Total loss': 0.8652611222378043} | train loss {'Reaction outcome loss': 0.8332868978810408, 'Total loss': 0.8332868978810408}
2022-11-18 02:29:41,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:41,755 INFO:     Epoch: 27
2022-11-18 02:29:42,521 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8718125404313554, 'Total loss': 0.8718125404313554} | train loss {'Reaction outcome loss': 0.838407612263911, 'Total loss': 0.838407612263911}
2022-11-18 02:29:42,521 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:42,522 INFO:     Epoch: 28
2022-11-18 02:29:43,333 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8676432211731755, 'Total loss': 0.8676432211731755} | train loss {'Reaction outcome loss': 0.836977484294907, 'Total loss': 0.836977484294907}
2022-11-18 02:29:43,334 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:43,334 INFO:     Epoch: 29
2022-11-18 02:29:44,130 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8653827108616052, 'Total loss': 0.8653827108616052} | train loss {'Reaction outcome loss': 0.8360418040811279, 'Total loss': 0.8360418040811279}
2022-11-18 02:29:44,131 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:44,131 INFO:     Epoch: 30
2022-11-18 02:29:44,888 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8312652637792188, 'Total loss': 0.8312652637792188} | train loss {'Reaction outcome loss': 0.8330895887235555, 'Total loss': 0.8330895887235555}
2022-11-18 02:29:44,890 INFO:     Found new best model at epoch 30
2022-11-18 02:29:44,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:44,890 INFO:     Epoch: 31
2022-11-18 02:29:45,661 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8569418968156327, 'Total loss': 0.8569418968156327} | train loss {'Reaction outcome loss': 0.8332246971228485, 'Total loss': 0.8332246971228485}
2022-11-18 02:29:45,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:45,661 INFO:     Epoch: 32
2022-11-18 02:29:46,444 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.841056206891703, 'Total loss': 0.841056206891703} | train loss {'Reaction outcome loss': 0.8335260404235542, 'Total loss': 0.8335260404235542}
2022-11-18 02:29:46,445 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:46,445 INFO:     Epoch: 33
2022-11-18 02:29:47,217 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8837763292844906, 'Total loss': 0.8837763292844906} | train loss {'Reaction outcome loss': 0.8351451635606004, 'Total loss': 0.8351451635606004}
2022-11-18 02:29:47,217 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:47,217 INFO:     Epoch: 34
2022-11-18 02:29:48,015 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8550185422564662, 'Total loss': 0.8550185422564662} | train loss {'Reaction outcome loss': 0.8333735931434749, 'Total loss': 0.8333735931434749}
2022-11-18 02:29:48,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:48,016 INFO:     Epoch: 35
2022-11-18 02:29:48,790 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8860244958899742, 'Total loss': 0.8860244958899742} | train loss {'Reaction outcome loss': 0.8316788489435926, 'Total loss': 0.8316788489435926}
2022-11-18 02:29:48,791 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:48,791 INFO:     Epoch: 36
2022-11-18 02:29:49,582 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.9027089975601019, 'Total loss': 0.9027089975601019} | train loss {'Reaction outcome loss': 0.8335350375361894, 'Total loss': 0.8335350375361894}
2022-11-18 02:29:49,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:49,582 INFO:     Epoch: 37
2022-11-18 02:29:50,341 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8557792042576989, 'Total loss': 0.8557792042576989} | train loss {'Reaction outcome loss': 0.8336725286495539, 'Total loss': 0.8336725286495539}
2022-11-18 02:29:50,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:50,342 INFO:     Epoch: 38
2022-11-18 02:29:51,094 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8598770499229431, 'Total loss': 0.8598770499229431} | train loss {'Reaction outcome loss': 0.8288407645843647, 'Total loss': 0.8288407645843647}
2022-11-18 02:29:51,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:51,095 INFO:     Epoch: 39
2022-11-18 02:29:51,866 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8567633594191352, 'Total loss': 0.8567633594191352} | train loss {'Reaction outcome loss': 0.8332138347282331, 'Total loss': 0.8332138347282331}
2022-11-18 02:29:51,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:51,867 INFO:     Epoch: 40
2022-11-18 02:29:52,629 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8751103420590245, 'Total loss': 0.8751103420590245} | train loss {'Reaction outcome loss': 0.8309556064291747, 'Total loss': 0.8309556064291747}
2022-11-18 02:29:52,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:52,629 INFO:     Epoch: 41
2022-11-18 02:29:53,411 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8468118919882663, 'Total loss': 0.8468118919882663} | train loss {'Reaction outcome loss': 0.8328644800701259, 'Total loss': 0.8328644800701259}
2022-11-18 02:29:53,411 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:53,411 INFO:     Epoch: 42
2022-11-18 02:29:54,201 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8570900192094404, 'Total loss': 0.8570900192094404} | train loss {'Reaction outcome loss': 0.8316103260458252, 'Total loss': 0.8316103260458252}
2022-11-18 02:29:54,202 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:54,202 INFO:     Epoch: 43
2022-11-18 02:29:54,935 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8740757509719493, 'Total loss': 0.8740757509719493} | train loss {'Reaction outcome loss': 0.8338741373132776, 'Total loss': 0.8338741373132776}
2022-11-18 02:29:54,935 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:54,936 INFO:     Epoch: 44
2022-11-18 02:29:55,720 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8501128263251726, 'Total loss': 0.8501128263251726} | train loss {'Reaction outcome loss': 0.8332774323936353, 'Total loss': 0.8332774323936353}
2022-11-18 02:29:55,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:55,720 INFO:     Epoch: 45
2022-11-18 02:29:56,506 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8587221267611481, 'Total loss': 0.8587221267611481} | train loss {'Reaction outcome loss': 0.832980716670001, 'Total loss': 0.832980716670001}
2022-11-18 02:29:56,506 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:56,506 INFO:     Epoch: 46
2022-11-18 02:29:57,272 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8491718561150307, 'Total loss': 0.8491718561150307} | train loss {'Reaction outcome loss': 0.8338872976754428, 'Total loss': 0.8338872976754428}
2022-11-18 02:29:57,272 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:57,272 INFO:     Epoch: 47
2022-11-18 02:29:58,056 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8442240648491438, 'Total loss': 0.8442240648491438} | train loss {'Reaction outcome loss': 0.8296961461810909, 'Total loss': 0.8296961461810909}
2022-11-18 02:29:58,056 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:58,056 INFO:     Epoch: 48
2022-11-18 02:29:58,818 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8548164132029511, 'Total loss': 0.8548164132029511} | train loss {'Reaction outcome loss': 0.8303274503705923, 'Total loss': 0.8303274503705923}
2022-11-18 02:29:58,818 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:58,818 INFO:     Epoch: 49
2022-11-18 02:29:59,591 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8517789022867069, 'Total loss': 0.8517789022867069} | train loss {'Reaction outcome loss': 0.8343514207704568, 'Total loss': 0.8343514207704568}
2022-11-18 02:29:59,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:29:59,592 INFO:     Epoch: 50
2022-11-18 02:30:00,363 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8395395570023115, 'Total loss': 0.8395395570023115} | train loss {'Reaction outcome loss': 0.8302614611608011, 'Total loss': 0.8302614611608011}
2022-11-18 02:30:00,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:00,363 INFO:     Epoch: 51
2022-11-18 02:30:01,127 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8387377262115479, 'Total loss': 0.8387377262115479} | train loss {'Reaction outcome loss': 0.8358454198994264, 'Total loss': 0.8358454198994264}
2022-11-18 02:30:01,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:01,128 INFO:     Epoch: 52
2022-11-18 02:30:01,886 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8369172478831092, 'Total loss': 0.8369172478831092} | train loss {'Reaction outcome loss': 0.8304765072379092, 'Total loss': 0.8304765072379092}
2022-11-18 02:30:01,886 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:01,886 INFO:     Epoch: 53
2022-11-18 02:30:02,652 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8542629106100216, 'Total loss': 0.8542629106100216} | train loss {'Reaction outcome loss': 0.8331045077906715, 'Total loss': 0.8331045077906715}
2022-11-18 02:30:02,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:02,652 INFO:     Epoch: 54
2022-11-18 02:30:03,418 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8679521880870642, 'Total loss': 0.8679521880870642} | train loss {'Reaction outcome loss': 0.8306090375523508, 'Total loss': 0.8306090375523508}
2022-11-18 02:30:03,419 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:03,419 INFO:     Epoch: 55
2022-11-18 02:30:04,171 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8332762108292691, 'Total loss': 0.8332762108292691} | train loss {'Reaction outcome loss': 0.8327043496777491, 'Total loss': 0.8327043496777491}
2022-11-18 02:30:04,172 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:04,172 INFO:     Epoch: 56
2022-11-18 02:30:04,944 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8925815418709157, 'Total loss': 0.8925815418709157} | train loss {'Reaction outcome loss': 0.8322628526775925, 'Total loss': 0.8322628526775925}
2022-11-18 02:30:04,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:04,944 INFO:     Epoch: 57
2022-11-18 02:30:05,710 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8368388608444569, 'Total loss': 0.8368388608444569} | train loss {'Reaction outcome loss': 0.8305623985121771, 'Total loss': 0.8305623985121771}
2022-11-18 02:30:05,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:05,710 INFO:     Epoch: 58
2022-11-18 02:30:06,490 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8684161388596823, 'Total loss': 0.8684161388596823} | train loss {'Reaction outcome loss': 0.8269986042392597, 'Total loss': 0.8269986042392597}
2022-11-18 02:30:06,490 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:06,490 INFO:     Epoch: 59
2022-11-18 02:30:07,243 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8457560518453288, 'Total loss': 0.8457560518453288} | train loss {'Reaction outcome loss': 0.832707515101374, 'Total loss': 0.832707515101374}
2022-11-18 02:30:07,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:07,243 INFO:     Epoch: 60
2022-11-18 02:30:08,031 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8592676485693732, 'Total loss': 0.8592676485693732} | train loss {'Reaction outcome loss': 0.8331812883846064, 'Total loss': 0.8331812883846064}
2022-11-18 02:30:08,031 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:08,031 INFO:     Epoch: 61
2022-11-18 02:30:08,810 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.84397586833599, 'Total loss': 0.84397586833599} | train loss {'Reaction outcome loss': 0.8326504757865466, 'Total loss': 0.8326504757865466}
2022-11-18 02:30:08,810 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:08,810 INFO:     Epoch: 62
2022-11-18 02:30:09,585 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8664286032665608, 'Total loss': 0.8664286032665608} | train loss {'Reaction outcome loss': 0.829134484132131, 'Total loss': 0.829134484132131}
2022-11-18 02:30:09,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:09,585 INFO:     Epoch: 63
2022-11-18 02:30:10,341 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8403782733651095, 'Total loss': 0.8403782733651095} | train loss {'Reaction outcome loss': 0.8299341286406104, 'Total loss': 0.8299341286406104}
2022-11-18 02:30:10,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:10,342 INFO:     Epoch: 64
2022-11-18 02:30:11,136 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8937291322752486, 'Total loss': 0.8937291322752486} | train loss {'Reaction outcome loss': 0.829342985962644, 'Total loss': 0.829342985962644}
2022-11-18 02:30:11,136 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:11,136 INFO:     Epoch: 65
2022-11-18 02:30:11,921 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8471241953761078, 'Total loss': 0.8471241953761078} | train loss {'Reaction outcome loss': 0.830395879936807, 'Total loss': 0.830395879936807}
2022-11-18 02:30:11,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:11,921 INFO:     Epoch: 66
2022-11-18 02:30:12,691 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8296220586743466, 'Total loss': 0.8296220586743466} | train loss {'Reaction outcome loss': 0.8296462662916615, 'Total loss': 0.8296462662916615}
2022-11-18 02:30:12,692 INFO:     Found new best model at epoch 66
2022-11-18 02:30:12,692 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:12,693 INFO:     Epoch: 67
2022-11-18 02:30:13,446 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8445033181545346, 'Total loss': 0.8445033181545346} | train loss {'Reaction outcome loss': 0.8309896558891108, 'Total loss': 0.8309896558891108}
2022-11-18 02:30:13,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:13,446 INFO:     Epoch: 68
2022-11-18 02:30:14,211 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8449633052182752, 'Total loss': 0.8449633052182752} | train loss {'Reaction outcome loss': 0.8310899377605061, 'Total loss': 0.8310899377605061}
2022-11-18 02:30:14,212 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:14,212 INFO:     Epoch: 69
2022-11-18 02:30:14,997 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8469366528267084, 'Total loss': 0.8469366528267084} | train loss {'Reaction outcome loss': 0.8281516581160542, 'Total loss': 0.8281516581160542}
2022-11-18 02:30:14,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:14,997 INFO:     Epoch: 70
2022-11-18 02:30:15,766 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8465063405591388, 'Total loss': 0.8465063405591388} | train loss {'Reaction outcome loss': 0.8356362961447288, 'Total loss': 0.8356362961447288}
2022-11-18 02:30:15,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:15,767 INFO:     Epoch: 71
2022-11-18 02:30:16,535 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8768248689729113, 'Total loss': 0.8768248689729113} | train loss {'Reaction outcome loss': 0.8297745287418365, 'Total loss': 0.8297745287418365}
2022-11-18 02:30:16,536 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:16,536 INFO:     Epoch: 72
2022-11-18 02:30:17,307 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.852987174377885, 'Total loss': 0.852987174377885} | train loss {'Reaction outcome loss': 0.8275480424916303, 'Total loss': 0.8275480424916303}
2022-11-18 02:30:17,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:17,308 INFO:     Epoch: 73
2022-11-18 02:30:18,085 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.9194570980792822, 'Total loss': 0.9194570980792822} | train loss {'Reaction outcome loss': 0.8257075766477074, 'Total loss': 0.8257075766477074}
2022-11-18 02:30:18,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:18,085 INFO:     Epoch: 74
2022-11-18 02:30:18,862 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8747352978517843, 'Total loss': 0.8747352978517843} | train loss {'Reaction outcome loss': 0.8309003288853806, 'Total loss': 0.8309003288853806}
2022-11-18 02:30:18,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:18,863 INFO:     Epoch: 75
2022-11-18 02:30:19,631 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8546817323496175, 'Total loss': 0.8546817323496175} | train loss {'Reaction outcome loss': 0.8318160390902939, 'Total loss': 0.8318160390902939}
2022-11-18 02:30:19,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:19,631 INFO:     Epoch: 76
2022-11-18 02:30:20,381 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8447013663691144, 'Total loss': 0.8447013663691144} | train loss {'Reaction outcome loss': 0.8303801907923977, 'Total loss': 0.8303801907923977}
2022-11-18 02:30:20,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:20,381 INFO:     Epoch: 77
2022-11-18 02:30:21,140 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8472488924514415, 'Total loss': 0.8472488924514415} | train loss {'Reaction outcome loss': 0.8267857472837707, 'Total loss': 0.8267857472837707}
2022-11-18 02:30:21,140 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:21,140 INFO:     Epoch: 78
2022-11-18 02:30:21,927 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8352725609790447, 'Total loss': 0.8352725609790447} | train loss {'Reaction outcome loss': 0.8281242416964637, 'Total loss': 0.8281242416964637}
2022-11-18 02:30:21,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:21,928 INFO:     Epoch: 79
2022-11-18 02:30:22,720 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8444630129392757, 'Total loss': 0.8444630129392757} | train loss {'Reaction outcome loss': 0.8283459179931216, 'Total loss': 0.8283459179931216}
2022-11-18 02:30:22,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:22,720 INFO:     Epoch: 80
2022-11-18 02:30:23,462 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8562513478966647, 'Total loss': 0.8562513478966647} | train loss {'Reaction outcome loss': 0.8304335446759997, 'Total loss': 0.8304335446759997}
2022-11-18 02:30:23,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:23,462 INFO:     Epoch: 81
2022-11-18 02:30:24,223 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8633576271145843, 'Total loss': 0.8633576271145843} | train loss {'Reaction outcome loss': 0.8348601769517969, 'Total loss': 0.8348601769517969}
2022-11-18 02:30:24,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:24,223 INFO:     Epoch: 82
2022-11-18 02:30:24,978 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.8395743903725646, 'Total loss': 0.8395743903725646} | train loss {'Reaction outcome loss': 0.8250168461981133, 'Total loss': 0.8250168461981133}
2022-11-18 02:30:24,978 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:24,978 INFO:     Epoch: 83
2022-11-18 02:30:25,757 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8426252853038699, 'Total loss': 0.8426252853038699} | train loss {'Reaction outcome loss': 0.8279325606401075, 'Total loss': 0.8279325606401075}
2022-11-18 02:30:25,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:25,757 INFO:     Epoch: 84
2022-11-18 02:30:26,488 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8356445043586022, 'Total loss': 0.8356445043586022} | train loss {'Reaction outcome loss': 0.8355102001884838, 'Total loss': 0.8355102001884838}
2022-11-18 02:30:26,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:26,488 INFO:     Epoch: 85
2022-11-18 02:30:27,242 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8491450797679813, 'Total loss': 0.8491450797679813} | train loss {'Reaction outcome loss': 0.827370482952997, 'Total loss': 0.827370482952997}
2022-11-18 02:30:27,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:27,243 INFO:     Epoch: 86
2022-11-18 02:30:28,027 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8422866248807241, 'Total loss': 0.8422866248807241} | train loss {'Reaction outcome loss': 0.8302895304106881, 'Total loss': 0.8302895304106881}
2022-11-18 02:30:28,027 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:28,027 INFO:     Epoch: 87
2022-11-18 02:30:28,787 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8452659249305725, 'Total loss': 0.8452659249305725} | train loss {'Reaction outcome loss': 0.8313468080243946, 'Total loss': 0.8313468080243946}
2022-11-18 02:30:28,787 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:28,787 INFO:     Epoch: 88
2022-11-18 02:30:29,545 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.84023781155431, 'Total loss': 0.84023781155431} | train loss {'Reaction outcome loss': 0.8290536284692003, 'Total loss': 0.8290536284692003}
2022-11-18 02:30:29,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:29,546 INFO:     Epoch: 89
2022-11-18 02:30:30,302 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8342982828617096, 'Total loss': 0.8342982828617096} | train loss {'Reaction outcome loss': 0.8310120187301204, 'Total loss': 0.8310120187301204}
2022-11-18 02:30:30,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:30,302 INFO:     Epoch: 90
2022-11-18 02:30:31,080 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8351235237232474, 'Total loss': 0.8351235237232474} | train loss {'Reaction outcome loss': 0.8286704752180312, 'Total loss': 0.8286704752180312}
2022-11-18 02:30:31,080 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:31,080 INFO:     Epoch: 91
2022-11-18 02:30:31,867 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8448124015054037, 'Total loss': 0.8448124015054037} | train loss {'Reaction outcome loss': 0.8325595569953997, 'Total loss': 0.8325595569953997}
2022-11-18 02:30:31,867 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:31,867 INFO:     Epoch: 92
2022-11-18 02:30:32,611 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8453322163847989, 'Total loss': 0.8453322163847989} | train loss {'Reaction outcome loss': 0.8263268926997244, 'Total loss': 0.8263268926997244}
2022-11-18 02:30:32,611 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:32,611 INFO:     Epoch: 93
2022-11-18 02:30:33,410 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8502753723499387, 'Total loss': 0.8502753723499387} | train loss {'Reaction outcome loss': 0.8279427223735385, 'Total loss': 0.8279427223735385}
2022-11-18 02:30:33,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:33,410 INFO:     Epoch: 94
2022-11-18 02:30:34,179 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8608025880747063, 'Total loss': 0.8608025880747063} | train loss {'Reaction outcome loss': 0.8292997627837178, 'Total loss': 0.8292997627837178}
2022-11-18 02:30:34,180 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:34,180 INFO:     Epoch: 95
2022-11-18 02:30:34,950 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8417140439499257, 'Total loss': 0.8417140439499257} | train loss {'Reaction outcome loss': 0.8322315370595014, 'Total loss': 0.8322315370595014}
2022-11-18 02:30:34,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:34,951 INFO:     Epoch: 96
2022-11-18 02:30:35,757 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8634388010169185, 'Total loss': 0.8634388010169185} | train loss {'Reaction outcome loss': 0.8332708601843674, 'Total loss': 0.8332708601843674}
2022-11-18 02:30:35,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:35,757 INFO:     Epoch: 97
2022-11-18 02:30:36,510 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.843141433111457, 'Total loss': 0.843141433111457} | train loss {'Reaction outcome loss': 0.8278515769375695, 'Total loss': 0.8278515769375695}
2022-11-18 02:30:36,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:36,511 INFO:     Epoch: 98
2022-11-18 02:30:37,264 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8631521075270897, 'Total loss': 0.8631521075270897} | train loss {'Reaction outcome loss': 0.8271754657535396, 'Total loss': 0.8271754657535396}
2022-11-18 02:30:37,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:37,264 INFO:     Epoch: 99
2022-11-18 02:30:38,012 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8365635740202527, 'Total loss': 0.8365635740202527} | train loss {'Reaction outcome loss': 0.8277230931162344, 'Total loss': 0.8277230931162344}
2022-11-18 02:30:38,012 INFO:     Best model found after epoch 67 of 100.
2022-11-18 02:30:38,012 INFO:   Done with stage: TRAINING
2022-11-18 02:30:38,012 INFO:   Starting stage: EVALUATION
2022-11-18 02:30:38,156 INFO:   Done with stage: EVALUATION
2022-11-18 02:30:38,156 INFO:   Leaving out SEQ value Fold_2
2022-11-18 02:30:38,169 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 02:30:38,169 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:30:38,837 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:30:38,838 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:30:38,907 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:30:38,907 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:30:38,908 INFO:     No hyperparam tuning for this model
2022-11-18 02:30:38,908 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:30:38,908 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:30:38,909 INFO:     None feature selector for col prot
2022-11-18 02:30:38,909 INFO:     None feature selector for col prot
2022-11-18 02:30:38,909 INFO:     None feature selector for col prot
2022-11-18 02:30:38,909 INFO:     None feature selector for col chem
2022-11-18 02:30:38,910 INFO:     None feature selector for col chem
2022-11-18 02:30:38,910 INFO:     None feature selector for col chem
2022-11-18 02:30:38,910 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:30:38,910 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:30:38,911 INFO:     Number of params in model 168571
2022-11-18 02:30:38,915 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:30:38,915 INFO:   Starting stage: TRAINING
2022-11-18 02:30:38,972 INFO:     Val loss before train {'Reaction outcome loss': 1.0113853487101467, 'Total loss': 1.0113853487101467}
2022-11-18 02:30:38,972 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:38,972 INFO:     Epoch: 0
2022-11-18 02:30:39,756 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8629972054199739, 'Total loss': 0.8629972054199739} | train loss {'Reaction outcome loss': 0.8920278982240326, 'Total loss': 0.8920278982240326}
2022-11-18 02:30:39,756 INFO:     Found new best model at epoch 0
2022-11-18 02:30:39,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:39,757 INFO:     Epoch: 1
2022-11-18 02:30:40,540 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8132926679470323, 'Total loss': 0.8132926679470323} | train loss {'Reaction outcome loss': 0.8632400752330313, 'Total loss': 0.8632400752330313}
2022-11-18 02:30:40,540 INFO:     Found new best model at epoch 1
2022-11-18 02:30:40,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:40,541 INFO:     Epoch: 2
2022-11-18 02:30:41,335 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8632893474264578, 'Total loss': 0.8632893474264578} | train loss {'Reaction outcome loss': 0.8599689745173162, 'Total loss': 0.8599689745173162}
2022-11-18 02:30:41,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:41,336 INFO:     Epoch: 3
2022-11-18 02:30:42,111 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8114080043001608, 'Total loss': 0.8114080043001608} | train loss {'Reaction outcome loss': 0.852171215475822, 'Total loss': 0.852171215475822}
2022-11-18 02:30:42,111 INFO:     Found new best model at epoch 3
2022-11-18 02:30:42,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:42,112 INFO:     Epoch: 4
2022-11-18 02:30:42,883 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7980318895795129, 'Total loss': 0.7980318895795129} | train loss {'Reaction outcome loss': 0.8545019893013701, 'Total loss': 0.8545019893013701}
2022-11-18 02:30:42,884 INFO:     Found new best model at epoch 4
2022-11-18 02:30:42,884 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:42,884 INFO:     Epoch: 5
2022-11-18 02:30:43,684 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8030920526520773, 'Total loss': 0.8030920526520773} | train loss {'Reaction outcome loss': 0.8492396027457957, 'Total loss': 0.8492396027457957}
2022-11-18 02:30:43,684 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:43,684 INFO:     Epoch: 6
2022-11-18 02:30:44,472 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8090986013412476, 'Total loss': 0.8090986013412476} | train loss {'Reaction outcome loss': 0.8437574667590005, 'Total loss': 0.8437574667590005}
2022-11-18 02:30:44,472 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:44,472 INFO:     Epoch: 7
2022-11-18 02:30:45,300 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8193842998959802, 'Total loss': 0.8193842998959802} | train loss {'Reaction outcome loss': 0.8405369250141844, 'Total loss': 0.8405369250141844}
2022-11-18 02:30:45,300 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:45,300 INFO:     Epoch: 8
2022-11-18 02:30:46,097 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8156508593396707, 'Total loss': 0.8156508593396707} | train loss {'Reaction outcome loss': 0.837897015591057, 'Total loss': 0.837897015591057}
2022-11-18 02:30:46,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:46,097 INFO:     Epoch: 9
2022-11-18 02:30:46,885 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8142885301600803, 'Total loss': 0.8142885301600803} | train loss {'Reaction outcome loss': 0.8380651742828136, 'Total loss': 0.8380651742828136}
2022-11-18 02:30:46,887 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:46,887 INFO:     Epoch: 10
2022-11-18 02:30:47,668 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8015958775173534, 'Total loss': 0.8015958775173534} | train loss {'Reaction outcome loss': 0.8385466885809996, 'Total loss': 0.8385466885809996}
2022-11-18 02:30:47,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:47,668 INFO:     Epoch: 11
2022-11-18 02:30:48,510 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8009898994456638, 'Total loss': 0.8009898994456638} | train loss {'Reaction outcome loss': 0.837571995355645, 'Total loss': 0.837571995355645}
2022-11-18 02:30:48,510 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:48,510 INFO:     Epoch: 12
2022-11-18 02:30:49,352 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8104097897356207, 'Total loss': 0.8104097897356207} | train loss {'Reaction outcome loss': 0.8393839595269184, 'Total loss': 0.8393839595269184}
2022-11-18 02:30:49,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:49,353 INFO:     Epoch: 13
2022-11-18 02:30:50,137 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.823783428831534, 'Total loss': 0.823783428831534} | train loss {'Reaction outcome loss': 0.8398048191654439, 'Total loss': 0.8398048191654439}
2022-11-18 02:30:50,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:50,137 INFO:     Epoch: 14
2022-11-18 02:30:50,975 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8057702292095531, 'Total loss': 0.8057702292095531} | train loss {'Reaction outcome loss': 0.8355430860908664, 'Total loss': 0.8355430860908664}
2022-11-18 02:30:50,975 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:50,975 INFO:     Epoch: 15
2022-11-18 02:30:51,753 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.81426187266003, 'Total loss': 0.81426187266003} | train loss {'Reaction outcome loss': 0.8325995271303216, 'Total loss': 0.8325995271303216}
2022-11-18 02:30:51,753 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:51,753 INFO:     Epoch: 16
2022-11-18 02:30:52,521 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7962586351416328, 'Total loss': 0.7962586351416328} | train loss {'Reaction outcome loss': 0.8347916504558252, 'Total loss': 0.8347916504558252}
2022-11-18 02:30:52,521 INFO:     Found new best model at epoch 16
2022-11-18 02:30:52,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:52,522 INFO:     Epoch: 17
2022-11-18 02:30:53,303 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7896354154429652, 'Total loss': 0.7896354154429652} | train loss {'Reaction outcome loss': 0.8341585907400871, 'Total loss': 0.8341585907400871}
2022-11-18 02:30:53,304 INFO:     Found new best model at epoch 17
2022-11-18 02:30:53,305 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:53,305 INFO:     Epoch: 18
2022-11-18 02:30:54,069 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7976405549455773, 'Total loss': 0.7976405549455773} | train loss {'Reaction outcome loss': 0.8352233349060526, 'Total loss': 0.8352233349060526}
2022-11-18 02:30:54,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:54,069 INFO:     Epoch: 19
2022-11-18 02:30:54,904 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8162889724428003, 'Total loss': 0.8162889724428003} | train loss {'Reaction outcome loss': 0.8361702348504748, 'Total loss': 0.8361702348504748}
2022-11-18 02:30:54,904 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:54,904 INFO:     Epoch: 20
2022-11-18 02:30:55,722 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8082752925428477, 'Total loss': 0.8082752925428477} | train loss {'Reaction outcome loss': 0.8347785454623553, 'Total loss': 0.8347785454623553}
2022-11-18 02:30:55,722 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:55,722 INFO:     Epoch: 21
2022-11-18 02:30:56,508 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8072748543186621, 'Total loss': 0.8072748543186621} | train loss {'Reaction outcome loss': 0.8316044163947203, 'Total loss': 0.8316044163947203}
2022-11-18 02:30:56,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:56,508 INFO:     Epoch: 22
2022-11-18 02:30:57,299 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7898923686959527, 'Total loss': 0.7898923686959527} | train loss {'Reaction outcome loss': 0.8311376333236694, 'Total loss': 0.8311376333236694}
2022-11-18 02:30:57,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:57,299 INFO:     Epoch: 23
2022-11-18 02:30:58,095 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8252095546234738, 'Total loss': 0.8252095546234738} | train loss {'Reaction outcome loss': 0.8317257883597393, 'Total loss': 0.8317257883597393}
2022-11-18 02:30:58,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:58,095 INFO:     Epoch: 24
2022-11-18 02:30:58,923 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7976749999956652, 'Total loss': 0.7976749999956652} | train loss {'Reaction outcome loss': 0.8332151889801025, 'Total loss': 0.8332151889801025}
2022-11-18 02:30:58,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:58,923 INFO:     Epoch: 25
2022-11-18 02:30:59,724 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8579231283881448, 'Total loss': 0.8579231283881448} | train loss {'Reaction outcome loss': 0.829844013403873, 'Total loss': 0.829844013403873}
2022-11-18 02:30:59,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:30:59,725 INFO:     Epoch: 26
2022-11-18 02:31:00,508 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8292029506780885, 'Total loss': 0.8292029506780885} | train loss {'Reaction outcome loss': 0.8340868526575517, 'Total loss': 0.8340868526575517}
2022-11-18 02:31:00,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:00,509 INFO:     Epoch: 27
2022-11-18 02:31:01,319 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7990024530074813, 'Total loss': 0.7990024530074813} | train loss {'Reaction outcome loss': 0.833403445993151, 'Total loss': 0.833403445993151}
2022-11-18 02:31:01,319 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:01,319 INFO:     Epoch: 28
2022-11-18 02:31:02,165 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8345672528852116, 'Total loss': 0.8345672528852116} | train loss {'Reaction outcome loss': 0.8344702805791583, 'Total loss': 0.8344702805791583}
2022-11-18 02:31:02,165 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:02,165 INFO:     Epoch: 29
2022-11-18 02:31:02,919 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8121034760366787, 'Total loss': 0.8121034760366787} | train loss {'Reaction outcome loss': 0.8319764789269894, 'Total loss': 0.8319764789269894}
2022-11-18 02:31:02,919 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:02,920 INFO:     Epoch: 30
2022-11-18 02:31:03,746 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8185158439657905, 'Total loss': 0.8185158439657905} | train loss {'Reaction outcome loss': 0.8295426233690613, 'Total loss': 0.8295426233690613}
2022-11-18 02:31:03,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:03,746 INFO:     Epoch: 31
2022-11-18 02:31:04,553 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8233334124088287, 'Total loss': 0.8233334124088287} | train loss {'Reaction outcome loss': 0.8301019930109685, 'Total loss': 0.8301019930109685}
2022-11-18 02:31:04,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:04,553 INFO:     Epoch: 32
2022-11-18 02:31:05,378 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8301143361763521, 'Total loss': 0.8301143361763521} | train loss {'Reaction outcome loss': 0.8319793257178093, 'Total loss': 0.8319793257178093}
2022-11-18 02:31:05,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:05,380 INFO:     Epoch: 33
2022-11-18 02:31:06,200 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8125966408035972, 'Total loss': 0.8125966408035972} | train loss {'Reaction outcome loss': 0.8341808013770045, 'Total loss': 0.8341808013770045}
2022-11-18 02:31:06,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:06,200 INFO:     Epoch: 34
2022-11-18 02:31:07,012 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8261606151407416, 'Total loss': 0.8261606151407416} | train loss {'Reaction outcome loss': 0.8332852599572163, 'Total loss': 0.8332852599572163}
2022-11-18 02:31:07,012 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:07,012 INFO:     Epoch: 35
2022-11-18 02:31:07,803 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8326532129536975, 'Total loss': 0.8326532129536975} | train loss {'Reaction outcome loss': 0.8372098135704897, 'Total loss': 0.8372098135704897}
2022-11-18 02:31:07,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:07,803 INFO:     Epoch: 36
2022-11-18 02:31:08,579 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8129080594940619, 'Total loss': 0.8129080594940619} | train loss {'Reaction outcome loss': 0.8340536859570717, 'Total loss': 0.8340536859570717}
2022-11-18 02:31:08,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:08,580 INFO:     Epoch: 37
2022-11-18 02:31:09,352 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8172050071033564, 'Total loss': 0.8172050071033564} | train loss {'Reaction outcome loss': 0.8331403417246682, 'Total loss': 0.8331403417246682}
2022-11-18 02:31:09,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:09,352 INFO:     Epoch: 38
2022-11-18 02:31:10,132 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8009990155696869, 'Total loss': 0.8009990155696869} | train loss {'Reaction outcome loss': 0.8294087156957509, 'Total loss': 0.8294087156957509}
2022-11-18 02:31:10,132 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:10,132 INFO:     Epoch: 39
2022-11-18 02:31:10,897 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8087774765762415, 'Total loss': 0.8087774765762415} | train loss {'Reaction outcome loss': 0.8292226112618738, 'Total loss': 0.8292226112618738}
2022-11-18 02:31:10,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:10,897 INFO:     Epoch: 40
2022-11-18 02:31:11,661 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8123245401815935, 'Total loss': 0.8123245401815935} | train loss {'Reaction outcome loss': 0.831199693193241, 'Total loss': 0.831199693193241}
2022-11-18 02:31:11,661 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:11,661 INFO:     Epoch: 41
2022-11-18 02:31:12,417 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8097845911979675, 'Total loss': 0.8097845911979675} | train loss {'Reaction outcome loss': 0.8291822677972366, 'Total loss': 0.8291822677972366}
2022-11-18 02:31:12,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:12,417 INFO:     Epoch: 42
2022-11-18 02:31:13,178 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7966871474954215, 'Total loss': 0.7966871474954215} | train loss {'Reaction outcome loss': 0.8296112145696367, 'Total loss': 0.8296112145696367}
2022-11-18 02:31:13,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:13,178 INFO:     Epoch: 43
2022-11-18 02:31:13,942 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7918362217870626, 'Total loss': 0.7918362217870626} | train loss {'Reaction outcome loss': 0.831194508927209, 'Total loss': 0.831194508927209}
2022-11-18 02:31:13,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:13,942 INFO:     Epoch: 44
2022-11-18 02:31:14,733 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8381618999622085, 'Total loss': 0.8381618999622085} | train loss {'Reaction outcome loss': 0.8292075806734513, 'Total loss': 0.8292075806734513}
2022-11-18 02:31:14,733 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:14,733 INFO:     Epoch: 45
2022-11-18 02:31:15,514 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8018536280671303, 'Total loss': 0.8018536280671303} | train loss {'Reaction outcome loss': 0.8357895842620304, 'Total loss': 0.8357895842620304}
2022-11-18 02:31:15,515 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:15,515 INFO:     Epoch: 46
2022-11-18 02:31:16,294 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7938534739342603, 'Total loss': 0.7938534739342603} | train loss {'Reaction outcome loss': 0.8334341174485732, 'Total loss': 0.8334341174485732}
2022-11-18 02:31:16,294 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:16,294 INFO:     Epoch: 47
2022-11-18 02:31:17,076 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7846666906367649, 'Total loss': 0.7846666906367649} | train loss {'Reaction outcome loss': 0.8291999100422373, 'Total loss': 0.8291999100422373}
2022-11-18 02:31:17,076 INFO:     Found new best model at epoch 47
2022-11-18 02:31:17,077 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:17,077 INFO:     Epoch: 48
2022-11-18 02:31:17,839 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8481879098848863, 'Total loss': 0.8481879098848863} | train loss {'Reaction outcome loss': 0.8306039688538532, 'Total loss': 0.8306039688538532}
2022-11-18 02:31:17,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:17,841 INFO:     Epoch: 49
2022-11-18 02:31:18,607 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8173426261002367, 'Total loss': 0.8173426261002367} | train loss {'Reaction outcome loss': 0.8309841186416392, 'Total loss': 0.8309841186416392}
2022-11-18 02:31:18,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:18,607 INFO:     Epoch: 50
2022-11-18 02:31:19,418 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8156959814104167, 'Total loss': 0.8156959814104167} | train loss {'Reaction outcome loss': 0.8315496618042186, 'Total loss': 0.8315496618042186}
2022-11-18 02:31:19,418 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:19,418 INFO:     Epoch: 51
2022-11-18 02:31:20,205 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.838952977548946, 'Total loss': 0.838952977548946} | train loss {'Reaction outcome loss': 0.8311599917557775, 'Total loss': 0.8311599917557775}
2022-11-18 02:31:20,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:20,205 INFO:     Epoch: 52
2022-11-18 02:31:20,967 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.8095014711672609, 'Total loss': 0.8095014711672609} | train loss {'Reaction outcome loss': 0.8242995331482011, 'Total loss': 0.8242995331482011}
2022-11-18 02:31:20,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:20,968 INFO:     Epoch: 53
2022-11-18 02:31:21,734 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8204649063673887, 'Total loss': 0.8204649063673887} | train loss {'Reaction outcome loss': 0.8305272354155171, 'Total loss': 0.8305272354155171}
2022-11-18 02:31:21,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:21,734 INFO:     Epoch: 54
2022-11-18 02:31:22,503 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7946735776283524, 'Total loss': 0.7946735776283524} | train loss {'Reaction outcome loss': 0.8324806140393627, 'Total loss': 0.8324806140393627}
2022-11-18 02:31:22,503 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:22,503 INFO:     Epoch: 55
2022-11-18 02:31:23,266 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.8098068074746565, 'Total loss': 0.8098068074746565} | train loss {'Reaction outcome loss': 0.8321909528605792, 'Total loss': 0.8321909528605792}
2022-11-18 02:31:23,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:23,266 INFO:     Epoch: 56
2022-11-18 02:31:24,020 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8051050589843229, 'Total loss': 0.8051050589843229} | train loss {'Reaction outcome loss': 0.8317960955658737, 'Total loss': 0.8317960955658737}
2022-11-18 02:31:24,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:24,021 INFO:     Epoch: 57
2022-11-18 02:31:24,792 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8234521441838958, 'Total loss': 0.8234521441838958} | train loss {'Reaction outcome loss': 0.8297500146895039, 'Total loss': 0.8297500146895039}
2022-11-18 02:31:24,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:24,792 INFO:     Epoch: 58
2022-11-18 02:31:25,561 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8019594685597853, 'Total loss': 0.8019594685597853} | train loss {'Reaction outcome loss': 0.830741426166223, 'Total loss': 0.830741426166223}
2022-11-18 02:31:25,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:25,561 INFO:     Epoch: 59
2022-11-18 02:31:26,346 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7930030233480714, 'Total loss': 0.7930030233480714} | train loss {'Reaction outcome loss': 0.827211589959203, 'Total loss': 0.827211589959203}
2022-11-18 02:31:26,347 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:26,347 INFO:     Epoch: 60
2022-11-18 02:31:27,138 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7991884442215617, 'Total loss': 0.7991884442215617} | train loss {'Reaction outcome loss': 0.8302522205576605, 'Total loss': 0.8302522205576605}
2022-11-18 02:31:27,138 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:27,138 INFO:     Epoch: 61
2022-11-18 02:31:27,912 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.80942879346284, 'Total loss': 0.80942879346284} | train loss {'Reaction outcome loss': 0.8289881115057031, 'Total loss': 0.8289881115057031}
2022-11-18 02:31:27,913 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:27,913 INFO:     Epoch: 62
2022-11-18 02:31:28,682 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8062942041592165, 'Total loss': 0.8062942041592165} | train loss {'Reaction outcome loss': 0.8310278339045388, 'Total loss': 0.8310278339045388}
2022-11-18 02:31:28,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:28,683 INFO:     Epoch: 63
2022-11-18 02:31:29,466 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7940603508190676, 'Total loss': 0.7940603508190676} | train loss {'Reaction outcome loss': 0.8337167580516971, 'Total loss': 0.8337167580516971}
2022-11-18 02:31:29,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:29,466 INFO:     Epoch: 64
2022-11-18 02:31:30,247 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7789148012684151, 'Total loss': 0.7789148012684151} | train loss {'Reaction outcome loss': 0.830900402823273, 'Total loss': 0.830900402823273}
2022-11-18 02:31:30,248 INFO:     Found new best model at epoch 64
2022-11-18 02:31:30,248 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:30,248 INFO:     Epoch: 65
2022-11-18 02:31:31,036 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8033960671587423, 'Total loss': 0.8033960671587423} | train loss {'Reaction outcome loss': 0.8300503092152732, 'Total loss': 0.8300503092152732}
2022-11-18 02:31:31,036 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:31,036 INFO:     Epoch: 66
2022-11-18 02:31:31,812 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8189411319114945, 'Total loss': 0.8189411319114945} | train loss {'Reaction outcome loss': 0.8312235312802451, 'Total loss': 0.8312235312802451}
2022-11-18 02:31:31,812 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:31,812 INFO:     Epoch: 67
2022-11-18 02:31:32,586 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8067074397748167, 'Total loss': 0.8067074397748167} | train loss {'Reaction outcome loss': 0.8303895153561417, 'Total loss': 0.8303895153561417}
2022-11-18 02:31:32,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:32,586 INFO:     Epoch: 68
2022-11-18 02:31:33,381 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8089920830997553, 'Total loss': 0.8089920830997553} | train loss {'Reaction outcome loss': 0.8305568647627928, 'Total loss': 0.8305568647627928}
2022-11-18 02:31:33,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:33,381 INFO:     Epoch: 69
2022-11-18 02:31:34,150 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8156845461238514, 'Total loss': 0.8156845461238514} | train loss {'Reaction outcome loss': 0.8334998972561894, 'Total loss': 0.8334998972561894}
2022-11-18 02:31:34,150 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:34,150 INFO:     Epoch: 70
2022-11-18 02:31:34,941 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8132542466575449, 'Total loss': 0.8132542466575449} | train loss {'Reaction outcome loss': 0.8258146722705997, 'Total loss': 0.8258146722705997}
2022-11-18 02:31:34,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:34,941 INFO:     Epoch: 71
2022-11-18 02:31:35,709 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8201841522346843, 'Total loss': 0.8201841522346843} | train loss {'Reaction outcome loss': 0.8289058096554814, 'Total loss': 0.8289058096554814}
2022-11-18 02:31:35,709 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:35,709 INFO:     Epoch: 72
2022-11-18 02:31:36,494 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8008254346522418, 'Total loss': 0.8008254346522418} | train loss {'Reaction outcome loss': 0.8315389652641452, 'Total loss': 0.8315389652641452}
2022-11-18 02:31:36,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:36,495 INFO:     Epoch: 73
2022-11-18 02:31:37,261 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7974352260882204, 'Total loss': 0.7974352260882204} | train loss {'Reaction outcome loss': 0.8308120591299875, 'Total loss': 0.8308120591299875}
2022-11-18 02:31:37,261 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:37,261 INFO:     Epoch: 74
2022-11-18 02:31:38,046 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.783335115421902, 'Total loss': 0.783335115421902} | train loss {'Reaction outcome loss': 0.8288171479896623, 'Total loss': 0.8288171479896623}
2022-11-18 02:31:38,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:38,047 INFO:     Epoch: 75
2022-11-18 02:31:38,827 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7993202500722625, 'Total loss': 0.7993202500722625} | train loss {'Reaction outcome loss': 0.829978859424591, 'Total loss': 0.829978859424591}
2022-11-18 02:31:38,827 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:38,827 INFO:     Epoch: 76
2022-11-18 02:31:39,609 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7972170371900905, 'Total loss': 0.7972170371900905} | train loss {'Reaction outcome loss': 0.8306673649622469, 'Total loss': 0.8306673649622469}
2022-11-18 02:31:39,610 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:39,610 INFO:     Epoch: 77
2022-11-18 02:31:40,387 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8275006237355146, 'Total loss': 0.8275006237355146} | train loss {'Reaction outcome loss': 0.8253781199455261, 'Total loss': 0.8253781199455261}
2022-11-18 02:31:40,387 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:40,387 INFO:     Epoch: 78
2022-11-18 02:31:41,155 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7949553883888505, 'Total loss': 0.7949553883888505} | train loss {'Reaction outcome loss': 0.8298011289567363, 'Total loss': 0.8298011289567363}
2022-11-18 02:31:41,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:41,155 INFO:     Epoch: 79
2022-11-18 02:31:41,947 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7875019575215199, 'Total loss': 0.7875019575215199} | train loss {'Reaction outcome loss': 0.8278371719681487, 'Total loss': 0.8278371719681487}
2022-11-18 02:31:41,947 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:41,947 INFO:     Epoch: 80
2022-11-18 02:31:42,707 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8061165098439563, 'Total loss': 0.8061165098439563} | train loss {'Reaction outcome loss': 0.8277177633071432, 'Total loss': 0.8277177633071432}
2022-11-18 02:31:42,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:42,707 INFO:     Epoch: 81
2022-11-18 02:31:43,470 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8160578012466431, 'Total loss': 0.8160578012466431} | train loss {'Reaction outcome loss': 0.8296862736040232, 'Total loss': 0.8296862736040232}
2022-11-18 02:31:43,470 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:43,471 INFO:     Epoch: 82
2022-11-18 02:31:44,267 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7882781875404444, 'Total loss': 0.7882781875404444} | train loss {'Reaction outcome loss': 0.8263280023117454, 'Total loss': 0.8263280023117454}
2022-11-18 02:31:44,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:44,268 INFO:     Epoch: 83
2022-11-18 02:31:45,052 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8085372651165182, 'Total loss': 0.8085372651165182} | train loss {'Reaction outcome loss': 0.8229325051818576, 'Total loss': 0.8229325051818576}
2022-11-18 02:31:45,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:45,052 INFO:     Epoch: 84
2022-11-18 02:31:45,850 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.8095512633973901, 'Total loss': 0.8095512633973901} | train loss {'Reaction outcome loss': 0.8310343900505377, 'Total loss': 0.8310343900505377}
2022-11-18 02:31:45,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:45,850 INFO:     Epoch: 85
2022-11-18 02:31:46,628 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.807578138329766, 'Total loss': 0.807578138329766} | train loss {'Reaction outcome loss': 0.8283718319571748, 'Total loss': 0.8283718319571748}
2022-11-18 02:31:46,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:46,628 INFO:     Epoch: 86
2022-11-18 02:31:47,425 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7883415757255121, 'Total loss': 0.7883415757255121} | train loss {'Reaction outcome loss': 0.8243315938784151, 'Total loss': 0.8243315938784151}
2022-11-18 02:31:47,425 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:47,425 INFO:     Epoch: 87
2022-11-18 02:31:48,226 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7934555777094581, 'Total loss': 0.7934555777094581} | train loss {'Reaction outcome loss': 0.8265345316760394, 'Total loss': 0.8265345316760394}
2022-11-18 02:31:48,226 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:48,227 INFO:     Epoch: 88
2022-11-18 02:31:48,985 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8062484426931902, 'Total loss': 0.8062484426931902} | train loss {'Reaction outcome loss': 0.8234358483431291, 'Total loss': 0.8234358483431291}
2022-11-18 02:31:48,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:48,987 INFO:     Epoch: 89
2022-11-18 02:31:49,765 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7908750928261064, 'Total loss': 0.7908750928261064} | train loss {'Reaction outcome loss': 0.8251996080486141, 'Total loss': 0.8251996080486141}
2022-11-18 02:31:49,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:49,765 INFO:     Epoch: 90
2022-11-18 02:31:50,562 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8087921040979299, 'Total loss': 0.8087921040979299} | train loss {'Reaction outcome loss': 0.8257045377273948, 'Total loss': 0.8257045377273948}
2022-11-18 02:31:50,563 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:50,563 INFO:     Epoch: 91
2022-11-18 02:31:51,353 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7927911281585693, 'Total loss': 0.7927911281585693} | train loss {'Reaction outcome loss': 0.8288846094997562, 'Total loss': 0.8288846094997562}
2022-11-18 02:31:51,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:51,353 INFO:     Epoch: 92
2022-11-18 02:31:52,127 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7793496935205027, 'Total loss': 0.7793496935205027} | train loss {'Reaction outcome loss': 0.828458595275879, 'Total loss': 0.828458595275879}
2022-11-18 02:31:52,127 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:52,127 INFO:     Epoch: 93
2022-11-18 02:31:52,882 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7874316424131393, 'Total loss': 0.7874316424131393} | train loss {'Reaction outcome loss': 0.8285363002699249, 'Total loss': 0.8285363002699249}
2022-11-18 02:31:52,882 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:52,882 INFO:     Epoch: 94
2022-11-18 02:31:53,648 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7917591343549165, 'Total loss': 0.7917591343549165} | train loss {'Reaction outcome loss': 0.8284903206387345, 'Total loss': 0.8284903206387345}
2022-11-18 02:31:53,649 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:53,649 INFO:     Epoch: 95
2022-11-18 02:31:54,440 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.8120286220853979, 'Total loss': 0.8120286220853979} | train loss {'Reaction outcome loss': 0.8300963809295576, 'Total loss': 0.8300963809295576}
2022-11-18 02:31:54,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:54,440 INFO:     Epoch: 96
2022-11-18 02:31:55,233 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8003693141720511, 'Total loss': 0.8003693141720511} | train loss {'Reaction outcome loss': 0.8266251860832682, 'Total loss': 0.8266251860832682}
2022-11-18 02:31:55,234 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:55,234 INFO:     Epoch: 97
2022-11-18 02:31:56,023 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7863368547775529, 'Total loss': 0.7863368547775529} | train loss {'Reaction outcome loss': 0.8282465746208113, 'Total loss': 0.8282465746208113}
2022-11-18 02:31:56,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:56,024 INFO:     Epoch: 98
2022-11-18 02:31:56,828 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8132220533761111, 'Total loss': 0.8132220533761111} | train loss {'Reaction outcome loss': 0.8241503602387954, 'Total loss': 0.8241503602387954}
2022-11-18 02:31:56,828 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:56,829 INFO:     Epoch: 99
2022-11-18 02:31:57,600 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8560979467901316, 'Total loss': 0.8560979467901316} | train loss {'Reaction outcome loss': 0.8243281314567644, 'Total loss': 0.8243281314567644}
2022-11-18 02:31:57,600 INFO:     Best model found after epoch 65 of 100.
2022-11-18 02:31:57,600 INFO:   Done with stage: TRAINING
2022-11-18 02:31:57,601 INFO:   Starting stage: EVALUATION
2022-11-18 02:31:57,732 INFO:   Done with stage: EVALUATION
2022-11-18 02:31:57,732 INFO:   Leaving out SEQ value Fold_3
2022-11-18 02:31:57,746 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 02:31:57,746 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:31:58,407 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:31:58,407 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:31:58,477 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:31:58,477 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:31:58,477 INFO:     No hyperparam tuning for this model
2022-11-18 02:31:58,477 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:31:58,478 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:31:58,478 INFO:     None feature selector for col prot
2022-11-18 02:31:58,478 INFO:     None feature selector for col prot
2022-11-18 02:31:58,479 INFO:     None feature selector for col prot
2022-11-18 02:31:58,479 INFO:     None feature selector for col chem
2022-11-18 02:31:58,479 INFO:     None feature selector for col chem
2022-11-18 02:31:58,479 INFO:     None feature selector for col chem
2022-11-18 02:31:58,479 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:31:58,479 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:31:58,481 INFO:     Number of params in model 168571
2022-11-18 02:31:58,484 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:31:58,484 INFO:   Starting stage: TRAINING
2022-11-18 02:31:58,543 INFO:     Val loss before train {'Reaction outcome loss': 1.0178391513499347, 'Total loss': 1.0178391513499347}
2022-11-18 02:31:58,543 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:58,543 INFO:     Epoch: 0
2022-11-18 02:31:59,325 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8513624356551603, 'Total loss': 0.8513624356551603} | train loss {'Reaction outcome loss': 0.8752216806217116, 'Total loss': 0.8752216806217116}
2022-11-18 02:31:59,325 INFO:     Found new best model at epoch 0
2022-11-18 02:31:59,326 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:31:59,326 INFO:     Epoch: 1
2022-11-18 02:32:00,103 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8364543034271761, 'Total loss': 0.8364543034271761} | train loss {'Reaction outcome loss': 0.8444791723270806, 'Total loss': 0.8444791723270806}
2022-11-18 02:32:00,103 INFO:     Found new best model at epoch 1
2022-11-18 02:32:00,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:00,104 INFO:     Epoch: 2
2022-11-18 02:32:00,927 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8138608133251016, 'Total loss': 0.8138608133251016} | train loss {'Reaction outcome loss': 0.8395934967362151, 'Total loss': 0.8395934967362151}
2022-11-18 02:32:00,927 INFO:     Found new best model at epoch 2
2022-11-18 02:32:00,928 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:00,928 INFO:     Epoch: 3
2022-11-18 02:32:01,708 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8228293846953999, 'Total loss': 0.8228293846953999} | train loss {'Reaction outcome loss': 0.8382511307998579, 'Total loss': 0.8382511307998579}
2022-11-18 02:32:01,708 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:01,708 INFO:     Epoch: 4
2022-11-18 02:32:02,470 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8137944855473258, 'Total loss': 0.8137944855473258} | train loss {'Reaction outcome loss': 0.8341581536799061, 'Total loss': 0.8341581536799061}
2022-11-18 02:32:02,471 INFO:     Found new best model at epoch 4
2022-11-18 02:32:02,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:02,472 INFO:     Epoch: 5
2022-11-18 02:32:03,266 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.801667917181145, 'Total loss': 0.801667917181145} | train loss {'Reaction outcome loss': 0.828926710084993, 'Total loss': 0.828926710084993}
2022-11-18 02:32:03,266 INFO:     Found new best model at epoch 5
2022-11-18 02:32:03,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:03,267 INFO:     Epoch: 6
2022-11-18 02:32:04,058 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7968838722868399, 'Total loss': 0.7968838722868399} | train loss {'Reaction outcome loss': 0.8204251089874579, 'Total loss': 0.8204251089874579}
2022-11-18 02:32:04,058 INFO:     Found new best model at epoch 6
2022-11-18 02:32:04,059 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:04,059 INFO:     Epoch: 7
2022-11-18 02:32:04,822 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.833514697172425, 'Total loss': 0.833514697172425} | train loss {'Reaction outcome loss': 0.8223055736142761, 'Total loss': 0.8223055736142761}
2022-11-18 02:32:04,823 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:04,823 INFO:     Epoch: 8
2022-11-18 02:32:05,604 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.847972643646327, 'Total loss': 0.847972643646327} | train loss {'Reaction outcome loss': 0.8203566289677912, 'Total loss': 0.8203566289677912}
2022-11-18 02:32:05,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:05,604 INFO:     Epoch: 9
2022-11-18 02:32:06,363 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8049040619622577, 'Total loss': 0.8049040619622577} | train loss {'Reaction outcome loss': 0.8222508738235551, 'Total loss': 0.8222508738235551}
2022-11-18 02:32:06,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:06,364 INFO:     Epoch: 10
2022-11-18 02:32:07,121 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8174624808809974, 'Total loss': 0.8174624808809974} | train loss {'Reaction outcome loss': 0.8206027069870306, 'Total loss': 0.8206027069870306}
2022-11-18 02:32:07,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:07,122 INFO:     Epoch: 11
2022-11-18 02:32:07,887 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8144809996539896, 'Total loss': 0.8144809996539896} | train loss {'Reaction outcome loss': 0.8201427571627559, 'Total loss': 0.8201427571627559}
2022-11-18 02:32:07,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:07,889 INFO:     Epoch: 12
2022-11-18 02:32:08,682 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8002972359007056, 'Total loss': 0.8002972359007056} | train loss {'Reaction outcome loss': 0.8156152011180411, 'Total loss': 0.8156152011180411}
2022-11-18 02:32:08,682 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:08,682 INFO:     Epoch: 13
2022-11-18 02:32:09,456 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8062967651269652, 'Total loss': 0.8062967651269652} | train loss {'Reaction outcome loss': 0.8134771612225746, 'Total loss': 0.8134771612225746}
2022-11-18 02:32:09,456 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:09,456 INFO:     Epoch: 14
2022-11-18 02:32:10,237 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8066060231490568, 'Total loss': 0.8066060231490568} | train loss {'Reaction outcome loss': 0.8177176928033634, 'Total loss': 0.8177176928033634}
2022-11-18 02:32:10,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:10,237 INFO:     Epoch: 15
2022-11-18 02:32:11,001 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.808488167822361, 'Total loss': 0.808488167822361} | train loss {'Reaction outcome loss': 0.8212658237437813, 'Total loss': 0.8212658237437813}
2022-11-18 02:32:11,001 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:11,001 INFO:     Epoch: 16
2022-11-18 02:32:11,755 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8063233887607401, 'Total loss': 0.8063233887607401} | train loss {'Reaction outcome loss': 0.8153536621405154, 'Total loss': 0.8153536621405154}
2022-11-18 02:32:11,755 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:11,755 INFO:     Epoch: 17
2022-11-18 02:32:12,534 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8342856338078325, 'Total loss': 0.8342856338078325} | train loss {'Reaction outcome loss': 0.8191866371096397, 'Total loss': 0.8191866371096397}
2022-11-18 02:32:12,534 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:12,534 INFO:     Epoch: 18
2022-11-18 02:32:13,307 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8118131661956961, 'Total loss': 0.8118131661956961} | train loss {'Reaction outcome loss': 0.8173980180098086, 'Total loss': 0.8173980180098086}
2022-11-18 02:32:13,307 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:13,307 INFO:     Epoch: 19
2022-11-18 02:32:14,114 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8023222495209087, 'Total loss': 0.8023222495209087} | train loss {'Reaction outcome loss': 0.8130860610884063, 'Total loss': 0.8130860610884063}
2022-11-18 02:32:14,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:14,115 INFO:     Epoch: 20
2022-11-18 02:32:14,890 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7990517345341769, 'Total loss': 0.7990517345341769} | train loss {'Reaction outcome loss': 0.8158761423461292, 'Total loss': 0.8158761423461292}
2022-11-18 02:32:14,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:14,891 INFO:     Epoch: 21
2022-11-18 02:32:15,662 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7999494766647165, 'Total loss': 0.7999494766647165} | train loss {'Reaction outcome loss': 0.8123072107227481, 'Total loss': 0.8123072107227481}
2022-11-18 02:32:15,662 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:15,662 INFO:     Epoch: 22
2022-11-18 02:32:16,440 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8037936298007314, 'Total loss': 0.8037936298007314} | train loss {'Reaction outcome loss': 0.8125835484387923, 'Total loss': 0.8125835484387923}
2022-11-18 02:32:16,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:16,440 INFO:     Epoch: 23
2022-11-18 02:32:17,227 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8264208381826227, 'Total loss': 0.8264208381826227} | train loss {'Reaction outcome loss': 0.8097197151913935, 'Total loss': 0.8097197151913935}
2022-11-18 02:32:17,228 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:17,228 INFO:     Epoch: 24
2022-11-18 02:32:18,026 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.820330260829492, 'Total loss': 0.820330260829492} | train loss {'Reaction outcome loss': 0.8161313694350574, 'Total loss': 0.8161313694350574}
2022-11-18 02:32:18,026 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:18,026 INFO:     Epoch: 25
2022-11-18 02:32:18,805 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8079639348116788, 'Total loss': 0.8079639348116788} | train loss {'Reaction outcome loss': 0.8126022505516909, 'Total loss': 0.8126022505516909}
2022-11-18 02:32:18,806 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:18,806 INFO:     Epoch: 26
2022-11-18 02:32:19,586 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8043101470578801, 'Total loss': 0.8043101470578801} | train loss {'Reaction outcome loss': 0.8093440737651318, 'Total loss': 0.8093440737651318}
2022-11-18 02:32:19,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:19,586 INFO:     Epoch: 27
2022-11-18 02:32:20,389 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.809723438187079, 'Total loss': 0.809723438187079} | train loss {'Reaction outcome loss': 0.8106568307292704, 'Total loss': 0.8106568307292704}
2022-11-18 02:32:20,390 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:20,391 INFO:     Epoch: 28
2022-11-18 02:32:21,154 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7876693945039402, 'Total loss': 0.7876693945039402} | train loss {'Reaction outcome loss': 0.812959626986056, 'Total loss': 0.812959626986056}
2022-11-18 02:32:21,154 INFO:     Found new best model at epoch 28
2022-11-18 02:32:21,155 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:21,155 INFO:     Epoch: 29
2022-11-18 02:32:21,954 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7994381392543967, 'Total loss': 0.7994381392543967} | train loss {'Reaction outcome loss': 0.8058941131951858, 'Total loss': 0.8058941131951858}
2022-11-18 02:32:21,954 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:21,954 INFO:     Epoch: 30
2022-11-18 02:32:22,712 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8025738800113852, 'Total loss': 0.8025738800113852} | train loss {'Reaction outcome loss': 0.8081234401586105, 'Total loss': 0.8081234401586105}
2022-11-18 02:32:22,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:22,712 INFO:     Epoch: 31
2022-11-18 02:32:23,466 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7905893048102205, 'Total loss': 0.7905893048102205} | train loss {'Reaction outcome loss': 0.8070484532385457, 'Total loss': 0.8070484532385457}
2022-11-18 02:32:23,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:23,467 INFO:     Epoch: 32
2022-11-18 02:32:24,254 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8100745312192223, 'Total loss': 0.8100745312192223} | train loss {'Reaction outcome loss': 0.8105751413471844, 'Total loss': 0.8105751413471844}
2022-11-18 02:32:24,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:24,255 INFO:     Epoch: 33
2022-11-18 02:32:25,024 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.816743752495809, 'Total loss': 0.816743752495809} | train loss {'Reaction outcome loss': 0.811244469151205, 'Total loss': 0.811244469151205}
2022-11-18 02:32:25,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:25,024 INFO:     Epoch: 34
2022-11-18 02:32:25,807 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7963142110542818, 'Total loss': 0.7963142110542818} | train loss {'Reaction outcome loss': 0.8144352990753797, 'Total loss': 0.8144352990753797}
2022-11-18 02:32:25,807 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:25,808 INFO:     Epoch: 35
2022-11-18 02:32:26,598 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8379190523516048, 'Total loss': 0.8379190523516048} | train loss {'Reaction outcome loss': 0.8089463322746511, 'Total loss': 0.8089463322746511}
2022-11-18 02:32:26,599 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:26,599 INFO:     Epoch: 36
2022-11-18 02:32:27,372 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7964458777145906, 'Total loss': 0.7964458777145906} | train loss {'Reaction outcome loss': 0.8115067859085239, 'Total loss': 0.8115067859085239}
2022-11-18 02:32:27,372 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:27,372 INFO:     Epoch: 37
2022-11-18 02:32:28,157 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.8065551763231104, 'Total loss': 0.8065551763231104} | train loss {'Reaction outcome loss': 0.811171560141505, 'Total loss': 0.811171560141505}
2022-11-18 02:32:28,157 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:28,157 INFO:     Epoch: 38
2022-11-18 02:32:28,944 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8072314113378525, 'Total loss': 0.8072314113378525} | train loss {'Reaction outcome loss': 0.8107218722907864, 'Total loss': 0.8107218722907864}
2022-11-18 02:32:28,944 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:28,944 INFO:     Epoch: 39
2022-11-18 02:32:29,715 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7926763539964502, 'Total loss': 0.7926763539964502} | train loss {'Reaction outcome loss': 0.808918289019137, 'Total loss': 0.808918289019137}
2022-11-18 02:32:29,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:29,716 INFO:     Epoch: 40
2022-11-18 02:32:30,479 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7976757369258187, 'Total loss': 0.7976757369258187} | train loss {'Reaction outcome loss': 0.8090572199042962, 'Total loss': 0.8090572199042962}
2022-11-18 02:32:30,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:30,479 INFO:     Epoch: 41
2022-11-18 02:32:31,265 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8085200800137087, 'Total loss': 0.8085200800137087} | train loss {'Reaction outcome loss': 0.8098247512262695, 'Total loss': 0.8098247512262695}
2022-11-18 02:32:31,265 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:31,265 INFO:     Epoch: 42
2022-11-18 02:32:32,044 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7824201773513447, 'Total loss': 0.7824201773513447} | train loss {'Reaction outcome loss': 0.806867881332125, 'Total loss': 0.806867881332125}
2022-11-18 02:32:32,045 INFO:     Found new best model at epoch 42
2022-11-18 02:32:32,045 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:32,045 INFO:     Epoch: 43
2022-11-18 02:32:32,785 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8168967677788301, 'Total loss': 0.8168967677788301} | train loss {'Reaction outcome loss': 0.8095067341716922, 'Total loss': 0.8095067341716922}
2022-11-18 02:32:32,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:32,785 INFO:     Epoch: 44
2022-11-18 02:32:33,577 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.79475106976249, 'Total loss': 0.79475106976249} | train loss {'Reaction outcome loss': 0.8120319557433225, 'Total loss': 0.8120319557433225}
2022-11-18 02:32:33,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:33,577 INFO:     Epoch: 45
2022-11-18 02:32:34,354 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.803125105120919, 'Total loss': 0.803125105120919} | train loss {'Reaction outcome loss': 0.8083003746003521, 'Total loss': 0.8083003746003521}
2022-11-18 02:32:34,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:34,354 INFO:     Epoch: 46
2022-11-18 02:32:35,139 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7960884035988287, 'Total loss': 0.7960884035988287} | train loss {'Reaction outcome loss': 0.8067863995931587, 'Total loss': 0.8067863995931587}
2022-11-18 02:32:35,139 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:35,139 INFO:     Epoch: 47
2022-11-18 02:32:35,905 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8092047829519619, 'Total loss': 0.8092047829519619} | train loss {'Reaction outcome loss': 0.8080954454383071, 'Total loss': 0.8080954454383071}
2022-11-18 02:32:35,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:35,905 INFO:     Epoch: 48
2022-11-18 02:32:36,686 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8102437853813171, 'Total loss': 0.8102437853813171} | train loss {'Reaction outcome loss': 0.8093613099078742, 'Total loss': 0.8093613099078742}
2022-11-18 02:32:36,686 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:36,686 INFO:     Epoch: 49
2022-11-18 02:32:37,478 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8032276725227182, 'Total loss': 0.8032276725227182} | train loss {'Reaction outcome loss': 0.8119743855632081, 'Total loss': 0.8119743855632081}
2022-11-18 02:32:37,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:37,478 INFO:     Epoch: 50
2022-11-18 02:32:38,266 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7928325073285536, 'Total loss': 0.7928325073285536} | train loss {'Reaction outcome loss': 0.8095748271260943, 'Total loss': 0.8095748271260943}
2022-11-18 02:32:38,266 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:38,266 INFO:     Epoch: 51
2022-11-18 02:32:39,041 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7898523570461706, 'Total loss': 0.7898523570461706} | train loss {'Reaction outcome loss': 0.8116556240587819, 'Total loss': 0.8116556240587819}
2022-11-18 02:32:39,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:39,043 INFO:     Epoch: 52
2022-11-18 02:32:39,798 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7975060966881838, 'Total loss': 0.7975060966881838} | train loss {'Reaction outcome loss': 0.8105103307840775, 'Total loss': 0.8105103307840775}
2022-11-18 02:32:39,798 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:39,798 INFO:     Epoch: 53
2022-11-18 02:32:40,557 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8190418529239568, 'Total loss': 0.8190418529239568} | train loss {'Reaction outcome loss': 0.809752769251259, 'Total loss': 0.809752769251259}
2022-11-18 02:32:40,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:40,558 INFO:     Epoch: 54
2022-11-18 02:32:41,335 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7912940247492357, 'Total loss': 0.7912940247492357} | train loss {'Reaction outcome loss': 0.8128845346217253, 'Total loss': 0.8128845346217253}
2022-11-18 02:32:41,335 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:41,336 INFO:     Epoch: 55
2022-11-18 02:32:42,126 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.794139412316409, 'Total loss': 0.794139412316409} | train loss {'Reaction outcome loss': 0.8078317207949502, 'Total loss': 0.8078317207949502}
2022-11-18 02:32:42,126 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:42,126 INFO:     Epoch: 56
2022-11-18 02:32:42,909 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7828597465360706, 'Total loss': 0.7828597465360706} | train loss {'Reaction outcome loss': 0.8088592369945682, 'Total loss': 0.8088592369945682}
2022-11-18 02:32:42,909 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:42,909 INFO:     Epoch: 57
2022-11-18 02:32:43,689 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8242861066352237, 'Total loss': 0.8242861066352237} | train loss {'Reaction outcome loss': 0.8096280546820893, 'Total loss': 0.8096280546820893}
2022-11-18 02:32:43,689 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:43,689 INFO:     Epoch: 58
2022-11-18 02:32:44,491 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8141547184098851, 'Total loss': 0.8141547184098851} | train loss {'Reaction outcome loss': 0.8125439488157934, 'Total loss': 0.8125439488157934}
2022-11-18 02:32:44,491 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:44,491 INFO:     Epoch: 59
2022-11-18 02:32:45,244 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8104420703920451, 'Total loss': 0.8104420703920451} | train loss {'Reaction outcome loss': 0.8086579032090245, 'Total loss': 0.8086579032090245}
2022-11-18 02:32:45,244 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:45,245 INFO:     Epoch: 60
2022-11-18 02:32:46,060 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.820507787168026, 'Total loss': 0.820507787168026} | train loss {'Reaction outcome loss': 0.8117901660958114, 'Total loss': 0.8117901660958114}
2022-11-18 02:32:46,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:46,061 INFO:     Epoch: 61
2022-11-18 02:32:46,860 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8511973951350559, 'Total loss': 0.8511973951350559} | train loss {'Reaction outcome loss': 0.8105191356065322, 'Total loss': 0.8105191356065322}
2022-11-18 02:32:46,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:46,860 INFO:     Epoch: 62
2022-11-18 02:32:47,654 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7961290532892401, 'Total loss': 0.7961290532892401} | train loss {'Reaction outcome loss': 0.8111520857227091, 'Total loss': 0.8111520857227091}
2022-11-18 02:32:47,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:47,655 INFO:     Epoch: 63
2022-11-18 02:32:48,461 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7997747266834433, 'Total loss': 0.7997747266834433} | train loss {'Reaction outcome loss': 0.8101434596947261, 'Total loss': 0.8101434596947261}
2022-11-18 02:32:48,461 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:48,461 INFO:     Epoch: 64
2022-11-18 02:32:49,323 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8039167482744564, 'Total loss': 0.8039167482744564} | train loss {'Reaction outcome loss': 0.8125602025158551, 'Total loss': 0.8125602025158551}
2022-11-18 02:32:49,323 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:49,323 INFO:     Epoch: 65
2022-11-18 02:32:50,123 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7876186099919406, 'Total loss': 0.7876186099919406} | train loss {'Reaction outcome loss': 0.8173301146954907, 'Total loss': 0.8173301146954907}
2022-11-18 02:32:50,123 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:50,123 INFO:     Epoch: 66
2022-11-18 02:32:50,932 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.818706130439585, 'Total loss': 0.818706130439585} | train loss {'Reaction outcome loss': 0.8106401449563552, 'Total loss': 0.8106401449563552}
2022-11-18 02:32:50,933 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:50,934 INFO:     Epoch: 67
2022-11-18 02:32:51,714 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7812493443489075, 'Total loss': 0.7812493443489075} | train loss {'Reaction outcome loss': 0.8102455659788482, 'Total loss': 0.8102455659788482}
2022-11-18 02:32:51,714 INFO:     Found new best model at epoch 67
2022-11-18 02:32:51,715 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:51,715 INFO:     Epoch: 68
2022-11-18 02:32:52,482 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8074199442159046, 'Total loss': 0.8074199442159046} | train loss {'Reaction outcome loss': 0.8086580766707051, 'Total loss': 0.8086580766707051}
2022-11-18 02:32:52,483 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:52,483 INFO:     Epoch: 69
2022-11-18 02:32:53,306 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8366405083374544, 'Total loss': 0.8366405083374544} | train loss {'Reaction outcome loss': 0.8064634197828721, 'Total loss': 0.8064634197828721}
2022-11-18 02:32:53,306 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:53,306 INFO:     Epoch: 70
2022-11-18 02:32:54,114 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7905731478875334, 'Total loss': 0.7905731478875334} | train loss {'Reaction outcome loss': 0.8118971591093103, 'Total loss': 0.8118971591093103}
2022-11-18 02:32:54,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:54,114 INFO:     Epoch: 71
2022-11-18 02:32:54,931 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.784860409796238, 'Total loss': 0.784860409796238} | train loss {'Reaction outcome loss': 0.8075274066049225, 'Total loss': 0.8075274066049225}
2022-11-18 02:32:54,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:54,931 INFO:     Epoch: 72
2022-11-18 02:32:55,742 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8194669220935215, 'Total loss': 0.8194669220935215} | train loss {'Reaction outcome loss': 0.8076109656265804, 'Total loss': 0.8076109656265804}
2022-11-18 02:32:55,742 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:55,742 INFO:     Epoch: 73
2022-11-18 02:32:56,545 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8093607974323359, 'Total loss': 0.8093607974323359} | train loss {'Reaction outcome loss': 0.8113072985289048, 'Total loss': 0.8113072985289048}
2022-11-18 02:32:56,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:56,545 INFO:     Epoch: 74
2022-11-18 02:32:57,376 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8302715129472993, 'Total loss': 0.8302715129472993} | train loss {'Reaction outcome loss': 0.8104334024750457, 'Total loss': 0.8104334024750457}
2022-11-18 02:32:57,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:57,377 INFO:     Epoch: 75
2022-11-18 02:32:58,194 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8106477057391946, 'Total loss': 0.8106477057391946} | train loss {'Reaction outcome loss': 0.812010693671752, 'Total loss': 0.812010693671752}
2022-11-18 02:32:58,194 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:58,194 INFO:     Epoch: 76
2022-11-18 02:32:58,979 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.8302241076122631, 'Total loss': 0.8302241076122631} | train loss {'Reaction outcome loss': 0.808623594045639, 'Total loss': 0.808623594045639}
2022-11-18 02:32:58,979 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:58,979 INFO:     Epoch: 77
2022-11-18 02:32:59,767 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7922408702698621, 'Total loss': 0.7922408702698621} | train loss {'Reaction outcome loss': 0.8144625385196842, 'Total loss': 0.8144625385196842}
2022-11-18 02:32:59,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:32:59,767 INFO:     Epoch: 78
2022-11-18 02:33:00,554 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8049483035098423, 'Total loss': 0.8049483035098423} | train loss {'Reaction outcome loss': 0.80526746377653, 'Total loss': 0.80526746377653}
2022-11-18 02:33:00,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:00,554 INFO:     Epoch: 79
2022-11-18 02:33:01,377 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8364358496936884, 'Total loss': 0.8364358496936884} | train loss {'Reaction outcome loss': 0.8121736531354943, 'Total loss': 0.8121736531354943}
2022-11-18 02:33:01,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:01,377 INFO:     Epoch: 80
2022-11-18 02:33:02,210 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8198325837200339, 'Total loss': 0.8198325837200339} | train loss {'Reaction outcome loss': 0.81542213291538, 'Total loss': 0.81542213291538}
2022-11-18 02:33:02,210 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:02,210 INFO:     Epoch: 81
2022-11-18 02:33:03,037 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7992491844025525, 'Total loss': 0.7992491844025525} | train loss {'Reaction outcome loss': 0.8123054773223644, 'Total loss': 0.8123054773223644}
2022-11-18 02:33:03,037 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:03,037 INFO:     Epoch: 82
2022-11-18 02:33:03,813 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7990723848342896, 'Total loss': 0.7990723848342896} | train loss {'Reaction outcome loss': 0.8108406487776308, 'Total loss': 0.8108406487776308}
2022-11-18 02:33:03,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:03,814 INFO:     Epoch: 83
2022-11-18 02:33:04,624 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.804402459751476, 'Total loss': 0.804402459751476} | train loss {'Reaction outcome loss': 0.8133160069280742, 'Total loss': 0.8133160069280742}
2022-11-18 02:33:04,624 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:04,624 INFO:     Epoch: 84
2022-11-18 02:33:05,439 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7980745771730487, 'Total loss': 0.7980745771730487} | train loss {'Reaction outcome loss': 0.811023968823102, 'Total loss': 0.811023968823102}
2022-11-18 02:33:05,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:05,439 INFO:     Epoch: 85
2022-11-18 02:33:06,279 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.822869979522445, 'Total loss': 0.822869979522445} | train loss {'Reaction outcome loss': 0.8056206548700527, 'Total loss': 0.8056206548700527}
2022-11-18 02:33:06,279 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:06,279 INFO:     Epoch: 86
2022-11-18 02:33:07,122 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7963113209063356, 'Total loss': 0.7963113209063356} | train loss {'Reaction outcome loss': 0.812346251765076, 'Total loss': 0.812346251765076}
2022-11-18 02:33:07,122 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:07,123 INFO:     Epoch: 87
2022-11-18 02:33:07,940 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8174371617761526, 'Total loss': 0.8174371617761526} | train loss {'Reaction outcome loss': 0.8083225384050486, 'Total loss': 0.8083225384050486}
2022-11-18 02:33:07,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:07,941 INFO:     Epoch: 88
2022-11-18 02:33:08,760 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7998293970118869, 'Total loss': 0.7998293970118869} | train loss {'Reaction outcome loss': 0.8108555936083501, 'Total loss': 0.8108555936083501}
2022-11-18 02:33:08,760 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:08,761 INFO:     Epoch: 89
2022-11-18 02:33:09,557 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8122292757034302, 'Total loss': 0.8122292757034302} | train loss {'Reaction outcome loss': 0.8077585830980417, 'Total loss': 0.8077585830980417}
2022-11-18 02:33:09,558 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:09,558 INFO:     Epoch: 90
2022-11-18 02:33:10,372 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7869647748091004, 'Total loss': 0.7869647748091004} | train loss {'Reaction outcome loss': 0.8099097777386101, 'Total loss': 0.8099097777386101}
2022-11-18 02:33:10,373 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:10,373 INFO:     Epoch: 91
2022-11-18 02:33:11,141 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7996481311592188, 'Total loss': 0.7996481311592188} | train loss {'Reaction outcome loss': 0.8082045489427995, 'Total loss': 0.8082045489427995}
2022-11-18 02:33:11,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:11,141 INFO:     Epoch: 92
2022-11-18 02:33:11,920 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8393481875007803, 'Total loss': 0.8393481875007803} | train loss {'Reaction outcome loss': 0.8147409957282398, 'Total loss': 0.8147409957282398}
2022-11-18 02:33:11,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:11,920 INFO:     Epoch: 93
2022-11-18 02:33:12,712 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8037441576069052, 'Total loss': 0.8037441576069052} | train loss {'Reaction outcome loss': 0.8100082930253476, 'Total loss': 0.8100082930253476}
2022-11-18 02:33:12,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:12,712 INFO:     Epoch: 94
2022-11-18 02:33:13,544 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8052623549645598, 'Total loss': 0.8052623549645598} | train loss {'Reaction outcome loss': 0.8063900389233414, 'Total loss': 0.8063900389233414}
2022-11-18 02:33:13,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:13,544 INFO:     Epoch: 95
2022-11-18 02:33:14,349 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7917234867133878, 'Total loss': 0.7917234867133878} | train loss {'Reaction outcome loss': 0.8041542913232531, 'Total loss': 0.8041542913232531}
2022-11-18 02:33:14,350 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:14,350 INFO:     Epoch: 96
2022-11-18 02:33:15,147 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8177642090754076, 'Total loss': 0.8177642090754076} | train loss {'Reaction outcome loss': 0.812885369816605, 'Total loss': 0.812885369816605}
2022-11-18 02:33:15,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:15,147 INFO:     Epoch: 97
2022-11-18 02:33:15,926 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8107376396656036, 'Total loss': 0.8107376396656036} | train loss {'Reaction outcome loss': 0.8086989530495234, 'Total loss': 0.8086989530495234}
2022-11-18 02:33:15,926 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:15,926 INFO:     Epoch: 98
2022-11-18 02:33:16,725 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8023555021394383, 'Total loss': 0.8023555021394383} | train loss {'Reaction outcome loss': 0.8132567839963095, 'Total loss': 0.8132567839963095}
2022-11-18 02:33:16,725 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:16,725 INFO:     Epoch: 99
2022-11-18 02:33:17,535 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.8141206181184812, 'Total loss': 0.8141206181184812} | train loss {'Reaction outcome loss': 0.8070248420141182, 'Total loss': 0.8070248420141182}
2022-11-18 02:33:17,535 INFO:     Best model found after epoch 68 of 100.
2022-11-18 02:33:17,536 INFO:   Done with stage: TRAINING
2022-11-18 02:33:17,536 INFO:   Starting stage: EVALUATION
2022-11-18 02:33:17,669 INFO:   Done with stage: EVALUATION
2022-11-18 02:33:17,669 INFO:   Leaving out SEQ value Fold_4
2022-11-18 02:33:17,682 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 02:33:17,682 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:33:18,356 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:33:18,356 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:33:18,430 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:33:18,430 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:33:18,430 INFO:     No hyperparam tuning for this model
2022-11-18 02:33:18,430 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:33:18,430 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:33:18,431 INFO:     None feature selector for col prot
2022-11-18 02:33:18,431 INFO:     None feature selector for col prot
2022-11-18 02:33:18,431 INFO:     None feature selector for col prot
2022-11-18 02:33:18,432 INFO:     None feature selector for col chem
2022-11-18 02:33:18,432 INFO:     None feature selector for col chem
2022-11-18 02:33:18,432 INFO:     None feature selector for col chem
2022-11-18 02:33:18,432 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:33:18,432 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:33:18,433 INFO:     Number of params in model 168571
2022-11-18 02:33:18,437 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:33:18,437 INFO:   Starting stage: TRAINING
2022-11-18 02:33:18,494 INFO:     Val loss before train {'Reaction outcome loss': 1.0073121718385003, 'Total loss': 1.0073121718385003}
2022-11-18 02:33:18,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:18,495 INFO:     Epoch: 0
2022-11-18 02:33:19,286 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8533454056490551, 'Total loss': 0.8533454056490551} | train loss {'Reaction outcome loss': 0.8840249160282042, 'Total loss': 0.8840249160282042}
2022-11-18 02:33:19,286 INFO:     Found new best model at epoch 0
2022-11-18 02:33:19,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:19,286 INFO:     Epoch: 1
2022-11-18 02:33:20,088 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7922426888888533, 'Total loss': 0.7922426888888533} | train loss {'Reaction outcome loss': 0.8431326508642691, 'Total loss': 0.8431326508642691}
2022-11-18 02:33:20,088 INFO:     Found new best model at epoch 1
2022-11-18 02:33:20,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:20,089 INFO:     Epoch: 2
2022-11-18 02:33:20,859 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.799462313001806, 'Total loss': 0.799462313001806} | train loss {'Reaction outcome loss': 0.8401557482205905, 'Total loss': 0.8401557482205905}
2022-11-18 02:33:20,860 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:20,860 INFO:     Epoch: 3
2022-11-18 02:33:21,696 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8120006763122298, 'Total loss': 0.8120006763122298} | train loss {'Reaction outcome loss': 0.8366812751119436, 'Total loss': 0.8366812751119436}
2022-11-18 02:33:21,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:21,696 INFO:     Epoch: 4
2022-11-18 02:33:22,516 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.7969484173438766, 'Total loss': 0.7969484173438766} | train loss {'Reaction outcome loss': 0.8289152541261936, 'Total loss': 0.8289152541261936}
2022-11-18 02:33:22,518 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:22,518 INFO:     Epoch: 5
2022-11-18 02:33:23,351 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7645836926319383, 'Total loss': 0.7645836926319383} | train loss {'Reaction outcome loss': 0.8247241112384719, 'Total loss': 0.8247241112384719}
2022-11-18 02:33:23,352 INFO:     Found new best model at epoch 5
2022-11-18 02:33:23,352 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:23,352 INFO:     Epoch: 6
2022-11-18 02:33:24,154 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7652614827860486, 'Total loss': 0.7652614827860486} | train loss {'Reaction outcome loss': 0.8166496925025817, 'Total loss': 0.8166496925025817}
2022-11-18 02:33:24,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:24,154 INFO:     Epoch: 7
2022-11-18 02:33:24,952 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7628794068639929, 'Total loss': 0.7628794068639929} | train loss {'Reaction outcome loss': 0.819248050692593, 'Total loss': 0.819248050692593}
2022-11-18 02:33:24,952 INFO:     Found new best model at epoch 7
2022-11-18 02:33:24,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:24,953 INFO:     Epoch: 8
2022-11-18 02:33:25,758 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7823447639291937, 'Total loss': 0.7823447639291937} | train loss {'Reaction outcome loss': 0.8208245719492677, 'Total loss': 0.8208245719492677}
2022-11-18 02:33:25,758 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:25,758 INFO:     Epoch: 9
2022-11-18 02:33:26,588 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.768107143315402, 'Total loss': 0.768107143315402} | train loss {'Reaction outcome loss': 0.8245757247513605, 'Total loss': 0.8245757247513605}
2022-11-18 02:33:26,588 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:26,588 INFO:     Epoch: 10
2022-11-18 02:33:27,377 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.809485603462566, 'Total loss': 0.809485603462566} | train loss {'Reaction outcome loss': 0.8152291242048325, 'Total loss': 0.8152291242048325}
2022-11-18 02:33:27,377 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:27,377 INFO:     Epoch: 11
2022-11-18 02:33:28,167 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7505039799619805, 'Total loss': 0.7505039799619805} | train loss {'Reaction outcome loss': 0.8223873002809069, 'Total loss': 0.8223873002809069}
2022-11-18 02:33:28,167 INFO:     Found new best model at epoch 11
2022-11-18 02:33:28,168 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:28,168 INFO:     Epoch: 12
2022-11-18 02:33:28,972 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7738357538526709, 'Total loss': 0.7738357538526709} | train loss {'Reaction outcome loss': 0.8086076493899108, 'Total loss': 0.8086076493899108}
2022-11-18 02:33:28,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:28,973 INFO:     Epoch: 13
2022-11-18 02:33:29,761 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7823035513812845, 'Total loss': 0.7823035513812845} | train loss {'Reaction outcome loss': 0.814727173884388, 'Total loss': 0.814727173884388}
2022-11-18 02:33:29,761 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:29,761 INFO:     Epoch: 14
2022-11-18 02:33:30,569 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7758612334728241, 'Total loss': 0.7758612334728241} | train loss {'Reaction outcome loss': 0.816074413145602, 'Total loss': 0.816074413145602}
2022-11-18 02:33:30,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:30,570 INFO:     Epoch: 15
2022-11-18 02:33:31,358 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7630433331836354, 'Total loss': 0.7630433331836354} | train loss {'Reaction outcome loss': 0.8106339760426327, 'Total loss': 0.8106339760426327}
2022-11-18 02:33:31,358 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:31,358 INFO:     Epoch: 16
2022-11-18 02:33:32,157 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7792732708833434, 'Total loss': 0.7792732708833434} | train loss {'Reaction outcome loss': 0.8127898074656363, 'Total loss': 0.8127898074656363}
2022-11-18 02:33:32,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:32,158 INFO:     Epoch: 17
2022-11-18 02:33:32,943 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7609938857230273, 'Total loss': 0.7609938857230273} | train loss {'Reaction outcome loss': 0.8104080229786484, 'Total loss': 0.8104080229786484}
2022-11-18 02:33:32,943 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:32,943 INFO:     Epoch: 18
2022-11-18 02:33:33,713 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7764180952852423, 'Total loss': 0.7764180952852423} | train loss {'Reaction outcome loss': 0.8182481002469777, 'Total loss': 0.8182481002469777}
2022-11-18 02:33:33,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:33,713 INFO:     Epoch: 19
2022-11-18 02:33:34,460 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7671120837330818, 'Total loss': 0.7671120837330818} | train loss {'Reaction outcome loss': 0.8122188588868269, 'Total loss': 0.8122188588868269}
2022-11-18 02:33:34,460 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:34,460 INFO:     Epoch: 20
2022-11-18 02:33:35,241 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7722337896173651, 'Total loss': 0.7722337896173651} | train loss {'Reaction outcome loss': 0.8165826305807361, 'Total loss': 0.8165826305807361}
2022-11-18 02:33:35,241 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:35,242 INFO:     Epoch: 21
2022-11-18 02:33:36,018 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7890863675962795, 'Total loss': 0.7890863675962795} | train loss {'Reaction outcome loss': 0.8092153896445687, 'Total loss': 0.8092153896445687}
2022-11-18 02:33:36,018 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:36,018 INFO:     Epoch: 22
2022-11-18 02:33:36,850 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.7562891630963846, 'Total loss': 0.7562891630963846} | train loss {'Reaction outcome loss': 0.814937707383623, 'Total loss': 0.814937707383623}
2022-11-18 02:33:36,850 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:36,851 INFO:     Epoch: 23
2022-11-18 02:33:37,640 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7645816775885496, 'Total loss': 0.7645816775885496} | train loss {'Reaction outcome loss': 0.8091305780265978, 'Total loss': 0.8091305780265978}
2022-11-18 02:33:37,641 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:37,641 INFO:     Epoch: 24
2022-11-18 02:33:38,466 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7740763805129312, 'Total loss': 0.7740763805129312} | train loss {'Reaction outcome loss': 0.8098392179801397, 'Total loss': 0.8098392179801397}
2022-11-18 02:33:38,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:38,466 INFO:     Epoch: 25
2022-11-18 02:33:39,286 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7623420323837887, 'Total loss': 0.7623420323837887} | train loss {'Reaction outcome loss': 0.8063861529233485, 'Total loss': 0.8063861529233485}
2022-11-18 02:33:39,286 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:39,286 INFO:     Epoch: 26
2022-11-18 02:33:40,103 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7975851378657601, 'Total loss': 0.7975851378657601} | train loss {'Reaction outcome loss': 0.8160700443302572, 'Total loss': 0.8160700443302572}
2022-11-18 02:33:40,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:40,104 INFO:     Epoch: 27
2022-11-18 02:33:40,930 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7820264453237707, 'Total loss': 0.7820264453237707} | train loss {'Reaction outcome loss': 0.8104453323341092, 'Total loss': 0.8104453323341092}
2022-11-18 02:33:40,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:40,931 INFO:     Epoch: 28
2022-11-18 02:33:41,753 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7708783921870318, 'Total loss': 0.7708783921870318} | train loss {'Reaction outcome loss': 0.8162550780213313, 'Total loss': 0.8162550780213313}
2022-11-18 02:33:41,754 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:41,754 INFO:     Epoch: 29
2022-11-18 02:33:42,554 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7688740308989178, 'Total loss': 0.7688740308989178} | train loss {'Reaction outcome loss': 0.8243337713996408, 'Total loss': 0.8243337713996408}
2022-11-18 02:33:42,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:42,554 INFO:     Epoch: 30
2022-11-18 02:33:43,428 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7692100703716278, 'Total loss': 0.7692100703716278} | train loss {'Reaction outcome loss': 0.817012684909921, 'Total loss': 0.817012684909921}
2022-11-18 02:33:43,428 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:43,428 INFO:     Epoch: 31
2022-11-18 02:33:44,227 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8011766238646074, 'Total loss': 0.8011766238646074} | train loss {'Reaction outcome loss': 0.8123971935708513, 'Total loss': 0.8123971935708513}
2022-11-18 02:33:44,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:44,227 INFO:     Epoch: 32
2022-11-18 02:33:45,042 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.766769222237847, 'Total loss': 0.766769222237847} | train loss {'Reaction outcome loss': 0.8181387586632238, 'Total loss': 0.8181387586632238}
2022-11-18 02:33:45,042 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:45,042 INFO:     Epoch: 33
2022-11-18 02:33:45,853 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7810821878639135, 'Total loss': 0.7810821878639135} | train loss {'Reaction outcome loss': 0.8077327300783111, 'Total loss': 0.8077327300783111}
2022-11-18 02:33:45,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:45,854 INFO:     Epoch: 34
2022-11-18 02:33:46,633 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7667014768177812, 'Total loss': 0.7667014768177812} | train loss {'Reaction outcome loss': 0.8068855453719977, 'Total loss': 0.8068855453719977}
2022-11-18 02:33:46,633 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:46,633 INFO:     Epoch: 35
2022-11-18 02:33:47,438 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7698748267509721, 'Total loss': 0.7698748267509721} | train loss {'Reaction outcome loss': 0.8121137153281857, 'Total loss': 0.8121137153281857}
2022-11-18 02:33:47,438 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:47,439 INFO:     Epoch: 36
2022-11-18 02:33:48,243 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.763986160132018, 'Total loss': 0.763986160132018} | train loss {'Reaction outcome loss': 0.8118846516015559, 'Total loss': 0.8118846516015559}
2022-11-18 02:33:48,243 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:48,243 INFO:     Epoch: 37
2022-11-18 02:33:49,050 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7605554928833788, 'Total loss': 0.7605554928833788} | train loss {'Reaction outcome loss': 0.8121989849607955, 'Total loss': 0.8121989849607955}
2022-11-18 02:33:49,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:49,051 INFO:     Epoch: 38
2022-11-18 02:33:49,908 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7924929430538957, 'Total loss': 0.7924929430538957} | train loss {'Reaction outcome loss': 0.8082004301702446, 'Total loss': 0.8082004301702446}
2022-11-18 02:33:49,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:49,908 INFO:     Epoch: 39
2022-11-18 02:33:50,741 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7674830068241466, 'Total loss': 0.7674830068241466} | train loss {'Reaction outcome loss': 0.811232559232094, 'Total loss': 0.811232559232094}
2022-11-18 02:33:50,741 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:50,742 INFO:     Epoch: 40
2022-11-18 02:33:51,561 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.76027726856145, 'Total loss': 0.76027726856145} | train loss {'Reaction outcome loss': 0.8341952407890968, 'Total loss': 0.8341952407890968}
2022-11-18 02:33:51,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:51,561 INFO:     Epoch: 41
2022-11-18 02:33:52,385 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7797920378771696, 'Total loss': 0.7797920378771696} | train loss {'Reaction outcome loss': 0.8212787965048662, 'Total loss': 0.8212787965048662}
2022-11-18 02:33:52,385 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:52,385 INFO:     Epoch: 42
2022-11-18 02:33:53,161 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.775352268056436, 'Total loss': 0.775352268056436} | train loss {'Reaction outcome loss': 0.8142109677376534, 'Total loss': 0.8142109677376534}
2022-11-18 02:33:53,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:53,163 INFO:     Epoch: 43
2022-11-18 02:33:53,985 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.748147727413611, 'Total loss': 0.748147727413611} | train loss {'Reaction outcome loss': 0.806583161658121, 'Total loss': 0.806583161658121}
2022-11-18 02:33:53,985 INFO:     Found new best model at epoch 43
2022-11-18 02:33:53,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:53,986 INFO:     Epoch: 44
2022-11-18 02:33:54,780 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7596535161137581, 'Total loss': 0.7596535161137581} | train loss {'Reaction outcome loss': 0.810571328408805, 'Total loss': 0.810571328408805}
2022-11-18 02:33:54,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:54,780 INFO:     Epoch: 45
2022-11-18 02:33:55,586 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7540905428203669, 'Total loss': 0.7540905428203669} | train loss {'Reaction outcome loss': 0.8042007171009716, 'Total loss': 0.8042007171009716}
2022-11-18 02:33:55,586 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:55,586 INFO:     Epoch: 46
2022-11-18 02:33:56,365 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.796095921234651, 'Total loss': 0.796095921234651} | train loss {'Reaction outcome loss': 0.815990217301527, 'Total loss': 0.815990217301527}
2022-11-18 02:33:56,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:56,365 INFO:     Epoch: 47
2022-11-18 02:33:57,137 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7725288359956308, 'Total loss': 0.7725288359956308} | train loss {'Reaction outcome loss': 0.8129253244170775, 'Total loss': 0.8129253244170775}
2022-11-18 02:33:57,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:57,137 INFO:     Epoch: 48
2022-11-18 02:33:57,952 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7574905875054273, 'Total loss': 0.7574905875054273} | train loss {'Reaction outcome loss': 0.8110908473792829, 'Total loss': 0.8110908473792829}
2022-11-18 02:33:57,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:57,953 INFO:     Epoch: 49
2022-11-18 02:33:58,777 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7588991570201787, 'Total loss': 0.7588991570201787} | train loss {'Reaction outcome loss': 0.8080028256454207, 'Total loss': 0.8080028256454207}
2022-11-18 02:33:58,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:58,777 INFO:     Epoch: 50
2022-11-18 02:33:59,569 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7602674134752967, 'Total loss': 0.7602674134752967} | train loss {'Reaction outcome loss': 0.8078733815355339, 'Total loss': 0.8078733815355339}
2022-11-18 02:33:59,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:33:59,570 INFO:     Epoch: 51
2022-11-18 02:34:00,351 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7756990106268362, 'Total loss': 0.7756990106268362} | train loss {'Reaction outcome loss': 0.8079547860512608, 'Total loss': 0.8079547860512608}
2022-11-18 02:34:00,351 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:00,351 INFO:     Epoch: 52
2022-11-18 02:34:01,133 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7624232254245065, 'Total loss': 0.7624232254245065} | train loss {'Reaction outcome loss': 0.8076069644588207, 'Total loss': 0.8076069644588207}
2022-11-18 02:34:01,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:01,133 INFO:     Epoch: 53
2022-11-18 02:34:01,956 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7630838338624347, 'Total loss': 0.7630838338624347} | train loss {'Reaction outcome loss': 0.8136144478311423, 'Total loss': 0.8136144478311423}
2022-11-18 02:34:01,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:01,956 INFO:     Epoch: 54
2022-11-18 02:34:02,730 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7866253717379137, 'Total loss': 0.7866253717379137} | train loss {'Reaction outcome loss': 0.8115235234079091, 'Total loss': 0.8115235234079091}
2022-11-18 02:34:02,730 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:02,730 INFO:     Epoch: 55
2022-11-18 02:34:03,559 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7567585083571348, 'Total loss': 0.7567585083571348} | train loss {'Reaction outcome loss': 0.8161172619474079, 'Total loss': 0.8161172619474079}
2022-11-18 02:34:03,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:03,559 INFO:     Epoch: 56
2022-11-18 02:34:04,381 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7729376405477524, 'Total loss': 0.7729376405477524} | train loss {'Reaction outcome loss': 0.8090316420383299, 'Total loss': 0.8090316420383299}
2022-11-18 02:34:04,381 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:04,381 INFO:     Epoch: 57
2022-11-18 02:34:05,185 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.776616245508194, 'Total loss': 0.776616245508194} | train loss {'Reaction outcome loss': 0.8186551164156994, 'Total loss': 0.8186551164156994}
2022-11-18 02:34:05,186 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:05,186 INFO:     Epoch: 58
2022-11-18 02:34:05,984 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7482190315019001, 'Total loss': 0.7482190315019001} | train loss {'Reaction outcome loss': 0.8248993736288326, 'Total loss': 0.8248993736288326}
2022-11-18 02:34:05,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:05,984 INFO:     Epoch: 59
2022-11-18 02:34:06,808 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7748338715596632, 'Total loss': 0.7748338715596632} | train loss {'Reaction outcome loss': 0.8193229045945141, 'Total loss': 0.8193229045945141}
2022-11-18 02:34:06,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:06,808 INFO:     Epoch: 60
2022-11-18 02:34:07,590 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7728430005637082, 'Total loss': 0.7728430005637082} | train loss {'Reaction outcome loss': 0.8110504015254588, 'Total loss': 0.8110504015254588}
2022-11-18 02:34:07,590 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:07,591 INFO:     Epoch: 61
2022-11-18 02:34:08,398 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7608736333521929, 'Total loss': 0.7608736333521929} | train loss {'Reaction outcome loss': 0.8156521856060878, 'Total loss': 0.8156521856060878}
2022-11-18 02:34:08,398 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:08,398 INFO:     Epoch: 62
2022-11-18 02:34:09,237 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7554059780456803, 'Total loss': 0.7554059780456803} | train loss {'Reaction outcome loss': 0.8136673650519568, 'Total loss': 0.8136673650519568}
2022-11-18 02:34:09,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:09,237 INFO:     Epoch: 63
2022-11-18 02:34:10,050 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7522421323440291, 'Total loss': 0.7522421323440291} | train loss {'Reaction outcome loss': 0.8134143126879626, 'Total loss': 0.8134143126879626}
2022-11-18 02:34:10,050 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:10,050 INFO:     Epoch: 64
2022-11-18 02:34:10,875 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7861659404906359, 'Total loss': 0.7861659404906359} | train loss {'Reaction outcome loss': 0.8167131721732105, 'Total loss': 0.8167131721732105}
2022-11-18 02:34:10,875 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:10,875 INFO:     Epoch: 65
2022-11-18 02:34:11,719 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7609391822056337, 'Total loss': 0.7609391822056337} | train loss {'Reaction outcome loss': 0.8108636152889082, 'Total loss': 0.8108636152889082}
2022-11-18 02:34:11,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:11,720 INFO:     Epoch: 66
2022-11-18 02:34:12,538 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7602652169086717, 'Total loss': 0.7602652169086717} | train loss {'Reaction outcome loss': 0.814529459848095, 'Total loss': 0.814529459848095}
2022-11-18 02:34:12,538 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:12,539 INFO:     Epoch: 67
2022-11-18 02:34:13,321 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7706736123019998, 'Total loss': 0.7706736123019998} | train loss {'Reaction outcome loss': 0.8074833833978243, 'Total loss': 0.8074833833978243}
2022-11-18 02:34:13,321 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:13,321 INFO:     Epoch: 68
2022-11-18 02:34:14,097 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7843377983028238, 'Total loss': 0.7843377983028238} | train loss {'Reaction outcome loss': 0.8168253395480183, 'Total loss': 0.8168253395480183}
2022-11-18 02:34:14,097 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:14,097 INFO:     Epoch: 69
2022-11-18 02:34:14,863 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7572408420118418, 'Total loss': 0.7572408420118418} | train loss {'Reaction outcome loss': 0.8125624088381949, 'Total loss': 0.8125624088381949}
2022-11-18 02:34:14,863 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:14,863 INFO:     Epoch: 70
2022-11-18 02:34:15,681 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7618742314251986, 'Total loss': 0.7618742314251986} | train loss {'Reaction outcome loss': 0.8026171576397622, 'Total loss': 0.8026171576397622}
2022-11-18 02:34:15,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:15,681 INFO:     Epoch: 71
2022-11-18 02:34:16,477 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7564177587628365, 'Total loss': 0.7564177587628365} | train loss {'Reaction outcome loss': 0.8176597590871185, 'Total loss': 0.8176597590871185}
2022-11-18 02:34:16,477 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:16,477 INFO:     Epoch: 72
2022-11-18 02:34:17,315 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7739785083315589, 'Total loss': 0.7739785083315589} | train loss {'Reaction outcome loss': 0.8113439655014378, 'Total loss': 0.8113439655014378}
2022-11-18 02:34:17,315 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:17,315 INFO:     Epoch: 73
2022-11-18 02:34:18,143 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7927649800073017, 'Total loss': 0.7927649800073017} | train loss {'Reaction outcome loss': 0.8133912326443774, 'Total loss': 0.8133912326443774}
2022-11-18 02:34:18,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:18,143 INFO:     Epoch: 74
2022-11-18 02:34:18,915 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7768913331356916, 'Total loss': 0.7768913331356916} | train loss {'Reaction outcome loss': 0.8019422396926986, 'Total loss': 0.8019422396926986}
2022-11-18 02:34:18,915 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:18,915 INFO:     Epoch: 75
2022-11-18 02:34:19,677 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.777118962935426, 'Total loss': 0.777118962935426} | train loss {'Reaction outcome loss': 0.8037877420513977, 'Total loss': 0.8037877420513977}
2022-11-18 02:34:19,677 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:19,677 INFO:     Epoch: 76
2022-11-18 02:34:20,465 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.766728060489351, 'Total loss': 0.766728060489351} | train loss {'Reaction outcome loss': 0.8214742356707693, 'Total loss': 0.8214742356707693}
2022-11-18 02:34:20,466 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:20,466 INFO:     Epoch: 77
2022-11-18 02:34:21,254 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7763674055988138, 'Total loss': 0.7763674055988138} | train loss {'Reaction outcome loss': 0.8194697317082872, 'Total loss': 0.8194697317082872}
2022-11-18 02:34:21,254 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:21,254 INFO:     Epoch: 78
2022-11-18 02:34:22,023 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.758983009240844, 'Total loss': 0.758983009240844} | train loss {'Reaction outcome loss': 0.8182119192623416, 'Total loss': 0.8182119192623416}
2022-11-18 02:34:22,024 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:22,024 INFO:     Epoch: 79
2022-11-18 02:34:22,794 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7533304582942616, 'Total loss': 0.7533304582942616} | train loss {'Reaction outcome loss': 0.8051152970144141, 'Total loss': 0.8051152970144141}
2022-11-18 02:34:22,794 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:22,794 INFO:     Epoch: 80
2022-11-18 02:34:23,579 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7765060730955817, 'Total loss': 0.7765060730955817} | train loss {'Reaction outcome loss': 0.8066153847254239, 'Total loss': 0.8066153847254239}
2022-11-18 02:34:23,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:23,580 INFO:     Epoch: 81
2022-11-18 02:34:24,354 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.769133747978644, 'Total loss': 0.769133747978644} | train loss {'Reaction outcome loss': 0.8114824476029708, 'Total loss': 0.8114824476029708}
2022-11-18 02:34:24,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:24,354 INFO:     Epoch: 82
2022-11-18 02:34:25,160 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7637251039797609, 'Total loss': 0.7637251039797609} | train loss {'Reaction outcome loss': 0.8106482883213986, 'Total loss': 0.8106482883213986}
2022-11-18 02:34:25,162 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:25,162 INFO:     Epoch: 83
2022-11-18 02:34:25,932 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.763900681652806, 'Total loss': 0.763900681652806} | train loss {'Reaction outcome loss': 0.8090879049619683, 'Total loss': 0.8090879049619683}
2022-11-18 02:34:25,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:25,932 INFO:     Epoch: 84
2022-11-18 02:34:26,721 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7528875266963785, 'Total loss': 0.7528875266963785} | train loss {'Reaction outcome loss': 0.809278843796205, 'Total loss': 0.809278843796205}
2022-11-18 02:34:26,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:26,721 INFO:     Epoch: 85
2022-11-18 02:34:27,494 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.742569396441633, 'Total loss': 0.742569396441633} | train loss {'Reaction outcome loss': 0.8096854008643734, 'Total loss': 0.8096854008643734}
2022-11-18 02:34:27,494 INFO:     Found new best model at epoch 85
2022-11-18 02:34:27,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:27,495 INFO:     Epoch: 86
2022-11-18 02:34:28,281 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7950057529590346, 'Total loss': 0.7950057529590346} | train loss {'Reaction outcome loss': 0.8125668165654789, 'Total loss': 0.8125668165654789}
2022-11-18 02:34:28,281 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:28,281 INFO:     Epoch: 87
2022-11-18 02:34:29,053 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7705906866626306, 'Total loss': 0.7705906866626306} | train loss {'Reaction outcome loss': 0.8152642474785025, 'Total loss': 0.8152642474785025}
2022-11-18 02:34:29,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:29,053 INFO:     Epoch: 88
2022-11-18 02:34:29,846 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7799389247189868, 'Total loss': 0.7799389247189868} | train loss {'Reaction outcome loss': 0.8051055506897359, 'Total loss': 0.8051055506897359}
2022-11-18 02:34:29,846 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:29,846 INFO:     Epoch: 89
2022-11-18 02:34:30,637 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7546282546086744, 'Total loss': 0.7546282546086744} | train loss {'Reaction outcome loss': 0.8069270762656382, 'Total loss': 0.8069270762656382}
2022-11-18 02:34:30,637 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:30,638 INFO:     Epoch: 90
2022-11-18 02:34:31,440 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7561170255595987, 'Total loss': 0.7561170255595987} | train loss {'Reaction outcome loss': 0.807410133753711, 'Total loss': 0.807410133753711}
2022-11-18 02:34:31,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:31,442 INFO:     Epoch: 91
2022-11-18 02:34:32,214 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7702225636352192, 'Total loss': 0.7702225636352192} | train loss {'Reaction outcome loss': 0.8165191004150792, 'Total loss': 0.8165191004150792}
2022-11-18 02:34:32,214 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:32,214 INFO:     Epoch: 92
2022-11-18 02:34:32,991 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7815734893083572, 'Total loss': 0.7815734893083572} | train loss {'Reaction outcome loss': 0.8129536803917363, 'Total loss': 0.8129536803917363}
2022-11-18 02:34:32,992 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:32,992 INFO:     Epoch: 93
2022-11-18 02:34:33,784 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7839977924119342, 'Total loss': 0.7839977924119342} | train loss {'Reaction outcome loss': 0.811231967167333, 'Total loss': 0.811231967167333}
2022-11-18 02:34:33,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:33,784 INFO:     Epoch: 94
2022-11-18 02:34:34,576 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7700371884486892, 'Total loss': 0.7700371884486892} | train loss {'Reaction outcome loss': 0.8064099499118714, 'Total loss': 0.8064099499118714}
2022-11-18 02:34:34,577 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:34,577 INFO:     Epoch: 95
2022-11-18 02:34:35,354 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7665426175702702, 'Total loss': 0.7665426175702702} | train loss {'Reaction outcome loss': 0.8185563918791319, 'Total loss': 0.8185563918791319}
2022-11-18 02:34:35,354 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:35,354 INFO:     Epoch: 96
2022-11-18 02:34:36,148 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7580805617299947, 'Total loss': 0.7580805617299947} | train loss {'Reaction outcome loss': 0.8088283575618798, 'Total loss': 0.8088283575618798}
2022-11-18 02:34:36,148 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:36,148 INFO:     Epoch: 97
2022-11-18 02:34:36,946 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.797142705456777, 'Total loss': 0.797142705456777} | train loss {'Reaction outcome loss': 0.8146025678406843, 'Total loss': 0.8146025678406843}
2022-11-18 02:34:36,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:36,946 INFO:     Epoch: 98
2022-11-18 02:34:37,721 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7597891925410791, 'Total loss': 0.7597891925410791} | train loss {'Reaction outcome loss': 0.8203464857479821, 'Total loss': 0.8203464857479821}
2022-11-18 02:34:37,721 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:37,721 INFO:     Epoch: 99
2022-11-18 02:34:38,500 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7851016050712629, 'Total loss': 0.7851016050712629} | train loss {'Reaction outcome loss': 0.8178571852353903, 'Total loss': 0.8178571852353903}
2022-11-18 02:34:38,500 INFO:     Best model found after epoch 86 of 100.
2022-11-18 02:34:38,500 INFO:   Done with stage: TRAINING
2022-11-18 02:34:38,500 INFO:   Starting stage: EVALUATION
2022-11-18 02:34:38,632 INFO:   Done with stage: EVALUATION
2022-11-18 02:34:38,633 INFO:   Leaving out SEQ value Fold_5
2022-11-18 02:34:38,646 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 02:34:38,646 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:34:39,316 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:34:39,317 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:34:39,387 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:34:39,388 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:34:39,388 INFO:     No hyperparam tuning for this model
2022-11-18 02:34:39,388 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:34:39,388 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:34:39,389 INFO:     None feature selector for col prot
2022-11-18 02:34:39,389 INFO:     None feature selector for col prot
2022-11-18 02:34:39,389 INFO:     None feature selector for col prot
2022-11-18 02:34:39,389 INFO:     None feature selector for col chem
2022-11-18 02:34:39,390 INFO:     None feature selector for col chem
2022-11-18 02:34:39,390 INFO:     None feature selector for col chem
2022-11-18 02:34:39,390 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:34:39,390 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:34:39,391 INFO:     Number of params in model 168571
2022-11-18 02:34:39,395 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:34:39,395 INFO:   Starting stage: TRAINING
2022-11-18 02:34:39,453 INFO:     Val loss before train {'Reaction outcome loss': 0.996493015776981, 'Total loss': 0.996493015776981}
2022-11-18 02:34:39,453 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:39,453 INFO:     Epoch: 0
2022-11-18 02:34:40,229 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8402062573216178, 'Total loss': 0.8402062573216178} | train loss {'Reaction outcome loss': 0.8736212270394448, 'Total loss': 0.8736212270394448}
2022-11-18 02:34:40,229 INFO:     Found new best model at epoch 0
2022-11-18 02:34:40,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:40,230 INFO:     Epoch: 1
2022-11-18 02:34:41,020 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8143820505250584, 'Total loss': 0.8143820505250584} | train loss {'Reaction outcome loss': 0.8475457524820682, 'Total loss': 0.8475457524820682}
2022-11-18 02:34:41,020 INFO:     Found new best model at epoch 1
2022-11-18 02:34:41,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:41,021 INFO:     Epoch: 2
2022-11-18 02:34:41,802 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8173225339163434, 'Total loss': 0.8173225339163434} | train loss {'Reaction outcome loss': 0.8416150239927154, 'Total loss': 0.8416150239927154}
2022-11-18 02:34:41,802 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:41,802 INFO:     Epoch: 3
2022-11-18 02:34:42,608 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8084768361665986, 'Total loss': 0.8084768361665986} | train loss {'Reaction outcome loss': 0.8360551879290612, 'Total loss': 0.8360551879290612}
2022-11-18 02:34:42,608 INFO:     Found new best model at epoch 3
2022-11-18 02:34:42,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:42,609 INFO:     Epoch: 4
2022-11-18 02:34:43,404 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.801110443066467, 'Total loss': 0.801110443066467} | train loss {'Reaction outcome loss': 0.8325676605586083, 'Total loss': 0.8325676605586083}
2022-11-18 02:34:43,404 INFO:     Found new best model at epoch 4
2022-11-18 02:34:43,405 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:43,405 INFO:     Epoch: 5
2022-11-18 02:34:44,256 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.7970648137005892, 'Total loss': 0.7970648137005892} | train loss {'Reaction outcome loss': 0.8300275163304421, 'Total loss': 0.8300275163304421}
2022-11-18 02:34:44,257 INFO:     Found new best model at epoch 5
2022-11-18 02:34:44,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:44,258 INFO:     Epoch: 6
2022-11-18 02:34:45,094 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7962891479784792, 'Total loss': 0.7962891479784792} | train loss {'Reaction outcome loss': 0.8283496288762938, 'Total loss': 0.8283496288762938}
2022-11-18 02:34:45,094 INFO:     Found new best model at epoch 6
2022-11-18 02:34:45,095 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:45,095 INFO:     Epoch: 7
2022-11-18 02:34:45,902 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8004731691696427, 'Total loss': 0.8004731691696427} | train loss {'Reaction outcome loss': 0.8289671601547349, 'Total loss': 0.8289671601547349}
2022-11-18 02:34:45,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:45,902 INFO:     Epoch: 8
2022-11-18 02:34:46,715 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8170974112369798, 'Total loss': 0.8170974112369798} | train loss {'Reaction outcome loss': 0.825992654408178, 'Total loss': 0.825992654408178}
2022-11-18 02:34:46,716 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:46,716 INFO:     Epoch: 9
2022-11-18 02:34:47,522 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8041467998515476, 'Total loss': 0.8041467998515476} | train loss {'Reaction outcome loss': 0.8241119091549227, 'Total loss': 0.8241119091549227}
2022-11-18 02:34:47,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:47,522 INFO:     Epoch: 10
2022-11-18 02:34:48,289 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8081535453146155, 'Total loss': 0.8081535453146155} | train loss {'Reaction outcome loss': 0.8202810185330529, 'Total loss': 0.8202810185330529}
2022-11-18 02:34:48,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:48,289 INFO:     Epoch: 11
2022-11-18 02:34:49,101 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8143877305767753, 'Total loss': 0.8143877305767753} | train loss {'Reaction outcome loss': 0.82265437105971, 'Total loss': 0.82265437105971}
2022-11-18 02:34:49,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:49,101 INFO:     Epoch: 12
2022-11-18 02:34:49,940 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.78855130889199, 'Total loss': 0.78855130889199} | train loss {'Reaction outcome loss': 0.8241387354510445, 'Total loss': 0.8241387354510445}
2022-11-18 02:34:49,940 INFO:     Found new best model at epoch 12
2022-11-18 02:34:49,941 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:49,941 INFO:     Epoch: 13
2022-11-18 02:34:50,733 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7877614091743123, 'Total loss': 0.7877614091743123} | train loss {'Reaction outcome loss': 0.8202949141062075, 'Total loss': 0.8202949141062075}
2022-11-18 02:34:50,733 INFO:     Found new best model at epoch 13
2022-11-18 02:34:50,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:50,734 INFO:     Epoch: 14
2022-11-18 02:34:51,542 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7985826256600294, 'Total loss': 0.7985826256600294} | train loss {'Reaction outcome loss': 0.8225299504495436, 'Total loss': 0.8225299504495436}
2022-11-18 02:34:51,542 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:51,543 INFO:     Epoch: 15
2022-11-18 02:34:52,361 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8148434853011911, 'Total loss': 0.8148434853011911} | train loss {'Reaction outcome loss': 0.8182090119488777, 'Total loss': 0.8182090119488777}
2022-11-18 02:34:52,361 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:52,361 INFO:     Epoch: 16
2022-11-18 02:34:53,167 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7949490736831318, 'Total loss': 0.7949490736831318} | train loss {'Reaction outcome loss': 0.818746282689033, 'Total loss': 0.818746282689033}
2022-11-18 02:34:53,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:53,167 INFO:     Epoch: 17
2022-11-18 02:34:53,987 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8096028071912852, 'Total loss': 0.8096028071912852} | train loss {'Reaction outcome loss': 0.82036791008807, 'Total loss': 0.82036791008807}
2022-11-18 02:34:53,987 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:53,987 INFO:     Epoch: 18
2022-11-18 02:34:54,840 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7925856160846624, 'Total loss': 0.7925856160846624} | train loss {'Reaction outcome loss': 0.8204084818641986, 'Total loss': 0.8204084818641986}
2022-11-18 02:34:54,840 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:54,840 INFO:     Epoch: 19
2022-11-18 02:34:55,670 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8126276961781762, 'Total loss': 0.8126276961781762} | train loss {'Reaction outcome loss': 0.8173353778979471, 'Total loss': 0.8173353778979471}
2022-11-18 02:34:55,671 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:55,671 INFO:     Epoch: 20
2022-11-18 02:34:56,472 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.787380991334265, 'Total loss': 0.787380991334265} | train loss {'Reaction outcome loss': 0.8218356769892478, 'Total loss': 0.8218356769892478}
2022-11-18 02:34:56,474 INFO:     Found new best model at epoch 20
2022-11-18 02:34:56,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:56,475 INFO:     Epoch: 21
2022-11-18 02:34:57,255 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7987831749699332, 'Total loss': 0.7987831749699332} | train loss {'Reaction outcome loss': 0.8182339712737068, 'Total loss': 0.8182339712737068}
2022-11-18 02:34:57,255 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:57,255 INFO:     Epoch: 22
2022-11-18 02:34:58,038 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.79844130711122, 'Total loss': 0.79844130711122} | train loss {'Reaction outcome loss': 0.8210914597636269, 'Total loss': 0.8210914597636269}
2022-11-18 02:34:58,038 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:58,039 INFO:     Epoch: 23
2022-11-18 02:34:58,839 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7887108292091977, 'Total loss': 0.7887108292091977} | train loss {'Reaction outcome loss': 0.8161860515754069, 'Total loss': 0.8161860515754069}
2022-11-18 02:34:58,839 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:58,839 INFO:     Epoch: 24
2022-11-18 02:34:59,604 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7880192832513289, 'Total loss': 0.7880192832513289} | train loss {'Reaction outcome loss': 0.8132739140381736, 'Total loss': 0.8132739140381736}
2022-11-18 02:34:59,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:34:59,604 INFO:     Epoch: 25
2022-11-18 02:35:00,421 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7968924045562744, 'Total loss': 0.7968924045562744} | train loss {'Reaction outcome loss': 0.8178263085503732, 'Total loss': 0.8178263085503732}
2022-11-18 02:35:00,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:00,421 INFO:     Epoch: 26
2022-11-18 02:35:01,269 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7804613993926481, 'Total loss': 0.7804613993926481} | train loss {'Reaction outcome loss': 0.8158830566512, 'Total loss': 0.8158830566512}
2022-11-18 02:35:01,270 INFO:     Found new best model at epoch 26
2022-11-18 02:35:01,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:01,270 INFO:     Epoch: 27
2022-11-18 02:35:02,076 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8121686537157405, 'Total loss': 0.8121686537157405} | train loss {'Reaction outcome loss': 0.8174040559078416, 'Total loss': 0.8174040559078416}
2022-11-18 02:35:02,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:02,076 INFO:     Epoch: 28
2022-11-18 02:35:02,891 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7771200889890845, 'Total loss': 0.7771200889890845} | train loss {'Reaction outcome loss': 0.8148108846958606, 'Total loss': 0.8148108846958606}
2022-11-18 02:35:02,892 INFO:     Found new best model at epoch 28
2022-11-18 02:35:02,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:02,893 INFO:     Epoch: 29
2022-11-18 02:35:03,720 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7844196903434667, 'Total loss': 0.7844196903434667} | train loss {'Reaction outcome loss': 0.8153079082408259, 'Total loss': 0.8153079082408259}
2022-11-18 02:35:03,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:03,720 INFO:     Epoch: 30
2022-11-18 02:35:04,501 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7977505150166425, 'Total loss': 0.7977505150166425} | train loss {'Reaction outcome loss': 0.8142412607708285, 'Total loss': 0.8142412607708285}
2022-11-18 02:35:04,501 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:04,501 INFO:     Epoch: 31
2022-11-18 02:35:05,293 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8084613856944171, 'Total loss': 0.8084613856944171} | train loss {'Reaction outcome loss': 0.814382731674179, 'Total loss': 0.814382731674179}
2022-11-18 02:35:05,293 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:05,293 INFO:     Epoch: 32
2022-11-18 02:35:06,132 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8005697937174276, 'Total loss': 0.8005697937174276} | train loss {'Reaction outcome loss': 0.8148219389540534, 'Total loss': 0.8148219389540534}
2022-11-18 02:35:06,133 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:06,133 INFO:     Epoch: 33
2022-11-18 02:35:06,930 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.793824860995466, 'Total loss': 0.793824860995466} | train loss {'Reaction outcome loss': 0.8164979969301531, 'Total loss': 0.8164979969301531}
2022-11-18 02:35:06,930 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:06,931 INFO:     Epoch: 34
2022-11-18 02:35:07,742 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8153017081997611, 'Total loss': 0.8153017081997611} | train loss {'Reaction outcome loss': 0.818540278341501, 'Total loss': 0.818540278341501}
2022-11-18 02:35:07,743 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:07,743 INFO:     Epoch: 35
2022-11-18 02:35:08,531 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.805259535935792, 'Total loss': 0.805259535935792} | train loss {'Reaction outcome loss': 0.8167806336235616, 'Total loss': 0.8167806336235616}
2022-11-18 02:35:08,532 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:08,532 INFO:     Epoch: 36
2022-11-18 02:35:09,370 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7955554120919921, 'Total loss': 0.7955554120919921} | train loss {'Reaction outcome loss': 0.8134410428183694, 'Total loss': 0.8134410428183694}
2022-11-18 02:35:09,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:09,370 INFO:     Epoch: 37
2022-11-18 02:35:10,135 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.807908877053044, 'Total loss': 0.807908877053044} | train loss {'Reaction outcome loss': 0.8157573207732169, 'Total loss': 0.8157573207732169}
2022-11-18 02:35:10,135 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:10,135 INFO:     Epoch: 38
2022-11-18 02:35:10,927 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.785599722103639, 'Total loss': 0.785599722103639} | train loss {'Reaction outcome loss': 0.8180936912615453, 'Total loss': 0.8180936912615453}
2022-11-18 02:35:10,927 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:10,927 INFO:     Epoch: 39
2022-11-18 02:35:11,696 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7874620123343035, 'Total loss': 0.7874620123343035} | train loss {'Reaction outcome loss': 0.8123808956194308, 'Total loss': 0.8123808956194308}
2022-11-18 02:35:11,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:11,696 INFO:     Epoch: 40
2022-11-18 02:35:12,482 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7786009846763178, 'Total loss': 0.7786009846763178} | train loss {'Reaction outcome loss': 0.8190367361230235, 'Total loss': 0.8190367361230235}
2022-11-18 02:35:12,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:12,482 INFO:     Epoch: 41
2022-11-18 02:35:13,264 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7826531793583523, 'Total loss': 0.7826531793583523} | train loss {'Reaction outcome loss': 0.8142858958773075, 'Total loss': 0.8142858958773075}
2022-11-18 02:35:13,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:13,264 INFO:     Epoch: 42
2022-11-18 02:35:14,048 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8044265942140059, 'Total loss': 0.8044265942140059} | train loss {'Reaction outcome loss': 0.8144785218661831, 'Total loss': 0.8144785218661831}
2022-11-18 02:35:14,048 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:14,048 INFO:     Epoch: 43
2022-11-18 02:35:14,843 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7991506775671785, 'Total loss': 0.7991506775671785} | train loss {'Reaction outcome loss': 0.8129831558514026, 'Total loss': 0.8129831558514026}
2022-11-18 02:35:14,843 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:14,843 INFO:     Epoch: 44
2022-11-18 02:35:15,603 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7955732677470554, 'Total loss': 0.7955732677470554} | train loss {'Reaction outcome loss': 0.8161685601357491, 'Total loss': 0.8161685601357491}
2022-11-18 02:35:15,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:15,604 INFO:     Epoch: 45
2022-11-18 02:35:16,388 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.794798112728379, 'Total loss': 0.794798112728379} | train loss {'Reaction outcome loss': 0.8182248618573912, 'Total loss': 0.8182248618573912}
2022-11-18 02:35:16,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:16,388 INFO:     Epoch: 46
2022-11-18 02:35:17,181 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8010351684960452, 'Total loss': 0.8010351684960452} | train loss {'Reaction outcome loss': 0.8127537005611004, 'Total loss': 0.8127537005611004}
2022-11-18 02:35:17,182 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:17,182 INFO:     Epoch: 47
2022-11-18 02:35:17,967 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8016875453970649, 'Total loss': 0.8016875453970649} | train loss {'Reaction outcome loss': 0.8145511123922563, 'Total loss': 0.8145511123922563}
2022-11-18 02:35:17,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:17,968 INFO:     Epoch: 48
2022-11-18 02:35:18,778 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.792335300960324, 'Total loss': 0.792335300960324} | train loss {'Reaction outcome loss': 0.818236235649355, 'Total loss': 0.818236235649355}
2022-11-18 02:35:18,779 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:18,779 INFO:     Epoch: 49
2022-11-18 02:35:19,540 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8198747018521483, 'Total loss': 0.8198747018521483} | train loss {'Reaction outcome loss': 0.8122654027275501, 'Total loss': 0.8122654027275501}
2022-11-18 02:35:19,541 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:19,541 INFO:     Epoch: 50
2022-11-18 02:35:20,325 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.817497996444052, 'Total loss': 0.817497996444052} | train loss {'Reaction outcome loss': 0.8153288090421308, 'Total loss': 0.8153288090421308}
2022-11-18 02:35:20,325 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:20,326 INFO:     Epoch: 51
2022-11-18 02:35:21,114 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8025060878558592, 'Total loss': 0.8025060878558592} | train loss {'Reaction outcome loss': 0.8132972297889571, 'Total loss': 0.8132972297889571}
2022-11-18 02:35:21,114 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:21,115 INFO:     Epoch: 52
2022-11-18 02:35:21,908 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7911378314549272, 'Total loss': 0.7911378314549272} | train loss {'Reaction outcome loss': 0.8146125346181854, 'Total loss': 0.8146125346181854}
2022-11-18 02:35:21,908 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:21,908 INFO:     Epoch: 53
2022-11-18 02:35:22,696 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8110209418968721, 'Total loss': 0.8110209418968721} | train loss {'Reaction outcome loss': 0.8154904634481476, 'Total loss': 0.8154904634481476}
2022-11-18 02:35:22,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:22,696 INFO:     Epoch: 54
2022-11-18 02:35:23,495 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7994458607651971, 'Total loss': 0.7994458607651971} | train loss {'Reaction outcome loss': 0.8191344668307612, 'Total loss': 0.8191344668307612}
2022-11-18 02:35:23,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:23,495 INFO:     Epoch: 55
2022-11-18 02:35:24,289 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7981010743162849, 'Total loss': 0.7981010743162849} | train loss {'Reaction outcome loss': 0.8093142525082634, 'Total loss': 0.8093142525082634}
2022-11-18 02:35:24,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:24,289 INFO:     Epoch: 56
2022-11-18 02:35:25,098 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8031606362624601, 'Total loss': 0.8031606362624601} | train loss {'Reaction outcome loss': 0.8095308853493582, 'Total loss': 0.8095308853493582}
2022-11-18 02:35:25,098 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:25,099 INFO:     Epoch: 57
2022-11-18 02:35:25,896 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7860419330271807, 'Total loss': 0.7860419330271807} | train loss {'Reaction outcome loss': 0.81583480957535, 'Total loss': 0.81583480957535}
2022-11-18 02:35:25,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:25,896 INFO:     Epoch: 58
2022-11-18 02:35:26,709 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7911383678967302, 'Total loss': 0.7911383678967302} | train loss {'Reaction outcome loss': 0.8133412396475193, 'Total loss': 0.8133412396475193}
2022-11-18 02:35:26,710 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:26,710 INFO:     Epoch: 59
2022-11-18 02:35:27,495 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7926932586864992, 'Total loss': 0.7926932586864992} | train loss {'Reaction outcome loss': 0.8154075668463784, 'Total loss': 0.8154075668463784}
2022-11-18 02:35:27,496 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:27,497 INFO:     Epoch: 60
2022-11-18 02:35:28,274 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.79462669654326, 'Total loss': 0.79462669654326} | train loss {'Reaction outcome loss': 0.8084173161656626, 'Total loss': 0.8084173161656626}
2022-11-18 02:35:28,274 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:28,274 INFO:     Epoch: 61
2022-11-18 02:35:29,085 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.795394858176058, 'Total loss': 0.795394858176058} | train loss {'Reaction outcome loss': 0.8159470845374369, 'Total loss': 0.8159470845374369}
2022-11-18 02:35:29,085 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:29,085 INFO:     Epoch: 62
2022-11-18 02:35:29,896 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7926628867333586, 'Total loss': 0.7926628867333586} | train loss {'Reaction outcome loss': 0.8185401856899261, 'Total loss': 0.8185401856899261}
2022-11-18 02:35:29,896 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:29,896 INFO:     Epoch: 63
2022-11-18 02:35:30,683 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7849574346433986, 'Total loss': 0.7849574346433986} | train loss {'Reaction outcome loss': 0.8123564014752065, 'Total loss': 0.8123564014752065}
2022-11-18 02:35:30,683 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:30,683 INFO:     Epoch: 64
2022-11-18 02:35:31,507 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8072723935950886, 'Total loss': 0.8072723935950886} | train loss {'Reaction outcome loss': 0.812573827442623, 'Total loss': 0.812573827442623}
2022-11-18 02:35:31,507 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:31,507 INFO:     Epoch: 65
2022-11-18 02:35:32,298 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7919476337053559, 'Total loss': 0.7919476337053559} | train loss {'Reaction outcome loss': 0.8122374576426321, 'Total loss': 0.8122374576426321}
2022-11-18 02:35:32,298 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:32,299 INFO:     Epoch: 66
2022-11-18 02:35:33,125 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7856835675510493, 'Total loss': 0.7856835675510493} | train loss {'Reaction outcome loss': 0.8150648633318562, 'Total loss': 0.8150648633318562}
2022-11-18 02:35:33,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:33,125 INFO:     Epoch: 67
2022-11-18 02:35:33,936 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7956750792535868, 'Total loss': 0.7956750792535868} | train loss {'Reaction outcome loss': 0.8122506527410399, 'Total loss': 0.8122506527410399}
2022-11-18 02:35:33,937 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:33,937 INFO:     Epoch: 68
2022-11-18 02:35:34,745 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.7906057509509, 'Total loss': 0.7906057509509} | train loss {'Reaction outcome loss': 0.8157703860873177, 'Total loss': 0.8157703860873177}
2022-11-18 02:35:34,746 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:34,746 INFO:     Epoch: 69
2022-11-18 02:35:35,545 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7858792875300754, 'Total loss': 0.7858792875300754} | train loss {'Reaction outcome loss': 0.811452454136264, 'Total loss': 0.811452454136264}
2022-11-18 02:35:35,545 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:35,545 INFO:     Epoch: 70
2022-11-18 02:35:36,396 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7991438643498854, 'Total loss': 0.7991438643498854} | train loss {'Reaction outcome loss': 0.8151817508041859, 'Total loss': 0.8151817508041859}
2022-11-18 02:35:36,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:36,397 INFO:     Epoch: 71
2022-11-18 02:35:37,190 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7839854237708178, 'Total loss': 0.7839854237708178} | train loss {'Reaction outcome loss': 0.8150316316994929, 'Total loss': 0.8150316316994929}
2022-11-18 02:35:37,190 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:37,190 INFO:     Epoch: 72
2022-11-18 02:35:37,994 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8047719652002508, 'Total loss': 0.8047719652002508} | train loss {'Reaction outcome loss': 0.8123875449021016, 'Total loss': 0.8123875449021016}
2022-11-18 02:35:37,994 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:37,994 INFO:     Epoch: 73
2022-11-18 02:35:38,789 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8112580112435601, 'Total loss': 0.8112580112435601} | train loss {'Reaction outcome loss': 0.8164369486753018, 'Total loss': 0.8164369486753018}
2022-11-18 02:35:38,790 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:38,790 INFO:     Epoch: 74
2022-11-18 02:35:39,659 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7760588946667585, 'Total loss': 0.7760588946667585} | train loss {'Reaction outcome loss': 0.8099825800426544, 'Total loss': 0.8099825800426544}
2022-11-18 02:35:39,659 INFO:     Found new best model at epoch 74
2022-11-18 02:35:39,660 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:39,660 INFO:     Epoch: 75
2022-11-18 02:35:40,502 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8098827465014025, 'Total loss': 0.8098827465014025} | train loss {'Reaction outcome loss': 0.814086789085019, 'Total loss': 0.814086789085019}
2022-11-18 02:35:40,502 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:40,502 INFO:     Epoch: 76
2022-11-18 02:35:41,332 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7817686728455804, 'Total loss': 0.7817686728455804} | train loss {'Reaction outcome loss': 0.8170112888178518, 'Total loss': 0.8170112888178518}
2022-11-18 02:35:41,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:41,333 INFO:     Epoch: 77
2022-11-18 02:35:42,167 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7770350270650603, 'Total loss': 0.7770350270650603} | train loss {'Reaction outcome loss': 0.8127404387679792, 'Total loss': 0.8127404387679792}
2022-11-18 02:35:42,167 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:42,167 INFO:     Epoch: 78
2022-11-18 02:35:43,007 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8135837987065315, 'Total loss': 0.8135837987065315} | train loss {'Reaction outcome loss': 0.8141319111229912, 'Total loss': 0.8141319111229912}
2022-11-18 02:35:43,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:43,008 INFO:     Epoch: 79
2022-11-18 02:35:43,889 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7791742574084889, 'Total loss': 0.7791742574084889} | train loss {'Reaction outcome loss': 0.8124007908326965, 'Total loss': 0.8124007908326965}
2022-11-18 02:35:43,889 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:43,889 INFO:     Epoch: 80
2022-11-18 02:35:44,726 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7888670489192009, 'Total loss': 0.7888670489192009} | train loss {'Reaction outcome loss': 0.8082592952395639, 'Total loss': 0.8082592952395639}
2022-11-18 02:35:44,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:44,726 INFO:     Epoch: 81
2022-11-18 02:35:45,511 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8154552700844678, 'Total loss': 0.8154552700844678} | train loss {'Reaction outcome loss': 0.8127871557108818, 'Total loss': 0.8127871557108818}
2022-11-18 02:35:45,511 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:45,511 INFO:     Epoch: 82
2022-11-18 02:35:46,317 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7836687957698648, 'Total loss': 0.7836687957698648} | train loss {'Reaction outcome loss': 0.8149595287057662, 'Total loss': 0.8149595287057662}
2022-11-18 02:35:46,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:46,318 INFO:     Epoch: 83
2022-11-18 02:35:47,143 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8057987540960312, 'Total loss': 0.8057987540960312} | train loss {'Reaction outcome loss': 0.8091097198907407, 'Total loss': 0.8091097198907407}
2022-11-18 02:35:47,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:47,143 INFO:     Epoch: 84
2022-11-18 02:35:47,968 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7976877242326736, 'Total loss': 0.7976877242326736} | train loss {'Reaction outcome loss': 0.8107450791905003, 'Total loss': 0.8107450791905003}
2022-11-18 02:35:47,968 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:47,968 INFO:     Epoch: 85
2022-11-18 02:35:48,764 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.824040025472641, 'Total loss': 0.824040025472641} | train loss {'Reaction outcome loss': 0.8109896301982864, 'Total loss': 0.8109896301982864}
2022-11-18 02:35:48,764 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:48,764 INFO:     Epoch: 86
2022-11-18 02:35:49,625 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7951142720200799, 'Total loss': 0.7951142720200799} | train loss {'Reaction outcome loss': 0.8162238093153122, 'Total loss': 0.8162238093153122}
2022-11-18 02:35:49,625 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:49,625 INFO:     Epoch: 87
2022-11-18 02:35:50,401 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7813383076678623, 'Total loss': 0.7813383076678623} | train loss {'Reaction outcome loss': 0.8139119179498765, 'Total loss': 0.8139119179498765}
2022-11-18 02:35:50,401 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:50,401 INFO:     Epoch: 88
2022-11-18 02:35:51,178 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7772228074344721, 'Total loss': 0.7772228074344721} | train loss {'Reaction outcome loss': 0.8158475370897401, 'Total loss': 0.8158475370897401}
2022-11-18 02:35:51,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:51,178 INFO:     Epoch: 89
2022-11-18 02:35:51,981 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8136180117726326, 'Total loss': 0.8136180117726326} | train loss {'Reaction outcome loss': 0.8144480940555373, 'Total loss': 0.8144480940555373}
2022-11-18 02:35:51,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:51,981 INFO:     Epoch: 90
2022-11-18 02:35:52,776 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7911902273243124, 'Total loss': 0.7911902273243124} | train loss {'Reaction outcome loss': 0.809817283264091, 'Total loss': 0.809817283264091}
2022-11-18 02:35:52,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:52,776 INFO:     Epoch: 91
2022-11-18 02:35:53,553 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7953701100566171, 'Total loss': 0.7953701100566171} | train loss {'Reaction outcome loss': 0.8096912652854958, 'Total loss': 0.8096912652854958}
2022-11-18 02:35:53,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:53,553 INFO:     Epoch: 92
2022-11-18 02:35:54,355 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.8101769936355677, 'Total loss': 0.8101769936355677} | train loss {'Reaction outcome loss': 0.8128402823161694, 'Total loss': 0.8128402823161694}
2022-11-18 02:35:54,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:54,355 INFO:     Epoch: 93
2022-11-18 02:35:55,145 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7953359098597006, 'Total loss': 0.7953359098597006} | train loss {'Reaction outcome loss': 0.8166226237531631, 'Total loss': 0.8166226237531631}
2022-11-18 02:35:55,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:55,145 INFO:     Epoch: 94
2022-11-18 02:35:55,961 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.8001906119964339, 'Total loss': 0.8001906119964339} | train loss {'Reaction outcome loss': 0.8134428772234148, 'Total loss': 0.8134428772234148}
2022-11-18 02:35:55,961 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:55,962 INFO:     Epoch: 95
2022-11-18 02:35:56,764 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7889615039933812, 'Total loss': 0.7889615039933812} | train loss {'Reaction outcome loss': 0.8140966680742079, 'Total loss': 0.8140966680742079}
2022-11-18 02:35:56,765 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:56,765 INFO:     Epoch: 96
2022-11-18 02:35:57,512 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7897095490585674, 'Total loss': 0.7897095490585674} | train loss {'Reaction outcome loss': 0.8140354455719071, 'Total loss': 0.8140354455719071}
2022-11-18 02:35:57,512 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:57,513 INFO:     Epoch: 97
2022-11-18 02:35:58,331 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8104346597736533, 'Total loss': 0.8104346597736533} | train loss {'Reaction outcome loss': 0.8127235914430311, 'Total loss': 0.8127235914430311}
2022-11-18 02:35:58,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:58,332 INFO:     Epoch: 98
2022-11-18 02:35:59,149 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8151016215031798, 'Total loss': 0.8151016215031798} | train loss {'Reaction outcome loss': 0.8115536422739106, 'Total loss': 0.8115536422739106}
2022-11-18 02:35:59,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:35:59,149 INFO:     Epoch: 99
2022-11-18 02:35:59,942 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7851313379677859, 'Total loss': 0.7851313379677859} | train loss {'Reaction outcome loss': 0.8105257240634772, 'Total loss': 0.8105257240634772}
2022-11-18 02:35:59,942 INFO:     Best model found after epoch 75 of 100.
2022-11-18 02:35:59,942 INFO:   Done with stage: TRAINING
2022-11-18 02:35:59,943 INFO:   Starting stage: EVALUATION
2022-11-18 02:36:00,062 INFO:   Done with stage: EVALUATION
2022-11-18 02:36:00,063 INFO:   Leaving out SEQ value Fold_6
2022-11-18 02:36:00,075 INFO:   examples: 20,544| examples in train: 15,830 | examples in val: 2,794| examples in test: 1,920
2022-11-18 02:36:00,076 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:36:00,743 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:36:00,743 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:36:00,813 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:36:00,813 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:36:00,813 INFO:     No hyperparam tuning for this model
2022-11-18 02:36:00,813 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:36:00,813 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:36:00,814 INFO:     None feature selector for col prot
2022-11-18 02:36:00,814 INFO:     None feature selector for col prot
2022-11-18 02:36:00,814 INFO:     None feature selector for col prot
2022-11-18 02:36:00,815 INFO:     None feature selector for col chem
2022-11-18 02:36:00,815 INFO:     None feature selector for col chem
2022-11-18 02:36:00,815 INFO:     None feature selector for col chem
2022-11-18 02:36:00,815 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:36:00,815 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:36:00,817 INFO:     Number of params in model 168571
2022-11-18 02:36:00,820 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:36:00,820 INFO:   Starting stage: TRAINING
2022-11-18 02:36:00,878 INFO:     Val loss before train {'Reaction outcome loss': 0.9825698096643795, 'Total loss': 0.9825698096643795}
2022-11-18 02:36:00,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:00,878 INFO:     Epoch: 0
2022-11-18 02:36:01,717 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8155585303902626, 'Total loss': 0.8155585303902626} | train loss {'Reaction outcome loss': 0.8815698206665055, 'Total loss': 0.8815698206665055}
2022-11-18 02:36:01,717 INFO:     Found new best model at epoch 0
2022-11-18 02:36:01,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:01,718 INFO:     Epoch: 1
2022-11-18 02:36:02,556 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8290105814283545, 'Total loss': 0.8290105814283545} | train loss {'Reaction outcome loss': 0.8481313636706721, 'Total loss': 0.8481313636706721}
2022-11-18 02:36:02,556 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:02,557 INFO:     Epoch: 2
2022-11-18 02:36:03,399 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.7937087233770977, 'Total loss': 0.7937087233770977} | train loss {'Reaction outcome loss': 0.8454429912230661, 'Total loss': 0.8454429912230661}
2022-11-18 02:36:03,399 INFO:     Found new best model at epoch 2
2022-11-18 02:36:03,400 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:03,400 INFO:     Epoch: 3
2022-11-18 02:36:04,200 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8093845627524636, 'Total loss': 0.8093845627524636} | train loss {'Reaction outcome loss': 0.8439158597780813, 'Total loss': 0.8439158597780813}
2022-11-18 02:36:04,200 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:04,200 INFO:     Epoch: 4
2022-11-18 02:36:04,980 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8058312352408062, 'Total loss': 0.8058312352408062} | train loss {'Reaction outcome loss': 0.8377559970944158, 'Total loss': 0.8377559970944158}
2022-11-18 02:36:04,981 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:04,981 INFO:     Epoch: 5
2022-11-18 02:36:05,784 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8169036934321577, 'Total loss': 0.8169036934321577} | train loss {'Reaction outcome loss': 0.8363295209503943, 'Total loss': 0.8363295209503943}
2022-11-18 02:36:05,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:05,784 INFO:     Epoch: 6
2022-11-18 02:36:06,607 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8073903566057031, 'Total loss': 0.8073903566057031} | train loss {'Reaction outcome loss': 0.8310021755676116, 'Total loss': 0.8310021755676116}
2022-11-18 02:36:06,607 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:06,607 INFO:     Epoch: 7
2022-11-18 02:36:07,395 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8046324293721806, 'Total loss': 0.8046324293721806} | train loss {'Reaction outcome loss': 0.828897443149359, 'Total loss': 0.828897443149359}
2022-11-18 02:36:07,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:07,395 INFO:     Epoch: 8
2022-11-18 02:36:08,260 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7990498407320543, 'Total loss': 0.7990498407320543} | train loss {'Reaction outcome loss': 0.8258617397758269, 'Total loss': 0.8258617397758269}
2022-11-18 02:36:08,260 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:08,260 INFO:     Epoch: 9
2022-11-18 02:36:09,104 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.7836217284202576, 'Total loss': 0.7836217284202576} | train loss {'Reaction outcome loss': 0.8165246208588923, 'Total loss': 0.8165246208588923}
2022-11-18 02:36:09,104 INFO:     Found new best model at epoch 9
2022-11-18 02:36:09,104 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:09,104 INFO:     Epoch: 10
2022-11-18 02:36:09,921 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8213047683238983, 'Total loss': 0.8213047683238983} | train loss {'Reaction outcome loss': 0.8248895010159861, 'Total loss': 0.8248895010159861}
2022-11-18 02:36:09,921 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:09,921 INFO:     Epoch: 11
2022-11-18 02:36:10,725 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7836752696470781, 'Total loss': 0.7836752696470781} | train loss {'Reaction outcome loss': 0.8205316732487371, 'Total loss': 0.8205316732487371}
2022-11-18 02:36:10,726 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:10,726 INFO:     Epoch: 12
2022-11-18 02:36:11,556 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7830772210251201, 'Total loss': 0.7830772210251201} | train loss {'Reaction outcome loss': 0.8192240302601168, 'Total loss': 0.8192240302601168}
2022-11-18 02:36:11,556 INFO:     Found new best model at epoch 12
2022-11-18 02:36:11,557 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:11,557 INFO:     Epoch: 13
2022-11-18 02:36:12,396 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7870102985338732, 'Total loss': 0.7870102985338732} | train loss {'Reaction outcome loss': 0.8278840088075207, 'Total loss': 0.8278840088075207}
2022-11-18 02:36:12,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:12,397 INFO:     Epoch: 14
2022-11-18 02:36:13,174 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7846862572160634, 'Total loss': 0.7846862572160634} | train loss {'Reaction outcome loss': 0.814239671513919, 'Total loss': 0.814239671513919}
2022-11-18 02:36:13,174 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:13,174 INFO:     Epoch: 15
2022-11-18 02:36:13,996 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.7795832102948969, 'Total loss': 0.7795832102948969} | train loss {'Reaction outcome loss': 0.8186735731940116, 'Total loss': 0.8186735731940116}
2022-11-18 02:36:13,996 INFO:     Found new best model at epoch 15
2022-11-18 02:36:13,997 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:13,997 INFO:     Epoch: 16
2022-11-18 02:36:14,788 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7893298620527441, 'Total loss': 0.7893298620527441} | train loss {'Reaction outcome loss': 0.814045813295149, 'Total loss': 0.814045813295149}
2022-11-18 02:36:14,789 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:14,789 INFO:     Epoch: 17
2022-11-18 02:36:15,646 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7690837003967979, 'Total loss': 0.7690837003967979} | train loss {'Reaction outcome loss': 0.8169893183775486, 'Total loss': 0.8169893183775486}
2022-11-18 02:36:15,646 INFO:     Found new best model at epoch 17
2022-11-18 02:36:15,647 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:15,647 INFO:     Epoch: 18
2022-11-18 02:36:16,429 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7826537950472399, 'Total loss': 0.7826537950472399} | train loss {'Reaction outcome loss': 0.818392000731922, 'Total loss': 0.818392000731922}
2022-11-18 02:36:16,430 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:16,430 INFO:     Epoch: 19
2022-11-18 02:36:17,220 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7814782343127511, 'Total loss': 0.7814782343127511} | train loss {'Reaction outcome loss': 0.8140674950855393, 'Total loss': 0.8140674950855393}
2022-11-18 02:36:17,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:17,221 INFO:     Epoch: 20
2022-11-18 02:36:17,999 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7852747189727697, 'Total loss': 0.7852747189727697} | train loss {'Reaction outcome loss': 0.8192175906752387, 'Total loss': 0.8192175906752387}
2022-11-18 02:36:17,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:18,000 INFO:     Epoch: 21
2022-11-18 02:36:18,773 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7753933431072668, 'Total loss': 0.7753933431072668} | train loss {'Reaction outcome loss': 0.8162051641171978, 'Total loss': 0.8162051641171978}
2022-11-18 02:36:18,773 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:18,773 INFO:     Epoch: 22
2022-11-18 02:36:19,576 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.8037172867493196, 'Total loss': 0.8037172867493196} | train loss {'Reaction outcome loss': 0.8118906882741759, 'Total loss': 0.8118906882741759}
2022-11-18 02:36:19,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:19,576 INFO:     Epoch: 23
2022-11-18 02:36:20,357 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.7794826105237007, 'Total loss': 0.7794826105237007} | train loss {'Reaction outcome loss': 0.8182843746917863, 'Total loss': 0.8182843746917863}
2022-11-18 02:36:20,357 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:20,357 INFO:     Epoch: 24
2022-11-18 02:36:21,145 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7914581576531584, 'Total loss': 0.7914581576531584} | train loss {'Reaction outcome loss': 0.81089481410961, 'Total loss': 0.81089481410961}
2022-11-18 02:36:21,145 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:21,145 INFO:     Epoch: 25
2022-11-18 02:36:21,910 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7822289805520665, 'Total loss': 0.7822289805520665} | train loss {'Reaction outcome loss': 0.8150309929924626, 'Total loss': 0.8150309929924626}
2022-11-18 02:36:21,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:21,911 INFO:     Epoch: 26
2022-11-18 02:36:22,694 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.7839815684340217, 'Total loss': 0.7839815684340217} | train loss {'Reaction outcome loss': 0.8159935688299518, 'Total loss': 0.8159935688299518}
2022-11-18 02:36:22,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:22,695 INFO:     Epoch: 27
2022-11-18 02:36:23,452 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7911183475093408, 'Total loss': 0.7911183475093408} | train loss {'Reaction outcome loss': 0.8144264513206098, 'Total loss': 0.8144264513206098}
2022-11-18 02:36:23,452 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:23,452 INFO:     Epoch: 28
2022-11-18 02:36:24,250 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7829844789071516, 'Total loss': 0.7829844789071516} | train loss {'Reaction outcome loss': 0.8124906534869825, 'Total loss': 0.8124906534869825}
2022-11-18 02:36:24,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:24,250 INFO:     Epoch: 29
2022-11-18 02:36:25,009 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.78172182765874, 'Total loss': 0.78172182765874} | train loss {'Reaction outcome loss': 0.8170510723946556, 'Total loss': 0.8170510723946556}
2022-11-18 02:36:25,009 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:25,009 INFO:     Epoch: 30
2022-11-18 02:36:25,817 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.7725341157479719, 'Total loss': 0.7725341157479719} | train loss {'Reaction outcome loss': 0.8125576141380495, 'Total loss': 0.8125576141380495}
2022-11-18 02:36:25,817 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:25,817 INFO:     Epoch: 31
2022-11-18 02:36:26,595 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7790255600755865, 'Total loss': 0.7790255600755865} | train loss {'Reaction outcome loss': 0.8139041311317875, 'Total loss': 0.8139041311317875}
2022-11-18 02:36:26,595 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:26,595 INFO:     Epoch: 32
2022-11-18 02:36:27,363 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.782963021912358, 'Total loss': 0.782963021912358} | train loss {'Reaction outcome loss': 0.8094928110198628, 'Total loss': 0.8094928110198628}
2022-11-18 02:36:27,363 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:27,363 INFO:     Epoch: 33
2022-11-18 02:36:28,146 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7820871553637765, 'Total loss': 0.7820871553637765} | train loss {'Reaction outcome loss': 0.8120091088837192, 'Total loss': 0.8120091088837192}
2022-11-18 02:36:28,146 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:28,146 INFO:     Epoch: 34
2022-11-18 02:36:28,920 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7843373174017126, 'Total loss': 0.7843373174017126} | train loss {'Reaction outcome loss': 0.8143357105793492, 'Total loss': 0.8143357105793492}
2022-11-18 02:36:28,920 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:28,920 INFO:     Epoch: 35
2022-11-18 02:36:29,699 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.7692172324115579, 'Total loss': 0.7692172324115579} | train loss {'Reaction outcome loss': 0.8123458518135932, 'Total loss': 0.8123458518135932}
2022-11-18 02:36:29,701 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:29,701 INFO:     Epoch: 36
2022-11-18 02:36:30,523 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7729985998435454, 'Total loss': 0.7729985998435454} | train loss {'Reaction outcome loss': 0.8102872934072248, 'Total loss': 0.8102872934072248}
2022-11-18 02:36:30,523 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:30,524 INFO:     Epoch: 37
2022-11-18 02:36:31,307 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7865085493434559, 'Total loss': 0.7865085493434559} | train loss {'Reaction outcome loss': 0.8086864698317743, 'Total loss': 0.8086864698317743}
2022-11-18 02:36:31,308 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:31,308 INFO:     Epoch: 38
2022-11-18 02:36:32,103 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7866287631067362, 'Total loss': 0.7866287631067362} | train loss {'Reaction outcome loss': 0.8140402831617863, 'Total loss': 0.8140402831617863}
2022-11-18 02:36:32,103 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:32,103 INFO:     Epoch: 39
2022-11-18 02:36:32,877 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7674956355582584, 'Total loss': 0.7674956355582584} | train loss {'Reaction outcome loss': 0.8095239147303566, 'Total loss': 0.8095239147303566}
2022-11-18 02:36:32,877 INFO:     Found new best model at epoch 39
2022-11-18 02:36:32,878 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:32,878 INFO:     Epoch: 40
2022-11-18 02:36:33,695 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7571761377833106, 'Total loss': 0.7571761377833106} | train loss {'Reaction outcome loss': 0.8132909120270803, 'Total loss': 0.8132909120270803}
2022-11-18 02:36:33,695 INFO:     Found new best model at epoch 40
2022-11-18 02:36:33,696 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:33,696 INFO:     Epoch: 41
2022-11-18 02:36:34,475 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7878618098118089, 'Total loss': 0.7878618098118089} | train loss {'Reaction outcome loss': 0.8127088471045417, 'Total loss': 0.8127088471045417}
2022-11-18 02:36:34,475 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:34,475 INFO:     Epoch: 42
2022-11-18 02:36:35,252 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7812720401720568, 'Total loss': 0.7812720401720568} | train loss {'Reaction outcome loss': 0.8151359463170651, 'Total loss': 0.8151359463170651}
2022-11-18 02:36:35,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:35,252 INFO:     Epoch: 43
2022-11-18 02:36:36,020 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7775837101719596, 'Total loss': 0.7775837101719596} | train loss {'Reaction outcome loss': 0.8083069078143565, 'Total loss': 0.8083069078143565}
2022-11-18 02:36:36,021 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:36,021 INFO:     Epoch: 44
2022-11-18 02:36:36,786 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7793061570687727, 'Total loss': 0.7793061570687727} | train loss {'Reaction outcome loss': 0.8119041414991501, 'Total loss': 0.8119041414991501}
2022-11-18 02:36:36,786 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:36,787 INFO:     Epoch: 45
2022-11-18 02:36:37,576 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7713017836213112, 'Total loss': 0.7713017836213112} | train loss {'Reaction outcome loss': 0.8081544077684802, 'Total loss': 0.8081544077684802}
2022-11-18 02:36:37,576 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:37,576 INFO:     Epoch: 46
2022-11-18 02:36:38,379 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7852461419322274, 'Total loss': 0.7852461419322274} | train loss {'Reaction outcome loss': 0.8071239594249956, 'Total loss': 0.8071239594249956}
2022-11-18 02:36:38,379 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:38,379 INFO:     Epoch: 47
2022-11-18 02:36:39,158 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7867005149071867, 'Total loss': 0.7867005149071867} | train loss {'Reaction outcome loss': 0.8118099752933748, 'Total loss': 0.8118099752933748}
2022-11-18 02:36:39,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:39,158 INFO:     Epoch: 48
2022-11-18 02:36:39,939 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7757847295566038, 'Total loss': 0.7757847295566038} | train loss {'Reaction outcome loss': 0.8104044740959522, 'Total loss': 0.8104044740959522}
2022-11-18 02:36:39,939 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:39,939 INFO:     Epoch: 49
2022-11-18 02:36:40,717 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7736793993548914, 'Total loss': 0.7736793993548914} | train loss {'Reaction outcome loss': 0.8108217557591777, 'Total loss': 0.8108217557591777}
2022-11-18 02:36:40,718 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:40,718 INFO:     Epoch: 50
2022-11-18 02:36:41,493 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7935909039594911, 'Total loss': 0.7935909039594911} | train loss {'Reaction outcome loss': 0.8093444694194102, 'Total loss': 0.8093444694194102}
2022-11-18 02:36:41,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:41,493 INFO:     Epoch: 51
2022-11-18 02:36:42,291 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7814364385875788, 'Total loss': 0.7814364385875788} | train loss {'Reaction outcome loss': 0.813668463619486, 'Total loss': 0.813668463619486}
2022-11-18 02:36:42,291 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:42,291 INFO:     Epoch: 52
2022-11-18 02:36:43,082 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7774726504629309, 'Total loss': 0.7774726504629309} | train loss {'Reaction outcome loss': 0.8092838408004853, 'Total loss': 0.8092838408004853}
2022-11-18 02:36:43,082 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:43,082 INFO:     Epoch: 53
2022-11-18 02:36:43,852 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.79981629550457, 'Total loss': 0.79981629550457} | train loss {'Reaction outcome loss': 0.809206226059506, 'Total loss': 0.809206226059506}
2022-11-18 02:36:43,852 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:43,852 INFO:     Epoch: 54
2022-11-18 02:36:44,638 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7634898166764866, 'Total loss': 0.7634898166764866} | train loss {'Reaction outcome loss': 0.8136354903540304, 'Total loss': 0.8136354903540304}
2022-11-18 02:36:44,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:44,639 INFO:     Epoch: 55
2022-11-18 02:36:45,417 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7807154303247278, 'Total loss': 0.7807154303247278} | train loss {'Reaction outcome loss': 0.8093390223239699, 'Total loss': 0.8093390223239699}
2022-11-18 02:36:45,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:45,417 INFO:     Epoch: 56
2022-11-18 02:36:46,220 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7767165492881428, 'Total loss': 0.7767165492881428} | train loss {'Reaction outcome loss': 0.8156589040112111, 'Total loss': 0.8156589040112111}
2022-11-18 02:36:46,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:46,221 INFO:     Epoch: 57
2022-11-18 02:36:47,005 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7679441097107801, 'Total loss': 0.7679441097107801} | train loss {'Reaction outcome loss': 0.8100973153787274, 'Total loss': 0.8100973153787274}
2022-11-18 02:36:47,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:47,005 INFO:     Epoch: 58
2022-11-18 02:36:47,808 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.805626088922674, 'Total loss': 0.805626088922674} | train loss {'Reaction outcome loss': 0.808797316926141, 'Total loss': 0.808797316926141}
2022-11-18 02:36:47,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:47,808 INFO:     Epoch: 59
2022-11-18 02:36:48,608 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7754313166845929, 'Total loss': 0.7754313166845929} | train loss {'Reaction outcome loss': 0.8115945520900911, 'Total loss': 0.8115945520900911}
2022-11-18 02:36:48,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:48,609 INFO:     Epoch: 60
2022-11-18 02:36:49,388 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7747376249595122, 'Total loss': 0.7747376249595122} | train loss {'Reaction outcome loss': 0.8092563155918352, 'Total loss': 0.8092563155918352}
2022-11-18 02:36:49,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:49,388 INFO:     Epoch: 61
2022-11-18 02:36:50,181 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7752435905012217, 'Total loss': 0.7752435905012217} | train loss {'Reaction outcome loss': 0.8125008928679651, 'Total loss': 0.8125008928679651}
2022-11-18 02:36:50,181 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:50,181 INFO:     Epoch: 62
2022-11-18 02:36:50,988 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7804770537398078, 'Total loss': 0.7804770537398078} | train loss {'Reaction outcome loss': 0.811576160211717, 'Total loss': 0.811576160211717}
2022-11-18 02:36:50,988 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:50,988 INFO:     Epoch: 63
2022-11-18 02:36:51,767 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7777952653440562, 'Total loss': 0.7777952653440562} | train loss {'Reaction outcome loss': 0.8106369944589753, 'Total loss': 0.8106369944589753}
2022-11-18 02:36:51,767 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:51,767 INFO:     Epoch: 64
2022-11-18 02:36:52,559 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7683174603364684, 'Total loss': 0.7683174603364684} | train loss {'Reaction outcome loss': 0.8096641153097153, 'Total loss': 0.8096641153097153}
2022-11-18 02:36:52,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:52,559 INFO:     Epoch: 65
2022-11-18 02:36:53,354 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7819548852064393, 'Total loss': 0.7819548852064393} | train loss {'Reaction outcome loss': 0.806126999758905, 'Total loss': 0.806126999758905}
2022-11-18 02:36:53,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:53,355 INFO:     Epoch: 66
2022-11-18 02:36:54,154 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.783218656073917, 'Total loss': 0.783218656073917} | train loss {'Reaction outcome loss': 0.8138960297069242, 'Total loss': 0.8138960297069242}
2022-11-18 02:36:54,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:54,154 INFO:     Epoch: 67
2022-11-18 02:36:54,942 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.7721489715305242, 'Total loss': 0.7721489715305242} | train loss {'Reaction outcome loss': 0.8135861548925599, 'Total loss': 0.8135861548925599}
2022-11-18 02:36:54,942 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:54,942 INFO:     Epoch: 68
2022-11-18 02:36:55,734 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.763447804884477, 'Total loss': 0.763447804884477} | train loss {'Reaction outcome loss': 0.8110997581914547, 'Total loss': 0.8110997581914547}
2022-11-18 02:36:55,734 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:55,734 INFO:     Epoch: 69
2022-11-18 02:36:56,544 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7666583447293802, 'Total loss': 0.7666583447293802} | train loss {'Reaction outcome loss': 0.8113192968190678, 'Total loss': 0.8113192968190678}
2022-11-18 02:36:56,544 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:56,544 INFO:     Epoch: 70
2022-11-18 02:36:57,341 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7832156771963293, 'Total loss': 0.7832156771963293} | train loss {'Reaction outcome loss': 0.8128709789485701, 'Total loss': 0.8128709789485701}
2022-11-18 02:36:57,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:57,342 INFO:     Epoch: 71
2022-11-18 02:36:58,120 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7741756175052036, 'Total loss': 0.7741756175052036} | train loss {'Reaction outcome loss': 0.8056960141947193, 'Total loss': 0.8056960141947193}
2022-11-18 02:36:58,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:58,121 INFO:     Epoch: 72
2022-11-18 02:36:58,895 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7605770921165292, 'Total loss': 0.7605770921165292} | train loss {'Reaction outcome loss': 0.8095012420127469, 'Total loss': 0.8095012420127469}
2022-11-18 02:36:58,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:58,895 INFO:     Epoch: 73
2022-11-18 02:36:59,688 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.7798609300093218, 'Total loss': 0.7798609300093218} | train loss {'Reaction outcome loss': 0.8093660128933768, 'Total loss': 0.8093660128933768}
2022-11-18 02:36:59,688 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:36:59,688 INFO:     Epoch: 74
2022-11-18 02:37:00,487 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.790032949637283, 'Total loss': 0.790032949637283} | train loss {'Reaction outcome loss': 0.8081079311668873, 'Total loss': 0.8081079311668873}
2022-11-18 02:37:00,488 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:00,488 INFO:     Epoch: 75
2022-11-18 02:37:01,264 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.788828507065773, 'Total loss': 0.788828507065773} | train loss {'Reaction outcome loss': 0.8124860435003235, 'Total loss': 0.8124860435003235}
2022-11-18 02:37:01,264 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:01,264 INFO:     Epoch: 76
2022-11-18 02:37:02,047 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7942477877844464, 'Total loss': 0.7942477877844464} | train loss {'Reaction outcome loss': 0.8096667928320747, 'Total loss': 0.8096667928320747}
2022-11-18 02:37:02,047 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:02,047 INFO:     Epoch: 77
2022-11-18 02:37:02,854 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7726231921802867, 'Total loss': 0.7726231921802867} | train loss {'Reaction outcome loss': 0.8097192220870526, 'Total loss': 0.8097192220870526}
2022-11-18 02:37:02,854 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:02,854 INFO:     Epoch: 78
2022-11-18 02:37:03,631 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.7664303657683459, 'Total loss': 0.7664303657683459} | train loss {'Reaction outcome loss': 0.8078265688832729, 'Total loss': 0.8078265688832729}
2022-11-18 02:37:03,631 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:03,631 INFO:     Epoch: 79
2022-11-18 02:37:04,414 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7755125313997269, 'Total loss': 0.7755125313997269} | train loss {'Reaction outcome loss': 0.8093976266682148, 'Total loss': 0.8093976266682148}
2022-11-18 02:37:04,414 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:04,414 INFO:     Epoch: 80
2022-11-18 02:37:05,202 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.831730688160116, 'Total loss': 0.831730688160116} | train loss {'Reaction outcome loss': 0.8060600419919337, 'Total loss': 0.8060600419919337}
2022-11-18 02:37:05,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:05,203 INFO:     Epoch: 81
2022-11-18 02:37:06,005 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7841492227532647, 'Total loss': 0.7841492227532647} | train loss {'Reaction outcome loss': 0.8049317474567121, 'Total loss': 0.8049317474567121}
2022-11-18 02:37:06,005 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:06,006 INFO:     Epoch: 82
2022-11-18 02:37:06,820 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7911215783520178, 'Total loss': 0.7911215783520178} | train loss {'Reaction outcome loss': 0.805072640699725, 'Total loss': 0.805072640699725}
2022-11-18 02:37:06,821 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:06,821 INFO:     Epoch: 83
2022-11-18 02:37:07,580 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.7752885242754762, 'Total loss': 0.7752885242754762} | train loss {'Reaction outcome loss': 0.8100710948628764, 'Total loss': 0.8100710948628764}
2022-11-18 02:37:07,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:07,580 INFO:     Epoch: 84
2022-11-18 02:37:08,363 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7706139243461869, 'Total loss': 0.7706139243461869} | train loss {'Reaction outcome loss': 0.8123985704395079, 'Total loss': 0.8123985704395079}
2022-11-18 02:37:08,364 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:08,364 INFO:     Epoch: 85
2022-11-18 02:37:09,149 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7766229158098047, 'Total loss': 0.7766229158098047} | train loss {'Reaction outcome loss': 0.8071131059719671, 'Total loss': 0.8071131059719671}
2022-11-18 02:37:09,149 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:09,149 INFO:     Epoch: 86
2022-11-18 02:37:09,932 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.838963002643802, 'Total loss': 0.838963002643802} | train loss {'Reaction outcome loss': 0.807098155781146, 'Total loss': 0.807098155781146}
2022-11-18 02:37:09,932 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:09,932 INFO:     Epoch: 87
2022-11-18 02:37:10,712 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7717411877079443, 'Total loss': 0.7717411877079443} | train loss {'Reaction outcome loss': 0.808088043884885, 'Total loss': 0.808088043884885}
2022-11-18 02:37:10,712 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:10,712 INFO:     Epoch: 88
2022-11-18 02:37:11,515 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8001063615083694, 'Total loss': 0.8001063615083694} | train loss {'Reaction outcome loss': 0.803841786759515, 'Total loss': 0.803841786759515}
2022-11-18 02:37:11,516 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:11,516 INFO:     Epoch: 89
2022-11-18 02:37:12,277 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.770489318126982, 'Total loss': 0.770489318126982} | train loss {'Reaction outcome loss': 0.8080014657349356, 'Total loss': 0.8080014657349356}
2022-11-18 02:37:12,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:12,278 INFO:     Epoch: 90
2022-11-18 02:37:13,061 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7840402099219236, 'Total loss': 0.7840402099219236} | train loss {'Reaction outcome loss': 0.810103565814995, 'Total loss': 0.810103565814995}
2022-11-18 02:37:13,061 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:13,061 INFO:     Epoch: 91
2022-11-18 02:37:13,858 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7755522179332647, 'Total loss': 0.7755522179332647} | train loss {'Reaction outcome loss': 0.8090040138171565, 'Total loss': 0.8090040138171565}
2022-11-18 02:37:13,858 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:13,858 INFO:     Epoch: 92
2022-11-18 02:37:14,635 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.771782245148312, 'Total loss': 0.771782245148312} | train loss {'Reaction outcome loss': 0.8037676993877657, 'Total loss': 0.8037676993877657}
2022-11-18 02:37:14,635 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:14,635 INFO:     Epoch: 93
2022-11-18 02:37:15,421 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7860834104093638, 'Total loss': 0.7860834104093638} | train loss {'Reaction outcome loss': 0.8134459651285603, 'Total loss': 0.8134459651285603}
2022-11-18 02:37:15,421 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:15,421 INFO:     Epoch: 94
2022-11-18 02:37:16,230 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7800619168715044, 'Total loss': 0.7800619168715044} | train loss {'Reaction outcome loss': 0.8087237924337387, 'Total loss': 0.8087237924337387}
2022-11-18 02:37:16,230 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:16,230 INFO:     Epoch: 95
2022-11-18 02:37:17,020 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7720650204203345, 'Total loss': 0.7720650204203345} | train loss {'Reaction outcome loss': 0.8083333838130197, 'Total loss': 0.8083333838130197}
2022-11-18 02:37:17,020 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:17,021 INFO:     Epoch: 96
2022-11-18 02:37:17,799 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7917720878666098, 'Total loss': 0.7917720878666098} | train loss {'Reaction outcome loss': 0.8139525519744042, 'Total loss': 0.8139525519744042}
2022-11-18 02:37:17,799 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:17,800 INFO:     Epoch: 97
2022-11-18 02:37:18,603 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7801313386722044, 'Total loss': 0.7801313386722044} | train loss {'Reaction outcome loss': 0.8040767747067636, 'Total loss': 0.8040767747067636}
2022-11-18 02:37:18,603 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:18,603 INFO:     Epoch: 98
2022-11-18 02:37:19,369 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8110749640248038, 'Total loss': 0.8110749640248038} | train loss {'Reaction outcome loss': 0.807056330444832, 'Total loss': 0.807056330444832}
2022-11-18 02:37:19,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:19,370 INFO:     Epoch: 99
2022-11-18 02:37:20,151 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7697850696065209, 'Total loss': 0.7697850696065209} | train loss {'Reaction outcome loss': 0.811021969563538, 'Total loss': 0.811021969563538}
2022-11-18 02:37:20,151 INFO:     Best model found after epoch 41 of 100.
2022-11-18 02:37:20,152 INFO:   Done with stage: TRAINING
2022-11-18 02:37:20,152 INFO:   Starting stage: EVALUATION
2022-11-18 02:37:20,271 INFO:   Done with stage: EVALUATION
2022-11-18 02:37:20,271 INFO:   Leaving out SEQ value Fold_7
2022-11-18 02:37:20,284 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 02:37:20,284 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:37:20,965 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:37:20,965 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:37:21,036 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:37:21,037 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:37:21,037 INFO:     No hyperparam tuning for this model
2022-11-18 02:37:21,037 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:37:21,037 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:37:21,038 INFO:     None feature selector for col prot
2022-11-18 02:37:21,038 INFO:     None feature selector for col prot
2022-11-18 02:37:21,038 INFO:     None feature selector for col prot
2022-11-18 02:37:21,039 INFO:     None feature selector for col chem
2022-11-18 02:37:21,039 INFO:     None feature selector for col chem
2022-11-18 02:37:21,039 INFO:     None feature selector for col chem
2022-11-18 02:37:21,039 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:37:21,039 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:37:21,041 INFO:     Number of params in model 168571
2022-11-18 02:37:21,044 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:37:21,044 INFO:   Starting stage: TRAINING
2022-11-18 02:37:21,102 INFO:     Val loss before train {'Reaction outcome loss': 1.0267120125618847, 'Total loss': 1.0267120125618847}
2022-11-18 02:37:21,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:21,102 INFO:     Epoch: 0
2022-11-18 02:37:21,868 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8462208238514987, 'Total loss': 0.8462208238514987} | train loss {'Reaction outcome loss': 0.8726745256286884, 'Total loss': 0.8726745256286884}
2022-11-18 02:37:21,868 INFO:     Found new best model at epoch 0
2022-11-18 02:37:21,869 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:21,869 INFO:     Epoch: 1
2022-11-18 02:37:22,670 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8478143296458505, 'Total loss': 0.8478143296458505} | train loss {'Reaction outcome loss': 0.8458281109931498, 'Total loss': 0.8458281109931498}
2022-11-18 02:37:22,670 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:22,670 INFO:     Epoch: 2
2022-11-18 02:37:23,461 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8205376240340146, 'Total loss': 0.8205376240340146} | train loss {'Reaction outcome loss': 0.840778787609054, 'Total loss': 0.840778787609054}
2022-11-18 02:37:23,461 INFO:     Found new best model at epoch 2
2022-11-18 02:37:23,462 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:23,462 INFO:     Epoch: 3
2022-11-18 02:37:24,247 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8228412920778448, 'Total loss': 0.8228412920778448} | train loss {'Reaction outcome loss': 0.8315451775002576, 'Total loss': 0.8315451775002576}
2022-11-18 02:37:24,247 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:24,247 INFO:     Epoch: 4
2022-11-18 02:37:25,015 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8354441360993818, 'Total loss': 0.8354441360993818} | train loss {'Reaction outcome loss': 0.8236566810352117, 'Total loss': 0.8236566810352117}
2022-11-18 02:37:25,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:25,015 INFO:     Epoch: 5
2022-11-18 02:37:25,779 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8161470090801065, 'Total loss': 0.8161470090801065} | train loss {'Reaction outcome loss': 0.8257602228809465, 'Total loss': 0.8257602228809465}
2022-11-18 02:37:25,780 INFO:     Found new best model at epoch 5
2022-11-18 02:37:25,780 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:25,780 INFO:     Epoch: 6
2022-11-18 02:37:26,569 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8222191685980017, 'Total loss': 0.8222191685980017} | train loss {'Reaction outcome loss': 0.8268518215007628, 'Total loss': 0.8268518215007628}
2022-11-18 02:37:26,569 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:26,569 INFO:     Epoch: 7
2022-11-18 02:37:27,337 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8112386505712162, 'Total loss': 0.8112386505712162} | train loss {'Reaction outcome loss': 0.816854523743695, 'Total loss': 0.816854523743695}
2022-11-18 02:37:27,337 INFO:     Found new best model at epoch 7
2022-11-18 02:37:27,338 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:27,338 INFO:     Epoch: 8
2022-11-18 02:37:28,129 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8413223258473657, 'Total loss': 0.8413223258473657} | train loss {'Reaction outcome loss': 0.8188713229136911, 'Total loss': 0.8188713229136911}
2022-11-18 02:37:28,129 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:28,129 INFO:     Epoch: 9
2022-11-18 02:37:28,910 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8321944136511196, 'Total loss': 0.8321944136511196} | train loss {'Reaction outcome loss': 0.8241769157440556, 'Total loss': 0.8241769157440556}
2022-11-18 02:37:28,910 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:28,910 INFO:     Epoch: 10
2022-11-18 02:37:29,695 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8275132023475387, 'Total loss': 0.8275132023475387} | train loss {'Reaction outcome loss': 0.8161196826923232, 'Total loss': 0.8161196826923232}
2022-11-18 02:37:29,695 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:29,695 INFO:     Epoch: 11
2022-11-18 02:37:30,494 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8431639928709377, 'Total loss': 0.8431639928709377} | train loss {'Reaction outcome loss': 0.8123754274989912, 'Total loss': 0.8123754274989912}
2022-11-18 02:37:30,495 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:30,495 INFO:     Epoch: 12
2022-11-18 02:37:31,301 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.8183874697847799, 'Total loss': 0.8183874697847799} | train loss {'Reaction outcome loss': 0.8150554210068244, 'Total loss': 0.8150554210068244}
2022-11-18 02:37:31,302 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:31,302 INFO:     Epoch: 13
2022-11-18 02:37:32,076 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8189366954294118, 'Total loss': 0.8189366954294118} | train loss {'Reaction outcome loss': 0.8070165389462521, 'Total loss': 0.8070165389462521}
2022-11-18 02:37:32,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:32,076 INFO:     Epoch: 14
2022-11-18 02:37:32,836 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.8246175890619104, 'Total loss': 0.8246175890619104} | train loss {'Reaction outcome loss': 0.8093683860803905, 'Total loss': 0.8093683860803905}
2022-11-18 02:37:32,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:32,836 INFO:     Epoch: 15
2022-11-18 02:37:33,620 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8075841434977271, 'Total loss': 0.8075841434977271} | train loss {'Reaction outcome loss': 0.8098482415984999, 'Total loss': 0.8098482415984999}
2022-11-18 02:37:33,620 INFO:     Found new best model at epoch 15
2022-11-18 02:37:33,621 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:33,621 INFO:     Epoch: 16
2022-11-18 02:37:34,434 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8206424564123154, 'Total loss': 0.8206424564123154} | train loss {'Reaction outcome loss': 0.804219270283394, 'Total loss': 0.804219270283394}
2022-11-18 02:37:34,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:34,434 INFO:     Epoch: 17
2022-11-18 02:37:35,227 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.833968342027881, 'Total loss': 0.833968342027881} | train loss {'Reaction outcome loss': 0.8009270085738256, 'Total loss': 0.8009270085738256}
2022-11-18 02:37:35,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:35,227 INFO:     Epoch: 18
2022-11-18 02:37:36,007 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.8153703409162435, 'Total loss': 0.8153703409162435} | train loss {'Reaction outcome loss': 0.8077870541014652, 'Total loss': 0.8077870541014652}
2022-11-18 02:37:36,007 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:36,007 INFO:     Epoch: 19
2022-11-18 02:37:36,814 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.8374786241488024, 'Total loss': 0.8374786241488024} | train loss {'Reaction outcome loss': 0.8049322390845912, 'Total loss': 0.8049322390845912}
2022-11-18 02:37:36,814 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:36,814 INFO:     Epoch: 20
2022-11-18 02:37:37,590 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.8193700557405298, 'Total loss': 0.8193700557405298} | train loss {'Reaction outcome loss': 0.8065987250311413, 'Total loss': 0.8065987250311413}
2022-11-18 02:37:37,591 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:37,591 INFO:     Epoch: 21
2022-11-18 02:37:38,392 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8168119137937372, 'Total loss': 0.8168119137937372} | train loss {'Reaction outcome loss': 0.8103546941811256, 'Total loss': 0.8103546941811256}
2022-11-18 02:37:38,392 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:38,392 INFO:     Epoch: 22
2022-11-18 02:37:39,171 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.815731564706022, 'Total loss': 0.815731564706022} | train loss {'Reaction outcome loss': 0.8088949667780023, 'Total loss': 0.8088949667780023}
2022-11-18 02:37:39,171 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:39,171 INFO:     Epoch: 23
2022-11-18 02:37:39,946 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8174572803757407, 'Total loss': 0.8174572803757407} | train loss {'Reaction outcome loss': 0.8106716120773964, 'Total loss': 0.8106716120773964}
2022-11-18 02:37:39,946 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:39,946 INFO:     Epoch: 24
2022-11-18 02:37:40,720 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.8294131566177715, 'Total loss': 0.8294131566177715} | train loss {'Reaction outcome loss': 0.8117508509381097, 'Total loss': 0.8117508509381097}
2022-11-18 02:37:40,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:40,720 INFO:     Epoch: 25
2022-11-18 02:37:41,497 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8287742700089108, 'Total loss': 0.8287742700089108} | train loss {'Reaction outcome loss': 0.8078186608519149, 'Total loss': 0.8078186608519149}
2022-11-18 02:37:41,497 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:41,497 INFO:     Epoch: 26
2022-11-18 02:37:42,282 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8125347505238923, 'Total loss': 0.8125347505238923} | train loss {'Reaction outcome loss': 0.8103707583568357, 'Total loss': 0.8103707583568357}
2022-11-18 02:37:42,282 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:42,282 INFO:     Epoch: 27
2022-11-18 02:37:43,074 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8241110979156061, 'Total loss': 0.8241110979156061} | train loss {'Reaction outcome loss': 0.8031965377420066, 'Total loss': 0.8031965377420066}
2022-11-18 02:37:43,074 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:43,075 INFO:     Epoch: 28
2022-11-18 02:37:43,841 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.8012560524723746, 'Total loss': 0.8012560524723746} | train loss {'Reaction outcome loss': 0.800913598750405, 'Total loss': 0.800913598750405}
2022-11-18 02:37:43,841 INFO:     Found new best model at epoch 28
2022-11-18 02:37:43,842 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:43,842 INFO:     Epoch: 29
2022-11-18 02:37:44,628 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8083459105003964, 'Total loss': 0.8083459105003964} | train loss {'Reaction outcome loss': 0.8018143219262482, 'Total loss': 0.8018143219262482}
2022-11-18 02:37:44,628 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:44,628 INFO:     Epoch: 30
2022-11-18 02:37:45,395 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.8026210882446982, 'Total loss': 0.8026210882446982} | train loss {'Reaction outcome loss': 0.8067792475163212, 'Total loss': 0.8067792475163212}
2022-11-18 02:37:45,395 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:45,395 INFO:     Epoch: 31
2022-11-18 02:37:46,153 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.8198797106742859, 'Total loss': 0.8198797106742859} | train loss {'Reaction outcome loss': 0.8002352857366506, 'Total loss': 0.8002352857366506}
2022-11-18 02:37:46,154 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:46,154 INFO:     Epoch: 32
2022-11-18 02:37:46,936 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.8076894879341125, 'Total loss': 0.8076894879341125} | train loss {'Reaction outcome loss': 0.8053323240415288, 'Total loss': 0.8053323240415288}
2022-11-18 02:37:46,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:46,936 INFO:     Epoch: 33
2022-11-18 02:37:47,713 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8074187995357947, 'Total loss': 0.8074187995357947} | train loss {'Reaction outcome loss': 0.8039054258873588, 'Total loss': 0.8039054258873588}
2022-11-18 02:37:47,713 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:47,713 INFO:     Epoch: 34
2022-11-18 02:37:48,504 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8095718974416907, 'Total loss': 0.8095718974416907} | train loss {'Reaction outcome loss': 0.8011520606001862, 'Total loss': 0.8011520606001862}
2022-11-18 02:37:48,504 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:48,504 INFO:     Epoch: 35
2022-11-18 02:37:49,318 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.8129468201236292, 'Total loss': 0.8129468201236292} | train loss {'Reaction outcome loss': 0.8070166333001635, 'Total loss': 0.8070166333001635}
2022-11-18 02:37:49,318 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:49,318 INFO:     Epoch: 36
2022-11-18 02:37:50,162 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.819041949104179, 'Total loss': 0.819041949104179} | train loss {'Reaction outcome loss': 0.8119867371644086, 'Total loss': 0.8119867371644086}
2022-11-18 02:37:50,163 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:50,163 INFO:     Epoch: 37
2022-11-18 02:37:50,984 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7956826104359194, 'Total loss': 0.7956826104359194} | train loss {'Reaction outcome loss': 0.8066804824087784, 'Total loss': 0.8066804824087784}
2022-11-18 02:37:50,984 INFO:     Found new best model at epoch 37
2022-11-18 02:37:50,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:50,985 INFO:     Epoch: 38
2022-11-18 02:37:51,784 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.8150929754430597, 'Total loss': 0.8150929754430597} | train loss {'Reaction outcome loss': 0.8013432716671754, 'Total loss': 0.8013432716671754}
2022-11-18 02:37:51,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:51,784 INFO:     Epoch: 39
2022-11-18 02:37:52,609 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.8058969195593487, 'Total loss': 0.8058969195593487} | train loss {'Reaction outcome loss': 0.8040686860861566, 'Total loss': 0.8040686860861566}
2022-11-18 02:37:52,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:52,609 INFO:     Epoch: 40
2022-11-18 02:37:53,403 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.8135247440500692, 'Total loss': 0.8135247440500692} | train loss {'Reaction outcome loss': 0.7980072939926796, 'Total loss': 0.7980072939926796}
2022-11-18 02:37:53,404 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:53,404 INFO:     Epoch: 41
2022-11-18 02:37:54,193 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8235857649282976, 'Total loss': 0.8235857649282976} | train loss {'Reaction outcome loss': 0.8092517880534353, 'Total loss': 0.8092517880534353}
2022-11-18 02:37:54,193 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:54,193 INFO:     Epoch: 42
2022-11-18 02:37:54,972 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.8119282079013911, 'Total loss': 0.8119282079013911} | train loss {'Reaction outcome loss': 0.8002986199701363, 'Total loss': 0.8002986199701363}
2022-11-18 02:37:54,973 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:54,973 INFO:     Epoch: 43
2022-11-18 02:37:55,777 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.8169112903150645, 'Total loss': 0.8169112903150645} | train loss {'Reaction outcome loss': 0.8031445047874682, 'Total loss': 0.8031445047874682}
2022-11-18 02:37:55,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:55,777 INFO:     Epoch: 44
2022-11-18 02:37:56,585 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.8128719465299086, 'Total loss': 0.8128719465299086} | train loss {'Reaction outcome loss': 0.8011279085628417, 'Total loss': 0.8011279085628417}
2022-11-18 02:37:56,585 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:56,586 INFO:     Epoch: 45
2022-11-18 02:37:57,388 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8133340058001605, 'Total loss': 0.8133340058001605} | train loss {'Reaction outcome loss': 0.8106141420993728, 'Total loss': 0.8106141420993728}
2022-11-18 02:37:57,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:57,388 INFO:     Epoch: 46
2022-11-18 02:37:58,207 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.8563097038052299, 'Total loss': 0.8563097038052299} | train loss {'Reaction outcome loss': 0.8264850117417, 'Total loss': 0.8264850117417}
2022-11-18 02:37:58,207 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:58,207 INFO:     Epoch: 47
2022-11-18 02:37:59,016 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.8119367117231543, 'Total loss': 0.8119367117231543} | train loss {'Reaction outcome loss': 0.8215439614014104, 'Total loss': 0.8215439614014104}
2022-11-18 02:37:59,016 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:59,016 INFO:     Epoch: 48
2022-11-18 02:37:59,830 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.8278549584475431, 'Total loss': 0.8278549584475431} | train loss {'Reaction outcome loss': 0.8103328331520683, 'Total loss': 0.8103328331520683}
2022-11-18 02:37:59,830 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:37:59,830 INFO:     Epoch: 49
2022-11-18 02:38:00,618 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.8392782109704885, 'Total loss': 0.8392782109704885} | train loss {'Reaction outcome loss': 0.8103077755524561, 'Total loss': 0.8103077755524561}
2022-11-18 02:38:00,618 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:00,619 INFO:     Epoch: 50
2022-11-18 02:38:01,454 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8467975814234127, 'Total loss': 0.8467975814234127} | train loss {'Reaction outcome loss': 0.801450571309217, 'Total loss': 0.801450571309217}
2022-11-18 02:38:01,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:01,454 INFO:     Epoch: 51
2022-11-18 02:38:02,270 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.8148133930834857, 'Total loss': 0.8148133930834857} | train loss {'Reaction outcome loss': 0.801154915017155, 'Total loss': 0.801154915017155}
2022-11-18 02:38:02,270 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:02,270 INFO:     Epoch: 52
2022-11-18 02:38:03,065 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.799988257614049, 'Total loss': 0.799988257614049} | train loss {'Reaction outcome loss': 0.8059746900550749, 'Total loss': 0.8059746900550749}
2022-11-18 02:38:03,066 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:03,066 INFO:     Epoch: 53
2022-11-18 02:38:03,836 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.8112620528448712, 'Total loss': 0.8112620528448712} | train loss {'Reaction outcome loss': 0.8061250757109298, 'Total loss': 0.8061250757109298}
2022-11-18 02:38:03,836 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:03,837 INFO:     Epoch: 54
2022-11-18 02:38:04,655 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.8229963928461075, 'Total loss': 0.8229963928461075} | train loss {'Reaction outcome loss': 0.8063456045712537, 'Total loss': 0.8063456045712537}
2022-11-18 02:38:04,655 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:04,655 INFO:     Epoch: 55
2022-11-18 02:38:05,478 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.840598380023783, 'Total loss': 0.840598380023783} | train loss {'Reaction outcome loss': 0.8048528389409486, 'Total loss': 0.8048528389409486}
2022-11-18 02:38:05,479 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:05,479 INFO:     Epoch: 56
2022-11-18 02:38:06,277 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8298111273483797, 'Total loss': 0.8298111273483797} | train loss {'Reaction outcome loss': 0.8002821795853526, 'Total loss': 0.8002821795853526}
2022-11-18 02:38:06,277 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:06,277 INFO:     Epoch: 57
2022-11-18 02:38:07,089 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8311524966900999, 'Total loss': 0.8311524966900999} | train loss {'Reaction outcome loss': 0.7986567259317467, 'Total loss': 0.7986567259317467}
2022-11-18 02:38:07,089 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:07,089 INFO:     Epoch: 58
2022-11-18 02:38:07,870 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8192154128443111, 'Total loss': 0.8192154128443111} | train loss {'Reaction outcome loss': 0.8049805295853479, 'Total loss': 0.8049805295853479}
2022-11-18 02:38:07,870 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:07,870 INFO:     Epoch: 59
2022-11-18 02:38:08,668 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.8179751133376901, 'Total loss': 0.8179751133376901} | train loss {'Reaction outcome loss': 0.805435812907663, 'Total loss': 0.805435812907663}
2022-11-18 02:38:08,668 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:08,668 INFO:     Epoch: 60
2022-11-18 02:38:09,492 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.8105708143927834, 'Total loss': 0.8105708143927834} | train loss {'Reaction outcome loss': 0.8027179948231469, 'Total loss': 0.8027179948231469}
2022-11-18 02:38:09,493 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:09,493 INFO:     Epoch: 61
2022-11-18 02:38:10,288 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.8334113420410589, 'Total loss': 0.8334113420410589} | train loss {'Reaction outcome loss': 0.8055573298637322, 'Total loss': 0.8055573298637322}
2022-11-18 02:38:10,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:10,289 INFO:     Epoch: 62
2022-11-18 02:38:11,110 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.8005208163098856, 'Total loss': 0.8005208163098856} | train loss {'Reaction outcome loss': 0.804531166850314, 'Total loss': 0.804531166850314}
2022-11-18 02:38:11,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:11,110 INFO:     Epoch: 63
2022-11-18 02:38:11,902 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8046699924902483, 'Total loss': 0.8046699924902483} | train loss {'Reaction outcome loss': 0.8062546165124608, 'Total loss': 0.8062546165124608}
2022-11-18 02:38:11,902 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:11,902 INFO:     Epoch: 64
2022-11-18 02:38:12,751 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8000877059318803, 'Total loss': 0.8000877059318803} | train loss {'Reaction outcome loss': 0.8088002250744746, 'Total loss': 0.8088002250744746}
2022-11-18 02:38:12,751 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:12,751 INFO:     Epoch: 65
2022-11-18 02:38:13,551 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.8108652288263495, 'Total loss': 0.8108652288263495} | train loss {'Reaction outcome loss': 0.8059112565961444, 'Total loss': 0.8059112565961444}
2022-11-18 02:38:13,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:13,552 INFO:     Epoch: 66
2022-11-18 02:38:14,346 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.8191068809140812, 'Total loss': 0.8191068809140812} | train loss {'Reaction outcome loss': 0.8064590028905676, 'Total loss': 0.8064590028905676}
2022-11-18 02:38:14,346 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:14,346 INFO:     Epoch: 67
2022-11-18 02:38:15,153 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.8504306775602427, 'Total loss': 0.8504306775602427} | train loss {'Reaction outcome loss': 0.8073918289742489, 'Total loss': 0.8073918289742489}
2022-11-18 02:38:15,153 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:15,153 INFO:     Epoch: 68
2022-11-18 02:38:15,951 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8190520202571695, 'Total loss': 0.8190520202571695} | train loss {'Reaction outcome loss': 0.7980758877780273, 'Total loss': 0.7980758877780273}
2022-11-18 02:38:15,951 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:15,951 INFO:     Epoch: 69
2022-11-18 02:38:16,771 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.8163402236320756, 'Total loss': 0.8163402236320756} | train loss {'Reaction outcome loss': 0.7954261383335841, 'Total loss': 0.7954261383335841}
2022-11-18 02:38:16,771 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:16,771 INFO:     Epoch: 70
2022-11-18 02:38:17,547 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.8094019747593186, 'Total loss': 0.8094019747593186} | train loss {'Reaction outcome loss': 0.8035019285343437, 'Total loss': 0.8035019285343437}
2022-11-18 02:38:17,548 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:17,548 INFO:     Epoch: 71
2022-11-18 02:38:18,371 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8231048387559977, 'Total loss': 0.8231048387559977} | train loss {'Reaction outcome loss': 0.8068274604646783, 'Total loss': 0.8068274604646783}
2022-11-18 02:38:18,371 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:18,372 INFO:     Epoch: 72
2022-11-18 02:38:19,178 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8107268031347882, 'Total loss': 0.8107268031347882} | train loss {'Reaction outcome loss': 0.7989269887749483, 'Total loss': 0.7989269887749483}
2022-11-18 02:38:19,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:19,178 INFO:     Epoch: 73
2022-11-18 02:38:19,971 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.8182566640051928, 'Total loss': 0.8182566640051928} | train loss {'Reaction outcome loss': 0.8009602644062235, 'Total loss': 0.8009602644062235}
2022-11-18 02:38:19,971 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:19,971 INFO:     Epoch: 74
2022-11-18 02:38:20,784 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.8121630149808797, 'Total loss': 0.8121630149808797} | train loss {'Reaction outcome loss': 0.807302170074903, 'Total loss': 0.807302170074903}
2022-11-18 02:38:20,785 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:20,785 INFO:     Epoch: 75
2022-11-18 02:38:21,552 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.8126175606792624, 'Total loss': 0.8126175606792624} | train loss {'Reaction outcome loss': 0.8035630778021176, 'Total loss': 0.8035630778021176}
2022-11-18 02:38:21,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:21,553 INFO:     Epoch: 76
2022-11-18 02:38:22,397 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.800887600264766, 'Total loss': 0.800887600264766} | train loss {'Reaction outcome loss': 0.8000527087010836, 'Total loss': 0.8000527087010836}
2022-11-18 02:38:22,397 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:22,398 INFO:     Epoch: 77
2022-11-18 02:38:23,215 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.8068264099684629, 'Total loss': 0.8068264099684629} | train loss {'Reaction outcome loss': 0.8002970464799085, 'Total loss': 0.8002970464799085}
2022-11-18 02:38:23,215 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:23,215 INFO:     Epoch: 78
2022-11-18 02:38:24,060 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8176582320169969, 'Total loss': 0.8176582320169969} | train loss {'Reaction outcome loss': 0.8069770111728777, 'Total loss': 0.8069770111728777}
2022-11-18 02:38:24,060 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:24,060 INFO:     Epoch: 79
2022-11-18 02:38:24,853 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.8173082796010104, 'Total loss': 0.8173082796010104} | train loss {'Reaction outcome loss': 0.8116519696075424, 'Total loss': 0.8116519696075424}
2022-11-18 02:38:24,853 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:24,853 INFO:     Epoch: 80
2022-11-18 02:38:25,665 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.8327667327089743, 'Total loss': 0.8327667327089743} | train loss {'Reaction outcome loss': 0.8131192390494019, 'Total loss': 0.8131192390494019}
2022-11-18 02:38:25,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:25,665 INFO:     Epoch: 81
2022-11-18 02:38:26,473 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8314132568511096, 'Total loss': 0.8314132568511096} | train loss {'Reaction outcome loss': 0.8015711057765281, 'Total loss': 0.8015711057765281}
2022-11-18 02:38:26,474 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:26,474 INFO:     Epoch: 82
2022-11-18 02:38:27,249 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.79261215031147, 'Total loss': 0.79261215031147} | train loss {'Reaction outcome loss': 0.7988420779466147, 'Total loss': 0.7988420779466147}
2022-11-18 02:38:27,249 INFO:     Found new best model at epoch 82
2022-11-18 02:38:27,250 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:27,250 INFO:     Epoch: 83
2022-11-18 02:38:28,035 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8165238777344878, 'Total loss': 0.8165238777344878} | train loss {'Reaction outcome loss': 0.7976429577660464, 'Total loss': 0.7976429577660464}
2022-11-18 02:38:28,035 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:28,035 INFO:     Epoch: 84
2022-11-18 02:38:28,845 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7940838594328273, 'Total loss': 0.7940838594328273} | train loss {'Reaction outcome loss': 0.8012835923959369, 'Total loss': 0.8012835923959369}
2022-11-18 02:38:28,845 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:28,845 INFO:     Epoch: 85
2022-11-18 02:38:29,691 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.8098734563047235, 'Total loss': 0.8098734563047235} | train loss {'Reaction outcome loss': 0.7995721207335893, 'Total loss': 0.7995721207335893}
2022-11-18 02:38:29,691 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:29,692 INFO:     Epoch: 86
2022-11-18 02:38:30,498 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.8377967700362206, 'Total loss': 0.8377967700362206} | train loss {'Reaction outcome loss': 0.8049251245342286, 'Total loss': 0.8049251245342286}
2022-11-18 02:38:30,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:30,498 INFO:     Epoch: 87
2022-11-18 02:38:31,341 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8143784593452107, 'Total loss': 0.8143784593452107} | train loss {'Reaction outcome loss': 0.8052806792109601, 'Total loss': 0.8052806792109601}
2022-11-18 02:38:31,342 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:31,342 INFO:     Epoch: 88
2022-11-18 02:38:32,147 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.8133011995391413, 'Total loss': 0.8133011995391413} | train loss {'Reaction outcome loss': 0.7978933785367108, 'Total loss': 0.7978933785367108}
2022-11-18 02:38:32,147 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:32,147 INFO:     Epoch: 89
2022-11-18 02:38:32,949 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.8176473582332785, 'Total loss': 0.8176473582332785} | train loss {'Reaction outcome loss': 0.7974785917442337, 'Total loss': 0.7974785917442337}
2022-11-18 02:38:32,949 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:32,949 INFO:     Epoch: 90
2022-11-18 02:38:33,775 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.8415541012178768, 'Total loss': 0.8415541012178768} | train loss {'Reaction outcome loss': 0.8080307421413994, 'Total loss': 0.8080307421413994}
2022-11-18 02:38:33,776 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:33,776 INFO:     Epoch: 91
2022-11-18 02:38:34,604 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8093753721226346, 'Total loss': 0.8093753721226346} | train loss {'Reaction outcome loss': 0.8053359707236772, 'Total loss': 0.8053359707236772}
2022-11-18 02:38:34,604 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:34,604 INFO:     Epoch: 92
2022-11-18 02:38:35,410 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.813770207491788, 'Total loss': 0.813770207491788} | train loss {'Reaction outcome loss': 0.8098516656078307, 'Total loss': 0.8098516656078307}
2022-11-18 02:38:35,410 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:35,410 INFO:     Epoch: 93
2022-11-18 02:38:36,223 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8009971867908131, 'Total loss': 0.8009971867908131} | train loss {'Reaction outcome loss': 0.7989709380908534, 'Total loss': 0.7989709380908534}
2022-11-18 02:38:36,223 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:36,224 INFO:     Epoch: 94
2022-11-18 02:38:37,028 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7986543517221104, 'Total loss': 0.7986543517221104} | train loss {'Reaction outcome loss': 0.8029418675764369, 'Total loss': 0.8029418675764369}
2022-11-18 02:38:37,028 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:37,028 INFO:     Epoch: 95
2022-11-18 02:38:37,881 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.819226204671643, 'Total loss': 0.819226204671643} | train loss {'Reaction outcome loss': 0.8025003594425526, 'Total loss': 0.8025003594425526}
2022-11-18 02:38:37,881 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:37,881 INFO:     Epoch: 96
2022-11-18 02:38:38,687 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.8088737082752314, 'Total loss': 0.8088737082752314} | train loss {'Reaction outcome loss': 0.8025421337017163, 'Total loss': 0.8025421337017163}
2022-11-18 02:38:38,687 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:38,687 INFO:     Epoch: 97
2022-11-18 02:38:39,478 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.8088279739022255, 'Total loss': 0.8088279739022255} | train loss {'Reaction outcome loss': 0.7947119005959526, 'Total loss': 0.7947119005959526}
2022-11-18 02:38:39,478 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:39,478 INFO:     Epoch: 98
2022-11-18 02:38:40,298 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.8140798881649971, 'Total loss': 0.8140798881649971} | train loss {'Reaction outcome loss': 0.8074223793711257, 'Total loss': 0.8074223793711257}
2022-11-18 02:38:40,299 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:40,299 INFO:     Epoch: 99
2022-11-18 02:38:41,099 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.835815126245672, 'Total loss': 0.835815126245672} | train loss {'Reaction outcome loss': 0.8079562681889244, 'Total loss': 0.8079562681889244}
2022-11-18 02:38:41,099 INFO:     Best model found after epoch 83 of 100.
2022-11-18 02:38:41,099 INFO:   Done with stage: TRAINING
2022-11-18 02:38:41,099 INFO:   Starting stage: EVALUATION
2022-11-18 02:38:41,224 INFO:   Done with stage: EVALUATION
2022-11-18 02:38:41,225 INFO:   Leaving out SEQ value Fold_8
2022-11-18 02:38:41,238 INFO:   examples: 20,544| examples in train: 15,667 | examples in val: 2,765| examples in test: 2,112
2022-11-18 02:38:41,238 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:38:41,906 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:38:41,906 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:38:41,975 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:38:41,975 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:38:41,975 INFO:     No hyperparam tuning for this model
2022-11-18 02:38:41,975 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:38:41,975 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:38:41,976 INFO:     None feature selector for col prot
2022-11-18 02:38:41,976 INFO:     None feature selector for col prot
2022-11-18 02:38:41,977 INFO:     None feature selector for col prot
2022-11-18 02:38:41,977 INFO:     None feature selector for col chem
2022-11-18 02:38:41,977 INFO:     None feature selector for col chem
2022-11-18 02:38:41,977 INFO:     None feature selector for col chem
2022-11-18 02:38:41,977 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:38:41,977 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:38:41,979 INFO:     Number of params in model 168571
2022-11-18 02:38:41,982 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:38:41,982 INFO:   Starting stage: TRAINING
2022-11-18 02:38:42,041 INFO:     Val loss before train {'Reaction outcome loss': 0.9555081156167117, 'Total loss': 0.9555081156167117}
2022-11-18 02:38:42,041 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:42,041 INFO:     Epoch: 0
2022-11-18 02:38:42,846 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8101208325136792, 'Total loss': 0.8101208325136792} | train loss {'Reaction outcome loss': 0.8791587533999462, 'Total loss': 0.8791587533999462}
2022-11-18 02:38:42,846 INFO:     Found new best model at epoch 0
2022-11-18 02:38:42,847 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:42,847 INFO:     Epoch: 1
2022-11-18 02:38:43,658 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.783258277584206, 'Total loss': 0.783258277584206} | train loss {'Reaction outcome loss': 0.8472541509842386, 'Total loss': 0.8472541509842386}
2022-11-18 02:38:43,658 INFO:     Found new best model at epoch 1
2022-11-18 02:38:43,659 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:43,659 INFO:     Epoch: 2
2022-11-18 02:38:44,484 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8010950447483496, 'Total loss': 0.8010950447483496} | train loss {'Reaction outcome loss': 0.8459254577451822, 'Total loss': 0.8459254577451822}
2022-11-18 02:38:44,485 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:44,485 INFO:     Epoch: 3
2022-11-18 02:38:45,267 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.7801043398000977, 'Total loss': 0.7801043398000977} | train loss {'Reaction outcome loss': 0.843793348511871, 'Total loss': 0.843793348511871}
2022-11-18 02:38:45,267 INFO:     Found new best model at epoch 3
2022-11-18 02:38:45,268 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:45,268 INFO:     Epoch: 4
2022-11-18 02:38:46,052 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.802981201897968, 'Total loss': 0.802981201897968} | train loss {'Reaction outcome loss': 0.842501146817694, 'Total loss': 0.842501146817694}
2022-11-18 02:38:46,052 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:46,052 INFO:     Epoch: 5
2022-11-18 02:38:46,841 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.806477768177336, 'Total loss': 0.806477768177336} | train loss {'Reaction outcome loss': 0.8418650166112549, 'Total loss': 0.8418650166112549}
2022-11-18 02:38:46,841 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:46,841 INFO:     Epoch: 6
2022-11-18 02:38:47,639 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.7904644405299966, 'Total loss': 0.7904644405299966} | train loss {'Reaction outcome loss': 0.8362987288406917, 'Total loss': 0.8362987288406917}
2022-11-18 02:38:47,639 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:47,639 INFO:     Epoch: 7
2022-11-18 02:38:48,434 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.7857457710938021, 'Total loss': 0.7857457710938021} | train loss {'Reaction outcome loss': 0.8359165438583919, 'Total loss': 0.8359165438583919}
2022-11-18 02:38:48,434 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:48,434 INFO:     Epoch: 8
2022-11-18 02:38:49,229 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.7898314757780596, 'Total loss': 0.7898314757780596} | train loss {'Reaction outcome loss': 0.8265722059473699, 'Total loss': 0.8265722059473699}
2022-11-18 02:38:49,229 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:49,229 INFO:     Epoch: 9
2022-11-18 02:38:50,022 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.800164058804512, 'Total loss': 0.800164058804512} | train loss {'Reaction outcome loss': 0.827442790172538, 'Total loss': 0.827442790172538}
2022-11-18 02:38:50,023 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:50,023 INFO:     Epoch: 10
2022-11-18 02:38:50,777 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.7957145646214485, 'Total loss': 0.7957145646214485} | train loss {'Reaction outcome loss': 0.8245176287329927, 'Total loss': 0.8245176287329927}
2022-11-18 02:38:50,777 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:50,778 INFO:     Epoch: 11
2022-11-18 02:38:51,553 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.7880640111186288, 'Total loss': 0.7880640111186288} | train loss {'Reaction outcome loss': 0.825744754927499, 'Total loss': 0.825744754927499}
2022-11-18 02:38:51,553 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:51,553 INFO:     Epoch: 12
2022-11-18 02:38:52,326 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7832408527081663, 'Total loss': 0.7832408527081663} | train loss {'Reaction outcome loss': 0.8222064456161188, 'Total loss': 0.8222064456161188}
2022-11-18 02:38:52,327 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:52,327 INFO:     Epoch: 13
2022-11-18 02:38:53,137 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.7951455820690502, 'Total loss': 0.7951455820690502} | train loss {'Reaction outcome loss': 0.8209545557596245, 'Total loss': 0.8209545557596245}
2022-11-18 02:38:53,137 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:53,137 INFO:     Epoch: 14
2022-11-18 02:38:53,936 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7829597903923555, 'Total loss': 0.7829597903923555} | train loss {'Reaction outcome loss': 0.8233251833185857, 'Total loss': 0.8233251833185857}
2022-11-18 02:38:53,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:53,936 INFO:     Epoch: 15
2022-11-18 02:38:54,724 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.8006875948472456, 'Total loss': 0.8006875948472456} | train loss {'Reaction outcome loss': 0.8204590599147641, 'Total loss': 0.8204590599147641}
2022-11-18 02:38:54,724 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:54,724 INFO:     Epoch: 16
2022-11-18 02:38:55,484 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.7910070581869646, 'Total loss': 0.7910070581869646} | train loss {'Reaction outcome loss': 0.819954693074129, 'Total loss': 0.819954693074129}
2022-11-18 02:38:55,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:55,484 INFO:     Epoch: 17
2022-11-18 02:38:56,289 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.7828918681903319, 'Total loss': 0.7828918681903319} | train loss {'Reaction outcome loss': 0.816824191322132, 'Total loss': 0.816824191322132}
2022-11-18 02:38:56,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:56,289 INFO:     Epoch: 18
2022-11-18 02:38:57,119 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7652901621027426, 'Total loss': 0.7652901621027426} | train loss {'Reaction outcome loss': 0.8197694685994362, 'Total loss': 0.8197694685994362}
2022-11-18 02:38:57,119 INFO:     Found new best model at epoch 18
2022-11-18 02:38:57,120 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:57,120 INFO:     Epoch: 19
2022-11-18 02:38:57,953 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.7854067073626951, 'Total loss': 0.7854067073626951} | train loss {'Reaction outcome loss': 0.8168807635501939, 'Total loss': 0.8168807635501939}
2022-11-18 02:38:57,953 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:57,953 INFO:     Epoch: 20
2022-11-18 02:38:58,731 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7765416198156097, 'Total loss': 0.7765416198156097} | train loss {'Reaction outcome loss': 0.8192262124042122, 'Total loss': 0.8192262124042122}
2022-11-18 02:38:58,731 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:58,731 INFO:     Epoch: 21
2022-11-18 02:38:59,587 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.7888402627273039, 'Total loss': 0.7888402627273039} | train loss {'Reaction outcome loss': 0.8195188011441912, 'Total loss': 0.8195188011441912}
2022-11-18 02:38:59,587 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:38:59,587 INFO:     Epoch: 22
2022-11-18 02:39:00,426 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.772778332233429, 'Total loss': 0.772778332233429} | train loss {'Reaction outcome loss': 0.8184513388847818, 'Total loss': 0.8184513388847818}
2022-11-18 02:39:00,426 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:00,426 INFO:     Epoch: 23
2022-11-18 02:39:01,258 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.784148899668997, 'Total loss': 0.784148899668997} | train loss {'Reaction outcome loss': 0.8189738932920962, 'Total loss': 0.8189738932920962}
2022-11-18 02:39:01,258 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:01,258 INFO:     Epoch: 24
2022-11-18 02:39:02,053 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7944760566407983, 'Total loss': 0.7944760566407983} | train loss {'Reaction outcome loss': 0.8188849977692779, 'Total loss': 0.8188849977692779}
2022-11-18 02:39:02,053 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:02,053 INFO:     Epoch: 25
2022-11-18 02:39:02,872 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.7705916728485714, 'Total loss': 0.7705916728485714} | train loss {'Reaction outcome loss': 0.8155942274599659, 'Total loss': 0.8155942274599659}
2022-11-18 02:39:02,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:02,873 INFO:     Epoch: 26
2022-11-18 02:39:03,629 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8014223426580429, 'Total loss': 0.8014223426580429} | train loss {'Reaction outcome loss': 0.8211161843367986, 'Total loss': 0.8211161843367986}
2022-11-18 02:39:03,629 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:03,629 INFO:     Epoch: 27
2022-11-18 02:39:04,438 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.7843146087093786, 'Total loss': 0.7843146087093786} | train loss {'Reaction outcome loss': 0.8210784358637674, 'Total loss': 0.8210784358637674}
2022-11-18 02:39:04,439 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:04,439 INFO:     Epoch: 28
2022-11-18 02:39:05,267 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7831447124481201, 'Total loss': 0.7831447124481201} | train loss {'Reaction outcome loss': 0.8172860022710294, 'Total loss': 0.8172860022710294}
2022-11-18 02:39:05,269 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:05,269 INFO:     Epoch: 29
2022-11-18 02:39:06,076 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.7973540852015669, 'Total loss': 0.7973540852015669} | train loss {'Reaction outcome loss': 0.8235105681176088, 'Total loss': 0.8235105681176088}
2022-11-18 02:39:06,076 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:06,076 INFO:     Epoch: 30
2022-11-18 02:39:06,873 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.770164274356582, 'Total loss': 0.770164274356582} | train loss {'Reaction outcome loss': 0.8231011619373244, 'Total loss': 0.8231011619373244}
2022-11-18 02:39:06,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:06,873 INFO:     Epoch: 31
2022-11-18 02:39:07,674 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.7883601825345646, 'Total loss': 0.7883601825345646} | train loss {'Reaction outcome loss': 0.8140736611521974, 'Total loss': 0.8140736611521974}
2022-11-18 02:39:07,674 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:07,674 INFO:     Epoch: 32
2022-11-18 02:39:08,497 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.7787815190174363, 'Total loss': 0.7787815190174363} | train loss {'Reaction outcome loss': 0.8185625526369834, 'Total loss': 0.8185625526369834}
2022-11-18 02:39:08,498 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:08,498 INFO:     Epoch: 33
2022-11-18 02:39:09,289 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.7742776098576459, 'Total loss': 0.7742776098576459} | train loss {'Reaction outcome loss': 0.8152417617184775, 'Total loss': 0.8152417617184775}
2022-11-18 02:39:09,289 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:09,289 INFO:     Epoch: 34
2022-11-18 02:39:10,100 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.7923823208971457, 'Total loss': 0.7923823208971457} | train loss {'Reaction outcome loss': 0.8185148515263382, 'Total loss': 0.8185148515263382}
2022-11-18 02:39:10,101 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:10,101 INFO:     Epoch: 35
2022-11-18 02:39:10,877 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.775294615463777, 'Total loss': 0.775294615463777} | train loss {'Reaction outcome loss': 0.8197453622915307, 'Total loss': 0.8197453622915307}
2022-11-18 02:39:10,877 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:10,877 INFO:     Epoch: 36
2022-11-18 02:39:11,678 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.7714236893437125, 'Total loss': 0.7714236893437125} | train loss {'Reaction outcome loss': 0.8176335294635928, 'Total loss': 0.8176335294635928}
2022-11-18 02:39:11,679 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:11,679 INFO:     Epoch: 37
2022-11-18 02:39:12,488 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7626393809914589, 'Total loss': 0.7626393809914589} | train loss {'Reaction outcome loss': 0.8156338692927847, 'Total loss': 0.8156338692927847}
2022-11-18 02:39:12,488 INFO:     Found new best model at epoch 37
2022-11-18 02:39:12,489 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:12,489 INFO:     Epoch: 38
2022-11-18 02:39:13,275 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7665499821305275, 'Total loss': 0.7665499821305275} | train loss {'Reaction outcome loss': 0.8185027109116924, 'Total loss': 0.8185027109116924}
2022-11-18 02:39:13,275 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:13,275 INFO:     Epoch: 39
2022-11-18 02:39:14,124 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.771099941297011, 'Total loss': 0.771099941297011} | train loss {'Reaction outcome loss': 0.8177003224285282, 'Total loss': 0.8177003224285282}
2022-11-18 02:39:14,124 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:14,125 INFO:     Epoch: 40
2022-11-18 02:39:14,902 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7588462667031721, 'Total loss': 0.7588462667031721} | train loss {'Reaction outcome loss': 0.8160637557506562, 'Total loss': 0.8160637557506562}
2022-11-18 02:39:14,902 INFO:     Found new best model at epoch 40
2022-11-18 02:39:14,903 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:14,903 INFO:     Epoch: 41
2022-11-18 02:39:15,652 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.7698538012125276, 'Total loss': 0.7698538012125276} | train loss {'Reaction outcome loss': 0.8189755459221042, 'Total loss': 0.8189755459221042}
2022-11-18 02:39:15,652 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:15,652 INFO:     Epoch: 42
2022-11-18 02:39:16,450 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7832359190691601, 'Total loss': 0.7832359190691601} | train loss {'Reaction outcome loss': 0.819487054007394, 'Total loss': 0.819487054007394}
2022-11-18 02:39:16,450 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:16,450 INFO:     Epoch: 43
2022-11-18 02:39:17,236 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.7828201035206969, 'Total loss': 0.7828201035206969} | train loss {'Reaction outcome loss': 0.8193531733386371, 'Total loss': 0.8193531733386371}
2022-11-18 02:39:17,237 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:17,237 INFO:     Epoch: 44
2022-11-18 02:39:18,011 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7850203974680467, 'Total loss': 0.7850203974680467} | train loss {'Reaction outcome loss': 0.814602866829658, 'Total loss': 0.814602866829658}
2022-11-18 02:39:18,011 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:18,011 INFO:     Epoch: 45
2022-11-18 02:39:18,808 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.7651421678337184, 'Total loss': 0.7651421678337184} | train loss {'Reaction outcome loss': 0.8216442987018702, 'Total loss': 0.8216442987018702}
2022-11-18 02:39:18,808 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:18,808 INFO:     Epoch: 46
2022-11-18 02:39:19,602 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7637658071788874, 'Total loss': 0.7637658071788874} | train loss {'Reaction outcome loss': 0.8154971131256649, 'Total loss': 0.8154971131256649}
2022-11-18 02:39:19,602 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:19,602 INFO:     Epoch: 47
2022-11-18 02:39:20,365 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7881904542446136, 'Total loss': 0.7881904542446136} | train loss {'Reaction outcome loss': 0.8176036497768091, 'Total loss': 0.8176036497768091}
2022-11-18 02:39:20,365 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:20,365 INFO:     Epoch: 48
2022-11-18 02:39:21,143 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7843594171784141, 'Total loss': 0.7843594171784141} | train loss {'Reaction outcome loss': 0.8150375281061445, 'Total loss': 0.8150375281061445}
2022-11-18 02:39:21,143 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:21,144 INFO:     Epoch: 49
2022-11-18 02:39:21,905 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.796389365060763, 'Total loss': 0.796389365060763} | train loss {'Reaction outcome loss': 0.8207577108120432, 'Total loss': 0.8207577108120432}
2022-11-18 02:39:21,905 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:21,905 INFO:     Epoch: 50
2022-11-18 02:39:22,707 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.7711761844429103, 'Total loss': 0.7711761844429103} | train loss {'Reaction outcome loss': 0.8128711626845964, 'Total loss': 0.8128711626845964}
2022-11-18 02:39:22,707 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:22,707 INFO:     Epoch: 51
2022-11-18 02:39:23,484 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7910519072955305, 'Total loss': 0.7910519072955305} | train loss {'Reaction outcome loss': 0.8180145749023983, 'Total loss': 0.8180145749023983}
2022-11-18 02:39:23,484 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:23,484 INFO:     Epoch: 52
2022-11-18 02:39:24,250 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7963089536536824, 'Total loss': 0.7963089536536824} | train loss {'Reaction outcome loss': 0.8182617341985507, 'Total loss': 0.8182617341985507}
2022-11-18 02:39:24,251 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:24,251 INFO:     Epoch: 53
2022-11-18 02:39:25,033 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7830449491739273, 'Total loss': 0.7830449491739273} | train loss {'Reaction outcome loss': 0.8262562833270248, 'Total loss': 0.8262562833270248}
2022-11-18 02:39:25,033 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:25,033 INFO:     Epoch: 54
2022-11-18 02:39:25,797 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7636902555823326, 'Total loss': 0.7636902555823326} | train loss {'Reaction outcome loss': 0.8191289382321494, 'Total loss': 0.8191289382321494}
2022-11-18 02:39:25,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:25,797 INFO:     Epoch: 55
2022-11-18 02:39:26,550 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7793468711051074, 'Total loss': 0.7793468711051074} | train loss {'Reaction outcome loss': 0.8211517771896051, 'Total loss': 0.8211517771896051}
2022-11-18 02:39:26,550 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:26,550 INFO:     Epoch: 56
2022-11-18 02:39:27,324 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.7730921940370039, 'Total loss': 0.7730921940370039} | train loss {'Reaction outcome loss': 0.8191216251071618, 'Total loss': 0.8191216251071618}
2022-11-18 02:39:27,324 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:27,324 INFO:     Epoch: 57
2022-11-18 02:39:28,102 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.7767773263833739, 'Total loss': 0.7767773263833739} | train loss {'Reaction outcome loss': 0.820353881193667, 'Total loss': 0.820353881193667}
2022-11-18 02:39:28,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:28,102 INFO:     Epoch: 58
2022-11-18 02:39:28,880 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.7795226167548787, 'Total loss': 0.7795226167548787} | train loss {'Reaction outcome loss': 0.8195666662284307, 'Total loss': 0.8195666662284307}
2022-11-18 02:39:28,880 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:28,881 INFO:     Epoch: 59
2022-11-18 02:39:29,679 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7583401237021793, 'Total loss': 0.7583401237021793} | train loss {'Reaction outcome loss': 0.8187109088411136, 'Total loss': 0.8187109088411136}
2022-11-18 02:39:29,679 INFO:     Found new best model at epoch 59
2022-11-18 02:39:29,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:29,680 INFO:     Epoch: 60
2022-11-18 02:39:30,457 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.781225439499725, 'Total loss': 0.781225439499725} | train loss {'Reaction outcome loss': 0.8159759528782903, 'Total loss': 0.8159759528782903}
2022-11-18 02:39:30,457 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:30,457 INFO:     Epoch: 61
2022-11-18 02:39:31,227 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7694616520946677, 'Total loss': 0.7694616520946677} | train loss {'Reaction outcome loss': 0.8188686688335575, 'Total loss': 0.8188686688335575}
2022-11-18 02:39:31,227 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:31,228 INFO:     Epoch: 62
2022-11-18 02:39:32,000 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7696828605099157, 'Total loss': 0.7696828605099157} | train loss {'Reaction outcome loss': 0.8168365135484812, 'Total loss': 0.8168365135484812}
2022-11-18 02:39:32,000 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:32,001 INFO:     Epoch: 63
2022-11-18 02:39:32,784 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.7939754771915349, 'Total loss': 0.7939754771915349} | train loss {'Reaction outcome loss': 0.8185089979852949, 'Total loss': 0.8185089979852949}
2022-11-18 02:39:32,784 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:32,784 INFO:     Epoch: 64
2022-11-18 02:39:33,561 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.7653111734173514, 'Total loss': 0.7653111734173514} | train loss {'Reaction outcome loss': 0.8125273739805027, 'Total loss': 0.8125273739805027}
2022-11-18 02:39:33,561 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:33,561 INFO:     Epoch: 65
2022-11-18 02:39:34,331 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7687274414029989, 'Total loss': 0.7687274414029989} | train loss {'Reaction outcome loss': 0.816242841798432, 'Total loss': 0.816242841798432}
2022-11-18 02:39:34,331 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:34,331 INFO:     Epoch: 66
2022-11-18 02:39:35,125 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7674199193716049, 'Total loss': 0.7674199193716049} | train loss {'Reaction outcome loss': 0.8137951035888827, 'Total loss': 0.8137951035888827}
2022-11-18 02:39:35,125 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:35,125 INFO:     Epoch: 67
2022-11-18 02:39:35,895 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.774782151661136, 'Total loss': 0.774782151661136} | train loss {'Reaction outcome loss': 0.8217765016215188, 'Total loss': 0.8217765016215188}
2022-11-18 02:39:35,895 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:35,895 INFO:     Epoch: 68
2022-11-18 02:39:36,692 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.8024279712276026, 'Total loss': 0.8024279712276026} | train loss {'Reaction outcome loss': 0.8143698099924593, 'Total loss': 0.8143698099924593}
2022-11-18 02:39:36,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:36,694 INFO:     Epoch: 69
2022-11-18 02:39:37,454 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.7657049501484091, 'Total loss': 0.7657049501484091} | train loss {'Reaction outcome loss': 0.8156722043241773, 'Total loss': 0.8156722043241773}
2022-11-18 02:39:37,454 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:37,454 INFO:     Epoch: 70
2022-11-18 02:39:38,208 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7704627378420397, 'Total loss': 0.7704627378420397} | train loss {'Reaction outcome loss': 0.8198115493570055, 'Total loss': 0.8198115493570055}
2022-11-18 02:39:38,208 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:38,208 INFO:     Epoch: 71
2022-11-18 02:39:38,986 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.7894571674141017, 'Total loss': 0.7894571674141017} | train loss {'Reaction outcome loss': 0.8170933043470188, 'Total loss': 0.8170933043470188}
2022-11-18 02:39:38,986 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:38,986 INFO:     Epoch: 72
2022-11-18 02:39:39,782 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.7928593761541627, 'Total loss': 0.7928593761541627} | train loss {'Reaction outcome loss': 0.8235998985718708, 'Total loss': 0.8235998985718708}
2022-11-18 02:39:39,783 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:39,783 INFO:     Epoch: 73
2022-11-18 02:39:40,552 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.789173848927021, 'Total loss': 0.789173848927021} | train loss {'Reaction outcome loss': 0.8165666481670069, 'Total loss': 0.8165666481670069}
2022-11-18 02:39:40,552 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:40,552 INFO:     Epoch: 74
2022-11-18 02:39:41,332 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7878797094930302, 'Total loss': 0.7878797094930302} | train loss {'Reaction outcome loss': 0.8190787790989389, 'Total loss': 0.8190787790989389}
2022-11-18 02:39:41,332 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:41,332 INFO:     Epoch: 75
2022-11-18 02:39:42,089 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7686012163758278, 'Total loss': 0.7686012163758278} | train loss {'Reaction outcome loss': 0.8196025421424787, 'Total loss': 0.8196025421424787}
2022-11-18 02:39:42,090 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:42,090 INFO:     Epoch: 76
2022-11-18 02:39:42,859 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.7617797966707837, 'Total loss': 0.7617797966707837} | train loss {'Reaction outcome loss': 0.8192880971091134, 'Total loss': 0.8192880971091134}
2022-11-18 02:39:42,859 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:42,860 INFO:     Epoch: 77
2022-11-18 02:39:43,600 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.7849674373865128, 'Total loss': 0.7849674373865128} | train loss {'Reaction outcome loss': 0.8148601961379148, 'Total loss': 0.8148601961379148}
2022-11-18 02:39:43,600 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:43,600 INFO:     Epoch: 78
2022-11-18 02:39:44,388 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.782210652123798, 'Total loss': 0.782210652123798} | train loss {'Reaction outcome loss': 0.8183097922072119, 'Total loss': 0.8183097922072119}
2022-11-18 02:39:44,388 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:44,388 INFO:     Epoch: 79
2022-11-18 02:39:45,178 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7608399905941703, 'Total loss': 0.7608399905941703} | train loss {'Reaction outcome loss': 0.816444632350182, 'Total loss': 0.816444632350182}
2022-11-18 02:39:45,178 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:45,178 INFO:     Epoch: 80
2022-11-18 02:39:45,966 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7896411581472917, 'Total loss': 0.7896411581472917} | train loss {'Reaction outcome loss': 0.8198982837248822, 'Total loss': 0.8198982837248822}
2022-11-18 02:39:45,966 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:45,966 INFO:     Epoch: 81
2022-11-18 02:39:46,762 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.7749271372502501, 'Total loss': 0.7749271372502501} | train loss {'Reaction outcome loss': 0.8186811900868708, 'Total loss': 0.8186811900868708}
2022-11-18 02:39:46,762 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:46,762 INFO:     Epoch: 82
2022-11-18 02:39:47,539 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7725245905193415, 'Total loss': 0.7725245905193415} | train loss {'Reaction outcome loss': 0.8147993975756119, 'Total loss': 0.8147993975756119}
2022-11-18 02:39:47,539 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:47,539 INFO:     Epoch: 83
2022-11-18 02:39:48,332 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8072019409049641, 'Total loss': 0.8072019409049641} | train loss {'Reaction outcome loss': 0.8174161044918761, 'Total loss': 0.8174161044918761}
2022-11-18 02:39:48,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:48,333 INFO:     Epoch: 84
2022-11-18 02:39:49,112 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7596780217506669, 'Total loss': 0.7596780217506669} | train loss {'Reaction outcome loss': 0.8169656330225419, 'Total loss': 0.8169656330225419}
2022-11-18 02:39:49,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:49,112 INFO:     Epoch: 85
2022-11-18 02:39:49,890 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7781662344932556, 'Total loss': 0.7781662344932556} | train loss {'Reaction outcome loss': 0.8214883505081644, 'Total loss': 0.8214883505081644}
2022-11-18 02:39:49,890 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:49,890 INFO:     Epoch: 86
2022-11-18 02:39:50,663 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7947121316736395, 'Total loss': 0.7947121316736395} | train loss {'Reaction outcome loss': 0.817158112355641, 'Total loss': 0.817158112355641}
2022-11-18 02:39:50,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:50,663 INFO:     Epoch: 87
2022-11-18 02:39:51,441 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.7590343207120895, 'Total loss': 0.7590343207120895} | train loss {'Reaction outcome loss': 0.8186753266928147, 'Total loss': 0.8186753266928147}
2022-11-18 02:39:51,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:51,441 INFO:     Epoch: 88
2022-11-18 02:39:52,203 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.7800315334038301, 'Total loss': 0.7800315334038301} | train loss {'Reaction outcome loss': 0.8170493640461747, 'Total loss': 0.8170493640461747}
2022-11-18 02:39:52,203 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:52,203 INFO:     Epoch: 89
2022-11-18 02:39:52,984 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7615404149348085, 'Total loss': 0.7615404149348085} | train loss {'Reaction outcome loss': 0.8213015609857988, 'Total loss': 0.8213015609857988}
2022-11-18 02:39:52,984 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:52,984 INFO:     Epoch: 90
2022-11-18 02:39:53,791 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7789526121182875, 'Total loss': 0.7789526121182875} | train loss {'Reaction outcome loss': 0.8161997151618101, 'Total loss': 0.8161997151618101}
2022-11-18 02:39:53,792 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:53,792 INFO:     Epoch: 91
2022-11-18 02:39:54,578 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.7831046012314883, 'Total loss': 0.7831046012314883} | train loss {'Reaction outcome loss': 0.8158800620205549, 'Total loss': 0.8158800620205549}
2022-11-18 02:39:54,579 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:54,579 INFO:     Epoch: 92
2022-11-18 02:39:55,354 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7652492672204971, 'Total loss': 0.7652492672204971} | train loss {'Reaction outcome loss': 0.8153955134810233, 'Total loss': 0.8153955134810233}
2022-11-18 02:39:55,355 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:55,355 INFO:     Epoch: 93
2022-11-18 02:39:56,121 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.7701998891478236, 'Total loss': 0.7701998891478236} | train loss {'Reaction outcome loss': 0.8191397883454148, 'Total loss': 0.8191397883454148}
2022-11-18 02:39:56,121 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:56,121 INFO:     Epoch: 94
2022-11-18 02:39:56,906 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.7812602106820453, 'Total loss': 0.7812602106820453} | train loss {'Reaction outcome loss': 0.8195620140250848, 'Total loss': 0.8195620140250848}
2022-11-18 02:39:56,907 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:56,907 INFO:     Epoch: 95
2022-11-18 02:39:57,681 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7887173701416362, 'Total loss': 0.7887173701416362} | train loss {'Reaction outcome loss': 0.8159037645982237, 'Total loss': 0.8159037645982237}
2022-11-18 02:39:57,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:57,681 INFO:     Epoch: 96
2022-11-18 02:39:58,446 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7679326127875935, 'Total loss': 0.7679326127875935} | train loss {'Reaction outcome loss': 0.8177271670224715, 'Total loss': 0.8177271670224715}
2022-11-18 02:39:58,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:58,446 INFO:     Epoch: 97
2022-11-18 02:39:59,219 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.7740840430964123, 'Total loss': 0.7740840430964123} | train loss {'Reaction outcome loss': 0.8189069277169753, 'Total loss': 0.8189069277169753}
2022-11-18 02:39:59,219 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:59,219 INFO:     Epoch: 98
2022-11-18 02:39:59,999 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7770456238226457, 'Total loss': 0.7770456238226457} | train loss {'Reaction outcome loss': 0.8131248416949292, 'Total loss': 0.8131248416949292}
2022-11-18 02:39:59,999 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:39:59,999 INFO:     Epoch: 99
2022-11-18 02:40:00,760 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.7928517724980008, 'Total loss': 0.7928517724980008} | train loss {'Reaction outcome loss': 0.8191112324899557, 'Total loss': 0.8191112324899557}
2022-11-18 02:40:00,761 INFO:     Best model found after epoch 60 of 100.
2022-11-18 02:40:00,761 INFO:   Done with stage: TRAINING
2022-11-18 02:40:00,761 INFO:   Starting stage: EVALUATION
2022-11-18 02:40:00,893 INFO:   Done with stage: EVALUATION
2022-11-18 02:40:00,893 INFO:   Leaving out SEQ value Fold_9
2022-11-18 02:40:00,906 INFO:   examples: 20,544| examples in train: 15,748 | examples in val: 2,780| examples in test: 2,016
2022-11-18 02:40:00,906 INFO:   Starting stage: FEATURE SCALING
2022-11-18 02:40:01,573 INFO:   Done with stage: FEATURE SCALING
2022-11-18 02:40:01,573 INFO:   Starting stage: SCALING TARGETS
2022-11-18 02:40:01,649 INFO:   Done with stage: SCALING TARGETS
2022-11-18 02:40:01,649 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:40:01,649 INFO:     No hyperparam tuning for this model
2022-11-18 02:40:01,649 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-11-18 02:40:01,649 INFO:   Starting stage: FEATURE SELECTION
2022-11-18 02:40:01,650 INFO:     None feature selector for col prot
2022-11-18 02:40:01,650 INFO:     None feature selector for col prot
2022-11-18 02:40:01,650 INFO:     None feature selector for col prot
2022-11-18 02:40:01,651 INFO:     None feature selector for col chem
2022-11-18 02:40:01,651 INFO:     None feature selector for col chem
2022-11-18 02:40:01,651 INFO:     None feature selector for col chem
2022-11-18 02:40:01,651 INFO:   Done with stage: FEATURE SELECTION
2022-11-18 02:40:01,651 INFO:   Starting stage: BUILD MODEL
2022-11-18 02:40:01,653 INFO:     Number of params in model 168571
2022-11-18 02:40:01,656 INFO:   Done with stage: BUILD MODEL
2022-11-18 02:40:01,656 INFO:   Starting stage: TRAINING
2022-11-18 02:40:01,714 INFO:     Val loss before train {'Reaction outcome loss': 0.9686879569833929, 'Total loss': 0.9686879569833929}
2022-11-18 02:40:01,714 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:01,715 INFO:     Epoch: 0
2022-11-18 02:40:02,481 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9053043574094772, 'Total loss': 0.9053043574094772} | train loss {'Reaction outcome loss': 0.8811225494151174, 'Total loss': 0.8811225494151174}
2022-11-18 02:40:02,481 INFO:     Found new best model at epoch 0
2022-11-18 02:40:02,482 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:02,482 INFO:     Epoch: 1
2022-11-18 02:40:03,270 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.8468451100316915, 'Total loss': 0.8468451100316915} | train loss {'Reaction outcome loss': 0.8471259103507286, 'Total loss': 0.8471259103507286}
2022-11-18 02:40:03,270 INFO:     Found new best model at epoch 1
2022-11-18 02:40:03,271 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:03,271 INFO:     Epoch: 2
2022-11-18 02:40:04,111 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.8128073858943853, 'Total loss': 0.8128073858943853} | train loss {'Reaction outcome loss': 0.8453138683006348, 'Total loss': 0.8453138683006348}
2022-11-18 02:40:04,111 INFO:     Found new best model at epoch 2
2022-11-18 02:40:04,112 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:04,112 INFO:     Epoch: 3
2022-11-18 02:40:04,922 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.8120446706360037, 'Total loss': 0.8120446706360037} | train loss {'Reaction outcome loss': 0.8392543328797769, 'Total loss': 0.8392543328797769}
2022-11-18 02:40:04,922 INFO:     Found new best model at epoch 3
2022-11-18 02:40:04,923 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:04,923 INFO:     Epoch: 4
2022-11-18 02:40:05,757 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.8122763376344334, 'Total loss': 0.8122763376344334} | train loss {'Reaction outcome loss': 0.8317521326696342, 'Total loss': 0.8317521326696342}
2022-11-18 02:40:05,757 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:05,757 INFO:     Epoch: 5
2022-11-18 02:40:06,540 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.8187430250373754, 'Total loss': 0.8187430250373754} | train loss {'Reaction outcome loss': 0.8365838410641983, 'Total loss': 0.8365838410641983}
2022-11-18 02:40:06,540 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:06,540 INFO:     Epoch: 6
2022-11-18 02:40:07,353 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.8234171230684627, 'Total loss': 0.8234171230684627} | train loss {'Reaction outcome loss': 0.8332906392542457, 'Total loss': 0.8332906392542457}
2022-11-18 02:40:07,353 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:07,353 INFO:     Epoch: 7
2022-11-18 02:40:08,170 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.8063731837001714, 'Total loss': 0.8063731837001714} | train loss {'Reaction outcome loss': 0.8312910866399525, 'Total loss': 0.8312910866399525}
2022-11-18 02:40:08,172 INFO:     Found new best model at epoch 7
2022-11-18 02:40:08,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:08,173 INFO:     Epoch: 8
2022-11-18 02:40:09,019 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.8503110124306246, 'Total loss': 0.8503110124306246} | train loss {'Reaction outcome loss': 0.8254776459247598, 'Total loss': 0.8254776459247598}
2022-11-18 02:40:09,019 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:09,020 INFO:     Epoch: 9
2022-11-18 02:40:09,834 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.8307457776232199, 'Total loss': 0.8307457776232199} | train loss {'Reaction outcome loss': 0.8229120260911432, 'Total loss': 0.8229120260911432}
2022-11-18 02:40:09,834 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:09,834 INFO:     Epoch: 10
2022-11-18 02:40:10,619 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.8015306429429487, 'Total loss': 0.8015306429429487} | train loss {'Reaction outcome loss': 0.8209064307618841, 'Total loss': 0.8209064307618841}
2022-11-18 02:40:10,619 INFO:     Found new best model at epoch 10
2022-11-18 02:40:10,619 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:10,620 INFO:     Epoch: 11
2022-11-18 02:40:11,429 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.8037721853364598, 'Total loss': 0.8037721853364598} | train loss {'Reaction outcome loss': 0.8256597911056719, 'Total loss': 0.8256597911056719}
2022-11-18 02:40:11,429 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:11,429 INFO:     Epoch: 12
2022-11-18 02:40:12,238 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.7958398122679103, 'Total loss': 0.7958398122679103} | train loss {'Reaction outcome loss': 0.8231498272071484, 'Total loss': 0.8231498272071484}
2022-11-18 02:40:12,238 INFO:     Found new best model at epoch 12
2022-11-18 02:40:12,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:12,239 INFO:     Epoch: 13
2022-11-18 02:40:13,068 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.8273729654875669, 'Total loss': 0.8273729654875669} | train loss {'Reaction outcome loss': 0.8219145769366489, 'Total loss': 0.8219145769366489}
2022-11-18 02:40:13,068 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:13,068 INFO:     Epoch: 14
2022-11-18 02:40:13,885 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.7974662679162893, 'Total loss': 0.7974662679162893} | train loss {'Reaction outcome loss': 0.8208461893714873, 'Total loss': 0.8208461893714873}
2022-11-18 02:40:13,885 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:13,885 INFO:     Epoch: 15
2022-11-18 02:40:14,644 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.797630297189409, 'Total loss': 0.797630297189409} | train loss {'Reaction outcome loss': 0.8174301551783133, 'Total loss': 0.8174301551783133}
2022-11-18 02:40:14,645 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:14,645 INFO:     Epoch: 16
2022-11-18 02:40:15,473 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.8026115582747892, 'Total loss': 0.8026115582747892} | train loss {'Reaction outcome loss': 0.8207146753425058, 'Total loss': 0.8207146753425058}
2022-11-18 02:40:15,473 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:15,474 INFO:     Epoch: 17
2022-11-18 02:40:16,296 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.8087592389095913, 'Total loss': 0.8087592389095913} | train loss {'Reaction outcome loss': 0.826288313518169, 'Total loss': 0.826288313518169}
2022-11-18 02:40:16,296 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:16,296 INFO:     Epoch: 18
2022-11-18 02:40:17,110 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.7925388630140912, 'Total loss': 0.7925388630140912} | train loss {'Reaction outcome loss': 0.813696083661757, 'Total loss': 0.813696083661757}
2022-11-18 02:40:17,110 INFO:     Found new best model at epoch 18
2022-11-18 02:40:17,110 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:17,111 INFO:     Epoch: 19
2022-11-18 02:40:17,930 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.799596947025169, 'Total loss': 0.799596947025169} | train loss {'Reaction outcome loss': 0.8158443803005373, 'Total loss': 0.8158443803005373}
2022-11-18 02:40:17,931 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:17,931 INFO:     Epoch: 20
2022-11-18 02:40:18,762 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.7946747510947965, 'Total loss': 0.7946747510947965} | train loss {'Reaction outcome loss': 0.8167748658763252, 'Total loss': 0.8167748658763252}
2022-11-18 02:40:18,763 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:18,763 INFO:     Epoch: 21
2022-11-18 02:40:19,570 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.8056480451063677, 'Total loss': 0.8056480451063677} | train loss {'Reaction outcome loss': 0.8174002305698781, 'Total loss': 0.8174002305698781}
2022-11-18 02:40:19,570 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:19,570 INFO:     Epoch: 22
2022-11-18 02:40:20,395 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.830181437459859, 'Total loss': 0.830181437459859} | train loss {'Reaction outcome loss': 0.8222271743332327, 'Total loss': 0.8222271743332327}
2022-11-18 02:40:20,396 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:20,396 INFO:     Epoch: 23
2022-11-18 02:40:21,238 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.8007216927680102, 'Total loss': 0.8007216927680102} | train loss {'Reaction outcome loss': 0.8310343428903263, 'Total loss': 0.8310343428903263}
2022-11-18 02:40:21,238 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:21,238 INFO:     Epoch: 24
2022-11-18 02:40:22,055 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.7992693930864334, 'Total loss': 0.7992693930864334} | train loss {'Reaction outcome loss': 0.8247026342612046, 'Total loss': 0.8247026342612046}
2022-11-18 02:40:22,055 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:22,055 INFO:     Epoch: 25
2022-11-18 02:40:22,893 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.8032097985798662, 'Total loss': 0.8032097985798662} | train loss {'Reaction outcome loss': 0.8190178860295639, 'Total loss': 0.8190178860295639}
2022-11-18 02:40:22,893 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:22,894 INFO:     Epoch: 26
2022-11-18 02:40:23,693 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.8041445545174859, 'Total loss': 0.8041445545174859} | train loss {'Reaction outcome loss': 0.8202669725485658, 'Total loss': 0.8202669725485658}
2022-11-18 02:40:23,693 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:23,693 INFO:     Epoch: 27
2022-11-18 02:40:24,471 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.8094801130619916, 'Total loss': 0.8094801130619916} | train loss {'Reaction outcome loss': 0.8157472050624338, 'Total loss': 0.8157472050624338}
2022-11-18 02:40:24,471 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:24,472 INFO:     Epoch: 28
2022-11-18 02:40:25,252 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.7864040515639565, 'Total loss': 0.7864040515639565} | train loss {'Reaction outcome loss': 0.8117236983679567, 'Total loss': 0.8117236983679567}
2022-11-18 02:40:25,252 INFO:     Found new best model at epoch 28
2022-11-18 02:40:25,252 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:25,253 INFO:     Epoch: 29
2022-11-18 02:40:26,073 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.8041264076124538, 'Total loss': 0.8041264076124538} | train loss {'Reaction outcome loss': 0.8166191352282458, 'Total loss': 0.8166191352282458}
2022-11-18 02:40:26,073 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:26,073 INFO:     Epoch: 30
2022-11-18 02:40:26,897 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.823840310627764, 'Total loss': 0.823840310627764} | train loss {'Reaction outcome loss': 0.8323574179579855, 'Total loss': 0.8323574179579855}
2022-11-18 02:40:26,897 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:26,898 INFO:     Epoch: 31
2022-11-18 02:40:27,720 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.795624774965373, 'Total loss': 0.795624774965373} | train loss {'Reaction outcome loss': 0.8174909116768161, 'Total loss': 0.8174909116768161}
2022-11-18 02:40:27,720 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:27,720 INFO:     Epoch: 32
2022-11-18 02:40:28,508 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.791093724695119, 'Total loss': 0.791093724695119} | train loss {'Reaction outcome loss': 0.8101064199619448, 'Total loss': 0.8101064199619448}
2022-11-18 02:40:28,508 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:28,508 INFO:     Epoch: 33
2022-11-18 02:40:29,341 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.8279372982003472, 'Total loss': 0.8279372982003472} | train loss {'Reaction outcome loss': 0.8226222432094065, 'Total loss': 0.8226222432094065}
2022-11-18 02:40:29,341 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:29,341 INFO:     Epoch: 34
2022-11-18 02:40:30,172 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.8206732002171603, 'Total loss': 0.8206732002171603} | train loss {'Reaction outcome loss': 0.8180219070148854, 'Total loss': 0.8180219070148854}
2022-11-18 02:40:30,173 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:30,173 INFO:     Epoch: 35
2022-11-18 02:40:30,966 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.79756210134788, 'Total loss': 0.79756210134788} | train loss {'Reaction outcome loss': 0.8123187016137698, 'Total loss': 0.8123187016137698}
2022-11-18 02:40:30,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:30,967 INFO:     Epoch: 36
2022-11-18 02:40:31,803 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.8059621812267737, 'Total loss': 0.8059621812267737} | train loss {'Reaction outcome loss': 0.8144384001189398, 'Total loss': 0.8144384001189398}
2022-11-18 02:40:31,803 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:31,803 INFO:     Epoch: 37
2022-11-18 02:40:32,609 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.7870273529128595, 'Total loss': 0.7870273529128595} | train loss {'Reaction outcome loss': 0.8110738809292133, 'Total loss': 0.8110738809292133}
2022-11-18 02:40:32,609 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:32,609 INFO:     Epoch: 38
2022-11-18 02:40:33,416 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.7944531264630231, 'Total loss': 0.7944531264630231} | train loss {'Reaction outcome loss': 0.8092944101705725, 'Total loss': 0.8092944101705725}
2022-11-18 02:40:33,417 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:33,417 INFO:     Epoch: 39
2022-11-18 02:40:34,276 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.7891244691881266, 'Total loss': 0.7891244691881266} | train loss {'Reaction outcome loss': 0.8142623255549655, 'Total loss': 0.8142623255549655}
2022-11-18 02:40:34,276 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:34,277 INFO:     Epoch: 40
2022-11-18 02:40:35,096 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.7980054935271089, 'Total loss': 0.7980054935271089} | train loss {'Reaction outcome loss': 0.8159807645357572, 'Total loss': 0.8159807645357572}
2022-11-18 02:40:35,096 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:35,096 INFO:     Epoch: 41
2022-11-18 02:40:35,936 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.8019183339043097, 'Total loss': 0.8019183339043097} | train loss {'Reaction outcome loss': 0.8169965585957655, 'Total loss': 0.8169965585957655}
2022-11-18 02:40:35,936 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:35,936 INFO:     Epoch: 42
2022-11-18 02:40:36,738 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.7866096367890184, 'Total loss': 0.7866096367890184} | train loss {'Reaction outcome loss': 0.8121317464571732, 'Total loss': 0.8121317464571732}
2022-11-18 02:40:36,738 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:36,738 INFO:     Epoch: 43
2022-11-18 02:40:37,553 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.793994201855226, 'Total loss': 0.793994201855226} | train loss {'Reaction outcome loss': 0.814910345352613, 'Total loss': 0.814910345352613}
2022-11-18 02:40:37,554 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:37,554 INFO:     Epoch: 44
2022-11-18 02:40:38,333 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.7975040775808421, 'Total loss': 0.7975040775808421} | train loss {'Reaction outcome loss': 0.8160029979128587, 'Total loss': 0.8160029979128587}
2022-11-18 02:40:38,333 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:38,333 INFO:     Epoch: 45
2022-11-18 02:40:39,098 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.8001733280041001, 'Total loss': 0.8001733280041001} | train loss {'Reaction outcome loss': 0.8099429893952149, 'Total loss': 0.8099429893952149}
2022-11-18 02:40:39,099 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:39,099 INFO:     Epoch: 46
2022-11-18 02:40:39,886 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.7977464307438243, 'Total loss': 0.7977464307438243} | train loss {'Reaction outcome loss': 0.8083593943099744, 'Total loss': 0.8083593943099744}
2022-11-18 02:40:39,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:39,888 INFO:     Epoch: 47
2022-11-18 02:40:40,665 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.7872648550705477, 'Total loss': 0.7872648550705477} | train loss {'Reaction outcome loss': 0.8121371463484127, 'Total loss': 0.8121371463484127}
2022-11-18 02:40:40,665 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:40,665 INFO:     Epoch: 48
2022-11-18 02:40:41,446 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.7909674224528399, 'Total loss': 0.7909674224528399} | train loss {'Reaction outcome loss': 0.8179571276402425, 'Total loss': 0.8179571276402425}
2022-11-18 02:40:41,446 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:41,446 INFO:     Epoch: 49
2022-11-18 02:40:42,221 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.7886666343970732, 'Total loss': 0.7886666343970732} | train loss {'Reaction outcome loss': 0.8098457991352931, 'Total loss': 0.8098457991352931}
2022-11-18 02:40:42,221 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:42,221 INFO:     Epoch: 50
2022-11-18 02:40:43,014 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.8104996728626165, 'Total loss': 0.8104996728626165} | train loss {'Reaction outcome loss': 0.8120672326942204, 'Total loss': 0.8120672326942204}
2022-11-18 02:40:43,014 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:43,015 INFO:     Epoch: 51
2022-11-18 02:40:43,797 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.7925311530178244, 'Total loss': 0.7925311530178244} | train loss {'Reaction outcome loss': 0.8112014363320009, 'Total loss': 0.8112014363320009}
2022-11-18 02:40:43,797 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:43,797 INFO:     Epoch: 52
2022-11-18 02:40:44,580 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.7876367279413071, 'Total loss': 0.7876367279413071} | train loss {'Reaction outcome loss': 0.8133502310586844, 'Total loss': 0.8133502310586844}
2022-11-18 02:40:44,580 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:44,580 INFO:     Epoch: 53
2022-11-18 02:40:45,380 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.7947748465971514, 'Total loss': 0.7947748465971514} | train loss {'Reaction outcome loss': 0.8184169158037857, 'Total loss': 0.8184169158037857}
2022-11-18 02:40:45,380 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:45,380 INFO:     Epoch: 54
2022-11-18 02:40:46,157 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.7965677651492032, 'Total loss': 0.7965677651492032} | train loss {'Reaction outcome loss': 0.8155903519406492, 'Total loss': 0.8155903519406492}
2022-11-18 02:40:46,158 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:46,158 INFO:     Epoch: 55
2022-11-18 02:40:46,967 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.7908677533268929, 'Total loss': 0.7908677533268929} | train loss {'Reaction outcome loss': 0.8121002125233291, 'Total loss': 0.8121002125233291}
2022-11-18 02:40:46,967 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:46,968 INFO:     Epoch: 56
2022-11-18 02:40:47,766 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.8040460287169977, 'Total loss': 0.8040460287169977} | train loss {'Reaction outcome loss': 0.8148088773131853, 'Total loss': 0.8148088773131853}
2022-11-18 02:40:47,766 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:47,766 INFO:     Epoch: 57
2022-11-18 02:40:48,582 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.8101607398553328, 'Total loss': 0.8101607398553328} | train loss {'Reaction outcome loss': 0.8119485177522004, 'Total loss': 0.8119485177522004}
2022-11-18 02:40:48,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:48,582 INFO:     Epoch: 58
2022-11-18 02:40:49,349 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.8084163469347087, 'Total loss': 0.8084163469347087} | train loss {'Reaction outcome loss': 0.8112087089281815, 'Total loss': 0.8112087089281815}
2022-11-18 02:40:49,349 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:49,349 INFO:     Epoch: 59
2022-11-18 02:40:50,102 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.7896981259638612, 'Total loss': 0.7896981259638612} | train loss {'Reaction outcome loss': 0.8086591584962389, 'Total loss': 0.8086591584962389}
2022-11-18 02:40:50,102 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:50,102 INFO:     Epoch: 60
2022-11-18 02:40:50,892 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.7897542240944776, 'Total loss': 0.7897542240944776} | train loss {'Reaction outcome loss': 0.8222635889101607, 'Total loss': 0.8222635889101607}
2022-11-18 02:40:50,892 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:50,893 INFO:     Epoch: 61
2022-11-18 02:40:51,666 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.7964860146695917, 'Total loss': 0.7964860146695917} | train loss {'Reaction outcome loss': 0.8168685133399268, 'Total loss': 0.8168685133399268}
2022-11-18 02:40:51,666 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:51,666 INFO:     Epoch: 62
2022-11-18 02:40:52,439 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.7922218414870176, 'Total loss': 0.7922218414870176} | train loss {'Reaction outcome loss': 0.8139781058136268, 'Total loss': 0.8139781058136268}
2022-11-18 02:40:52,440 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:52,440 INFO:     Epoch: 63
2022-11-18 02:40:53,218 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.8039656708186323, 'Total loss': 0.8039656708186323} | train loss {'Reaction outcome loss': 0.8118943455006912, 'Total loss': 0.8118943455006912}
2022-11-18 02:40:53,218 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:53,219 INFO:     Epoch: 64
2022-11-18 02:40:53,984 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.8087971860712225, 'Total loss': 0.8087971860712225} | train loss {'Reaction outcome loss': 0.814444399555685, 'Total loss': 0.814444399555685}
2022-11-18 02:40:53,985 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:53,985 INFO:     Epoch: 65
2022-11-18 02:40:54,750 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.7998875894329764, 'Total loss': 0.7998875894329764} | train loss {'Reaction outcome loss': 0.8175801277039987, 'Total loss': 0.8175801277039987}
2022-11-18 02:40:54,750 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:54,750 INFO:     Epoch: 66
2022-11-18 02:40:55,535 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.7898969121954658, 'Total loss': 0.7898969121954658} | train loss {'Reaction outcome loss': 0.8189933645097833, 'Total loss': 0.8189933645097833}
2022-11-18 02:40:55,535 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:55,535 INFO:     Epoch: 67
2022-11-18 02:40:56,310 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.788317889652469, 'Total loss': 0.788317889652469} | train loss {'Reaction outcome loss': 0.8172912661604553, 'Total loss': 0.8172912661604553}
2022-11-18 02:40:56,310 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:56,310 INFO:     Epoch: 68
2022-11-18 02:40:57,107 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.798460150306875, 'Total loss': 0.798460150306875} | train loss {'Reaction outcome loss': 0.8147960651500022, 'Total loss': 0.8147960651500022}
2022-11-18 02:40:57,107 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:57,107 INFO:     Epoch: 69
2022-11-18 02:40:57,888 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.790349624373696, 'Total loss': 0.790349624373696} | train loss {'Reaction outcome loss': 0.8119837283967477, 'Total loss': 0.8119837283967477}
2022-11-18 02:40:57,888 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:57,888 INFO:     Epoch: 70
2022-11-18 02:40:58,662 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.7910379550673745, 'Total loss': 0.7910379550673745} | train loss {'Reaction outcome loss': 0.8255958748973815, 'Total loss': 0.8255958748973815}
2022-11-18 02:40:58,663 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:58,663 INFO:     Epoch: 71
2022-11-18 02:40:59,440 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.8112484860149297, 'Total loss': 0.8112484860149297} | train loss {'Reaction outcome loss': 0.8200342704048041, 'Total loss': 0.8200342704048041}
2022-11-18 02:40:59,441 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:40:59,441 INFO:     Epoch: 72
2022-11-18 02:41:00,205 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.8114738830111243, 'Total loss': 0.8114738830111243} | train loss {'Reaction outcome loss': 0.8110741357571682, 'Total loss': 0.8110741357571682}
2022-11-18 02:41:00,205 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:00,205 INFO:     Epoch: 73
2022-11-18 02:41:00,983 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.792006834664128, 'Total loss': 0.792006834664128} | train loss {'Reaction outcome loss': 0.8098179794817801, 'Total loss': 0.8098179794817801}
2022-11-18 02:41:00,983 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:00,983 INFO:     Epoch: 74
2022-11-18 02:41:01,774 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.7965897369113836, 'Total loss': 0.7965897369113836} | train loss {'Reaction outcome loss': 0.8117762358806394, 'Total loss': 0.8117762358806394}
2022-11-18 02:41:01,774 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:01,774 INFO:     Epoch: 75
2022-11-18 02:41:02,559 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.7926463200287386, 'Total loss': 0.7926463200287386} | train loss {'Reaction outcome loss': 0.8136223124920839, 'Total loss': 0.8136223124920839}
2022-11-18 02:41:02,559 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:02,559 INFO:     Epoch: 76
2022-11-18 02:41:03,370 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.789582213217562, 'Total loss': 0.789582213217562} | train loss {'Reaction outcome loss': 0.8103633012607513, 'Total loss': 0.8103633012607513}
2022-11-18 02:41:03,370 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:03,370 INFO:     Epoch: 77
2022-11-18 02:41:04,176 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.799117390405048, 'Total loss': 0.799117390405048} | train loss {'Reaction outcome loss': 0.8194791786825126, 'Total loss': 0.8194791786825126}
2022-11-18 02:41:04,176 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:04,177 INFO:     Epoch: 78
2022-11-18 02:41:05,015 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.8073731132528998, 'Total loss': 0.8073731132528998} | train loss {'Reaction outcome loss': 0.815862180009062, 'Total loss': 0.815862180009062}
2022-11-18 02:41:05,015 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:05,016 INFO:     Epoch: 79
2022-11-18 02:41:05,788 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.7877052128314972, 'Total loss': 0.7877052128314972} | train loss {'Reaction outcome loss': 0.8109994132509116, 'Total loss': 0.8109994132509116}
2022-11-18 02:41:05,788 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:05,788 INFO:     Epoch: 80
2022-11-18 02:41:06,582 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.7899308841336857, 'Total loss': 0.7899308841336857} | train loss {'Reaction outcome loss': 0.8052260203490614, 'Total loss': 0.8052260203490614}
2022-11-18 02:41:06,582 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:06,582 INFO:     Epoch: 81
2022-11-18 02:41:07,402 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.8019886721264232, 'Total loss': 0.8019886721264232} | train loss {'Reaction outcome loss': 0.8229281733393187, 'Total loss': 0.8229281733393187}
2022-11-18 02:41:07,403 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:07,403 INFO:     Epoch: 82
2022-11-18 02:41:08,241 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.7863735543055967, 'Total loss': 0.7863735543055967} | train loss {'Reaction outcome loss': 0.8240470602686106, 'Total loss': 0.8240470602686106}
2022-11-18 02:41:08,242 INFO:     Found new best model at epoch 82
2022-11-18 02:41:08,242 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:08,242 INFO:     Epoch: 83
2022-11-18 02:41:09,069 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.8121003833684054, 'Total loss': 0.8121003833684054} | train loss {'Reaction outcome loss': 0.8150152660272865, 'Total loss': 0.8150152660272865}
2022-11-18 02:41:09,069 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:09,069 INFO:     Epoch: 84
2022-11-18 02:41:09,862 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.7948301705447111, 'Total loss': 0.7948301705447111} | train loss {'Reaction outcome loss': 0.8169247016974306, 'Total loss': 0.8169247016974306}
2022-11-18 02:41:09,862 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:09,862 INFO:     Epoch: 85
2022-11-18 02:41:10,678 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.7972478290850465, 'Total loss': 0.7972478290850465} | train loss {'Reaction outcome loss': 0.8114417317485519, 'Total loss': 0.8114417317485519}
2022-11-18 02:41:10,680 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:10,680 INFO:     Epoch: 86
2022-11-18 02:41:11,500 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.7900894954800606, 'Total loss': 0.7900894954800606} | train loss {'Reaction outcome loss': 0.8140921441890933, 'Total loss': 0.8140921441890933}
2022-11-18 02:41:11,500 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:11,500 INFO:     Epoch: 87
2022-11-18 02:41:12,262 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.8010603575543924, 'Total loss': 0.8010603575543924} | train loss {'Reaction outcome loss': 0.814806412226758, 'Total loss': 0.814806412226758}
2022-11-18 02:41:12,262 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:12,263 INFO:     Epoch: 88
2022-11-18 02:41:13,046 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.800157333639535, 'Total loss': 0.800157333639535} | train loss {'Reaction outcome loss': 0.8136548568241992, 'Total loss': 0.8136548568241992}
2022-11-18 02:41:13,046 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:13,046 INFO:     Epoch: 89
2022-11-18 02:41:13,873 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.7974316301670942, 'Total loss': 0.7974316301670942} | train loss {'Reaction outcome loss': 0.809593774408464, 'Total loss': 0.809593774408464}
2022-11-18 02:41:13,873 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:13,873 INFO:     Epoch: 90
2022-11-18 02:41:14,681 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.7886632010340691, 'Total loss': 0.7886632010340691} | train loss {'Reaction outcome loss': 0.8197700328189834, 'Total loss': 0.8197700328189834}
2022-11-18 02:41:14,681 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:14,681 INFO:     Epoch: 91
2022-11-18 02:41:15,468 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.8073195164853876, 'Total loss': 0.8073195164853876} | train loss {'Reaction outcome loss': 0.8183596639136071, 'Total loss': 0.8183596639136071}
2022-11-18 02:41:15,468 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:15,469 INFO:     Epoch: 92
2022-11-18 02:41:16,300 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.7918490930037065, 'Total loss': 0.7918490930037065} | train loss {'Reaction outcome loss': 0.8224942148455724, 'Total loss': 0.8224942148455724}
2022-11-18 02:41:16,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:16,301 INFO:     Epoch: 93
2022-11-18 02:41:17,141 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.8115710812536153, 'Total loss': 0.8115710812536153} | train loss {'Reaction outcome loss': 0.8121704738662552, 'Total loss': 0.8121704738662552}
2022-11-18 02:41:17,141 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:17,142 INFO:     Epoch: 94
2022-11-18 02:41:17,956 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.801517931575125, 'Total loss': 0.801517931575125} | train loss {'Reaction outcome loss': 0.8113207821903924, 'Total loss': 0.8113207821903924}
2022-11-18 02:41:17,956 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:17,957 INFO:     Epoch: 95
2022-11-18 02:41:18,749 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.7894883467392488, 'Total loss': 0.7894883467392488} | train loss {'Reaction outcome loss': 0.8128667244544396, 'Total loss': 0.8128667244544396}
2022-11-18 02:41:18,749 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:18,749 INFO:     Epoch: 96
2022-11-18 02:41:19,522 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.7926574891263788, 'Total loss': 0.7926574891263788} | train loss {'Reaction outcome loss': 0.8209649243576806, 'Total loss': 0.8209649243576806}
2022-11-18 02:41:19,522 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:19,522 INFO:     Epoch: 97
2022-11-18 02:41:20,301 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.802303793078119, 'Total loss': 0.802303793078119} | train loss {'Reaction outcome loss': 0.8166797906763641, 'Total loss': 0.8166797906763641}
2022-11-18 02:41:20,301 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:20,301 INFO:     Epoch: 98
2022-11-18 02:41:21,111 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.7983614890412851, 'Total loss': 0.7983614890412851} | train loss {'Reaction outcome loss': 0.8160215762824665, 'Total loss': 0.8160215762824665}
2022-11-18 02:41:21,111 INFO:     Current learning rate [0.001491528877467142]
2022-11-18 02:41:21,111 INFO:     Epoch: 99
2022-11-18 02:41:21,920 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.789247836578976, 'Total loss': 0.789247836578976} | train loss {'Reaction outcome loss': 0.8108004557217664, 'Total loss': 0.8108004557217664}
2022-11-18 02:41:21,920 INFO:     Best model found after epoch 83 of 100.
2022-11-18 02:41:21,921 INFO:   Done with stage: TRAINING
2022-11-18 02:41:21,921 INFO:   Starting stage: EVALUATION
2022-11-18 02:41:22,047 INFO:   Done with stage: EVALUATION
2022-11-18 02:41:22,047 INFO: Done with stage: RUNNING SPLITS
2022-11-18 02:41:22,047 INFO: Starting stage: COMPUTE METRICS
2022-11-18 02:41:23,252 INFO: Done with stage: COMPUTE METRICS
2022-11-18 02:41:23,252 INFO: Starting stage: EXPORT RESULTS
2022-11-18 02:41:23,269 INFO:   Final results averaged over 50 folds: 
2022-11-18 02:41:23,273 INFO:   
                     mae  neg-spearman      rmse  spearman
dataset_split                                            
test           0.250886           NaN  0.346485       NaN
2022-11-18 02:41:25,075 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2022-11-18 02:41:25,081 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2022-11-18 02:41:25,083 DEBUG:   interactive is False
2022-11-18 02:41:25,083 DEBUG:   platform is linux
2022-11-18 02:41:25,083 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.naming', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2022-11-18 02:41:25,266 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2022-11-18 02:41:25,268 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2022-11-18 02:41:25,715 DEBUG:   Loaded backend agg version unknown.
2022-11-18 02:41:25,717 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-11-18 02:41:25,717 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 02:41:25,717 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,718 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,718 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 02:41:25,718 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 02:41:25,718 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-18 02:41:25,718 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 02:41:25,718 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 02:41:25,718 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,718 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,718 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 02:41:25,718 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-18 02:41:25,718 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,718 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,718 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,718 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 02:41:25,718 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,719 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 02:41:25,719 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,719 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,719 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-18 02:41:25,719 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 02:41:25,719 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 02:41:25,719 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,719 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,719 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,719 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 02:41:25,719 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,719 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 02:41:25,719 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 02:41:25,719 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,719 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 02:41:25,720 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-18 02:41:25,720 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,720 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,720 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 02:41:25,720 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,720 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 02:41:25,720 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-18 02:41:25,720 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,720 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 02:41:25,720 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,720 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-18 02:41:25,720 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 02:41:25,720 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-18 02:41:25,758 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2022-11-18 02:41:25,759 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 02:41:25,759 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,759 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,759 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 02:41:25,759 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 02:41:25,759 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-18 02:41:25,759 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 02:41:25,759 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 02:41:25,760 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,760 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,760 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 02:41:25,760 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-18 02:41:25,760 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,760 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,760 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,760 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 02:41:25,760 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,761 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 02:41:25,761 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,761 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,761 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-18 02:41:25,761 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 02:41:25,761 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 02:41:25,761 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,761 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,762 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,762 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 02:41:25,762 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,762 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 02:41:25,762 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 02:41:25,762 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,762 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 02:41:25,762 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-18 02:41:25,762 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,763 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,763 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 02:41:25,763 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,763 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 02:41:25,763 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-18 02:41:25,763 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,763 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 02:41:25,763 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,763 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-18 02:41:25,763 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 02:41:25,764 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-18 02:41:25,772 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-11-18 02:41:25,773 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 02:41:25,773 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,773 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,773 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 02:41:25,773 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 02:41:25,773 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-18 02:41:25,773 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 02:41:25,774 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 02:41:25,774 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,774 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,774 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 02:41:25,774 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-18 02:41:25,774 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,774 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,774 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,774 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 02:41:25,774 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,774 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 02:41:25,774 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,775 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,775 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-11-18 02:41:25,775 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 02:41:25,775 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-11-18 02:41:25,775 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,775 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,775 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,775 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 02:41:25,775 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,775 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 02:41:25,775 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 02:41:25,775 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,775 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 02:41:25,775 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-11-18 02:41:25,775 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,776 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,776 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 02:41:25,776 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,776 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-11-18 02:41:25,776 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-11-18 02:41:25,776 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,776 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 02:41:25,776 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-11-18 02:41:25,776 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-11-18 02:41:25,776 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-11-18 02:41:25,776 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-11-18 02:41:26,273 INFO: Done with stage: EXPORT RESULTS
2022-11-18 02:41:26,274 INFO: Starting stage: SAVE MODEL
2022-11-18 02:41:26,343 INFO: Done with stage: SAVE MODEL
2022-11-18 02:41:26,343 INFO: Wall time for program:  4043.47 seconds
