2022-12-31 09:30:45,898 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffn/9b52f48c712e4c9cfbfc342f165d61dd/2022_12_31-024243",
  "seed": 1,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "morgan1024",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffndot/952cbf3d9c8ab59fe9c0531715302502/2021_05_26-165106_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffn",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.95,
  "val_size": 0.05,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.00015553873022161447,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 3,
  "hidden_size": 90,
  "model_dropout": 0.04479215158380028,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.0016309161239175475,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2022-12-31 09:30:45,905 INFO: Starting stage: BUILD FEATURIZERS
2022-12-31 09:30:45,908 INFO:   Creating esm representation model
2022-12-31 09:30:45,908 INFO:   Done esm representation model
2022-12-31 09:30:45,908 INFO: Done with stage: BUILD FEATURIZERS
2022-12-31 09:30:45,908 INFO: Starting stage: BUILDING DATASET
2022-12-31 09:30:45,962 INFO: Done with stage: BUILDING DATASET
2022-12-31 09:30:45,962 INFO: Starting stage: FEATURIZING DATA
2022-12-31 09:30:45,962 INFO:   Featurizing proteins
2022-12-31 09:30:45,964 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2022-12-31 09:30:45,993 INFO:   Loaded feature cache of size 489
2022-12-31 09:30:45,994 INFO:   Starting to pool ESM Embeddings
2022-12-31 09:30:46,095 INFO:   Featurizing molecules
2022-12-31 09:30:46,097 INFO:   Loading cache file data/program_cache/739a0d20a6c75d701bd3663cec254635
2022-12-31 09:30:46,099 INFO:   Loaded feature cache of size 498
2022-12-31 09:30:47,437 INFO: Done with stage: FEATURIZING DATA
2022-12-31 09:30:47,437 INFO: Starting stage: RUNNING SPLITS
2022-12-31 09:30:47,446 INFO:   Leaving out SEQ value Fold_0
2022-12-31 09:30:47,460 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 09:30:47,460 INFO:   Starting stage: FEATURE SCALING
2022-12-31 09:30:48,130 INFO:   Done with stage: FEATURE SCALING
2022-12-31 09:30:48,130 INFO:   Starting stage: SCALING TARGETS
2022-12-31 09:30:48,198 INFO:   Done with stage: SCALING TARGETS
2022-12-31 09:30:48,198 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:30:48,198 INFO:     No hyperparam tuning for this model
2022-12-31 09:30:48,198 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:30:48,198 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 09:30:48,199 INFO:     None feature selector for col prot
2022-12-31 09:30:48,199 INFO:     None feature selector for col prot
2022-12-31 09:30:48,199 INFO:     None feature selector for col prot
2022-12-31 09:30:48,200 INFO:     None feature selector for col chem
2022-12-31 09:30:48,200 INFO:     None feature selector for col chem
2022-12-31 09:30:48,200 INFO:     None feature selector for col chem
2022-12-31 09:30:48,200 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 09:30:48,200 INFO:   Starting stage: BUILD MODEL
2022-12-31 09:30:48,202 INFO:     Number of params in model 223921
2022-12-31 09:30:48,202 INFO:   Done with stage: BUILD MODEL
2022-12-31 09:30:48,202 INFO:   Starting stage: TRAINING
2022-12-31 09:30:49,814 INFO:     Val loss before train {'Reaction outcome loss': 0.8769432743390401, 'Total loss': 0.8769432743390401}
2022-12-31 09:30:49,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:30:49,815 INFO:     Epoch: 0
2022-12-31 09:30:51,455 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6845316191514333, 'Total loss': 0.6845316191514333} | train loss {'Reaction outcome loss': 0.8433667539240239, 'Total loss': 0.8433667539240239}
2022-12-31 09:30:51,455 INFO:     Found new best model at epoch 0
2022-12-31 09:30:51,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:30:51,456 INFO:     Epoch: 1
2022-12-31 09:30:53,048 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5398665686448415, 'Total loss': 0.5398665686448415} | train loss {'Reaction outcome loss': 0.6232581357488702, 'Total loss': 0.6232581357488702}
2022-12-31 09:30:53,048 INFO:     Found new best model at epoch 1
2022-12-31 09:30:53,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:30:53,049 INFO:     Epoch: 2
2022-12-31 09:30:54,670 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49959483444690705, 'Total loss': 0.49959483444690705} | train loss {'Reaction outcome loss': 0.5362844067615468, 'Total loss': 0.5362844067615468}
2022-12-31 09:30:54,670 INFO:     Found new best model at epoch 2
2022-12-31 09:30:54,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:30:54,671 INFO:     Epoch: 3
2022-12-31 09:30:56,266 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.49795176287492116, 'Total loss': 0.49795176287492116} | train loss {'Reaction outcome loss': 0.510713344555853, 'Total loss': 0.510713344555853}
2022-12-31 09:30:56,267 INFO:     Found new best model at epoch 3
2022-12-31 09:30:56,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:30:56,268 INFO:     Epoch: 4
2022-12-31 09:30:57,862 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4981023669242859, 'Total loss': 0.4981023669242859} | train loss {'Reaction outcome loss': 0.49065967804782995, 'Total loss': 0.49065967804782995}
2022-12-31 09:30:57,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:30:57,863 INFO:     Epoch: 5
2022-12-31 09:30:59,480 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4814722036321958, 'Total loss': 0.4814722036321958} | train loss {'Reaction outcome loss': 0.48044566097822816, 'Total loss': 0.48044566097822816}
2022-12-31 09:30:59,480 INFO:     Found new best model at epoch 5
2022-12-31 09:30:59,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:30:59,481 INFO:     Epoch: 6
2022-12-31 09:31:01,108 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.467585285504659, 'Total loss': 0.467585285504659} | train loss {'Reaction outcome loss': 0.47723821629753044, 'Total loss': 0.47723821629753044}
2022-12-31 09:31:01,108 INFO:     Found new best model at epoch 6
2022-12-31 09:31:01,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:01,109 INFO:     Epoch: 7
2022-12-31 09:31:02,665 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4768621603647868, 'Total loss': 0.4768621603647868} | train loss {'Reaction outcome loss': 0.4721744804482757, 'Total loss': 0.4721744804482757}
2022-12-31 09:31:02,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:02,665 INFO:     Epoch: 8
2022-12-31 09:31:04,258 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5193223784367244, 'Total loss': 0.5193223784367244} | train loss {'Reaction outcome loss': 0.45887697250633447, 'Total loss': 0.45887697250633447}
2022-12-31 09:31:04,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:04,258 INFO:     Epoch: 9
2022-12-31 09:31:05,851 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4678682823975881, 'Total loss': 0.4678682823975881} | train loss {'Reaction outcome loss': 0.453224798207318, 'Total loss': 0.453224798207318}
2022-12-31 09:31:05,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:05,852 INFO:     Epoch: 10
2022-12-31 09:31:07,456 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46820297340552014, 'Total loss': 0.46820297340552014} | train loss {'Reaction outcome loss': 0.44568879230991826, 'Total loss': 0.44568879230991826}
2022-12-31 09:31:07,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:07,456 INFO:     Epoch: 11
2022-12-31 09:31:09,048 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4413924217224121, 'Total loss': 0.4413924217224121} | train loss {'Reaction outcome loss': 0.44610360218382583, 'Total loss': 0.44610360218382583}
2022-12-31 09:31:09,048 INFO:     Found new best model at epoch 11
2022-12-31 09:31:09,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:09,049 INFO:     Epoch: 12
2022-12-31 09:31:10,630 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4211464673280716, 'Total loss': 0.4211464673280716} | train loss {'Reaction outcome loss': 0.4370925425391494, 'Total loss': 0.4370925425391494}
2022-12-31 09:31:10,631 INFO:     Found new best model at epoch 12
2022-12-31 09:31:10,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:10,632 INFO:     Epoch: 13
2022-12-31 09:31:12,218 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45754496653874716, 'Total loss': 0.45754496653874716} | train loss {'Reaction outcome loss': 0.4257576930653918, 'Total loss': 0.4257576930653918}
2022-12-31 09:31:12,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:12,218 INFO:     Epoch: 14
2022-12-31 09:31:13,810 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4477994720141093, 'Total loss': 0.4477994720141093} | train loss {'Reaction outcome loss': 0.4213644409681851, 'Total loss': 0.4213644409681851}
2022-12-31 09:31:13,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:13,810 INFO:     Epoch: 15
2022-12-31 09:31:15,401 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44487310846646627, 'Total loss': 0.44487310846646627} | train loss {'Reaction outcome loss': 0.41930028083887727, 'Total loss': 0.41930028083887727}
2022-12-31 09:31:15,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:15,401 INFO:     Epoch: 16
2022-12-31 09:31:16,988 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4389877607425054, 'Total loss': 0.4389877607425054} | train loss {'Reaction outcome loss': 0.4155810325246154, 'Total loss': 0.4155810325246154}
2022-12-31 09:31:16,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:16,990 INFO:     Epoch: 17
2022-12-31 09:31:18,600 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.428650971253713, 'Total loss': 0.428650971253713} | train loss {'Reaction outcome loss': 0.40987994183441656, 'Total loss': 0.40987994183441656}
2022-12-31 09:31:18,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:18,600 INFO:     Epoch: 18
2022-12-31 09:31:20,178 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4418966889381409, 'Total loss': 0.4418966889381409} | train loss {'Reaction outcome loss': 0.39374545497662855, 'Total loss': 0.39374545497662855}
2022-12-31 09:31:20,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:20,178 INFO:     Epoch: 19
2022-12-31 09:31:21,757 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4071287244558334, 'Total loss': 0.4071287244558334} | train loss {'Reaction outcome loss': 0.3955625621499596, 'Total loss': 0.3955625621499596}
2022-12-31 09:31:21,757 INFO:     Found new best model at epoch 19
2022-12-31 09:31:21,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:21,758 INFO:     Epoch: 20
2022-12-31 09:31:23,352 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42126051187515257, 'Total loss': 0.42126051187515257} | train loss {'Reaction outcome loss': 0.38707644811698366, 'Total loss': 0.38707644811698366}
2022-12-31 09:31:23,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:23,353 INFO:     Epoch: 21
2022-12-31 09:31:24,946 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4059881386657556, 'Total loss': 0.4059881386657556} | train loss {'Reaction outcome loss': 0.3834999787447217, 'Total loss': 0.3834999787447217}
2022-12-31 09:31:24,946 INFO:     Found new best model at epoch 21
2022-12-31 09:31:24,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:24,947 INFO:     Epoch: 22
2022-12-31 09:31:26,543 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4159504969914754, 'Total loss': 0.4159504969914754} | train loss {'Reaction outcome loss': 0.37858120169176723, 'Total loss': 0.37858120169176723}
2022-12-31 09:31:26,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:26,543 INFO:     Epoch: 23
2022-12-31 09:31:28,145 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43079244991143545, 'Total loss': 0.43079244991143545} | train loss {'Reaction outcome loss': 0.36987686779472856, 'Total loss': 0.36987686779472856}
2022-12-31 09:31:28,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:28,146 INFO:     Epoch: 24
2022-12-31 09:31:29,701 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42076798776785534, 'Total loss': 0.42076798776785534} | train loss {'Reaction outcome loss': 0.3700588771002197, 'Total loss': 0.3700588771002197}
2022-12-31 09:31:29,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:29,701 INFO:     Epoch: 25
2022-12-31 09:31:31,300 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4027295480171839, 'Total loss': 0.4027295480171839} | train loss {'Reaction outcome loss': 0.36061873606273104, 'Total loss': 0.36061873606273104}
2022-12-31 09:31:31,300 INFO:     Found new best model at epoch 25
2022-12-31 09:31:31,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:31,301 INFO:     Epoch: 26
2022-12-31 09:31:32,895 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4019190758466721, 'Total loss': 0.4019190758466721} | train loss {'Reaction outcome loss': 0.3596956382195155, 'Total loss': 0.3596956382195155}
2022-12-31 09:31:32,895 INFO:     Found new best model at epoch 26
2022-12-31 09:31:32,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:32,896 INFO:     Epoch: 27
2022-12-31 09:31:34,491 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40206801692644756, 'Total loss': 0.40206801692644756} | train loss {'Reaction outcome loss': 0.3515083222162156, 'Total loss': 0.3515083222162156}
2022-12-31 09:31:34,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:34,492 INFO:     Epoch: 28
2022-12-31 09:31:36,096 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41501493950684865, 'Total loss': 0.41501493950684865} | train loss {'Reaction outcome loss': 0.34567194816830393, 'Total loss': 0.34567194816830393}
2022-12-31 09:31:36,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:36,096 INFO:     Epoch: 29
2022-12-31 09:31:37,704 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4082236657540003, 'Total loss': 0.4082236657540003} | train loss {'Reaction outcome loss': 0.34553740239077874, 'Total loss': 0.34553740239077874}
2022-12-31 09:31:37,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:37,705 INFO:     Epoch: 30
2022-12-31 09:31:39,301 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.438701456785202, 'Total loss': 0.438701456785202} | train loss {'Reaction outcome loss': 0.3450420363209186, 'Total loss': 0.3450420363209186}
2022-12-31 09:31:39,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:39,302 INFO:     Epoch: 31
2022-12-31 09:31:40,927 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4074777940909068, 'Total loss': 0.4074777940909068} | train loss {'Reaction outcome loss': 0.33799415829526636, 'Total loss': 0.33799415829526636}
2022-12-31 09:31:40,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:40,928 INFO:     Epoch: 32
2022-12-31 09:31:42,530 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3940153976281484, 'Total loss': 0.3940153976281484} | train loss {'Reaction outcome loss': 0.3340894969746525, 'Total loss': 0.3340894969746525}
2022-12-31 09:31:42,531 INFO:     Found new best model at epoch 32
2022-12-31 09:31:42,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:42,531 INFO:     Epoch: 33
2022-12-31 09:31:44,123 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.415213746825854, 'Total loss': 0.415213746825854} | train loss {'Reaction outcome loss': 0.3223781626135957, 'Total loss': 0.3223781626135957}
2022-12-31 09:31:44,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:44,123 INFO:     Epoch: 34
2022-12-31 09:31:45,716 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40107899606227876, 'Total loss': 0.40107899606227876} | train loss {'Reaction outcome loss': 0.32548358797644955, 'Total loss': 0.32548358797644955}
2022-12-31 09:31:45,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:45,717 INFO:     Epoch: 35
2022-12-31 09:31:47,311 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.37634233633677167, 'Total loss': 0.37634233633677167} | train loss {'Reaction outcome loss': 0.3200632460456301, 'Total loss': 0.3200632460456301}
2022-12-31 09:31:47,311 INFO:     Found new best model at epoch 35
2022-12-31 09:31:47,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:47,312 INFO:     Epoch: 36
2022-12-31 09:31:48,881 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.39076824188232423, 'Total loss': 0.39076824188232423} | train loss {'Reaction outcome loss': 0.3179750315872304, 'Total loss': 0.3179750315872304}
2022-12-31 09:31:48,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:48,882 INFO:     Epoch: 37
2022-12-31 09:31:50,474 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3953807512919108, 'Total loss': 0.3953807512919108} | train loss {'Reaction outcome loss': 0.3131539767314663, 'Total loss': 0.3131539767314663}
2022-12-31 09:31:50,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:50,475 INFO:     Epoch: 38
2022-12-31 09:31:52,068 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4038266479969025, 'Total loss': 0.4038266479969025} | train loss {'Reaction outcome loss': 0.314587492564004, 'Total loss': 0.314587492564004}
2022-12-31 09:31:52,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:52,069 INFO:     Epoch: 39
2022-12-31 09:31:53,660 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4049179712931315, 'Total loss': 0.4049179712931315} | train loss {'Reaction outcome loss': 0.3091574920675693, 'Total loss': 0.3091574920675693}
2022-12-31 09:31:53,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:53,661 INFO:     Epoch: 40
2022-12-31 09:31:55,249 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.36896129747231804, 'Total loss': 0.36896129747231804} | train loss {'Reaction outcome loss': 0.3083982242223544, 'Total loss': 0.3083982242223544}
2022-12-31 09:31:55,249 INFO:     Found new best model at epoch 40
2022-12-31 09:31:55,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:55,250 INFO:     Epoch: 41
2022-12-31 09:31:56,813 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.36400820389389993, 'Total loss': 0.36400820389389993} | train loss {'Reaction outcome loss': 0.2986449105426287, 'Total loss': 0.2986449105426287}
2022-12-31 09:31:56,813 INFO:     Found new best model at epoch 41
2022-12-31 09:31:56,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:56,814 INFO:     Epoch: 42
2022-12-31 09:31:58,408 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40570023059844973, 'Total loss': 0.40570023059844973} | train loss {'Reaction outcome loss': 0.29620779659121466, 'Total loss': 0.29620779659121466}
2022-12-31 09:31:58,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:31:58,409 INFO:     Epoch: 43
2022-12-31 09:32:00,002 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3893950710693995, 'Total loss': 0.3893950710693995} | train loss {'Reaction outcome loss': 0.30310480136956486, 'Total loss': 0.30310480136956486}
2022-12-31 09:32:00,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:00,002 INFO:     Epoch: 44
2022-12-31 09:32:01,596 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.39509318470954896, 'Total loss': 0.39509318470954896} | train loss {'Reaction outcome loss': 0.2934910778242808, 'Total loss': 0.2934910778242808}
2022-12-31 09:32:01,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:01,596 INFO:     Epoch: 45
2022-12-31 09:32:03,189 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41631887952486674, 'Total loss': 0.41631887952486674} | train loss {'Reaction outcome loss': 0.2866191779273552, 'Total loss': 0.2866191779273552}
2022-12-31 09:32:03,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:03,190 INFO:     Epoch: 46
2022-12-31 09:32:04,766 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39601597711443903, 'Total loss': 0.39601597711443903} | train loss {'Reaction outcome loss': 0.2861266697999158, 'Total loss': 0.2861266697999158}
2022-12-31 09:32:04,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:04,767 INFO:     Epoch: 47
2022-12-31 09:32:06,339 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42394850850105287, 'Total loss': 0.42394850850105287} | train loss {'Reaction outcome loss': 0.28099123202946596, 'Total loss': 0.28099123202946596}
2022-12-31 09:32:06,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:06,339 INFO:     Epoch: 48
2022-12-31 09:32:07,936 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4028232345978419, 'Total loss': 0.4028232345978419} | train loss {'Reaction outcome loss': 0.2794216989706724, 'Total loss': 0.2794216989706724}
2022-12-31 09:32:07,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:07,936 INFO:     Epoch: 49
2022-12-31 09:32:09,534 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.36146420737107593, 'Total loss': 0.36146420737107593} | train loss {'Reaction outcome loss': 0.2883429329965141, 'Total loss': 0.2883429329965141}
2022-12-31 09:32:09,534 INFO:     Found new best model at epoch 49
2022-12-31 09:32:09,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:09,535 INFO:     Epoch: 50
2022-12-31 09:32:11,130 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42090864380200704, 'Total loss': 0.42090864380200704} | train loss {'Reaction outcome loss': 0.27375610024009867, 'Total loss': 0.27375610024009867}
2022-12-31 09:32:11,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:11,132 INFO:     Epoch: 51
2022-12-31 09:32:12,727 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.38834372063477834, 'Total loss': 0.38834372063477834} | train loss {'Reaction outcome loss': 0.27591795786778567, 'Total loss': 0.27591795786778567}
2022-12-31 09:32:12,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:12,728 INFO:     Epoch: 52
2022-12-31 09:32:14,308 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3615540454785029, 'Total loss': 0.3615540454785029} | train loss {'Reaction outcome loss': 0.27158494490188556, 'Total loss': 0.27158494490188556}
2022-12-31 09:32:14,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:14,308 INFO:     Epoch: 53
2022-12-31 09:32:15,898 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3687516083319982, 'Total loss': 0.3687516083319982} | train loss {'Reaction outcome loss': 0.2655103733087634, 'Total loss': 0.2655103733087634}
2022-12-31 09:32:15,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:15,898 INFO:     Epoch: 54
2022-12-31 09:32:17,490 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3664956202109655, 'Total loss': 0.3664956202109655} | train loss {'Reaction outcome loss': 0.2612272265073826, 'Total loss': 0.2612272265073826}
2022-12-31 09:32:17,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:17,491 INFO:     Epoch: 55
2022-12-31 09:32:19,084 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4269641806681951, 'Total loss': 0.4269641806681951} | train loss {'Reaction outcome loss': 0.25672172231006096, 'Total loss': 0.25672172231006096}
2022-12-31 09:32:19,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:19,084 INFO:     Epoch: 56
2022-12-31 09:32:20,678 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39425792594750725, 'Total loss': 0.39425792594750725} | train loss {'Reaction outcome loss': 0.2614430421246932, 'Total loss': 0.2614430421246932}
2022-12-31 09:32:20,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:20,678 INFO:     Epoch: 57
2022-12-31 09:32:22,268 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.39678904265165327, 'Total loss': 0.39678904265165327} | train loss {'Reaction outcome loss': 0.2609245807423696, 'Total loss': 0.2609245807423696}
2022-12-31 09:32:22,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:22,269 INFO:     Epoch: 58
2022-12-31 09:32:23,850 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.375028158724308, 'Total loss': 0.375028158724308} | train loss {'Reaction outcome loss': 0.25977532550583393, 'Total loss': 0.25977532550583393}
2022-12-31 09:32:23,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:23,850 INFO:     Epoch: 59
2022-12-31 09:32:25,486 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38864499926567075, 'Total loss': 0.38864499926567075} | train loss {'Reaction outcome loss': 0.2621524495690133, 'Total loss': 0.2621524495690133}
2022-12-31 09:32:25,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:25,486 INFO:     Epoch: 60
2022-12-31 09:32:27,117 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3576344167192777, 'Total loss': 0.3576344167192777} | train loss {'Reaction outcome loss': 0.2576460740204914, 'Total loss': 0.2576460740204914}
2022-12-31 09:32:27,117 INFO:     Found new best model at epoch 60
2022-12-31 09:32:27,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:27,118 INFO:     Epoch: 61
2022-12-31 09:32:28,762 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4378812809785207, 'Total loss': 0.4378812809785207} | train loss {'Reaction outcome loss': 0.24446359040700036, 'Total loss': 0.24446359040700036}
2022-12-31 09:32:28,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:28,763 INFO:     Epoch: 62
2022-12-31 09:32:30,351 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41949490308761594, 'Total loss': 0.41949490308761594} | train loss {'Reaction outcome loss': 0.2549420729170352, 'Total loss': 0.2549420729170352}
2022-12-31 09:32:30,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:30,351 INFO:     Epoch: 63
2022-12-31 09:32:31,932 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.36762163589398067, 'Total loss': 0.36762163589398067} | train loss {'Reaction outcome loss': 0.2570824939552899, 'Total loss': 0.2570824939552899}
2022-12-31 09:32:31,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:31,932 INFO:     Epoch: 64
2022-12-31 09:32:33,503 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4320035179456075, 'Total loss': 0.4320035179456075} | train loss {'Reaction outcome loss': 0.24410835590773014, 'Total loss': 0.24410835590773014}
2022-12-31 09:32:33,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:33,503 INFO:     Epoch: 65
2022-12-31 09:32:35,097 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.358000123500824, 'Total loss': 0.358000123500824} | train loss {'Reaction outcome loss': 0.2504237322170874, 'Total loss': 0.2504237322170874}
2022-12-31 09:32:35,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:35,099 INFO:     Epoch: 66
2022-12-31 09:32:36,692 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.37016864866018295, 'Total loss': 0.37016864866018295} | train loss {'Reaction outcome loss': 0.2436546986076585, 'Total loss': 0.2436546986076585}
2022-12-31 09:32:36,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:36,692 INFO:     Epoch: 67
2022-12-31 09:32:38,287 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3946447968482971, 'Total loss': 0.3946447968482971} | train loss {'Reaction outcome loss': 0.24037352935052836, 'Total loss': 0.24037352935052836}
2022-12-31 09:32:38,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:38,288 INFO:     Epoch: 68
2022-12-31 09:32:39,886 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.37975656762719157, 'Total loss': 0.37975656762719157} | train loss {'Reaction outcome loss': 0.2383283937534133, 'Total loss': 0.2383283937534133}
2022-12-31 09:32:39,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:39,887 INFO:     Epoch: 69
2022-12-31 09:32:41,465 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40428694784641267, 'Total loss': 0.40428694784641267} | train loss {'Reaction outcome loss': 0.24254524761012622, 'Total loss': 0.24254524761012622}
2022-12-31 09:32:41,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:41,466 INFO:     Epoch: 70
2022-12-31 09:32:43,065 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3626119554042816, 'Total loss': 0.3626119554042816} | train loss {'Reaction outcome loss': 0.23497869380350625, 'Total loss': 0.23497869380350625}
2022-12-31 09:32:43,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:43,065 INFO:     Epoch: 71
2022-12-31 09:32:44,699 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.391880198319753, 'Total loss': 0.391880198319753} | train loss {'Reaction outcome loss': 0.23793384417782337, 'Total loss': 0.23793384417782337}
2022-12-31 09:32:44,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:44,699 INFO:     Epoch: 72
2022-12-31 09:32:46,299 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40094157457351687, 'Total loss': 0.40094157457351687} | train loss {'Reaction outcome loss': 0.2348215438207209, 'Total loss': 0.2348215438207209}
2022-12-31 09:32:46,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:46,299 INFO:     Epoch: 73
2022-12-31 09:32:47,899 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45605307817459106, 'Total loss': 0.45605307817459106} | train loss {'Reaction outcome loss': 0.2313773846287867, 'Total loss': 0.2313773846287867}
2022-12-31 09:32:47,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:47,900 INFO:     Epoch: 74
2022-12-31 09:32:49,492 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39347725808620454, 'Total loss': 0.39347725808620454} | train loss {'Reaction outcome loss': 0.23419091661525515, 'Total loss': 0.23419091661525515}
2022-12-31 09:32:49,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:49,492 INFO:     Epoch: 75
2022-12-31 09:32:51,063 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3896037732561429, 'Total loss': 0.3896037732561429} | train loss {'Reaction outcome loss': 0.22998089120883644, 'Total loss': 0.22998089120883644}
2022-12-31 09:32:51,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:51,064 INFO:     Epoch: 76
2022-12-31 09:32:52,659 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41561172405878705, 'Total loss': 0.41561172405878705} | train loss {'Reaction outcome loss': 0.22485227278355277, 'Total loss': 0.22485227278355277}
2022-12-31 09:32:52,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:52,659 INFO:     Epoch: 77
2022-12-31 09:32:54,255 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4054961164792379, 'Total loss': 0.4054961164792379} | train loss {'Reaction outcome loss': 0.23593721235164136, 'Total loss': 0.23593721235164136}
2022-12-31 09:32:54,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:54,257 INFO:     Epoch: 78
2022-12-31 09:32:55,851 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4820491453011831, 'Total loss': 0.4820491453011831} | train loss {'Reaction outcome loss': 0.2292105068653931, 'Total loss': 0.2292105068653931}
2022-12-31 09:32:55,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:55,852 INFO:     Epoch: 79
2022-12-31 09:32:57,446 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44107110997041066, 'Total loss': 0.44107110997041066} | train loss {'Reaction outcome loss': 0.23099215499947579, 'Total loss': 0.23099215499947579}
2022-12-31 09:32:57,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:57,447 INFO:     Epoch: 80
2022-12-31 09:32:59,033 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4055774688720703, 'Total loss': 0.4055774688720703} | train loss {'Reaction outcome loss': 0.22631629556417465, 'Total loss': 0.22631629556417465}
2022-12-31 09:32:59,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:32:59,034 INFO:     Epoch: 81
2022-12-31 09:33:00,605 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42042038838068646, 'Total loss': 0.42042038838068646} | train loss {'Reaction outcome loss': 0.2250781740733992, 'Total loss': 0.2250781740733992}
2022-12-31 09:33:00,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:00,605 INFO:     Epoch: 82
2022-12-31 09:33:02,200 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4228225201368332, 'Total loss': 0.4228225201368332} | train loss {'Reaction outcome loss': 0.21793621485104492, 'Total loss': 0.21793621485104492}
2022-12-31 09:33:02,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:02,201 INFO:     Epoch: 83
2022-12-31 09:33:03,797 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.38964892079432806, 'Total loss': 0.38964892079432806} | train loss {'Reaction outcome loss': 0.22211503649587597, 'Total loss': 0.22211503649587597}
2022-12-31 09:33:03,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:03,797 INFO:     Epoch: 84
2022-12-31 09:33:05,393 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.391862161954244, 'Total loss': 0.391862161954244} | train loss {'Reaction outcome loss': 0.21975629681195968, 'Total loss': 0.21975629681195968}
2022-12-31 09:33:05,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:05,393 INFO:     Epoch: 85
2022-12-31 09:33:06,989 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4223086650172869, 'Total loss': 0.4223086650172869} | train loss {'Reaction outcome loss': 0.2269777845413912, 'Total loss': 0.2269777845413912}
2022-12-31 09:33:06,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:06,990 INFO:     Epoch: 86
2022-12-31 09:33:08,567 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.406976547340552, 'Total loss': 0.406976547340552} | train loss {'Reaction outcome loss': 0.21679379455676992, 'Total loss': 0.21679379455676992}
2022-12-31 09:33:08,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:08,567 INFO:     Epoch: 87
2022-12-31 09:33:10,145 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39750789379080137, 'Total loss': 0.39750789379080137} | train loss {'Reaction outcome loss': 0.21436269548568096, 'Total loss': 0.21436269548568096}
2022-12-31 09:33:10,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:10,146 INFO:     Epoch: 88
2022-12-31 09:33:11,741 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4287524571021398, 'Total loss': 0.4287524571021398} | train loss {'Reaction outcome loss': 0.22357432793266388, 'Total loss': 0.22357432793266388}
2022-12-31 09:33:11,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:11,741 INFO:     Epoch: 89
2022-12-31 09:33:13,333 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3930431857705116, 'Total loss': 0.3930431857705116} | train loss {'Reaction outcome loss': 0.2195602511720998, 'Total loss': 0.2195602511720998}
2022-12-31 09:33:13,334 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:13,334 INFO:     Epoch: 90
2022-12-31 09:33:14,926 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4335405319929123, 'Total loss': 0.4335405319929123} | train loss {'Reaction outcome loss': 0.2115088094737135, 'Total loss': 0.2115088094737135}
2022-12-31 09:33:14,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:14,926 INFO:     Epoch: 91
2022-12-31 09:33:16,511 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.40709728995958966, 'Total loss': 0.40709728995958966} | train loss {'Reaction outcome loss': 0.20531377133541492, 'Total loss': 0.20531377133541492}
2022-12-31 09:33:16,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:16,512 INFO:     Epoch: 92
2022-12-31 09:33:18,067 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40651092380285264, 'Total loss': 0.40651092380285264} | train loss {'Reaction outcome loss': 0.21296360154701022, 'Total loss': 0.21296360154701022}
2022-12-31 09:33:18,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:18,067 INFO:     Epoch: 93
2022-12-31 09:33:19,669 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.411960968375206, 'Total loss': 0.411960968375206} | train loss {'Reaction outcome loss': 0.21339807413764053, 'Total loss': 0.21339807413764053}
2022-12-31 09:33:19,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:19,670 INFO:     Epoch: 94
2022-12-31 09:33:21,266 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41522764166196185, 'Total loss': 0.41522764166196185} | train loss {'Reaction outcome loss': 0.213126911686208, 'Total loss': 0.213126911686208}
2022-12-31 09:33:21,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:21,266 INFO:     Epoch: 95
2022-12-31 09:33:22,865 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.39086241523424786, 'Total loss': 0.39086241523424786} | train loss {'Reaction outcome loss': 0.20690228753201254, 'Total loss': 0.20690228753201254}
2022-12-31 09:33:22,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:22,865 INFO:     Epoch: 96
2022-12-31 09:33:24,464 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4388154099384944, 'Total loss': 0.4388154099384944} | train loss {'Reaction outcome loss': 0.20957779665324058, 'Total loss': 0.20957779665324058}
2022-12-31 09:33:24,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:24,464 INFO:     Epoch: 97
2022-12-31 09:33:26,047 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4388548831144969, 'Total loss': 0.4388548831144969} | train loss {'Reaction outcome loss': 0.20563104613803518, 'Total loss': 0.20563104613803518}
2022-12-31 09:33:26,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:26,048 INFO:     Epoch: 98
2022-12-31 09:33:27,623 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4218513906002045, 'Total loss': 0.4218513906002045} | train loss {'Reaction outcome loss': 0.20902894711592696, 'Total loss': 0.20902894711592696}
2022-12-31 09:33:27,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:27,624 INFO:     Epoch: 99
2022-12-31 09:33:29,221 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.38963728708525497, 'Total loss': 0.38963728708525497} | train loss {'Reaction outcome loss': 0.20886385554768444, 'Total loss': 0.20886385554768444}
2022-12-31 09:33:29,222 INFO:     Best model found after epoch 61 of 100.
2022-12-31 09:33:29,222 INFO:   Done with stage: TRAINING
2022-12-31 09:33:29,222 INFO:   Starting stage: EVALUATION
2022-12-31 09:33:29,359 INFO:   Done with stage: EVALUATION
2022-12-31 09:33:29,359 INFO:   Leaving out SEQ value Fold_1
2022-12-31 09:33:29,371 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 09:33:29,371 INFO:   Starting stage: FEATURE SCALING
2022-12-31 09:33:30,025 INFO:   Done with stage: FEATURE SCALING
2022-12-31 09:33:30,025 INFO:   Starting stage: SCALING TARGETS
2022-12-31 09:33:30,094 INFO:   Done with stage: SCALING TARGETS
2022-12-31 09:33:30,095 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:33:30,095 INFO:     No hyperparam tuning for this model
2022-12-31 09:33:30,095 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:33:30,095 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 09:33:30,095 INFO:     None feature selector for col prot
2022-12-31 09:33:30,096 INFO:     None feature selector for col prot
2022-12-31 09:33:30,096 INFO:     None feature selector for col prot
2022-12-31 09:33:30,096 INFO:     None feature selector for col chem
2022-12-31 09:33:30,096 INFO:     None feature selector for col chem
2022-12-31 09:33:30,096 INFO:     None feature selector for col chem
2022-12-31 09:33:30,096 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 09:33:30,096 INFO:   Starting stage: BUILD MODEL
2022-12-31 09:33:30,098 INFO:     Number of params in model 223921
2022-12-31 09:33:30,101 INFO:   Done with stage: BUILD MODEL
2022-12-31 09:33:30,101 INFO:   Starting stage: TRAINING
2022-12-31 09:33:30,147 INFO:     Val loss before train {'Reaction outcome loss': 1.0045692443847656, 'Total loss': 1.0045692443847656}
2022-12-31 09:33:30,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:30,147 INFO:     Epoch: 0
2022-12-31 09:33:31,754 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7041277348995209, 'Total loss': 0.7041277348995209} | train loss {'Reaction outcome loss': 0.8135134496834076, 'Total loss': 0.8135134496834076}
2022-12-31 09:33:31,755 INFO:     Found new best model at epoch 0
2022-12-31 09:33:31,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:31,756 INFO:     Epoch: 1
2022-12-31 09:33:33,363 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6261291881402333, 'Total loss': 0.6261291881402333} | train loss {'Reaction outcome loss': 0.6001329540808186, 'Total loss': 0.6001329540808186}
2022-12-31 09:33:33,363 INFO:     Found new best model at epoch 1
2022-12-31 09:33:33,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:33,364 INFO:     Epoch: 2
2022-12-31 09:33:34,968 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6206487496693929, 'Total loss': 0.6206487496693929} | train loss {'Reaction outcome loss': 0.5623818017218424, 'Total loss': 0.5623818017218424}
2022-12-31 09:33:34,968 INFO:     Found new best model at epoch 2
2022-12-31 09:33:34,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:34,969 INFO:     Epoch: 3
2022-12-31 09:33:36,564 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.621833594640096, 'Total loss': 0.621833594640096} | train loss {'Reaction outcome loss': 0.5381355608950126, 'Total loss': 0.5381355608950126}
2022-12-31 09:33:36,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:36,564 INFO:     Epoch: 4
2022-12-31 09:33:38,176 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5942588786284129, 'Total loss': 0.5942588786284129} | train loss {'Reaction outcome loss': 0.4937185775353641, 'Total loss': 0.4937185775353641}
2022-12-31 09:33:38,177 INFO:     Found new best model at epoch 4
2022-12-31 09:33:38,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:38,178 INFO:     Epoch: 5
2022-12-31 09:33:39,786 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5969765663146973, 'Total loss': 0.5969765663146973} | train loss {'Reaction outcome loss': 0.4741084560131033, 'Total loss': 0.4741084560131033}
2022-12-31 09:33:39,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:39,786 INFO:     Epoch: 6
2022-12-31 09:33:41,394 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5836174468199412, 'Total loss': 0.5836174468199412} | train loss {'Reaction outcome loss': 0.46309310670071485, 'Total loss': 0.46309310670071485}
2022-12-31 09:33:41,394 INFO:     Found new best model at epoch 6
2022-12-31 09:33:41,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:41,395 INFO:     Epoch: 7
2022-12-31 09:33:43,001 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5616440852483113, 'Total loss': 0.5616440852483113} | train loss {'Reaction outcome loss': 0.46170401860338944, 'Total loss': 0.46170401860338944}
2022-12-31 09:33:43,003 INFO:     Found new best model at epoch 7
2022-12-31 09:33:43,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:43,004 INFO:     Epoch: 8
2022-12-31 09:33:44,597 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.6197852571805318, 'Total loss': 0.6197852571805318} | train loss {'Reaction outcome loss': 0.45408385479147884, 'Total loss': 0.45408385479147884}
2022-12-31 09:33:44,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:44,598 INFO:     Epoch: 9
2022-12-31 09:33:46,190 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.558424029747645, 'Total loss': 0.558424029747645} | train loss {'Reaction outcome loss': 0.44857009395069536, 'Total loss': 0.44857009395069536}
2022-12-31 09:33:46,190 INFO:     Found new best model at epoch 9
2022-12-31 09:33:46,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:46,191 INFO:     Epoch: 10
2022-12-31 09:33:47,793 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.6002272049585978, 'Total loss': 0.6002272049585978} | train loss {'Reaction outcome loss': 0.4433200752389604, 'Total loss': 0.4433200752389604}
2022-12-31 09:33:47,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:47,793 INFO:     Epoch: 11
2022-12-31 09:33:49,434 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5699209252993266, 'Total loss': 0.5699209252993266} | train loss {'Reaction outcome loss': 0.4434968579385052, 'Total loss': 0.4434968579385052}
2022-12-31 09:33:49,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:49,435 INFO:     Epoch: 12
2022-12-31 09:33:51,080 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5593439102172851, 'Total loss': 0.5593439102172851} | train loss {'Reaction outcome loss': 0.4323528448143591, 'Total loss': 0.4323528448143591}
2022-12-31 09:33:51,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:51,081 INFO:     Epoch: 13
2022-12-31 09:33:52,701 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5589202046394348, 'Total loss': 0.5589202046394348} | train loss {'Reaction outcome loss': 0.427478917563955, 'Total loss': 0.427478917563955}
2022-12-31 09:33:52,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:52,701 INFO:     Epoch: 14
2022-12-31 09:33:54,312 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5321010410785675, 'Total loss': 0.5321010410785675} | train loss {'Reaction outcome loss': 0.42247393902769126, 'Total loss': 0.42247393902769126}
2022-12-31 09:33:54,313 INFO:     Found new best model at epoch 14
2022-12-31 09:33:54,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:54,314 INFO:     Epoch: 15
2022-12-31 09:33:55,945 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5388147075970967, 'Total loss': 0.5388147075970967} | train loss {'Reaction outcome loss': 0.4174022665951718, 'Total loss': 0.4174022665951718}
2022-12-31 09:33:55,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:55,945 INFO:     Epoch: 16
2022-12-31 09:33:57,592 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.529830660422643, 'Total loss': 0.529830660422643} | train loss {'Reaction outcome loss': 0.4082029216511148, 'Total loss': 0.4082029216511148}
2022-12-31 09:33:57,592 INFO:     Found new best model at epoch 16
2022-12-31 09:33:57,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:57,593 INFO:     Epoch: 17
2022-12-31 09:33:59,251 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5472123483816783, 'Total loss': 0.5472123483816783} | train loss {'Reaction outcome loss': 0.4052008274904464, 'Total loss': 0.4052008274904464}
2022-12-31 09:33:59,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:33:59,251 INFO:     Epoch: 18
2022-12-31 09:34:00,890 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5653616229693095, 'Total loss': 0.5653616229693095} | train loss {'Reaction outcome loss': 0.39714690950105264, 'Total loss': 0.39714690950105264}
2022-12-31 09:34:00,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:00,891 INFO:     Epoch: 19
2022-12-31 09:34:02,491 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5512924075126648, 'Total loss': 0.5512924075126648} | train loss {'Reaction outcome loss': 0.39074958619945077, 'Total loss': 0.39074958619945077}
2022-12-31 09:34:02,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:02,491 INFO:     Epoch: 20
2022-12-31 09:34:04,108 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.612303630510966, 'Total loss': 0.612303630510966} | train loss {'Reaction outcome loss': 0.38457638694756274, 'Total loss': 0.38457638694756274}
2022-12-31 09:34:04,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:04,108 INFO:     Epoch: 21
2022-12-31 09:34:05,720 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5421309093634288, 'Total loss': 0.5421309093634288} | train loss {'Reaction outcome loss': 0.38075405795910006, 'Total loss': 0.38075405795910006}
2022-12-31 09:34:05,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:05,721 INFO:     Epoch: 22
2022-12-31 09:34:07,334 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5177953859170278, 'Total loss': 0.5177953859170278} | train loss {'Reaction outcome loss': 0.3773609884268861, 'Total loss': 0.3773609884268861}
2022-12-31 09:34:07,335 INFO:     Found new best model at epoch 22
2022-12-31 09:34:07,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:07,336 INFO:     Epoch: 23
2022-12-31 09:34:08,946 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5328313529491424, 'Total loss': 0.5328313529491424} | train loss {'Reaction outcome loss': 0.3705827398390165, 'Total loss': 0.3705827398390165}
2022-12-31 09:34:08,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:08,946 INFO:     Epoch: 24
2022-12-31 09:34:10,554 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5537655393282572, 'Total loss': 0.5537655393282572} | train loss {'Reaction outcome loss': 0.37407392861348565, 'Total loss': 0.37407392861348565}
2022-12-31 09:34:10,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:10,554 INFO:     Epoch: 25
2022-12-31 09:34:12,144 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5431027313073477, 'Total loss': 0.5431027313073477} | train loss {'Reaction outcome loss': 0.36755641827324365, 'Total loss': 0.36755641827324365}
2022-12-31 09:34:12,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:12,145 INFO:     Epoch: 26
2022-12-31 09:34:13,799 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4866104821364085, 'Total loss': 0.4866104821364085} | train loss {'Reaction outcome loss': 0.3636565657705406, 'Total loss': 0.3636565657705406}
2022-12-31 09:34:13,799 INFO:     Found new best model at epoch 26
2022-12-31 09:34:13,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:13,800 INFO:     Epoch: 27
2022-12-31 09:34:15,414 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5188765406608582, 'Total loss': 0.5188765406608582} | train loss {'Reaction outcome loss': 0.35364817506195034, 'Total loss': 0.35364817506195034}
2022-12-31 09:34:15,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:15,415 INFO:     Epoch: 28
2022-12-31 09:34:17,025 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.530978282292684, 'Total loss': 0.530978282292684} | train loss {'Reaction outcome loss': 0.3490718462339103, 'Total loss': 0.3490718462339103}
2022-12-31 09:34:17,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:17,026 INFO:     Epoch: 29
2022-12-31 09:34:18,635 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5165335516134898, 'Total loss': 0.5165335516134898} | train loss {'Reaction outcome loss': 0.34520991193594586, 'Total loss': 0.34520991193594586}
2022-12-31 09:34:18,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:18,635 INFO:     Epoch: 30
2022-12-31 09:34:20,228 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5128642638524373, 'Total loss': 0.5128642638524373} | train loss {'Reaction outcome loss': 0.34120166236939636, 'Total loss': 0.34120166236939636}
2022-12-31 09:34:20,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:20,228 INFO:     Epoch: 31
2022-12-31 09:34:21,833 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5018541157245636, 'Total loss': 0.5018541157245636} | train loss {'Reaction outcome loss': 0.33484417912457476, 'Total loss': 0.33484417912457476}
2022-12-31 09:34:21,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:21,834 INFO:     Epoch: 32
2022-12-31 09:34:23,503 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5092452734708786, 'Total loss': 0.5092452734708786} | train loss {'Reaction outcome loss': 0.3336270225868709, 'Total loss': 0.3336270225868709}
2022-12-31 09:34:23,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:23,503 INFO:     Epoch: 33
2022-12-31 09:34:25,168 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.49237414201100665, 'Total loss': 0.49237414201100665} | train loss {'Reaction outcome loss': 0.39086604195788666, 'Total loss': 0.39086604195788666}
2022-12-31 09:34:25,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:25,168 INFO:     Epoch: 34
2022-12-31 09:34:26,820 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5241203318039577, 'Total loss': 0.5241203318039577} | train loss {'Reaction outcome loss': 0.340769701964034, 'Total loss': 0.340769701964034}
2022-12-31 09:34:26,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:26,821 INFO:     Epoch: 35
2022-12-31 09:34:28,452 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.48192787965138756, 'Total loss': 0.48192787965138756} | train loss {'Reaction outcome loss': 0.3285874038043877, 'Total loss': 0.3285874038043877}
2022-12-31 09:34:28,453 INFO:     Found new best model at epoch 35
2022-12-31 09:34:28,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:28,453 INFO:     Epoch: 36
2022-12-31 09:34:30,055 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.49321619073549905, 'Total loss': 0.49321619073549905} | train loss {'Reaction outcome loss': 0.34630529336847254, 'Total loss': 0.34630529336847254}
2022-12-31 09:34:30,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:30,055 INFO:     Epoch: 37
2022-12-31 09:34:31,646 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.512291760245959, 'Total loss': 0.512291760245959} | train loss {'Reaction outcome loss': 0.32617043765882653, 'Total loss': 0.32617043765882653}
2022-12-31 09:34:31,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:31,646 INFO:     Epoch: 38
2022-12-31 09:34:33,257 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5142179518938065, 'Total loss': 0.5142179518938065} | train loss {'Reaction outcome loss': 0.31762236764188856, 'Total loss': 0.31762236764188856}
2022-12-31 09:34:33,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:33,258 INFO:     Epoch: 39
2022-12-31 09:34:34,867 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5104121367136637, 'Total loss': 0.5104121367136637} | train loss {'Reaction outcome loss': 0.30692396487638296, 'Total loss': 0.30692396487638296}
2022-12-31 09:34:34,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:34,867 INFO:     Epoch: 40
2022-12-31 09:34:36,476 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48030505577723187, 'Total loss': 0.48030505577723187} | train loss {'Reaction outcome loss': 0.30149827531755075, 'Total loss': 0.30149827531755075}
2022-12-31 09:34:36,476 INFO:     Found new best model at epoch 40
2022-12-31 09:34:36,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:36,477 INFO:     Epoch: 41
2022-12-31 09:34:38,063 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5135907232761383, 'Total loss': 0.5135907232761383} | train loss {'Reaction outcome loss': 0.301949188788084, 'Total loss': 0.301949188788084}
2022-12-31 09:34:38,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:38,063 INFO:     Epoch: 42
2022-12-31 09:34:39,685 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.48910369475682575, 'Total loss': 0.48910369475682575} | train loss {'Reaction outcome loss': 0.2953634423834771, 'Total loss': 0.2953634423834771}
2022-12-31 09:34:39,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:39,686 INFO:     Epoch: 43
2022-12-31 09:34:41,315 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4669868399699529, 'Total loss': 0.4669868399699529} | train loss {'Reaction outcome loss': 0.29311193946573505, 'Total loss': 0.29311193946573505}
2022-12-31 09:34:41,315 INFO:     Found new best model at epoch 43
2022-12-31 09:34:41,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:41,316 INFO:     Epoch: 44
2022-12-31 09:34:42,925 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5045813143253326, 'Total loss': 0.5045813143253326} | train loss {'Reaction outcome loss': 0.2827864952547395, 'Total loss': 0.2827864952547395}
2022-12-31 09:34:42,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:42,925 INFO:     Epoch: 45
2022-12-31 09:34:44,536 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4703005706270536, 'Total loss': 0.4703005706270536} | train loss {'Reaction outcome loss': 0.2853456910522874, 'Total loss': 0.2853456910522874}
2022-12-31 09:34:44,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:44,537 INFO:     Epoch: 46
2022-12-31 09:34:46,148 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.48602007031440736, 'Total loss': 0.48602007031440736} | train loss {'Reaction outcome loss': 0.28620494156063575, 'Total loss': 0.28620494156063575}
2022-12-31 09:34:46,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:46,149 INFO:     Epoch: 47
2022-12-31 09:34:47,745 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5019237438837687, 'Total loss': 0.5019237438837687} | train loss {'Reaction outcome loss': 0.2832235218695554, 'Total loss': 0.2832235218695554}
2022-12-31 09:34:47,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:47,745 INFO:     Epoch: 48
2022-12-31 09:34:49,041 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4815076172351837, 'Total loss': 0.4815076172351837} | train loss {'Reaction outcome loss': 0.2784523643667985, 'Total loss': 0.2784523643667985}
2022-12-31 09:34:49,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:49,041 INFO:     Epoch: 49
2022-12-31 09:34:50,114 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.48958516816298164, 'Total loss': 0.48958516816298164} | train loss {'Reaction outcome loss': 0.27234986877284834, 'Total loss': 0.27234986877284834}
2022-12-31 09:34:50,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:50,115 INFO:     Epoch: 50
2022-12-31 09:34:51,185 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4829294482866923, 'Total loss': 0.4829294482866923} | train loss {'Reaction outcome loss': 0.2696340830247525, 'Total loss': 0.2696340830247525}
2022-12-31 09:34:51,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:51,186 INFO:     Epoch: 51
2022-12-31 09:34:52,256 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48305161111056805, 'Total loss': 0.48305161111056805} | train loss {'Reaction outcome loss': 0.2623324692054819, 'Total loss': 0.2623324692054819}
2022-12-31 09:34:52,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:52,257 INFO:     Epoch: 52
2022-12-31 09:34:53,552 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.49605667193730674, 'Total loss': 0.49605667193730674} | train loss {'Reaction outcome loss': 0.2665963571372969, 'Total loss': 0.2665963571372969}
2022-12-31 09:34:53,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:53,552 INFO:     Epoch: 53
2022-12-31 09:34:55,149 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4729339043299357, 'Total loss': 0.4729339043299357} | train loss {'Reaction outcome loss': 0.25525753655697836, 'Total loss': 0.25525753655697836}
2022-12-31 09:34:55,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:55,149 INFO:     Epoch: 54
2022-12-31 09:34:56,759 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.48728834887345635, 'Total loss': 0.48728834887345635} | train loss {'Reaction outcome loss': 0.25994812761959823, 'Total loss': 0.25994812761959823}
2022-12-31 09:34:56,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:56,760 INFO:     Epoch: 55
2022-12-31 09:34:58,365 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47617391447226204, 'Total loss': 0.47617391447226204} | train loss {'Reaction outcome loss': 0.25652340948126157, 'Total loss': 0.25652340948126157}
2022-12-31 09:34:58,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:58,365 INFO:     Epoch: 56
2022-12-31 09:34:59,975 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4950210253397624, 'Total loss': 0.4950210253397624} | train loss {'Reaction outcome loss': 0.2564232789518428, 'Total loss': 0.2564232789518428}
2022-12-31 09:34:59,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:34:59,975 INFO:     Epoch: 57
2022-12-31 09:35:01,585 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46684751510620115, 'Total loss': 0.46684751510620115} | train loss {'Reaction outcome loss': 0.25367069026222033, 'Total loss': 0.25367069026222033}
2022-12-31 09:35:01,585 INFO:     Found new best model at epoch 57
2022-12-31 09:35:01,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:01,586 INFO:     Epoch: 58
2022-12-31 09:35:03,160 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5065863798062007, 'Total loss': 0.5065863798062007} | train loss {'Reaction outcome loss': 0.2522655282229897, 'Total loss': 0.2522655282229897}
2022-12-31 09:35:03,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:03,161 INFO:     Epoch: 59
2022-12-31 09:35:04,770 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47222206791241966, 'Total loss': 0.47222206791241966} | train loss {'Reaction outcome loss': 0.2537894243867123, 'Total loss': 0.2537894243867123}
2022-12-31 09:35:04,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:04,771 INFO:     Epoch: 60
2022-12-31 09:35:06,416 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.49601109822591144, 'Total loss': 0.49601109822591144} | train loss {'Reaction outcome loss': 0.2487733059130825, 'Total loss': 0.2487733059130825}
2022-12-31 09:35:06,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:06,416 INFO:     Epoch: 61
2022-12-31 09:35:08,120 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5020471970240276, 'Total loss': 0.5020471970240276} | train loss {'Reaction outcome loss': 0.2442327112607334, 'Total loss': 0.2442327112607334}
2022-12-31 09:35:08,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:08,121 INFO:     Epoch: 62
2022-12-31 09:35:09,806 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4743640810251236, 'Total loss': 0.4743640810251236} | train loss {'Reaction outcome loss': 0.24586575355320034, 'Total loss': 0.24586575355320034}
2022-12-31 09:35:09,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:09,806 INFO:     Epoch: 63
2022-12-31 09:35:11,469 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5341743091742198, 'Total loss': 0.5341743091742198} | train loss {'Reaction outcome loss': 0.23839067144872156, 'Total loss': 0.23839067144872156}
2022-12-31 09:35:11,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:11,469 INFO:     Epoch: 64
2022-12-31 09:35:13,074 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.49829712361097334, 'Total loss': 0.49829712361097334} | train loss {'Reaction outcome loss': 0.2450118020292459, 'Total loss': 0.2450118020292459}
2022-12-31 09:35:13,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:13,075 INFO:     Epoch: 65
2022-12-31 09:35:14,685 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48220508098602294, 'Total loss': 0.48220508098602294} | train loss {'Reaction outcome loss': 0.24658426817715762, 'Total loss': 0.24658426817715762}
2022-12-31 09:35:14,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:14,686 INFO:     Epoch: 66
2022-12-31 09:35:16,297 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4945904235045115, 'Total loss': 0.4945904235045115} | train loss {'Reaction outcome loss': 0.23774135987395825, 'Total loss': 0.23774135987395825}
2022-12-31 09:35:16,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:16,297 INFO:     Epoch: 67
2022-12-31 09:35:17,919 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48399192790190376, 'Total loss': 0.48399192790190376} | train loss {'Reaction outcome loss': 0.2629734056097442, 'Total loss': 0.2629734056097442}
2022-12-31 09:35:17,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:17,920 INFO:     Epoch: 68
2022-12-31 09:35:19,571 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49661296208699546, 'Total loss': 0.49661296208699546} | train loss {'Reaction outcome loss': 0.2933890828668761, 'Total loss': 0.2933890828668761}
2022-12-31 09:35:19,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:19,571 INFO:     Epoch: 69
2022-12-31 09:35:21,177 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4806425005197525, 'Total loss': 0.4806425005197525} | train loss {'Reaction outcome loss': 0.23984469802699226, 'Total loss': 0.23984469802699226}
2022-12-31 09:35:21,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:21,178 INFO:     Epoch: 70
2022-12-31 09:35:22,803 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4827964723110199, 'Total loss': 0.4827964723110199} | train loss {'Reaction outcome loss': 0.23226523168546997, 'Total loss': 0.23226523168546997}
2022-12-31 09:35:22,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:22,803 INFO:     Epoch: 71
2022-12-31 09:35:24,455 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47752032776673636, 'Total loss': 0.47752032776673636} | train loss {'Reaction outcome loss': 0.2420153617690169, 'Total loss': 0.2420153617690169}
2022-12-31 09:35:24,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:24,455 INFO:     Epoch: 72
2022-12-31 09:35:26,158 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4749347408612569, 'Total loss': 0.4749347408612569} | train loss {'Reaction outcome loss': 0.23543280439596434, 'Total loss': 0.23543280439596434}
2022-12-31 09:35:26,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:26,159 INFO:     Epoch: 73
2022-12-31 09:35:27,832 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4779083413382371, 'Total loss': 0.4779083413382371} | train loss {'Reaction outcome loss': 0.22796992452640552, 'Total loss': 0.22796992452640552}
2022-12-31 09:35:27,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:27,833 INFO:     Epoch: 74
2022-12-31 09:35:29,482 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47662224173545836, 'Total loss': 0.47662224173545836} | train loss {'Reaction outcome loss': 0.2244121813156475, 'Total loss': 0.2244121813156475}
2022-12-31 09:35:29,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:29,482 INFO:     Epoch: 75
2022-12-31 09:35:31,093 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45677646646896997, 'Total loss': 0.45677646646896997} | train loss {'Reaction outcome loss': 0.23231382525831368, 'Total loss': 0.23231382525831368}
2022-12-31 09:35:31,093 INFO:     Found new best model at epoch 75
2022-12-31 09:35:31,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:31,094 INFO:     Epoch: 76
2022-12-31 09:35:32,743 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4314086526632309, 'Total loss': 0.4314086526632309} | train loss {'Reaction outcome loss': 0.23058145160262095, 'Total loss': 0.23058145160262095}
2022-12-31 09:35:32,745 INFO:     Found new best model at epoch 76
2022-12-31 09:35:32,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:32,745 INFO:     Epoch: 77
2022-12-31 09:35:34,401 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45505012571811676, 'Total loss': 0.45505012571811676} | train loss {'Reaction outcome loss': 0.21841463961712745, 'Total loss': 0.21841463961712745}
2022-12-31 09:35:34,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:34,401 INFO:     Epoch: 78
2022-12-31 09:35:36,030 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4817712624867757, 'Total loss': 0.4817712624867757} | train loss {'Reaction outcome loss': 0.22486340099324784, 'Total loss': 0.22486340099324784}
2022-12-31 09:35:36,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:36,030 INFO:     Epoch: 79
2022-12-31 09:35:37,641 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46370457907517754, 'Total loss': 0.46370457907517754} | train loss {'Reaction outcome loss': 0.23906687790514441, 'Total loss': 0.23906687790514441}
2022-12-31 09:35:37,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:37,641 INFO:     Epoch: 80
2022-12-31 09:35:39,226 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5039311200380325, 'Total loss': 0.5039311200380325} | train loss {'Reaction outcome loss': 0.22346518441791768, 'Total loss': 0.22346518441791768}
2022-12-31 09:35:39,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:39,227 INFO:     Epoch: 81
2022-12-31 09:35:40,860 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.48867057214180626, 'Total loss': 0.48867057214180626} | train loss {'Reaction outcome loss': 0.22973318626063174, 'Total loss': 0.22973318626063174}
2022-12-31 09:35:40,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:40,860 INFO:     Epoch: 82
2022-12-31 09:35:42,504 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4660839120546977, 'Total loss': 0.4660839120546977} | train loss {'Reaction outcome loss': 0.21968066811804537, 'Total loss': 0.21968066811804537}
2022-12-31 09:35:42,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:42,504 INFO:     Epoch: 83
2022-12-31 09:35:44,124 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45539722641309105, 'Total loss': 0.45539722641309105} | train loss {'Reaction outcome loss': 0.22391870786584372, 'Total loss': 0.22391870786584372}
2022-12-31 09:35:44,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:44,125 INFO:     Epoch: 84
2022-12-31 09:35:45,750 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5017289916674296, 'Total loss': 0.5017289916674296} | train loss {'Reaction outcome loss': 0.22989768276423, 'Total loss': 0.22989768276423}
2022-12-31 09:35:45,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:45,751 INFO:     Epoch: 85
2022-12-31 09:35:47,376 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4679299980401993, 'Total loss': 0.4679299980401993} | train loss {'Reaction outcome loss': 0.2561578884369606, 'Total loss': 0.2561578884369606}
2022-12-31 09:35:47,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:47,377 INFO:     Epoch: 86
2022-12-31 09:35:48,956 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4467009887099266, 'Total loss': 0.4467009887099266} | train loss {'Reaction outcome loss': 0.22594291411097284, 'Total loss': 0.22594291411097284}
2022-12-31 09:35:48,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:48,956 INFO:     Epoch: 87
2022-12-31 09:35:50,594 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47163327733675636, 'Total loss': 0.47163327733675636} | train loss {'Reaction outcome loss': 0.21942284521039412, 'Total loss': 0.21942284521039412}
2022-12-31 09:35:50,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:50,594 INFO:     Epoch: 88
2022-12-31 09:35:52,249 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47243684232234956, 'Total loss': 0.47243684232234956} | train loss {'Reaction outcome loss': 0.21556724506713773, 'Total loss': 0.21556724506713773}
2022-12-31 09:35:52,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:52,251 INFO:     Epoch: 89
2022-12-31 09:35:53,875 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.46970872084299725, 'Total loss': 0.46970872084299725} | train loss {'Reaction outcome loss': 0.22891248802815148, 'Total loss': 0.22891248802815148}
2022-12-31 09:35:53,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:53,875 INFO:     Epoch: 90
2022-12-31 09:35:55,489 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5103516151507695, 'Total loss': 0.5103516151507695} | train loss {'Reaction outcome loss': 0.2148070735716644, 'Total loss': 0.2148070735716644}
2022-12-31 09:35:55,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:55,490 INFO:     Epoch: 91
2022-12-31 09:35:57,088 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4626141329606374, 'Total loss': 0.4626141329606374} | train loss {'Reaction outcome loss': 0.21288204841244884, 'Total loss': 0.21288204841244884}
2022-12-31 09:35:57,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:57,089 INFO:     Epoch: 92
2022-12-31 09:35:58,682 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47893436849117277, 'Total loss': 0.47893436849117277} | train loss {'Reaction outcome loss': 0.2152689065720103, 'Total loss': 0.2152689065720103}
2022-12-31 09:35:58,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:35:58,682 INFO:     Epoch: 93
2022-12-31 09:36:00,324 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48981172939141593, 'Total loss': 0.48981172939141593} | train loss {'Reaction outcome loss': 0.2173680818967219, 'Total loss': 0.2173680818967219}
2022-12-31 09:36:00,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:00,324 INFO:     Epoch: 94
2022-12-31 09:36:01,968 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5003463039795558, 'Total loss': 0.5003463039795558} | train loss {'Reaction outcome loss': 0.20884120772150683, 'Total loss': 0.20884120772150683}
2022-12-31 09:36:01,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:01,968 INFO:     Epoch: 95
2022-12-31 09:36:03,643 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4880275090535482, 'Total loss': 0.4880275090535482} | train loss {'Reaction outcome loss': 0.2109580137901872, 'Total loss': 0.2109580137901872}
2022-12-31 09:36:03,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:03,644 INFO:     Epoch: 96
2022-12-31 09:36:05,289 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4983451128005981, 'Total loss': 0.4983451128005981} | train loss {'Reaction outcome loss': 0.21919597335606036, 'Total loss': 0.21919597335606036}
2022-12-31 09:36:05,289 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:05,289 INFO:     Epoch: 97
2022-12-31 09:36:06,885 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5210253963867824, 'Total loss': 0.5210253963867824} | train loss {'Reaction outcome loss': 0.20810585574962306, 'Total loss': 0.20810585574962306}
2022-12-31 09:36:06,885 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:06,886 INFO:     Epoch: 98
2022-12-31 09:36:08,534 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.46091594795386, 'Total loss': 0.46091594795386} | train loss {'Reaction outcome loss': 0.21252238806261195, 'Total loss': 0.21252238806261195}
2022-12-31 09:36:08,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:08,535 INFO:     Epoch: 99
2022-12-31 09:36:10,180 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.49618363479773203, 'Total loss': 0.49618363479773203} | train loss {'Reaction outcome loss': 0.2091759295541071, 'Total loss': 0.2091759295541071}
2022-12-31 09:36:10,180 INFO:     Best model found after epoch 77 of 100.
2022-12-31 09:36:10,180 INFO:   Done with stage: TRAINING
2022-12-31 09:36:10,180 INFO:   Starting stage: EVALUATION
2022-12-31 09:36:10,306 INFO:   Done with stage: EVALUATION
2022-12-31 09:36:10,307 INFO:   Leaving out SEQ value Fold_2
2022-12-31 09:36:10,319 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 09:36:10,319 INFO:   Starting stage: FEATURE SCALING
2022-12-31 09:36:10,971 INFO:   Done with stage: FEATURE SCALING
2022-12-31 09:36:10,971 INFO:   Starting stage: SCALING TARGETS
2022-12-31 09:36:11,042 INFO:   Done with stage: SCALING TARGETS
2022-12-31 09:36:11,042 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:36:11,042 INFO:     No hyperparam tuning for this model
2022-12-31 09:36:11,042 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:36:11,042 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 09:36:11,043 INFO:     None feature selector for col prot
2022-12-31 09:36:11,043 INFO:     None feature selector for col prot
2022-12-31 09:36:11,043 INFO:     None feature selector for col prot
2022-12-31 09:36:11,044 INFO:     None feature selector for col chem
2022-12-31 09:36:11,044 INFO:     None feature selector for col chem
2022-12-31 09:36:11,044 INFO:     None feature selector for col chem
2022-12-31 09:36:11,044 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 09:36:11,044 INFO:   Starting stage: BUILD MODEL
2022-12-31 09:36:11,046 INFO:     Number of params in model 223921
2022-12-31 09:36:11,049 INFO:   Done with stage: BUILD MODEL
2022-12-31 09:36:11,049 INFO:   Starting stage: TRAINING
2022-12-31 09:36:11,093 INFO:     Val loss before train {'Reaction outcome loss': 0.95841264128685, 'Total loss': 0.95841264128685}
2022-12-31 09:36:11,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:11,094 INFO:     Epoch: 0
2022-12-31 09:36:12,727 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5934931457042694, 'Total loss': 0.5934931457042694} | train loss {'Reaction outcome loss': 0.8170632944054848, 'Total loss': 0.8170632944054848}
2022-12-31 09:36:12,727 INFO:     Found new best model at epoch 0
2022-12-31 09:36:12,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:12,728 INFO:     Epoch: 1
2022-12-31 09:36:14,353 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4995249758164088, 'Total loss': 0.4995249758164088} | train loss {'Reaction outcome loss': 0.5982710332983602, 'Total loss': 0.5982710332983602}
2022-12-31 09:36:14,353 INFO:     Found new best model at epoch 1
2022-12-31 09:36:14,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:14,354 INFO:     Epoch: 2
2022-12-31 09:36:15,915 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4654203871885935, 'Total loss': 0.4654203871885935} | train loss {'Reaction outcome loss': 0.5285758387542119, 'Total loss': 0.5285758387542119}
2022-12-31 09:36:15,916 INFO:     Found new best model at epoch 2
2022-12-31 09:36:15,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:15,917 INFO:     Epoch: 3
2022-12-31 09:36:17,518 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4431840002536774, 'Total loss': 0.4431840002536774} | train loss {'Reaction outcome loss': 0.5040568867630332, 'Total loss': 0.5040568867630332}
2022-12-31 09:36:17,518 INFO:     Found new best model at epoch 3
2022-12-31 09:36:17,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:17,519 INFO:     Epoch: 4
2022-12-31 09:36:19,122 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44083518385887144, 'Total loss': 0.44083518385887144} | train loss {'Reaction outcome loss': 0.4883503459230827, 'Total loss': 0.4883503459230827}
2022-12-31 09:36:19,122 INFO:     Found new best model at epoch 4
2022-12-31 09:36:19,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:19,123 INFO:     Epoch: 5
2022-12-31 09:36:20,728 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45695560723543166, 'Total loss': 0.45695560723543166} | train loss {'Reaction outcome loss': 0.4718077840269917, 'Total loss': 0.4718077840269917}
2022-12-31 09:36:20,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:20,728 INFO:     Epoch: 6
2022-12-31 09:36:22,330 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.40067816972732545, 'Total loss': 0.40067816972732545} | train loss {'Reaction outcome loss': 0.4648546194725663, 'Total loss': 0.4648546194725663}
2022-12-31 09:36:22,331 INFO:     Found new best model at epoch 6
2022-12-31 09:36:22,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:22,332 INFO:     Epoch: 7
2022-12-31 09:36:23,932 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.41682292024294537, 'Total loss': 0.41682292024294537} | train loss {'Reaction outcome loss': 0.46127331577730873, 'Total loss': 0.46127331577730873}
2022-12-31 09:36:23,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:23,932 INFO:     Epoch: 8
2022-12-31 09:36:25,510 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.39127740760644275, 'Total loss': 0.39127740760644275} | train loss {'Reaction outcome loss': 0.45082428173100864, 'Total loss': 0.45082428173100864}
2022-12-31 09:36:25,510 INFO:     Found new best model at epoch 8
2022-12-31 09:36:25,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:25,511 INFO:     Epoch: 9
2022-12-31 09:36:27,145 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4295445422331492, 'Total loss': 0.4295445422331492} | train loss {'Reaction outcome loss': 0.44564829948936063, 'Total loss': 0.44564829948936063}
2022-12-31 09:36:27,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:27,145 INFO:     Epoch: 10
2022-12-31 09:36:28,780 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4020642767349879, 'Total loss': 0.4020642767349879} | train loss {'Reaction outcome loss': 0.43951915547142933, 'Total loss': 0.43951915547142933}
2022-12-31 09:36:28,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:28,781 INFO:     Epoch: 11
2022-12-31 09:36:30,381 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.3647512912750244, 'Total loss': 0.3647512912750244} | train loss {'Reaction outcome loss': 0.4323078892363684, 'Total loss': 0.4323078892363684}
2022-12-31 09:36:30,381 INFO:     Found new best model at epoch 11
2022-12-31 09:36:30,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:30,382 INFO:     Epoch: 12
2022-12-31 09:36:31,982 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3939143339792887, 'Total loss': 0.3939143339792887} | train loss {'Reaction outcome loss': 0.4276859516916919, 'Total loss': 0.4276859516916919}
2022-12-31 09:36:31,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:31,982 INFO:     Epoch: 13
2022-12-31 09:36:33,559 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41056356330712634, 'Total loss': 0.41056356330712634} | train loss {'Reaction outcome loss': 0.41552052641437004, 'Total loss': 0.41552052641437004}
2022-12-31 09:36:33,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:33,561 INFO:     Epoch: 14
2022-12-31 09:36:35,140 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.3608985885977745, 'Total loss': 0.3608985885977745} | train loss {'Reaction outcome loss': 0.4160231004068016, 'Total loss': 0.4160231004068016}
2022-12-31 09:36:35,140 INFO:     Found new best model at epoch 14
2022-12-31 09:36:35,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:35,141 INFO:     Epoch: 15
2022-12-31 09:36:36,742 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.3767628153165182, 'Total loss': 0.3767628153165182} | train loss {'Reaction outcome loss': 0.40678740031745314, 'Total loss': 0.40678740031745314}
2022-12-31 09:36:36,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:36,743 INFO:     Epoch: 16
2022-12-31 09:36:38,351 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.35834411482016243, 'Total loss': 0.35834411482016243} | train loss {'Reaction outcome loss': 0.397133693887587, 'Total loss': 0.397133693887587}
2022-12-31 09:36:38,351 INFO:     Found new best model at epoch 16
2022-12-31 09:36:38,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:38,352 INFO:     Epoch: 17
2022-12-31 09:36:39,958 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.355170934398969, 'Total loss': 0.355170934398969} | train loss {'Reaction outcome loss': 0.39623306811290937, 'Total loss': 0.39623306811290937}
2022-12-31 09:36:39,959 INFO:     Found new best model at epoch 17
2022-12-31 09:36:39,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:39,960 INFO:     Epoch: 18
2022-12-31 09:36:41,564 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3523131042718887, 'Total loss': 0.3523131042718887} | train loss {'Reaction outcome loss': 0.3960813287183316, 'Total loss': 0.3960813287183316}
2022-12-31 09:36:41,564 INFO:     Found new best model at epoch 18
2022-12-31 09:36:41,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:41,565 INFO:     Epoch: 19
2022-12-31 09:36:43,119 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.36893848876158397, 'Total loss': 0.36893848876158397} | train loss {'Reaction outcome loss': 0.38791459826004765, 'Total loss': 0.38791459826004765}
2022-12-31 09:36:43,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:43,119 INFO:     Epoch: 20
2022-12-31 09:36:44,774 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39694536427656807, 'Total loss': 0.39694536427656807} | train loss {'Reaction outcome loss': 0.3804555815393037, 'Total loss': 0.3804555815393037}
2022-12-31 09:36:44,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:44,775 INFO:     Epoch: 21
2022-12-31 09:36:46,381 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.37884840766588845, 'Total loss': 0.37884840766588845} | train loss {'Reaction outcome loss': 0.36713064233534526, 'Total loss': 0.36713064233534526}
2022-12-31 09:36:46,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:46,381 INFO:     Epoch: 22
2022-12-31 09:36:47,986 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3742898205916087, 'Total loss': 0.3742898205916087} | train loss {'Reaction outcome loss': 0.3725964132777966, 'Total loss': 0.3725964132777966}
2022-12-31 09:36:47,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:47,987 INFO:     Epoch: 23
2022-12-31 09:36:49,588 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3744632293780645, 'Total loss': 0.3744632293780645} | train loss {'Reaction outcome loss': 0.36282573543815283, 'Total loss': 0.36282573543815283}
2022-12-31 09:36:49,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:49,588 INFO:     Epoch: 24
2022-12-31 09:36:51,196 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.36821013391017915, 'Total loss': 0.36821013391017915} | train loss {'Reaction outcome loss': 0.3563947770064765, 'Total loss': 0.3563947770064765}
2022-12-31 09:36:51,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:51,197 INFO:     Epoch: 25
2022-12-31 09:36:52,768 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3447455654541651, 'Total loss': 0.3447455654541651} | train loss {'Reaction outcome loss': 0.35445758374067987, 'Total loss': 0.35445758374067987}
2022-12-31 09:36:52,768 INFO:     Found new best model at epoch 25
2022-12-31 09:36:52,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:52,769 INFO:     Epoch: 26
2022-12-31 09:36:54,374 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.33972069521745046, 'Total loss': 0.33972069521745046} | train loss {'Reaction outcome loss': 0.34638140527327566, 'Total loss': 0.34638140527327566}
2022-12-31 09:36:54,374 INFO:     Found new best model at epoch 26
2022-12-31 09:36:54,375 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:54,375 INFO:     Epoch: 27
2022-12-31 09:36:55,981 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3469192137320836, 'Total loss': 0.3469192137320836} | train loss {'Reaction outcome loss': 0.34491704689869046, 'Total loss': 0.34491704689869046}
2022-12-31 09:36:55,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:55,981 INFO:     Epoch: 28
2022-12-31 09:36:57,616 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3314541786909103, 'Total loss': 0.3314541786909103} | train loss {'Reaction outcome loss': 0.3390687204571101, 'Total loss': 0.3390687204571101}
2022-12-31 09:36:57,618 INFO:     Found new best model at epoch 28
2022-12-31 09:36:57,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:57,619 INFO:     Epoch: 29
2022-12-31 09:36:59,248 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3987724552551905, 'Total loss': 0.3987724552551905} | train loss {'Reaction outcome loss': 0.3342093830778651, 'Total loss': 0.3342093830778651}
2022-12-31 09:36:59,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:36:59,248 INFO:     Epoch: 30
2022-12-31 09:37:00,828 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.34188474180797734, 'Total loss': 0.34188474180797734} | train loss {'Reaction outcome loss': 0.3341929099801248, 'Total loss': 0.3341929099801248}
2022-12-31 09:37:00,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:00,828 INFO:     Epoch: 31
2022-12-31 09:37:02,413 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3765416751305262, 'Total loss': 0.3765416751305262} | train loss {'Reaction outcome loss': 0.3330201386698406, 'Total loss': 0.3330201386698406}
2022-12-31 09:37:02,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:02,413 INFO:     Epoch: 32
2022-12-31 09:37:04,017 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.35184528430302936, 'Total loss': 0.35184528430302936} | train loss {'Reaction outcome loss': 0.32863915829926077, 'Total loss': 0.32863915829926077}
2022-12-31 09:37:04,018 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:04,018 INFO:     Epoch: 33
2022-12-31 09:37:05,623 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.365787997841835, 'Total loss': 0.365787997841835} | train loss {'Reaction outcome loss': 0.3191799745779403, 'Total loss': 0.3191799745779403}
2022-12-31 09:37:05,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:05,623 INFO:     Epoch: 34
2022-12-31 09:37:07,230 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.32711514135201775, 'Total loss': 0.32711514135201775} | train loss {'Reaction outcome loss': 0.3064092991832834, 'Total loss': 0.3064092991832834}
2022-12-31 09:37:07,230 INFO:     Found new best model at epoch 34
2022-12-31 09:37:07,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:07,231 INFO:     Epoch: 35
2022-12-31 09:37:08,835 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.35333710263172785, 'Total loss': 0.35333710263172785} | train loss {'Reaction outcome loss': 0.3064376321641633, 'Total loss': 0.3064376321641633}
2022-12-31 09:37:08,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:08,836 INFO:     Epoch: 36
2022-12-31 09:37:10,394 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3639883607625961, 'Total loss': 0.3639883607625961} | train loss {'Reaction outcome loss': 0.3109359152506303, 'Total loss': 0.3109359152506303}
2022-12-31 09:37:10,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:10,394 INFO:     Epoch: 37
2022-12-31 09:37:12,000 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.36018652419249214, 'Total loss': 0.36018652419249214} | train loss {'Reaction outcome loss': 0.3078374878306241, 'Total loss': 0.3078374878306241}
2022-12-31 09:37:12,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:12,001 INFO:     Epoch: 38
2022-12-31 09:37:13,600 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3326460361480713, 'Total loss': 0.3326460361480713} | train loss {'Reaction outcome loss': 0.3020064904198159, 'Total loss': 0.3020064904198159}
2022-12-31 09:37:13,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:13,601 INFO:     Epoch: 39
2022-12-31 09:37:15,200 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3101210057735443, 'Total loss': 0.3101210057735443} | train loss {'Reaction outcome loss': 0.2974293805169363, 'Total loss': 0.2974293805169363}
2022-12-31 09:37:15,200 INFO:     Found new best model at epoch 39
2022-12-31 09:37:15,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:15,201 INFO:     Epoch: 40
2022-12-31 09:37:16,799 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.33664101660251616, 'Total loss': 0.33664101660251616} | train loss {'Reaction outcome loss': 0.2971343833980334, 'Total loss': 0.2971343833980334}
2022-12-31 09:37:16,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:16,800 INFO:     Epoch: 41
2022-12-31 09:37:18,397 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.34364743034044903, 'Total loss': 0.34364743034044903} | train loss {'Reaction outcome loss': 0.2863147604911432, 'Total loss': 0.2863147604911432}
2022-12-31 09:37:18,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:18,397 INFO:     Epoch: 42
2022-12-31 09:37:19,963 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3571871896584829, 'Total loss': 0.3571871896584829} | train loss {'Reaction outcome loss': 0.28570657435559876, 'Total loss': 0.28570657435559876}
2022-12-31 09:37:19,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:19,964 INFO:     Epoch: 43
2022-12-31 09:37:21,559 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3494211584329605, 'Total loss': 0.3494211584329605} | train loss {'Reaction outcome loss': 0.2968536353105829, 'Total loss': 0.2968536353105829}
2022-12-31 09:37:21,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:21,559 INFO:     Epoch: 44
2022-12-31 09:37:23,165 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3305870225032171, 'Total loss': 0.3305870225032171} | train loss {'Reaction outcome loss': 0.2853823330688433, 'Total loss': 0.2853823330688433}
2022-12-31 09:37:23,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:23,167 INFO:     Epoch: 45
2022-12-31 09:37:24,765 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3932266573111216, 'Total loss': 0.3932266573111216} | train loss {'Reaction outcome loss': 0.2775776860079844, 'Total loss': 0.2775776860079844}
2022-12-31 09:37:24,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:24,765 INFO:     Epoch: 46
2022-12-31 09:37:26,401 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40651949048042296, 'Total loss': 0.40651949048042296} | train loss {'Reaction outcome loss': 0.28283190596712765, 'Total loss': 0.28283190596712765}
2022-12-31 09:37:26,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:26,401 INFO:     Epoch: 47
2022-12-31 09:37:27,998 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3254565487305323, 'Total loss': 0.3254565487305323} | train loss {'Reaction outcome loss': 0.2802054908833582, 'Total loss': 0.2802054908833582}
2022-12-31 09:37:27,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:28,000 INFO:     Epoch: 48
2022-12-31 09:37:29,609 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3428370088338852, 'Total loss': 0.3428370088338852} | train loss {'Reaction outcome loss': 0.27319509472126946, 'Total loss': 0.27319509472126946}
2022-12-31 09:37:29,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:29,609 INFO:     Epoch: 49
2022-12-31 09:37:31,236 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3415003443757693, 'Total loss': 0.3415003443757693} | train loss {'Reaction outcome loss': 0.2778503590528547, 'Total loss': 0.2778503590528547}
2022-12-31 09:37:31,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:31,236 INFO:     Epoch: 50
2022-12-31 09:37:32,860 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.34722778300444285, 'Total loss': 0.34722778300444285} | train loss {'Reaction outcome loss': 0.27181209056862515, 'Total loss': 0.27181209056862515}
2022-12-31 09:37:32,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:32,861 INFO:     Epoch: 51
2022-12-31 09:37:34,497 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.36794166763623554, 'Total loss': 0.36794166763623554} | train loss {'Reaction outcome loss': 0.26847592022025235, 'Total loss': 0.26847592022025235}
2022-12-31 09:37:34,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:34,498 INFO:     Epoch: 52
2022-12-31 09:37:36,114 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3198340649406115, 'Total loss': 0.3198340649406115} | train loss {'Reaction outcome loss': 0.2700890611286146, 'Total loss': 0.2700890611286146}
2022-12-31 09:37:36,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:36,114 INFO:     Epoch: 53
2022-12-31 09:37:37,684 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.289933834473292, 'Total loss': 0.289933834473292} | train loss {'Reaction outcome loss': 0.2676131917286093, 'Total loss': 0.2676131917286093}
2022-12-31 09:37:37,684 INFO:     Found new best model at epoch 53
2022-12-31 09:37:37,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:37,685 INFO:     Epoch: 54
2022-12-31 09:37:39,276 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.32361310770114265, 'Total loss': 0.32361310770114265} | train loss {'Reaction outcome loss': 0.26193805043007773, 'Total loss': 0.26193805043007773}
2022-12-31 09:37:39,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:39,277 INFO:     Epoch: 55
2022-12-31 09:37:40,917 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3276955192287763, 'Total loss': 0.3276955192287763} | train loss {'Reaction outcome loss': 0.25574970939434577, 'Total loss': 0.25574970939434577}
2022-12-31 09:37:40,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:40,919 INFO:     Epoch: 56
2022-12-31 09:37:42,571 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.33224431773026786, 'Total loss': 0.33224431773026786} | train loss {'Reaction outcome loss': 0.26437023469675197, 'Total loss': 0.26437023469675197}
2022-12-31 09:37:42,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:42,572 INFO:     Epoch: 57
2022-12-31 09:37:44,223 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.36988780498504636, 'Total loss': 0.36988780498504636} | train loss {'Reaction outcome loss': 0.2572805895911951, 'Total loss': 0.2572805895911951}
2022-12-31 09:37:44,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:44,224 INFO:     Epoch: 58
2022-12-31 09:37:45,875 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38098445534706116, 'Total loss': 0.38098445534706116} | train loss {'Reaction outcome loss': 0.2599623705511981, 'Total loss': 0.2599623705511981}
2022-12-31 09:37:45,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:45,877 INFO:     Epoch: 59
2022-12-31 09:37:47,496 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.35634056727091473, 'Total loss': 0.35634056727091473} | train loss {'Reaction outcome loss': 0.2570927795022726, 'Total loss': 0.2570927795022726}
2022-12-31 09:37:47,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:47,496 INFO:     Epoch: 60
2022-12-31 09:37:49,105 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.34247034738461174, 'Total loss': 0.34247034738461174} | train loss {'Reaction outcome loss': 0.2497241284127218, 'Total loss': 0.2497241284127218}
2022-12-31 09:37:49,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:49,105 INFO:     Epoch: 61
2022-12-31 09:37:50,755 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.32928248345851896, 'Total loss': 0.32928248345851896} | train loss {'Reaction outcome loss': 0.2482506093317575, 'Total loss': 0.2482506093317575}
2022-12-31 09:37:50,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:50,756 INFO:     Epoch: 62
2022-12-31 09:37:52,402 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.30195497795939447, 'Total loss': 0.30195497795939447} | train loss {'Reaction outcome loss': 0.25122594422096534, 'Total loss': 0.25122594422096534}
2022-12-31 09:37:52,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:52,403 INFO:     Epoch: 63
2022-12-31 09:37:54,000 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.351109970609347, 'Total loss': 0.351109970609347} | train loss {'Reaction outcome loss': 0.24720744208099632, 'Total loss': 0.24720744208099632}
2022-12-31 09:37:54,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:54,000 INFO:     Epoch: 64
2022-12-31 09:37:55,597 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3342808152238528, 'Total loss': 0.3342808152238528} | train loss {'Reaction outcome loss': 0.2448918043778543, 'Total loss': 0.2448918043778543}
2022-12-31 09:37:55,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:55,597 INFO:     Epoch: 65
2022-12-31 09:37:57,194 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3219969669977824, 'Total loss': 0.3219969669977824} | train loss {'Reaction outcome loss': 0.24486840781449837, 'Total loss': 0.24486840781449837}
2022-12-31 09:37:57,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:57,194 INFO:     Epoch: 66
2022-12-31 09:37:58,795 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3378893295923869, 'Total loss': 0.3378893295923869} | train loss {'Reaction outcome loss': 0.24419685393354318, 'Total loss': 0.24419685393354318}
2022-12-31 09:37:58,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:37:58,796 INFO:     Epoch: 67
2022-12-31 09:38:00,397 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3666646679242452, 'Total loss': 0.3666646679242452} | train loss {'Reaction outcome loss': 0.23646016452923743, 'Total loss': 0.23646016452923743}
2022-12-31 09:38:00,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:00,398 INFO:     Epoch: 68
2022-12-31 09:38:01,998 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39731170833110807, 'Total loss': 0.39731170833110807} | train loss {'Reaction outcome loss': 0.23859809617763453, 'Total loss': 0.23859809617763453}
2022-12-31 09:38:01,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:01,998 INFO:     Epoch: 69
2022-12-31 09:38:03,598 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3771681586901347, 'Total loss': 0.3771681586901347} | train loss {'Reaction outcome loss': 0.2305740834533298, 'Total loss': 0.2305740834533298}
2022-12-31 09:38:03,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:03,600 INFO:     Epoch: 70
2022-12-31 09:38:05,170 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3247939375539621, 'Total loss': 0.3247939375539621} | train loss {'Reaction outcome loss': 0.2321082522691547, 'Total loss': 0.2321082522691547}
2022-12-31 09:38:05,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:05,170 INFO:     Epoch: 71
2022-12-31 09:38:06,768 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3485773300131162, 'Total loss': 0.3485773300131162} | train loss {'Reaction outcome loss': 0.23597838955992548, 'Total loss': 0.23597838955992548}
2022-12-31 09:38:06,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:06,768 INFO:     Epoch: 72
2022-12-31 09:38:08,368 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.34832178403933844, 'Total loss': 0.34832178403933844} | train loss {'Reaction outcome loss': 0.23977712942899143, 'Total loss': 0.23977712942899143}
2022-12-31 09:38:08,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:08,368 INFO:     Epoch: 73
2022-12-31 09:38:09,968 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3602628986040751, 'Total loss': 0.3602628986040751} | train loss {'Reaction outcome loss': 0.23096817100325423, 'Total loss': 0.23096817100325423}
2022-12-31 09:38:09,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:09,969 INFO:     Epoch: 74
2022-12-31 09:38:11,567 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.37687288522720336, 'Total loss': 0.37687288522720336} | train loss {'Reaction outcome loss': 0.23669271449130164, 'Total loss': 0.23669271449130164}
2022-12-31 09:38:11,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:11,567 INFO:     Epoch: 75
2022-12-31 09:38:13,219 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3659673084815343, 'Total loss': 0.3659673084815343} | train loss {'Reaction outcome loss': 0.2360684533406348, 'Total loss': 0.2360684533406348}
2022-12-31 09:38:13,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:13,219 INFO:     Epoch: 76
2022-12-31 09:38:14,795 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.36222926080226897, 'Total loss': 0.36222926080226897} | train loss {'Reaction outcome loss': 0.23127539335906397, 'Total loss': 0.23127539335906397}
2022-12-31 09:38:14,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:14,795 INFO:     Epoch: 77
2022-12-31 09:38:16,392 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3424849381049474, 'Total loss': 0.3424849381049474} | train loss {'Reaction outcome loss': 0.22740547883793386, 'Total loss': 0.22740547883793386}
2022-12-31 09:38:16,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:16,393 INFO:     Epoch: 78
2022-12-31 09:38:17,992 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.35929498573144275, 'Total loss': 0.35929498573144275} | train loss {'Reaction outcome loss': 0.2206473025989576, 'Total loss': 0.2206473025989576}
2022-12-31 09:38:17,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:17,993 INFO:     Epoch: 79
2022-12-31 09:38:19,593 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.33546053916215895, 'Total loss': 0.33546053916215895} | train loss {'Reaction outcome loss': 0.22781463861329496, 'Total loss': 0.22781463861329496}
2022-12-31 09:38:19,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:19,594 INFO:     Epoch: 80
2022-12-31 09:38:21,194 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.354057169953982, 'Total loss': 0.354057169953982} | train loss {'Reaction outcome loss': 0.21732871907416487, 'Total loss': 0.21732871907416487}
2022-12-31 09:38:21,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:21,195 INFO:     Epoch: 81
2022-12-31 09:38:22,771 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3334769750634829, 'Total loss': 0.3334769750634829} | train loss {'Reaction outcome loss': 0.22047061352127226, 'Total loss': 0.22047061352127226}
2022-12-31 09:38:22,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:22,772 INFO:     Epoch: 82
2022-12-31 09:38:24,349 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.32360735883315406, 'Total loss': 0.32360735883315406} | train loss {'Reaction outcome loss': 0.22666698793479562, 'Total loss': 0.22666698793479562}
2022-12-31 09:38:24,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:24,350 INFO:     Epoch: 83
2022-12-31 09:38:25,950 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3243697457015514, 'Total loss': 0.3243697457015514} | train loss {'Reaction outcome loss': 0.21963222362916834, 'Total loss': 0.21963222362916834}
2022-12-31 09:38:25,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:25,950 INFO:     Epoch: 84
2022-12-31 09:38:27,551 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3580989847580592, 'Total loss': 0.3580989847580592} | train loss {'Reaction outcome loss': 0.22080068419395138, 'Total loss': 0.22080068419395138}
2022-12-31 09:38:27,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:27,552 INFO:     Epoch: 85
2022-12-31 09:38:29,152 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3814832617839177, 'Total loss': 0.3814832617839177} | train loss {'Reaction outcome loss': 0.2226660655553106, 'Total loss': 0.2226660655553106}
2022-12-31 09:38:29,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:29,153 INFO:     Epoch: 86
2022-12-31 09:38:30,754 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38682657356063527, 'Total loss': 0.38682657356063527} | train loss {'Reaction outcome loss': 0.2186879571935121, 'Total loss': 0.2186879571935121}
2022-12-31 09:38:30,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:30,754 INFO:     Epoch: 87
2022-12-31 09:38:32,326 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3451160371303558, 'Total loss': 0.3451160371303558} | train loss {'Reaction outcome loss': 0.2129142629288572, 'Total loss': 0.2129142629288572}
2022-12-31 09:38:32,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:32,326 INFO:     Epoch: 88
2022-12-31 09:38:33,927 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.36114399433135985, 'Total loss': 0.36114399433135985} | train loss {'Reaction outcome loss': 0.21827460738089288, 'Total loss': 0.21827460738089288}
2022-12-31 09:38:33,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:33,927 INFO:     Epoch: 89
2022-12-31 09:38:35,526 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.32232554455598195, 'Total loss': 0.32232554455598195} | train loss {'Reaction outcome loss': 0.21451140152983858, 'Total loss': 0.21451140152983858}
2022-12-31 09:38:35,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:35,527 INFO:     Epoch: 90
2022-12-31 09:38:37,126 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.39204966425895693, 'Total loss': 0.39204966425895693} | train loss {'Reaction outcome loss': 0.21020756077266087, 'Total loss': 0.21020756077266087}
2022-12-31 09:38:37,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:37,126 INFO:     Epoch: 91
2022-12-31 09:38:38,725 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.37187306930621467, 'Total loss': 0.37187306930621467} | train loss {'Reaction outcome loss': 0.21682231298165164, 'Total loss': 0.21682231298165164}
2022-12-31 09:38:38,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:38,726 INFO:     Epoch: 92
2022-12-31 09:38:40,312 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.34486300895611444, 'Total loss': 0.34486300895611444} | train loss {'Reaction outcome loss': 0.2120396947134694, 'Total loss': 0.2120396947134694}
2022-12-31 09:38:40,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:40,314 INFO:     Epoch: 93
2022-12-31 09:38:41,894 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.31953122317790983, 'Total loss': 0.31953122317790983} | train loss {'Reaction outcome loss': 0.2095339172383784, 'Total loss': 0.2095339172383784}
2022-12-31 09:38:41,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:41,894 INFO:     Epoch: 94
2022-12-31 09:38:43,497 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.33507974396149315, 'Total loss': 0.33507974396149315} | train loss {'Reaction outcome loss': 0.2059032180802013, 'Total loss': 0.2059032180802013}
2022-12-31 09:38:43,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:43,497 INFO:     Epoch: 95
2022-12-31 09:38:45,101 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3242042620976766, 'Total loss': 0.3242042620976766} | train loss {'Reaction outcome loss': 0.20316112566956857, 'Total loss': 0.20316112566956857}
2022-12-31 09:38:45,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:45,101 INFO:     Epoch: 96
2022-12-31 09:38:46,706 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.35309623430172604, 'Total loss': 0.35309623430172604} | train loss {'Reaction outcome loss': 0.21769016299287985, 'Total loss': 0.21769016299287985}
2022-12-31 09:38:46,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:46,708 INFO:     Epoch: 97
2022-12-31 09:38:48,310 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.36933385332425434, 'Total loss': 0.36933385332425434} | train loss {'Reaction outcome loss': 0.2101588510724641, 'Total loss': 0.2101588510724641}
2022-12-31 09:38:48,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:48,310 INFO:     Epoch: 98
2022-12-31 09:38:49,889 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.33036620914936066, 'Total loss': 0.33036620914936066} | train loss {'Reaction outcome loss': 0.2147420102009808, 'Total loss': 0.2147420102009808}
2022-12-31 09:38:49,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:49,889 INFO:     Epoch: 99
2022-12-31 09:38:51,519 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3214671455323696, 'Total loss': 0.3214671455323696} | train loss {'Reaction outcome loss': 0.20683424073495787, 'Total loss': 0.20683424073495787}
2022-12-31 09:38:51,519 INFO:     Best model found after epoch 54 of 100.
2022-12-31 09:38:51,519 INFO:   Done with stage: TRAINING
2022-12-31 09:38:51,519 INFO:   Starting stage: EVALUATION
2022-12-31 09:38:51,654 INFO:   Done with stage: EVALUATION
2022-12-31 09:38:51,654 INFO:   Leaving out SEQ value Fold_3
2022-12-31 09:38:51,667 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 09:38:51,667 INFO:   Starting stage: FEATURE SCALING
2022-12-31 09:38:52,333 INFO:   Done with stage: FEATURE SCALING
2022-12-31 09:38:52,334 INFO:   Starting stage: SCALING TARGETS
2022-12-31 09:38:52,404 INFO:   Done with stage: SCALING TARGETS
2022-12-31 09:38:52,404 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:38:52,404 INFO:     No hyperparam tuning for this model
2022-12-31 09:38:52,404 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:38:52,404 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 09:38:52,405 INFO:     None feature selector for col prot
2022-12-31 09:38:52,405 INFO:     None feature selector for col prot
2022-12-31 09:38:52,405 INFO:     None feature selector for col prot
2022-12-31 09:38:52,406 INFO:     None feature selector for col chem
2022-12-31 09:38:52,406 INFO:     None feature selector for col chem
2022-12-31 09:38:52,406 INFO:     None feature selector for col chem
2022-12-31 09:38:52,406 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 09:38:52,406 INFO:   Starting stage: BUILD MODEL
2022-12-31 09:38:52,408 INFO:     Number of params in model 223921
2022-12-31 09:38:52,411 INFO:   Done with stage: BUILD MODEL
2022-12-31 09:38:52,411 INFO:   Starting stage: TRAINING
2022-12-31 09:38:52,456 INFO:     Val loss before train {'Reaction outcome loss': 0.9849787354469299, 'Total loss': 0.9849787354469299}
2022-12-31 09:38:52,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:52,456 INFO:     Epoch: 0
2022-12-31 09:38:54,090 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6792457640171051, 'Total loss': 0.6792457640171051} | train loss {'Reaction outcome loss': 0.8306344619197567, 'Total loss': 0.8306344619197567}
2022-12-31 09:38:54,090 INFO:     Found new best model at epoch 0
2022-12-31 09:38:54,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:54,091 INFO:     Epoch: 1
2022-12-31 09:38:55,722 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5135886609554291, 'Total loss': 0.5135886609554291} | train loss {'Reaction outcome loss': 0.6101926380809206, 'Total loss': 0.6101926380809206}
2022-12-31 09:38:55,722 INFO:     Found new best model at epoch 1
2022-12-31 09:38:55,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:55,723 INFO:     Epoch: 2
2022-12-31 09:38:57,322 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49645669758319855, 'Total loss': 0.49645669758319855} | train loss {'Reaction outcome loss': 0.539812724846993, 'Total loss': 0.539812724846993}
2022-12-31 09:38:57,322 INFO:     Found new best model at epoch 2
2022-12-31 09:38:57,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:57,323 INFO:     Epoch: 3
2022-12-31 09:38:58,903 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5232558012008667, 'Total loss': 0.5232558012008667} | train loss {'Reaction outcome loss': 0.5134523343974656, 'Total loss': 0.5134523343974656}
2022-12-31 09:38:58,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:38:58,924 INFO:     Epoch: 4
2022-12-31 09:39:00,500 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4668856451908747, 'Total loss': 0.4668856451908747} | train loss {'Reaction outcome loss': 0.4973281123233538, 'Total loss': 0.4973281123233538}
2022-12-31 09:39:00,500 INFO:     Found new best model at epoch 4
2022-12-31 09:39:00,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:00,501 INFO:     Epoch: 5
2022-12-31 09:39:02,136 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4628370523452759, 'Total loss': 0.4628370523452759} | train loss {'Reaction outcome loss': 0.48210572494860116, 'Total loss': 0.48210572494860116}
2022-12-31 09:39:02,136 INFO:     Found new best model at epoch 5
2022-12-31 09:39:02,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:02,137 INFO:     Epoch: 6
2022-12-31 09:39:03,714 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4834359288215637, 'Total loss': 0.4834359288215637} | train loss {'Reaction outcome loss': 0.4762373197361501, 'Total loss': 0.4762373197361501}
2022-12-31 09:39:03,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:03,714 INFO:     Epoch: 7
2022-12-31 09:39:05,346 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.473351976275444, 'Total loss': 0.473351976275444} | train loss {'Reaction outcome loss': 0.4701814736056067, 'Total loss': 0.4701814736056067}
2022-12-31 09:39:05,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:05,347 INFO:     Epoch: 8
2022-12-31 09:39:06,961 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44879824022452036, 'Total loss': 0.44879824022452036} | train loss {'Reaction outcome loss': 0.456458907900718, 'Total loss': 0.456458907900718}
2022-12-31 09:39:06,961 INFO:     Found new best model at epoch 8
2022-12-31 09:39:06,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:06,962 INFO:     Epoch: 9
2022-12-31 09:39:08,534 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4490685075521469, 'Total loss': 0.4490685075521469} | train loss {'Reaction outcome loss': 0.45284995779286336, 'Total loss': 0.45284995779286336}
2022-12-31 09:39:08,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:08,534 INFO:     Epoch: 10
2022-12-31 09:39:10,135 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4423271596431732, 'Total loss': 0.4423271596431732} | train loss {'Reaction outcome loss': 0.4427069047071638, 'Total loss': 0.4427069047071638}
2022-12-31 09:39:10,135 INFO:     Found new best model at epoch 10
2022-12-31 09:39:10,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:10,136 INFO:     Epoch: 11
2022-12-31 09:39:11,736 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44701733589172366, 'Total loss': 0.44701733589172366} | train loss {'Reaction outcome loss': 0.44443387614331975, 'Total loss': 0.44443387614331975}
2022-12-31 09:39:11,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:11,737 INFO:     Epoch: 12
2022-12-31 09:39:13,337 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46563405394554136, 'Total loss': 0.46563405394554136} | train loss {'Reaction outcome loss': 0.4369811515466575, 'Total loss': 0.4369811515466575}
2022-12-31 09:39:13,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:13,337 INFO:     Epoch: 13
2022-12-31 09:39:14,936 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43903248608112333, 'Total loss': 0.43903248608112333} | train loss {'Reaction outcome loss': 0.4266442425385879, 'Total loss': 0.4266442425385879}
2022-12-31 09:39:14,937 INFO:     Found new best model at epoch 13
2022-12-31 09:39:14,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:14,937 INFO:     Epoch: 14
2022-12-31 09:39:16,496 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44856879810492195, 'Total loss': 0.44856879810492195} | train loss {'Reaction outcome loss': 0.42449168159361306, 'Total loss': 0.42449168159361306}
2022-12-31 09:39:16,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:16,497 INFO:     Epoch: 15
2022-12-31 09:39:18,093 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43254746596018473, 'Total loss': 0.43254746596018473} | train loss {'Reaction outcome loss': 0.4161207841532509, 'Total loss': 0.4161207841532509}
2022-12-31 09:39:18,093 INFO:     Found new best model at epoch 15
2022-12-31 09:39:18,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:18,094 INFO:     Epoch: 16
2022-12-31 09:39:19,693 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42376510600248973, 'Total loss': 0.42376510600248973} | train loss {'Reaction outcome loss': 0.41180017166329125, 'Total loss': 0.41180017166329125}
2022-12-31 09:39:19,693 INFO:     Found new best model at epoch 16
2022-12-31 09:39:19,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:19,694 INFO:     Epoch: 17
2022-12-31 09:39:21,293 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43528019189834594, 'Total loss': 0.43528019189834594} | train loss {'Reaction outcome loss': 0.40265468953952305, 'Total loss': 0.40265468953952305}
2022-12-31 09:39:21,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:21,293 INFO:     Epoch: 18
2022-12-31 09:39:22,892 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4620558023452759, 'Total loss': 0.4620558023452759} | train loss {'Reaction outcome loss': 0.397480254897671, 'Total loss': 0.397480254897671}
2022-12-31 09:39:22,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:22,894 INFO:     Epoch: 19
2022-12-31 09:39:24,491 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4553083290656408, 'Total loss': 0.4553083290656408} | train loss {'Reaction outcome loss': 0.3968622239075438, 'Total loss': 0.3968622239075438}
2022-12-31 09:39:24,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:24,491 INFO:     Epoch: 20
2022-12-31 09:39:26,041 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40361954470475514, 'Total loss': 0.40361954470475514} | train loss {'Reaction outcome loss': 0.3867468396949507, 'Total loss': 0.3867468396949507}
2022-12-31 09:39:26,041 INFO:     Found new best model at epoch 20
2022-12-31 09:39:26,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:26,042 INFO:     Epoch: 21
2022-12-31 09:39:27,632 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40524969100952146, 'Total loss': 0.40524969100952146} | train loss {'Reaction outcome loss': 0.3818461636122126, 'Total loss': 0.3818461636122126}
2022-12-31 09:39:27,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:27,632 INFO:     Epoch: 22
2022-12-31 09:39:29,230 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41883563896020254, 'Total loss': 0.41883563896020254} | train loss {'Reaction outcome loss': 0.37400009211179985, 'Total loss': 0.37400009211179985}
2022-12-31 09:39:29,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:29,232 INFO:     Epoch: 23
2022-12-31 09:39:30,856 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44101481735706327, 'Total loss': 0.44101481735706327} | train loss {'Reaction outcome loss': 0.3698967381169761, 'Total loss': 0.3698967381169761}
2022-12-31 09:39:30,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:30,856 INFO:     Epoch: 24
2022-12-31 09:39:32,459 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4060533344745636, 'Total loss': 0.4060533344745636} | train loss {'Reaction outcome loss': 0.3702929928409357, 'Total loss': 0.3702929928409357}
2022-12-31 09:39:32,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:32,460 INFO:     Epoch: 25
2022-12-31 09:39:34,046 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4135622625549634, 'Total loss': 0.4135622625549634} | train loss {'Reaction outcome loss': 0.36062291792056855, 'Total loss': 0.36062291792056855}
2022-12-31 09:39:34,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:34,047 INFO:     Epoch: 26
2022-12-31 09:39:35,604 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40023840268452965, 'Total loss': 0.40023840268452965} | train loss {'Reaction outcome loss': 0.350612865067529, 'Total loss': 0.350612865067529}
2022-12-31 09:39:35,604 INFO:     Found new best model at epoch 26
2022-12-31 09:39:35,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:35,605 INFO:     Epoch: 27
2022-12-31 09:39:37,214 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3756466979781787, 'Total loss': 0.3756466979781787} | train loss {'Reaction outcome loss': 0.35436436599188476, 'Total loss': 0.35436436599188476}
2022-12-31 09:39:37,215 INFO:     Found new best model at epoch 27
2022-12-31 09:39:37,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:37,215 INFO:     Epoch: 28
2022-12-31 09:39:38,823 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.39567805429299674, 'Total loss': 0.39567805429299674} | train loss {'Reaction outcome loss': 0.3408292745151659, 'Total loss': 0.3408292745151659}
2022-12-31 09:39:38,823 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:38,824 INFO:     Epoch: 29
2022-12-31 09:39:40,420 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43157939116160077, 'Total loss': 0.43157939116160077} | train loss {'Reaction outcome loss': 0.3370219052490527, 'Total loss': 0.3370219052490527}
2022-12-31 09:39:40,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:40,422 INFO:     Epoch: 30
2022-12-31 09:39:42,032 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4374045878648758, 'Total loss': 0.4374045878648758} | train loss {'Reaction outcome loss': 0.3380210401395159, 'Total loss': 0.3380210401395159}
2022-12-31 09:39:42,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:42,032 INFO:     Epoch: 31
2022-12-31 09:39:43,523 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38611669739087423, 'Total loss': 0.38611669739087423} | train loss {'Reaction outcome loss': 0.33209608544180863, 'Total loss': 0.33209608544180863}
2022-12-31 09:39:43,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:43,523 INFO:     Epoch: 32
2022-12-31 09:39:44,576 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.38663147191206615, 'Total loss': 0.38663147191206615} | train loss {'Reaction outcome loss': 0.32572606015596944, 'Total loss': 0.32572606015596944}
2022-12-31 09:39:44,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:44,576 INFO:     Epoch: 33
2022-12-31 09:39:45,624 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3999164506793022, 'Total loss': 0.3999164506793022} | train loss {'Reaction outcome loss': 0.3209351943465915, 'Total loss': 0.3209351943465915}
2022-12-31 09:39:45,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:45,626 INFO:     Epoch: 34
2022-12-31 09:39:46,676 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4080718904733658, 'Total loss': 0.4080718904733658} | train loss {'Reaction outcome loss': 0.3118851855941062, 'Total loss': 0.3118851855941062}
2022-12-31 09:39:46,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:46,676 INFO:     Epoch: 35
2022-12-31 09:39:47,724 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39729826549688974, 'Total loss': 0.39729826549688974} | train loss {'Reaction outcome loss': 0.31271217555405884, 'Total loss': 0.31271217555405884}
2022-12-31 09:39:47,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:47,725 INFO:     Epoch: 36
2022-12-31 09:39:49,229 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3962064117193222, 'Total loss': 0.3962064117193222} | train loss {'Reaction outcome loss': 0.30360301187003613, 'Total loss': 0.30360301187003613}
2022-12-31 09:39:49,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:49,229 INFO:     Epoch: 37
2022-12-31 09:39:50,819 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.37886276841163635, 'Total loss': 0.37886276841163635} | train loss {'Reaction outcome loss': 0.30161186147236474, 'Total loss': 0.30161186147236474}
2022-12-31 09:39:50,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:50,819 INFO:     Epoch: 38
2022-12-31 09:39:52,440 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42108825941880546, 'Total loss': 0.42108825941880546} | train loss {'Reaction outcome loss': 0.30027616094036474, 'Total loss': 0.30027616094036474}
2022-12-31 09:39:52,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:52,441 INFO:     Epoch: 39
2022-12-31 09:39:54,045 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3617596795161565, 'Total loss': 0.3617596795161565} | train loss {'Reaction outcome loss': 0.30235990722847245, 'Total loss': 0.30235990722847245}
2022-12-31 09:39:54,045 INFO:     Found new best model at epoch 39
2022-12-31 09:39:54,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:54,046 INFO:     Epoch: 40
2022-12-31 09:39:55,642 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4092052340507507, 'Total loss': 0.4092052340507507} | train loss {'Reaction outcome loss': 0.2945498316990633, 'Total loss': 0.2945498316990633}
2022-12-31 09:39:55,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:55,643 INFO:     Epoch: 41
2022-12-31 09:39:57,221 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3747948557138443, 'Total loss': 0.3747948557138443} | train loss {'Reaction outcome loss': 0.2913733404401663, 'Total loss': 0.2913733404401663}
2022-12-31 09:39:57,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:57,221 INFO:     Epoch: 42
2022-12-31 09:39:58,809 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4091682195663452, 'Total loss': 0.4091682195663452} | train loss {'Reaction outcome loss': 0.2840754351014421, 'Total loss': 0.2840754351014421}
2022-12-31 09:39:58,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:39:58,810 INFO:     Epoch: 43
2022-12-31 09:40:00,399 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3586734841267268, 'Total loss': 0.3586734841267268} | train loss {'Reaction outcome loss': 0.2863650475594684, 'Total loss': 0.2863650475594684}
2022-12-31 09:40:00,400 INFO:     Found new best model at epoch 43
2022-12-31 09:40:00,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:00,401 INFO:     Epoch: 44
2022-12-31 09:40:01,997 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40622840225696566, 'Total loss': 0.40622840225696566} | train loss {'Reaction outcome loss': 0.28074384590841994, 'Total loss': 0.28074384590841994}
2022-12-31 09:40:01,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:01,998 INFO:     Epoch: 45
2022-12-31 09:40:03,596 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.339477875828743, 'Total loss': 0.339477875828743} | train loss {'Reaction outcome loss': 0.2758594426686746, 'Total loss': 0.2758594426686746}
2022-12-31 09:40:03,596 INFO:     Found new best model at epoch 45
2022-12-31 09:40:03,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:03,597 INFO:     Epoch: 46
2022-12-31 09:40:05,192 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.38438833753267926, 'Total loss': 0.38438833753267926} | train loss {'Reaction outcome loss': 0.27567807911303793, 'Total loss': 0.27567807911303793}
2022-12-31 09:40:05,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:05,194 INFO:     Epoch: 47
2022-12-31 09:40:06,779 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3954375505447388, 'Total loss': 0.3954375505447388} | train loss {'Reaction outcome loss': 0.279128918872915, 'Total loss': 0.279128918872915}
2022-12-31 09:40:06,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:06,779 INFO:     Epoch: 48
2022-12-31 09:40:08,373 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38094702263673147, 'Total loss': 0.38094702263673147} | train loss {'Reaction outcome loss': 0.2743162732149889, 'Total loss': 0.2743162732149889}
2022-12-31 09:40:08,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:08,374 INFO:     Epoch: 49
2022-12-31 09:40:10,021 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3653316463033358, 'Total loss': 0.3653316463033358} | train loss {'Reaction outcome loss': 0.27012656593736073, 'Total loss': 0.27012656593736073}
2022-12-31 09:40:10,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:10,022 INFO:     Epoch: 50
2022-12-31 09:40:11,621 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3875423361857732, 'Total loss': 0.3875423361857732} | train loss {'Reaction outcome loss': 0.267880646607084, 'Total loss': 0.267880646607084}
2022-12-31 09:40:11,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:11,622 INFO:     Epoch: 51
2022-12-31 09:40:13,218 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3577169562379519, 'Total loss': 0.3577169562379519} | train loss {'Reaction outcome loss': 0.26746805210726976, 'Total loss': 0.26746805210726976}
2022-12-31 09:40:13,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:13,218 INFO:     Epoch: 52
2022-12-31 09:40:14,863 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3654176505903403, 'Total loss': 0.3654176505903403} | train loss {'Reaction outcome loss': 0.2607578683481382, 'Total loss': 0.2607578683481382}
2022-12-31 09:40:14,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:14,863 INFO:     Epoch: 53
2022-12-31 09:40:16,454 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38862973848978677, 'Total loss': 0.38862973848978677} | train loss {'Reaction outcome loss': 0.2689005311945603, 'Total loss': 0.2689005311945603}
2022-12-31 09:40:16,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:16,455 INFO:     Epoch: 54
2022-12-31 09:40:18,036 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40959558884302777, 'Total loss': 0.40959558884302777} | train loss {'Reaction outcome loss': 0.25910864949878987, 'Total loss': 0.25910864949878987}
2022-12-31 09:40:18,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:18,036 INFO:     Epoch: 55
2022-12-31 09:40:19,637 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3798433889945348, 'Total loss': 0.3798433889945348} | train loss {'Reaction outcome loss': 0.2516110396780835, 'Total loss': 0.2516110396780835}
2022-12-31 09:40:19,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:19,637 INFO:     Epoch: 56
2022-12-31 09:40:21,253 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3744479810198148, 'Total loss': 0.3744479810198148} | train loss {'Reaction outcome loss': 0.25554971073339455, 'Total loss': 0.25554971073339455}
2022-12-31 09:40:21,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:21,253 INFO:     Epoch: 57
2022-12-31 09:40:22,860 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40291614929835, 'Total loss': 0.40291614929835} | train loss {'Reaction outcome loss': 0.2532416134053012, 'Total loss': 0.2532416134053012}
2022-12-31 09:40:22,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:22,861 INFO:     Epoch: 58
2022-12-31 09:40:24,471 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.372773019472758, 'Total loss': 0.372773019472758} | train loss {'Reaction outcome loss': 0.2520088353772124, 'Total loss': 0.2520088353772124}
2022-12-31 09:40:24,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:24,471 INFO:     Epoch: 59
2022-12-31 09:40:26,082 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3470865289370219, 'Total loss': 0.3470865289370219} | train loss {'Reaction outcome loss': 0.24581094635446576, 'Total loss': 0.24581094635446576}
2022-12-31 09:40:26,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:26,082 INFO:     Epoch: 60
2022-12-31 09:40:27,684 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3744395097096761, 'Total loss': 0.3744395097096761} | train loss {'Reaction outcome loss': 0.24957789078246068, 'Total loss': 0.24957789078246068}
2022-12-31 09:40:27,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:27,684 INFO:     Epoch: 61
2022-12-31 09:40:29,283 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3448893626530965, 'Total loss': 0.3448893626530965} | train loss {'Reaction outcome loss': 0.24253943449661244, 'Total loss': 0.24253943449661244}
2022-12-31 09:40:29,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:29,284 INFO:     Epoch: 62
2022-12-31 09:40:30,918 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3697458624839783, 'Total loss': 0.3697458624839783} | train loss {'Reaction outcome loss': 0.24546940178766738, 'Total loss': 0.24546940178766738}
2022-12-31 09:40:30,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:30,918 INFO:     Epoch: 63
2022-12-31 09:40:32,557 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3535525461037954, 'Total loss': 0.3535525461037954} | train loss {'Reaction outcome loss': 0.24108708840217033, 'Total loss': 0.24108708840217033}
2022-12-31 09:40:32,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:32,558 INFO:     Epoch: 64
2022-12-31 09:40:34,176 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3710662712653478, 'Total loss': 0.3710662712653478} | train loss {'Reaction outcome loss': 0.23865146854770009, 'Total loss': 0.23865146854770009}
2022-12-31 09:40:34,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:34,177 INFO:     Epoch: 65
2022-12-31 09:40:35,797 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40376431941986085, 'Total loss': 0.40376431941986085} | train loss {'Reaction outcome loss': 0.23930352090783144, 'Total loss': 0.23930352090783144}
2022-12-31 09:40:35,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:35,797 INFO:     Epoch: 66
2022-12-31 09:40:37,439 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39014052152633666, 'Total loss': 0.39014052152633666} | train loss {'Reaction outcome loss': 0.23889740152678784, 'Total loss': 0.23889740152678784}
2022-12-31 09:40:37,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:37,439 INFO:     Epoch: 67
2022-12-31 09:40:39,087 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38953914990027744, 'Total loss': 0.38953914990027744} | train loss {'Reaction outcome loss': 0.2389223845335689, 'Total loss': 0.2389223845335689}
2022-12-31 09:40:39,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:39,088 INFO:     Epoch: 68
2022-12-31 09:40:40,733 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3634975160161654, 'Total loss': 0.3634975160161654} | train loss {'Reaction outcome loss': 0.22944000625071953, 'Total loss': 0.22944000625071953}
2022-12-31 09:40:40,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:40,734 INFO:     Epoch: 69
2022-12-31 09:40:42,378 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3874602824449539, 'Total loss': 0.3874602824449539} | train loss {'Reaction outcome loss': 0.23825331853471532, 'Total loss': 0.23825331853471532}
2022-12-31 09:40:42,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:42,379 INFO:     Epoch: 70
2022-12-31 09:40:43,998 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.34681240071853003, 'Total loss': 0.34681240071853003} | train loss {'Reaction outcome loss': 0.2338076377573022, 'Total loss': 0.2338076377573022}
2022-12-31 09:40:43,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:43,998 INFO:     Epoch: 71
2022-12-31 09:40:45,592 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.36696013510227204, 'Total loss': 0.36696013510227204} | train loss {'Reaction outcome loss': 0.22582450184807942, 'Total loss': 0.22582450184807942}
2022-12-31 09:40:45,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:45,592 INFO:     Epoch: 72
2022-12-31 09:40:47,198 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40377203077077867, 'Total loss': 0.40377203077077867} | train loss {'Reaction outcome loss': 0.2293503833866685, 'Total loss': 0.2293503833866685}
2022-12-31 09:40:47,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:47,200 INFO:     Epoch: 73
2022-12-31 09:40:48,824 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3744419713815053, 'Total loss': 0.3744419713815053} | train loss {'Reaction outcome loss': 0.22618268252126056, 'Total loss': 0.22618268252126056}
2022-12-31 09:40:48,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:48,824 INFO:     Epoch: 74
2022-12-31 09:40:50,432 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3706301401058833, 'Total loss': 0.3706301401058833} | train loss {'Reaction outcome loss': 0.22375817789295077, 'Total loss': 0.22375817789295077}
2022-12-31 09:40:50,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:50,433 INFO:     Epoch: 75
2022-12-31 09:40:52,030 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.35468177994092304, 'Total loss': 0.35468177994092304} | train loss {'Reaction outcome loss': 0.2247694620155614, 'Total loss': 0.2247694620155614}
2022-12-31 09:40:52,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:52,030 INFO:     Epoch: 76
2022-12-31 09:40:53,613 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.34113829185565314, 'Total loss': 0.34113829185565314} | train loss {'Reaction outcome loss': 0.2236961733114763, 'Total loss': 0.2236961733114763}
2022-12-31 09:40:53,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:53,614 INFO:     Epoch: 77
2022-12-31 09:40:55,219 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3508598198493322, 'Total loss': 0.3508598198493322} | train loss {'Reaction outcome loss': 0.2277796677293351, 'Total loss': 0.2277796677293351}
2022-12-31 09:40:55,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:55,219 INFO:     Epoch: 78
2022-12-31 09:40:56,826 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.37042980790138247, 'Total loss': 0.37042980790138247} | train loss {'Reaction outcome loss': 0.22454807419248307, 'Total loss': 0.22454807419248307}
2022-12-31 09:40:56,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:56,826 INFO:     Epoch: 79
2022-12-31 09:40:58,432 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3353299836317698, 'Total loss': 0.3353299836317698} | train loss {'Reaction outcome loss': 0.21648431244054742, 'Total loss': 0.21648431244054742}
2022-12-31 09:40:58,432 INFO:     Found new best model at epoch 79
2022-12-31 09:40:58,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:40:58,433 INFO:     Epoch: 80
2022-12-31 09:41:00,039 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.338578587770462, 'Total loss': 0.338578587770462} | train loss {'Reaction outcome loss': 0.22584995532911406, 'Total loss': 0.22584995532911406}
2022-12-31 09:41:00,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:00,040 INFO:     Epoch: 81
2022-12-31 09:41:01,625 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.34012970328330994, 'Total loss': 0.34012970328330994} | train loss {'Reaction outcome loss': 0.21437634444747963, 'Total loss': 0.21437634444747963}
2022-12-31 09:41:01,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:01,626 INFO:     Epoch: 82
2022-12-31 09:41:03,239 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.36649648249149325, 'Total loss': 0.36649648249149325} | train loss {'Reaction outcome loss': 0.21709478770919743, 'Total loss': 0.21709478770919743}
2022-12-31 09:41:03,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:03,239 INFO:     Epoch: 83
2022-12-31 09:41:04,846 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.345495842397213, 'Total loss': 0.345495842397213} | train loss {'Reaction outcome loss': 0.2216548093247914, 'Total loss': 0.2216548093247914}
2022-12-31 09:41:04,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:04,846 INFO:     Epoch: 84
2022-12-31 09:41:06,478 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38088514357805253, 'Total loss': 0.38088514357805253} | train loss {'Reaction outcome loss': 0.22766498954164505, 'Total loss': 0.22766498954164505}
2022-12-31 09:41:06,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:06,480 INFO:     Epoch: 85
2022-12-31 09:41:08,093 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.35068455735842385, 'Total loss': 0.35068455735842385} | train loss {'Reaction outcome loss': 0.21732434191244798, 'Total loss': 0.21732434191244798}
2022-12-31 09:41:08,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:08,094 INFO:     Epoch: 86
2022-12-31 09:41:09,690 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.35586169809103013, 'Total loss': 0.35586169809103013} | train loss {'Reaction outcome loss': 0.21459820227575127, 'Total loss': 0.21459820227575127}
2022-12-31 09:41:09,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:09,690 INFO:     Epoch: 87
2022-12-31 09:41:11,282 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.33609081506729127, 'Total loss': 0.33609081506729127} | train loss {'Reaction outcome loss': 0.21647261724854908, 'Total loss': 0.21647261724854908}
2022-12-31 09:41:11,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:11,283 INFO:     Epoch: 88
2022-12-31 09:41:12,899 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.34901373386383056, 'Total loss': 0.34901373386383056} | train loss {'Reaction outcome loss': 0.2091281577523281, 'Total loss': 0.2091281577523281}
2022-12-31 09:41:12,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:12,899 INFO:     Epoch: 89
2022-12-31 09:41:14,555 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3817455460627874, 'Total loss': 0.3817455460627874} | train loss {'Reaction outcome loss': 0.2118460043829723, 'Total loss': 0.2118460043829723}
2022-12-31 09:41:14,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:14,555 INFO:     Epoch: 90
2022-12-31 09:41:16,164 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3447777330875397, 'Total loss': 0.3447777330875397} | train loss {'Reaction outcome loss': 0.2149528929705385, 'Total loss': 0.2149528929705385}
2022-12-31 09:41:16,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:16,165 INFO:     Epoch: 91
2022-12-31 09:41:17,763 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38862879772981007, 'Total loss': 0.38862879772981007} | train loss {'Reaction outcome loss': 0.21274381953488736, 'Total loss': 0.21274381953488736}
2022-12-31 09:41:17,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:17,763 INFO:     Epoch: 92
2022-12-31 09:41:19,372 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3690968150893847, 'Total loss': 0.3690968150893847} | train loss {'Reaction outcome loss': 0.20255346491722132, 'Total loss': 0.20255346491722132}
2022-12-31 09:41:19,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:19,373 INFO:     Epoch: 93
2022-12-31 09:41:20,978 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3844101538260778, 'Total loss': 0.3844101538260778} | train loss {'Reaction outcome loss': 0.20486761949766075, 'Total loss': 0.20486761949766075}
2022-12-31 09:41:20,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:20,978 INFO:     Epoch: 94
2022-12-31 09:41:22,585 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38188173100352285, 'Total loss': 0.38188173100352285} | train loss {'Reaction outcome loss': 0.20170249274666727, 'Total loss': 0.20170249274666727}
2022-12-31 09:41:22,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:22,586 INFO:     Epoch: 95
2022-12-31 09:41:24,188 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.36481869320074717, 'Total loss': 0.36481869320074717} | train loss {'Reaction outcome loss': 0.20764015407648181, 'Total loss': 0.20764015407648181}
2022-12-31 09:41:24,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:24,189 INFO:     Epoch: 96
2022-12-31 09:41:25,789 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.36949841504295666, 'Total loss': 0.36949841504295666} | train loss {'Reaction outcome loss': 0.20588414997447038, 'Total loss': 0.20588414997447038}
2022-12-31 09:41:25,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:25,789 INFO:     Epoch: 97
2022-12-31 09:41:27,390 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.38848638733228047, 'Total loss': 0.38848638733228047} | train loss {'Reaction outcome loss': 0.19977491978474343, 'Total loss': 0.19977491978474343}
2022-12-31 09:41:27,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:27,391 INFO:     Epoch: 98
2022-12-31 09:41:28,981 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3585372596979141, 'Total loss': 0.3585372596979141} | train loss {'Reaction outcome loss': 0.19946847638509568, 'Total loss': 0.19946847638509568}
2022-12-31 09:41:28,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:28,982 INFO:     Epoch: 99
2022-12-31 09:41:30,581 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.37122979064782463, 'Total loss': 0.37122979064782463} | train loss {'Reaction outcome loss': 0.2039762325448929, 'Total loss': 0.2039762325448929}
2022-12-31 09:41:30,581 INFO:     Best model found after epoch 80 of 100.
2022-12-31 09:41:30,581 INFO:   Done with stage: TRAINING
2022-12-31 09:41:30,581 INFO:   Starting stage: EVALUATION
2022-12-31 09:41:30,714 INFO:   Done with stage: EVALUATION
2022-12-31 09:41:30,715 INFO:   Leaving out SEQ value Fold_4
2022-12-31 09:41:30,727 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 09:41:30,727 INFO:   Starting stage: FEATURE SCALING
2022-12-31 09:41:31,390 INFO:   Done with stage: FEATURE SCALING
2022-12-31 09:41:31,390 INFO:   Starting stage: SCALING TARGETS
2022-12-31 09:41:31,460 INFO:   Done with stage: SCALING TARGETS
2022-12-31 09:41:31,460 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:41:31,460 INFO:     No hyperparam tuning for this model
2022-12-31 09:41:31,460 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:41:31,460 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 09:41:31,461 INFO:     None feature selector for col prot
2022-12-31 09:41:31,461 INFO:     None feature selector for col prot
2022-12-31 09:41:31,461 INFO:     None feature selector for col prot
2022-12-31 09:41:31,462 INFO:     None feature selector for col chem
2022-12-31 09:41:31,462 INFO:     None feature selector for col chem
2022-12-31 09:41:31,462 INFO:     None feature selector for col chem
2022-12-31 09:41:31,462 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 09:41:31,462 INFO:   Starting stage: BUILD MODEL
2022-12-31 09:41:31,464 INFO:     Number of params in model 223921
2022-12-31 09:41:31,467 INFO:   Done with stage: BUILD MODEL
2022-12-31 09:41:31,467 INFO:   Starting stage: TRAINING
2022-12-31 09:41:31,511 INFO:     Val loss before train {'Reaction outcome loss': 0.9542633473873139, 'Total loss': 0.9542633473873139}
2022-12-31 09:41:31,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:31,512 INFO:     Epoch: 0
2022-12-31 09:41:33,151 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5920696099599202, 'Total loss': 0.5920696099599202} | train loss {'Reaction outcome loss': 0.8058208796012141, 'Total loss': 0.8058208796012141}
2022-12-31 09:41:33,151 INFO:     Found new best model at epoch 0
2022-12-31 09:41:33,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:33,152 INFO:     Epoch: 1
2022-12-31 09:41:34,784 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5491318186124166, 'Total loss': 0.5491318186124166} | train loss {'Reaction outcome loss': 0.5898513229985307, 'Total loss': 0.5898513229985307}
2022-12-31 09:41:34,784 INFO:     Found new best model at epoch 1
2022-12-31 09:41:34,785 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:34,785 INFO:     Epoch: 2
2022-12-31 09:41:36,392 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4931746522585551, 'Total loss': 0.4931746522585551} | train loss {'Reaction outcome loss': 0.5151815832096295, 'Total loss': 0.5151815832096295}
2022-12-31 09:41:36,393 INFO:     Found new best model at epoch 2
2022-12-31 09:41:36,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:36,394 INFO:     Epoch: 3
2022-12-31 09:41:37,975 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4712450345357259, 'Total loss': 0.4712450345357259} | train loss {'Reaction outcome loss': 0.4957508336018472, 'Total loss': 0.4957508336018472}
2022-12-31 09:41:37,975 INFO:     Found new best model at epoch 3
2022-12-31 09:41:37,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:37,976 INFO:     Epoch: 4
2022-12-31 09:41:39,557 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.477982955177625, 'Total loss': 0.477982955177625} | train loss {'Reaction outcome loss': 0.47212250068457456, 'Total loss': 0.47212250068457456}
2022-12-31 09:41:39,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:39,557 INFO:     Epoch: 5
2022-12-31 09:41:41,167 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49225929379463196, 'Total loss': 0.49225929379463196} | train loss {'Reaction outcome loss': 0.46549613316998867, 'Total loss': 0.46549613316998867}
2022-12-31 09:41:41,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:41,167 INFO:     Epoch: 6
2022-12-31 09:41:42,773 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4755438615878423, 'Total loss': 0.4755438615878423} | train loss {'Reaction outcome loss': 0.45610012320706445, 'Total loss': 0.45610012320706445}
2022-12-31 09:41:42,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:42,774 INFO:     Epoch: 7
2022-12-31 09:41:44,376 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4541323810815811, 'Total loss': 0.4541323810815811} | train loss {'Reaction outcome loss': 0.44954330126081943, 'Total loss': 0.44954330126081943}
2022-12-31 09:41:44,377 INFO:     Found new best model at epoch 7
2022-12-31 09:41:44,377 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:44,378 INFO:     Epoch: 8
2022-12-31 09:41:45,968 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4378548870484034, 'Total loss': 0.4378548870484034} | train loss {'Reaction outcome loss': 0.43875034680984315, 'Total loss': 0.43875034680984315}
2022-12-31 09:41:45,968 INFO:     Found new best model at epoch 8
2022-12-31 09:41:45,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:45,969 INFO:     Epoch: 9
2022-12-31 09:41:47,550 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44360411862532295, 'Total loss': 0.44360411862532295} | train loss {'Reaction outcome loss': 0.4350782292929009, 'Total loss': 0.4350782292929009}
2022-12-31 09:41:47,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:47,551 INFO:     Epoch: 10
2022-12-31 09:41:49,131 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4542960753043493, 'Total loss': 0.4542960753043493} | train loss {'Reaction outcome loss': 0.4279801885794549, 'Total loss': 0.4279801885794549}
2022-12-31 09:41:49,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:49,131 INFO:     Epoch: 11
2022-12-31 09:41:50,734 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45709025065104164, 'Total loss': 0.45709025065104164} | train loss {'Reaction outcome loss': 0.42165813578741396, 'Total loss': 0.42165813578741396}
2022-12-31 09:41:50,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:50,734 INFO:     Epoch: 12
2022-12-31 09:41:52,336 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4636915644009908, 'Total loss': 0.4636915644009908} | train loss {'Reaction outcome loss': 0.4191078145845528, 'Total loss': 0.4191078145845528}
2022-12-31 09:41:52,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:52,336 INFO:     Epoch: 13
2022-12-31 09:41:53,971 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45204345186551415, 'Total loss': 0.45204345186551415} | train loss {'Reaction outcome loss': 0.4097494434320579, 'Total loss': 0.4097494434320579}
2022-12-31 09:41:53,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:53,973 INFO:     Epoch: 14
2022-12-31 09:41:55,566 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42004366517066954, 'Total loss': 0.42004366517066954} | train loss {'Reaction outcome loss': 0.4025076974971886, 'Total loss': 0.4025076974971886}
2022-12-31 09:41:55,566 INFO:     Found new best model at epoch 14
2022-12-31 09:41:55,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:55,567 INFO:     Epoch: 15
2022-12-31 09:41:57,189 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45321073532104494, 'Total loss': 0.45321073532104494} | train loss {'Reaction outcome loss': 0.397767614369301, 'Total loss': 0.397767614369301}
2022-12-31 09:41:57,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:57,189 INFO:     Epoch: 16
2022-12-31 09:41:58,836 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.422784635424614, 'Total loss': 0.422784635424614} | train loss {'Reaction outcome loss': 0.39974747304498714, 'Total loss': 0.39974747304498714}
2022-12-31 09:41:58,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:41:58,836 INFO:     Epoch: 17
2022-12-31 09:42:00,457 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44706561664740246, 'Total loss': 0.44706561664740246} | train loss {'Reaction outcome loss': 0.3942996858190881, 'Total loss': 0.3942996858190881}
2022-12-31 09:42:00,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:00,459 INFO:     Epoch: 18
2022-12-31 09:42:02,093 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46015390157699587, 'Total loss': 0.46015390157699587} | train loss {'Reaction outcome loss': 0.38730120563702863, 'Total loss': 0.38730120563702863}
2022-12-31 09:42:02,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:02,093 INFO:     Epoch: 19
2022-12-31 09:42:03,718 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43034897843996683, 'Total loss': 0.43034897843996683} | train loss {'Reaction outcome loss': 0.38609353278892755, 'Total loss': 0.38609353278892755}
2022-12-31 09:42:03,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:03,718 INFO:     Epoch: 20
2022-12-31 09:42:05,324 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4407863656679789, 'Total loss': 0.4407863656679789} | train loss {'Reaction outcome loss': 0.3716027305672204, 'Total loss': 0.3716027305672204}
2022-12-31 09:42:05,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:05,325 INFO:     Epoch: 21
2022-12-31 09:42:06,933 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4115671793619792, 'Total loss': 0.4115671793619792} | train loss {'Reaction outcome loss': 0.3750452741599866, 'Total loss': 0.3750452741599866}
2022-12-31 09:42:06,933 INFO:     Found new best model at epoch 21
2022-12-31 09:42:06,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:06,934 INFO:     Epoch: 22
2022-12-31 09:42:08,561 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41811366776625314, 'Total loss': 0.41811366776625314} | train loss {'Reaction outcome loss': 0.364249933456635, 'Total loss': 0.364249933456635}
2022-12-31 09:42:08,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:08,561 INFO:     Epoch: 23
2022-12-31 09:42:10,183 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4453828235467275, 'Total loss': 0.4453828235467275} | train loss {'Reaction outcome loss': 0.36404141460130685, 'Total loss': 0.36404141460130685}
2022-12-31 09:42:10,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:10,184 INFO:     Epoch: 24
2022-12-31 09:42:11,820 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43938894669214884, 'Total loss': 0.43938894669214884} | train loss {'Reaction outcome loss': 0.36069490249357083, 'Total loss': 0.36069490249357083}
2022-12-31 09:42:11,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:11,820 INFO:     Epoch: 25
2022-12-31 09:42:13,449 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41154066820939383, 'Total loss': 0.41154066820939383} | train loss {'Reaction outcome loss': 0.35367073439551094, 'Total loss': 0.35367073439551094}
2022-12-31 09:42:13,449 INFO:     Found new best model at epoch 25
2022-12-31 09:42:13,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:13,450 INFO:     Epoch: 26
2022-12-31 09:42:15,100 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4070363283157349, 'Total loss': 0.4070363283157349} | train loss {'Reaction outcome loss': 0.34609943655503056, 'Total loss': 0.34609943655503056}
2022-12-31 09:42:15,100 INFO:     Found new best model at epoch 26
2022-12-31 09:42:15,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:15,101 INFO:     Epoch: 27
2022-12-31 09:42:16,707 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4214425474405289, 'Total loss': 0.4214425474405289} | train loss {'Reaction outcome loss': 0.3480300525080984, 'Total loss': 0.3480300525080984}
2022-12-31 09:42:16,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:16,707 INFO:     Epoch: 28
2022-12-31 09:42:18,350 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40646820863087973, 'Total loss': 0.40646820863087973} | train loss {'Reaction outcome loss': 0.33804045130845406, 'Total loss': 0.33804045130845406}
2022-12-31 09:42:18,352 INFO:     Found new best model at epoch 28
2022-12-31 09:42:18,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:18,353 INFO:     Epoch: 29
2022-12-31 09:42:20,002 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4407765875260035, 'Total loss': 0.4407765875260035} | train loss {'Reaction outcome loss': 0.33061153811477395, 'Total loss': 0.33061153811477395}
2022-12-31 09:42:20,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:20,002 INFO:     Epoch: 30
2022-12-31 09:42:21,620 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.387213929494222, 'Total loss': 0.387213929494222} | train loss {'Reaction outcome loss': 0.3283054138513377, 'Total loss': 0.3283054138513377}
2022-12-31 09:42:21,620 INFO:     Found new best model at epoch 30
2022-12-31 09:42:21,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:21,621 INFO:     Epoch: 31
2022-12-31 09:42:23,198 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.39483744502067564, 'Total loss': 0.39483744502067564} | train loss {'Reaction outcome loss': 0.33099134046122103, 'Total loss': 0.33099134046122103}
2022-12-31 09:42:23,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:23,200 INFO:     Epoch: 32
2022-12-31 09:42:24,792 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.38342177172501885, 'Total loss': 0.38342177172501885} | train loss {'Reaction outcome loss': 0.32445214842412157, 'Total loss': 0.32445214842412157}
2022-12-31 09:42:24,792 INFO:     Found new best model at epoch 32
2022-12-31 09:42:24,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:24,793 INFO:     Epoch: 33
2022-12-31 09:42:26,397 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3740385264158249, 'Total loss': 0.3740385264158249} | train loss {'Reaction outcome loss': 0.31806138737032014, 'Total loss': 0.31806138737032014}
2022-12-31 09:42:26,397 INFO:     Found new best model at epoch 33
2022-12-31 09:42:26,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:26,398 INFO:     Epoch: 34
2022-12-31 09:42:28,004 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4397060026725133, 'Total loss': 0.4397060026725133} | train loss {'Reaction outcome loss': 0.31999557024806086, 'Total loss': 0.31999557024806086}
2022-12-31 09:42:28,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:28,004 INFO:     Epoch: 35
2022-12-31 09:42:29,613 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3610913003484408, 'Total loss': 0.3610913003484408} | train loss {'Reaction outcome loss': 0.31133686438420394, 'Total loss': 0.31133686438420394}
2022-12-31 09:42:29,613 INFO:     Found new best model at epoch 35
2022-12-31 09:42:29,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:29,614 INFO:     Epoch: 36
2022-12-31 09:42:31,198 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.36728535989920297, 'Total loss': 0.36728535989920297} | train loss {'Reaction outcome loss': 0.3076569445050546, 'Total loss': 0.3076569445050546}
2022-12-31 09:42:31,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:31,200 INFO:     Epoch: 37
2022-12-31 09:42:32,783 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3650425970554352, 'Total loss': 0.3650425970554352} | train loss {'Reaction outcome loss': 0.3058288214034843, 'Total loss': 0.3058288214034843}
2022-12-31 09:42:32,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:32,784 INFO:     Epoch: 38
2022-12-31 09:42:34,383 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3991129477818807, 'Total loss': 0.3991129477818807} | train loss {'Reaction outcome loss': 0.30140117770672714, 'Total loss': 0.30140117770672714}
2022-12-31 09:42:34,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:34,383 INFO:     Epoch: 39
2022-12-31 09:42:35,960 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3685577193895976, 'Total loss': 0.3685577193895976} | train loss {'Reaction outcome loss': 0.3005146438622997, 'Total loss': 0.3005146438622997}
2022-12-31 09:42:35,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:35,961 INFO:     Epoch: 40
2022-12-31 09:42:37,587 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40067530473073326, 'Total loss': 0.40067530473073326} | train loss {'Reaction outcome loss': 0.2889002012836672, 'Total loss': 0.2889002012836672}
2022-12-31 09:42:37,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:37,588 INFO:     Epoch: 41
2022-12-31 09:42:39,202 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39144139289855956, 'Total loss': 0.39144139289855956} | train loss {'Reaction outcome loss': 0.2975795956015804, 'Total loss': 0.2975795956015804}
2022-12-31 09:42:39,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:39,203 INFO:     Epoch: 42
2022-12-31 09:42:40,793 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.36963043312231697, 'Total loss': 0.36963043312231697} | train loss {'Reaction outcome loss': 0.2932868091946971, 'Total loss': 0.2932868091946971}
2022-12-31 09:42:40,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:40,794 INFO:     Epoch: 43
2022-12-31 09:42:42,407 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4100724657376607, 'Total loss': 0.4100724657376607} | train loss {'Reaction outcome loss': 0.28843124824011845, 'Total loss': 0.28843124824011845}
2022-12-31 09:42:42,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:42,408 INFO:     Epoch: 44
2022-12-31 09:42:44,005 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4012987027565638, 'Total loss': 0.4012987027565638} | train loss {'Reaction outcome loss': 0.28200234499943516, 'Total loss': 0.28200234499943516}
2022-12-31 09:42:44,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:44,006 INFO:     Epoch: 45
2022-12-31 09:42:45,599 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4012471069892248, 'Total loss': 0.4012471069892248} | train loss {'Reaction outcome loss': 0.2762970706298403, 'Total loss': 0.2762970706298403}
2022-12-31 09:42:45,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:45,600 INFO:     Epoch: 46
2022-12-31 09:42:47,200 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40299696624279024, 'Total loss': 0.40299696624279024} | train loss {'Reaction outcome loss': 0.27424295640883656, 'Total loss': 0.27424295640883656}
2022-12-31 09:42:47,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:47,200 INFO:     Epoch: 47
2022-12-31 09:42:48,801 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39014915625254315, 'Total loss': 0.39014915625254315} | train loss {'Reaction outcome loss': 0.27605398655971036, 'Total loss': 0.27605398655971036}
2022-12-31 09:42:48,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:48,803 INFO:     Epoch: 48
2022-12-31 09:42:50,397 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3736191252867381, 'Total loss': 0.3736191252867381} | train loss {'Reaction outcome loss': 0.2723012141353131, 'Total loss': 0.2723012141353131}
2022-12-31 09:42:50,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:50,397 INFO:     Epoch: 49
2022-12-31 09:42:51,990 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3513147165377935, 'Total loss': 0.3513147165377935} | train loss {'Reaction outcome loss': 0.27178776764521634, 'Total loss': 0.27178776764521634}
2022-12-31 09:42:51,990 INFO:     Found new best model at epoch 49
2022-12-31 09:42:51,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:51,991 INFO:     Epoch: 50
2022-12-31 09:42:53,587 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4404920021692912, 'Total loss': 0.4404920021692912} | train loss {'Reaction outcome loss': 0.2700175235088724, 'Total loss': 0.2700175235088724}
2022-12-31 09:42:53,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:53,588 INFO:     Epoch: 51
2022-12-31 09:42:55,185 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3963356335957845, 'Total loss': 0.3963356335957845} | train loss {'Reaction outcome loss': 0.26309456741505294, 'Total loss': 0.26309456741505294}
2022-12-31 09:42:55,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:55,186 INFO:     Epoch: 52
2022-12-31 09:42:56,786 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4106627066930135, 'Total loss': 0.4106627066930135} | train loss {'Reaction outcome loss': 0.2705847537484917, 'Total loss': 0.2705847537484917}
2022-12-31 09:42:56,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:56,786 INFO:     Epoch: 53
2022-12-31 09:42:58,387 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38786287009716036, 'Total loss': 0.38786287009716036} | train loss {'Reaction outcome loss': 0.26142076128264413, 'Total loss': 0.26142076128264413}
2022-12-31 09:42:58,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:58,387 INFO:     Epoch: 54
2022-12-31 09:42:59,974 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.37538387974103293, 'Total loss': 0.37538387974103293} | train loss {'Reaction outcome loss': 0.26308584315226463, 'Total loss': 0.26308584315226463}
2022-12-31 09:42:59,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:42:59,976 INFO:     Epoch: 55
2022-12-31 09:43:01,581 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3499863346417745, 'Total loss': 0.3499863346417745} | train loss {'Reaction outcome loss': 0.2502322168205015, 'Total loss': 0.2502322168205015}
2022-12-31 09:43:01,581 INFO:     Found new best model at epoch 55
2022-12-31 09:43:01,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:01,582 INFO:     Epoch: 56
2022-12-31 09:43:03,178 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.36792010366916655, 'Total loss': 0.36792010366916655} | train loss {'Reaction outcome loss': 0.2567668272331901, 'Total loss': 0.2567668272331901}
2022-12-31 09:43:03,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:03,178 INFO:     Epoch: 57
2022-12-31 09:43:04,775 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4147119144598643, 'Total loss': 0.4147119144598643} | train loss {'Reaction outcome loss': 0.25574728196663576, 'Total loss': 0.25574728196663576}
2022-12-31 09:43:04,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:04,775 INFO:     Epoch: 58
2022-12-31 09:43:06,398 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.35869842519362766, 'Total loss': 0.35869842519362766} | train loss {'Reaction outcome loss': 0.24625079399042757, 'Total loss': 0.24625079399042757}
2022-12-31 09:43:06,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:06,398 INFO:     Epoch: 59
2022-12-31 09:43:08,009 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3796752283970515, 'Total loss': 0.3796752283970515} | train loss {'Reaction outcome loss': 0.24630485486619882, 'Total loss': 0.24630485486619882}
2022-12-31 09:43:08,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:08,011 INFO:     Epoch: 60
2022-12-31 09:43:09,591 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3363479753335317, 'Total loss': 0.3363479753335317} | train loss {'Reaction outcome loss': 0.25535085549863584, 'Total loss': 0.25535085549863584}
2022-12-31 09:43:09,591 INFO:     Found new best model at epoch 60
2022-12-31 09:43:09,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:09,592 INFO:     Epoch: 61
2022-12-31 09:43:11,176 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3550528183579445, 'Total loss': 0.3550528183579445} | train loss {'Reaction outcome loss': 0.2446450015570778, 'Total loss': 0.2446450015570778}
2022-12-31 09:43:11,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:11,177 INFO:     Epoch: 62
2022-12-31 09:43:12,769 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3542732874552409, 'Total loss': 0.3542732874552409} | train loss {'Reaction outcome loss': 0.24575288045172491, 'Total loss': 0.24575288045172491}
2022-12-31 09:43:12,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:12,769 INFO:     Epoch: 63
2022-12-31 09:43:14,364 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.36292359431584675, 'Total loss': 0.36292359431584675} | train loss {'Reaction outcome loss': 0.23729604653959727, 'Total loss': 0.23729604653959727}
2022-12-31 09:43:14,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:14,365 INFO:     Epoch: 64
2022-12-31 09:43:15,957 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3787994906306267, 'Total loss': 0.3787994906306267} | train loss {'Reaction outcome loss': 0.2410333338091626, 'Total loss': 0.2410333338091626}
2022-12-31 09:43:15,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:15,957 INFO:     Epoch: 65
2022-12-31 09:43:17,586 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.35823128124078113, 'Total loss': 0.35823128124078113} | train loss {'Reaction outcome loss': 0.23411613431534845, 'Total loss': 0.23411613431534845}
2022-12-31 09:43:17,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:17,587 INFO:     Epoch: 66
2022-12-31 09:43:19,251 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.37099203169345857, 'Total loss': 0.37099203169345857} | train loss {'Reaction outcome loss': 0.2393752926566305, 'Total loss': 0.2393752926566305}
2022-12-31 09:43:19,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:19,251 INFO:     Epoch: 67
2022-12-31 09:43:20,913 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.36736680070559186, 'Total loss': 0.36736680070559186} | train loss {'Reaction outcome loss': 0.23264395398679225, 'Total loss': 0.23264395398679225}
2022-12-31 09:43:20,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:20,915 INFO:     Epoch: 68
2022-12-31 09:43:22,573 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3725072691837947, 'Total loss': 0.3725072691837947} | train loss {'Reaction outcome loss': 0.23320562886686003, 'Total loss': 0.23320562886686003}
2022-12-31 09:43:22,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:22,574 INFO:     Epoch: 69
2022-12-31 09:43:24,223 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.372102623184522, 'Total loss': 0.372102623184522} | train loss {'Reaction outcome loss': 0.23347568815832373, 'Total loss': 0.23347568815832373}
2022-12-31 09:43:24,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:24,223 INFO:     Epoch: 70
2022-12-31 09:43:25,870 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3811979865034421, 'Total loss': 0.3811979865034421} | train loss {'Reaction outcome loss': 0.23460218077865394, 'Total loss': 0.23460218077865394}
2022-12-31 09:43:25,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:25,871 INFO:     Epoch: 71
2022-12-31 09:43:27,525 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.32129813730716705, 'Total loss': 0.32129813730716705} | train loss {'Reaction outcome loss': 0.22934394709113307, 'Total loss': 0.22934394709113307}
2022-12-31 09:43:27,526 INFO:     Found new best model at epoch 71
2022-12-31 09:43:27,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:27,527 INFO:     Epoch: 72
2022-12-31 09:43:29,164 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.38604787389437356, 'Total loss': 0.38604787389437356} | train loss {'Reaction outcome loss': 0.23290889406998228, 'Total loss': 0.23290889406998228}
2022-12-31 09:43:29,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:29,164 INFO:     Epoch: 73
2022-12-31 09:43:30,815 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.34350968301296236, 'Total loss': 0.34350968301296236} | train loss {'Reaction outcome loss': 0.22448652737304894, 'Total loss': 0.22448652737304894}
2022-12-31 09:43:30,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:30,817 INFO:     Epoch: 74
2022-12-31 09:43:32,471 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3330870320399602, 'Total loss': 0.3330870320399602} | train loss {'Reaction outcome loss': 0.2290798658267153, 'Total loss': 0.2290798658267153}
2022-12-31 09:43:32,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:32,471 INFO:     Epoch: 75
2022-12-31 09:43:34,120 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3721680730581284, 'Total loss': 0.3721680730581284} | train loss {'Reaction outcome loss': 0.2225680494830556, 'Total loss': 0.2225680494830556}
2022-12-31 09:43:34,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:34,121 INFO:     Epoch: 76
2022-12-31 09:43:35,752 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41546923071146014, 'Total loss': 0.41546923071146014} | train loss {'Reaction outcome loss': 0.2212806426831623, 'Total loss': 0.2212806426831623}
2022-12-31 09:43:35,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:35,752 INFO:     Epoch: 77
2022-12-31 09:43:37,393 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.36259100437164304, 'Total loss': 0.36259100437164304} | train loss {'Reaction outcome loss': 0.2248456562209847, 'Total loss': 0.2248456562209847}
2022-12-31 09:43:37,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:37,394 INFO:     Epoch: 78
2022-12-31 09:43:39,025 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40159930984179176, 'Total loss': 0.40159930984179176} | train loss {'Reaction outcome loss': 0.22199915568378284, 'Total loss': 0.22199915568378284}
2022-12-31 09:43:39,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:39,026 INFO:     Epoch: 79
2022-12-31 09:43:40,660 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3763709505399068, 'Total loss': 0.3763709505399068} | train loss {'Reaction outcome loss': 0.2218979164196627, 'Total loss': 0.2218979164196627}
2022-12-31 09:43:40,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:40,661 INFO:     Epoch: 80
2022-12-31 09:43:42,303 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.39281666129827497, 'Total loss': 0.39281666129827497} | train loss {'Reaction outcome loss': 0.21883009852719132, 'Total loss': 0.21883009852719132}
2022-12-31 09:43:42,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:42,304 INFO:     Epoch: 81
2022-12-31 09:43:43,961 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3675166813035806, 'Total loss': 0.3675166813035806} | train loss {'Reaction outcome loss': 0.20942449632243518, 'Total loss': 0.20942449632243518}
2022-12-31 09:43:43,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:43,962 INFO:     Epoch: 82
2022-12-31 09:43:45,549 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.36203639904657997, 'Total loss': 0.36203639904657997} | train loss {'Reaction outcome loss': 0.2204055752006978, 'Total loss': 0.2204055752006978}
2022-12-31 09:43:45,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:45,550 INFO:     Epoch: 83
2022-12-31 09:43:47,127 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3879605750242869, 'Total loss': 0.3879605750242869} | train loss {'Reaction outcome loss': 0.21545201082489568, 'Total loss': 0.21545201082489568}
2022-12-31 09:43:47,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:47,127 INFO:     Epoch: 84
2022-12-31 09:43:48,716 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3784022609392802, 'Total loss': 0.3784022609392802} | train loss {'Reaction outcome loss': 0.20653786963314144, 'Total loss': 0.20653786963314144}
2022-12-31 09:43:48,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:48,718 INFO:     Epoch: 85
2022-12-31 09:43:50,306 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3592439413070679, 'Total loss': 0.3592439413070679} | train loss {'Reaction outcome loss': 0.2147934301858292, 'Total loss': 0.2147934301858292}
2022-12-31 09:43:50,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:50,306 INFO:     Epoch: 86
2022-12-31 09:43:51,895 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.354961738238732, 'Total loss': 0.354961738238732} | train loss {'Reaction outcome loss': 0.21779769222612363, 'Total loss': 0.21779769222612363}
2022-12-31 09:43:51,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:51,896 INFO:     Epoch: 87
2022-12-31 09:43:53,472 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3647918144861857, 'Total loss': 0.3647918144861857} | train loss {'Reaction outcome loss': 0.21259709933677512, 'Total loss': 0.21259709933677512}
2022-12-31 09:43:53,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:53,472 INFO:     Epoch: 88
2022-12-31 09:43:55,078 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.35170661807060244, 'Total loss': 0.35170661807060244} | train loss {'Reaction outcome loss': 0.2146128699672918, 'Total loss': 0.2146128699672918}
2022-12-31 09:43:55,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:55,080 INFO:     Epoch: 89
2022-12-31 09:43:56,676 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42207194268703463, 'Total loss': 0.42207194268703463} | train loss {'Reaction outcome loss': 0.2052127691529637, 'Total loss': 0.2052127691529637}
2022-12-31 09:43:56,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:56,676 INFO:     Epoch: 90
2022-12-31 09:43:58,274 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3876831884185473, 'Total loss': 0.3876831884185473} | train loss {'Reaction outcome loss': 0.20990606379715632, 'Total loss': 0.20990606379715632}
2022-12-31 09:43:58,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:58,274 INFO:     Epoch: 91
2022-12-31 09:43:59,875 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4003404438495636, 'Total loss': 0.4003404438495636} | train loss {'Reaction outcome loss': 0.20488169480686205, 'Total loss': 0.20488169480686205}
2022-12-31 09:43:59,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:43:59,875 INFO:     Epoch: 92
2022-12-31 09:44:01,474 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3769251545270284, 'Total loss': 0.3769251545270284} | train loss {'Reaction outcome loss': 0.20430700104330143, 'Total loss': 0.20430700104330143}
2022-12-31 09:44:01,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:01,475 INFO:     Epoch: 93
2022-12-31 09:44:03,053 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39240607420603435, 'Total loss': 0.39240607420603435} | train loss {'Reaction outcome loss': 0.19976653298702987, 'Total loss': 0.19976653298702987}
2022-12-31 09:44:03,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:03,053 INFO:     Epoch: 94
2022-12-31 09:44:04,628 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3615509341160456, 'Total loss': 0.3615509341160456} | train loss {'Reaction outcome loss': 0.20645469453620868, 'Total loss': 0.20645469453620868}
2022-12-31 09:44:04,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:04,628 INFO:     Epoch: 95
2022-12-31 09:44:06,244 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.357338825861613, 'Total loss': 0.357338825861613} | train loss {'Reaction outcome loss': 0.19956333909428467, 'Total loss': 0.19956333909428467}
2022-12-31 09:44:06,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:06,244 INFO:     Epoch: 96
2022-12-31 09:44:07,841 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.34779281814893087, 'Total loss': 0.34779281814893087} | train loss {'Reaction outcome loss': 0.19653882089675995, 'Total loss': 0.19653882089675995}
2022-12-31 09:44:07,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:07,842 INFO:     Epoch: 97
2022-12-31 09:44:09,438 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3974412024021149, 'Total loss': 0.3974412024021149} | train loss {'Reaction outcome loss': 0.20148410255184573, 'Total loss': 0.20148410255184573}
2022-12-31 09:44:09,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:09,439 INFO:     Epoch: 98
2022-12-31 09:44:11,036 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41899748543898263, 'Total loss': 0.41899748543898263} | train loss {'Reaction outcome loss': 0.19552842933127154, 'Total loss': 0.19552842933127154}
2022-12-31 09:44:11,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:11,037 INFO:     Epoch: 99
2022-12-31 09:44:12,617 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3642929494380951, 'Total loss': 0.3642929494380951} | train loss {'Reaction outcome loss': 0.20501562530841053, 'Total loss': 0.20501562530841053}
2022-12-31 09:44:12,617 INFO:     Best model found after epoch 72 of 100.
2022-12-31 09:44:12,617 INFO:   Done with stage: TRAINING
2022-12-31 09:44:12,617 INFO:   Starting stage: EVALUATION
2022-12-31 09:44:12,749 INFO:   Done with stage: EVALUATION
2022-12-31 09:44:12,749 INFO:   Leaving out SEQ value Fold_5
2022-12-31 09:44:12,762 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 09:44:12,762 INFO:   Starting stage: FEATURE SCALING
2022-12-31 09:44:13,407 INFO:   Done with stage: FEATURE SCALING
2022-12-31 09:44:13,407 INFO:   Starting stage: SCALING TARGETS
2022-12-31 09:44:13,477 INFO:   Done with stage: SCALING TARGETS
2022-12-31 09:44:13,477 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:44:13,477 INFO:     No hyperparam tuning for this model
2022-12-31 09:44:13,477 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:44:13,477 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 09:44:13,478 INFO:     None feature selector for col prot
2022-12-31 09:44:13,478 INFO:     None feature selector for col prot
2022-12-31 09:44:13,478 INFO:     None feature selector for col prot
2022-12-31 09:44:13,479 INFO:     None feature selector for col chem
2022-12-31 09:44:13,479 INFO:     None feature selector for col chem
2022-12-31 09:44:13,479 INFO:     None feature selector for col chem
2022-12-31 09:44:13,479 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 09:44:13,479 INFO:   Starting stage: BUILD MODEL
2022-12-31 09:44:13,481 INFO:     Number of params in model 223921
2022-12-31 09:44:13,484 INFO:   Done with stage: BUILD MODEL
2022-12-31 09:44:13,484 INFO:   Starting stage: TRAINING
2022-12-31 09:44:13,527 INFO:     Val loss before train {'Reaction outcome loss': 1.0338176965713501, 'Total loss': 1.0338176965713501}
2022-12-31 09:44:13,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:13,527 INFO:     Epoch: 0
2022-12-31 09:44:15,154 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6989496747652689, 'Total loss': 0.6989496747652689} | train loss {'Reaction outcome loss': 0.8097403769421837, 'Total loss': 0.8097403769421837}
2022-12-31 09:44:15,154 INFO:     Found new best model at epoch 0
2022-12-31 09:44:15,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:15,155 INFO:     Epoch: 1
2022-12-31 09:44:16,768 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5901688655217489, 'Total loss': 0.5901688655217489} | train loss {'Reaction outcome loss': 0.6031685047445522, 'Total loss': 0.6031685047445522}
2022-12-31 09:44:16,768 INFO:     Found new best model at epoch 1
2022-12-31 09:44:16,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:16,769 INFO:     Epoch: 2
2022-12-31 09:44:18,381 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5137750347455342, 'Total loss': 0.5137750347455342} | train loss {'Reaction outcome loss': 0.5313983024498684, 'Total loss': 0.5313983024498684}
2022-12-31 09:44:18,381 INFO:     Found new best model at epoch 2
2022-12-31 09:44:18,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:18,382 INFO:     Epoch: 3
2022-12-31 09:44:19,993 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.51827978293101, 'Total loss': 0.51827978293101} | train loss {'Reaction outcome loss': 0.5065599713420522, 'Total loss': 0.5065599713420522}
2022-12-31 09:44:19,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:19,994 INFO:     Epoch: 4
2022-12-31 09:44:21,591 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5377480983734131, 'Total loss': 0.5377480983734131} | train loss {'Reaction outcome loss': 0.4965084674970611, 'Total loss': 0.4965084674970611}
2022-12-31 09:44:21,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:21,591 INFO:     Epoch: 5
2022-12-31 09:44:23,190 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.528005701303482, 'Total loss': 0.528005701303482} | train loss {'Reaction outcome loss': 0.47683991329909803, 'Total loss': 0.47683991329909803}
2022-12-31 09:44:23,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:23,190 INFO:     Epoch: 6
2022-12-31 09:44:24,804 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.500194905201594, 'Total loss': 0.500194905201594} | train loss {'Reaction outcome loss': 0.4687224236627314, 'Total loss': 0.4687224236627314}
2022-12-31 09:44:24,805 INFO:     Found new best model at epoch 6
2022-12-31 09:44:24,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:24,806 INFO:     Epoch: 7
2022-12-31 09:44:26,417 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47187397082646687, 'Total loss': 0.47187397082646687} | train loss {'Reaction outcome loss': 0.45512030615076504, 'Total loss': 0.45512030615076504}
2022-12-31 09:44:26,417 INFO:     Found new best model at epoch 7
2022-12-31 09:44:26,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:26,418 INFO:     Epoch: 8
2022-12-31 09:44:28,084 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49087429642677305, 'Total loss': 0.49087429642677305} | train loss {'Reaction outcome loss': 0.44844020257933415, 'Total loss': 0.44844020257933415}
2022-12-31 09:44:28,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:28,084 INFO:     Epoch: 9
2022-12-31 09:44:29,698 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4476189533869425, 'Total loss': 0.4476189533869425} | train loss {'Reaction outcome loss': 0.44165904615985474, 'Total loss': 0.44165904615985474}
2022-12-31 09:44:29,698 INFO:     Found new best model at epoch 9
2022-12-31 09:44:29,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:29,699 INFO:     Epoch: 10
2022-12-31 09:44:31,312 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4615495204925537, 'Total loss': 0.4615495204925537} | train loss {'Reaction outcome loss': 0.43456030773349863, 'Total loss': 0.43456030773349863}
2022-12-31 09:44:31,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:31,314 INFO:     Epoch: 11
2022-12-31 09:44:32,946 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49041065375010173, 'Total loss': 0.49041065375010173} | train loss {'Reaction outcome loss': 0.4327869402865569, 'Total loss': 0.4327869402865569}
2022-12-31 09:44:32,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:32,946 INFO:     Epoch: 12
2022-12-31 09:44:34,577 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47218819657961525, 'Total loss': 0.47218819657961525} | train loss {'Reaction outcome loss': 0.47903000328527845, 'Total loss': 0.47903000328527845}
2022-12-31 09:44:34,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:34,577 INFO:     Epoch: 13
2022-12-31 09:44:36,192 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47448789278666176, 'Total loss': 0.47448789278666176} | train loss {'Reaction outcome loss': 0.4315431268390756, 'Total loss': 0.4315431268390756}
2022-12-31 09:44:36,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:36,192 INFO:     Epoch: 14
2022-12-31 09:44:37,807 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5051047146320343, 'Total loss': 0.5051047146320343} | train loss {'Reaction outcome loss': 0.418985128780638, 'Total loss': 0.418985128780638}
2022-12-31 09:44:37,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:37,808 INFO:     Epoch: 15
2022-12-31 09:44:39,419 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45585652987162273, 'Total loss': 0.45585652987162273} | train loss {'Reaction outcome loss': 0.4350621573402864, 'Total loss': 0.4350621573402864}
2022-12-31 09:44:39,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:39,420 INFO:     Epoch: 16
2022-12-31 09:44:41,014 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45087693333625795, 'Total loss': 0.45087693333625795} | train loss {'Reaction outcome loss': 0.4094154865596699, 'Total loss': 0.4094154865596699}
2022-12-31 09:44:41,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:41,015 INFO:     Epoch: 17
2022-12-31 09:44:42,645 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.47280619442462923, 'Total loss': 0.47280619442462923} | train loss {'Reaction outcome loss': 0.3989990410543438, 'Total loss': 0.3989990410543438}
2022-12-31 09:44:42,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:42,646 INFO:     Epoch: 18
2022-12-31 09:44:44,259 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4220596154530843, 'Total loss': 0.4220596154530843} | train loss {'Reaction outcome loss': 0.38918748411100934, 'Total loss': 0.38918748411100934}
2022-12-31 09:44:44,260 INFO:     Found new best model at epoch 18
2022-12-31 09:44:44,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:44,261 INFO:     Epoch: 19
2022-12-31 09:44:45,872 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46242664059003197, 'Total loss': 0.46242664059003197} | train loss {'Reaction outcome loss': 0.38299343158639426, 'Total loss': 0.38299343158639426}
2022-12-31 09:44:45,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:45,872 INFO:     Epoch: 20
2022-12-31 09:44:47,463 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5301915387312571, 'Total loss': 0.5301915387312571} | train loss {'Reaction outcome loss': 0.38553543326755363, 'Total loss': 0.38553543326755363}
2022-12-31 09:44:47,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:47,464 INFO:     Epoch: 21
2022-12-31 09:44:49,074 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4417101740837097, 'Total loss': 0.4417101740837097} | train loss {'Reaction outcome loss': 0.41012717242035474, 'Total loss': 0.41012717242035474}
2022-12-31 09:44:49,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:49,075 INFO:     Epoch: 22
2022-12-31 09:44:50,690 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.419366995493571, 'Total loss': 0.419366995493571} | train loss {'Reaction outcome loss': 0.3710876379054094, 'Total loss': 0.3710876379054094}
2022-12-31 09:44:50,691 INFO:     Found new best model at epoch 22
2022-12-31 09:44:50,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:50,691 INFO:     Epoch: 23
2022-12-31 09:44:52,298 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4247896571954091, 'Total loss': 0.4247896571954091} | train loss {'Reaction outcome loss': 0.36511690124461893, 'Total loss': 0.36511690124461893}
2022-12-31 09:44:52,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:52,299 INFO:     Epoch: 24
2022-12-31 09:44:53,913 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4474852333466212, 'Total loss': 0.4474852333466212} | train loss {'Reaction outcome loss': 0.36791182440314174, 'Total loss': 0.36791182440314174}
2022-12-31 09:44:53,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:53,914 INFO:     Epoch: 25
2022-12-31 09:44:55,523 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42789424856503805, 'Total loss': 0.42789424856503805} | train loss {'Reaction outcome loss': 0.35806171814708604, 'Total loss': 0.35806171814708604}
2022-12-31 09:44:55,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:55,525 INFO:     Epoch: 26
2022-12-31 09:44:57,123 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.426016887029012, 'Total loss': 0.426016887029012} | train loss {'Reaction outcome loss': 0.3802447784199686, 'Total loss': 0.3802447784199686}
2022-12-31 09:44:57,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:57,123 INFO:     Epoch: 27
2022-12-31 09:44:58,723 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.42237917085488635, 'Total loss': 0.42237917085488635} | train loss {'Reaction outcome loss': 0.35051984445232415, 'Total loss': 0.35051984445232415}
2022-12-31 09:44:58,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:44:58,723 INFO:     Epoch: 28
2022-12-31 09:45:00,327 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41759673158327737, 'Total loss': 0.41759673158327737} | train loss {'Reaction outcome loss': 0.3356041205676603, 'Total loss': 0.3356041205676603}
2022-12-31 09:45:00,327 INFO:     Found new best model at epoch 28
2022-12-31 09:45:00,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:00,328 INFO:     Epoch: 29
2022-12-31 09:45:01,940 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4149687230587006, 'Total loss': 0.4149687230587006} | train loss {'Reaction outcome loss': 0.32861123849516327, 'Total loss': 0.32861123849516327}
2022-12-31 09:45:01,942 INFO:     Found new best model at epoch 29
2022-12-31 09:45:01,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:01,943 INFO:     Epoch: 30
2022-12-31 09:45:03,554 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44322858850161234, 'Total loss': 0.44322858850161234} | train loss {'Reaction outcome loss': 0.3315715520116298, 'Total loss': 0.3315715520116298}
2022-12-31 09:45:03,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:03,555 INFO:     Epoch: 31
2022-12-31 09:45:05,168 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45987648665905, 'Total loss': 0.45987648665905} | train loss {'Reaction outcome loss': 0.3339297936662384, 'Total loss': 0.3339297936662384}
2022-12-31 09:45:05,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:05,168 INFO:     Epoch: 32
2022-12-31 09:45:06,781 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41922085781892143, 'Total loss': 0.41922085781892143} | train loss {'Reaction outcome loss': 0.32220484923648957, 'Total loss': 0.32220484923648957}
2022-12-31 09:45:06,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:06,782 INFO:     Epoch: 33
2022-12-31 09:45:08,388 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4188639144102732, 'Total loss': 0.4188639144102732} | train loss {'Reaction outcome loss': 0.30906335797018086, 'Total loss': 0.30906335797018086}
2022-12-31 09:45:08,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:08,388 INFO:     Epoch: 34
2022-12-31 09:45:10,054 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4510699341694514, 'Total loss': 0.4510699341694514} | train loss {'Reaction outcome loss': 0.3106856123186594, 'Total loss': 0.3106856123186594}
2022-12-31 09:45:10,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:10,055 INFO:     Epoch: 35
2022-12-31 09:45:11,682 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41472549438476564, 'Total loss': 0.41472549438476564} | train loss {'Reaction outcome loss': 0.30899895808956435, 'Total loss': 0.30899895808956435}
2022-12-31 09:45:11,682 INFO:     Found new best model at epoch 35
2022-12-31 09:45:11,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:11,683 INFO:     Epoch: 36
2022-12-31 09:45:13,295 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41861352970202764, 'Total loss': 0.41861352970202764} | train loss {'Reaction outcome loss': 0.32030320031217474, 'Total loss': 0.32030320031217474}
2022-12-31 09:45:13,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:13,297 INFO:     Epoch: 37
2022-12-31 09:45:14,879 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.38636216322580974, 'Total loss': 0.38636216322580974} | train loss {'Reaction outcome loss': 0.3274555657461979, 'Total loss': 0.3274555657461979}
2022-12-31 09:45:14,879 INFO:     Found new best model at epoch 37
2022-12-31 09:45:14,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:14,880 INFO:     Epoch: 38
2022-12-31 09:45:16,535 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.37717622915903726, 'Total loss': 0.37717622915903726} | train loss {'Reaction outcome loss': 0.30494503521386185, 'Total loss': 0.30494503521386185}
2022-12-31 09:45:16,535 INFO:     Found new best model at epoch 38
2022-12-31 09:45:16,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:16,536 INFO:     Epoch: 39
2022-12-31 09:45:18,154 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4052947789430618, 'Total loss': 0.4052947789430618} | train loss {'Reaction outcome loss': 0.299795838923234, 'Total loss': 0.299795838923234}
2022-12-31 09:45:18,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:18,154 INFO:     Epoch: 40
2022-12-31 09:45:19,768 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4374457269906998, 'Total loss': 0.4374457269906998} | train loss {'Reaction outcome loss': 0.29332616794314503, 'Total loss': 0.29332616794314503}
2022-12-31 09:45:19,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:19,769 INFO:     Epoch: 41
2022-12-31 09:45:21,382 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4641212632258733, 'Total loss': 0.4641212632258733} | train loss {'Reaction outcome loss': 0.2967842197774545, 'Total loss': 0.2967842197774545}
2022-12-31 09:45:21,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:21,383 INFO:     Epoch: 42
2022-12-31 09:45:22,995 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4091806809107463, 'Total loss': 0.4091806809107463} | train loss {'Reaction outcome loss': 0.3141651238783843, 'Total loss': 0.3141651238783843}
2022-12-31 09:45:22,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:22,995 INFO:     Epoch: 43
2022-12-31 09:45:24,610 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4083651085694631, 'Total loss': 0.4083651085694631} | train loss {'Reaction outcome loss': 0.28616708913898986, 'Total loss': 0.28616708913898986}
2022-12-31 09:45:24,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:24,611 INFO:     Epoch: 44
2022-12-31 09:45:26,180 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4218150734901428, 'Total loss': 0.4218150734901428} | train loss {'Reaction outcome loss': 0.2826362287328727, 'Total loss': 0.2826362287328727}
2022-12-31 09:45:26,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:26,181 INFO:     Epoch: 45
2022-12-31 09:45:27,848 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3806830495595932, 'Total loss': 0.3806830495595932} | train loss {'Reaction outcome loss': 0.2757640772012393, 'Total loss': 0.2757640772012393}
2022-12-31 09:45:27,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:27,849 INFO:     Epoch: 46
2022-12-31 09:45:29,513 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4098095913728078, 'Total loss': 0.4098095913728078} | train loss {'Reaction outcome loss': 0.2671854552084013, 'Total loss': 0.2671854552084013}
2022-12-31 09:45:29,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:29,514 INFO:     Epoch: 47
2022-12-31 09:45:31,135 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4313420365254084, 'Total loss': 0.4313420365254084} | train loss {'Reaction outcome loss': 0.26373765427876567, 'Total loss': 0.26373765427876567}
2022-12-31 09:45:31,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:31,137 INFO:     Epoch: 48
2022-12-31 09:45:32,728 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38901045521100364, 'Total loss': 0.38901045521100364} | train loss {'Reaction outcome loss': 0.2606581367849224, 'Total loss': 0.2606581367849224}
2022-12-31 09:45:32,728 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:32,728 INFO:     Epoch: 49
2022-12-31 09:45:34,340 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4479890743891398, 'Total loss': 0.4479890743891398} | train loss {'Reaction outcome loss': 0.2755359463613865, 'Total loss': 0.2755359463613865}
2022-12-31 09:45:34,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:34,340 INFO:     Epoch: 50
2022-12-31 09:45:35,932 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.415048615137736, 'Total loss': 0.415048615137736} | train loss {'Reaction outcome loss': 0.27365985496536543, 'Total loss': 0.27365985496536543}
2022-12-31 09:45:35,932 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:35,932 INFO:     Epoch: 51
2022-12-31 09:45:37,545 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.44988649984200796, 'Total loss': 0.44988649984200796} | train loss {'Reaction outcome loss': 0.29476341725313576, 'Total loss': 0.29476341725313576}
2022-12-31 09:45:37,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:37,545 INFO:     Epoch: 52
2022-12-31 09:45:39,155 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43478825489679973, 'Total loss': 0.43478825489679973} | train loss {'Reaction outcome loss': 0.2836644086392893, 'Total loss': 0.2836644086392893}
2022-12-31 09:45:39,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:39,156 INFO:     Epoch: 53
2022-12-31 09:45:40,755 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40121282438437145, 'Total loss': 0.40121282438437145} | train loss {'Reaction outcome loss': 0.34241884339438833, 'Total loss': 0.34241884339438833}
2022-12-31 09:45:40,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:40,755 INFO:     Epoch: 54
2022-12-31 09:45:42,349 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3996675819158554, 'Total loss': 0.3996675819158554} | train loss {'Reaction outcome loss': 0.29146135282581265, 'Total loss': 0.29146135282581265}
2022-12-31 09:45:42,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:42,349 INFO:     Epoch: 55
2022-12-31 09:45:43,952 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3840362747510274, 'Total loss': 0.3840362747510274} | train loss {'Reaction outcome loss': 0.28592998191523145, 'Total loss': 0.28592998191523145}
2022-12-31 09:45:43,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:43,953 INFO:     Epoch: 56
2022-12-31 09:45:45,545 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.37925945520401, 'Total loss': 0.37925945520401} | train loss {'Reaction outcome loss': 0.26042362731591245, 'Total loss': 0.26042362731591245}
2022-12-31 09:45:45,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:45,545 INFO:     Epoch: 57
2022-12-31 09:45:47,152 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41563659807046255, 'Total loss': 0.41563659807046255} | train loss {'Reaction outcome loss': 0.24888412194137555, 'Total loss': 0.24888412194137555}
2022-12-31 09:45:47,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:47,153 INFO:     Epoch: 58
2022-12-31 09:45:48,759 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4057613785068194, 'Total loss': 0.4057613785068194} | train loss {'Reaction outcome loss': 0.25425151805730833, 'Total loss': 0.25425151805730833}
2022-12-31 09:45:48,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:48,760 INFO:     Epoch: 59
2022-12-31 09:45:50,364 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42717858056227365, 'Total loss': 0.42717858056227365} | train loss {'Reaction outcome loss': 0.2649094176586663, 'Total loss': 0.2649094176586663}
2022-12-31 09:45:50,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:50,365 INFO:     Epoch: 60
2022-12-31 09:45:51,956 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4155118644237518, 'Total loss': 0.4155118644237518} | train loss {'Reaction outcome loss': 0.24701294378494335, 'Total loss': 0.24701294378494335}
2022-12-31 09:45:51,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:51,957 INFO:     Epoch: 61
2022-12-31 09:45:53,549 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3695326338211695, 'Total loss': 0.3695326338211695} | train loss {'Reaction outcome loss': 0.2468838299320086, 'Total loss': 0.2468838299320086}
2022-12-31 09:45:53,549 INFO:     Found new best model at epoch 61
2022-12-31 09:45:53,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:53,550 INFO:     Epoch: 62
2022-12-31 09:45:55,156 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3983402361472448, 'Total loss': 0.3983402361472448} | train loss {'Reaction outcome loss': 0.24224023727794597, 'Total loss': 0.24224023727794597}
2022-12-31 09:45:55,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:55,157 INFO:     Epoch: 63
2022-12-31 09:45:56,765 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40617114504178364, 'Total loss': 0.40617114504178364} | train loss {'Reaction outcome loss': 0.24147277099647277, 'Total loss': 0.24147277099647277}
2022-12-31 09:45:56,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:56,766 INFO:     Epoch: 64
2022-12-31 09:45:58,371 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4207091212272644, 'Total loss': 0.4207091212272644} | train loss {'Reaction outcome loss': 0.24279645172140116, 'Total loss': 0.24279645172140116}
2022-12-31 09:45:58,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:58,371 INFO:     Epoch: 65
2022-12-31 09:45:59,968 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3877063155174255, 'Total loss': 0.3877063155174255} | train loss {'Reaction outcome loss': 0.2453273589371879, 'Total loss': 0.2453273589371879}
2022-12-31 09:45:59,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:45:59,968 INFO:     Epoch: 66
2022-12-31 09:46:01,577 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.429303510983785, 'Total loss': 0.429303510983785} | train loss {'Reaction outcome loss': 0.2464390544058836, 'Total loss': 0.2464390544058836}
2022-12-31 09:46:01,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:01,578 INFO:     Epoch: 67
2022-12-31 09:46:03,169 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4434933771689733, 'Total loss': 0.4434933771689733} | train loss {'Reaction outcome loss': 0.24406953029456022, 'Total loss': 0.24406953029456022}
2022-12-31 09:46:03,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:03,169 INFO:     Epoch: 68
2022-12-31 09:46:04,775 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42498000065485636, 'Total loss': 0.42498000065485636} | train loss {'Reaction outcome loss': 0.2405556789143821, 'Total loss': 0.2405556789143821}
2022-12-31 09:46:04,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:04,776 INFO:     Epoch: 69
2022-12-31 09:46:06,382 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40458271851142247, 'Total loss': 0.40458271851142247} | train loss {'Reaction outcome loss': 0.22847820044135797, 'Total loss': 0.22847820044135797}
2022-12-31 09:46:06,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:06,382 INFO:     Epoch: 70
2022-12-31 09:46:07,988 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4128862261772156, 'Total loss': 0.4128862261772156} | train loss {'Reaction outcome loss': 0.22983490685473426, 'Total loss': 0.22983490685473426}
2022-12-31 09:46:07,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:07,989 INFO:     Epoch: 71
2022-12-31 09:46:09,581 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3916661232709885, 'Total loss': 0.3916661232709885} | train loss {'Reaction outcome loss': 0.22708502454473922, 'Total loss': 0.22708502454473922}
2022-12-31 09:46:09,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:09,581 INFO:     Epoch: 72
2022-12-31 09:46:11,169 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45207127432028454, 'Total loss': 0.45207127432028454} | train loss {'Reaction outcome loss': 0.22745730720149973, 'Total loss': 0.22745730720149973}
2022-12-31 09:46:11,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:11,169 INFO:     Epoch: 73
2022-12-31 09:46:12,808 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43037989338239035, 'Total loss': 0.43037989338239035} | train loss {'Reaction outcome loss': 0.22525703163979494, 'Total loss': 0.22525703163979494}
2022-12-31 09:46:12,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:12,808 INFO:     Epoch: 74
2022-12-31 09:46:14,428 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39755936662356056, 'Total loss': 0.39755936662356056} | train loss {'Reaction outcome loss': 0.23453413416375068, 'Total loss': 0.23453413416375068}
2022-12-31 09:46:14,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:14,429 INFO:     Epoch: 75
2022-12-31 09:46:16,029 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4000624030828476, 'Total loss': 0.4000624030828476} | train loss {'Reaction outcome loss': 0.22205807267818128, 'Total loss': 0.22205807267818128}
2022-12-31 09:46:16,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:16,029 INFO:     Epoch: 76
2022-12-31 09:46:17,618 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43305241167545316, 'Total loss': 0.43305241167545316} | train loss {'Reaction outcome loss': 0.2266661563746469, 'Total loss': 0.2266661563746469}
2022-12-31 09:46:17,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:17,618 INFO:     Epoch: 77
2022-12-31 09:46:19,257 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39706673864275216, 'Total loss': 0.39706673864275216} | train loss {'Reaction outcome loss': 0.31097959378899576, 'Total loss': 0.31097959378899576}
2022-12-31 09:46:19,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:19,258 INFO:     Epoch: 78
2022-12-31 09:46:20,883 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4157010644674301, 'Total loss': 0.4157010644674301} | train loss {'Reaction outcome loss': 0.22770703578556795, 'Total loss': 0.22770703578556795}
2022-12-31 09:46:20,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:20,883 INFO:     Epoch: 79
2022-12-31 09:46:22,549 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4367751494050026, 'Total loss': 0.4367751494050026} | train loss {'Reaction outcome loss': 0.2267626792671618, 'Total loss': 0.2267626792671618}
2022-12-31 09:46:22,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:22,549 INFO:     Epoch: 80
2022-12-31 09:46:24,163 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4156118184328079, 'Total loss': 0.4156118184328079} | train loss {'Reaction outcome loss': 0.21384687024832258, 'Total loss': 0.21384687024832258}
2022-12-31 09:46:24,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:24,163 INFO:     Epoch: 81
2022-12-31 09:46:25,776 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41984669665495555, 'Total loss': 0.41984669665495555} | train loss {'Reaction outcome loss': 0.21387226389344796, 'Total loss': 0.21387226389344796}
2022-12-31 09:46:25,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:25,777 INFO:     Epoch: 82
2022-12-31 09:46:27,380 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4150421291589737, 'Total loss': 0.4150421291589737} | train loss {'Reaction outcome loss': 0.21969468738582995, 'Total loss': 0.21969468738582995}
2022-12-31 09:46:27,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:27,380 INFO:     Epoch: 83
2022-12-31 09:46:29,029 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4710008531808853, 'Total loss': 0.4710008531808853} | train loss {'Reaction outcome loss': 0.22126975005433094, 'Total loss': 0.22126975005433094}
2022-12-31 09:46:29,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:29,029 INFO:     Epoch: 84
2022-12-31 09:46:30,657 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.411243603626887, 'Total loss': 0.411243603626887} | train loss {'Reaction outcome loss': 0.21271513252007856, 'Total loss': 0.21271513252007856}
2022-12-31 09:46:30,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:30,658 INFO:     Epoch: 85
2022-12-31 09:46:32,262 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4615882416566213, 'Total loss': 0.4615882416566213} | train loss {'Reaction outcome loss': 0.2132592962038673, 'Total loss': 0.2132592962038673}
2022-12-31 09:46:32,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:32,263 INFO:     Epoch: 86
2022-12-31 09:46:33,870 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.37661415338516235, 'Total loss': 0.37661415338516235} | train loss {'Reaction outcome loss': 0.21153292337945406, 'Total loss': 0.21153292337945406}
2022-12-31 09:46:33,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:33,871 INFO:     Epoch: 87
2022-12-31 09:46:35,473 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43165944516658783, 'Total loss': 0.43165944516658783} | train loss {'Reaction outcome loss': 0.21161893225170375, 'Total loss': 0.21161893225170375}
2022-12-31 09:46:35,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:35,473 INFO:     Epoch: 88
2022-12-31 09:46:37,063 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4049228310585022, 'Total loss': 0.4049228310585022} | train loss {'Reaction outcome loss': 0.2194424091797808, 'Total loss': 0.2194424091797808}
2022-12-31 09:46:37,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:37,063 INFO:     Epoch: 89
2022-12-31 09:46:38,658 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4232948978741964, 'Total loss': 0.4232948978741964} | train loss {'Reaction outcome loss': 0.2099688730162123, 'Total loss': 0.2099688730162123}
2022-12-31 09:46:38,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:38,658 INFO:     Epoch: 90
2022-12-31 09:46:40,279 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4134016096591949, 'Total loss': 0.4134016096591949} | train loss {'Reaction outcome loss': 0.20737924784982065, 'Total loss': 0.20737924784982065}
2022-12-31 09:46:40,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:40,281 INFO:     Epoch: 91
2022-12-31 09:46:41,890 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.40565967162450156, 'Total loss': 0.40565967162450156} | train loss {'Reaction outcome loss': 0.20885682632755218, 'Total loss': 0.20885682632755218}
2022-12-31 09:46:41,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:41,890 INFO:     Epoch: 92
2022-12-31 09:46:43,502 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4619140108426412, 'Total loss': 0.4619140108426412} | train loss {'Reaction outcome loss': 0.2088069376414237, 'Total loss': 0.2088069376414237}
2022-12-31 09:46:43,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:43,502 INFO:     Epoch: 93
2022-12-31 09:46:45,100 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42343689799308776, 'Total loss': 0.42343689799308776} | train loss {'Reaction outcome loss': 0.20778966852509073, 'Total loss': 0.20778966852509073}
2022-12-31 09:46:45,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:45,101 INFO:     Epoch: 94
2022-12-31 09:46:46,709 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3824704478184382, 'Total loss': 0.3824704478184382} | train loss {'Reaction outcome loss': 0.20797481252120106, 'Total loss': 0.20797481252120106}
2022-12-31 09:46:46,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:46,709 INFO:     Epoch: 95
2022-12-31 09:46:48,296 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43372401396433513, 'Total loss': 0.43372401396433513} | train loss {'Reaction outcome loss': 0.21173210066183895, 'Total loss': 0.21173210066183895}
2022-12-31 09:46:48,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:48,296 INFO:     Epoch: 96
2022-12-31 09:46:49,906 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39276480277379355, 'Total loss': 0.39276480277379355} | train loss {'Reaction outcome loss': 0.20264316839925217, 'Total loss': 0.20264316839925217}
2022-12-31 09:46:49,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:49,906 INFO:     Epoch: 97
2022-12-31 09:46:51,517 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41909357011318205, 'Total loss': 0.41909357011318205} | train loss {'Reaction outcome loss': 0.19871430946995278, 'Total loss': 0.19871430946995278}
2022-12-31 09:46:51,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:51,518 INFO:     Epoch: 98
2022-12-31 09:46:53,126 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4442357728878657, 'Total loss': 0.4442357728878657} | train loss {'Reaction outcome loss': 0.20453151507957745, 'Total loss': 0.20453151507957745}
2022-12-31 09:46:53,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:53,127 INFO:     Epoch: 99
2022-12-31 09:46:54,727 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4002920371790727, 'Total loss': 0.4002920371790727} | train loss {'Reaction outcome loss': 0.20003334359616798, 'Total loss': 0.20003334359616798}
2022-12-31 09:46:54,727 INFO:     Best model found after epoch 62 of 100.
2022-12-31 09:46:54,727 INFO:   Done with stage: TRAINING
2022-12-31 09:46:54,727 INFO:   Starting stage: EVALUATION
2022-12-31 09:46:54,854 INFO:   Done with stage: EVALUATION
2022-12-31 09:46:54,854 INFO:   Leaving out SEQ value Fold_6
2022-12-31 09:46:54,867 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 09:46:54,867 INFO:   Starting stage: FEATURE SCALING
2022-12-31 09:46:55,512 INFO:   Done with stage: FEATURE SCALING
2022-12-31 09:46:55,513 INFO:   Starting stage: SCALING TARGETS
2022-12-31 09:46:55,583 INFO:   Done with stage: SCALING TARGETS
2022-12-31 09:46:55,583 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:46:55,583 INFO:     No hyperparam tuning for this model
2022-12-31 09:46:55,583 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:46:55,583 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 09:46:55,584 INFO:     None feature selector for col prot
2022-12-31 09:46:55,584 INFO:     None feature selector for col prot
2022-12-31 09:46:55,584 INFO:     None feature selector for col prot
2022-12-31 09:46:55,585 INFO:     None feature selector for col chem
2022-12-31 09:46:55,585 INFO:     None feature selector for col chem
2022-12-31 09:46:55,585 INFO:     None feature selector for col chem
2022-12-31 09:46:55,585 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 09:46:55,585 INFO:   Starting stage: BUILD MODEL
2022-12-31 09:46:55,587 INFO:     Number of params in model 223921
2022-12-31 09:46:55,590 INFO:   Done with stage: BUILD MODEL
2022-12-31 09:46:55,590 INFO:   Starting stage: TRAINING
2022-12-31 09:46:55,636 INFO:     Val loss before train {'Reaction outcome loss': 1.0430015484491983, 'Total loss': 1.0430015484491983}
2022-12-31 09:46:55,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:55,636 INFO:     Epoch: 0
2022-12-31 09:46:57,236 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6853794654210409, 'Total loss': 0.6853794654210409} | train loss {'Reaction outcome loss': 0.8330330604465429, 'Total loss': 0.8330330604465429}
2022-12-31 09:46:57,236 INFO:     Found new best model at epoch 0
2022-12-31 09:46:57,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:57,237 INFO:     Epoch: 1
2022-12-31 09:46:58,851 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5225454340378444, 'Total loss': 0.5225454340378444} | train loss {'Reaction outcome loss': 0.6098232661451244, 'Total loss': 0.6098232661451244}
2022-12-31 09:46:58,851 INFO:     Found new best model at epoch 1
2022-12-31 09:46:58,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:46:58,852 INFO:     Epoch: 2
2022-12-31 09:47:00,464 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.513782282670339, 'Total loss': 0.513782282670339} | train loss {'Reaction outcome loss': 0.529262584092815, 'Total loss': 0.529262584092815}
2022-12-31 09:47:00,465 INFO:     Found new best model at epoch 2
2022-12-31 09:47:00,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:00,466 INFO:     Epoch: 3
2022-12-31 09:47:02,090 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4894030531247457, 'Total loss': 0.4894030531247457} | train loss {'Reaction outcome loss': 0.5035096771127481, 'Total loss': 0.5035096771127481}
2022-12-31 09:47:02,091 INFO:     Found new best model at epoch 3
2022-12-31 09:47:02,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:02,092 INFO:     Epoch: 4
2022-12-31 09:47:03,693 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5044666449228923, 'Total loss': 0.5044666449228923} | train loss {'Reaction outcome loss': 0.4922304200243864, 'Total loss': 0.4922304200243864}
2022-12-31 09:47:03,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:03,693 INFO:     Epoch: 5
2022-12-31 09:47:05,280 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4730943510929743, 'Total loss': 0.4730943510929743} | train loss {'Reaction outcome loss': 0.47315089124849985, 'Total loss': 0.47315089124849985}
2022-12-31 09:47:05,281 INFO:     Found new best model at epoch 5
2022-12-31 09:47:05,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:05,282 INFO:     Epoch: 6
2022-12-31 09:47:06,899 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.485099724928538, 'Total loss': 0.485099724928538} | train loss {'Reaction outcome loss': 0.4755341014169183, 'Total loss': 0.4755341014169183}
2022-12-31 09:47:06,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:06,899 INFO:     Epoch: 7
2022-12-31 09:47:08,524 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46490846276283265, 'Total loss': 0.46490846276283265} | train loss {'Reaction outcome loss': 0.4596970029148384, 'Total loss': 0.4596970029148384}
2022-12-31 09:47:08,525 INFO:     Found new best model at epoch 7
2022-12-31 09:47:08,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:08,526 INFO:     Epoch: 8
2022-12-31 09:47:10,160 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47611718078454335, 'Total loss': 0.47611718078454335} | train loss {'Reaction outcome loss': 0.4594983651104387, 'Total loss': 0.4594983651104387}
2022-12-31 09:47:10,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:10,160 INFO:     Epoch: 9
2022-12-31 09:47:11,769 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4577596465746562, 'Total loss': 0.4577596465746562} | train loss {'Reaction outcome loss': 0.44890282859871106, 'Total loss': 0.44890282859871106}
2022-12-31 09:47:11,769 INFO:     Found new best model at epoch 9
2022-12-31 09:47:11,770 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:11,770 INFO:     Epoch: 10
2022-12-31 09:47:13,388 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4599770416816076, 'Total loss': 0.4599770416816076} | train loss {'Reaction outcome loss': 0.4415523003692661, 'Total loss': 0.4415523003692661}
2022-12-31 09:47:13,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:13,389 INFO:     Epoch: 11
2022-12-31 09:47:14,992 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5088990241289139, 'Total loss': 0.5088990241289139} | train loss {'Reaction outcome loss': 0.4374398735456088, 'Total loss': 0.4374398735456088}
2022-12-31 09:47:14,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:14,993 INFO:     Epoch: 12
2022-12-31 09:47:16,607 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4825001895427704, 'Total loss': 0.4825001895427704} | train loss {'Reaction outcome loss': 0.4286116146438819, 'Total loss': 0.4286116146438819}
2022-12-31 09:47:16,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:16,607 INFO:     Epoch: 13
2022-12-31 09:47:18,232 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4584347407023112, 'Total loss': 0.4584347407023112} | train loss {'Reaction outcome loss': 0.41942285681782215, 'Total loss': 0.41942285681782215}
2022-12-31 09:47:18,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:18,233 INFO:     Epoch: 14
2022-12-31 09:47:19,848 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44145714739958447, 'Total loss': 0.44145714739958447} | train loss {'Reaction outcome loss': 0.4151780090499871, 'Total loss': 0.4151780090499871}
2022-12-31 09:47:19,850 INFO:     Found new best model at epoch 14
2022-12-31 09:47:19,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:19,851 INFO:     Epoch: 15
2022-12-31 09:47:21,455 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4508442868789037, 'Total loss': 0.4508442868789037} | train loss {'Reaction outcome loss': 0.4078746887751004, 'Total loss': 0.4078746887751004}
2022-12-31 09:47:21,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:21,455 INFO:     Epoch: 16
2022-12-31 09:47:23,089 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4242667178312937, 'Total loss': 0.4242667178312937} | train loss {'Reaction outcome loss': 0.4083359653822782, 'Total loss': 0.4083359653822782}
2022-12-31 09:47:23,089 INFO:     Found new best model at epoch 16
2022-12-31 09:47:23,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:23,090 INFO:     Epoch: 17
2022-12-31 09:47:24,687 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4136113206545512, 'Total loss': 0.4136113206545512} | train loss {'Reaction outcome loss': 0.39724355921256843, 'Total loss': 0.39724355921256843}
2022-12-31 09:47:24,687 INFO:     Found new best model at epoch 17
2022-12-31 09:47:24,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:24,688 INFO:     Epoch: 18
2022-12-31 09:47:26,295 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4230420599381129, 'Total loss': 0.4230420599381129} | train loss {'Reaction outcome loss': 0.3917740200669757, 'Total loss': 0.3917740200669757}
2022-12-31 09:47:26,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:26,295 INFO:     Epoch: 19
2022-12-31 09:47:27,905 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41950185000896456, 'Total loss': 0.41950185000896456} | train loss {'Reaction outcome loss': 0.3881914536552739, 'Total loss': 0.3881914536552739}
2022-12-31 09:47:27,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:27,905 INFO:     Epoch: 20
2022-12-31 09:47:29,509 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4084397455056508, 'Total loss': 0.4084397455056508} | train loss {'Reaction outcome loss': 0.38058695985199315, 'Total loss': 0.38058695985199315}
2022-12-31 09:47:29,509 INFO:     Found new best model at epoch 20
2022-12-31 09:47:29,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:29,510 INFO:     Epoch: 21
2022-12-31 09:47:31,117 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.41054942707220715, 'Total loss': 0.41054942707220715} | train loss {'Reaction outcome loss': 0.37818714099455397, 'Total loss': 0.37818714099455397}
2022-12-31 09:47:31,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:31,117 INFO:     Epoch: 22
2022-12-31 09:47:32,719 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3988213618596395, 'Total loss': 0.3988213618596395} | train loss {'Reaction outcome loss': 0.3656931802334553, 'Total loss': 0.3656931802334553}
2022-12-31 09:47:32,721 INFO:     Found new best model at epoch 22
2022-12-31 09:47:32,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:32,721 INFO:     Epoch: 23
2022-12-31 09:47:34,361 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.38807637691497804, 'Total loss': 0.38807637691497804} | train loss {'Reaction outcome loss': 0.36898600794240455, 'Total loss': 0.36898600794240455}
2022-12-31 09:47:34,361 INFO:     Found new best model at epoch 23
2022-12-31 09:47:34,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:34,362 INFO:     Epoch: 24
2022-12-31 09:47:36,003 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4049619962771734, 'Total loss': 0.4049619962771734} | train loss {'Reaction outcome loss': 0.3588447137618108, 'Total loss': 0.3588447137618108}
2022-12-31 09:47:36,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:36,004 INFO:     Epoch: 25
2022-12-31 09:47:37,625 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39791672229766845, 'Total loss': 0.39791672229766845} | train loss {'Reaction outcome loss': 0.355530768579094, 'Total loss': 0.355530768579094}
2022-12-31 09:47:37,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:37,626 INFO:     Epoch: 26
2022-12-31 09:47:39,235 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41728712419668834, 'Total loss': 0.41728712419668834} | train loss {'Reaction outcome loss': 0.3556123273682508, 'Total loss': 0.3556123273682508}
2022-12-31 09:47:39,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:39,236 INFO:     Epoch: 27
2022-12-31 09:47:40,856 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.38490869800249733, 'Total loss': 0.38490869800249733} | train loss {'Reaction outcome loss': 0.3465892063043608, 'Total loss': 0.3465892063043608}
2022-12-31 09:47:40,856 INFO:     Found new best model at epoch 27
2022-12-31 09:47:40,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:40,857 INFO:     Epoch: 28
2022-12-31 09:47:42,452 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3981558163960775, 'Total loss': 0.3981558163960775} | train loss {'Reaction outcome loss': 0.3428654736613969, 'Total loss': 0.3428654736613969}
2022-12-31 09:47:42,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:42,452 INFO:     Epoch: 29
2022-12-31 09:47:44,072 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3932258188724518, 'Total loss': 0.3932258188724518} | train loss {'Reaction outcome loss': 0.33497913242300925, 'Total loss': 0.33497913242300925}
2022-12-31 09:47:44,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:44,072 INFO:     Epoch: 30
2022-12-31 09:47:45,692 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39607540840903915, 'Total loss': 0.39607540840903915} | train loss {'Reaction outcome loss': 0.3253531356204288, 'Total loss': 0.3253531356204288}
2022-12-31 09:47:45,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:45,693 INFO:     Epoch: 31
2022-12-31 09:47:47,314 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3767105852564176, 'Total loss': 0.3767105852564176} | train loss {'Reaction outcome loss': 0.32852763128517337, 'Total loss': 0.32852763128517337}
2022-12-31 09:47:47,315 INFO:     Found new best model at epoch 31
2022-12-31 09:47:47,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:47,315 INFO:     Epoch: 32
2022-12-31 09:47:48,942 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3760437419017156, 'Total loss': 0.3760437419017156} | train loss {'Reaction outcome loss': 0.3262941980404974, 'Total loss': 0.3262941980404974}
2022-12-31 09:47:48,942 INFO:     Found new best model at epoch 32
2022-12-31 09:47:48,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:48,943 INFO:     Epoch: 33
2022-12-31 09:47:50,567 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.37208457191785177, 'Total loss': 0.37208457191785177} | train loss {'Reaction outcome loss': 0.3144409870090037, 'Total loss': 0.3144409870090037}
2022-12-31 09:47:50,568 INFO:     Found new best model at epoch 33
2022-12-31 09:47:50,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:50,569 INFO:     Epoch: 34
2022-12-31 09:47:52,234 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3579089274009069, 'Total loss': 0.3579089274009069} | train loss {'Reaction outcome loss': 0.31811322387482716, 'Total loss': 0.31811322387482716}
2022-12-31 09:47:52,234 INFO:     Found new best model at epoch 34
2022-12-31 09:47:52,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:52,235 INFO:     Epoch: 35
2022-12-31 09:47:53,849 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.38239662945270536, 'Total loss': 0.38239662945270536} | train loss {'Reaction outcome loss': 0.30629395920823627, 'Total loss': 0.30629395920823627}
2022-12-31 09:47:53,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:53,849 INFO:     Epoch: 36
2022-12-31 09:47:55,468 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3455959709982077, 'Total loss': 0.3455959709982077} | train loss {'Reaction outcome loss': 0.3113088477335682, 'Total loss': 0.3113088477335682}
2022-12-31 09:47:55,468 INFO:     Found new best model at epoch 36
2022-12-31 09:47:55,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:55,469 INFO:     Epoch: 37
2022-12-31 09:47:57,065 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3748161127169927, 'Total loss': 0.3748161127169927} | train loss {'Reaction outcome loss': 0.3032753784814681, 'Total loss': 0.3032753784814681}
2022-12-31 09:47:57,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:57,066 INFO:     Epoch: 38
2022-12-31 09:47:58,678 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3742160608371099, 'Total loss': 0.3742160608371099} | train loss {'Reaction outcome loss': 0.3040213215464074, 'Total loss': 0.3040213215464074}
2022-12-31 09:47:58,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:47:58,678 INFO:     Epoch: 39
2022-12-31 09:48:00,282 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.36724719405174255, 'Total loss': 0.36724719405174255} | train loss {'Reaction outcome loss': 0.2982823210583482, 'Total loss': 0.2982823210583482}
2022-12-31 09:48:00,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:00,282 INFO:     Epoch: 40
2022-12-31 09:48:01,899 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3507611006498337, 'Total loss': 0.3507611006498337} | train loss {'Reaction outcome loss': 0.2941667998229769, 'Total loss': 0.2941667998229769}
2022-12-31 09:48:01,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:01,901 INFO:     Epoch: 41
2022-12-31 09:48:03,515 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3599338799715042, 'Total loss': 0.3599338799715042} | train loss {'Reaction outcome loss': 0.29022654260270003, 'Total loss': 0.29022654260270003}
2022-12-31 09:48:03,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:03,515 INFO:     Epoch: 42
2022-12-31 09:48:05,132 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3798152804374695, 'Total loss': 0.3798152804374695} | train loss {'Reaction outcome loss': 0.279367471497089, 'Total loss': 0.279367471497089}
2022-12-31 09:48:05,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:05,132 INFO:     Epoch: 43
2022-12-31 09:48:06,735 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3386978417634964, 'Total loss': 0.3386978417634964} | train loss {'Reaction outcome loss': 0.2867182438339137, 'Total loss': 0.2867182438339137}
2022-12-31 09:48:06,735 INFO:     Found new best model at epoch 43
2022-12-31 09:48:06,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:06,736 INFO:     Epoch: 44
2022-12-31 09:48:08,344 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3630964214603106, 'Total loss': 0.3630964214603106} | train loss {'Reaction outcome loss': 0.2809121597437222, 'Total loss': 0.2809121597437222}
2022-12-31 09:48:08,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:08,345 INFO:     Epoch: 45
2022-12-31 09:48:09,989 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.37875952819983166, 'Total loss': 0.37875952819983166} | train loss {'Reaction outcome loss': 0.27510717302722193, 'Total loss': 0.27510717302722193}
2022-12-31 09:48:09,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:09,989 INFO:     Epoch: 46
2022-12-31 09:48:11,658 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3719523479541143, 'Total loss': 0.3719523479541143} | train loss {'Reaction outcome loss': 0.2739572291554957, 'Total loss': 0.2739572291554957}
2022-12-31 09:48:11,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:11,658 INFO:     Epoch: 47
2022-12-31 09:48:13,324 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.35769897550344465, 'Total loss': 0.35769897550344465} | train loss {'Reaction outcome loss': 0.2685974707779902, 'Total loss': 0.2685974707779902}
2022-12-31 09:48:13,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:13,325 INFO:     Epoch: 48
2022-12-31 09:48:14,929 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3591202100118001, 'Total loss': 0.3591202100118001} | train loss {'Reaction outcome loss': 0.27362302833300634, 'Total loss': 0.27362302833300634}
2022-12-31 09:48:14,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:14,929 INFO:     Epoch: 49
2022-12-31 09:48:16,548 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.34849848474065465, 'Total loss': 0.34849848474065465} | train loss {'Reaction outcome loss': 0.26633135207831216, 'Total loss': 0.26633135207831216}
2022-12-31 09:48:16,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:16,548 INFO:     Epoch: 50
2022-12-31 09:48:18,144 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.33974626461664836, 'Total loss': 0.33974626461664836} | train loss {'Reaction outcome loss': 0.2658557850827164, 'Total loss': 0.2658557850827164}
2022-12-31 09:48:18,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:18,144 INFO:     Epoch: 51
2022-12-31 09:48:19,762 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.37346168557802834, 'Total loss': 0.37346168557802834} | train loss {'Reaction outcome loss': 0.26041884022337863, 'Total loss': 0.26041884022337863}
2022-12-31 09:48:19,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:19,763 INFO:     Epoch: 52
2022-12-31 09:48:21,376 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.40683037439982095, 'Total loss': 0.40683037439982095} | train loss {'Reaction outcome loss': 0.2654329142415567, 'Total loss': 0.2654329142415567}
2022-12-31 09:48:21,377 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:21,378 INFO:     Epoch: 53
2022-12-31 09:48:22,990 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3460624451438586, 'Total loss': 0.3460624451438586} | train loss {'Reaction outcome loss': 0.2633322127405487, 'Total loss': 0.2633322127405487}
2022-12-31 09:48:22,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:22,990 INFO:     Epoch: 54
2022-12-31 09:48:24,592 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3381997555494308, 'Total loss': 0.3381997555494308} | train loss {'Reaction outcome loss': 0.26028833589398903, 'Total loss': 0.26028833589398903}
2022-12-31 09:48:24,592 INFO:     Found new best model at epoch 54
2022-12-31 09:48:24,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:24,593 INFO:     Epoch: 55
2022-12-31 09:48:26,210 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.33906122148036955, 'Total loss': 0.33906122148036955} | train loss {'Reaction outcome loss': 0.25949385498620114, 'Total loss': 0.25949385498620114}
2022-12-31 09:48:26,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:26,212 INFO:     Epoch: 56
2022-12-31 09:48:27,811 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39202842116355896, 'Total loss': 0.39202842116355896} | train loss {'Reaction outcome loss': 0.2549894749445821, 'Total loss': 0.2549894749445821}
2022-12-31 09:48:27,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:27,811 INFO:     Epoch: 57
2022-12-31 09:48:29,448 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.377029812335968, 'Total loss': 0.377029812335968} | train loss {'Reaction outcome loss': 0.25233372924883013, 'Total loss': 0.25233372924883013}
2022-12-31 09:48:29,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:29,448 INFO:     Epoch: 58
2022-12-31 09:48:31,110 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3544741610685984, 'Total loss': 0.3544741610685984} | train loss {'Reaction outcome loss': 0.24954079166861648, 'Total loss': 0.24954079166861648}
2022-12-31 09:48:31,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:31,112 INFO:     Epoch: 59
2022-12-31 09:48:32,771 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.372870900730292, 'Total loss': 0.372870900730292} | train loss {'Reaction outcome loss': 0.2480942846447337, 'Total loss': 0.2480942846447337}
2022-12-31 09:48:32,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:32,771 INFO:     Epoch: 60
2022-12-31 09:48:34,374 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3437561651070913, 'Total loss': 0.3437561651070913} | train loss {'Reaction outcome loss': 0.2459217969879562, 'Total loss': 0.2459217969879562}
2022-12-31 09:48:34,375 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:34,375 INFO:     Epoch: 61
2022-12-31 09:48:35,966 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.369925257563591, 'Total loss': 0.369925257563591} | train loss {'Reaction outcome loss': 0.24511371487045547, 'Total loss': 0.24511371487045547}
2022-12-31 09:48:35,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:35,967 INFO:     Epoch: 62
2022-12-31 09:48:37,582 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.36766094863414767, 'Total loss': 0.36766094863414767} | train loss {'Reaction outcome loss': 0.246344403185569, 'Total loss': 0.246344403185569}
2022-12-31 09:48:37,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:37,584 INFO:     Epoch: 63
2022-12-31 09:48:39,197 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.36258414487044016, 'Total loss': 0.36258414487044016} | train loss {'Reaction outcome loss': 0.2503949472754656, 'Total loss': 0.2503949472754656}
2022-12-31 09:48:39,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:39,197 INFO:     Epoch: 64
2022-12-31 09:48:40,811 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.35649481614430745, 'Total loss': 0.35649481614430745} | train loss {'Reaction outcome loss': 0.2395465114836443, 'Total loss': 0.2395465114836443}
2022-12-31 09:48:40,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:40,811 INFO:     Epoch: 65
2022-12-31 09:48:42,416 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3801572576165199, 'Total loss': 0.3801572576165199} | train loss {'Reaction outcome loss': 0.23912937855785074, 'Total loss': 0.23912937855785074}
2022-12-31 09:48:42,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:42,416 INFO:     Epoch: 66
2022-12-31 09:48:44,067 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.36349908510843915, 'Total loss': 0.36349908510843915} | train loss {'Reaction outcome loss': 0.2359288507796797, 'Total loss': 0.2359288507796797}
2022-12-31 09:48:44,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:44,068 INFO:     Epoch: 67
2022-12-31 09:48:45,660 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.37340087393919624, 'Total loss': 0.37340087393919624} | train loss {'Reaction outcome loss': 0.2310515213959484, 'Total loss': 0.2310515213959484}
2022-12-31 09:48:45,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:45,661 INFO:     Epoch: 68
2022-12-31 09:48:47,282 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3583664620916049, 'Total loss': 0.3583664620916049} | train loss {'Reaction outcome loss': 0.22548831954584977, 'Total loss': 0.22548831954584977}
2022-12-31 09:48:47,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:47,282 INFO:     Epoch: 69
2022-12-31 09:48:48,900 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.346180859208107, 'Total loss': 0.346180859208107} | train loss {'Reaction outcome loss': 0.2379714857504471, 'Total loss': 0.2379714857504471}
2022-12-31 09:48:48,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:48,900 INFO:     Epoch: 70
2022-12-31 09:48:50,551 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.36865090429782865, 'Total loss': 0.36865090429782865} | train loss {'Reaction outcome loss': 0.23802386588729676, 'Total loss': 0.23802386588729676}
2022-12-31 09:48:50,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:50,553 INFO:     Epoch: 71
2022-12-31 09:48:52,153 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3375816136598587, 'Total loss': 0.3375816136598587} | train loss {'Reaction outcome loss': 0.23077626620496652, 'Total loss': 0.23077626620496652}
2022-12-31 09:48:52,153 INFO:     Found new best model at epoch 71
2022-12-31 09:48:52,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:52,154 INFO:     Epoch: 72
2022-12-31 09:48:53,760 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3540603150924047, 'Total loss': 0.3540603150924047} | train loss {'Reaction outcome loss': 0.23061085606686474, 'Total loss': 0.23061085606686474}
2022-12-31 09:48:53,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:53,761 INFO:     Epoch: 73
2022-12-31 09:48:55,368 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3501960872362057, 'Total loss': 0.3501960872362057} | train loss {'Reaction outcome loss': 0.22410273276914974, 'Total loss': 0.22410273276914974}
2022-12-31 09:48:55,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:55,368 INFO:     Epoch: 74
2022-12-31 09:48:57,003 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.37014756600062054, 'Total loss': 0.37014756600062054} | train loss {'Reaction outcome loss': 0.22615536097907848, 'Total loss': 0.22615536097907848}
2022-12-31 09:48:57,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:57,004 INFO:     Epoch: 75
2022-12-31 09:48:58,623 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.38027430772781373, 'Total loss': 0.38027430772781373} | train loss {'Reaction outcome loss': 0.22609746926178356, 'Total loss': 0.22609746926178356}
2022-12-31 09:48:58,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:48:58,623 INFO:     Epoch: 76
2022-12-31 09:49:00,222 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.33729064563910166, 'Total loss': 0.33729064563910166} | train loss {'Reaction outcome loss': 0.2241809173934296, 'Total loss': 0.2241809173934296}
2022-12-31 09:49:00,222 INFO:     Found new best model at epoch 76
2022-12-31 09:49:00,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:00,223 INFO:     Epoch: 77
2022-12-31 09:49:01,843 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3813325732946396, 'Total loss': 0.3813325732946396} | train loss {'Reaction outcome loss': 0.22214217889475693, 'Total loss': 0.22214217889475693}
2022-12-31 09:49:01,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:01,844 INFO:     Epoch: 78
2022-12-31 09:49:03,456 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3887644718090693, 'Total loss': 0.3887644718090693} | train loss {'Reaction outcome loss': 0.2227688500126454, 'Total loss': 0.2227688500126454}
2022-12-31 09:49:03,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:03,456 INFO:     Epoch: 79
2022-12-31 09:49:05,072 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3597275843222936, 'Total loss': 0.3597275843222936} | train loss {'Reaction outcome loss': 0.23098807627274673, 'Total loss': 0.23098807627274673}
2022-12-31 09:49:05,072 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:05,072 INFO:     Epoch: 80
2022-12-31 09:49:06,690 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.38717197875181836, 'Total loss': 0.38717197875181836} | train loss {'Reaction outcome loss': 0.22335386469906418, 'Total loss': 0.22335386469906418}
2022-12-31 09:49:06,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:06,691 INFO:     Epoch: 81
2022-12-31 09:49:08,309 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3583274980386098, 'Total loss': 0.3583274980386098} | train loss {'Reaction outcome loss': 0.21497159765945875, 'Total loss': 0.21497159765945875}
2022-12-31 09:49:08,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:08,310 INFO:     Epoch: 82
2022-12-31 09:49:09,906 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.39901622335116066, 'Total loss': 0.39901622335116066} | train loss {'Reaction outcome loss': 0.21388067424781487, 'Total loss': 0.21388067424781487}
2022-12-31 09:49:09,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:09,906 INFO:     Epoch: 83
2022-12-31 09:49:11,526 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.37892062266667687, 'Total loss': 0.37892062266667687} | train loss {'Reaction outcome loss': 0.2199267387417034, 'Total loss': 0.2199267387417034}
2022-12-31 09:49:11,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:11,526 INFO:     Epoch: 84
2022-12-31 09:49:13,126 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.34406034350395204, 'Total loss': 0.34406034350395204} | train loss {'Reaction outcome loss': 0.2129249493339324, 'Total loss': 0.2129249493339324}
2022-12-31 09:49:13,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:13,126 INFO:     Epoch: 85
2022-12-31 09:49:14,745 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.35662683794895805, 'Total loss': 0.35662683794895805} | train loss {'Reaction outcome loss': 0.2246731324827413, 'Total loss': 0.2246731324827413}
2022-12-31 09:49:14,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:14,745 INFO:     Epoch: 86
2022-12-31 09:49:16,364 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3473432123661041, 'Total loss': 0.3473432123661041} | train loss {'Reaction outcome loss': 0.21504606950745686, 'Total loss': 0.21504606950745686}
2022-12-31 09:49:16,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:16,365 INFO:     Epoch: 87
2022-12-31 09:49:17,972 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3740579724311829, 'Total loss': 0.3740579724311829} | train loss {'Reaction outcome loss': 0.21250393316620417, 'Total loss': 0.21250393316620417}
2022-12-31 09:49:17,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:17,972 INFO:     Epoch: 88
2022-12-31 09:49:19,591 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.37254760166009265, 'Total loss': 0.37254760166009265} | train loss {'Reaction outcome loss': 0.21424781561355083, 'Total loss': 0.21424781561355083}
2022-12-31 09:49:19,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:19,591 INFO:     Epoch: 89
2022-12-31 09:49:21,195 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.33450978609422843, 'Total loss': 0.33450978609422843} | train loss {'Reaction outcome loss': 0.21675547196896283, 'Total loss': 0.21675547196896283}
2022-12-31 09:49:21,196 INFO:     Found new best model at epoch 89
2022-12-31 09:49:21,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:21,197 INFO:     Epoch: 90
2022-12-31 09:49:22,819 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3457611771921317, 'Total loss': 0.3457611771921317} | train loss {'Reaction outcome loss': 0.20492898943138035, 'Total loss': 0.20492898943138035}
2022-12-31 09:49:22,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:22,819 INFO:     Epoch: 91
2022-12-31 09:49:24,438 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.35030700837572415, 'Total loss': 0.35030700837572415} | train loss {'Reaction outcome loss': 0.20709966115034875, 'Total loss': 0.20709966115034875}
2022-12-31 09:49:24,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:24,438 INFO:     Epoch: 92
2022-12-31 09:49:26,116 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.37402115762233734, 'Total loss': 0.37402115762233734} | train loss {'Reaction outcome loss': 0.20888572340891678, 'Total loss': 0.20888572340891678}
2022-12-31 09:49:26,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:26,117 INFO:     Epoch: 93
2022-12-31 09:49:27,733 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3444892625013987, 'Total loss': 0.3444892625013987} | train loss {'Reaction outcome loss': 0.20803511843408057, 'Total loss': 0.20803511843408057}
2022-12-31 09:49:27,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:27,734 INFO:     Epoch: 94
2022-12-31 09:49:29,354 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38350463211536406, 'Total loss': 0.38350463211536406} | train loss {'Reaction outcome loss': 0.20223218875698448, 'Total loss': 0.20223218875698448}
2022-12-31 09:49:29,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:29,354 INFO:     Epoch: 95
2022-12-31 09:49:30,979 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.36164684693018595, 'Total loss': 0.36164684693018595} | train loss {'Reaction outcome loss': 0.20334814786104088, 'Total loss': 0.20334814786104088}
2022-12-31 09:49:30,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:30,979 INFO:     Epoch: 96
2022-12-31 09:49:32,633 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.35653053025404613, 'Total loss': 0.35653053025404613} | train loss {'Reaction outcome loss': 0.19617692505544057, 'Total loss': 0.19617692505544057}
2022-12-31 09:49:32,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:32,634 INFO:     Epoch: 97
2022-12-31 09:49:34,272 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.33193425138791405, 'Total loss': 0.33193425138791405} | train loss {'Reaction outcome loss': 0.20257656664893514, 'Total loss': 0.20257656664893514}
2022-12-31 09:49:34,272 INFO:     Found new best model at epoch 97
2022-12-31 09:49:34,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:34,273 INFO:     Epoch: 98
2022-12-31 09:49:35,891 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39003310203552244, 'Total loss': 0.39003310203552244} | train loss {'Reaction outcome loss': 0.1997681814464421, 'Total loss': 0.1997681814464421}
2022-12-31 09:49:35,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:35,891 INFO:     Epoch: 99
2022-12-31 09:49:37,488 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3816066195567449, 'Total loss': 0.3816066195567449} | train loss {'Reaction outcome loss': 0.2100278800454273, 'Total loss': 0.2100278800454273}
2022-12-31 09:49:37,489 INFO:     Best model found after epoch 98 of 100.
2022-12-31 09:49:37,489 INFO:   Done with stage: TRAINING
2022-12-31 09:49:37,489 INFO:   Starting stage: EVALUATION
2022-12-31 09:49:37,609 INFO:   Done with stage: EVALUATION
2022-12-31 09:49:37,609 INFO:   Leaving out SEQ value Fold_7
2022-12-31 09:49:37,621 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 09:49:37,621 INFO:   Starting stage: FEATURE SCALING
2022-12-31 09:49:38,255 INFO:   Done with stage: FEATURE SCALING
2022-12-31 09:49:38,256 INFO:   Starting stage: SCALING TARGETS
2022-12-31 09:49:38,325 INFO:   Done with stage: SCALING TARGETS
2022-12-31 09:49:38,325 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:49:38,325 INFO:     No hyperparam tuning for this model
2022-12-31 09:49:38,325 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:49:38,325 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 09:49:38,326 INFO:     None feature selector for col prot
2022-12-31 09:49:38,326 INFO:     None feature selector for col prot
2022-12-31 09:49:38,326 INFO:     None feature selector for col prot
2022-12-31 09:49:38,327 INFO:     None feature selector for col chem
2022-12-31 09:49:38,327 INFO:     None feature selector for col chem
2022-12-31 09:49:38,327 INFO:     None feature selector for col chem
2022-12-31 09:49:38,327 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 09:49:38,327 INFO:   Starting stage: BUILD MODEL
2022-12-31 09:49:38,329 INFO:     Number of params in model 223921
2022-12-31 09:49:38,332 INFO:   Done with stage: BUILD MODEL
2022-12-31 09:49:38,332 INFO:   Starting stage: TRAINING
2022-12-31 09:49:38,377 INFO:     Val loss before train {'Reaction outcome loss': 0.9443092981974284, 'Total loss': 0.9443092981974284}
2022-12-31 09:49:38,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:38,378 INFO:     Epoch: 0
2022-12-31 09:49:39,966 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6697119633356731, 'Total loss': 0.6697119633356731} | train loss {'Reaction outcome loss': 0.8114205188509347, 'Total loss': 0.8114205188509347}
2022-12-31 09:49:39,966 INFO:     Found new best model at epoch 0
2022-12-31 09:49:39,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:39,967 INFO:     Epoch: 1
2022-12-31 09:49:41,578 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5498758951822916, 'Total loss': 0.5498758951822916} | train loss {'Reaction outcome loss': 0.5947163596317389, 'Total loss': 0.5947163596317389}
2022-12-31 09:49:41,578 INFO:     Found new best model at epoch 1
2022-12-31 09:49:41,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:41,579 INFO:     Epoch: 2
2022-12-31 09:49:43,198 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5042216956615448, 'Total loss': 0.5042216956615448} | train loss {'Reaction outcome loss': 0.5570855570984059, 'Total loss': 0.5570855570984059}
2022-12-31 09:49:43,198 INFO:     Found new best model at epoch 2
2022-12-31 09:49:43,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:43,199 INFO:     Epoch: 3
2022-12-31 09:49:44,820 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.536527560154597, 'Total loss': 0.536527560154597} | train loss {'Reaction outcome loss': 0.5033011593572472, 'Total loss': 0.5033011593572472}
2022-12-31 09:49:44,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:44,822 INFO:     Epoch: 4
2022-12-31 09:49:46,450 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5135569095611572, 'Total loss': 0.5135569095611572} | train loss {'Reaction outcome loss': 0.4834188693135545, 'Total loss': 0.4834188693135545}
2022-12-31 09:49:46,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:46,450 INFO:     Epoch: 5
2022-12-31 09:49:48,058 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5008412698904673, 'Total loss': 0.5008412698904673} | train loss {'Reaction outcome loss': 0.47333809010519146, 'Total loss': 0.47333809010519146}
2022-12-31 09:49:48,058 INFO:     Found new best model at epoch 5
2022-12-31 09:49:48,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:48,059 INFO:     Epoch: 6
2022-12-31 09:49:49,675 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5236896077791849, 'Total loss': 0.5236896077791849} | train loss {'Reaction outcome loss': 0.4674007364724209, 'Total loss': 0.4674007364724209}
2022-12-31 09:49:49,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:49,676 INFO:     Epoch: 7
2022-12-31 09:49:51,280 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5011014729738236, 'Total loss': 0.5011014729738236} | train loss {'Reaction outcome loss': 0.45751679684709756, 'Total loss': 0.45751679684709756}
2022-12-31 09:49:51,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:51,280 INFO:     Epoch: 8
2022-12-31 09:49:52,916 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5155698776245117, 'Total loss': 0.5155698776245117} | train loss {'Reaction outcome loss': 0.4466344351083904, 'Total loss': 0.4466344351083904}
2022-12-31 09:49:52,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:52,916 INFO:     Epoch: 9
2022-12-31 09:49:54,507 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5327979832887649, 'Total loss': 0.5327979832887649} | train loss {'Reaction outcome loss': 0.44168344388827274, 'Total loss': 0.44168344388827274}
2022-12-31 09:49:54,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:54,508 INFO:     Epoch: 10
2022-12-31 09:49:56,119 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4865965982278188, 'Total loss': 0.4865965982278188} | train loss {'Reaction outcome loss': 0.4383392042439917, 'Total loss': 0.4383392042439917}
2022-12-31 09:49:56,119 INFO:     Found new best model at epoch 10
2022-12-31 09:49:56,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:56,120 INFO:     Epoch: 11
2022-12-31 09:49:57,510 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5118230044841766, 'Total loss': 0.5118230044841766} | train loss {'Reaction outcome loss': 0.43479535504298256, 'Total loss': 0.43479535504298256}
2022-12-31 09:49:57,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:57,511 INFO:     Epoch: 12
2022-12-31 09:49:58,584 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4940182387828827, 'Total loss': 0.4940182387828827} | train loss {'Reaction outcome loss': 0.42646252603309764, 'Total loss': 0.42646252603309764}
2022-12-31 09:49:58,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:58,584 INFO:     Epoch: 13
2022-12-31 09:49:59,652 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4917918781439463, 'Total loss': 0.4917918781439463} | train loss {'Reaction outcome loss': 0.42374296094277414, 'Total loss': 0.42374296094277414}
2022-12-31 09:49:59,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:49:59,652 INFO:     Epoch: 14
2022-12-31 09:50:00,721 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5304228504498799, 'Total loss': 0.5304228504498799} | train loss {'Reaction outcome loss': 0.41095391057045333, 'Total loss': 0.41095391057045333}
2022-12-31 09:50:00,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:00,721 INFO:     Epoch: 15
2022-12-31 09:50:01,899 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4900717258453369, 'Total loss': 0.4900717258453369} | train loss {'Reaction outcome loss': 0.41420583872367506, 'Total loss': 0.41420583872367506}
2022-12-31 09:50:01,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:01,899 INFO:     Epoch: 16
2022-12-31 09:50:03,557 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5103261172771454, 'Total loss': 0.5103261172771454} | train loss {'Reaction outcome loss': 0.41832043820202514, 'Total loss': 0.41832043820202514}
2022-12-31 09:50:03,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:03,558 INFO:     Epoch: 17
2022-12-31 09:50:05,196 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4903950373331706, 'Total loss': 0.4903950373331706} | train loss {'Reaction outcome loss': 0.39987931650462843, 'Total loss': 0.39987931650462843}
2022-12-31 09:50:05,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:05,197 INFO:     Epoch: 18
2022-12-31 09:50:06,814 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4615138034025828, 'Total loss': 0.4615138034025828} | train loss {'Reaction outcome loss': 0.39621032071232365, 'Total loss': 0.39621032071232365}
2022-12-31 09:50:06,814 INFO:     Found new best model at epoch 18
2022-12-31 09:50:06,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:06,815 INFO:     Epoch: 19
2022-12-31 09:50:08,452 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46122414072354634, 'Total loss': 0.46122414072354634} | train loss {'Reaction outcome loss': 0.38330330083018466, 'Total loss': 0.38330330083018466}
2022-12-31 09:50:08,454 INFO:     Found new best model at epoch 19
2022-12-31 09:50:08,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:08,455 INFO:     Epoch: 20
2022-12-31 09:50:10,054 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47744611899058026, 'Total loss': 0.47744611899058026} | train loss {'Reaction outcome loss': 0.3837459217098987, 'Total loss': 0.3837459217098987}
2022-12-31 09:50:10,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:10,054 INFO:     Epoch: 21
2022-12-31 09:50:11,677 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4456313043832779, 'Total loss': 0.4456313043832779} | train loss {'Reaction outcome loss': 0.37823609254606394, 'Total loss': 0.37823609254606394}
2022-12-31 09:50:11,677 INFO:     Found new best model at epoch 21
2022-12-31 09:50:11,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:11,678 INFO:     Epoch: 22
2022-12-31 09:50:13,303 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4659287850062052, 'Total loss': 0.4659287850062052} | train loss {'Reaction outcome loss': 0.3939647322075199, 'Total loss': 0.3939647322075199}
2022-12-31 09:50:13,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:13,304 INFO:     Epoch: 23
2022-12-31 09:50:14,955 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.486551870405674, 'Total loss': 0.486551870405674} | train loss {'Reaction outcome loss': 0.3678402787562041, 'Total loss': 0.3678402787562041}
2022-12-31 09:50:14,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:14,955 INFO:     Epoch: 24
2022-12-31 09:50:16,569 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4793327391147614, 'Total loss': 0.4793327391147614} | train loss {'Reaction outcome loss': 0.3623013987612533, 'Total loss': 0.3623013987612533}
2022-12-31 09:50:16,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:16,570 INFO:     Epoch: 25
2022-12-31 09:50:18,183 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4226246734460195, 'Total loss': 0.4226246734460195} | train loss {'Reaction outcome loss': 0.3539252069009387, 'Total loss': 0.3539252069009387}
2022-12-31 09:50:18,183 INFO:     Found new best model at epoch 25
2022-12-31 09:50:18,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:18,184 INFO:     Epoch: 26
2022-12-31 09:50:19,785 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.446964693069458, 'Total loss': 0.446964693069458} | train loss {'Reaction outcome loss': 0.35392274787528033, 'Total loss': 0.35392274787528033}
2022-12-31 09:50:19,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:19,786 INFO:     Epoch: 27
2022-12-31 09:50:21,386 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44258007605870564, 'Total loss': 0.44258007605870564} | train loss {'Reaction outcome loss': 0.33918504688072193, 'Total loss': 0.33918504688072193}
2022-12-31 09:50:21,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:21,386 INFO:     Epoch: 28
2022-12-31 09:50:23,000 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44331064621607463, 'Total loss': 0.44331064621607463} | train loss {'Reaction outcome loss': 0.3384741299610207, 'Total loss': 0.3384741299610207}
2022-12-31 09:50:23,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:23,000 INFO:     Epoch: 29
2022-12-31 09:50:24,615 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42631858388582866, 'Total loss': 0.42631858388582866} | train loss {'Reaction outcome loss': 0.344485177287319, 'Total loss': 0.344485177287319}
2022-12-31 09:50:24,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:24,615 INFO:     Epoch: 30
2022-12-31 09:50:26,231 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42798768579959867, 'Total loss': 0.42798768579959867} | train loss {'Reaction outcome loss': 0.32978991338429786, 'Total loss': 0.32978991338429786}
2022-12-31 09:50:26,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:26,232 INFO:     Epoch: 31
2022-12-31 09:50:27,846 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5175985793272654, 'Total loss': 0.5175985793272654} | train loss {'Reaction outcome loss': 0.3447570986505868, 'Total loss': 0.3447570986505868}
2022-12-31 09:50:27,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:27,846 INFO:     Epoch: 32
2022-12-31 09:50:29,435 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4224674602349599, 'Total loss': 0.4224674602349599} | train loss {'Reaction outcome loss': 0.32809803524540493, 'Total loss': 0.32809803524540493}
2022-12-31 09:50:29,435 INFO:     Found new best model at epoch 32
2022-12-31 09:50:29,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:29,436 INFO:     Epoch: 33
2022-12-31 09:50:31,040 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4316589057445526, 'Total loss': 0.4316589057445526} | train loss {'Reaction outcome loss': 0.3130501765849647, 'Total loss': 0.3130501765849647}
2022-12-31 09:50:31,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:31,041 INFO:     Epoch: 34
2022-12-31 09:50:32,655 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4127140760421753, 'Total loss': 0.4127140760421753} | train loss {'Reaction outcome loss': 0.3094072300345811, 'Total loss': 0.3094072300345811}
2022-12-31 09:50:32,656 INFO:     Found new best model at epoch 34
2022-12-31 09:50:32,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:32,657 INFO:     Epoch: 35
2022-12-31 09:50:34,268 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45271435578664143, 'Total loss': 0.45271435578664143} | train loss {'Reaction outcome loss': 0.31673049417904753, 'Total loss': 0.31673049417904753}
2022-12-31 09:50:34,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:34,268 INFO:     Epoch: 36
2022-12-31 09:50:35,882 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43846684594949087, 'Total loss': 0.43846684594949087} | train loss {'Reaction outcome loss': 0.31221970241983854, 'Total loss': 0.31221970241983854}
2022-12-31 09:50:35,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:35,882 INFO:     Epoch: 37
2022-12-31 09:50:37,471 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4722144216299057, 'Total loss': 0.4722144216299057} | train loss {'Reaction outcome loss': 0.30101957165744103, 'Total loss': 0.30101957165744103}
2022-12-31 09:50:37,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:37,472 INFO:     Epoch: 38
2022-12-31 09:50:39,078 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4025079508622487, 'Total loss': 0.4025079508622487} | train loss {'Reaction outcome loss': 0.296783966176799, 'Total loss': 0.296783966176799}
2022-12-31 09:50:39,078 INFO:     Found new best model at epoch 38
2022-12-31 09:50:39,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:39,079 INFO:     Epoch: 39
2022-12-31 09:50:40,704 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4091879606246948, 'Total loss': 0.4091879606246948} | train loss {'Reaction outcome loss': 0.2893737829764849, 'Total loss': 0.2893737829764849}
2022-12-31 09:50:40,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:40,705 INFO:     Epoch: 40
2022-12-31 09:50:42,328 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39373722275098166, 'Total loss': 0.39373722275098166} | train loss {'Reaction outcome loss': 0.28290284528739523, 'Total loss': 0.28290284528739523}
2022-12-31 09:50:42,328 INFO:     Found new best model at epoch 40
2022-12-31 09:50:42,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:42,329 INFO:     Epoch: 41
2022-12-31 09:50:43,941 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42531219919522606, 'Total loss': 0.42531219919522606} | train loss {'Reaction outcome loss': 0.2879292038838764, 'Total loss': 0.2879292038838764}
2022-12-31 09:50:43,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:43,942 INFO:     Epoch: 42
2022-12-31 09:50:45,590 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4280869781970978, 'Total loss': 0.4280869781970978} | train loss {'Reaction outcome loss': 0.27806725707816204, 'Total loss': 0.27806725707816204}
2022-12-31 09:50:45,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:45,591 INFO:     Epoch: 43
2022-12-31 09:50:47,161 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3856889734665553, 'Total loss': 0.3856889734665553} | train loss {'Reaction outcome loss': 0.28338253291566734, 'Total loss': 0.28338253291566734}
2022-12-31 09:50:47,161 INFO:     Found new best model at epoch 43
2022-12-31 09:50:47,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:47,162 INFO:     Epoch: 44
2022-12-31 09:50:48,793 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4173266510168711, 'Total loss': 0.4173266510168711} | train loss {'Reaction outcome loss': 0.27173233180698275, 'Total loss': 0.27173233180698275}
2022-12-31 09:50:48,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:48,794 INFO:     Epoch: 45
2022-12-31 09:50:50,437 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39777701795101167, 'Total loss': 0.39777701795101167} | train loss {'Reaction outcome loss': 0.2877792223100213, 'Total loss': 0.2877792223100213}
2022-12-31 09:50:50,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:50,437 INFO:     Epoch: 46
2022-12-31 09:50:52,051 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.427378261089325, 'Total loss': 0.427378261089325} | train loss {'Reaction outcome loss': 0.28452695174601633, 'Total loss': 0.28452695174601633}
2022-12-31 09:50:52,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:52,051 INFO:     Epoch: 47
2022-12-31 09:50:53,664 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41787705520788826, 'Total loss': 0.41787705520788826} | train loss {'Reaction outcome loss': 0.2704093737959646, 'Total loss': 0.2704093737959646}
2022-12-31 09:50:53,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:53,664 INFO:     Epoch: 48
2022-12-31 09:50:55,262 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39076483647028604, 'Total loss': 0.39076483647028604} | train loss {'Reaction outcome loss': 0.26583214836985763, 'Total loss': 0.26583214836985763}
2022-12-31 09:50:55,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:55,263 INFO:     Epoch: 49
2022-12-31 09:50:56,846 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3872833122809728, 'Total loss': 0.3872833122809728} | train loss {'Reaction outcome loss': 0.2636885570962846, 'Total loss': 0.2636885570962846}
2022-12-31 09:50:56,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:56,846 INFO:     Epoch: 50
2022-12-31 09:50:58,460 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3733750859896342, 'Total loss': 0.3733750859896342} | train loss {'Reaction outcome loss': 0.2608807371284786, 'Total loss': 0.2608807371284786}
2022-12-31 09:50:58,460 INFO:     Found new best model at epoch 50
2022-12-31 09:50:58,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:50:58,461 INFO:     Epoch: 51
2022-12-31 09:51:00,106 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.392550058166186, 'Total loss': 0.392550058166186} | train loss {'Reaction outcome loss': 0.25296431085418747, 'Total loss': 0.25296431085418747}
2022-12-31 09:51:00,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:00,107 INFO:     Epoch: 52
2022-12-31 09:51:01,748 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45303291579087573, 'Total loss': 0.45303291579087573} | train loss {'Reaction outcome loss': 0.2574247748631498, 'Total loss': 0.2574247748631498}
2022-12-31 09:51:01,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:01,749 INFO:     Epoch: 53
2022-12-31 09:51:03,388 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42223404347896576, 'Total loss': 0.42223404347896576} | train loss {'Reaction outcome loss': 0.2610923756045573, 'Total loss': 0.2610923756045573}
2022-12-31 09:51:03,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:03,388 INFO:     Epoch: 54
2022-12-31 09:51:05,002 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4022819052139918, 'Total loss': 0.4022819052139918} | train loss {'Reaction outcome loss': 0.25216103384635696, 'Total loss': 0.25216103384635696}
2022-12-31 09:51:05,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:05,002 INFO:     Epoch: 55
2022-12-31 09:51:06,595 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41480157474676765, 'Total loss': 0.41480157474676765} | train loss {'Reaction outcome loss': 0.25266869939134823, 'Total loss': 0.25266869939134823}
2022-12-31 09:51:06,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:06,596 INFO:     Epoch: 56
2022-12-31 09:51:08,213 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3889545803268751, 'Total loss': 0.3889545803268751} | train loss {'Reaction outcome loss': 0.255151504482205, 'Total loss': 0.255151504482205}
2022-12-31 09:51:08,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:08,214 INFO:     Epoch: 57
2022-12-31 09:51:09,827 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3801340162754059, 'Total loss': 0.3801340162754059} | train loss {'Reaction outcome loss': 0.24651095603358175, 'Total loss': 0.24651095603358175}
2022-12-31 09:51:09,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:09,827 INFO:     Epoch: 58
2022-12-31 09:51:11,438 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3951190412044525, 'Total loss': 0.3951190412044525} | train loss {'Reaction outcome loss': 0.25019863520685537, 'Total loss': 0.25019863520685537}
2022-12-31 09:51:11,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:11,439 INFO:     Epoch: 59
2022-12-31 09:51:13,051 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3684861660003662, 'Total loss': 0.3684861660003662} | train loss {'Reaction outcome loss': 0.24461229952166963, 'Total loss': 0.24461229952166963}
2022-12-31 09:51:13,052 INFO:     Found new best model at epoch 59
2022-12-31 09:51:13,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:13,053 INFO:     Epoch: 60
2022-12-31 09:51:14,631 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3583360120654106, 'Total loss': 0.3583360120654106} | train loss {'Reaction outcome loss': 0.2465158351285778, 'Total loss': 0.2465158351285778}
2022-12-31 09:51:14,631 INFO:     Found new best model at epoch 60
2022-12-31 09:51:14,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:14,632 INFO:     Epoch: 61
2022-12-31 09:51:16,246 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.39031483232975006, 'Total loss': 0.39031483232975006} | train loss {'Reaction outcome loss': 0.2505055431570129, 'Total loss': 0.2505055431570129}
2022-12-31 09:51:16,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:16,246 INFO:     Epoch: 62
2022-12-31 09:51:17,868 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.424653426806132, 'Total loss': 0.424653426806132} | train loss {'Reaction outcome loss': 0.23882275895348226, 'Total loss': 0.23882275895348226}
2022-12-31 09:51:17,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:17,868 INFO:     Epoch: 63
2022-12-31 09:51:19,482 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40363088647524514, 'Total loss': 0.40363088647524514} | train loss {'Reaction outcome loss': 0.23733095523789086, 'Total loss': 0.23733095523789086}
2022-12-31 09:51:19,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:19,483 INFO:     Epoch: 64
2022-12-31 09:51:21,097 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3935674548149109, 'Total loss': 0.3935674548149109} | train loss {'Reaction outcome loss': 0.22854128826757136, 'Total loss': 0.22854128826757136}
2022-12-31 09:51:21,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:21,097 INFO:     Epoch: 65
2022-12-31 09:51:22,689 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.34743406176567077, 'Total loss': 0.34743406176567077} | train loss {'Reaction outcome loss': 0.23208499733743299, 'Total loss': 0.23208499733743299}
2022-12-31 09:51:22,690 INFO:     Found new best model at epoch 65
2022-12-31 09:51:22,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:22,691 INFO:     Epoch: 66
2022-12-31 09:51:24,299 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4311855932076772, 'Total loss': 0.4311855932076772} | train loss {'Reaction outcome loss': 0.2319752696864231, 'Total loss': 0.2319752696864231}
2022-12-31 09:51:24,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:24,299 INFO:     Epoch: 67
2022-12-31 09:51:25,943 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3858975057800611, 'Total loss': 0.3858975057800611} | train loss {'Reaction outcome loss': 0.23566347553624192, 'Total loss': 0.23566347553624192}
2022-12-31 09:51:25,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:25,944 INFO:     Epoch: 68
2022-12-31 09:51:27,555 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3543784648180008, 'Total loss': 0.3543784648180008} | train loss {'Reaction outcome loss': 0.2337753587483388, 'Total loss': 0.2337753587483388}
2022-12-31 09:51:27,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:27,555 INFO:     Epoch: 69
2022-12-31 09:51:29,168 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4544146776199341, 'Total loss': 0.4544146776199341} | train loss {'Reaction outcome loss': 0.25570191020496946, 'Total loss': 0.25570191020496946}
2022-12-31 09:51:29,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:29,168 INFO:     Epoch: 70
2022-12-31 09:51:30,782 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.48656283020973207, 'Total loss': 0.48656283020973207} | train loss {'Reaction outcome loss': 0.347799605946394, 'Total loss': 0.347799605946394}
2022-12-31 09:51:30,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:30,783 INFO:     Epoch: 71
2022-12-31 09:51:32,371 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.43753799398740134, 'Total loss': 0.43753799398740134} | train loss {'Reaction outcome loss': 0.305323144313002, 'Total loss': 0.305323144313002}
2022-12-31 09:51:32,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:32,372 INFO:     Epoch: 72
2022-12-31 09:51:33,980 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.38753576278686525, 'Total loss': 0.38753576278686525} | train loss {'Reaction outcome loss': 0.2685299703507158, 'Total loss': 0.2685299703507158}
2022-12-31 09:51:33,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:33,981 INFO:     Epoch: 73
2022-12-31 09:51:35,594 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47591193914413454, 'Total loss': 0.47591193914413454} | train loss {'Reaction outcome loss': 0.26565058245930984, 'Total loss': 0.26565058245930984}
2022-12-31 09:51:35,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:35,594 INFO:     Epoch: 74
2022-12-31 09:51:37,206 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4322953303654989, 'Total loss': 0.4322953303654989} | train loss {'Reaction outcome loss': 0.31782447737413866, 'Total loss': 0.31782447737413866}
2022-12-31 09:51:37,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:37,207 INFO:     Epoch: 75
2022-12-31 09:51:38,819 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3958008388678233, 'Total loss': 0.3958008388678233} | train loss {'Reaction outcome loss': 0.26092029747804557, 'Total loss': 0.26092029747804557}
2022-12-31 09:51:38,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:38,819 INFO:     Epoch: 76
2022-12-31 09:51:40,420 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42929655959208807, 'Total loss': 0.42929655959208807} | train loss {'Reaction outcome loss': 0.24733928613131181, 'Total loss': 0.24733928613131181}
2022-12-31 09:51:40,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:40,421 INFO:     Epoch: 77
2022-12-31 09:51:42,025 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4166131685177485, 'Total loss': 0.4166131685177485} | train loss {'Reaction outcome loss': 0.2462208816457702, 'Total loss': 0.2462208816457702}
2022-12-31 09:51:42,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:42,025 INFO:     Epoch: 78
2022-12-31 09:51:43,637 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40849088033040365, 'Total loss': 0.40849088033040365} | train loss {'Reaction outcome loss': 0.2833821267139275, 'Total loss': 0.2833821267139275}
2022-12-31 09:51:43,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:43,639 INFO:     Epoch: 79
2022-12-31 09:51:45,250 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4340895116329193, 'Total loss': 0.4340895116329193} | train loss {'Reaction outcome loss': 0.2369276173564646, 'Total loss': 0.2369276173564646}
2022-12-31 09:51:45,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:45,250 INFO:     Epoch: 80
2022-12-31 09:51:46,864 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.37967642545700075, 'Total loss': 0.37967642545700075} | train loss {'Reaction outcome loss': 0.23373214593005326, 'Total loss': 0.23373214593005326}
2022-12-31 09:51:46,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:46,864 INFO:     Epoch: 81
2022-12-31 09:51:48,477 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4295933852593104, 'Total loss': 0.4295933852593104} | train loss {'Reaction outcome loss': 0.22124436559987362, 'Total loss': 0.22124436559987362}
2022-12-31 09:51:48,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:48,478 INFO:     Epoch: 82
2022-12-31 09:51:50,085 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.34285815606514614, 'Total loss': 0.34285815606514614} | train loss {'Reaction outcome loss': 0.223607429417957, 'Total loss': 0.223607429417957}
2022-12-31 09:51:50,085 INFO:     Found new best model at epoch 82
2022-12-31 09:51:50,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:50,086 INFO:     Epoch: 83
2022-12-31 09:51:51,686 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4235981315374374, 'Total loss': 0.4235981315374374} | train loss {'Reaction outcome loss': 0.2204093779977141, 'Total loss': 0.2204093779977141}
2022-12-31 09:51:51,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:51,687 INFO:     Epoch: 84
2022-12-31 09:51:53,299 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4113472660382589, 'Total loss': 0.4113472660382589} | train loss {'Reaction outcome loss': 0.23095622367185095, 'Total loss': 0.23095622367185095}
2022-12-31 09:51:53,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:53,300 INFO:     Epoch: 85
2022-12-31 09:51:54,910 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.37631805092096327, 'Total loss': 0.37631805092096327} | train loss {'Reaction outcome loss': 0.2340962020477847, 'Total loss': 0.2340962020477847}
2022-12-31 09:51:54,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:54,910 INFO:     Epoch: 86
2022-12-31 09:51:56,532 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38641164302825926, 'Total loss': 0.38641164302825926} | train loss {'Reaction outcome loss': 0.22411495350820917, 'Total loss': 0.22411495350820917}
2022-12-31 09:51:56,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:56,533 INFO:     Epoch: 87
2022-12-31 09:51:58,144 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4501175234715144, 'Total loss': 0.4501175234715144} | train loss {'Reaction outcome loss': 0.2147371612786167, 'Total loss': 0.2147371612786167}
2022-12-31 09:51:58,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:58,145 INFO:     Epoch: 88
2022-12-31 09:51:59,726 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4236445734898249, 'Total loss': 0.4236445734898249} | train loss {'Reaction outcome loss': 0.23780954687306446, 'Total loss': 0.23780954687306446}
2022-12-31 09:51:59,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:51:59,726 INFO:     Epoch: 89
2022-12-31 09:52:01,371 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.42658691505591073, 'Total loss': 0.42658691505591073} | train loss {'Reaction outcome loss': 0.22204315072546402, 'Total loss': 0.22204315072546402}
2022-12-31 09:52:01,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:01,371 INFO:     Epoch: 90
2022-12-31 09:52:03,009 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3638370354970296, 'Total loss': 0.3638370354970296} | train loss {'Reaction outcome loss': 0.22109478073632446, 'Total loss': 0.22109478073632446}
2022-12-31 09:52:03,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:03,010 INFO:     Epoch: 91
2022-12-31 09:52:04,618 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4230776821573575, 'Total loss': 0.4230776821573575} | train loss {'Reaction outcome loss': 0.21375402178944278, 'Total loss': 0.21375402178944278}
2022-12-31 09:52:04,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:04,618 INFO:     Epoch: 92
2022-12-31 09:52:06,225 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.393455970287323, 'Total loss': 0.393455970287323} | train loss {'Reaction outcome loss': 0.20684301030414118, 'Total loss': 0.20684301030414118}
2022-12-31 09:52:06,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:06,225 INFO:     Epoch: 93
2022-12-31 09:52:07,819 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4681490128238996, 'Total loss': 0.4681490128238996} | train loss {'Reaction outcome loss': 0.21533550765446346, 'Total loss': 0.21533550765446346}
2022-12-31 09:52:07,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:07,820 INFO:     Epoch: 94
2022-12-31 09:52:09,432 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.33689260184764863, 'Total loss': 0.33689260184764863} | train loss {'Reaction outcome loss': 0.2604779275977795, 'Total loss': 0.2604779275977795}
2022-12-31 09:52:09,432 INFO:     Found new best model at epoch 94
2022-12-31 09:52:09,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:09,433 INFO:     Epoch: 95
2022-12-31 09:52:11,040 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4015824258327484, 'Total loss': 0.4015824258327484} | train loss {'Reaction outcome loss': 0.21777197220565184, 'Total loss': 0.21777197220565184}
2022-12-31 09:52:11,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:11,040 INFO:     Epoch: 96
2022-12-31 09:52:12,660 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4004031389951706, 'Total loss': 0.4004031389951706} | train loss {'Reaction outcome loss': 0.21597224803965376, 'Total loss': 0.21597224803965376}
2022-12-31 09:52:12,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:12,660 INFO:     Epoch: 97
2022-12-31 09:52:14,273 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3569190119703611, 'Total loss': 0.3569190119703611} | train loss {'Reaction outcome loss': 0.2047664997559311, 'Total loss': 0.2047664997559311}
2022-12-31 09:52:14,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:14,275 INFO:     Epoch: 98
2022-12-31 09:52:15,887 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3771227071682612, 'Total loss': 0.3771227071682612} | train loss {'Reaction outcome loss': 0.20155246582713068, 'Total loss': 0.20155246582713068}
2022-12-31 09:52:15,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:15,888 INFO:     Epoch: 99
2022-12-31 09:52:17,487 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.378368337949117, 'Total loss': 0.378368337949117} | train loss {'Reaction outcome loss': 0.19989414590468252, 'Total loss': 0.19989414590468252}
2022-12-31 09:52:17,487 INFO:     Best model found after epoch 95 of 100.
2022-12-31 09:52:17,488 INFO:   Done with stage: TRAINING
2022-12-31 09:52:17,488 INFO:   Starting stage: EVALUATION
2022-12-31 09:52:17,614 INFO:   Done with stage: EVALUATION
2022-12-31 09:52:17,615 INFO:   Leaving out SEQ value Fold_8
2022-12-31 09:52:17,627 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 09:52:17,627 INFO:   Starting stage: FEATURE SCALING
2022-12-31 09:52:18,269 INFO:   Done with stage: FEATURE SCALING
2022-12-31 09:52:18,269 INFO:   Starting stage: SCALING TARGETS
2022-12-31 09:52:18,338 INFO:   Done with stage: SCALING TARGETS
2022-12-31 09:52:18,338 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:52:18,338 INFO:     No hyperparam tuning for this model
2022-12-31 09:52:18,338 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:52:18,338 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 09:52:18,339 INFO:     None feature selector for col prot
2022-12-31 09:52:18,339 INFO:     None feature selector for col prot
2022-12-31 09:52:18,339 INFO:     None feature selector for col prot
2022-12-31 09:52:18,339 INFO:     None feature selector for col chem
2022-12-31 09:52:18,339 INFO:     None feature selector for col chem
2022-12-31 09:52:18,340 INFO:     None feature selector for col chem
2022-12-31 09:52:18,340 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 09:52:18,340 INFO:   Starting stage: BUILD MODEL
2022-12-31 09:52:18,341 INFO:     Number of params in model 223921
2022-12-31 09:52:18,345 INFO:   Done with stage: BUILD MODEL
2022-12-31 09:52:18,345 INFO:   Starting stage: TRAINING
2022-12-31 09:52:18,389 INFO:     Val loss before train {'Reaction outcome loss': 0.9282591541608175, 'Total loss': 0.9282591541608175}
2022-12-31 09:52:18,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:18,390 INFO:     Epoch: 0
2022-12-31 09:52:20,008 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6425298353036245, 'Total loss': 0.6425298353036245} | train loss {'Reaction outcome loss': 0.8410368566671251, 'Total loss': 0.8410368566671251}
2022-12-31 09:52:20,009 INFO:     Found new best model at epoch 0
2022-12-31 09:52:20,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:20,010 INFO:     Epoch: 1
2022-12-31 09:52:21,622 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5290579537550608, 'Total loss': 0.5290579537550608} | train loss {'Reaction outcome loss': 0.6239751891597457, 'Total loss': 0.6239751891597457}
2022-12-31 09:52:21,622 INFO:     Found new best model at epoch 1
2022-12-31 09:52:21,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:21,623 INFO:     Epoch: 2
2022-12-31 09:52:23,233 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5190665404001872, 'Total loss': 0.5190665404001872} | train loss {'Reaction outcome loss': 0.5485381841747279, 'Total loss': 0.5485381841747279}
2022-12-31 09:52:23,234 INFO:     Found new best model at epoch 2
2022-12-31 09:52:23,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:23,235 INFO:     Epoch: 3
2022-12-31 09:52:24,846 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5032897790273031, 'Total loss': 0.5032897790273031} | train loss {'Reaction outcome loss': 0.5147383281610151, 'Total loss': 0.5147383281610151}
2022-12-31 09:52:24,847 INFO:     Found new best model at epoch 3
2022-12-31 09:52:24,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:24,848 INFO:     Epoch: 4
2022-12-31 09:52:26,422 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4920019825299581, 'Total loss': 0.4920019825299581} | train loss {'Reaction outcome loss': 0.5319236881383087, 'Total loss': 0.5319236881383087}
2022-12-31 09:52:26,422 INFO:     Found new best model at epoch 4
2022-12-31 09:52:26,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:26,423 INFO:     Epoch: 5
2022-12-31 09:52:28,047 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4787352959314982, 'Total loss': 0.4787352959314982} | train loss {'Reaction outcome loss': 0.5104198444472707, 'Total loss': 0.5104198444472707}
2022-12-31 09:52:28,047 INFO:     Found new best model at epoch 5
2022-12-31 09:52:28,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:28,048 INFO:     Epoch: 6
2022-12-31 09:52:29,683 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4722880760828654, 'Total loss': 0.4722880760828654} | train loss {'Reaction outcome loss': 0.49131745448044123, 'Total loss': 0.49131745448044123}
2022-12-31 09:52:29,684 INFO:     Found new best model at epoch 6
2022-12-31 09:52:29,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:29,684 INFO:     Epoch: 7
2022-12-31 09:52:31,314 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4939141750335693, 'Total loss': 0.4939141750335693} | train loss {'Reaction outcome loss': 0.47626185531228565, 'Total loss': 0.47626185531228565}
2022-12-31 09:52:31,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:31,314 INFO:     Epoch: 8
2022-12-31 09:52:32,941 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4859204789002736, 'Total loss': 0.4859204789002736} | train loss {'Reaction outcome loss': 0.4626735647249481, 'Total loss': 0.4626735647249481}
2022-12-31 09:52:32,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:32,942 INFO:     Epoch: 9
2022-12-31 09:52:34,554 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47906818191210426, 'Total loss': 0.47906818191210426} | train loss {'Reaction outcome loss': 0.47120894264915714, 'Total loss': 0.47120894264915714}
2022-12-31 09:52:34,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:34,554 INFO:     Epoch: 10
2022-12-31 09:52:36,157 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47775391340255735, 'Total loss': 0.47775391340255735} | train loss {'Reaction outcome loss': 0.49145719192355225, 'Total loss': 0.49145719192355225}
2022-12-31 09:52:36,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:36,158 INFO:     Epoch: 11
2022-12-31 09:52:37,792 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48877840439478554, 'Total loss': 0.48877840439478554} | train loss {'Reaction outcome loss': 0.45030085007369897, 'Total loss': 0.45030085007369897}
2022-12-31 09:52:37,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:37,792 INFO:     Epoch: 12
2022-12-31 09:52:39,379 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47259729405244194, 'Total loss': 0.47259729405244194} | train loss {'Reaction outcome loss': 0.4464820142349471, 'Total loss': 0.4464820142349471}
2022-12-31 09:52:39,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:39,380 INFO:     Epoch: 13
2022-12-31 09:52:40,980 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.46753625671068827, 'Total loss': 0.46753625671068827} | train loss {'Reaction outcome loss': 0.43770756294944096, 'Total loss': 0.43770756294944096}
2022-12-31 09:52:40,980 INFO:     Found new best model at epoch 13
2022-12-31 09:52:40,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:40,981 INFO:     Epoch: 14
2022-12-31 09:52:42,568 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45536405841509503, 'Total loss': 0.45536405841509503} | train loss {'Reaction outcome loss': 0.43457029369976913, 'Total loss': 0.43457029369976913}
2022-12-31 09:52:42,568 INFO:     Found new best model at epoch 14
2022-12-31 09:52:42,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:42,569 INFO:     Epoch: 15
2022-12-31 09:52:44,161 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44943017363548277, 'Total loss': 0.44943017363548277} | train loss {'Reaction outcome loss': 0.42675190359569976, 'Total loss': 0.42675190359569976}
2022-12-31 09:52:44,162 INFO:     Found new best model at epoch 15
2022-12-31 09:52:44,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:44,163 INFO:     Epoch: 16
2022-12-31 09:52:45,767 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4416293829679489, 'Total loss': 0.4416293829679489} | train loss {'Reaction outcome loss': 0.4266711441530893, 'Total loss': 0.4266711441530893}
2022-12-31 09:52:45,767 INFO:     Found new best model at epoch 16
2022-12-31 09:52:45,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:45,768 INFO:     Epoch: 17
2022-12-31 09:52:47,370 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44484041035175326, 'Total loss': 0.44484041035175326} | train loss {'Reaction outcome loss': 0.41574941563421686, 'Total loss': 0.41574941563421686}
2022-12-31 09:52:47,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:47,370 INFO:     Epoch: 18
2022-12-31 09:52:48,973 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4475647469361623, 'Total loss': 0.4475647469361623} | train loss {'Reaction outcome loss': 0.41354785585587006, 'Total loss': 0.41354785585587006}
2022-12-31 09:52:48,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:48,973 INFO:     Epoch: 19
2022-12-31 09:52:50,576 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43068845172723136, 'Total loss': 0.43068845172723136} | train loss {'Reaction outcome loss': 0.4093428423115309, 'Total loss': 0.4093428423115309}
2022-12-31 09:52:50,577 INFO:     Found new best model at epoch 19
2022-12-31 09:52:50,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:50,578 INFO:     Epoch: 20
2022-12-31 09:52:52,167 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4317213982343674, 'Total loss': 0.4317213982343674} | train loss {'Reaction outcome loss': 0.40636759044845466, 'Total loss': 0.40636759044845466}
2022-12-31 09:52:52,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:52,168 INFO:     Epoch: 21
2022-12-31 09:52:53,746 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43227341572443645, 'Total loss': 0.43227341572443645} | train loss {'Reaction outcome loss': 0.4007336338273371, 'Total loss': 0.4007336338273371}
2022-12-31 09:52:53,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:53,746 INFO:     Epoch: 22
2022-12-31 09:52:55,349 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41882885893185934, 'Total loss': 0.41882885893185934} | train loss {'Reaction outcome loss': 0.39196985820645763, 'Total loss': 0.39196985820645763}
2022-12-31 09:52:55,349 INFO:     Found new best model at epoch 22
2022-12-31 09:52:55,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:55,350 INFO:     Epoch: 23
2022-12-31 09:52:56,952 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4056598256031672, 'Total loss': 0.4056598256031672} | train loss {'Reaction outcome loss': 0.3863704625679099, 'Total loss': 0.3863704625679099}
2022-12-31 09:52:56,954 INFO:     Found new best model at epoch 23
2022-12-31 09:52:56,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:56,955 INFO:     Epoch: 24
2022-12-31 09:52:58,555 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4269479711850484, 'Total loss': 0.4269479711850484} | train loss {'Reaction outcome loss': 0.38151396461087617, 'Total loss': 0.38151396461087617}
2022-12-31 09:52:58,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:52:58,555 INFO:     Epoch: 25
2022-12-31 09:53:00,158 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4161446124315262, 'Total loss': 0.4161446124315262} | train loss {'Reaction outcome loss': 0.3776118649385761, 'Total loss': 0.3776118649385761}
2022-12-31 09:53:00,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:00,158 INFO:     Epoch: 26
2022-12-31 09:53:01,745 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4553010493516922, 'Total loss': 0.4553010493516922} | train loss {'Reaction outcome loss': 0.37123932728570874, 'Total loss': 0.37123932728570874}
2022-12-31 09:53:01,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:01,747 INFO:     Epoch: 27
2022-12-31 09:53:03,330 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.38318344155947365, 'Total loss': 0.38318344155947365} | train loss {'Reaction outcome loss': 0.3721512403352645, 'Total loss': 0.3721512403352645}
2022-12-31 09:53:03,330 INFO:     Found new best model at epoch 27
2022-12-31 09:53:03,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:03,331 INFO:     Epoch: 28
2022-12-31 09:53:04,933 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4289049247900645, 'Total loss': 0.4289049247900645} | train loss {'Reaction outcome loss': 0.36363885913422145, 'Total loss': 0.36363885913422145}
2022-12-31 09:53:04,933 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:04,933 INFO:     Epoch: 29
2022-12-31 09:53:06,539 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4466255416472753, 'Total loss': 0.4466255416472753} | train loss {'Reaction outcome loss': 0.373898545715391, 'Total loss': 0.373898545715391}
2022-12-31 09:53:06,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:06,539 INFO:     Epoch: 30
2022-12-31 09:53:08,145 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41394315361976625, 'Total loss': 0.41394315361976625} | train loss {'Reaction outcome loss': 0.3560948455773726, 'Total loss': 0.3560948455773726}
2022-12-31 09:53:08,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:08,146 INFO:     Epoch: 31
2022-12-31 09:53:09,750 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44526803692181904, 'Total loss': 0.44526803692181904} | train loss {'Reaction outcome loss': 0.3563929222578156, 'Total loss': 0.3563929222578156}
2022-12-31 09:53:09,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:09,751 INFO:     Epoch: 32
2022-12-31 09:53:11,314 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42166969875494636, 'Total loss': 0.42166969875494636} | train loss {'Reaction outcome loss': 0.3858739908892607, 'Total loss': 0.3858739908892607}
2022-12-31 09:53:11,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:11,314 INFO:     Epoch: 33
2022-12-31 09:53:12,965 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4008814230561256, 'Total loss': 0.4008814230561256} | train loss {'Reaction outcome loss': 0.3578636959816019, 'Total loss': 0.3578636959816019}
2022-12-31 09:53:12,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:12,965 INFO:     Epoch: 34
2022-12-31 09:53:14,603 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3953828970591227, 'Total loss': 0.3953828970591227} | train loss {'Reaction outcome loss': 0.34338324660759256, 'Total loss': 0.34338324660759256}
2022-12-31 09:53:14,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:14,604 INFO:     Epoch: 35
2022-12-31 09:53:16,187 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3976712554693222, 'Total loss': 0.3976712554693222} | train loss {'Reaction outcome loss': 0.3390995655461903, 'Total loss': 0.3390995655461903}
2022-12-31 09:53:16,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:16,187 INFO:     Epoch: 36
2022-12-31 09:53:17,815 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3976925084988276, 'Total loss': 0.3976925084988276} | train loss {'Reaction outcome loss': 0.335575182298772, 'Total loss': 0.335575182298772}
2022-12-31 09:53:17,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:17,815 INFO:     Epoch: 37
2022-12-31 09:53:19,410 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.37391297370195387, 'Total loss': 0.37391297370195387} | train loss {'Reaction outcome loss': 0.31996619840113755, 'Total loss': 0.31996619840113755}
2022-12-31 09:53:19,411 INFO:     Found new best model at epoch 37
2022-12-31 09:53:19,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:19,412 INFO:     Epoch: 38
2022-12-31 09:53:21,020 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3966066936651866, 'Total loss': 0.3966066936651866} | train loss {'Reaction outcome loss': 0.3313970008891994, 'Total loss': 0.3313970008891994}
2022-12-31 09:53:21,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:21,020 INFO:     Epoch: 39
2022-12-31 09:53:22,672 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.379810078193744, 'Total loss': 0.379810078193744} | train loss {'Reaction outcome loss': 0.3705469250098627, 'Total loss': 0.3705469250098627}
2022-12-31 09:53:22,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:22,672 INFO:     Epoch: 40
2022-12-31 09:53:24,326 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.38803162376085915, 'Total loss': 0.38803162376085915} | train loss {'Reaction outcome loss': 0.32773481567214796, 'Total loss': 0.32773481567214796}
2022-12-31 09:53:24,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:24,326 INFO:     Epoch: 41
2022-12-31 09:53:25,974 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3878664404153824, 'Total loss': 0.3878664404153824} | train loss {'Reaction outcome loss': 0.32646357025141304, 'Total loss': 0.32646357025141304}
2022-12-31 09:53:25,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:25,975 INFO:     Epoch: 42
2022-12-31 09:53:27,633 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4070124049981435, 'Total loss': 0.4070124049981435} | train loss {'Reaction outcome loss': 0.31605094878772355, 'Total loss': 0.31605094878772355}
2022-12-31 09:53:27,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:27,633 INFO:     Epoch: 43
2022-12-31 09:53:29,229 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.36029684394598005, 'Total loss': 0.36029684394598005} | train loss {'Reaction outcome loss': 0.3127099496541896, 'Total loss': 0.3127099496541896}
2022-12-31 09:53:29,230 INFO:     Found new best model at epoch 43
2022-12-31 09:53:29,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:29,231 INFO:     Epoch: 44
2022-12-31 09:53:30,853 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.39919647375742595, 'Total loss': 0.39919647375742595} | train loss {'Reaction outcome loss': 0.3028438882024932, 'Total loss': 0.3028438882024932}
2022-12-31 09:53:30,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:30,853 INFO:     Epoch: 45
2022-12-31 09:53:32,482 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4030908654133479, 'Total loss': 0.4030908654133479} | train loss {'Reaction outcome loss': 0.30145950755779294, 'Total loss': 0.30145950755779294}
2022-12-31 09:53:32,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:32,483 INFO:     Epoch: 46
2022-12-31 09:53:34,070 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.38284086287021635, 'Total loss': 0.38284086287021635} | train loss {'Reaction outcome loss': 0.29714383776772063, 'Total loss': 0.29714383776772063}
2022-12-31 09:53:34,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:34,070 INFO:     Epoch: 47
2022-12-31 09:53:35,706 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4036157007018725, 'Total loss': 0.4036157007018725} | train loss {'Reaction outcome loss': 0.3017135514081388, 'Total loss': 0.3017135514081388}
2022-12-31 09:53:35,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:35,706 INFO:     Epoch: 48
2022-12-31 09:53:37,344 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4066330432891846, 'Total loss': 0.4066330432891846} | train loss {'Reaction outcome loss': 0.33816440101119055, 'Total loss': 0.33816440101119055}
2022-12-31 09:53:37,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:37,345 INFO:     Epoch: 49
2022-12-31 09:53:38,930 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3723699470361074, 'Total loss': 0.3723699470361074} | train loss {'Reaction outcome loss': 0.2993953479437049, 'Total loss': 0.2993953479437049}
2022-12-31 09:53:38,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:38,931 INFO:     Epoch: 50
2022-12-31 09:53:40,518 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41530429224173226, 'Total loss': 0.41530429224173226} | train loss {'Reaction outcome loss': 0.2813596189615951, 'Total loss': 0.2813596189615951}
2022-12-31 09:53:40,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:40,518 INFO:     Epoch: 51
2022-12-31 09:53:42,149 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39022007981936135, 'Total loss': 0.39022007981936135} | train loss {'Reaction outcome loss': 0.2864514561623092, 'Total loss': 0.2864514561623092}
2022-12-31 09:53:42,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:42,149 INFO:     Epoch: 52
2022-12-31 09:53:43,751 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3896699885527293, 'Total loss': 0.3896699885527293} | train loss {'Reaction outcome loss': 0.28143420759000076, 'Total loss': 0.28143420759000076}
2022-12-31 09:53:43,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:43,751 INFO:     Epoch: 53
2022-12-31 09:53:45,354 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38296322226524354, 'Total loss': 0.38296322226524354} | train loss {'Reaction outcome loss': 0.2758794079359243, 'Total loss': 0.2758794079359243}
2022-12-31 09:53:45,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:45,355 INFO:     Epoch: 54
2022-12-31 09:53:46,938 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3771566430727641, 'Total loss': 0.3771566430727641} | train loss {'Reaction outcome loss': 0.27583927995882457, 'Total loss': 0.27583927995882457}
2022-12-31 09:53:46,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:46,938 INFO:     Epoch: 55
2022-12-31 09:53:48,526 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3968019018570582, 'Total loss': 0.3968019018570582} | train loss {'Reaction outcome loss': 0.27557515483040596, 'Total loss': 0.27557515483040596}
2022-12-31 09:53:48,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:48,526 INFO:     Epoch: 56
2022-12-31 09:53:50,129 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.36842684348424276, 'Total loss': 0.36842684348424276} | train loss {'Reaction outcome loss': 0.2779159757639349, 'Total loss': 0.2779159757639349}
2022-12-31 09:53:50,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:50,129 INFO:     Epoch: 57
2022-12-31 09:53:51,734 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3765462915102641, 'Total loss': 0.3765462915102641} | train loss {'Reaction outcome loss': 0.27256429654168995, 'Total loss': 0.27256429654168995}
2022-12-31 09:53:51,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:51,736 INFO:     Epoch: 58
2022-12-31 09:53:53,355 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.37040081024169924, 'Total loss': 0.37040081024169924} | train loss {'Reaction outcome loss': 0.26697912503479293, 'Total loss': 0.26697912503479293}
2022-12-31 09:53:53,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:53,356 INFO:     Epoch: 59
2022-12-31 09:53:55,004 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3679689606030782, 'Total loss': 0.3679689606030782} | train loss {'Reaction outcome loss': 0.2754414500668645, 'Total loss': 0.2754414500668645}
2022-12-31 09:53:55,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:55,004 INFO:     Epoch: 60
2022-12-31 09:53:56,579 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3693675950169563, 'Total loss': 0.3693675950169563} | train loss {'Reaction outcome loss': 0.26743444950704504, 'Total loss': 0.26743444950704504}
2022-12-31 09:53:56,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:56,580 INFO:     Epoch: 61
2022-12-31 09:53:58,189 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3587509979804357, 'Total loss': 0.3587509979804357} | train loss {'Reaction outcome loss': 0.2594065946877759, 'Total loss': 0.2594065946877759}
2022-12-31 09:53:58,190 INFO:     Found new best model at epoch 61
2022-12-31 09:53:58,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:58,191 INFO:     Epoch: 62
2022-12-31 09:53:59,798 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3502952555815379, 'Total loss': 0.3502952555815379} | train loss {'Reaction outcome loss': 0.2556125410485855, 'Total loss': 0.2556125410485855}
2022-12-31 09:53:59,798 INFO:     Found new best model at epoch 62
2022-12-31 09:53:59,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:53:59,799 INFO:     Epoch: 63
2022-12-31 09:54:01,407 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.34457037448883054, 'Total loss': 0.34457037448883054} | train loss {'Reaction outcome loss': 0.25716709243027686, 'Total loss': 0.25716709243027686}
2022-12-31 09:54:01,407 INFO:     Found new best model at epoch 63
2022-12-31 09:54:01,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:01,408 INFO:     Epoch: 64
2022-12-31 09:54:03,016 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3728839248418808, 'Total loss': 0.3728839248418808} | train loss {'Reaction outcome loss': 0.25013341852868703, 'Total loss': 0.25013341852868703}
2022-12-31 09:54:03,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:03,018 INFO:     Epoch: 65
2022-12-31 09:54:04,605 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40500566860040027, 'Total loss': 0.40500566860040027} | train loss {'Reaction outcome loss': 0.2535482862402442, 'Total loss': 0.2535482862402442}
2022-12-31 09:54:04,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:04,606 INFO:     Epoch: 66
2022-12-31 09:54:06,211 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.37414201299349464, 'Total loss': 0.37414201299349464} | train loss {'Reaction outcome loss': 0.2686240012096106, 'Total loss': 0.2686240012096106}
2022-12-31 09:54:06,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:06,212 INFO:     Epoch: 67
2022-12-31 09:54:07,834 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4221864968538284, 'Total loss': 0.4221864968538284} | train loss {'Reaction outcome loss': 0.3008260702093442, 'Total loss': 0.3008260702093442}
2022-12-31 09:54:07,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:07,834 INFO:     Epoch: 68
2022-12-31 09:54:09,441 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3756235927343369, 'Total loss': 0.3756235927343369} | train loss {'Reaction outcome loss': 0.26439337726839335, 'Total loss': 0.26439337726839335}
2022-12-31 09:54:09,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:09,442 INFO:     Epoch: 69
2022-12-31 09:54:11,046 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.34992729425430297, 'Total loss': 0.34992729425430297} | train loss {'Reaction outcome loss': 0.25076392953591153, 'Total loss': 0.25076392953591153}
2022-12-31 09:54:11,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:11,046 INFO:     Epoch: 70
2022-12-31 09:54:12,652 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.35500325212876, 'Total loss': 0.35500325212876} | train loss {'Reaction outcome loss': 0.262140517042059, 'Total loss': 0.262140517042059}
2022-12-31 09:54:12,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:12,653 INFO:     Epoch: 71
2022-12-31 09:54:14,266 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.37350097894668577, 'Total loss': 0.37350097894668577} | train loss {'Reaction outcome loss': 0.3079298112635919, 'Total loss': 0.3079298112635919}
2022-12-31 09:54:14,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:14,267 INFO:     Epoch: 72
2022-12-31 09:54:15,874 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3639354149500529, 'Total loss': 0.3639354149500529} | train loss {'Reaction outcome loss': 0.26833930434794095, 'Total loss': 0.26833930434794095}
2022-12-31 09:54:15,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:15,874 INFO:     Epoch: 73
2022-12-31 09:54:17,483 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3984419385592143, 'Total loss': 0.3984419385592143} | train loss {'Reaction outcome loss': 0.25522853071005014, 'Total loss': 0.25522853071005014}
2022-12-31 09:54:17,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:17,484 INFO:     Epoch: 74
2022-12-31 09:54:19,092 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3399682993690173, 'Total loss': 0.3399682993690173} | train loss {'Reaction outcome loss': 0.28309532521002373, 'Total loss': 0.28309532521002373}
2022-12-31 09:54:19,092 INFO:     Found new best model at epoch 74
2022-12-31 09:54:19,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:19,093 INFO:     Epoch: 75
2022-12-31 09:54:20,703 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3627550317595402, 'Total loss': 0.3627550317595402} | train loss {'Reaction outcome loss': 0.2562086151497763, 'Total loss': 0.2562086151497763}
2022-12-31 09:54:20,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:20,704 INFO:     Epoch: 76
2022-12-31 09:54:22,300 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39860781729221345, 'Total loss': 0.39860781729221345} | train loss {'Reaction outcome loss': 0.2513902299224224, 'Total loss': 0.2513902299224224}
2022-12-31 09:54:22,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:22,300 INFO:     Epoch: 77
2022-12-31 09:54:23,869 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.36220381955305736, 'Total loss': 0.36220381955305736} | train loss {'Reaction outcome loss': 0.2583282876867747, 'Total loss': 0.2583282876867747}
2022-12-31 09:54:23,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:23,869 INFO:     Epoch: 78
2022-12-31 09:54:25,459 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39089309573173525, 'Total loss': 0.39089309573173525} | train loss {'Reaction outcome loss': 0.2688557464970327, 'Total loss': 0.2688557464970327}
2022-12-31 09:54:25,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:25,459 INFO:     Epoch: 79
2022-12-31 09:54:27,085 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3776819944381714, 'Total loss': 0.3776819944381714} | train loss {'Reaction outcome loss': 0.25284701345536514, 'Total loss': 0.25284701345536514}
2022-12-31 09:54:27,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:27,086 INFO:     Epoch: 80
2022-12-31 09:54:28,694 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.34143400688966113, 'Total loss': 0.34143400688966113} | train loss {'Reaction outcome loss': 0.24623187749724215, 'Total loss': 0.24623187749724215}
2022-12-31 09:54:28,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:28,694 INFO:     Epoch: 81
2022-12-31 09:54:30,300 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40025556534528733, 'Total loss': 0.40025556534528733} | train loss {'Reaction outcome loss': 0.24497945738116012, 'Total loss': 0.24497945738116012}
2022-12-31 09:54:30,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:30,300 INFO:     Epoch: 82
2022-12-31 09:54:31,888 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3517872671286265, 'Total loss': 0.3517872671286265} | train loss {'Reaction outcome loss': 0.2372741730566528, 'Total loss': 0.2372741730566528}
2022-12-31 09:54:31,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:31,889 INFO:     Epoch: 83
2022-12-31 09:54:33,533 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3780941694974899, 'Total loss': 0.3780941694974899} | train loss {'Reaction outcome loss': 0.24228092482097555, 'Total loss': 0.24228092482097555}
2022-12-31 09:54:33,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:33,533 INFO:     Epoch: 84
2022-12-31 09:54:35,183 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.36446588337421415, 'Total loss': 0.36446588337421415} | train loss {'Reaction outcome loss': 0.22974001042598832, 'Total loss': 0.22974001042598832}
2022-12-31 09:54:35,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:35,183 INFO:     Epoch: 85
2022-12-31 09:54:36,793 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3763831302523613, 'Total loss': 0.3763831302523613} | train loss {'Reaction outcome loss': 0.23138656132199475, 'Total loss': 0.23138656132199475}
2022-12-31 09:54:36,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:36,794 INFO:     Epoch: 86
2022-12-31 09:54:38,400 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.36636067777872083, 'Total loss': 0.36636067777872083} | train loss {'Reaction outcome loss': 0.23826293862404543, 'Total loss': 0.23826293862404543}
2022-12-31 09:54:38,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:38,400 INFO:     Epoch: 87
2022-12-31 09:54:40,005 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3497062362730503, 'Total loss': 0.3497062362730503} | train loss {'Reaction outcome loss': 0.24779881134062356, 'Total loss': 0.24779881134062356}
2022-12-31 09:54:40,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:40,007 INFO:     Epoch: 88
2022-12-31 09:54:41,584 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.35013304352760316, 'Total loss': 0.35013304352760316} | train loss {'Reaction outcome loss': 0.24211671524398812, 'Total loss': 0.24211671524398812}
2022-12-31 09:54:41,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:41,585 INFO:     Epoch: 89
2022-12-31 09:54:43,223 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3946456968784332, 'Total loss': 0.3946456968784332} | train loss {'Reaction outcome loss': 0.2330691026037802, 'Total loss': 0.2330691026037802}
2022-12-31 09:54:43,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:43,223 INFO:     Epoch: 90
2022-12-31 09:54:44,873 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.39678185284137724, 'Total loss': 0.39678185284137724} | train loss {'Reaction outcome loss': 0.2640643947850918, 'Total loss': 0.2640643947850918}
2022-12-31 09:54:44,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:44,874 INFO:     Epoch: 91
2022-12-31 09:54:46,466 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.36910390506188073, 'Total loss': 0.36910390506188073} | train loss {'Reaction outcome loss': 0.23058965693707106, 'Total loss': 0.23058965693707106}
2022-12-31 09:54:46,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:46,466 INFO:     Epoch: 92
2022-12-31 09:54:48,099 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4190053443113963, 'Total loss': 0.4190053443113963} | train loss {'Reaction outcome loss': 0.21956577503284358, 'Total loss': 0.21956577503284358}
2022-12-31 09:54:48,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:48,099 INFO:     Epoch: 93
2022-12-31 09:54:49,644 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.37591420908768974, 'Total loss': 0.37591420908768974} | train loss {'Reaction outcome loss': 0.23216073630053713, 'Total loss': 0.23216073630053713}
2022-12-31 09:54:49,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:49,644 INFO:     Epoch: 94
2022-12-31 09:54:50,760 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3812131881713867, 'Total loss': 0.3812131881713867} | train loss {'Reaction outcome loss': 0.22928838660152615, 'Total loss': 0.22928838660152615}
2022-12-31 09:54:50,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:50,760 INFO:     Epoch: 95
2022-12-31 09:54:51,875 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3811112662156423, 'Total loss': 0.3811112662156423} | train loss {'Reaction outcome loss': 0.22702611881591703, 'Total loss': 0.22702611881591703}
2022-12-31 09:54:51,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:51,876 INFO:     Epoch: 96
2022-12-31 09:54:52,987 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3799663931131363, 'Total loss': 0.3799663931131363} | train loss {'Reaction outcome loss': 0.22967725334203112, 'Total loss': 0.22967725334203112}
2022-12-31 09:54:52,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:52,987 INFO:     Epoch: 97
2022-12-31 09:54:54,118 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3758910228808721, 'Total loss': 0.3758910228808721} | train loss {'Reaction outcome loss': 0.2558442505071888, 'Total loss': 0.2558442505071888}
2022-12-31 09:54:54,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:54,119 INFO:     Epoch: 98
2022-12-31 09:54:55,715 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3910456160704295, 'Total loss': 0.3910456160704295} | train loss {'Reaction outcome loss': 0.21665579912023267, 'Total loss': 0.21665579912023267}
2022-12-31 09:54:55,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:55,715 INFO:     Epoch: 99
2022-12-31 09:54:57,319 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3678877626856168, 'Total loss': 0.3678877626856168} | train loss {'Reaction outcome loss': 0.22486365198679065, 'Total loss': 0.22486365198679065}
2022-12-31 09:54:57,319 INFO:     Best model found after epoch 75 of 100.
2022-12-31 09:54:57,319 INFO:   Done with stage: TRAINING
2022-12-31 09:54:57,319 INFO:   Starting stage: EVALUATION
2022-12-31 09:54:57,446 INFO:   Done with stage: EVALUATION
2022-12-31 09:54:57,446 INFO:   Leaving out SEQ value Fold_9
2022-12-31 09:54:57,459 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 09:54:57,459 INFO:   Starting stage: FEATURE SCALING
2022-12-31 09:54:58,113 INFO:   Done with stage: FEATURE SCALING
2022-12-31 09:54:58,114 INFO:   Starting stage: SCALING TARGETS
2022-12-31 09:54:58,184 INFO:   Done with stage: SCALING TARGETS
2022-12-31 09:54:58,184 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:54:58,184 INFO:     No hyperparam tuning for this model
2022-12-31 09:54:58,184 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:54:58,184 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 09:54:58,185 INFO:     None feature selector for col prot
2022-12-31 09:54:58,185 INFO:     None feature selector for col prot
2022-12-31 09:54:58,185 INFO:     None feature selector for col prot
2022-12-31 09:54:58,186 INFO:     None feature selector for col chem
2022-12-31 09:54:58,186 INFO:     None feature selector for col chem
2022-12-31 09:54:58,186 INFO:     None feature selector for col chem
2022-12-31 09:54:58,186 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 09:54:58,186 INFO:   Starting stage: BUILD MODEL
2022-12-31 09:54:58,188 INFO:     Number of params in model 223921
2022-12-31 09:54:58,191 INFO:   Done with stage: BUILD MODEL
2022-12-31 09:54:58,191 INFO:   Starting stage: TRAINING
2022-12-31 09:54:58,234 INFO:     Val loss before train {'Reaction outcome loss': 1.021845038731893, 'Total loss': 1.021845038731893}
2022-12-31 09:54:58,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:58,234 INFO:     Epoch: 0
2022-12-31 09:54:59,881 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.700274384021759, 'Total loss': 0.700274384021759} | train loss {'Reaction outcome loss': 0.8064539607011534, 'Total loss': 0.8064539607011534}
2022-12-31 09:54:59,881 INFO:     Found new best model at epoch 0
2022-12-31 09:54:59,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:54:59,882 INFO:     Epoch: 1
2022-12-31 09:55:01,472 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.555563215414683, 'Total loss': 0.555563215414683} | train loss {'Reaction outcome loss': 0.5946959626989142, 'Total loss': 0.5946959626989142}
2022-12-31 09:55:01,473 INFO:     Found new best model at epoch 1
2022-12-31 09:55:01,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:01,474 INFO:     Epoch: 2
2022-12-31 09:55:03,097 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6464228928089142, 'Total loss': 0.6464228928089142} | train loss {'Reaction outcome loss': 0.5472016610421132, 'Total loss': 0.5472016610421132}
2022-12-31 09:55:03,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:03,097 INFO:     Epoch: 3
2022-12-31 09:55:04,701 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5277961035569508, 'Total loss': 0.5277961035569508} | train loss {'Reaction outcome loss': 0.5503990822741627, 'Total loss': 0.5503990822741627}
2022-12-31 09:55:04,702 INFO:     Found new best model at epoch 3
2022-12-31 09:55:04,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:04,703 INFO:     Epoch: 4
2022-12-31 09:55:06,301 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5172271132469177, 'Total loss': 0.5172271132469177} | train loss {'Reaction outcome loss': 0.5004705264624478, 'Total loss': 0.5004705264624478}
2022-12-31 09:55:06,301 INFO:     Found new best model at epoch 4
2022-12-31 09:55:06,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:06,302 INFO:     Epoch: 5
2022-12-31 09:55:07,896 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5047315080960592, 'Total loss': 0.5047315080960592} | train loss {'Reaction outcome loss': 0.4995896717452485, 'Total loss': 0.4995896717452485}
2022-12-31 09:55:07,896 INFO:     Found new best model at epoch 5
2022-12-31 09:55:07,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:07,897 INFO:     Epoch: 6
2022-12-31 09:55:09,505 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5295904080073038, 'Total loss': 0.5295904080073038} | train loss {'Reaction outcome loss': 0.47435791446638387, 'Total loss': 0.47435791446638387}
2022-12-31 09:55:09,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:09,506 INFO:     Epoch: 7
2022-12-31 09:55:11,114 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5217413564523061, 'Total loss': 0.5217413564523061} | train loss {'Reaction outcome loss': 0.46534131902587, 'Total loss': 0.46534131902587}
2022-12-31 09:55:11,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:11,116 INFO:     Epoch: 8
2022-12-31 09:55:12,707 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5240593214829763, 'Total loss': 0.5240593214829763} | train loss {'Reaction outcome loss': 0.4545769512930048, 'Total loss': 0.4545769512930048}
2022-12-31 09:55:12,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:12,708 INFO:     Epoch: 9
2022-12-31 09:55:14,372 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5187210450569789, 'Total loss': 0.5187210450569789} | train loss {'Reaction outcome loss': 0.44951376102972723, 'Total loss': 0.44951376102972723}
2022-12-31 09:55:14,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:14,372 INFO:     Epoch: 10
2022-12-31 09:55:16,005 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5279355585575104, 'Total loss': 0.5279355585575104} | train loss {'Reaction outcome loss': 0.44689248079278815, 'Total loss': 0.44689248079278815}
2022-12-31 09:55:16,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:16,005 INFO:     Epoch: 11
2022-12-31 09:55:17,669 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49324616392453513, 'Total loss': 0.49324616392453513} | train loss {'Reaction outcome loss': 0.4414091393304314, 'Total loss': 0.4414091393304314}
2022-12-31 09:55:17,670 INFO:     Found new best model at epoch 11
2022-12-31 09:55:17,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:17,671 INFO:     Epoch: 12
2022-12-31 09:55:19,282 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47970339929064115, 'Total loss': 0.47970339929064115} | train loss {'Reaction outcome loss': 0.43658961547349673, 'Total loss': 0.43658961547349673}
2022-12-31 09:55:19,282 INFO:     Found new best model at epoch 12
2022-12-31 09:55:19,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:19,283 INFO:     Epoch: 13
2022-12-31 09:55:20,879 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5235608140627543, 'Total loss': 0.5235608140627543} | train loss {'Reaction outcome loss': 0.4387667978695337, 'Total loss': 0.4387667978695337}
2022-12-31 09:55:20,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:20,879 INFO:     Epoch: 14
2022-12-31 09:55:22,507 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5003324190775553, 'Total loss': 0.5003324190775553} | train loss {'Reaction outcome loss': 0.42023906126817473, 'Total loss': 0.42023906126817473}
2022-12-31 09:55:22,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:22,509 INFO:     Epoch: 15
2022-12-31 09:55:24,138 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5151501297950745, 'Total loss': 0.5151501297950745} | train loss {'Reaction outcome loss': 0.42731624317989836, 'Total loss': 0.42731624317989836}
2022-12-31 09:55:24,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:24,138 INFO:     Epoch: 16
2022-12-31 09:55:25,736 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4949554741382599, 'Total loss': 0.4949554741382599} | train loss {'Reaction outcome loss': 0.4297742367118084, 'Total loss': 0.4297742367118084}
2022-12-31 09:55:25,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:25,737 INFO:     Epoch: 17
2022-12-31 09:55:27,344 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5081283132235209, 'Total loss': 0.5081283132235209} | train loss {'Reaction outcome loss': 0.41467697702456213, 'Total loss': 0.41467697702456213}
2022-12-31 09:55:27,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:27,344 INFO:     Epoch: 18
2022-12-31 09:55:28,952 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48642151554425556, 'Total loss': 0.48642151554425556} | train loss {'Reaction outcome loss': 0.41452210769057274, 'Total loss': 0.41452210769057274}
2022-12-31 09:55:28,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:28,952 INFO:     Epoch: 19
2022-12-31 09:55:30,544 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46413647532463076, 'Total loss': 0.46413647532463076} | train loss {'Reaction outcome loss': 0.40176626092221157, 'Total loss': 0.40176626092221157}
2022-12-31 09:55:30,545 INFO:     Found new best model at epoch 19
2022-12-31 09:55:30,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:30,546 INFO:     Epoch: 20
2022-12-31 09:55:32,154 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4690892418225606, 'Total loss': 0.4690892418225606} | train loss {'Reaction outcome loss': 0.3912326081027867, 'Total loss': 0.3912326081027867}
2022-12-31 09:55:32,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:32,154 INFO:     Epoch: 21
2022-12-31 09:55:33,742 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4926404078801473, 'Total loss': 0.4926404078801473} | train loss {'Reaction outcome loss': 0.3909017247134361, 'Total loss': 0.3909017247134361}
2022-12-31 09:55:33,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:33,742 INFO:     Epoch: 22
2022-12-31 09:55:35,396 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47907119592030845, 'Total loss': 0.47907119592030845} | train loss {'Reaction outcome loss': 0.3910298954843724, 'Total loss': 0.3910298954843724}
2022-12-31 09:55:35,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:35,396 INFO:     Epoch: 23
2022-12-31 09:55:37,047 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.484647003809611, 'Total loss': 0.484647003809611} | train loss {'Reaction outcome loss': 0.38134109464632615, 'Total loss': 0.38134109464632615}
2022-12-31 09:55:37,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:37,048 INFO:     Epoch: 24
2022-12-31 09:55:38,698 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4741703470547994, 'Total loss': 0.4741703470547994} | train loss {'Reaction outcome loss': 0.37434981722870597, 'Total loss': 0.37434981722870597}
2022-12-31 09:55:38,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:38,698 INFO:     Epoch: 25
2022-12-31 09:55:40,292 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5229523201783498, 'Total loss': 0.5229523201783498} | train loss {'Reaction outcome loss': 0.36825155430267553, 'Total loss': 0.36825155430267553}
2022-12-31 09:55:40,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:40,292 INFO:     Epoch: 26
2022-12-31 09:55:41,925 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45230648616949715, 'Total loss': 0.45230648616949715} | train loss {'Reaction outcome loss': 0.3622998406924349, 'Total loss': 0.3622998406924349}
2022-12-31 09:55:41,927 INFO:     Found new best model at epoch 26
2022-12-31 09:55:41,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:41,928 INFO:     Epoch: 27
2022-12-31 09:55:43,528 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4530204474925995, 'Total loss': 0.4530204474925995} | train loss {'Reaction outcome loss': 0.35247833336082596, 'Total loss': 0.35247833336082596}
2022-12-31 09:55:43,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:43,528 INFO:     Epoch: 28
2022-12-31 09:55:45,137 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4836247424284617, 'Total loss': 0.4836247424284617} | train loss {'Reaction outcome loss': 0.348343386605004, 'Total loss': 0.348343386605004}
2022-12-31 09:55:45,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:45,137 INFO:     Epoch: 29
2022-12-31 09:55:46,745 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.507543999950091, 'Total loss': 0.507543999950091} | train loss {'Reaction outcome loss': 0.3386245832839252, 'Total loss': 0.3386245832839252}
2022-12-31 09:55:46,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:46,745 INFO:     Epoch: 30
2022-12-31 09:55:48,340 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4818556785583496, 'Total loss': 0.4818556785583496} | train loss {'Reaction outcome loss': 0.34630760192732746, 'Total loss': 0.34630760192732746}
2022-12-31 09:55:48,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:48,342 INFO:     Epoch: 31
2022-12-31 09:55:49,939 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47210214932759603, 'Total loss': 0.47210214932759603} | train loss {'Reaction outcome loss': 0.3379841144179817, 'Total loss': 0.3379841144179817}
2022-12-31 09:55:49,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:49,939 INFO:     Epoch: 32
2022-12-31 09:55:51,579 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4412492881218592, 'Total loss': 0.4412492881218592} | train loss {'Reaction outcome loss': 0.3362161966152084, 'Total loss': 0.3362161966152084}
2022-12-31 09:55:51,579 INFO:     Found new best model at epoch 32
2022-12-31 09:55:51,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:51,580 INFO:     Epoch: 33
2022-12-31 09:55:53,181 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46190740366776784, 'Total loss': 0.46190740366776784} | train loss {'Reaction outcome loss': 0.3295608884452478, 'Total loss': 0.3295608884452478}
2022-12-31 09:55:53,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:53,182 INFO:     Epoch: 34
2022-12-31 09:55:54,766 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.49625337322553, 'Total loss': 0.49625337322553} | train loss {'Reaction outcome loss': 0.396088922365933, 'Total loss': 0.396088922365933}
2022-12-31 09:55:54,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:54,766 INFO:     Epoch: 35
2022-12-31 09:55:56,397 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.456422883272171, 'Total loss': 0.456422883272171} | train loss {'Reaction outcome loss': 0.3322104823900441, 'Total loss': 0.3322104823900441}
2022-12-31 09:55:56,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:56,398 INFO:     Epoch: 36
2022-12-31 09:55:57,998 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43695631325244905, 'Total loss': 0.43695631325244905} | train loss {'Reaction outcome loss': 0.3232363489881644, 'Total loss': 0.3232363489881644}
2022-12-31 09:55:57,998 INFO:     Found new best model at epoch 36
2022-12-31 09:55:57,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:57,999 INFO:     Epoch: 37
2022-12-31 09:55:59,603 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4501080632209778, 'Total loss': 0.4501080632209778} | train loss {'Reaction outcome loss': 0.31630257665571093, 'Total loss': 0.31630257665571093}
2022-12-31 09:55:59,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:55:59,603 INFO:     Epoch: 38
2022-12-31 09:56:01,241 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42506407101949056, 'Total loss': 0.42506407101949056} | train loss {'Reaction outcome loss': 0.3140552243558636, 'Total loss': 0.3140552243558636}
2022-12-31 09:56:01,242 INFO:     Found new best model at epoch 38
2022-12-31 09:56:01,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:01,244 INFO:     Epoch: 39
2022-12-31 09:56:02,907 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4409302413463593, 'Total loss': 0.4409302413463593} | train loss {'Reaction outcome loss': 0.30691271043737733, 'Total loss': 0.30691271043737733}
2022-12-31 09:56:02,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:02,907 INFO:     Epoch: 40
2022-12-31 09:56:04,528 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5131231546401978, 'Total loss': 0.5131231546401978} | train loss {'Reaction outcome loss': 0.30640892104070255, 'Total loss': 0.30640892104070255}
2022-12-31 09:56:04,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:04,528 INFO:     Epoch: 41
2022-12-31 09:56:06,122 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4667320857445399, 'Total loss': 0.4667320857445399} | train loss {'Reaction outcome loss': 0.32154550346498634, 'Total loss': 0.32154550346498634}
2022-12-31 09:56:06,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:06,124 INFO:     Epoch: 42
2022-12-31 09:56:07,767 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44503935078779855, 'Total loss': 0.44503935078779855} | train loss {'Reaction outcome loss': 0.2971906006695581, 'Total loss': 0.2971906006695581}
2022-12-31 09:56:07,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:07,767 INFO:     Epoch: 43
2022-12-31 09:56:09,434 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4326300005118052, 'Total loss': 0.4326300005118052} | train loss {'Reaction outcome loss': 0.28793196985919867, 'Total loss': 0.28793196985919867}
2022-12-31 09:56:09,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:09,434 INFO:     Epoch: 44
2022-12-31 09:56:11,061 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.47281033794085187, 'Total loss': 0.47281033794085187} | train loss {'Reaction outcome loss': 0.2842351923329419, 'Total loss': 0.2842351923329419}
2022-12-31 09:56:11,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:11,061 INFO:     Epoch: 45
2022-12-31 09:56:12,702 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4443051298459371, 'Total loss': 0.4443051298459371} | train loss {'Reaction outcome loss': 0.28592824622772745, 'Total loss': 0.28592824622772745}
2022-12-31 09:56:12,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:12,703 INFO:     Epoch: 46
2022-12-31 09:56:14,374 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4788279891014099, 'Total loss': 0.4788279891014099} | train loss {'Reaction outcome loss': 0.2842950609979132, 'Total loss': 0.2842950609979132}
2022-12-31 09:56:14,375 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:14,375 INFO:     Epoch: 47
2022-12-31 09:56:15,992 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.45282203555107114, 'Total loss': 0.45282203555107114} | train loss {'Reaction outcome loss': 0.2803998475479286, 'Total loss': 0.2803998475479286}
2022-12-31 09:56:15,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:15,992 INFO:     Epoch: 48
2022-12-31 09:56:17,600 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45914488335450493, 'Total loss': 0.45914488335450493} | train loss {'Reaction outcome loss': 0.27542249779081973, 'Total loss': 0.27542249779081973}
2022-12-31 09:56:17,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:17,601 INFO:     Epoch: 49
2022-12-31 09:56:19,208 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45534441868464154, 'Total loss': 0.45534441868464154} | train loss {'Reaction outcome loss': 0.2820131898827284, 'Total loss': 0.2820131898827284}
2022-12-31 09:56:19,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:19,208 INFO:     Epoch: 50
2022-12-31 09:56:20,809 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4710649748643239, 'Total loss': 0.4710649748643239} | train loss {'Reaction outcome loss': 0.27564546705727244, 'Total loss': 0.27564546705727244}
2022-12-31 09:56:20,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:20,809 INFO:     Epoch: 51
2022-12-31 09:56:22,417 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4686663309733073, 'Total loss': 0.4686663309733073} | train loss {'Reaction outcome loss': 0.26966109785480774, 'Total loss': 0.26966109785480774}
2022-12-31 09:56:22,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:22,418 INFO:     Epoch: 52
2022-12-31 09:56:24,025 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4733466664950053, 'Total loss': 0.4733466664950053} | train loss {'Reaction outcome loss': 0.2720403639680665, 'Total loss': 0.2720403639680665}
2022-12-31 09:56:24,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:24,027 INFO:     Epoch: 53
2022-12-31 09:56:25,613 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43010053237279255, 'Total loss': 0.43010053237279255} | train loss {'Reaction outcome loss': 0.3116611648738992, 'Total loss': 0.3116611648738992}
2022-12-31 09:56:25,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:25,613 INFO:     Epoch: 54
2022-12-31 09:56:27,222 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43364629745483396, 'Total loss': 0.43364629745483396} | train loss {'Reaction outcome loss': 0.2753626618541075, 'Total loss': 0.2753626618541075}
2022-12-31 09:56:27,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:27,222 INFO:     Epoch: 55
2022-12-31 09:56:28,809 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42780107955137886, 'Total loss': 0.42780107955137886} | train loss {'Reaction outcome loss': 0.2699262414884736, 'Total loss': 0.2699262414884736}
2022-12-31 09:56:28,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:28,809 INFO:     Epoch: 56
2022-12-31 09:56:30,418 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4640608678261439, 'Total loss': 0.4640608678261439} | train loss {'Reaction outcome loss': 0.2673560671086096, 'Total loss': 0.2673560671086096}
2022-12-31 09:56:30,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:30,419 INFO:     Epoch: 57
2022-12-31 09:56:32,028 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44814336597919463, 'Total loss': 0.44814336597919463} | train loss {'Reaction outcome loss': 0.2659515113822029, 'Total loss': 0.2659515113822029}
2022-12-31 09:56:32,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:32,028 INFO:     Epoch: 58
2022-12-31 09:56:33,616 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.44973640938599907, 'Total loss': 0.44973640938599907} | train loss {'Reaction outcome loss': 0.25963173440549575, 'Total loss': 0.25963173440549575}
2022-12-31 09:56:33,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:33,617 INFO:     Epoch: 59
2022-12-31 09:56:35,277 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4672716915607452, 'Total loss': 0.4672716915607452} | train loss {'Reaction outcome loss': 0.25670480846251914, 'Total loss': 0.25670480846251914}
2022-12-31 09:56:35,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:35,278 INFO:     Epoch: 60
2022-12-31 09:56:36,888 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45804910858472186, 'Total loss': 0.45804910858472186} | train loss {'Reaction outcome loss': 0.2534436038931481, 'Total loss': 0.2534436038931481}
2022-12-31 09:56:36,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:36,890 INFO:     Epoch: 61
2022-12-31 09:56:38,519 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4636167864004771, 'Total loss': 0.4636167864004771} | train loss {'Reaction outcome loss': 0.2561710445097824, 'Total loss': 0.2561710445097824}
2022-12-31 09:56:38,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:38,519 INFO:     Epoch: 62
2022-12-31 09:56:40,131 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5124569535255432, 'Total loss': 0.5124569535255432} | train loss {'Reaction outcome loss': 0.25633612788110244, 'Total loss': 0.25633612788110244}
2022-12-31 09:56:40,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:40,131 INFO:     Epoch: 63
2022-12-31 09:56:41,768 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4400305380423864, 'Total loss': 0.4400305380423864} | train loss {'Reaction outcome loss': 0.2720993336668049, 'Total loss': 0.2720993336668049}
2022-12-31 09:56:41,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:41,769 INFO:     Epoch: 64
2022-12-31 09:56:43,371 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4215615103642146, 'Total loss': 0.4215615103642146} | train loss {'Reaction outcome loss': 0.2833484450247193, 'Total loss': 0.2833484450247193}
2022-12-31 09:56:43,371 INFO:     Found new best model at epoch 64
2022-12-31 09:56:43,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:43,372 INFO:     Epoch: 65
2022-12-31 09:56:44,984 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4461435635884603, 'Total loss': 0.4461435635884603} | train loss {'Reaction outcome loss': 0.2538413468586362, 'Total loss': 0.2538413468586362}
2022-12-31 09:56:44,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:44,984 INFO:     Epoch: 66
2022-12-31 09:56:46,592 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4361446792880694, 'Total loss': 0.4361446792880694} | train loss {'Reaction outcome loss': 0.2442182781335799, 'Total loss': 0.2442182781335799}
2022-12-31 09:56:46,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:46,592 INFO:     Epoch: 67
2022-12-31 09:56:48,199 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43655180633068086, 'Total loss': 0.43655180633068086} | train loss {'Reaction outcome loss': 0.24342388181851113, 'Total loss': 0.24342388181851113}
2022-12-31 09:56:48,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:48,199 INFO:     Epoch: 68
2022-12-31 09:56:49,806 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46761266589164735, 'Total loss': 0.46761266589164735} | train loss {'Reaction outcome loss': 0.24201520215854913, 'Total loss': 0.24201520215854913}
2022-12-31 09:56:49,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:49,808 INFO:     Epoch: 69
2022-12-31 09:56:51,405 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4964223603407542, 'Total loss': 0.4964223603407542} | train loss {'Reaction outcome loss': 0.2435347106631683, 'Total loss': 0.2435347106631683}
2022-12-31 09:56:51,405 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:51,405 INFO:     Epoch: 70
2022-12-31 09:56:53,027 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4571511894464493, 'Total loss': 0.4571511894464493} | train loss {'Reaction outcome loss': 0.2411146129336397, 'Total loss': 0.2411146129336397}
2022-12-31 09:56:53,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:53,027 INFO:     Epoch: 71
2022-12-31 09:56:54,698 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4629055082798004, 'Total loss': 0.4629055082798004} | train loss {'Reaction outcome loss': 0.24369600091101704, 'Total loss': 0.24369600091101704}
2022-12-31 09:56:54,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:54,699 INFO:     Epoch: 72
2022-12-31 09:56:56,301 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4773111194372177, 'Total loss': 0.4773111194372177} | train loss {'Reaction outcome loss': 0.2425883738728969, 'Total loss': 0.2425883738728969}
2022-12-31 09:56:56,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:56,302 INFO:     Epoch: 73
2022-12-31 09:56:57,911 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46168868939081825, 'Total loss': 0.46168868939081825} | train loss {'Reaction outcome loss': 0.23895677092756765, 'Total loss': 0.23895677092756765}
2022-12-31 09:56:57,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:57,911 INFO:     Epoch: 74
2022-12-31 09:56:59,521 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4454838444789251, 'Total loss': 0.4454838444789251} | train loss {'Reaction outcome loss': 0.22884466339475193, 'Total loss': 0.22884466339475193}
2022-12-31 09:56:59,521 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:56:59,521 INFO:     Epoch: 75
2022-12-31 09:57:01,125 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.46337694227695464, 'Total loss': 0.46337694227695464} | train loss {'Reaction outcome loss': 0.2338482323022512, 'Total loss': 0.2338482323022512}
2022-12-31 09:57:01,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:01,125 INFO:     Epoch: 76
2022-12-31 09:57:02,757 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.47002275586128234, 'Total loss': 0.47002275586128234} | train loss {'Reaction outcome loss': 0.2297953343616994, 'Total loss': 0.2297953343616994}
2022-12-31 09:57:02,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:02,759 INFO:     Epoch: 77
2022-12-31 09:57:04,360 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.49447493304808937, 'Total loss': 0.49447493304808937} | train loss {'Reaction outcome loss': 0.23099360317734163, 'Total loss': 0.23099360317734163}
2022-12-31 09:57:04,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:04,360 INFO:     Epoch: 78
2022-12-31 09:57:05,954 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4768589695294698, 'Total loss': 0.4768589695294698} | train loss {'Reaction outcome loss': 0.23176195593618287, 'Total loss': 0.23176195593618287}
2022-12-31 09:57:05,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:05,954 INFO:     Epoch: 79
2022-12-31 09:57:07,565 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45143465598424276, 'Total loss': 0.45143465598424276} | train loss {'Reaction outcome loss': 0.22578926419879755, 'Total loss': 0.22578926419879755}
2022-12-31 09:57:07,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:07,565 INFO:     Epoch: 80
2022-12-31 09:57:09,180 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43288579682509104, 'Total loss': 0.43288579682509104} | train loss {'Reaction outcome loss': 0.22526941367465517, 'Total loss': 0.22526941367465517}
2022-12-31 09:57:09,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:09,181 INFO:     Epoch: 81
2022-12-31 09:57:10,791 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4670664111773173, 'Total loss': 0.4670664111773173} | train loss {'Reaction outcome loss': 0.221535453626859, 'Total loss': 0.221535453626859}
2022-12-31 09:57:10,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:10,791 INFO:     Epoch: 82
2022-12-31 09:57:12,418 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4712997665007909, 'Total loss': 0.4712997665007909} | train loss {'Reaction outcome loss': 0.23256491080594613, 'Total loss': 0.23256491080594613}
2022-12-31 09:57:12,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:12,419 INFO:     Epoch: 83
2022-12-31 09:57:14,011 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4826416879892349, 'Total loss': 0.4826416879892349} | train loss {'Reaction outcome loss': 0.2200814227591592, 'Total loss': 0.2200814227591592}
2022-12-31 09:57:14,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:14,012 INFO:     Epoch: 84
2022-12-31 09:57:15,632 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49520143270492556, 'Total loss': 0.49520143270492556} | train loss {'Reaction outcome loss': 0.2288092366129538, 'Total loss': 0.2288092366129538}
2022-12-31 09:57:15,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:15,633 INFO:     Epoch: 85
2022-12-31 09:57:17,250 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4677600423494975, 'Total loss': 0.4677600423494975} | train loss {'Reaction outcome loss': 0.21572701777399017, 'Total loss': 0.21572701777399017}
2022-12-31 09:57:17,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:17,250 INFO:     Epoch: 86
2022-12-31 09:57:18,846 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.521897828578949, 'Total loss': 0.521897828578949} | train loss {'Reaction outcome loss': 0.21919454196198046, 'Total loss': 0.21919454196198046}
2022-12-31 09:57:18,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:18,846 INFO:     Epoch: 87
2022-12-31 09:57:20,460 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4389786352713903, 'Total loss': 0.4389786352713903} | train loss {'Reaction outcome loss': 0.26269945573395764, 'Total loss': 0.26269945573395764}
2022-12-31 09:57:20,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:20,460 INFO:     Epoch: 88
2022-12-31 09:57:22,073 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46312151849269867, 'Total loss': 0.46312151849269867} | train loss {'Reaction outcome loss': 0.23014626973578572, 'Total loss': 0.23014626973578572}
2022-12-31 09:57:22,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:22,075 INFO:     Epoch: 89
2022-12-31 09:57:23,686 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4956696033477783, 'Total loss': 0.4956696033477783} | train loss {'Reaction outcome loss': 0.21506468260815673, 'Total loss': 0.21506468260815673}
2022-12-31 09:57:23,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:23,686 INFO:     Epoch: 90
2022-12-31 09:57:25,310 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47048595050970715, 'Total loss': 0.47048595050970715} | train loss {'Reaction outcome loss': 0.21939167591736422, 'Total loss': 0.21939167591736422}
2022-12-31 09:57:25,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:25,310 INFO:     Epoch: 91
2022-12-31 09:57:26,926 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5256618370612463, 'Total loss': 0.5256618370612463} | train loss {'Reaction outcome loss': 0.21483715375939358, 'Total loss': 0.21483715375939358}
2022-12-31 09:57:26,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:26,927 INFO:     Epoch: 92
2022-12-31 09:57:28,522 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4855157564083735, 'Total loss': 0.4855157564083735} | train loss {'Reaction outcome loss': 0.21756147767671896, 'Total loss': 0.21756147767671896}
2022-12-31 09:57:28,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:28,522 INFO:     Epoch: 93
2022-12-31 09:57:30,136 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.491814523935318, 'Total loss': 0.491814523935318} | train loss {'Reaction outcome loss': 0.21290026231334827, 'Total loss': 0.21290026231334827}
2022-12-31 09:57:30,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:30,136 INFO:     Epoch: 94
2022-12-31 09:57:31,727 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4784392029047012, 'Total loss': 0.4784392029047012} | train loss {'Reaction outcome loss': 0.21328699328950135, 'Total loss': 0.21328699328950135}
2022-12-31 09:57:31,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:31,728 INFO:     Epoch: 95
2022-12-31 09:57:33,345 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4633523235718409, 'Total loss': 0.4633523235718409} | train loss {'Reaction outcome loss': 0.2079803310764913, 'Total loss': 0.2079803310764913}
2022-12-31 09:57:33,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:33,346 INFO:     Epoch: 96
2022-12-31 09:57:34,959 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5219389468431472, 'Total loss': 0.5219389468431472} | train loss {'Reaction outcome loss': 0.2089169341826177, 'Total loss': 0.2089169341826177}
2022-12-31 09:57:34,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:34,961 INFO:     Epoch: 97
2022-12-31 09:57:36,569 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4751545409361521, 'Total loss': 0.4751545409361521} | train loss {'Reaction outcome loss': 0.2151987348755727, 'Total loss': 0.2151987348755727}
2022-12-31 09:57:36,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:36,569 INFO:     Epoch: 98
2022-12-31 09:57:38,171 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.45694688459237415, 'Total loss': 0.45694688459237415} | train loss {'Reaction outcome loss': 0.2123123075486441, 'Total loss': 0.2123123075486441}
2022-12-31 09:57:38,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:38,171 INFO:     Epoch: 99
2022-12-31 09:57:39,786 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4410858365396659, 'Total loss': 0.4410858365396659} | train loss {'Reaction outcome loss': 0.21680616097654676, 'Total loss': 0.21680616097654676}
2022-12-31 09:57:39,786 INFO:     Best model found after epoch 65 of 100.
2022-12-31 09:57:39,786 INFO:   Done with stage: TRAINING
2022-12-31 09:57:39,786 INFO:   Starting stage: EVALUATION
2022-12-31 09:57:39,913 INFO:   Done with stage: EVALUATION
2022-12-31 09:57:39,921 INFO:   Leaving out SEQ value Fold_0
2022-12-31 09:57:39,934 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2022-12-31 09:57:39,935 INFO:   Starting stage: FEATURE SCALING
2022-12-31 09:57:40,570 INFO:   Done with stage: FEATURE SCALING
2022-12-31 09:57:40,570 INFO:   Starting stage: SCALING TARGETS
2022-12-31 09:57:40,638 INFO:   Done with stage: SCALING TARGETS
2022-12-31 09:57:40,639 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:57:40,639 INFO:     No hyperparam tuning for this model
2022-12-31 09:57:40,639 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 09:57:40,639 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 09:57:40,639 INFO:     None feature selector for col prot
2022-12-31 09:57:40,640 INFO:     None feature selector for col prot
2022-12-31 09:57:40,640 INFO:     None feature selector for col prot
2022-12-31 09:57:40,640 INFO:     None feature selector for col chem
2022-12-31 09:57:40,640 INFO:     None feature selector for col chem
2022-12-31 09:57:40,640 INFO:     None feature selector for col chem
2022-12-31 09:57:40,640 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 09:57:40,640 INFO:   Starting stage: BUILD MODEL
2022-12-31 09:57:40,642 INFO:     Number of params in model 223921
2022-12-31 09:57:40,645 INFO:   Done with stage: BUILD MODEL
2022-12-31 09:57:40,646 INFO:   Starting stage: TRAINING
2022-12-31 09:57:40,689 INFO:     Val loss before train {'Reaction outcome loss': 0.970547596613566, 'Total loss': 0.970547596613566}
2022-12-31 09:57:40,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:40,690 INFO:     Epoch: 0
2022-12-31 09:57:42,279 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6322399556636811, 'Total loss': 0.6322399556636811} | train loss {'Reaction outcome loss': 0.8142656396895757, 'Total loss': 0.8142656396895757}
2022-12-31 09:57:42,280 INFO:     Found new best model at epoch 0
2022-12-31 09:57:42,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:42,280 INFO:     Epoch: 1
2022-12-31 09:57:43,865 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5591589947541554, 'Total loss': 0.5591589947541554} | train loss {'Reaction outcome loss': 0.5884515689582842, 'Total loss': 0.5884515689582842}
2022-12-31 09:57:43,865 INFO:     Found new best model at epoch 1
2022-12-31 09:57:43,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:43,866 INFO:     Epoch: 2
2022-12-31 09:57:45,440 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5151270012060801, 'Total loss': 0.5151270012060801} | train loss {'Reaction outcome loss': 0.5190324628265142, 'Total loss': 0.5190324628265142}
2022-12-31 09:57:45,440 INFO:     Found new best model at epoch 2
2022-12-31 09:57:45,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:45,441 INFO:     Epoch: 3
2022-12-31 09:57:47,046 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4710026701291402, 'Total loss': 0.4710026701291402} | train loss {'Reaction outcome loss': 0.4944838249155516, 'Total loss': 0.4944838249155516}
2022-12-31 09:57:47,047 INFO:     Found new best model at epoch 3
2022-12-31 09:57:47,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:47,048 INFO:     Epoch: 4
2022-12-31 09:57:48,678 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4874709943930308, 'Total loss': 0.4874709943930308} | train loss {'Reaction outcome loss': 0.47639531848395444, 'Total loss': 0.47639531848395444}
2022-12-31 09:57:48,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:48,678 INFO:     Epoch: 5
2022-12-31 09:57:50,250 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47242919603983563, 'Total loss': 0.47242919603983563} | train loss {'Reaction outcome loss': 0.46770082661586493, 'Total loss': 0.46770082661586493}
2022-12-31 09:57:50,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:50,250 INFO:     Epoch: 6
2022-12-31 09:57:51,836 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4739996631940206, 'Total loss': 0.4739996631940206} | train loss {'Reaction outcome loss': 0.46311059330222354, 'Total loss': 0.46311059330222354}
2022-12-31 09:57:51,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:51,837 INFO:     Epoch: 7
2022-12-31 09:57:53,423 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43600317736466726, 'Total loss': 0.43600317736466726} | train loss {'Reaction outcome loss': 0.45076389577775866, 'Total loss': 0.45076389577775866}
2022-12-31 09:57:53,424 INFO:     Found new best model at epoch 7
2022-12-31 09:57:53,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:53,425 INFO:     Epoch: 8
2022-12-31 09:57:54,994 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46228577693303424, 'Total loss': 0.46228577693303424} | train loss {'Reaction outcome loss': 0.44690373100037944, 'Total loss': 0.44690373100037944}
2022-12-31 09:57:54,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:54,995 INFO:     Epoch: 9
2022-12-31 09:57:56,584 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4809978495041529, 'Total loss': 0.4809978495041529} | train loss {'Reaction outcome loss': 0.4424342853996587, 'Total loss': 0.4424342853996587}
2022-12-31 09:57:56,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:56,584 INFO:     Epoch: 10
2022-12-31 09:57:58,172 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5419889350732168, 'Total loss': 0.5419889350732168} | train loss {'Reaction outcome loss': 0.4337906623843411, 'Total loss': 0.4337906623843411}
2022-12-31 09:57:58,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:58,174 INFO:     Epoch: 11
2022-12-31 09:57:59,741 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4639876266320547, 'Total loss': 0.4639876266320547} | train loss {'Reaction outcome loss': 0.4263096676926331, 'Total loss': 0.4263096676926331}
2022-12-31 09:57:59,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:57:59,741 INFO:     Epoch: 12
2022-12-31 09:58:01,328 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4637929379940033, 'Total loss': 0.4637929379940033} | train loss {'Reaction outcome loss': 0.418428560299627, 'Total loss': 0.418428560299627}
2022-12-31 09:58:01,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:01,328 INFO:     Epoch: 13
2022-12-31 09:58:02,915 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.498774250348409, 'Total loss': 0.498774250348409} | train loss {'Reaction outcome loss': 0.41391383270935816, 'Total loss': 0.41391383270935816}
2022-12-31 09:58:02,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:02,917 INFO:     Epoch: 14
2022-12-31 09:58:04,480 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44896938105424244, 'Total loss': 0.44896938105424244} | train loss {'Reaction outcome loss': 0.41086652858450845, 'Total loss': 0.41086652858450845}
2022-12-31 09:58:04,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:04,480 INFO:     Epoch: 15
2022-12-31 09:58:06,066 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43575628618709744, 'Total loss': 0.43575628618709744} | train loss {'Reaction outcome loss': 0.4063703435098553, 'Total loss': 0.4063703435098553}
2022-12-31 09:58:06,066 INFO:     Found new best model at epoch 15
2022-12-31 09:58:06,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:06,067 INFO:     Epoch: 16
2022-12-31 09:58:07,630 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48389135400454203, 'Total loss': 0.48389135400454203} | train loss {'Reaction outcome loss': 0.3987571746110916, 'Total loss': 0.3987571746110916}
2022-12-31 09:58:07,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:07,630 INFO:     Epoch: 17
2022-12-31 09:58:09,244 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46689880390961963, 'Total loss': 0.46689880390961963} | train loss {'Reaction outcome loss': 0.39611027617956, 'Total loss': 0.39611027617956}
2022-12-31 09:58:09,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:09,245 INFO:     Epoch: 18
2022-12-31 09:58:10,831 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47503023346265155, 'Total loss': 0.47503023346265155} | train loss {'Reaction outcome loss': 0.3907872681468175, 'Total loss': 0.3907872681468175}
2022-12-31 09:58:10,831 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:10,831 INFO:     Epoch: 19
2022-12-31 09:58:12,416 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4016756852467855, 'Total loss': 0.4016756852467855} | train loss {'Reaction outcome loss': 0.3811085239547645, 'Total loss': 0.3811085239547645}
2022-12-31 09:58:12,417 INFO:     Found new best model at epoch 19
2022-12-31 09:58:12,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:12,418 INFO:     Epoch: 20
2022-12-31 09:58:13,981 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4262166440486908, 'Total loss': 0.4262166440486908} | train loss {'Reaction outcome loss': 0.37724988954313565, 'Total loss': 0.37724988954313565}
2022-12-31 09:58:13,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:13,981 INFO:     Epoch: 21
2022-12-31 09:58:15,550 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4308458228905996, 'Total loss': 0.4308458228905996} | train loss {'Reaction outcome loss': 0.37300117440329267, 'Total loss': 0.37300117440329267}
2022-12-31 09:58:15,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:15,551 INFO:     Epoch: 22
2022-12-31 09:58:17,116 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4015344063440959, 'Total loss': 0.4015344063440959} | train loss {'Reaction outcome loss': 0.36823859410807214, 'Total loss': 0.36823859410807214}
2022-12-31 09:58:17,116 INFO:     Found new best model at epoch 22
2022-12-31 09:58:17,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:17,117 INFO:     Epoch: 23
2022-12-31 09:58:18,700 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4052794352173805, 'Total loss': 0.4052794352173805} | train loss {'Reaction outcome loss': 0.36110364576987236, 'Total loss': 0.36110364576987236}
2022-12-31 09:58:18,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:18,701 INFO:     Epoch: 24
2022-12-31 09:58:20,288 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44314349479973314, 'Total loss': 0.44314349479973314} | train loss {'Reaction outcome loss': 0.3562449366129192, 'Total loss': 0.3562449366129192}
2022-12-31 09:58:20,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:20,288 INFO:     Epoch: 25
2022-12-31 09:58:21,854 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4205775946378708, 'Total loss': 0.4205775946378708} | train loss {'Reaction outcome loss': 0.3469090984646245, 'Total loss': 0.3469090984646245}
2022-12-31 09:58:21,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:21,855 INFO:     Epoch: 26
2022-12-31 09:58:23,432 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4087414681911469, 'Total loss': 0.4087414681911469} | train loss {'Reaction outcome loss': 0.34218590987014597, 'Total loss': 0.34218590987014597}
2022-12-31 09:58:23,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:23,432 INFO:     Epoch: 27
2022-12-31 09:58:25,013 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40194388628005984, 'Total loss': 0.40194388628005984} | train loss {'Reaction outcome loss': 0.339914074160736, 'Total loss': 0.339914074160736}
2022-12-31 09:58:25,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:25,014 INFO:     Epoch: 28
2022-12-31 09:58:26,620 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4507866611083349, 'Total loss': 0.4507866611083349} | train loss {'Reaction outcome loss': 0.33531918467410815, 'Total loss': 0.33531918467410815}
2022-12-31 09:58:26,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:26,621 INFO:     Epoch: 29
2022-12-31 09:58:28,214 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39505667487780255, 'Total loss': 0.39505667487780255} | train loss {'Reaction outcome loss': 0.33061908465909784, 'Total loss': 0.33061908465909784}
2022-12-31 09:58:28,215 INFO:     Found new best model at epoch 29
2022-12-31 09:58:28,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:28,216 INFO:     Epoch: 30
2022-12-31 09:58:29,792 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44156639178593954, 'Total loss': 0.44156639178593954} | train loss {'Reaction outcome loss': 0.32400720324573484, 'Total loss': 0.32400720324573484}
2022-12-31 09:58:29,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:29,792 INFO:     Epoch: 31
2022-12-31 09:58:31,369 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4080340718229612, 'Total loss': 0.4080340718229612} | train loss {'Reaction outcome loss': 0.31692102151438317, 'Total loss': 0.31692102151438317}
2022-12-31 09:58:31,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:31,369 INFO:     Epoch: 32
2022-12-31 09:58:32,983 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.39526999890804293, 'Total loss': 0.39526999890804293} | train loss {'Reaction outcome loss': 0.3172591835590306, 'Total loss': 0.3172591835590306}
2022-12-31 09:58:32,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:32,983 INFO:     Epoch: 33
2022-12-31 09:58:34,596 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4458305637041728, 'Total loss': 0.4458305637041728} | train loss {'Reaction outcome loss': 0.31297972726865886, 'Total loss': 0.31297972726865886}
2022-12-31 09:58:34,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:34,598 INFO:     Epoch: 34
2022-12-31 09:58:36,189 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3846312274535497, 'Total loss': 0.3846312274535497} | train loss {'Reaction outcome loss': 0.30599416319514555, 'Total loss': 0.30599416319514555}
2022-12-31 09:58:36,189 INFO:     Found new best model at epoch 34
2022-12-31 09:58:36,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:36,190 INFO:     Epoch: 35
2022-12-31 09:58:37,804 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4180563936630885, 'Total loss': 0.4180563936630885} | train loss {'Reaction outcome loss': 0.3058732373578082, 'Total loss': 0.3058732373578082}
2022-12-31 09:58:37,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:37,804 INFO:     Epoch: 36
2022-12-31 09:58:39,388 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4285049190123876, 'Total loss': 0.4285049190123876} | train loss {'Reaction outcome loss': 0.2997765107788283, 'Total loss': 0.2997765107788283}
2022-12-31 09:58:39,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:39,389 INFO:     Epoch: 37
2022-12-31 09:58:40,970 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4125010003646215, 'Total loss': 0.4125010003646215} | train loss {'Reaction outcome loss': 0.2926617517682459, 'Total loss': 0.2926617517682459}
2022-12-31 09:58:40,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:40,971 INFO:     Epoch: 38
2022-12-31 09:58:42,531 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40518040855725607, 'Total loss': 0.40518040855725607} | train loss {'Reaction outcome loss': 0.2918986029977948, 'Total loss': 0.2918986029977948}
2022-12-31 09:58:42,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:42,531 INFO:     Epoch: 39
2022-12-31 09:58:44,097 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.415749521056811, 'Total loss': 0.415749521056811} | train loss {'Reaction outcome loss': 0.29135509693094724, 'Total loss': 0.29135509693094724}
2022-12-31 09:58:44,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:44,097 INFO:     Epoch: 40
2022-12-31 09:58:45,680 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4273764948050181, 'Total loss': 0.4273764948050181} | train loss {'Reaction outcome loss': 0.286018480426491, 'Total loss': 0.286018480426491}
2022-12-31 09:58:45,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:45,680 INFO:     Epoch: 41
2022-12-31 09:58:47,266 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3844932228326797, 'Total loss': 0.3844932228326797} | train loss {'Reaction outcome loss': 0.28063249128880974, 'Total loss': 0.28063249128880974}
2022-12-31 09:58:47,267 INFO:     Found new best model at epoch 41
2022-12-31 09:58:47,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:47,268 INFO:     Epoch: 42
2022-12-31 09:58:48,840 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4313629508018494, 'Total loss': 0.4313629508018494} | train loss {'Reaction outcome loss': 0.2803727783180251, 'Total loss': 0.2803727783180251}
2022-12-31 09:58:48,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:48,840 INFO:     Epoch: 43
2022-12-31 09:58:50,414 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.37267130650579927, 'Total loss': 0.37267130650579927} | train loss {'Reaction outcome loss': 0.2786927350222844, 'Total loss': 0.2786927350222844}
2022-12-31 09:58:50,414 INFO:     Found new best model at epoch 43
2022-12-31 09:58:50,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:50,415 INFO:     Epoch: 44
2022-12-31 09:58:51,999 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4380140095949173, 'Total loss': 0.4380140095949173} | train loss {'Reaction outcome loss': 0.26844665427379505, 'Total loss': 0.26844665427379505}
2022-12-31 09:58:51,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:51,999 INFO:     Epoch: 45
2022-12-31 09:58:53,571 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46807970801989235, 'Total loss': 0.46807970801989235} | train loss {'Reaction outcome loss': 0.26874347281302036, 'Total loss': 0.26874347281302036}
2022-12-31 09:58:53,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:53,572 INFO:     Epoch: 46
2022-12-31 09:58:55,171 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3867411424716314, 'Total loss': 0.3867411424716314} | train loss {'Reaction outcome loss': 0.2668512575053421, 'Total loss': 0.2668512575053421}
2022-12-31 09:58:55,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:55,171 INFO:     Epoch: 47
2022-12-31 09:58:56,763 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4024770960211754, 'Total loss': 0.4024770960211754} | train loss {'Reaction outcome loss': 0.2679778166335227, 'Total loss': 0.2679778166335227}
2022-12-31 09:58:56,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:56,763 INFO:     Epoch: 48
2022-12-31 09:58:58,363 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40882823765277865, 'Total loss': 0.40882823765277865} | train loss {'Reaction outcome loss': 0.25901762717764315, 'Total loss': 0.25901762717764315}
2022-12-31 09:58:58,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:58,363 INFO:     Epoch: 49
2022-12-31 09:58:59,989 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4731145431598028, 'Total loss': 0.4731145431598028} | train loss {'Reaction outcome loss': 0.2592596827122998, 'Total loss': 0.2592596827122998}
2022-12-31 09:58:59,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:58:59,989 INFO:     Epoch: 50
2022-12-31 09:59:01,596 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42044719407955805, 'Total loss': 0.42044719407955805} | train loss {'Reaction outcome loss': 0.2557436811060703, 'Total loss': 0.2557436811060703}
2022-12-31 09:59:01,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:01,596 INFO:     Epoch: 51
2022-12-31 09:59:03,173 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39061148365338644, 'Total loss': 0.39061148365338644} | train loss {'Reaction outcome loss': 0.2576297073869028, 'Total loss': 0.2576297073869028}
2022-12-31 09:59:03,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:03,173 INFO:     Epoch: 52
2022-12-31 09:59:04,773 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4060048838456472, 'Total loss': 0.4060048838456472} | train loss {'Reaction outcome loss': 0.2510861475364308, 'Total loss': 0.2510861475364308}
2022-12-31 09:59:04,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:04,774 INFO:     Epoch: 53
2022-12-31 09:59:06,391 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41198181609312695, 'Total loss': 0.41198181609312695} | train loss {'Reaction outcome loss': 0.24713912230273674, 'Total loss': 0.24713912230273674}
2022-12-31 09:59:06,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:06,391 INFO:     Epoch: 54
2022-12-31 09:59:07,954 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4533371647198995, 'Total loss': 0.4533371647198995} | train loss {'Reaction outcome loss': 0.24659304168226534, 'Total loss': 0.24659304168226534}
2022-12-31 09:59:07,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:07,955 INFO:     Epoch: 55
2022-12-31 09:59:09,539 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41857124070326485, 'Total loss': 0.41857124070326485} | train loss {'Reaction outcome loss': 0.24951892508351936, 'Total loss': 0.24951892508351936}
2022-12-31 09:59:09,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:09,539 INFO:     Epoch: 56
2022-12-31 09:59:11,126 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4452705025672913, 'Total loss': 0.4452705025672913} | train loss {'Reaction outcome loss': 0.24280090470595553, 'Total loss': 0.24280090470595553}
2022-12-31 09:59:11,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:11,127 INFO:     Epoch: 57
2022-12-31 09:59:12,732 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3752154096961021, 'Total loss': 0.3752154096961021} | train loss {'Reaction outcome loss': 0.24539518849821107, 'Total loss': 0.24539518849821107}
2022-12-31 09:59:12,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:12,732 INFO:     Epoch: 58
2022-12-31 09:59:14,314 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40450408359368645, 'Total loss': 0.40450408359368645} | train loss {'Reaction outcome loss': 0.23508217701227901, 'Total loss': 0.23508217701227901}
2022-12-31 09:59:14,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:14,314 INFO:     Epoch: 59
2022-12-31 09:59:15,896 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40042102138201396, 'Total loss': 0.40042102138201396} | train loss {'Reaction outcome loss': 0.2404445758384972, 'Total loss': 0.2404445758384972}
2022-12-31 09:59:15,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:15,896 INFO:     Epoch: 60
2022-12-31 09:59:17,457 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42981752852598826, 'Total loss': 0.42981752852598826} | train loss {'Reaction outcome loss': 0.2518174926513235, 'Total loss': 0.2518174926513235}
2022-12-31 09:59:17,457 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:17,457 INFO:     Epoch: 61
2022-12-31 09:59:19,039 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41132978200912473, 'Total loss': 0.41132978200912473} | train loss {'Reaction outcome loss': 0.23817097524875205, 'Total loss': 0.23817097524875205}
2022-12-31 09:59:19,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:19,039 INFO:     Epoch: 62
2022-12-31 09:59:20,608 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3948273003101349, 'Total loss': 0.3948273003101349} | train loss {'Reaction outcome loss': 0.23832997400657277, 'Total loss': 0.23832997400657277}
2022-12-31 09:59:20,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:20,609 INFO:     Epoch: 63
2022-12-31 09:59:22,199 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40541618267695106, 'Total loss': 0.40541618267695106} | train loss {'Reaction outcome loss': 0.23729863009549595, 'Total loss': 0.23729863009549595}
2022-12-31 09:59:22,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:22,199 INFO:     Epoch: 64
2022-12-31 09:59:23,792 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3934067289034526, 'Total loss': 0.3934067289034526} | train loss {'Reaction outcome loss': 0.23450564137381602, 'Total loss': 0.23450564137381602}
2022-12-31 09:59:23,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:23,793 INFO:     Epoch: 65
2022-12-31 09:59:25,354 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3972875108321508, 'Total loss': 0.3972875108321508} | train loss {'Reaction outcome loss': 0.22893215961946772, 'Total loss': 0.22893215961946772}
2022-12-31 09:59:25,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:25,354 INFO:     Epoch: 66
2022-12-31 09:59:26,939 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39560968478520714, 'Total loss': 0.39560968478520714} | train loss {'Reaction outcome loss': 0.22435891118959086, 'Total loss': 0.22435891118959086}
2022-12-31 09:59:26,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:26,939 INFO:     Epoch: 67
2022-12-31 09:59:28,523 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3654305179913839, 'Total loss': 0.3654305179913839} | train loss {'Reaction outcome loss': 0.22595179652472153, 'Total loss': 0.22595179652472153}
2022-12-31 09:59:28,523 INFO:     Found new best model at epoch 67
2022-12-31 09:59:28,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:28,524 INFO:     Epoch: 68
2022-12-31 09:59:30,090 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44176088174184164, 'Total loss': 0.44176088174184164} | train loss {'Reaction outcome loss': 0.22458724675157082, 'Total loss': 0.22458724675157082}
2022-12-31 09:59:30,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:30,091 INFO:     Epoch: 69
2022-12-31 09:59:31,677 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4017977784077326, 'Total loss': 0.4017977784077326} | train loss {'Reaction outcome loss': 0.23424951697792515, 'Total loss': 0.23424951697792515}
2022-12-31 09:59:31,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:31,677 INFO:     Epoch: 70
2022-12-31 09:59:33,264 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39576281706492106, 'Total loss': 0.39576281706492106} | train loss {'Reaction outcome loss': 0.21711909081580674, 'Total loss': 0.21711909081580674}
2022-12-31 09:59:33,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:33,264 INFO:     Epoch: 71
2022-12-31 09:59:34,831 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3743709199130535, 'Total loss': 0.3743709199130535} | train loss {'Reaction outcome loss': 0.22383104012488658, 'Total loss': 0.22383104012488658}
2022-12-31 09:59:34,831 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:34,831 INFO:     Epoch: 72
2022-12-31 09:59:36,417 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42123267948627474, 'Total loss': 0.42123267948627474} | train loss {'Reaction outcome loss': 0.2180422415812517, 'Total loss': 0.2180422415812517}
2022-12-31 09:59:36,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:36,417 INFO:     Epoch: 73
2022-12-31 09:59:38,002 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3865870416164398, 'Total loss': 0.3865870416164398} | train loss {'Reaction outcome loss': 0.2144484833240289, 'Total loss': 0.2144484833240289}
2022-12-31 09:59:38,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:38,002 INFO:     Epoch: 74
2022-12-31 09:59:39,604 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39862412710984546, 'Total loss': 0.39862412710984546} | train loss {'Reaction outcome loss': 0.21269150636402884, 'Total loss': 0.21269150636402884}
2022-12-31 09:59:39,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:39,604 INFO:     Epoch: 75
2022-12-31 09:59:41,191 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4157327562570572, 'Total loss': 0.4157327562570572} | train loss {'Reaction outcome loss': 0.21942449216060753, 'Total loss': 0.21942449216060753}
2022-12-31 09:59:41,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:41,192 INFO:     Epoch: 76
2022-12-31 09:59:42,772 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4084142138560613, 'Total loss': 0.4084142138560613} | train loss {'Reaction outcome loss': 0.20963711627652504, 'Total loss': 0.20963711627652504}
2022-12-31 09:59:42,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:42,772 INFO:     Epoch: 77
2022-12-31 09:59:44,331 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.37540600895881654, 'Total loss': 0.37540600895881654} | train loss {'Reaction outcome loss': 0.2186650872175544, 'Total loss': 0.2186650872175544}
2022-12-31 09:59:44,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:44,331 INFO:     Epoch: 78
2022-12-31 09:59:45,929 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.34995382527510327, 'Total loss': 0.34995382527510327} | train loss {'Reaction outcome loss': 0.21254730400564045, 'Total loss': 0.21254730400564045}
2022-12-31 09:59:45,929 INFO:     Found new best model at epoch 78
2022-12-31 09:59:45,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:45,930 INFO:     Epoch: 79
2022-12-31 09:59:47,497 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3850142647822698, 'Total loss': 0.3850142647822698} | train loss {'Reaction outcome loss': 0.20854205744361637, 'Total loss': 0.20854205744361637}
2022-12-31 09:59:47,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:47,498 INFO:     Epoch: 80
2022-12-31 09:59:49,100 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3875281592210134, 'Total loss': 0.3875281592210134} | train loss {'Reaction outcome loss': 0.2091962103886578, 'Total loss': 0.2091962103886578}
2022-12-31 09:59:49,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:49,100 INFO:     Epoch: 81
2022-12-31 09:59:50,687 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42014075915018717, 'Total loss': 0.42014075915018717} | train loss {'Reaction outcome loss': 0.21345409777056687, 'Total loss': 0.21345409777056687}
2022-12-31 09:59:50,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:50,687 INFO:     Epoch: 82
2022-12-31 09:59:52,262 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.354234953224659, 'Total loss': 0.354234953224659} | train loss {'Reaction outcome loss': 0.206609330177857, 'Total loss': 0.206609330177857}
2022-12-31 09:59:52,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:52,262 INFO:     Epoch: 83
2022-12-31 09:59:53,836 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42303815484046936, 'Total loss': 0.42303815484046936} | train loss {'Reaction outcome loss': 0.21214486025205068, 'Total loss': 0.21214486025205068}
2022-12-31 09:59:53,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:53,836 INFO:     Epoch: 84
2022-12-31 09:59:55,458 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38849022835493086, 'Total loss': 0.38849022835493086} | train loss {'Reaction outcome loss': 0.20581636759297875, 'Total loss': 0.20581636759297875}
2022-12-31 09:59:55,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:55,458 INFO:     Epoch: 85
2022-12-31 09:59:57,035 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3807090630133947, 'Total loss': 0.3807090630133947} | train loss {'Reaction outcome loss': 0.19934864261795893, 'Total loss': 0.19934864261795893}
2022-12-31 09:59:57,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:57,036 INFO:     Epoch: 86
2022-12-31 09:59:58,625 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.35641549676656725, 'Total loss': 0.35641549676656725} | train loss {'Reaction outcome loss': 0.2050415086955162, 'Total loss': 0.2050415086955162}
2022-12-31 09:59:58,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 09:59:58,625 INFO:     Epoch: 87
2022-12-31 10:00:00,227 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3699087311824163, 'Total loss': 0.3699087311824163} | train loss {'Reaction outcome loss': 0.20656768955647725, 'Total loss': 0.20656768955647725}
2022-12-31 10:00:00,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:00,228 INFO:     Epoch: 88
2022-12-31 10:00:01,808 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44421217739582064, 'Total loss': 0.44421217739582064} | train loss {'Reaction outcome loss': 0.20017648939167001, 'Total loss': 0.20017648939167001}
2022-12-31 10:00:01,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:01,809 INFO:     Epoch: 89
2022-12-31 10:00:03,429 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3669439951578776, 'Total loss': 0.3669439951578776} | train loss {'Reaction outcome loss': 0.20280750971493686, 'Total loss': 0.20280750971493686}
2022-12-31 10:00:03,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:03,430 INFO:     Epoch: 90
2022-12-31 10:00:05,050 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3756656363606453, 'Total loss': 0.3756656363606453} | train loss {'Reaction outcome loss': 0.20122851078085793, 'Total loss': 0.20122851078085793}
2022-12-31 10:00:05,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:05,050 INFO:     Epoch: 91
2022-12-31 10:00:06,640 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38384343683719635, 'Total loss': 0.38384343683719635} | train loss {'Reaction outcome loss': 0.20627145568163194, 'Total loss': 0.20627145568163194}
2022-12-31 10:00:06,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:06,640 INFO:     Epoch: 92
2022-12-31 10:00:08,260 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.37207360168298087, 'Total loss': 0.37207360168298087} | train loss {'Reaction outcome loss': 0.2006494063141711, 'Total loss': 0.2006494063141711}
2022-12-31 10:00:08,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:08,260 INFO:     Epoch: 93
2022-12-31 10:00:09,880 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.37885631422201793, 'Total loss': 0.37885631422201793} | train loss {'Reaction outcome loss': 0.1975618671845796, 'Total loss': 0.1975618671845796}
2022-12-31 10:00:09,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:09,880 INFO:     Epoch: 94
2022-12-31 10:00:11,465 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3967343091964722, 'Total loss': 0.3967343091964722} | train loss {'Reaction outcome loss': 0.1964069613671391, 'Total loss': 0.1964069613671391}
2022-12-31 10:00:11,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:11,466 INFO:     Epoch: 95
2022-12-31 10:00:13,054 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3789807717005412, 'Total loss': 0.3789807717005412} | train loss {'Reaction outcome loss': 0.19783960355658814, 'Total loss': 0.19783960355658814}
2022-12-31 10:00:13,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:13,054 INFO:     Epoch: 96
2022-12-31 10:00:14,625 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43878430078426994, 'Total loss': 0.43878430078426994} | train loss {'Reaction outcome loss': 0.19781777921143054, 'Total loss': 0.19781777921143054}
2022-12-31 10:00:14,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:14,625 INFO:     Epoch: 97
2022-12-31 10:00:16,235 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40325313607851665, 'Total loss': 0.40325313607851665} | train loss {'Reaction outcome loss': 0.19129072867223917, 'Total loss': 0.19129072867223917}
2022-12-31 10:00:16,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:16,235 INFO:     Epoch: 98
2022-12-31 10:00:17,856 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4014764736096064, 'Total loss': 0.4014764736096064} | train loss {'Reaction outcome loss': 0.191191669484786, 'Total loss': 0.191191669484786}
2022-12-31 10:00:17,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:17,857 INFO:     Epoch: 99
2022-12-31 10:00:19,476 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3838832477728526, 'Total loss': 0.3838832477728526} | train loss {'Reaction outcome loss': 0.1856523371091958, 'Total loss': 0.1856523371091958}
2022-12-31 10:00:19,476 INFO:     Best model found after epoch 79 of 100.
2022-12-31 10:00:19,476 INFO:   Done with stage: TRAINING
2022-12-31 10:00:19,476 INFO:   Starting stage: EVALUATION
2022-12-31 10:00:19,623 INFO:   Done with stage: EVALUATION
2022-12-31 10:00:19,623 INFO:   Leaving out SEQ value Fold_1
2022-12-31 10:00:19,636 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 10:00:19,636 INFO:   Starting stage: FEATURE SCALING
2022-12-31 10:00:20,281 INFO:   Done with stage: FEATURE SCALING
2022-12-31 10:00:20,282 INFO:   Starting stage: SCALING TARGETS
2022-12-31 10:00:20,351 INFO:   Done with stage: SCALING TARGETS
2022-12-31 10:00:20,351 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:00:20,351 INFO:     No hyperparam tuning for this model
2022-12-31 10:00:20,351 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:00:20,352 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 10:00:20,352 INFO:     None feature selector for col prot
2022-12-31 10:00:20,352 INFO:     None feature selector for col prot
2022-12-31 10:00:20,352 INFO:     None feature selector for col prot
2022-12-31 10:00:20,353 INFO:     None feature selector for col chem
2022-12-31 10:00:20,353 INFO:     None feature selector for col chem
2022-12-31 10:00:20,353 INFO:     None feature selector for col chem
2022-12-31 10:00:20,353 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 10:00:20,353 INFO:   Starting stage: BUILD MODEL
2022-12-31 10:00:20,355 INFO:     Number of params in model 223921
2022-12-31 10:00:20,358 INFO:   Done with stage: BUILD MODEL
2022-12-31 10:00:20,358 INFO:   Starting stage: TRAINING
2022-12-31 10:00:20,403 INFO:     Val loss before train {'Reaction outcome loss': 1.0929471890131632, 'Total loss': 1.0929471890131632}
2022-12-31 10:00:20,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:20,403 INFO:     Epoch: 0
2022-12-31 10:00:22,067 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.666053815682729, 'Total loss': 0.666053815682729} | train loss {'Reaction outcome loss': 0.8209892217123854, 'Total loss': 0.8209892217123854}
2022-12-31 10:00:22,067 INFO:     Found new best model at epoch 0
2022-12-31 10:00:22,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:22,068 INFO:     Epoch: 1
2022-12-31 10:00:23,660 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5831533173720042, 'Total loss': 0.5831533173720042} | train loss {'Reaction outcome loss': 0.6075443045060703, 'Total loss': 0.6075443045060703}
2022-12-31 10:00:23,660 INFO:     Found new best model at epoch 1
2022-12-31 10:00:23,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:23,661 INFO:     Epoch: 2
2022-12-31 10:00:25,304 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5048682630062103, 'Total loss': 0.5048682630062103} | train loss {'Reaction outcome loss': 0.5341293162301831, 'Total loss': 0.5341293162301831}
2022-12-31 10:00:25,304 INFO:     Found new best model at epoch 2
2022-12-31 10:00:25,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:25,305 INFO:     Epoch: 3
2022-12-31 10:00:26,921 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4887255787849426, 'Total loss': 0.4887255787849426} | train loss {'Reaction outcome loss': 0.5092676792401767, 'Total loss': 0.5092676792401767}
2022-12-31 10:00:26,921 INFO:     Found new best model at epoch 3
2022-12-31 10:00:26,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:26,922 INFO:     Epoch: 4
2022-12-31 10:00:28,511 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.519133601586024, 'Total loss': 0.519133601586024} | train loss {'Reaction outcome loss': 0.48896072124657425, 'Total loss': 0.48896072124657425}
2022-12-31 10:00:28,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:28,512 INFO:     Epoch: 5
2022-12-31 10:00:30,127 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5471002737681071, 'Total loss': 0.5471002737681071} | train loss {'Reaction outcome loss': 0.5011009855222874, 'Total loss': 0.5011009855222874}
2022-12-31 10:00:30,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:30,128 INFO:     Epoch: 6
2022-12-31 10:00:31,743 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4920385479927063, 'Total loss': 0.4920385479927063} | train loss {'Reaction outcome loss': 0.4797406520853089, 'Total loss': 0.4797406520853089}
2022-12-31 10:00:31,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:31,743 INFO:     Epoch: 7
2022-12-31 10:00:33,338 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4847430229187012, 'Total loss': 0.4847430229187012} | train loss {'Reaction outcome loss': 0.4600316837254534, 'Total loss': 0.4600316837254534}
2022-12-31 10:00:33,338 INFO:     Found new best model at epoch 7
2022-12-31 10:00:33,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:33,339 INFO:     Epoch: 8
2022-12-31 10:00:34,949 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48782159984111784, 'Total loss': 0.48782159984111784} | train loss {'Reaction outcome loss': 0.4566888932098189, 'Total loss': 0.4566888932098189}
2022-12-31 10:00:34,949 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:34,949 INFO:     Epoch: 9
2022-12-31 10:00:36,562 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.46855102976163227, 'Total loss': 0.46855102976163227} | train loss {'Reaction outcome loss': 0.45156068447977304, 'Total loss': 0.45156068447977304}
2022-12-31 10:00:36,563 INFO:     Found new best model at epoch 9
2022-12-31 10:00:36,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:36,564 INFO:     Epoch: 10
2022-12-31 10:00:38,172 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5173958798249563, 'Total loss': 0.5173958798249563} | train loss {'Reaction outcome loss': 0.5129068392443646, 'Total loss': 0.5129068392443646}
2022-12-31 10:00:38,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:38,172 INFO:     Epoch: 11
2022-12-31 10:00:39,838 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5189628442128499, 'Total loss': 0.5189628442128499} | train loss {'Reaction outcome loss': 0.4682772761021835, 'Total loss': 0.4682772761021835}
2022-12-31 10:00:39,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:39,838 INFO:     Epoch: 12
2022-12-31 10:00:41,465 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4600494762261709, 'Total loss': 0.4600494762261709} | train loss {'Reaction outcome loss': 0.45002593984489964, 'Total loss': 0.45002593984489964}
2022-12-31 10:00:41,465 INFO:     Found new best model at epoch 12
2022-12-31 10:00:41,466 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:41,466 INFO:     Epoch: 13
2022-12-31 10:00:43,099 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47334278325239815, 'Total loss': 0.47334278325239815} | train loss {'Reaction outcome loss': 0.4339788325562857, 'Total loss': 0.4339788325562857}
2022-12-31 10:00:43,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:43,100 INFO:     Epoch: 14
2022-12-31 10:00:44,691 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45254852374394733, 'Total loss': 0.45254852374394733} | train loss {'Reaction outcome loss': 0.43170190676853276, 'Total loss': 0.43170190676853276}
2022-12-31 10:00:44,691 INFO:     Found new best model at epoch 14
2022-12-31 10:00:44,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:44,692 INFO:     Epoch: 15
2022-12-31 10:00:46,313 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4390517473220825, 'Total loss': 0.4390517473220825} | train loss {'Reaction outcome loss': 0.4191759643887264, 'Total loss': 0.4191759643887264}
2022-12-31 10:00:46,313 INFO:     Found new best model at epoch 15
2022-12-31 10:00:46,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:46,314 INFO:     Epoch: 16
2022-12-31 10:00:47,944 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43980460464954374, 'Total loss': 0.43980460464954374} | train loss {'Reaction outcome loss': 0.41865416240972886, 'Total loss': 0.41865416240972886}
2022-12-31 10:00:47,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:47,944 INFO:     Epoch: 17
2022-12-31 10:00:49,552 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4579824010531108, 'Total loss': 0.4579824010531108} | train loss {'Reaction outcome loss': 0.4233758768220297, 'Total loss': 0.4233758768220297}
2022-12-31 10:00:49,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:49,553 INFO:     Epoch: 18
2022-12-31 10:00:51,158 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42891418834527334, 'Total loss': 0.42891418834527334} | train loss {'Reaction outcome loss': 0.4066067278601121, 'Total loss': 0.4066067278601121}
2022-12-31 10:00:51,158 INFO:     Found new best model at epoch 18
2022-12-31 10:00:51,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:51,159 INFO:     Epoch: 19
2022-12-31 10:00:52,768 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44711013237635294, 'Total loss': 0.44711013237635294} | train loss {'Reaction outcome loss': 0.41374816779263207, 'Total loss': 0.41374816779263207}
2022-12-31 10:00:52,768 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:52,768 INFO:     Epoch: 20
2022-12-31 10:00:54,380 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44311886926492056, 'Total loss': 0.44311886926492056} | train loss {'Reaction outcome loss': 0.39318833451556123, 'Total loss': 0.39318833451556123}
2022-12-31 10:00:54,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:54,380 INFO:     Epoch: 21
2022-12-31 10:00:55,974 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4382526516914368, 'Total loss': 0.4382526516914368} | train loss {'Reaction outcome loss': 0.3896899995515528, 'Total loss': 0.3896899995515528}
2022-12-31 10:00:55,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:55,974 INFO:     Epoch: 22
2022-12-31 10:00:57,588 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42594780027866364, 'Total loss': 0.42594780027866364} | train loss {'Reaction outcome loss': 0.38437644170894136, 'Total loss': 0.38437644170894136}
2022-12-31 10:00:57,588 INFO:     Found new best model at epoch 22
2022-12-31 10:00:57,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:57,589 INFO:     Epoch: 23
2022-12-31 10:00:59,200 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42511431574821473, 'Total loss': 0.42511431574821473} | train loss {'Reaction outcome loss': 0.40203754101758415, 'Total loss': 0.40203754101758415}
2022-12-31 10:00:59,200 INFO:     Found new best model at epoch 23
2022-12-31 10:00:59,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:00:59,201 INFO:     Epoch: 24
2022-12-31 10:01:00,801 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42626905143260957, 'Total loss': 0.42626905143260957} | train loss {'Reaction outcome loss': 0.3924334471829344, 'Total loss': 0.3924334471829344}
2022-12-31 10:01:00,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:00,802 INFO:     Epoch: 25
2022-12-31 10:01:02,427 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4228948230544726, 'Total loss': 0.4228948230544726} | train loss {'Reaction outcome loss': 0.3691724680087435, 'Total loss': 0.3691724680087435}
2022-12-31 10:01:02,428 INFO:     Found new best model at epoch 25
2022-12-31 10:01:02,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:02,429 INFO:     Epoch: 26
2022-12-31 10:01:04,042 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42310540974140165, 'Total loss': 0.42310540974140165} | train loss {'Reaction outcome loss': 0.36534389050043037, 'Total loss': 0.36534389050043037}
2022-12-31 10:01:04,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:04,042 INFO:     Epoch: 27
2022-12-31 10:01:05,635 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4144845167795817, 'Total loss': 0.4144845167795817} | train loss {'Reaction outcome loss': 0.35994182815235376, 'Total loss': 0.35994182815235376}
2022-12-31 10:01:05,635 INFO:     Found new best model at epoch 27
2022-12-31 10:01:05,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:05,636 INFO:     Epoch: 28
2022-12-31 10:01:07,250 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43943193753560383, 'Total loss': 0.43943193753560383} | train loss {'Reaction outcome loss': 0.35711742497548676, 'Total loss': 0.35711742497548676}
2022-12-31 10:01:07,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:07,250 INFO:     Epoch: 29
2022-12-31 10:01:08,833 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42673481404781344, 'Total loss': 0.42673481404781344} | train loss {'Reaction outcome loss': 0.3625158725611771, 'Total loss': 0.3625158725611771}
2022-12-31 10:01:08,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:08,833 INFO:     Epoch: 30
2022-12-31 10:01:10,455 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42072457720836004, 'Total loss': 0.42072457720836004} | train loss {'Reaction outcome loss': 0.3441195394202689, 'Total loss': 0.3441195394202689}
2022-12-31 10:01:10,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:10,455 INFO:     Epoch: 31
2022-12-31 10:01:12,070 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40280962189038594, 'Total loss': 0.40280962189038594} | train loss {'Reaction outcome loss': 0.35724846176479175, 'Total loss': 0.35724846176479175}
2022-12-31 10:01:12,070 INFO:     Found new best model at epoch 31
2022-12-31 10:01:12,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:12,071 INFO:     Epoch: 32
2022-12-31 10:01:13,682 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4151298597455025, 'Total loss': 0.4151298597455025} | train loss {'Reaction outcome loss': 0.37808746791890135, 'Total loss': 0.37808746791890135}
2022-12-31 10:01:13,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:13,682 INFO:     Epoch: 33
2022-12-31 10:01:15,286 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3817518770694733, 'Total loss': 0.3817518770694733} | train loss {'Reaction outcome loss': 0.3405305757322281, 'Total loss': 0.3405305757322281}
2022-12-31 10:01:15,287 INFO:     Found new best model at epoch 33
2022-12-31 10:01:15,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:15,288 INFO:     Epoch: 34
2022-12-31 10:01:16,901 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4234420080979665, 'Total loss': 0.4234420080979665} | train loss {'Reaction outcome loss': 0.33077130185278214, 'Total loss': 0.33077130185278214}
2022-12-31 10:01:16,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:16,901 INFO:     Epoch: 35
2022-12-31 10:01:18,506 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4099927892287572, 'Total loss': 0.4099927892287572} | train loss {'Reaction outcome loss': 0.32599460221219645, 'Total loss': 0.32599460221219645}
2022-12-31 10:01:18,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:18,507 INFO:     Epoch: 36
2022-12-31 10:01:20,124 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4297218590974808, 'Total loss': 0.4297218590974808} | train loss {'Reaction outcome loss': 0.3214971897178802, 'Total loss': 0.3214971897178802}
2022-12-31 10:01:20,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:20,125 INFO:     Epoch: 37
2022-12-31 10:01:21,737 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4414281934499741, 'Total loss': 0.4414281934499741} | train loss {'Reaction outcome loss': 0.3372796715196708, 'Total loss': 0.3372796715196708}
2022-12-31 10:01:21,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:21,737 INFO:     Epoch: 38
2022-12-31 10:01:23,335 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4277741094430288, 'Total loss': 0.4277741094430288} | train loss {'Reaction outcome loss': 0.3141220207967242, 'Total loss': 0.3141220207967242}
2022-12-31 10:01:23,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:23,335 INFO:     Epoch: 39
2022-12-31 10:01:24,946 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40284659365812936, 'Total loss': 0.40284659365812936} | train loss {'Reaction outcome loss': 0.31434164994119573, 'Total loss': 0.31434164994119573}
2022-12-31 10:01:24,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:24,947 INFO:     Epoch: 40
2022-12-31 10:01:26,557 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41125192046165465, 'Total loss': 0.41125192046165465} | train loss {'Reaction outcome loss': 0.30425419299728307, 'Total loss': 0.30425419299728307}
2022-12-31 10:01:26,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:26,558 INFO:     Epoch: 41
2022-12-31 10:01:28,193 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4162183403968811, 'Total loss': 0.4162183403968811} | train loss {'Reaction outcome loss': 0.3002539847981506, 'Total loss': 0.3002539847981506}
2022-12-31 10:01:28,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:28,193 INFO:     Epoch: 42
2022-12-31 10:01:29,782 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40161651571591694, 'Total loss': 0.40161651571591694} | train loss {'Reaction outcome loss': 0.2938770717954722, 'Total loss': 0.2938770717954722}
2022-12-31 10:01:29,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:29,782 INFO:     Epoch: 43
2022-12-31 10:01:31,430 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4057480901479721, 'Total loss': 0.4057480901479721} | train loss {'Reaction outcome loss': 0.295652038809182, 'Total loss': 0.295652038809182}
2022-12-31 10:01:31,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:31,430 INFO:     Epoch: 44
2022-12-31 10:01:33,042 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3631386399269104, 'Total loss': 0.3631386399269104} | train loss {'Reaction outcome loss': 0.29264436219481454, 'Total loss': 0.29264436219481454}
2022-12-31 10:01:33,042 INFO:     Found new best model at epoch 44
2022-12-31 10:01:33,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:33,043 INFO:     Epoch: 45
2022-12-31 10:01:34,657 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3943922420342763, 'Total loss': 0.3943922420342763} | train loss {'Reaction outcome loss': 0.29239277517679485, 'Total loss': 0.29239277517679485}
2022-12-31 10:01:34,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:34,657 INFO:     Epoch: 46
2022-12-31 10:01:36,254 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4197728435198466, 'Total loss': 0.4197728435198466} | train loss {'Reaction outcome loss': 0.28814667853631376, 'Total loss': 0.28814667853631376}
2022-12-31 10:01:36,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:36,255 INFO:     Epoch: 47
2022-12-31 10:01:37,862 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.429551370938619, 'Total loss': 0.429551370938619} | train loss {'Reaction outcome loss': 0.28048074570909626, 'Total loss': 0.28048074570909626}
2022-12-31 10:01:37,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:37,863 INFO:     Epoch: 48
2022-12-31 10:01:39,484 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4308428128560384, 'Total loss': 0.4308428128560384} | train loss {'Reaction outcome loss': 0.2787897432850593, 'Total loss': 0.2787897432850593}
2022-12-31 10:01:39,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:39,485 INFO:     Epoch: 49
2022-12-31 10:01:41,088 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.43640957127014796, 'Total loss': 0.43640957127014796} | train loss {'Reaction outcome loss': 0.2769392565829891, 'Total loss': 0.2769392565829891}
2022-12-31 10:01:41,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:41,089 INFO:     Epoch: 50
2022-12-31 10:01:42,695 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40112704237302144, 'Total loss': 0.40112704237302144} | train loss {'Reaction outcome loss': 0.27564245324406395, 'Total loss': 0.27564245324406395}
2022-12-31 10:01:42,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:42,695 INFO:     Epoch: 51
2022-12-31 10:01:44,301 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4222427189350128, 'Total loss': 0.4222427189350128} | train loss {'Reaction outcome loss': 0.27453379542398115, 'Total loss': 0.27453379542398115}
2022-12-31 10:01:44,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:44,301 INFO:     Epoch: 52
2022-12-31 10:01:45,893 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4072102755308151, 'Total loss': 0.4072102755308151} | train loss {'Reaction outcome loss': 0.2663752083815094, 'Total loss': 0.2663752083815094}
2022-12-31 10:01:45,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:45,893 INFO:     Epoch: 53
2022-12-31 10:01:47,499 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.37996551593144734, 'Total loss': 0.37996551593144734} | train loss {'Reaction outcome loss': 0.27129424011766695, 'Total loss': 0.27129424011766695}
2022-12-31 10:01:47,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:47,499 INFO:     Epoch: 54
2022-12-31 10:01:49,105 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3745337828993797, 'Total loss': 0.3745337828993797} | train loss {'Reaction outcome loss': 0.2681602007706069, 'Total loss': 0.2681602007706069}
2022-12-31 10:01:49,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:49,107 INFO:     Epoch: 55
2022-12-31 10:01:50,717 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37445699274539945, 'Total loss': 0.37445699274539945} | train loss {'Reaction outcome loss': 0.2589242883377533, 'Total loss': 0.2589242883377533}
2022-12-31 10:01:50,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:50,717 INFO:     Epoch: 56
2022-12-31 10:01:52,347 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4047853777805964, 'Total loss': 0.4047853777805964} | train loss {'Reaction outcome loss': 0.26175166805531236, 'Total loss': 0.26175166805531236}
2022-12-31 10:01:52,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:52,348 INFO:     Epoch: 57
2022-12-31 10:01:53,944 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4312490403652191, 'Total loss': 0.4312490403652191} | train loss {'Reaction outcome loss': 0.25732001818824507, 'Total loss': 0.25732001818824507}
2022-12-31 10:01:53,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:53,944 INFO:     Epoch: 58
2022-12-31 10:01:55,552 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43472926914691923, 'Total loss': 0.43472926914691923} | train loss {'Reaction outcome loss': 0.2536635685465771, 'Total loss': 0.2536635685465771}
2022-12-31 10:01:55,553 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:55,553 INFO:     Epoch: 59
2022-12-31 10:01:57,168 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43487319548924763, 'Total loss': 0.43487319548924763} | train loss {'Reaction outcome loss': 0.258794107467638, 'Total loss': 0.258794107467638}
2022-12-31 10:01:57,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:57,168 INFO:     Epoch: 60
2022-12-31 10:01:58,772 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.38325828115145366, 'Total loss': 0.38325828115145366} | train loss {'Reaction outcome loss': 0.25361563451218094, 'Total loss': 0.25361563451218094}
2022-12-31 10:01:58,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:01:58,772 INFO:     Epoch: 61
2022-12-31 10:02:00,377 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40057257215181985, 'Total loss': 0.40057257215181985} | train loss {'Reaction outcome loss': 0.25243837718722795, 'Total loss': 0.25243837718722795}
2022-12-31 10:02:00,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:00,378 INFO:     Epoch: 62
2022-12-31 10:02:01,990 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4078119566043218, 'Total loss': 0.4078119566043218} | train loss {'Reaction outcome loss': 0.2543858221552395, 'Total loss': 0.2543858221552395}
2022-12-31 10:02:01,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:01,990 INFO:     Epoch: 63
2022-12-31 10:02:03,585 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4127861479918162, 'Total loss': 0.4127861479918162} | train loss {'Reaction outcome loss': 0.2483213993963664, 'Total loss': 0.2483213993963664}
2022-12-31 10:02:03,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:03,586 INFO:     Epoch: 64
2022-12-31 10:02:05,199 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40478475391864777, 'Total loss': 0.40478475391864777} | train loss {'Reaction outcome loss': 0.23777847450590975, 'Total loss': 0.23777847450590975}
2022-12-31 10:02:05,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:05,199 INFO:     Epoch: 65
2022-12-31 10:02:06,810 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43245103557904563, 'Total loss': 0.43245103557904563} | train loss {'Reaction outcome loss': 0.2411572477245447, 'Total loss': 0.2411572477245447}
2022-12-31 10:02:06,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:06,810 INFO:     Epoch: 66
2022-12-31 10:02:08,406 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3915042281150818, 'Total loss': 0.3915042281150818} | train loss {'Reaction outcome loss': 0.24891277028085745, 'Total loss': 0.24891277028085745}
2022-12-31 10:02:08,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:08,407 INFO:     Epoch: 67
2022-12-31 10:02:10,019 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39523836473623913, 'Total loss': 0.39523836473623913} | train loss {'Reaction outcome loss': 0.2446913947895392, 'Total loss': 0.2446913947895392}
2022-12-31 10:02:10,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:10,019 INFO:     Epoch: 68
2022-12-31 10:02:11,634 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.37617796659469604, 'Total loss': 0.37617796659469604} | train loss {'Reaction outcome loss': 0.2394867470720783, 'Total loss': 0.2394867470720783}
2022-12-31 10:02:11,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:11,634 INFO:     Epoch: 69
2022-12-31 10:02:13,274 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.412970099846522, 'Total loss': 0.412970099846522} | train loss {'Reaction outcome loss': 0.2381942600933025, 'Total loss': 0.2381942600933025}
2022-12-31 10:02:13,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:13,274 INFO:     Epoch: 70
2022-12-31 10:02:14,934 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39962609807650246, 'Total loss': 0.39962609807650246} | train loss {'Reaction outcome loss': 0.22905535718566988, 'Total loss': 0.22905535718566988}
2022-12-31 10:02:14,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:14,934 INFO:     Epoch: 71
2022-12-31 10:02:16,602 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4381713330745697, 'Total loss': 0.4381713330745697} | train loss {'Reaction outcome loss': 0.23892753843076364, 'Total loss': 0.23892753843076364}
2022-12-31 10:02:16,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:16,603 INFO:     Epoch: 72
2022-12-31 10:02:18,228 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41614988446235657, 'Total loss': 0.41614988446235657} | train loss {'Reaction outcome loss': 0.2416499067486797, 'Total loss': 0.2416499067486797}
2022-12-31 10:02:18,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:18,228 INFO:     Epoch: 73
2022-12-31 10:02:19,900 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40981504519780476, 'Total loss': 0.40981504519780476} | train loss {'Reaction outcome loss': 0.253971496394471, 'Total loss': 0.253971496394471}
2022-12-31 10:02:19,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:19,902 INFO:     Epoch: 74
2022-12-31 10:02:21,538 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43557302877306936, 'Total loss': 0.43557302877306936} | train loss {'Reaction outcome loss': 0.2753412531118543, 'Total loss': 0.2753412531118543}
2022-12-31 10:02:21,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:21,538 INFO:     Epoch: 75
2022-12-31 10:02:23,205 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41613977452119194, 'Total loss': 0.41613977452119194} | train loss {'Reaction outcome loss': 0.24318467594254628, 'Total loss': 0.24318467594254628}
2022-12-31 10:02:23,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:23,205 INFO:     Epoch: 76
2022-12-31 10:02:24,872 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41170804599920907, 'Total loss': 0.41170804599920907} | train loss {'Reaction outcome loss': 0.23156789836386873, 'Total loss': 0.23156789836386873}
2022-12-31 10:02:24,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:24,873 INFO:     Epoch: 77
2022-12-31 10:02:26,475 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3870319108168284, 'Total loss': 0.3870319108168284} | train loss {'Reaction outcome loss': 0.22808074169122425, 'Total loss': 0.22808074169122425}
2022-12-31 10:02:26,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:26,476 INFO:     Epoch: 78
2022-12-31 10:02:28,092 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4037997911373774, 'Total loss': 0.4037997911373774} | train loss {'Reaction outcome loss': 0.23011767566355917, 'Total loss': 0.23011767566355917}
2022-12-31 10:02:28,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:28,092 INFO:     Epoch: 79
2022-12-31 10:02:29,726 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39493855386972426, 'Total loss': 0.39493855386972426} | train loss {'Reaction outcome loss': 0.22891788482051514, 'Total loss': 0.22891788482051514}
2022-12-31 10:02:29,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:29,726 INFO:     Epoch: 80
2022-12-31 10:02:31,352 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40047197937965395, 'Total loss': 0.40047197937965395} | train loss {'Reaction outcome loss': 0.22157826629953217, 'Total loss': 0.22157826629953217}
2022-12-31 10:02:31,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:31,353 INFO:     Epoch: 81
2022-12-31 10:02:33,017 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4466083159049352, 'Total loss': 0.4466083159049352} | train loss {'Reaction outcome loss': 0.2234316355165836, 'Total loss': 0.2234316355165836}
2022-12-31 10:02:33,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:33,017 INFO:     Epoch: 82
2022-12-31 10:02:34,638 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3648585617542267, 'Total loss': 0.3648585617542267} | train loss {'Reaction outcome loss': 0.2250682102985329, 'Total loss': 0.2250682102985329}
2022-12-31 10:02:34,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:34,639 INFO:     Epoch: 83
2022-12-31 10:02:36,235 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4086776405572891, 'Total loss': 0.4086776405572891} | train loss {'Reaction outcome loss': 0.21868126992595152, 'Total loss': 0.21868126992595152}
2022-12-31 10:02:36,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:36,235 INFO:     Epoch: 84
2022-12-31 10:02:37,849 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4267747143904368, 'Total loss': 0.4267747143904368} | train loss {'Reaction outcome loss': 0.22202642462418778, 'Total loss': 0.22202642462418778}
2022-12-31 10:02:37,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:37,849 INFO:     Epoch: 85
2022-12-31 10:02:39,461 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40230007767677306, 'Total loss': 0.40230007767677306} | train loss {'Reaction outcome loss': 0.2561358051307911, 'Total loss': 0.2561358051307911}
2022-12-31 10:02:39,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:39,462 INFO:     Epoch: 86
2022-12-31 10:02:41,105 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43713854253292084, 'Total loss': 0.43713854253292084} | train loss {'Reaction outcome loss': 0.22747446727547524, 'Total loss': 0.22747446727547524}
2022-12-31 10:02:41,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:41,106 INFO:     Epoch: 87
2022-12-31 10:02:42,727 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3923199901978175, 'Total loss': 0.3923199901978175} | train loss {'Reaction outcome loss': 0.22550416865282308, 'Total loss': 0.22550416865282308}
2022-12-31 10:02:42,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:42,727 INFO:     Epoch: 88
2022-12-31 10:02:44,351 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4243478844563166, 'Total loss': 0.4243478844563166} | train loss {'Reaction outcome loss': 0.21574721645489606, 'Total loss': 0.21574721645489606}
2022-12-31 10:02:44,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:44,351 INFO:     Epoch: 89
2022-12-31 10:02:45,955 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3999057153860728, 'Total loss': 0.3999057153860728} | train loss {'Reaction outcome loss': 0.21544293454591779, 'Total loss': 0.21544293454591779}
2022-12-31 10:02:45,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:45,955 INFO:     Epoch: 90
2022-12-31 10:02:47,573 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3410524715979894, 'Total loss': 0.3410524715979894} | train loss {'Reaction outcome loss': 0.21315028144053413, 'Total loss': 0.21315028144053413}
2022-12-31 10:02:47,573 INFO:     Found new best model at epoch 90
2022-12-31 10:02:47,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:47,574 INFO:     Epoch: 91
2022-12-31 10:02:49,178 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3845012390986085, 'Total loss': 0.3845012390986085} | train loss {'Reaction outcome loss': 0.20790516122149816, 'Total loss': 0.20790516122149816}
2022-12-31 10:02:49,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:49,178 INFO:     Epoch: 92
2022-12-31 10:02:50,846 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4172769069671631, 'Total loss': 0.4172769069671631} | train loss {'Reaction outcome loss': 0.2098777275853048, 'Total loss': 0.2098777275853048}
2022-12-31 10:02:50,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:50,848 INFO:     Epoch: 93
2022-12-31 10:02:52,479 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48140672942002616, 'Total loss': 0.48140672942002616} | train loss {'Reaction outcome loss': 0.21384724428661275, 'Total loss': 0.21384724428661275}
2022-12-31 10:02:52,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:52,479 INFO:     Epoch: 94
2022-12-31 10:02:54,076 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41450990637143453, 'Total loss': 0.41450990637143453} | train loss {'Reaction outcome loss': 0.25392629543568834, 'Total loss': 0.25392629543568834}
2022-12-31 10:02:54,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:54,076 INFO:     Epoch: 95
2022-12-31 10:02:55,694 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.37622976005077363, 'Total loss': 0.37622976005077363} | train loss {'Reaction outcome loss': 0.2188652726107635, 'Total loss': 0.2188652726107635}
2022-12-31 10:02:55,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:55,694 INFO:     Epoch: 96
2022-12-31 10:02:57,311 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3759962181250254, 'Total loss': 0.3759962181250254} | train loss {'Reaction outcome loss': 0.20757273848352453, 'Total loss': 0.20757273848352453}
2022-12-31 10:02:57,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:57,312 INFO:     Epoch: 97
2022-12-31 10:02:58,908 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40638108452161154, 'Total loss': 0.40638108452161154} | train loss {'Reaction outcome loss': 0.2109148371973129, 'Total loss': 0.2109148371973129}
2022-12-31 10:02:58,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:02:58,909 INFO:     Epoch: 98
2022-12-31 10:03:00,526 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3585773547490438, 'Total loss': 0.3585773547490438} | train loss {'Reaction outcome loss': 0.20675683005243048, 'Total loss': 0.20675683005243048}
2022-12-31 10:03:00,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:00,526 INFO:     Epoch: 99
2022-12-31 10:03:02,145 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3963509122530619, 'Total loss': 0.3963509122530619} | train loss {'Reaction outcome loss': 0.20852924796328307, 'Total loss': 0.20852924796328307}
2022-12-31 10:03:02,145 INFO:     Best model found after epoch 91 of 100.
2022-12-31 10:03:02,145 INFO:   Done with stage: TRAINING
2022-12-31 10:03:02,145 INFO:   Starting stage: EVALUATION
2022-12-31 10:03:02,271 INFO:   Done with stage: EVALUATION
2022-12-31 10:03:02,271 INFO:   Leaving out SEQ value Fold_2
2022-12-31 10:03:02,284 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 10:03:02,284 INFO:   Starting stage: FEATURE SCALING
2022-12-31 10:03:02,923 INFO:   Done with stage: FEATURE SCALING
2022-12-31 10:03:02,923 INFO:   Starting stage: SCALING TARGETS
2022-12-31 10:03:02,991 INFO:   Done with stage: SCALING TARGETS
2022-12-31 10:03:02,991 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:03:02,992 INFO:     No hyperparam tuning for this model
2022-12-31 10:03:02,992 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:03:02,992 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 10:03:02,992 INFO:     None feature selector for col prot
2022-12-31 10:03:02,992 INFO:     None feature selector for col prot
2022-12-31 10:03:02,993 INFO:     None feature selector for col prot
2022-12-31 10:03:02,993 INFO:     None feature selector for col chem
2022-12-31 10:03:02,993 INFO:     None feature selector for col chem
2022-12-31 10:03:02,993 INFO:     None feature selector for col chem
2022-12-31 10:03:02,993 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 10:03:02,993 INFO:   Starting stage: BUILD MODEL
2022-12-31 10:03:02,995 INFO:     Number of params in model 223921
2022-12-31 10:03:02,998 INFO:   Done with stage: BUILD MODEL
2022-12-31 10:03:02,998 INFO:   Starting stage: TRAINING
2022-12-31 10:03:03,043 INFO:     Val loss before train {'Reaction outcome loss': 1.1336515506108602, 'Total loss': 1.1336515506108602}
2022-12-31 10:03:03,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:03,043 INFO:     Epoch: 0
2022-12-31 10:03:04,676 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7837820867697398, 'Total loss': 0.7837820867697398} | train loss {'Reaction outcome loss': 0.8421071947273546, 'Total loss': 0.8421071947273546}
2022-12-31 10:03:04,676 INFO:     Found new best model at epoch 0
2022-12-31 10:03:04,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:04,677 INFO:     Epoch: 1
2022-12-31 10:03:06,283 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5938675343990326, 'Total loss': 0.5938675343990326} | train loss {'Reaction outcome loss': 0.6074348139393069, 'Total loss': 0.6074348139393069}
2022-12-31 10:03:06,283 INFO:     Found new best model at epoch 1
2022-12-31 10:03:06,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:06,284 INFO:     Epoch: 2
2022-12-31 10:03:07,869 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6146197140216827, 'Total loss': 0.6146197140216827} | train loss {'Reaction outcome loss': 0.5303794521920002, 'Total loss': 0.5303794521920002}
2022-12-31 10:03:07,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:07,869 INFO:     Epoch: 3
2022-12-31 10:03:09,474 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5795182685057322, 'Total loss': 0.5795182685057322} | train loss {'Reaction outcome loss': 0.5106168498631811, 'Total loss': 0.5106168498631811}
2022-12-31 10:03:09,474 INFO:     Found new best model at epoch 3
2022-12-31 10:03:09,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:09,475 INFO:     Epoch: 4
2022-12-31 10:03:11,077 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5823239187399546, 'Total loss': 0.5823239187399546} | train loss {'Reaction outcome loss': 0.49391147526946383, 'Total loss': 0.49391147526946383}
2022-12-31 10:03:11,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:11,077 INFO:     Epoch: 5
2022-12-31 10:03:12,665 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.588076251745224, 'Total loss': 0.588076251745224} | train loss {'Reaction outcome loss': 0.4867532176584223, 'Total loss': 0.4867532176584223}
2022-12-31 10:03:12,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:12,665 INFO:     Epoch: 6
2022-12-31 10:03:14,272 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5748203337192536, 'Total loss': 0.5748203337192536} | train loss {'Reaction outcome loss': 0.47649186354701534, 'Total loss': 0.47649186354701534}
2022-12-31 10:03:14,273 INFO:     Found new best model at epoch 6
2022-12-31 10:03:14,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:14,274 INFO:     Epoch: 7
2022-12-31 10:03:15,860 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5508013844490052, 'Total loss': 0.5508013844490052} | train loss {'Reaction outcome loss': 0.46989555170174935, 'Total loss': 0.46989555170174935}
2022-12-31 10:03:15,860 INFO:     Found new best model at epoch 7
2022-12-31 10:03:15,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:15,861 INFO:     Epoch: 8
2022-12-31 10:03:17,478 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5456112424532572, 'Total loss': 0.5456112424532572} | train loss {'Reaction outcome loss': 0.46350636485501795, 'Total loss': 0.46350636485501795}
2022-12-31 10:03:17,479 INFO:     Found new best model at epoch 8
2022-12-31 10:03:17,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:17,480 INFO:     Epoch: 9
2022-12-31 10:03:19,084 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.543360318740209, 'Total loss': 0.543360318740209} | train loss {'Reaction outcome loss': 0.456504222195949, 'Total loss': 0.456504222195949}
2022-12-31 10:03:19,084 INFO:     Found new best model at epoch 9
2022-12-31 10:03:19,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:19,085 INFO:     Epoch: 10
2022-12-31 10:03:20,668 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5528780221939087, 'Total loss': 0.5528780221939087} | train loss {'Reaction outcome loss': 0.4530755629232765, 'Total loss': 0.4530755629232765}
2022-12-31 10:03:20,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:20,669 INFO:     Epoch: 11
2022-12-31 10:03:22,326 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5552788376808167, 'Total loss': 0.5552788376808167} | train loss {'Reaction outcome loss': 0.44387549529001663, 'Total loss': 0.44387549529001663}
2022-12-31 10:03:22,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:22,327 INFO:     Epoch: 12
2022-12-31 10:03:23,911 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5368417819341024, 'Total loss': 0.5368417819341024} | train loss {'Reaction outcome loss': 0.43449025454312346, 'Total loss': 0.43449025454312346}
2022-12-31 10:03:23,912 INFO:     Found new best model at epoch 12
2022-12-31 10:03:23,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:23,913 INFO:     Epoch: 13
2022-12-31 10:03:25,520 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5371139248212179, 'Total loss': 0.5371139248212179} | train loss {'Reaction outcome loss': 0.4314798057677537, 'Total loss': 0.4314798057677537}
2022-12-31 10:03:25,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:25,520 INFO:     Epoch: 14
2022-12-31 10:03:27,123 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5241940498352051, 'Total loss': 0.5241940498352051} | train loss {'Reaction outcome loss': 0.4260943915395841, 'Total loss': 0.4260943915395841}
2022-12-31 10:03:27,123 INFO:     Found new best model at epoch 14
2022-12-31 10:03:27,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:27,124 INFO:     Epoch: 15
2022-12-31 10:03:28,724 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5107934435208639, 'Total loss': 0.5107934435208639} | train loss {'Reaction outcome loss': 0.4168041076674296, 'Total loss': 0.4168041076674296}
2022-12-31 10:03:28,724 INFO:     Found new best model at epoch 15
2022-12-31 10:03:28,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:28,725 INFO:     Epoch: 16
2022-12-31 10:03:30,310 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5485615958770116, 'Total loss': 0.5485615958770116} | train loss {'Reaction outcome loss': 0.41532019705232914, 'Total loss': 0.41532019705232914}
2022-12-31 10:03:30,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:30,311 INFO:     Epoch: 17
2022-12-31 10:03:31,913 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5220008671283722, 'Total loss': 0.5220008671283722} | train loss {'Reaction outcome loss': 0.41146987774511323, 'Total loss': 0.41146987774511323}
2022-12-31 10:03:31,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:31,913 INFO:     Epoch: 18
2022-12-31 10:03:33,515 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5326379299163818, 'Total loss': 0.5326379299163818} | train loss {'Reaction outcome loss': 0.40502288975637324, 'Total loss': 0.40502288975637324}
2022-12-31 10:03:33,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:33,515 INFO:     Epoch: 19
2022-12-31 10:03:35,097 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5547544896602631, 'Total loss': 0.5547544896602631} | train loss {'Reaction outcome loss': 0.3941905455813356, 'Total loss': 0.3941905455813356}
2022-12-31 10:03:35,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:35,098 INFO:     Epoch: 20
2022-12-31 10:03:36,697 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5055169602235158, 'Total loss': 0.5055169602235158} | train loss {'Reaction outcome loss': 0.39076578780247345, 'Total loss': 0.39076578780247345}
2022-12-31 10:03:36,698 INFO:     Found new best model at epoch 20
2022-12-31 10:03:36,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:36,699 INFO:     Epoch: 21
2022-12-31 10:03:38,291 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5028456603487332, 'Total loss': 0.5028456603487332} | train loss {'Reaction outcome loss': 0.3824365594471893, 'Total loss': 0.3824365594471893}
2022-12-31 10:03:38,291 INFO:     Found new best model at epoch 21
2022-12-31 10:03:38,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:38,292 INFO:     Epoch: 22
2022-12-31 10:03:39,879 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5235583682854971, 'Total loss': 0.5235583682854971} | train loss {'Reaction outcome loss': 0.37463269853135095, 'Total loss': 0.37463269853135095}
2022-12-31 10:03:39,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:39,879 INFO:     Epoch: 23
2022-12-31 10:03:41,488 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5164300759633382, 'Total loss': 0.5164300759633382} | train loss {'Reaction outcome loss': 0.37488849524979606, 'Total loss': 0.37488849524979606}
2022-12-31 10:03:41,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:41,488 INFO:     Epoch: 24
2022-12-31 10:03:43,069 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5062807460625967, 'Total loss': 0.5062807460625967} | train loss {'Reaction outcome loss': 0.37061852602845563, 'Total loss': 0.37061852602845563}
2022-12-31 10:03:43,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:43,070 INFO:     Epoch: 25
2022-12-31 10:03:44,671 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4915688931941986, 'Total loss': 0.4915688931941986} | train loss {'Reaction outcome loss': 0.35869569807265794, 'Total loss': 0.35869569807265794}
2022-12-31 10:03:44,671 INFO:     Found new best model at epoch 25
2022-12-31 10:03:44,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:44,672 INFO:     Epoch: 26
2022-12-31 10:03:46,273 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5030745406945546, 'Total loss': 0.5030745406945546} | train loss {'Reaction outcome loss': 0.36238463424200557, 'Total loss': 0.36238463424200557}
2022-12-31 10:03:46,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:46,273 INFO:     Epoch: 27
2022-12-31 10:03:47,872 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5383475363254547, 'Total loss': 0.5383475363254547} | train loss {'Reaction outcome loss': 0.3531918344597747, 'Total loss': 0.3531918344597747}
2022-12-31 10:03:47,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:47,872 INFO:     Epoch: 28
2022-12-31 10:03:49,488 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5206176300843557, 'Total loss': 0.5206176300843557} | train loss {'Reaction outcome loss': 0.35376568617176835, 'Total loss': 0.35376568617176835}
2022-12-31 10:03:49,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:49,489 INFO:     Epoch: 29
2022-12-31 10:03:51,089 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4924537817637126, 'Total loss': 0.4924537817637126} | train loss {'Reaction outcome loss': 0.34604547542594644, 'Total loss': 0.34604547542594644}
2022-12-31 10:03:51,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:51,089 INFO:     Epoch: 30
2022-12-31 10:03:52,671 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5096605092287063, 'Total loss': 0.5096605092287063} | train loss {'Reaction outcome loss': 0.33963394746945724, 'Total loss': 0.33963394746945724}
2022-12-31 10:03:52,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:52,672 INFO:     Epoch: 31
2022-12-31 10:03:54,273 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.49005897839864093, 'Total loss': 0.49005897839864093} | train loss {'Reaction outcome loss': 0.3313262202661403, 'Total loss': 0.3313262202661403}
2022-12-31 10:03:54,273 INFO:     Found new best model at epoch 31
2022-12-31 10:03:54,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:54,274 INFO:     Epoch: 32
2022-12-31 10:03:55,877 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4918316423892975, 'Total loss': 0.4918316423892975} | train loss {'Reaction outcome loss': 0.327530136563047, 'Total loss': 0.327530136563047}
2022-12-31 10:03:55,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:55,877 INFO:     Epoch: 33
2022-12-31 10:03:57,463 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45509978433450066, 'Total loss': 0.45509978433450066} | train loss {'Reaction outcome loss': 0.3307809570845026, 'Total loss': 0.3307809570845026}
2022-12-31 10:03:57,465 INFO:     Found new best model at epoch 33
2022-12-31 10:03:57,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:57,466 INFO:     Epoch: 34
2022-12-31 10:03:59,086 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48274327715237936, 'Total loss': 0.48274327715237936} | train loss {'Reaction outcome loss': 0.32260498544541155, 'Total loss': 0.32260498544541155}
2022-12-31 10:03:59,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:03:59,086 INFO:     Epoch: 35
2022-12-31 10:04:00,682 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.48892733454704285, 'Total loss': 0.48892733454704285} | train loss {'Reaction outcome loss': 0.315284971881957, 'Total loss': 0.315284971881957}
2022-12-31 10:04:00,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:00,682 INFO:     Epoch: 36
2022-12-31 10:04:02,315 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4549307937423388, 'Total loss': 0.4549307937423388} | train loss {'Reaction outcome loss': 0.3200937248494503, 'Total loss': 0.3200937248494503}
2022-12-31 10:04:02,315 INFO:     Found new best model at epoch 36
2022-12-31 10:04:02,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:02,316 INFO:     Epoch: 37
2022-12-31 10:04:03,909 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4617388218641281, 'Total loss': 0.4617388218641281} | train loss {'Reaction outcome loss': 0.31402707354158815, 'Total loss': 0.31402707354158815}
2022-12-31 10:04:03,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:03,910 INFO:     Epoch: 38
2022-12-31 10:04:05,494 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5051194667816162, 'Total loss': 0.5051194667816162} | train loss {'Reaction outcome loss': 0.3056616620942406, 'Total loss': 0.3056616620942406}
2022-12-31 10:04:05,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:05,495 INFO:     Epoch: 39
2022-12-31 10:04:07,090 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46178140342235563, 'Total loss': 0.46178140342235563} | train loss {'Reaction outcome loss': 0.30448878877354363, 'Total loss': 0.30448878877354363}
2022-12-31 10:04:07,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:07,090 INFO:     Epoch: 40
2022-12-31 10:04:08,692 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48916290054718653, 'Total loss': 0.48916290054718653} | train loss {'Reaction outcome loss': 0.30311375419969544, 'Total loss': 0.30311375419969544}
2022-12-31 10:04:08,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:08,692 INFO:     Epoch: 41
2022-12-31 10:04:10,277 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5050065060456593, 'Total loss': 0.5050065060456593} | train loss {'Reaction outcome loss': 0.2947892104785373, 'Total loss': 0.2947892104785373}
2022-12-31 10:04:10,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:10,277 INFO:     Epoch: 42
2022-12-31 10:04:11,880 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.49234821597735084, 'Total loss': 0.49234821597735084} | train loss {'Reaction outcome loss': 0.29166014705968163, 'Total loss': 0.29166014705968163}
2022-12-31 10:04:11,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:11,880 INFO:     Epoch: 43
2022-12-31 10:04:13,482 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4699855377276739, 'Total loss': 0.4699855377276739} | train loss {'Reaction outcome loss': 0.2932150836245422, 'Total loss': 0.2932150836245422}
2022-12-31 10:04:13,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:13,483 INFO:     Epoch: 44
2022-12-31 10:04:15,074 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5258212228616078, 'Total loss': 0.5258212228616078} | train loss {'Reaction outcome loss': 0.29120110952886785, 'Total loss': 0.29120110952886785}
2022-12-31 10:04:15,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:15,075 INFO:     Epoch: 45
2022-12-31 10:04:16,679 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45866379340489705, 'Total loss': 0.45866379340489705} | train loss {'Reaction outcome loss': 0.28833460758854873, 'Total loss': 0.28833460758854873}
2022-12-31 10:04:16,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:16,680 INFO:     Epoch: 46
2022-12-31 10:04:18,281 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4948636700709661, 'Total loss': 0.4948636700709661} | train loss {'Reaction outcome loss': 0.28816863739468757, 'Total loss': 0.28816863739468757}
2022-12-31 10:04:18,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:18,281 INFO:     Epoch: 47
2022-12-31 10:04:19,890 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47364125748475394, 'Total loss': 0.47364125748475394} | train loss {'Reaction outcome loss': 0.28148533787279234, 'Total loss': 0.28148533787279234}
2022-12-31 10:04:19,891 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:19,891 INFO:     Epoch: 48
2022-12-31 10:04:21,516 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5042362531026204, 'Total loss': 0.5042362531026204} | train loss {'Reaction outcome loss': 0.271795546472834, 'Total loss': 0.271795546472834}
2022-12-31 10:04:21,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:21,516 INFO:     Epoch: 49
2022-12-31 10:04:23,122 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47337681452433267, 'Total loss': 0.47337681452433267} | train loss {'Reaction outcome loss': 0.28717906735021703, 'Total loss': 0.28717906735021703}
2022-12-31 10:04:23,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:23,123 INFO:     Epoch: 50
2022-12-31 10:04:24,742 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47384138305981954, 'Total loss': 0.47384138305981954} | train loss {'Reaction outcome loss': 0.2756482604891062, 'Total loss': 0.2756482604891062}
2022-12-31 10:04:24,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:24,742 INFO:     Epoch: 51
2022-12-31 10:04:26,357 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47697630325953166, 'Total loss': 0.47697630325953166} | train loss {'Reaction outcome loss': 0.27289593072241025, 'Total loss': 0.27289593072241025}
2022-12-31 10:04:26,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:26,357 INFO:     Epoch: 52
2022-12-31 10:04:27,947 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.49587429165840147, 'Total loss': 0.49587429165840147} | train loss {'Reaction outcome loss': 0.28119790578519344, 'Total loss': 0.28119790578519344}
2022-12-31 10:04:27,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:27,948 INFO:     Epoch: 53
2022-12-31 10:04:29,541 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.490760999917984, 'Total loss': 0.490760999917984} | train loss {'Reaction outcome loss': 0.2661122030503776, 'Total loss': 0.2661122030503776}
2022-12-31 10:04:29,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:29,541 INFO:     Epoch: 54
2022-12-31 10:04:31,154 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4494415173927943, 'Total loss': 0.4494415173927943} | train loss {'Reaction outcome loss': 0.2637598683282624, 'Total loss': 0.2637598683282624}
2022-12-31 10:04:31,154 INFO:     Found new best model at epoch 54
2022-12-31 10:04:31,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:31,155 INFO:     Epoch: 55
2022-12-31 10:04:32,741 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47778517256180447, 'Total loss': 0.47778517256180447} | train loss {'Reaction outcome loss': 0.26280313446084513, 'Total loss': 0.26280313446084513}
2022-12-31 10:04:32,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:32,743 INFO:     Epoch: 56
2022-12-31 10:04:34,346 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4405940890312195, 'Total loss': 0.4405940890312195} | train loss {'Reaction outcome loss': 0.2644784487783909, 'Total loss': 0.2644784487783909}
2022-12-31 10:04:34,346 INFO:     Found new best model at epoch 56
2022-12-31 10:04:34,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:34,347 INFO:     Epoch: 57
2022-12-31 10:04:35,950 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43737052083015443, 'Total loss': 0.43737052083015443} | train loss {'Reaction outcome loss': 0.2577620420033914, 'Total loss': 0.2577620420033914}
2022-12-31 10:04:35,950 INFO:     Found new best model at epoch 57
2022-12-31 10:04:35,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:35,951 INFO:     Epoch: 58
2022-12-31 10:04:37,532 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4677267005046209, 'Total loss': 0.4677267005046209} | train loss {'Reaction outcome loss': 0.2587800427564304, 'Total loss': 0.2587800427564304}
2022-12-31 10:04:37,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:37,532 INFO:     Epoch: 59
2022-12-31 10:04:39,135 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4604890783627828, 'Total loss': 0.4604890783627828} | train loss {'Reaction outcome loss': 0.25061054213693107, 'Total loss': 0.25061054213693107}
2022-12-31 10:04:39,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:39,136 INFO:     Epoch: 60
2022-12-31 10:04:40,745 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.46530515551567075, 'Total loss': 0.46530515551567075} | train loss {'Reaction outcome loss': 0.24594795223950905, 'Total loss': 0.24594795223950905}
2022-12-31 10:04:40,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:40,746 INFO:     Epoch: 61
2022-12-31 10:04:42,338 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47054558495680493, 'Total loss': 0.47054558495680493} | train loss {'Reaction outcome loss': 0.25348987809661094, 'Total loss': 0.25348987809661094}
2022-12-31 10:04:42,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:42,338 INFO:     Epoch: 62
2022-12-31 10:04:43,945 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47789987723032634, 'Total loss': 0.47789987723032634} | train loss {'Reaction outcome loss': 0.24804365783114068, 'Total loss': 0.24804365783114068}
2022-12-31 10:04:43,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:43,945 INFO:     Epoch: 63
2022-12-31 10:04:45,555 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46509417990843455, 'Total loss': 0.46509417990843455} | train loss {'Reaction outcome loss': 0.25303226527180117, 'Total loss': 0.25303226527180117}
2022-12-31 10:04:45,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:45,555 INFO:     Epoch: 64
2022-12-31 10:04:47,130 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43664318372805916, 'Total loss': 0.43664318372805916} | train loss {'Reaction outcome loss': 0.24573386733821273, 'Total loss': 0.24573386733821273}
2022-12-31 10:04:47,130 INFO:     Found new best model at epoch 64
2022-12-31 10:04:47,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:47,131 INFO:     Epoch: 65
2022-12-31 10:04:48,735 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4341505030790965, 'Total loss': 0.4341505030790965} | train loss {'Reaction outcome loss': 0.24207942031432678, 'Total loss': 0.24207942031432678}
2022-12-31 10:04:48,735 INFO:     Found new best model at epoch 65
2022-12-31 10:04:48,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:48,736 INFO:     Epoch: 66
2022-12-31 10:04:50,338 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.413472784558932, 'Total loss': 0.413472784558932} | train loss {'Reaction outcome loss': 0.24492073591363472, 'Total loss': 0.24492073591363472}
2022-12-31 10:04:50,339 INFO:     Found new best model at epoch 66
2022-12-31 10:04:50,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:50,340 INFO:     Epoch: 67
2022-12-31 10:04:51,961 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4422245055437088, 'Total loss': 0.4422245055437088} | train loss {'Reaction outcome loss': 0.24218346561937437, 'Total loss': 0.24218346561937437}
2022-12-31 10:04:51,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:51,962 INFO:     Epoch: 68
2022-12-31 10:04:53,594 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43874533052245773, 'Total loss': 0.43874533052245773} | train loss {'Reaction outcome loss': 0.23633178890458423, 'Total loss': 0.23633178890458423}
2022-12-31 10:04:53,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:53,594 INFO:     Epoch: 69
2022-12-31 10:04:55,180 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46109918653965, 'Total loss': 0.46109918653965} | train loss {'Reaction outcome loss': 0.24502427205375402, 'Total loss': 0.24502427205375402}
2022-12-31 10:04:55,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:55,180 INFO:     Epoch: 70
2022-12-31 10:04:56,773 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.47531559467315676, 'Total loss': 0.47531559467315676} | train loss {'Reaction outcome loss': 0.2390075149898329, 'Total loss': 0.2390075149898329}
2022-12-31 10:04:56,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:56,773 INFO:     Epoch: 71
2022-12-31 10:04:58,408 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4808719952901204, 'Total loss': 0.4808719952901204} | train loss {'Reaction outcome loss': 0.238353042421441, 'Total loss': 0.238353042421441}
2022-12-31 10:04:58,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:04:58,408 INFO:     Epoch: 72
2022-12-31 10:05:00,029 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4159107302625974, 'Total loss': 0.4159107302625974} | train loss {'Reaction outcome loss': 0.23655944839663748, 'Total loss': 0.23655944839663748}
2022-12-31 10:05:00,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:00,029 INFO:     Epoch: 73
2022-12-31 10:05:01,632 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4238362282514572, 'Total loss': 0.4238362282514572} | train loss {'Reaction outcome loss': 0.23182886297794153, 'Total loss': 0.23182886297794153}
2022-12-31 10:05:01,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:01,632 INFO:     Epoch: 74
2022-12-31 10:05:03,236 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4380165954430898, 'Total loss': 0.4380165954430898} | train loss {'Reaction outcome loss': 0.2266861420451072, 'Total loss': 0.2266861420451072}
2022-12-31 10:05:03,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:03,237 INFO:     Epoch: 75
2022-12-31 10:05:04,654 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4424440761407216, 'Total loss': 0.4424440761407216} | train loss {'Reaction outcome loss': 0.23718720696948087, 'Total loss': 0.23718720696948087}
2022-12-31 10:05:04,654 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:04,654 INFO:     Epoch: 76
2022-12-31 10:05:05,721 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4296664396921794, 'Total loss': 0.4296664396921794} | train loss {'Reaction outcome loss': 0.22848051328239213, 'Total loss': 0.22848051328239213}
2022-12-31 10:05:05,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:05,722 INFO:     Epoch: 77
2022-12-31 10:05:06,787 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47728206117947897, 'Total loss': 0.47728206117947897} | train loss {'Reaction outcome loss': 0.2358422490638973, 'Total loss': 0.2358422490638973}
2022-12-31 10:05:06,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:06,787 INFO:     Epoch: 78
2022-12-31 10:05:07,860 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4353295207023621, 'Total loss': 0.4353295207023621} | train loss {'Reaction outcome loss': 0.2266454859330815, 'Total loss': 0.2266454859330815}
2022-12-31 10:05:07,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:07,860 INFO:     Epoch: 79
2022-12-31 10:05:08,996 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.48125302195549013, 'Total loss': 0.48125302195549013} | train loss {'Reaction outcome loss': 0.22592944231727263, 'Total loss': 0.22592944231727263}
2022-12-31 10:05:08,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:08,996 INFO:     Epoch: 80
2022-12-31 10:05:10,599 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44708265264829, 'Total loss': 0.44708265264829} | train loss {'Reaction outcome loss': 0.22673637765276172, 'Total loss': 0.22673637765276172}
2022-12-31 10:05:10,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:10,600 INFO:     Epoch: 81
2022-12-31 10:05:12,201 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4240674351652463, 'Total loss': 0.4240674351652463} | train loss {'Reaction outcome loss': 0.21978355384003506, 'Total loss': 0.21978355384003506}
2022-12-31 10:05:12,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:12,202 INFO:     Epoch: 82
2022-12-31 10:05:13,847 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4125730961561203, 'Total loss': 0.4125730961561203} | train loss {'Reaction outcome loss': 0.22493789448355236, 'Total loss': 0.22493789448355236}
2022-12-31 10:05:13,847 INFO:     Found new best model at epoch 82
2022-12-31 10:05:13,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:13,848 INFO:     Epoch: 83
2022-12-31 10:05:15,490 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45109294056892396, 'Total loss': 0.45109294056892396} | train loss {'Reaction outcome loss': 0.22537776460041747, 'Total loss': 0.22537776460041747}
2022-12-31 10:05:15,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:15,490 INFO:     Epoch: 84
2022-12-31 10:05:17,055 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40944498082002007, 'Total loss': 0.40944498082002007} | train loss {'Reaction outcome loss': 0.2156336192707837, 'Total loss': 0.2156336192707837}
2022-12-31 10:05:17,055 INFO:     Found new best model at epoch 84
2022-12-31 10:05:17,056 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:17,056 INFO:     Epoch: 85
2022-12-31 10:05:18,669 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44641496042410533, 'Total loss': 0.44641496042410533} | train loss {'Reaction outcome loss': 0.21670493684423559, 'Total loss': 0.21670493684423559}
2022-12-31 10:05:18,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:18,670 INFO:     Epoch: 86
2022-12-31 10:05:20,318 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4341698626677195, 'Total loss': 0.4341698626677195} | train loss {'Reaction outcome loss': 0.2168375469852973, 'Total loss': 0.2168375469852973}
2022-12-31 10:05:20,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:20,318 INFO:     Epoch: 87
2022-12-31 10:05:21,964 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4747968912124634, 'Total loss': 0.4747968912124634} | train loss {'Reaction outcome loss': 0.22232978362726033, 'Total loss': 0.22232978362726033}
2022-12-31 10:05:21,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:21,964 INFO:     Epoch: 88
2022-12-31 10:05:23,612 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4874570469061534, 'Total loss': 0.4874570469061534} | train loss {'Reaction outcome loss': 0.2161596273853831, 'Total loss': 0.2161596273853831}
2022-12-31 10:05:23,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:23,613 INFO:     Epoch: 89
2022-12-31 10:05:25,227 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4187877617776394, 'Total loss': 0.4187877617776394} | train loss {'Reaction outcome loss': 0.215748637255254, 'Total loss': 0.215748637255254}
2022-12-31 10:05:25,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:25,228 INFO:     Epoch: 90
2022-12-31 10:05:26,832 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5244015326102575, 'Total loss': 0.5244015326102575} | train loss {'Reaction outcome loss': 0.21046625255831403, 'Total loss': 0.21046625255831403}
2022-12-31 10:05:26,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:26,832 INFO:     Epoch: 91
2022-12-31 10:05:28,410 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4813514937957128, 'Total loss': 0.4813514937957128} | train loss {'Reaction outcome loss': 0.21419914406690285, 'Total loss': 0.21419914406690285}
2022-12-31 10:05:28,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:28,410 INFO:     Epoch: 92
2022-12-31 10:05:30,010 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43142893016338346, 'Total loss': 0.43142893016338346} | train loss {'Reaction outcome loss': 0.21310931002299716, 'Total loss': 0.21310931002299716}
2022-12-31 10:05:30,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:30,011 INFO:     Epoch: 93
2022-12-31 10:05:31,610 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46886924604574837, 'Total loss': 0.46886924604574837} | train loss {'Reaction outcome loss': 0.22391260076096675, 'Total loss': 0.22391260076096675}
2022-12-31 10:05:31,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:31,610 INFO:     Epoch: 94
2022-12-31 10:05:33,212 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4537509858608246, 'Total loss': 0.4537509858608246} | train loss {'Reaction outcome loss': 0.21606669668788023, 'Total loss': 0.21606669668788023}
2022-12-31 10:05:33,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:33,212 INFO:     Epoch: 95
2022-12-31 10:05:34,797 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4310415038838983, 'Total loss': 0.4310415038838983} | train loss {'Reaction outcome loss': 0.2121038797794141, 'Total loss': 0.2121038797794141}
2022-12-31 10:05:34,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:34,797 INFO:     Epoch: 96
2022-12-31 10:05:36,396 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48709775557120644, 'Total loss': 0.48709775557120644} | train loss {'Reaction outcome loss': 0.2102010379185098, 'Total loss': 0.2102010379185098}
2022-12-31 10:05:36,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:36,396 INFO:     Epoch: 97
2022-12-31 10:05:37,998 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4540194829305013, 'Total loss': 0.4540194829305013} | train loss {'Reaction outcome loss': 0.20280561072711092, 'Total loss': 0.20280561072711092}
2022-12-31 10:05:37,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:37,998 INFO:     Epoch: 98
2022-12-31 10:05:39,601 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4965759813785553, 'Total loss': 0.4965759813785553} | train loss {'Reaction outcome loss': 0.20855056333362404, 'Total loss': 0.20855056333362404}
2022-12-31 10:05:39,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:39,603 INFO:     Epoch: 99
2022-12-31 10:05:41,198 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4439833164215088, 'Total loss': 0.4439833164215088} | train loss {'Reaction outcome loss': 0.20873897456577606, 'Total loss': 0.20873897456577606}
2022-12-31 10:05:41,199 INFO:     Best model found after epoch 85 of 100.
2022-12-31 10:05:41,199 INFO:   Done with stage: TRAINING
2022-12-31 10:05:41,199 INFO:   Starting stage: EVALUATION
2022-12-31 10:05:41,331 INFO:   Done with stage: EVALUATION
2022-12-31 10:05:41,331 INFO:   Leaving out SEQ value Fold_3
2022-12-31 10:05:41,344 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 10:05:41,344 INFO:   Starting stage: FEATURE SCALING
2022-12-31 10:05:41,983 INFO:   Done with stage: FEATURE SCALING
2022-12-31 10:05:41,983 INFO:   Starting stage: SCALING TARGETS
2022-12-31 10:05:42,052 INFO:   Done with stage: SCALING TARGETS
2022-12-31 10:05:42,052 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:05:42,052 INFO:     No hyperparam tuning for this model
2022-12-31 10:05:42,052 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:05:42,052 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 10:05:42,053 INFO:     None feature selector for col prot
2022-12-31 10:05:42,053 INFO:     None feature selector for col prot
2022-12-31 10:05:42,053 INFO:     None feature selector for col prot
2022-12-31 10:05:42,053 INFO:     None feature selector for col chem
2022-12-31 10:05:42,053 INFO:     None feature selector for col chem
2022-12-31 10:05:42,054 INFO:     None feature selector for col chem
2022-12-31 10:05:42,054 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 10:05:42,054 INFO:   Starting stage: BUILD MODEL
2022-12-31 10:05:42,055 INFO:     Number of params in model 223921
2022-12-31 10:05:42,059 INFO:   Done with stage: BUILD MODEL
2022-12-31 10:05:42,059 INFO:   Starting stage: TRAINING
2022-12-31 10:05:42,103 INFO:     Val loss before train {'Reaction outcome loss': 0.9649502595265707, 'Total loss': 0.9649502595265707}
2022-12-31 10:05:42,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:42,103 INFO:     Epoch: 0
2022-12-31 10:05:43,680 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.667699807882309, 'Total loss': 0.667699807882309} | train loss {'Reaction outcome loss': 0.8020022595812987, 'Total loss': 0.8020022595812987}
2022-12-31 10:05:43,680 INFO:     Found new best model at epoch 0
2022-12-31 10:05:43,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:43,681 INFO:     Epoch: 1
2022-12-31 10:05:45,257 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5552618443965912, 'Total loss': 0.5552618443965912} | train loss {'Reaction outcome loss': 0.5833672614761325, 'Total loss': 0.5833672614761325}
2022-12-31 10:05:45,258 INFO:     Found new best model at epoch 1
2022-12-31 10:05:45,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:45,259 INFO:     Epoch: 2
2022-12-31 10:05:46,853 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6173955937226613, 'Total loss': 0.6173955937226613} | train loss {'Reaction outcome loss': 0.5212122959531708, 'Total loss': 0.5212122959531708}
2022-12-31 10:05:46,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:46,854 INFO:     Epoch: 3
2022-12-31 10:05:48,449 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5341541409492493, 'Total loss': 0.5341541409492493} | train loss {'Reaction outcome loss': 0.499512316215606, 'Total loss': 0.499512316215606}
2022-12-31 10:05:48,449 INFO:     Found new best model at epoch 3
2022-12-31 10:05:48,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:48,450 INFO:     Epoch: 4
2022-12-31 10:05:50,046 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.6098148107528687, 'Total loss': 0.6098148107528687} | train loss {'Reaction outcome loss': 0.47979112624467074, 'Total loss': 0.47979112624467074}
2022-12-31 10:05:50,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:50,046 INFO:     Epoch: 5
2022-12-31 10:05:51,634 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5207442204157512, 'Total loss': 0.5207442204157512} | train loss {'Reaction outcome loss': 0.4727711889333341, 'Total loss': 0.4727711889333341}
2022-12-31 10:05:51,634 INFO:     Found new best model at epoch 5
2022-12-31 10:05:51,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:51,635 INFO:     Epoch: 6
2022-12-31 10:05:53,270 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5109253744284312, 'Total loss': 0.5109253744284312} | train loss {'Reaction outcome loss': 0.46320556082349995, 'Total loss': 0.46320556082349995}
2022-12-31 10:05:53,270 INFO:     Found new best model at epoch 6
2022-12-31 10:05:53,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:53,271 INFO:     Epoch: 7
2022-12-31 10:05:54,856 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5082096775372823, 'Total loss': 0.5082096775372823} | train loss {'Reaction outcome loss': 0.4557252382729953, 'Total loss': 0.4557252382729953}
2022-12-31 10:05:54,856 INFO:     Found new best model at epoch 7
2022-12-31 10:05:54,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:54,857 INFO:     Epoch: 8
2022-12-31 10:05:56,441 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5146928528944651, 'Total loss': 0.5146928528944651} | train loss {'Reaction outcome loss': 0.45143500920180435, 'Total loss': 0.45143500920180435}
2022-12-31 10:05:56,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:56,441 INFO:     Epoch: 9
2022-12-31 10:05:58,036 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.516715443879366, 'Total loss': 0.516715443879366} | train loss {'Reaction outcome loss': 0.44008264374056144, 'Total loss': 0.44008264374056144}
2022-12-31 10:05:58,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:58,036 INFO:     Epoch: 10
2022-12-31 10:05:59,629 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5521472652753194, 'Total loss': 0.5521472652753194} | train loss {'Reaction outcome loss': 0.437047595342437, 'Total loss': 0.437047595342437}
2022-12-31 10:05:59,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:05:59,630 INFO:     Epoch: 11
2022-12-31 10:06:01,208 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.511488010485967, 'Total loss': 0.511488010485967} | train loss {'Reaction outcome loss': 0.42949380111563334, 'Total loss': 0.42949380111563334}
2022-12-31 10:06:01,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:01,209 INFO:     Epoch: 12
2022-12-31 10:06:02,857 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5269031683603923, 'Total loss': 0.5269031683603923} | train loss {'Reaction outcome loss': 0.4247767316661912, 'Total loss': 0.4247767316661912}
2022-12-31 10:06:02,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:02,857 INFO:     Epoch: 13
2022-12-31 10:06:04,448 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5337692429622014, 'Total loss': 0.5337692429622014} | train loss {'Reaction outcome loss': 0.42075333706761675, 'Total loss': 0.42075333706761675}
2022-12-31 10:06:04,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:04,448 INFO:     Epoch: 14
2022-12-31 10:06:06,094 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4957185705502828, 'Total loss': 0.4957185705502828} | train loss {'Reaction outcome loss': 0.41709832541453534, 'Total loss': 0.41709832541453534}
2022-12-31 10:06:06,094 INFO:     Found new best model at epoch 14
2022-12-31 10:06:06,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:06,095 INFO:     Epoch: 15
2022-12-31 10:06:07,741 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.49420811186234154, 'Total loss': 0.49420811186234154} | train loss {'Reaction outcome loss': 0.40192905425916226, 'Total loss': 0.40192905425916226}
2022-12-31 10:06:07,741 INFO:     Found new best model at epoch 15
2022-12-31 10:06:07,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:07,742 INFO:     Epoch: 16
2022-12-31 10:06:09,334 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4925471564133962, 'Total loss': 0.4925471564133962} | train loss {'Reaction outcome loss': 0.40701333520722477, 'Total loss': 0.40701333520722477}
2022-12-31 10:06:09,334 INFO:     Found new best model at epoch 16
2022-12-31 10:06:09,335 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:09,335 INFO:     Epoch: 17
2022-12-31 10:06:10,916 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49163757960001625, 'Total loss': 0.49163757960001625} | train loss {'Reaction outcome loss': 0.38780421310619556, 'Total loss': 0.38780421310619556}
2022-12-31 10:06:10,917 INFO:     Found new best model at epoch 17
2022-12-31 10:06:10,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:10,918 INFO:     Epoch: 18
2022-12-31 10:06:12,495 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4798783948024114, 'Total loss': 0.4798783948024114} | train loss {'Reaction outcome loss': 0.3864971420321709, 'Total loss': 0.3864971420321709}
2022-12-31 10:06:12,495 INFO:     Found new best model at epoch 18
2022-12-31 10:06:12,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:12,496 INFO:     Epoch: 19
2022-12-31 10:06:14,126 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49919955333073934, 'Total loss': 0.49919955333073934} | train loss {'Reaction outcome loss': 0.38158999570396357, 'Total loss': 0.38158999570396357}
2022-12-31 10:06:14,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:14,126 INFO:     Epoch: 20
2022-12-31 10:06:15,723 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5489158511161805, 'Total loss': 0.5489158511161805} | train loss {'Reaction outcome loss': 0.3759361286221188, 'Total loss': 0.3759361286221188}
2022-12-31 10:06:15,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:15,723 INFO:     Epoch: 21
2022-12-31 10:06:17,319 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47808130383491515, 'Total loss': 0.47808130383491515} | train loss {'Reaction outcome loss': 0.3766581186881432, 'Total loss': 0.3766581186881432}
2022-12-31 10:06:17,320 INFO:     Found new best model at epoch 21
2022-12-31 10:06:17,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:17,321 INFO:     Epoch: 22
2022-12-31 10:06:18,906 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46892510503530505, 'Total loss': 0.46892510503530505} | train loss {'Reaction outcome loss': 0.3610584347409916, 'Total loss': 0.3610584347409916}
2022-12-31 10:06:18,906 INFO:     Found new best model at epoch 22
2022-12-31 10:06:18,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:18,907 INFO:     Epoch: 23
2022-12-31 10:06:20,495 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46159373919169105, 'Total loss': 0.46159373919169105} | train loss {'Reaction outcome loss': 0.36531226274185563, 'Total loss': 0.36531226274185563}
2022-12-31 10:06:20,495 INFO:     Found new best model at epoch 23
2022-12-31 10:06:20,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:20,496 INFO:     Epoch: 24
2022-12-31 10:06:22,090 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4674495796362559, 'Total loss': 0.4674495796362559} | train loss {'Reaction outcome loss': 0.35582205420530544, 'Total loss': 0.35582205420530544}
2022-12-31 10:06:22,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:22,090 INFO:     Epoch: 25
2022-12-31 10:06:23,717 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5150751074155172, 'Total loss': 0.5150751074155172} | train loss {'Reaction outcome loss': 0.3511960905440998, 'Total loss': 0.3511960905440998}
2022-12-31 10:06:23,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:23,717 INFO:     Epoch: 26
2022-12-31 10:06:25,308 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4983943700790405, 'Total loss': 0.4983943700790405} | train loss {'Reaction outcome loss': 0.3475610036607627, 'Total loss': 0.3475610036607627}
2022-12-31 10:06:25,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:25,308 INFO:     Epoch: 27
2022-12-31 10:06:26,897 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47693560520807904, 'Total loss': 0.47693560520807904} | train loss {'Reaction outcome loss': 0.345442438627774, 'Total loss': 0.345442438627774}
2022-12-31 10:06:26,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:26,897 INFO:     Epoch: 28
2022-12-31 10:06:28,479 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4705256452163061, 'Total loss': 0.4705256452163061} | train loss {'Reaction outcome loss': 0.33581123955465936, 'Total loss': 0.33581123955465936}
2022-12-31 10:06:28,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:28,479 INFO:     Epoch: 29
2022-12-31 10:06:30,073 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47148393988609316, 'Total loss': 0.47148393988609316} | train loss {'Reaction outcome loss': 0.3388103463519842, 'Total loss': 0.3388103463519842}
2022-12-31 10:06:30,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:30,074 INFO:     Epoch: 30
2022-12-31 10:06:31,647 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.49950033028920493, 'Total loss': 0.49950033028920493} | train loss {'Reaction outcome loss': 0.328775782370087, 'Total loss': 0.328775782370087}
2022-12-31 10:06:31,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:31,648 INFO:     Epoch: 31
2022-12-31 10:06:33,240 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5253772914409638, 'Total loss': 0.5253772914409638} | train loss {'Reaction outcome loss': 0.33625920583586116, 'Total loss': 0.33625920583586116}
2022-12-31 10:06:33,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:33,240 INFO:     Epoch: 32
2022-12-31 10:06:34,832 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45743324359258014, 'Total loss': 0.45743324359258014} | train loss {'Reaction outcome loss': 0.321397592760486, 'Total loss': 0.321397592760486}
2022-12-31 10:06:34,832 INFO:     Found new best model at epoch 32
2022-12-31 10:06:34,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:34,833 INFO:     Epoch: 33
2022-12-31 10:06:36,428 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4343888034423192, 'Total loss': 0.4343888034423192} | train loss {'Reaction outcome loss': 0.32060810697056874, 'Total loss': 0.32060810697056874}
2022-12-31 10:06:36,428 INFO:     Found new best model at epoch 33
2022-12-31 10:06:36,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:36,429 INFO:     Epoch: 34
2022-12-31 10:06:38,008 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4353807846705119, 'Total loss': 0.4353807846705119} | train loss {'Reaction outcome loss': 0.3093135955746903, 'Total loss': 0.3093135955746903}
2022-12-31 10:06:38,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:38,008 INFO:     Epoch: 35
2022-12-31 10:06:39,576 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5270790179570516, 'Total loss': 0.5270790179570516} | train loss {'Reaction outcome loss': 0.31038548981586656, 'Total loss': 0.31038548981586656}
2022-12-31 10:06:39,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:39,576 INFO:     Epoch: 36
2022-12-31 10:06:41,215 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47261960109074913, 'Total loss': 0.47261960109074913} | train loss {'Reaction outcome loss': 0.3032228951871177, 'Total loss': 0.3032228951871177}
2022-12-31 10:06:41,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:41,216 INFO:     Epoch: 37
2022-12-31 10:06:42,856 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4561112293973565, 'Total loss': 0.4561112293973565} | train loss {'Reaction outcome loss': 0.301884829520415, 'Total loss': 0.301884829520415}
2022-12-31 10:06:42,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:42,856 INFO:     Epoch: 38
2022-12-31 10:06:44,491 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5195256431897481, 'Total loss': 0.5195256431897481} | train loss {'Reaction outcome loss': 0.3040912813565015, 'Total loss': 0.3040912813565015}
2022-12-31 10:06:44,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:44,491 INFO:     Epoch: 39
2022-12-31 10:06:46,083 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4426411479711533, 'Total loss': 0.4426411479711533} | train loss {'Reaction outcome loss': 0.2943430653203538, 'Total loss': 0.2943430653203538}
2022-12-31 10:06:46,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:46,084 INFO:     Epoch: 40
2022-12-31 10:06:47,676 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.43528586824735005, 'Total loss': 0.43528586824735005} | train loss {'Reaction outcome loss': 0.29469229005986736, 'Total loss': 0.29469229005986736}
2022-12-31 10:06:47,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:47,676 INFO:     Epoch: 41
2022-12-31 10:06:49,250 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45614907642205554, 'Total loss': 0.45614907642205554} | train loss {'Reaction outcome loss': 0.29382933380471155, 'Total loss': 0.29382933380471155}
2022-12-31 10:06:49,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:49,250 INFO:     Epoch: 42
2022-12-31 10:06:50,857 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44112415711085, 'Total loss': 0.44112415711085} | train loss {'Reaction outcome loss': 0.28685878700279926, 'Total loss': 0.28685878700279926}
2022-12-31 10:06:50,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:50,857 INFO:     Epoch: 43
2022-12-31 10:06:52,455 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4176004538933436, 'Total loss': 0.4176004538933436} | train loss {'Reaction outcome loss': 0.28773881212531865, 'Total loss': 0.28773881212531865}
2022-12-31 10:06:52,455 INFO:     Found new best model at epoch 43
2022-12-31 10:06:52,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:52,456 INFO:     Epoch: 44
2022-12-31 10:06:54,053 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44091314176718394, 'Total loss': 0.44091314176718394} | train loss {'Reaction outcome loss': 0.28064408005921393, 'Total loss': 0.28064408005921393}
2022-12-31 10:06:54,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:54,053 INFO:     Epoch: 45
2022-12-31 10:06:55,644 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4302442212899526, 'Total loss': 0.4302442212899526} | train loss {'Reaction outcome loss': 0.2801717432427319, 'Total loss': 0.2801717432427319}
2022-12-31 10:06:55,644 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:55,644 INFO:     Epoch: 46
2022-12-31 10:06:57,280 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46018414000670116, 'Total loss': 0.46018414000670116} | train loss {'Reaction outcome loss': 0.27188749343920976, 'Total loss': 0.27188749343920976}
2022-12-31 10:06:57,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:57,280 INFO:     Epoch: 47
2022-12-31 10:06:58,914 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40038227339585625, 'Total loss': 0.40038227339585625} | train loss {'Reaction outcome loss': 0.27334915585270075, 'Total loss': 0.27334915585270075}
2022-12-31 10:06:58,914 INFO:     Found new best model at epoch 47
2022-12-31 10:06:58,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:06:58,916 INFO:     Epoch: 48
2022-12-31 10:07:00,571 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4213459630807241, 'Total loss': 0.4213459630807241} | train loss {'Reaction outcome loss': 0.27251918059893143, 'Total loss': 0.27251918059893143}
2022-12-31 10:07:00,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:00,572 INFO:     Epoch: 49
2022-12-31 10:07:02,232 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4645752668380737, 'Total loss': 0.4645752668380737} | train loss {'Reaction outcome loss': 0.27234213264324725, 'Total loss': 0.27234213264324725}
2022-12-31 10:07:02,232 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:02,232 INFO:     Epoch: 50
2022-12-31 10:07:03,898 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4072091003259023, 'Total loss': 0.4072091003259023} | train loss {'Reaction outcome loss': 0.26717097108890286, 'Total loss': 0.26717097108890286}
2022-12-31 10:07:03,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:03,898 INFO:     Epoch: 51
2022-12-31 10:07:05,528 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.38285111784935, 'Total loss': 0.38285111784935} | train loss {'Reaction outcome loss': 0.26326778740536816, 'Total loss': 0.26326778740536816}
2022-12-31 10:07:05,528 INFO:     Found new best model at epoch 51
2022-12-31 10:07:05,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:05,530 INFO:     Epoch: 52
2022-12-31 10:07:07,164 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4034212271372477, 'Total loss': 0.4034212271372477} | train loss {'Reaction outcome loss': 0.2656722810979073, 'Total loss': 0.2656722810979073}
2022-12-31 10:07:07,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:07,164 INFO:     Epoch: 53
2022-12-31 10:07:08,843 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4347323735555013, 'Total loss': 0.4347323735555013} | train loss {'Reaction outcome loss': 0.2584219378975285, 'Total loss': 0.2584219378975285}
2022-12-31 10:07:08,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:08,844 INFO:     Epoch: 54
2022-12-31 10:07:10,493 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41772177318731946, 'Total loss': 0.41772177318731946} | train loss {'Reaction outcome loss': 0.2595052621003254, 'Total loss': 0.2595052621003254}
2022-12-31 10:07:10,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:10,494 INFO:     Epoch: 55
2022-12-31 10:07:12,109 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40571963687737783, 'Total loss': 0.40571963687737783} | train loss {'Reaction outcome loss': 0.25667712261606923, 'Total loss': 0.25667712261606923}
2022-12-31 10:07:12,109 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:12,109 INFO:     Epoch: 56
2022-12-31 10:07:13,739 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4843319207429886, 'Total loss': 0.4843319207429886} | train loss {'Reaction outcome loss': 0.2534677915056765, 'Total loss': 0.2534677915056765}
2022-12-31 10:07:13,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:13,739 INFO:     Epoch: 57
2022-12-31 10:07:15,380 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4282294357816378, 'Total loss': 0.4282294357816378} | train loss {'Reaction outcome loss': 0.2516329583435596, 'Total loss': 0.2516329583435596}
2022-12-31 10:07:15,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:15,380 INFO:     Epoch: 58
2022-12-31 10:07:16,970 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4283286392688751, 'Total loss': 0.4283286392688751} | train loss {'Reaction outcome loss': 0.2550460196785874, 'Total loss': 0.2550460196785874}
2022-12-31 10:07:16,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:16,971 INFO:     Epoch: 59
2022-12-31 10:07:18,610 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41318869491418203, 'Total loss': 0.41318869491418203} | train loss {'Reaction outcome loss': 0.250899759104182, 'Total loss': 0.250899759104182}
2022-12-31 10:07:18,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:18,610 INFO:     Epoch: 60
2022-12-31 10:07:20,190 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39906623562177024, 'Total loss': 0.39906623562177024} | train loss {'Reaction outcome loss': 0.25553711390484385, 'Total loss': 0.25553711390484385}
2022-12-31 10:07:20,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:20,190 INFO:     Epoch: 61
2022-12-31 10:07:21,766 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5140227089325587, 'Total loss': 0.5140227089325587} | train loss {'Reaction outcome loss': 0.25014291111475384, 'Total loss': 0.25014291111475384}
2022-12-31 10:07:21,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:21,767 INFO:     Epoch: 62
2022-12-31 10:07:23,353 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40574007978041965, 'Total loss': 0.40574007978041965} | train loss {'Reaction outcome loss': 0.2509514009477673, 'Total loss': 0.2509514009477673}
2022-12-31 10:07:23,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:23,353 INFO:     Epoch: 63
2022-12-31 10:07:24,950 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4282773047685623, 'Total loss': 0.4282773047685623} | train loss {'Reaction outcome loss': 0.2421093592931936, 'Total loss': 0.2421093592931936}
2022-12-31 10:07:24,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:24,950 INFO:     Epoch: 64
2022-12-31 10:07:26,558 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43965459493920206, 'Total loss': 0.43965459493920206} | train loss {'Reaction outcome loss': 0.24408136582472822, 'Total loss': 0.24408136582472822}
2022-12-31 10:07:26,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:26,558 INFO:     Epoch: 65
2022-12-31 10:07:28,212 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4558419644832611, 'Total loss': 0.4558419644832611} | train loss {'Reaction outcome loss': 0.24680020093863264, 'Total loss': 0.24680020093863264}
2022-12-31 10:07:28,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:28,212 INFO:     Epoch: 66
2022-12-31 10:07:29,860 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41218763490517935, 'Total loss': 0.41218763490517935} | train loss {'Reaction outcome loss': 0.24252476691372432, 'Total loss': 0.24252476691372432}
2022-12-31 10:07:29,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:29,860 INFO:     Epoch: 67
2022-12-31 10:07:31,466 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4105001469453176, 'Total loss': 0.4105001469453176} | train loss {'Reaction outcome loss': 0.24001928227834213, 'Total loss': 0.24001928227834213}
2022-12-31 10:07:31,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:31,467 INFO:     Epoch: 68
2022-12-31 10:07:33,037 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4462899684906006, 'Total loss': 0.4462899684906006} | train loss {'Reaction outcome loss': 0.24692907885754065, 'Total loss': 0.24692907885754065}
2022-12-31 10:07:33,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:33,037 INFO:     Epoch: 69
2022-12-31 10:07:34,631 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4006424923737844, 'Total loss': 0.4006424923737844} | train loss {'Reaction outcome loss': 0.2344638735581285, 'Total loss': 0.2344638735581285}
2022-12-31 10:07:34,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:34,631 INFO:     Epoch: 70
2022-12-31 10:07:36,239 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4098156680663427, 'Total loss': 0.4098156680663427} | train loss {'Reaction outcome loss': 0.23345979747290796, 'Total loss': 0.23345979747290796}
2022-12-31 10:07:36,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:36,240 INFO:     Epoch: 71
2022-12-31 10:07:37,881 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4370440860589345, 'Total loss': 0.4370440860589345} | train loss {'Reaction outcome loss': 0.23511552643508482, 'Total loss': 0.23511552643508482}
2022-12-31 10:07:37,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:37,881 INFO:     Epoch: 72
2022-12-31 10:07:39,529 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4257133404413859, 'Total loss': 0.4257133404413859} | train loss {'Reaction outcome loss': 0.232524193523131, 'Total loss': 0.232524193523131}
2022-12-31 10:07:39,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:39,529 INFO:     Epoch: 73
2022-12-31 10:07:41,172 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.501227276523908, 'Total loss': 0.501227276523908} | train loss {'Reaction outcome loss': 0.23045610397672042, 'Total loss': 0.23045610397672042}
2022-12-31 10:07:41,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:41,173 INFO:     Epoch: 74
2022-12-31 10:07:42,800 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4277328426639239, 'Total loss': 0.4277328426639239} | train loss {'Reaction outcome loss': 0.22882767092613948, 'Total loss': 0.22882767092613948}
2022-12-31 10:07:42,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:42,801 INFO:     Epoch: 75
2022-12-31 10:07:44,434 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4245854526758194, 'Total loss': 0.4245854526758194} | train loss {'Reaction outcome loss': 0.2282104147291118, 'Total loss': 0.2282104147291118}
2022-12-31 10:07:44,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:44,434 INFO:     Epoch: 76
2022-12-31 10:07:46,084 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3995658348004023, 'Total loss': 0.3995658348004023} | train loss {'Reaction outcome loss': 0.2281022313777562, 'Total loss': 0.2281022313777562}
2022-12-31 10:07:46,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:46,084 INFO:     Epoch: 77
2022-12-31 10:07:47,722 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4059026708205541, 'Total loss': 0.4059026708205541} | train loss {'Reaction outcome loss': 0.2266597716076361, 'Total loss': 0.2266597716076361}
2022-12-31 10:07:47,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:47,723 INFO:     Epoch: 78
2022-12-31 10:07:49,345 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4076690395673116, 'Total loss': 0.4076690395673116} | train loss {'Reaction outcome loss': 0.2271492377319288, 'Total loss': 0.2271492377319288}
2022-12-31 10:07:49,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:49,346 INFO:     Epoch: 79
2022-12-31 10:07:50,951 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41790403922398883, 'Total loss': 0.41790403922398883} | train loss {'Reaction outcome loss': 0.22379947137155812, 'Total loss': 0.22379947137155812}
2022-12-31 10:07:50,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:50,952 INFO:     Epoch: 80
2022-12-31 10:07:52,558 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3670043021440506, 'Total loss': 0.3670043021440506} | train loss {'Reaction outcome loss': 0.23151473520876287, 'Total loss': 0.23151473520876287}
2022-12-31 10:07:52,558 INFO:     Found new best model at epoch 80
2022-12-31 10:07:52,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:52,559 INFO:     Epoch: 81
2022-12-31 10:07:54,156 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41462312936782836, 'Total loss': 0.41462312936782836} | train loss {'Reaction outcome loss': 0.22553115120437336, 'Total loss': 0.22553115120437336}
2022-12-31 10:07:54,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:54,157 INFO:     Epoch: 82
2022-12-31 10:07:55,802 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44312100609143573, 'Total loss': 0.44312100609143573} | train loss {'Reaction outcome loss': 0.22008164873135178, 'Total loss': 0.22008164873135178}
2022-12-31 10:07:55,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:55,802 INFO:     Epoch: 83
2022-12-31 10:07:57,433 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3733770449956258, 'Total loss': 0.3733770449956258} | train loss {'Reaction outcome loss': 0.22291807682959588, 'Total loss': 0.22291807682959588}
2022-12-31 10:07:57,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:57,434 INFO:     Epoch: 84
2022-12-31 10:07:59,029 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3888092413544655, 'Total loss': 0.3888092413544655} | train loss {'Reaction outcome loss': 0.2176057149523071, 'Total loss': 0.2176057149523071}
2022-12-31 10:07:59,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:07:59,029 INFO:     Epoch: 85
2022-12-31 10:08:00,615 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4252166897058487, 'Total loss': 0.4252166897058487} | train loss {'Reaction outcome loss': 0.22072909802757887, 'Total loss': 0.22072909802757887}
2022-12-31 10:08:00,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:00,615 INFO:     Epoch: 86
2022-12-31 10:08:02,197 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3794495617349943, 'Total loss': 0.3794495617349943} | train loss {'Reaction outcome loss': 0.21523574698075051, 'Total loss': 0.21523574698075051}
2022-12-31 10:08:02,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:02,198 INFO:     Epoch: 87
2022-12-31 10:08:03,837 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4103352924187978, 'Total loss': 0.4103352924187978} | train loss {'Reaction outcome loss': 0.21676337124691122, 'Total loss': 0.21676337124691122}
2022-12-31 10:08:03,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:03,837 INFO:     Epoch: 88
2022-12-31 10:08:05,408 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.479252423842748, 'Total loss': 0.479252423842748} | train loss {'Reaction outcome loss': 0.21984800102782773, 'Total loss': 0.21984800102782773}
2022-12-31 10:08:05,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:05,408 INFO:     Epoch: 89
2022-12-31 10:08:07,028 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4368380228678385, 'Total loss': 0.4368380228678385} | train loss {'Reaction outcome loss': 0.2228952536270732, 'Total loss': 0.2228952536270732}
2022-12-31 10:08:07,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:07,029 INFO:     Epoch: 90
2022-12-31 10:08:08,641 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.38153373772899307, 'Total loss': 0.38153373772899307} | train loss {'Reaction outcome loss': 0.2178496175203404, 'Total loss': 0.2178496175203404}
2022-12-31 10:08:08,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:08,641 INFO:     Epoch: 91
2022-12-31 10:08:10,267 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43409514079491296, 'Total loss': 0.43409514079491296} | train loss {'Reaction outcome loss': 0.20940939971542621, 'Total loss': 0.20940939971542621}
2022-12-31 10:08:10,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:10,267 INFO:     Epoch: 92
2022-12-31 10:08:11,849 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3535000145435333, 'Total loss': 0.3535000145435333} | train loss {'Reaction outcome loss': 0.21455382502504758, 'Total loss': 0.21455382502504758}
2022-12-31 10:08:11,850 INFO:     Found new best model at epoch 92
2022-12-31 10:08:11,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:11,851 INFO:     Epoch: 93
2022-12-31 10:08:13,449 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43937342166900634, 'Total loss': 0.43937342166900634} | train loss {'Reaction outcome loss': 0.22076719650664392, 'Total loss': 0.22076719650664392}
2022-12-31 10:08:13,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:13,450 INFO:     Epoch: 94
2022-12-31 10:08:15,070 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4249917020400365, 'Total loss': 0.4249917020400365} | train loss {'Reaction outcome loss': 0.21154520296979518, 'Total loss': 0.21154520296979518}
2022-12-31 10:08:15,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:15,070 INFO:     Epoch: 95
2022-12-31 10:08:16,696 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43490364253520963, 'Total loss': 0.43490364253520963} | train loss {'Reaction outcome loss': 0.21259993919249856, 'Total loss': 0.21259993919249856}
2022-12-31 10:08:16,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:16,696 INFO:     Epoch: 96
2022-12-31 10:08:18,275 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39116132259368896, 'Total loss': 0.39116132259368896} | train loss {'Reaction outcome loss': 0.20488648721095407, 'Total loss': 0.20488648721095407}
2022-12-31 10:08:18,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:18,276 INFO:     Epoch: 97
2022-12-31 10:08:19,898 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4160516271988551, 'Total loss': 0.4160516271988551} | train loss {'Reaction outcome loss': 0.20685188773842084, 'Total loss': 0.20685188773842084}
2022-12-31 10:08:19,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:19,898 INFO:     Epoch: 98
2022-12-31 10:08:21,486 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4176972528298696, 'Total loss': 0.4176972528298696} | train loss {'Reaction outcome loss': 0.20695941701476828, 'Total loss': 0.20695941701476828}
2022-12-31 10:08:21,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:21,486 INFO:     Epoch: 99
2022-12-31 10:08:23,111 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4096108506123225, 'Total loss': 0.4096108506123225} | train loss {'Reaction outcome loss': 0.2077127549278758, 'Total loss': 0.2077127549278758}
2022-12-31 10:08:23,111 INFO:     Best model found after epoch 93 of 100.
2022-12-31 10:08:23,111 INFO:   Done with stage: TRAINING
2022-12-31 10:08:23,111 INFO:   Starting stage: EVALUATION
2022-12-31 10:08:23,250 INFO:   Done with stage: EVALUATION
2022-12-31 10:08:23,250 INFO:   Leaving out SEQ value Fold_4
2022-12-31 10:08:23,262 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 10:08:23,263 INFO:   Starting stage: FEATURE SCALING
2022-12-31 10:08:23,910 INFO:   Done with stage: FEATURE SCALING
2022-12-31 10:08:23,910 INFO:   Starting stage: SCALING TARGETS
2022-12-31 10:08:23,980 INFO:   Done with stage: SCALING TARGETS
2022-12-31 10:08:23,980 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:08:23,980 INFO:     No hyperparam tuning for this model
2022-12-31 10:08:23,980 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:08:23,980 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 10:08:23,981 INFO:     None feature selector for col prot
2022-12-31 10:08:23,981 INFO:     None feature selector for col prot
2022-12-31 10:08:23,981 INFO:     None feature selector for col prot
2022-12-31 10:08:23,982 INFO:     None feature selector for col chem
2022-12-31 10:08:23,982 INFO:     None feature selector for col chem
2022-12-31 10:08:23,982 INFO:     None feature selector for col chem
2022-12-31 10:08:23,982 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 10:08:23,982 INFO:   Starting stage: BUILD MODEL
2022-12-31 10:08:23,984 INFO:     Number of params in model 223921
2022-12-31 10:08:23,987 INFO:   Done with stage: BUILD MODEL
2022-12-31 10:08:23,987 INFO:   Starting stage: TRAINING
2022-12-31 10:08:24,032 INFO:     Val loss before train {'Reaction outcome loss': 1.0190867940584818, 'Total loss': 1.0190867940584818}
2022-12-31 10:08:24,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:24,033 INFO:     Epoch: 0
2022-12-31 10:08:25,660 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7374957442283631, 'Total loss': 0.7374957442283631} | train loss {'Reaction outcome loss': 0.8255015249452452, 'Total loss': 0.8255015249452452}
2022-12-31 10:08:25,661 INFO:     Found new best model at epoch 0
2022-12-31 10:08:25,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:25,662 INFO:     Epoch: 1
2022-12-31 10:08:27,254 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6153462151686351, 'Total loss': 0.6153462151686351} | train loss {'Reaction outcome loss': 0.61659449654339, 'Total loss': 0.61659449654339}
2022-12-31 10:08:27,255 INFO:     Found new best model at epoch 1
2022-12-31 10:08:27,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:27,256 INFO:     Epoch: 2
2022-12-31 10:08:28,853 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5918599963188171, 'Total loss': 0.5918599963188171} | train loss {'Reaction outcome loss': 0.5348178672529486, 'Total loss': 0.5348178672529486}
2022-12-31 10:08:28,853 INFO:     Found new best model at epoch 2
2022-12-31 10:08:28,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:28,854 INFO:     Epoch: 3
2022-12-31 10:08:30,444 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5394311567147573, 'Total loss': 0.5394311567147573} | train loss {'Reaction outcome loss': 0.5106484136768501, 'Total loss': 0.5106484136768501}
2022-12-31 10:08:30,444 INFO:     Found new best model at epoch 3
2022-12-31 10:08:30,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:30,445 INFO:     Epoch: 4
2022-12-31 10:08:32,077 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5098658382892609, 'Total loss': 0.5098658382892609} | train loss {'Reaction outcome loss': 0.4941881495344378, 'Total loss': 0.4941881495344378}
2022-12-31 10:08:32,077 INFO:     Found new best model at epoch 4
2022-12-31 10:08:32,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:32,078 INFO:     Epoch: 5
2022-12-31 10:08:33,703 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5039697249730428, 'Total loss': 0.5039697249730428} | train loss {'Reaction outcome loss': 0.4835719292181252, 'Total loss': 0.4835719292181252}
2022-12-31 10:08:33,703 INFO:     Found new best model at epoch 5
2022-12-31 10:08:33,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:33,704 INFO:     Epoch: 6
2022-12-31 10:08:35,331 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5298510601123174, 'Total loss': 0.5298510601123174} | train loss {'Reaction outcome loss': 0.47348954039115976, 'Total loss': 0.47348954039115976}
2022-12-31 10:08:35,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:35,331 INFO:     Epoch: 7
2022-12-31 10:08:36,942 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5089908381303151, 'Total loss': 0.5089908381303151} | train loss {'Reaction outcome loss': 0.46348271089313675, 'Total loss': 0.46348271089313675}
2022-12-31 10:08:36,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:36,942 INFO:     Epoch: 8
2022-12-31 10:08:38,582 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4863712141911189, 'Total loss': 0.4863712141911189} | train loss {'Reaction outcome loss': 0.4573414884779575, 'Total loss': 0.4573414884779575}
2022-12-31 10:08:38,583 INFO:     Found new best model at epoch 8
2022-12-31 10:08:38,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:38,584 INFO:     Epoch: 9
2022-12-31 10:08:40,218 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49815542499224347, 'Total loss': 0.49815542499224347} | train loss {'Reaction outcome loss': 0.44948823200742694, 'Total loss': 0.44948823200742694}
2022-12-31 10:08:40,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:40,219 INFO:     Epoch: 10
2022-12-31 10:08:41,830 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48027891914049786, 'Total loss': 0.48027891914049786} | train loss {'Reaction outcome loss': 0.4448355479288275, 'Total loss': 0.4448355479288275}
2022-12-31 10:08:41,830 INFO:     Found new best model at epoch 10
2022-12-31 10:08:41,830 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:41,831 INFO:     Epoch: 11
2022-12-31 10:08:43,426 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4752664963404338, 'Total loss': 0.4752664963404338} | train loss {'Reaction outcome loss': 0.43838513261862916, 'Total loss': 0.43838513261862916}
2022-12-31 10:08:43,426 INFO:     Found new best model at epoch 11
2022-12-31 10:08:43,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:43,427 INFO:     Epoch: 12
2022-12-31 10:08:45,008 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4804281006256739, 'Total loss': 0.4804281006256739} | train loss {'Reaction outcome loss': 0.4303256662385742, 'Total loss': 0.4303256662385742}
2022-12-31 10:08:45,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:45,008 INFO:     Epoch: 13
2022-12-31 10:08:46,616 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47587806383768716, 'Total loss': 0.47587806383768716} | train loss {'Reaction outcome loss': 0.4278670356058291, 'Total loss': 0.4278670356058291}
2022-12-31 10:08:46,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:46,616 INFO:     Epoch: 14
2022-12-31 10:08:48,206 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4722806046406428, 'Total loss': 0.4722806046406428} | train loss {'Reaction outcome loss': 0.4213123938245495, 'Total loss': 0.4213123938245495}
2022-12-31 10:08:48,206 INFO:     Found new best model at epoch 14
2022-12-31 10:08:48,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:48,207 INFO:     Epoch: 15
2022-12-31 10:08:49,842 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47773775657018025, 'Total loss': 0.47773775657018025} | train loss {'Reaction outcome loss': 0.4113113686007305, 'Total loss': 0.4113113686007305}
2022-12-31 10:08:49,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:49,843 INFO:     Epoch: 16
2022-12-31 10:08:51,430 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4737388888994853, 'Total loss': 0.4737388888994853} | train loss {'Reaction outcome loss': 0.40688437895074375, 'Total loss': 0.40688437895074375}
2022-12-31 10:08:51,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:51,430 INFO:     Epoch: 17
2022-12-31 10:08:53,030 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49161364436149596, 'Total loss': 0.49161364436149596} | train loss {'Reaction outcome loss': 0.4003820674099626, 'Total loss': 0.4003820674099626}
2022-12-31 10:08:53,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:53,030 INFO:     Epoch: 18
2022-12-31 10:08:54,626 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4823170656959216, 'Total loss': 0.4823170656959216} | train loss {'Reaction outcome loss': 0.39391526250834885, 'Total loss': 0.39391526250834885}
2022-12-31 10:08:54,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:54,626 INFO:     Epoch: 19
2022-12-31 10:08:56,222 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4757794717947642, 'Total loss': 0.4757794717947642} | train loss {'Reaction outcome loss': 0.38568969723517005, 'Total loss': 0.38568969723517005}
2022-12-31 10:08:56,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:56,223 INFO:     Epoch: 20
2022-12-31 10:08:57,800 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.49230723778406776, 'Total loss': 0.49230723778406776} | train loss {'Reaction outcome loss': 0.3835095600870839, 'Total loss': 0.3835095600870839}
2022-12-31 10:08:57,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:57,800 INFO:     Epoch: 21
2022-12-31 10:08:59,397 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5082430899143219, 'Total loss': 0.5082430899143219} | train loss {'Reaction outcome loss': 0.377109599265739, 'Total loss': 0.377109599265739}
2022-12-31 10:08:59,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:08:59,398 INFO:     Epoch: 22
2022-12-31 10:09:00,995 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.471026204029719, 'Total loss': 0.471026204029719} | train loss {'Reaction outcome loss': 0.37091968570203676, 'Total loss': 0.37091968570203676}
2022-12-31 10:09:00,995 INFO:     Found new best model at epoch 22
2022-12-31 10:09:00,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:00,996 INFO:     Epoch: 23
2022-12-31 10:09:02,592 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4893259088198344, 'Total loss': 0.4893259088198344} | train loss {'Reaction outcome loss': 0.3644932196849454, 'Total loss': 0.3644932196849454}
2022-12-31 10:09:02,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:02,593 INFO:     Epoch: 24
2022-12-31 10:09:04,176 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4650632917881012, 'Total loss': 0.4650632917881012} | train loss {'Reaction outcome loss': 0.36181840129251025, 'Total loss': 0.36181840129251025}
2022-12-31 10:09:04,176 INFO:     Found new best model at epoch 24
2022-12-31 10:09:04,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:04,177 INFO:     Epoch: 25
2022-12-31 10:09:05,750 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4699092740813891, 'Total loss': 0.4699092740813891} | train loss {'Reaction outcome loss': 0.3508426405652596, 'Total loss': 0.3508426405652596}
2022-12-31 10:09:05,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:05,751 INFO:     Epoch: 26
2022-12-31 10:09:07,348 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4818739593029022, 'Total loss': 0.4818739593029022} | train loss {'Reaction outcome loss': 0.3525150620317372, 'Total loss': 0.3525150620317372}
2022-12-31 10:09:07,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:07,348 INFO:     Epoch: 27
2022-12-31 10:09:08,945 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43743324478467305, 'Total loss': 0.43743324478467305} | train loss {'Reaction outcome loss': 0.3421049220011617, 'Total loss': 0.3421049220011617}
2022-12-31 10:09:08,946 INFO:     Found new best model at epoch 27
2022-12-31 10:09:08,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:08,947 INFO:     Epoch: 28
2022-12-31 10:09:10,543 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.485831148425738, 'Total loss': 0.485831148425738} | train loss {'Reaction outcome loss': 0.3394891711862853, 'Total loss': 0.3394891711862853}
2022-12-31 10:09:10,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:10,544 INFO:     Epoch: 29
2022-12-31 10:09:12,131 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4430786781013012, 'Total loss': 0.4430786781013012} | train loss {'Reaction outcome loss': 0.32849953883755817, 'Total loss': 0.32849953883755817}
2022-12-31 10:09:12,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:12,131 INFO:     Epoch: 30
2022-12-31 10:09:13,789 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46687745849291484, 'Total loss': 0.46687745849291484} | train loss {'Reaction outcome loss': 0.3330497352311211, 'Total loss': 0.3330497352311211}
2022-12-31 10:09:13,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:13,789 INFO:     Epoch: 31
2022-12-31 10:09:15,408 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46645014534393947, 'Total loss': 0.46645014534393947} | train loss {'Reaction outcome loss': 0.3220900678395355, 'Total loss': 0.3220900678395355}
2022-12-31 10:09:15,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:15,409 INFO:     Epoch: 32
2022-12-31 10:09:17,020 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43270118633906046, 'Total loss': 0.43270118633906046} | train loss {'Reaction outcome loss': 0.31426289946819747, 'Total loss': 0.31426289946819747}
2022-12-31 10:09:17,020 INFO:     Found new best model at epoch 32
2022-12-31 10:09:17,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:17,021 INFO:     Epoch: 33
2022-12-31 10:09:18,625 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4542229135831197, 'Total loss': 0.4542229135831197} | train loss {'Reaction outcome loss': 0.31230460379245506, 'Total loss': 0.31230460379245506}
2022-12-31 10:09:18,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:18,625 INFO:     Epoch: 34
2022-12-31 10:09:20,284 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.48507519662380216, 'Total loss': 0.48507519662380216} | train loss {'Reaction outcome loss': 0.31218477224346497, 'Total loss': 0.31218477224346497}
2022-12-31 10:09:20,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:20,285 INFO:     Epoch: 35
2022-12-31 10:09:21,882 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4427285929520925, 'Total loss': 0.4427285929520925} | train loss {'Reaction outcome loss': 0.31064266572794774, 'Total loss': 0.31064266572794774}
2022-12-31 10:09:21,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:21,883 INFO:     Epoch: 36
2022-12-31 10:09:23,489 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4961588521798452, 'Total loss': 0.4961588521798452} | train loss {'Reaction outcome loss': 0.30437532617934865, 'Total loss': 0.30437532617934865}
2022-12-31 10:09:23,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:23,489 INFO:     Epoch: 37
2022-12-31 10:09:25,084 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4546822210152944, 'Total loss': 0.4546822210152944} | train loss {'Reaction outcome loss': 0.30275912158680657, 'Total loss': 0.30275912158680657}
2022-12-31 10:09:25,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:25,085 INFO:     Epoch: 38
2022-12-31 10:09:26,716 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4793396453062693, 'Total loss': 0.4793396453062693} | train loss {'Reaction outcome loss': 0.2986183578597151, 'Total loss': 0.2986183578597151}
2022-12-31 10:09:26,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:26,716 INFO:     Epoch: 39
2022-12-31 10:09:28,321 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41570262213548026, 'Total loss': 0.41570262213548026} | train loss {'Reaction outcome loss': 0.2911509750071016, 'Total loss': 0.2911509750071016}
2022-12-31 10:09:28,322 INFO:     Found new best model at epoch 39
2022-12-31 10:09:28,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:28,323 INFO:     Epoch: 40
2022-12-31 10:09:29,970 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4332205936312675, 'Total loss': 0.4332205936312675} | train loss {'Reaction outcome loss': 0.28946982516506076, 'Total loss': 0.28946982516506076}
2022-12-31 10:09:29,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:29,970 INFO:     Epoch: 41
2022-12-31 10:09:31,561 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40577323536078136, 'Total loss': 0.40577323536078136} | train loss {'Reaction outcome loss': 0.2787874680501919, 'Total loss': 0.2787874680501919}
2022-12-31 10:09:31,561 INFO:     Found new best model at epoch 41
2022-12-31 10:09:31,562 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:31,562 INFO:     Epoch: 42
2022-12-31 10:09:33,148 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4576080024242401, 'Total loss': 0.4576080024242401} | train loss {'Reaction outcome loss': 0.27501080341528367, 'Total loss': 0.27501080341528367}
2022-12-31 10:09:33,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:33,148 INFO:     Epoch: 43
2022-12-31 10:09:34,761 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47337814966837566, 'Total loss': 0.47337814966837566} | train loss {'Reaction outcome loss': 0.274839329240966, 'Total loss': 0.274839329240966}
2022-12-31 10:09:34,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:34,761 INFO:     Epoch: 44
2022-12-31 10:09:36,371 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.49632907708485924, 'Total loss': 0.49632907708485924} | train loss {'Reaction outcome loss': 0.28008117539005994, 'Total loss': 0.28008117539005994}
2022-12-31 10:09:36,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:36,371 INFO:     Epoch: 45
2022-12-31 10:09:37,978 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43700582583745323, 'Total loss': 0.43700582583745323} | train loss {'Reaction outcome loss': 0.27405449651508, 'Total loss': 0.27405449651508}
2022-12-31 10:09:37,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:37,978 INFO:     Epoch: 46
2022-12-31 10:09:39,578 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4538600464661916, 'Total loss': 0.4538600464661916} | train loss {'Reaction outcome loss': 0.2728336499120197, 'Total loss': 0.2728336499120197}
2022-12-31 10:09:39,578 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:39,578 INFO:     Epoch: 47
2022-12-31 10:09:41,194 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4967537780602773, 'Total loss': 0.4967537780602773} | train loss {'Reaction outcome loss': 0.2715081447177995, 'Total loss': 0.2715081447177995}
2022-12-31 10:09:41,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:41,194 INFO:     Epoch: 48
2022-12-31 10:09:42,790 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4551262701551119, 'Total loss': 0.4551262701551119} | train loss {'Reaction outcome loss': 0.26847879504309086, 'Total loss': 0.26847879504309086}
2022-12-31 10:09:42,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:42,790 INFO:     Epoch: 49
2022-12-31 10:09:44,399 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.48825049499670664, 'Total loss': 0.48825049499670664} | train loss {'Reaction outcome loss': 0.26173265395264556, 'Total loss': 0.26173265395264556}
2022-12-31 10:09:44,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:44,400 INFO:     Epoch: 50
2022-12-31 10:09:46,010 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42953543762365975, 'Total loss': 0.42953543762365975} | train loss {'Reaction outcome loss': 0.26529720507181476, 'Total loss': 0.26529720507181476}
2022-12-31 10:09:46,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:46,010 INFO:     Epoch: 51
2022-12-31 10:09:47,626 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41871509651343025, 'Total loss': 0.41871509651343025} | train loss {'Reaction outcome loss': 0.25766582120835346, 'Total loss': 0.25766582120835346}
2022-12-31 10:09:47,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:47,627 INFO:     Epoch: 52
2022-12-31 10:09:49,237 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42221709887186687, 'Total loss': 0.42221709887186687} | train loss {'Reaction outcome loss': 0.258786248172341, 'Total loss': 0.258786248172341}
2022-12-31 10:09:49,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:49,237 INFO:     Epoch: 53
2022-12-31 10:09:50,848 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42827372848987577, 'Total loss': 0.42827372848987577} | train loss {'Reaction outcome loss': 0.25478037690104793, 'Total loss': 0.25478037690104793}
2022-12-31 10:09:50,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:50,848 INFO:     Epoch: 54
2022-12-31 10:09:52,464 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39239928076664604, 'Total loss': 0.39239928076664604} | train loss {'Reaction outcome loss': 0.2576547391019272, 'Total loss': 0.2576547391019272}
2022-12-31 10:09:52,464 INFO:     Found new best model at epoch 54
2022-12-31 10:09:52,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:52,465 INFO:     Epoch: 55
2022-12-31 10:09:54,092 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4616970519224803, 'Total loss': 0.4616970519224803} | train loss {'Reaction outcome loss': 0.24606352871841322, 'Total loss': 0.24606352871841322}
2022-12-31 10:09:54,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:54,092 INFO:     Epoch: 56
2022-12-31 10:09:55,706 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4235177179177602, 'Total loss': 0.4235177179177602} | train loss {'Reaction outcome loss': 0.2548960213325102, 'Total loss': 0.2548960213325102}
2022-12-31 10:09:55,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:55,707 INFO:     Epoch: 57
2022-12-31 10:09:57,325 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41082277297973635, 'Total loss': 0.41082277297973635} | train loss {'Reaction outcome loss': 0.2555397846158186, 'Total loss': 0.2555397846158186}
2022-12-31 10:09:57,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:57,326 INFO:     Epoch: 58
2022-12-31 10:09:58,445 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4468303213516871, 'Total loss': 0.4468303213516871} | train loss {'Reaction outcome loss': 0.24654779732771162, 'Total loss': 0.24654779732771162}
2022-12-31 10:09:58,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:58,446 INFO:     Epoch: 59
2022-12-31 10:09:59,510 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42687293340762456, 'Total loss': 0.42687293340762456} | train loss {'Reaction outcome loss': 0.24776385972670611, 'Total loss': 0.24776385972670611}
2022-12-31 10:09:59,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:09:59,510 INFO:     Epoch: 60
2022-12-31 10:10:00,560 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44294564028580985, 'Total loss': 0.44294564028580985} | train loss {'Reaction outcome loss': 0.2383900394622427, 'Total loss': 0.2383900394622427}
2022-12-31 10:10:00,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:00,560 INFO:     Epoch: 61
2022-12-31 10:10:01,608 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4510279595851898, 'Total loss': 0.4510279595851898} | train loss {'Reaction outcome loss': 0.24876347717142452, 'Total loss': 0.24876347717142452}
2022-12-31 10:10:01,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:01,608 INFO:     Epoch: 62
2022-12-31 10:10:02,904 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42004889249801636, 'Total loss': 0.42004889249801636} | train loss {'Reaction outcome loss': 0.24791920244911292, 'Total loss': 0.24791920244911292}
2022-12-31 10:10:02,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:02,905 INFO:     Epoch: 63
2022-12-31 10:10:04,503 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45248440802097323, 'Total loss': 0.45248440802097323} | train loss {'Reaction outcome loss': 0.24012575072854975, 'Total loss': 0.24012575072854975}
2022-12-31 10:10:04,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:04,503 INFO:     Epoch: 64
2022-12-31 10:10:06,096 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43509820103645325, 'Total loss': 0.43509820103645325} | train loss {'Reaction outcome loss': 0.2326614321855298, 'Total loss': 0.2326614321855298}
2022-12-31 10:10:06,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:06,097 INFO:     Epoch: 65
2022-12-31 10:10:07,689 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4547207713127136, 'Total loss': 0.4547207713127136} | train loss {'Reaction outcome loss': 0.23744666509765344, 'Total loss': 0.23744666509765344}
2022-12-31 10:10:07,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:07,689 INFO:     Epoch: 66
2022-12-31 10:10:09,287 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4232371817032496, 'Total loss': 0.4232371817032496} | train loss {'Reaction outcome loss': 0.22644749382361226, 'Total loss': 0.22644749382361226}
2022-12-31 10:10:09,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:09,287 INFO:     Epoch: 67
2022-12-31 10:10:10,884 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3777622679869334, 'Total loss': 0.3777622679869334} | train loss {'Reaction outcome loss': 0.242059087074858, 'Total loss': 0.242059087074858}
2022-12-31 10:10:10,885 INFO:     Found new best model at epoch 67
2022-12-31 10:10:10,885 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:10,886 INFO:     Epoch: 68
2022-12-31 10:10:12,476 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4029846012592316, 'Total loss': 0.4029846012592316} | train loss {'Reaction outcome loss': 0.22487980614069605, 'Total loss': 0.22487980614069605}
2022-12-31 10:10:12,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:12,476 INFO:     Epoch: 69
2022-12-31 10:10:14,118 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4167118380467097, 'Total loss': 0.4167118380467097} | train loss {'Reaction outcome loss': 0.22462506883227043, 'Total loss': 0.22462506883227043}
2022-12-31 10:10:14,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:14,118 INFO:     Epoch: 70
2022-12-31 10:10:15,726 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43736485838890077, 'Total loss': 0.43736485838890077} | train loss {'Reaction outcome loss': 0.2272465704756714, 'Total loss': 0.2272465704756714}
2022-12-31 10:10:15,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:15,727 INFO:     Epoch: 71
2022-12-31 10:10:17,307 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4640967895587285, 'Total loss': 0.4640967895587285} | train loss {'Reaction outcome loss': 0.22169089228268304, 'Total loss': 0.22169089228268304}
2022-12-31 10:10:17,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:17,307 INFO:     Epoch: 72
2022-12-31 10:10:18,908 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43172570914030073, 'Total loss': 0.43172570914030073} | train loss {'Reaction outcome loss': 0.22909330975019584, 'Total loss': 0.22909330975019584}
2022-12-31 10:10:18,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:18,908 INFO:     Epoch: 73
2022-12-31 10:10:20,519 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40021147032578785, 'Total loss': 0.40021147032578785} | train loss {'Reaction outcome loss': 0.22716217685871534, 'Total loss': 0.22716217685871534}
2022-12-31 10:10:20,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:20,519 INFO:     Epoch: 74
2022-12-31 10:10:22,122 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41980018677810826, 'Total loss': 0.41980018677810826} | train loss {'Reaction outcome loss': 0.22575128374852405, 'Total loss': 0.22575128374852405}
2022-12-31 10:10:22,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:22,122 INFO:     Epoch: 75
2022-12-31 10:10:23,726 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43097785909970604, 'Total loss': 0.43097785909970604} | train loss {'Reaction outcome loss': 0.22332874032580396, 'Total loss': 0.22332874032580396}
2022-12-31 10:10:23,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:23,726 INFO:     Epoch: 76
2022-12-31 10:10:25,310 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4297506352265676, 'Total loss': 0.4297506352265676} | train loss {'Reaction outcome loss': 0.2181903955247933, 'Total loss': 0.2181903955247933}
2022-12-31 10:10:25,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:25,310 INFO:     Epoch: 77
2022-12-31 10:10:26,908 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4565999408562978, 'Total loss': 0.4565999408562978} | train loss {'Reaction outcome loss': 0.21772490557364738, 'Total loss': 0.21772490557364738}
2022-12-31 10:10:26,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:26,909 INFO:     Epoch: 78
2022-12-31 10:10:28,536 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4312002857526143, 'Total loss': 0.4312002857526143} | train loss {'Reaction outcome loss': 0.2175901464941184, 'Total loss': 0.2175901464941184}
2022-12-31 10:10:28,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:28,536 INFO:     Epoch: 79
2022-12-31 10:10:30,145 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42072111268838247, 'Total loss': 0.42072111268838247} | train loss {'Reaction outcome loss': 0.21712461451109308, 'Total loss': 0.21712461451109308}
2022-12-31 10:10:30,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:30,145 INFO:     Epoch: 80
2022-12-31 10:10:31,744 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4768038332462311, 'Total loss': 0.4768038332462311} | train loss {'Reaction outcome loss': 0.21689090206131448, 'Total loss': 0.21689090206131448}
2022-12-31 10:10:31,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:31,745 INFO:     Epoch: 81
2022-12-31 10:10:33,344 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4624343631168207, 'Total loss': 0.4624343631168207} | train loss {'Reaction outcome loss': 0.21430884696964692, 'Total loss': 0.21430884696964692}
2022-12-31 10:10:33,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:33,345 INFO:     Epoch: 82
2022-12-31 10:10:34,946 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.42911179761091867, 'Total loss': 0.42911179761091867} | train loss {'Reaction outcome loss': 0.21463298348941073, 'Total loss': 0.21463298348941073}
2022-12-31 10:10:34,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:34,946 INFO:     Epoch: 83
2022-12-31 10:10:36,587 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4365396519502004, 'Total loss': 0.4365396519502004} | train loss {'Reaction outcome loss': 0.20729085212627793, 'Total loss': 0.20729085212627793}
2022-12-31 10:10:36,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:36,587 INFO:     Epoch: 84
2022-12-31 10:10:38,235 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4437662382920583, 'Total loss': 0.4437662382920583} | train loss {'Reaction outcome loss': 0.211381672779574, 'Total loss': 0.211381672779574}
2022-12-31 10:10:38,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:38,235 INFO:     Epoch: 85
2022-12-31 10:10:39,821 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3979062646627426, 'Total loss': 0.3979062646627426} | train loss {'Reaction outcome loss': 0.21366009016922355, 'Total loss': 0.21366009016922355}
2022-12-31 10:10:39,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:39,821 INFO:     Epoch: 86
2022-12-31 10:10:41,467 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42033621842662494, 'Total loss': 0.42033621842662494} | train loss {'Reaction outcome loss': 0.21509302024097338, 'Total loss': 0.21509302024097338}
2022-12-31 10:10:41,467 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:41,467 INFO:     Epoch: 87
2022-12-31 10:10:43,075 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3968894084294637, 'Total loss': 0.3968894084294637} | train loss {'Reaction outcome loss': 0.2183652210396028, 'Total loss': 0.2183652210396028}
2022-12-31 10:10:43,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:43,075 INFO:     Epoch: 88
2022-12-31 10:10:44,689 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4383886486291885, 'Total loss': 0.4383886486291885} | train loss {'Reaction outcome loss': 0.20953580138212355, 'Total loss': 0.20953580138212355}
2022-12-31 10:10:44,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:44,689 INFO:     Epoch: 89
2022-12-31 10:10:46,329 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41525988380114237, 'Total loss': 0.41525988380114237} | train loss {'Reaction outcome loss': 0.21420151020407024, 'Total loss': 0.21420151020407024}
2022-12-31 10:10:46,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:46,330 INFO:     Epoch: 90
2022-12-31 10:10:47,940 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4080292118092378, 'Total loss': 0.4080292118092378} | train loss {'Reaction outcome loss': 0.2094938468296815, 'Total loss': 0.2094938468296815}
2022-12-31 10:10:47,940 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:47,940 INFO:     Epoch: 91
2022-12-31 10:10:49,571 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4757545694708824, 'Total loss': 0.4757545694708824} | train loss {'Reaction outcome loss': 0.21258421769420052, 'Total loss': 0.21258421769420052}
2022-12-31 10:10:49,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:49,571 INFO:     Epoch: 92
2022-12-31 10:10:51,199 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41539152562618253, 'Total loss': 0.41539152562618253} | train loss {'Reaction outcome loss': 0.20537214213642327, 'Total loss': 0.20537214213642327}
2022-12-31 10:10:51,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:51,199 INFO:     Epoch: 93
2022-12-31 10:10:52,780 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4318978269894918, 'Total loss': 0.4318978269894918} | train loss {'Reaction outcome loss': 0.19201756523663763, 'Total loss': 0.19201756523663763}
2022-12-31 10:10:52,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:52,780 INFO:     Epoch: 94
2022-12-31 10:10:54,385 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46300498843193055, 'Total loss': 0.46300498843193055} | train loss {'Reaction outcome loss': 0.1994987294676095, 'Total loss': 0.1994987294676095}
2022-12-31 10:10:54,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:54,385 INFO:     Epoch: 95
2022-12-31 10:10:56,015 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.40687104165554044, 'Total loss': 0.40687104165554044} | train loss {'Reaction outcome loss': 0.20399163715731705, 'Total loss': 0.20399163715731705}
2022-12-31 10:10:56,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:56,015 INFO:     Epoch: 96
2022-12-31 10:10:57,604 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44152864813804626, 'Total loss': 0.44152864813804626} | train loss {'Reaction outcome loss': 0.2015802037501096, 'Total loss': 0.2015802037501096}
2022-12-31 10:10:57,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:57,604 INFO:     Epoch: 97
2022-12-31 10:10:59,205 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4614184518655141, 'Total loss': 0.4614184518655141} | train loss {'Reaction outcome loss': 0.1949862779260878, 'Total loss': 0.1949862779260878}
2022-12-31 10:10:59,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:10:59,205 INFO:     Epoch: 98
2022-12-31 10:11:00,805 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4147974282503128, 'Total loss': 0.4147974282503128} | train loss {'Reaction outcome loss': 0.19984930530734304, 'Total loss': 0.19984930530734304}
2022-12-31 10:11:00,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:00,805 INFO:     Epoch: 99
2022-12-31 10:11:02,387 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4534873366355896, 'Total loss': 0.4534873366355896} | train loss {'Reaction outcome loss': 0.19373845056474318, 'Total loss': 0.19373845056474318}
2022-12-31 10:11:02,388 INFO:     Best model found after epoch 68 of 100.
2022-12-31 10:11:02,389 INFO:   Done with stage: TRAINING
2022-12-31 10:11:02,389 INFO:   Starting stage: EVALUATION
2022-12-31 10:11:02,522 INFO:   Done with stage: EVALUATION
2022-12-31 10:11:02,522 INFO:   Leaving out SEQ value Fold_5
2022-12-31 10:11:02,534 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 10:11:02,534 INFO:   Starting stage: FEATURE SCALING
2022-12-31 10:11:03,178 INFO:   Done with stage: FEATURE SCALING
2022-12-31 10:11:03,178 INFO:   Starting stage: SCALING TARGETS
2022-12-31 10:11:03,248 INFO:   Done with stage: SCALING TARGETS
2022-12-31 10:11:03,248 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:11:03,248 INFO:     No hyperparam tuning for this model
2022-12-31 10:11:03,248 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:11:03,248 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 10:11:03,249 INFO:     None feature selector for col prot
2022-12-31 10:11:03,249 INFO:     None feature selector for col prot
2022-12-31 10:11:03,249 INFO:     None feature selector for col prot
2022-12-31 10:11:03,249 INFO:     None feature selector for col chem
2022-12-31 10:11:03,249 INFO:     None feature selector for col chem
2022-12-31 10:11:03,250 INFO:     None feature selector for col chem
2022-12-31 10:11:03,250 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 10:11:03,250 INFO:   Starting stage: BUILD MODEL
2022-12-31 10:11:03,251 INFO:     Number of params in model 223921
2022-12-31 10:11:03,255 INFO:   Done with stage: BUILD MODEL
2022-12-31 10:11:03,255 INFO:   Starting stage: TRAINING
2022-12-31 10:11:03,298 INFO:     Val loss before train {'Reaction outcome loss': 1.0825136025746664, 'Total loss': 1.0825136025746664}
2022-12-31 10:11:03,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:03,298 INFO:     Epoch: 0
2022-12-31 10:11:04,918 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7325469255447388, 'Total loss': 0.7325469255447388} | train loss {'Reaction outcome loss': 0.8094009233324829, 'Total loss': 0.8094009233324829}
2022-12-31 10:11:04,918 INFO:     Found new best model at epoch 0
2022-12-31 10:11:04,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:04,919 INFO:     Epoch: 1
2022-12-31 10:11:06,541 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5670916080474854, 'Total loss': 0.5670916080474854} | train loss {'Reaction outcome loss': 0.6059844508260763, 'Total loss': 0.6059844508260763}
2022-12-31 10:11:06,541 INFO:     Found new best model at epoch 1
2022-12-31 10:11:06,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:06,542 INFO:     Epoch: 2
2022-12-31 10:11:08,141 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.532465394337972, 'Total loss': 0.532465394337972} | train loss {'Reaction outcome loss': 0.5268230562341278, 'Total loss': 0.5268230562341278}
2022-12-31 10:11:08,141 INFO:     Found new best model at epoch 2
2022-12-31 10:11:08,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:08,142 INFO:     Epoch: 3
2022-12-31 10:11:09,749 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5380770077308019, 'Total loss': 0.5380770077308019} | train loss {'Reaction outcome loss': 0.5062522968560781, 'Total loss': 0.5062522968560781}
2022-12-31 10:11:09,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:09,750 INFO:     Epoch: 4
2022-12-31 10:11:11,337 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5361157496770222, 'Total loss': 0.5361157496770222} | train loss {'Reaction outcome loss': 0.48408396720196173, 'Total loss': 0.48408396720196173}
2022-12-31 10:11:11,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:11,337 INFO:     Epoch: 5
2022-12-31 10:11:12,999 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5302992125352224, 'Total loss': 0.5302992125352224} | train loss {'Reaction outcome loss': 0.4761873353542625, 'Total loss': 0.4761873353542625}
2022-12-31 10:11:12,999 INFO:     Found new best model at epoch 5
2022-12-31 10:11:13,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:13,000 INFO:     Epoch: 6
2022-12-31 10:11:14,592 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5440291861693064, 'Total loss': 0.5440291861693064} | train loss {'Reaction outcome loss': 0.49025157350621634, 'Total loss': 0.49025157350621634}
2022-12-31 10:11:14,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:14,592 INFO:     Epoch: 7
2022-12-31 10:11:16,188 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4989018241564433, 'Total loss': 0.4989018241564433} | train loss {'Reaction outcome loss': 0.45642097180952196, 'Total loss': 0.45642097180952196}
2022-12-31 10:11:16,188 INFO:     Found new best model at epoch 7
2022-12-31 10:11:16,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:16,189 INFO:     Epoch: 8
2022-12-31 10:11:17,785 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4882124284903208, 'Total loss': 0.4882124284903208} | train loss {'Reaction outcome loss': 0.45355644003290724, 'Total loss': 0.45355644003290724}
2022-12-31 10:11:17,785 INFO:     Found new best model at epoch 8
2022-12-31 10:11:17,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:17,786 INFO:     Epoch: 9
2022-12-31 10:11:19,372 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4778693079948425, 'Total loss': 0.4778693079948425} | train loss {'Reaction outcome loss': 0.4464350256232032, 'Total loss': 0.4464350256232032}
2022-12-31 10:11:19,372 INFO:     Found new best model at epoch 9
2022-12-31 10:11:19,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:19,373 INFO:     Epoch: 10
2022-12-31 10:11:20,991 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49702033003171286, 'Total loss': 0.49702033003171286} | train loss {'Reaction outcome loss': 0.43969679349844437, 'Total loss': 0.43969679349844437}
2022-12-31 10:11:20,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:20,991 INFO:     Epoch: 11
2022-12-31 10:11:22,600 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5615499575932821, 'Total loss': 0.5615499575932821} | train loss {'Reaction outcome loss': 0.4473823795122081, 'Total loss': 0.4473823795122081}
2022-12-31 10:11:22,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:22,601 INFO:     Epoch: 12
2022-12-31 10:11:24,211 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5196921706199646, 'Total loss': 0.5196921706199646} | train loss {'Reaction outcome loss': 0.5096952935167844, 'Total loss': 0.5096952935167844}
2022-12-31 10:11:24,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:24,211 INFO:     Epoch: 13
2022-12-31 10:11:25,851 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5393944124380747, 'Total loss': 0.5393944124380747} | train loss {'Reaction outcome loss': 0.44392587096376374, 'Total loss': 0.44392587096376374}
2022-12-31 10:11:25,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:25,852 INFO:     Epoch: 14
2022-12-31 10:11:27,485 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4707579255104065, 'Total loss': 0.4707579255104065} | train loss {'Reaction outcome loss': 0.4318818434700876, 'Total loss': 0.4318818434700876}
2022-12-31 10:11:27,485 INFO:     Found new best model at epoch 14
2022-12-31 10:11:27,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:27,486 INFO:     Epoch: 15
2022-12-31 10:11:29,089 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5335367977619171, 'Total loss': 0.5335367977619171} | train loss {'Reaction outcome loss': 0.426675496025597, 'Total loss': 0.426675496025597}
2022-12-31 10:11:29,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:29,089 INFO:     Epoch: 16
2022-12-31 10:11:30,692 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4956542909145355, 'Total loss': 0.4956542909145355} | train loss {'Reaction outcome loss': 0.41292911329968035, 'Total loss': 0.41292911329968035}
2022-12-31 10:11:30,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:30,693 INFO:     Epoch: 17
2022-12-31 10:11:32,297 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49302678803602856, 'Total loss': 0.49302678803602856} | train loss {'Reaction outcome loss': 0.40875952237663604, 'Total loss': 0.40875952237663604}
2022-12-31 10:11:32,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:32,298 INFO:     Epoch: 18
2022-12-31 10:11:33,925 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.458641987045606, 'Total loss': 0.458641987045606} | train loss {'Reaction outcome loss': 0.40482998765546124, 'Total loss': 0.40482998765546124}
2022-12-31 10:11:33,925 INFO:     Found new best model at epoch 18
2022-12-31 10:11:33,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:33,926 INFO:     Epoch: 19
2022-12-31 10:11:35,590 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5208162148793538, 'Total loss': 0.5208162148793538} | train loss {'Reaction outcome loss': 0.402365002727163, 'Total loss': 0.402365002727163}
2022-12-31 10:11:35,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:35,591 INFO:     Epoch: 20
2022-12-31 10:11:37,248 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.48771804571151733, 'Total loss': 0.48771804571151733} | train loss {'Reaction outcome loss': 0.4127403300093568, 'Total loss': 0.4127403300093568}
2022-12-31 10:11:37,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:37,249 INFO:     Epoch: 21
2022-12-31 10:11:38,843 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4503888010978699, 'Total loss': 0.4503888010978699} | train loss {'Reaction outcome loss': 0.3993954005637679, 'Total loss': 0.3993954005637679}
2022-12-31 10:11:38,844 INFO:     Found new best model at epoch 21
2022-12-31 10:11:38,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:38,845 INFO:     Epoch: 22
2022-12-31 10:11:40,455 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5157790998617808, 'Total loss': 0.5157790998617808} | train loss {'Reaction outcome loss': 0.4021762198890033, 'Total loss': 0.4021762198890033}
2022-12-31 10:11:40,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:40,455 INFO:     Epoch: 23
2022-12-31 10:11:42,050 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46262108385562895, 'Total loss': 0.46262108385562895} | train loss {'Reaction outcome loss': 0.4177792454385148, 'Total loss': 0.4177792454385148}
2022-12-31 10:11:42,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:42,050 INFO:     Epoch: 24
2022-12-31 10:11:43,660 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45988239447275797, 'Total loss': 0.45988239447275797} | train loss {'Reaction outcome loss': 0.38454148897300544, 'Total loss': 0.38454148897300544}
2022-12-31 10:11:43,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:43,660 INFO:     Epoch: 25
2022-12-31 10:11:45,270 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.475930784145991, 'Total loss': 0.475930784145991} | train loss {'Reaction outcome loss': 0.37049215450457745, 'Total loss': 0.37049215450457745}
2022-12-31 10:11:45,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:45,271 INFO:     Epoch: 26
2022-12-31 10:11:46,873 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4602013568083445, 'Total loss': 0.4602013568083445} | train loss {'Reaction outcome loss': 0.366990290157011, 'Total loss': 0.366990290157011}
2022-12-31 10:11:46,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:46,874 INFO:     Epoch: 27
2022-12-31 10:11:48,538 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44839680890242256, 'Total loss': 0.44839680890242256} | train loss {'Reaction outcome loss': 0.3601351630354327, 'Total loss': 0.3601351630354327}
2022-12-31 10:11:48,539 INFO:     Found new best model at epoch 27
2022-12-31 10:11:48,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:48,540 INFO:     Epoch: 28
2022-12-31 10:11:50,173 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45783697863419853, 'Total loss': 0.45783697863419853} | train loss {'Reaction outcome loss': 0.35935429092901555, 'Total loss': 0.35935429092901555}
2022-12-31 10:11:50,173 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:50,173 INFO:     Epoch: 29
2022-12-31 10:11:51,778 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44939065476258594, 'Total loss': 0.44939065476258594} | train loss {'Reaction outcome loss': 0.35748496498938725, 'Total loss': 0.35748496498938725}
2022-12-31 10:11:51,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:51,778 INFO:     Epoch: 30
2022-12-31 10:11:53,389 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.44894236127535503, 'Total loss': 0.44894236127535503} | train loss {'Reaction outcome loss': 0.35604169766715577, 'Total loss': 0.35604169766715577}
2022-12-31 10:11:53,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:53,390 INFO:     Epoch: 31
2022-12-31 10:11:55,001 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4485255827506383, 'Total loss': 0.4485255827506383} | train loss {'Reaction outcome loss': 0.3552487524820195, 'Total loss': 0.3552487524820195}
2022-12-31 10:11:55,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:55,001 INFO:     Epoch: 32
2022-12-31 10:11:56,592 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4367851773897807, 'Total loss': 0.4367851773897807} | train loss {'Reaction outcome loss': 0.3451093130380563, 'Total loss': 0.3451093130380563}
2022-12-31 10:11:56,592 INFO:     Found new best model at epoch 32
2022-12-31 10:11:56,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:56,593 INFO:     Epoch: 33
2022-12-31 10:11:58,203 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4341354330380758, 'Total loss': 0.4341354330380758} | train loss {'Reaction outcome loss': 0.335169708093068, 'Total loss': 0.335169708093068}
2022-12-31 10:11:58,203 INFO:     Found new best model at epoch 33
2022-12-31 10:11:58,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:58,204 INFO:     Epoch: 34
2022-12-31 10:11:59,800 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43937621514002484, 'Total loss': 0.43937621514002484} | train loss {'Reaction outcome loss': 0.33294568299121846, 'Total loss': 0.33294568299121846}
2022-12-31 10:11:59,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:11:59,800 INFO:     Epoch: 35
2022-12-31 10:12:01,414 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.431803834438324, 'Total loss': 0.431803834438324} | train loss {'Reaction outcome loss': 0.3296424084329519, 'Total loss': 0.3296424084329519}
2022-12-31 10:12:01,414 INFO:     Found new best model at epoch 35
2022-12-31 10:12:01,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:01,415 INFO:     Epoch: 36
2022-12-31 10:12:03,023 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4353354871273041, 'Total loss': 0.4353354871273041} | train loss {'Reaction outcome loss': 0.3382248523631606, 'Total loss': 0.3382248523631606}
2022-12-31 10:12:03,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:03,024 INFO:     Epoch: 37
2022-12-31 10:12:04,608 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4025554289420446, 'Total loss': 0.4025554289420446} | train loss {'Reaction outcome loss': 0.3601372353327663, 'Total loss': 0.3601372353327663}
2022-12-31 10:12:04,609 INFO:     Found new best model at epoch 37
2022-12-31 10:12:04,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:04,609 INFO:     Epoch: 38
2022-12-31 10:12:06,221 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4249244689941406, 'Total loss': 0.4249244689941406} | train loss {'Reaction outcome loss': 0.3359280279587108, 'Total loss': 0.3359280279587108}
2022-12-31 10:12:06,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:06,221 INFO:     Epoch: 39
2022-12-31 10:12:07,829 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4302179594834646, 'Total loss': 0.4302179594834646} | train loss {'Reaction outcome loss': 0.32110898102215235, 'Total loss': 0.32110898102215235}
2022-12-31 10:12:07,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:07,829 INFO:     Epoch: 40
2022-12-31 10:12:09,430 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4809673368930817, 'Total loss': 0.4809673368930817} | train loss {'Reaction outcome loss': 0.32231746516797855, 'Total loss': 0.32231746516797855}
2022-12-31 10:12:09,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:09,430 INFO:     Epoch: 41
2022-12-31 10:12:11,033 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4345252692699432, 'Total loss': 0.4345252692699432} | train loss {'Reaction outcome loss': 0.3278358587050352, 'Total loss': 0.3278358587050352}
2022-12-31 10:12:11,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:11,034 INFO:     Epoch: 42
2022-12-31 10:12:12,639 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4266885240872701, 'Total loss': 0.4266885240872701} | train loss {'Reaction outcome loss': 0.3078654102413355, 'Total loss': 0.3078654102413355}
2022-12-31 10:12:12,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:12,640 INFO:     Epoch: 43
2022-12-31 10:12:14,264 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4012237548828125, 'Total loss': 0.4012237548828125} | train loss {'Reaction outcome loss': 0.3016913156632496, 'Total loss': 0.3016913156632496}
2022-12-31 10:12:14,265 INFO:     Found new best model at epoch 43
2022-12-31 10:12:14,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:14,266 INFO:     Epoch: 44
2022-12-31 10:12:15,908 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.39039620061715447, 'Total loss': 0.39039620061715447} | train loss {'Reaction outcome loss': 0.3059938999021129, 'Total loss': 0.3059938999021129}
2022-12-31 10:12:15,909 INFO:     Found new best model at epoch 44
2022-12-31 10:12:15,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:15,910 INFO:     Epoch: 45
2022-12-31 10:12:17,556 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42716884513696035, 'Total loss': 0.42716884513696035} | train loss {'Reaction outcome loss': 0.2978245624863252, 'Total loss': 0.2978245624863252}
2022-12-31 10:12:17,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:17,556 INFO:     Epoch: 46
2022-12-31 10:12:19,145 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39117143948872884, 'Total loss': 0.39117143948872884} | train loss {'Reaction outcome loss': 0.2971162468783787, 'Total loss': 0.2971162468783787}
2022-12-31 10:12:19,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:19,146 INFO:     Epoch: 47
2022-12-31 10:12:20,752 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4024100174506505, 'Total loss': 0.4024100174506505} | train loss {'Reaction outcome loss': 0.2981971140505503, 'Total loss': 0.2981971140505503}
2022-12-31 10:12:20,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:20,753 INFO:     Epoch: 48
2022-12-31 10:12:22,358 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.375994739929835, 'Total loss': 0.375994739929835} | train loss {'Reaction outcome loss': 0.2848980944279743, 'Total loss': 0.2848980944279743}
2022-12-31 10:12:22,358 INFO:     Found new best model at epoch 48
2022-12-31 10:12:22,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:22,359 INFO:     Epoch: 49
2022-12-31 10:12:24,001 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4192481279373169, 'Total loss': 0.4192481279373169} | train loss {'Reaction outcome loss': 0.2971069815694795, 'Total loss': 0.2971069815694795}
2022-12-31 10:12:24,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:24,002 INFO:     Epoch: 50
2022-12-31 10:12:25,617 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3906812995672226, 'Total loss': 0.3906812995672226} | train loss {'Reaction outcome loss': 0.28029168622126205, 'Total loss': 0.28029168622126205}
2022-12-31 10:12:25,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:25,617 INFO:     Epoch: 51
2022-12-31 10:12:27,208 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3823017408450445, 'Total loss': 0.3823017408450445} | train loss {'Reaction outcome loss': 0.28289184710382065, 'Total loss': 0.28289184710382065}
2022-12-31 10:12:27,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:27,208 INFO:     Epoch: 52
2022-12-31 10:12:28,815 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.411697777112325, 'Total loss': 0.411697777112325} | train loss {'Reaction outcome loss': 0.28110548647700984, 'Total loss': 0.28110548647700984}
2022-12-31 10:12:28,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:28,815 INFO:     Epoch: 53
2022-12-31 10:12:30,426 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39273721873760226, 'Total loss': 0.39273721873760226} | train loss {'Reaction outcome loss': 0.28109418592477753, 'Total loss': 0.28109418592477753}
2022-12-31 10:12:30,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:30,426 INFO:     Epoch: 54
2022-12-31 10:12:32,029 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42644789467255273, 'Total loss': 0.42644789467255273} | train loss {'Reaction outcome loss': 0.27312909486531484, 'Total loss': 0.27312909486531484}
2022-12-31 10:12:32,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:32,029 INFO:     Epoch: 55
2022-12-31 10:12:33,633 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40680402517318726, 'Total loss': 0.40680402517318726} | train loss {'Reaction outcome loss': 0.27357328316176555, 'Total loss': 0.27357328316176555}
2022-12-31 10:12:33,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:33,634 INFO:     Epoch: 56
2022-12-31 10:12:35,240 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.37149515698353447, 'Total loss': 0.37149515698353447} | train loss {'Reaction outcome loss': 0.2694048915696128, 'Total loss': 0.2694048915696128}
2022-12-31 10:12:35,240 INFO:     Found new best model at epoch 56
2022-12-31 10:12:35,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:35,241 INFO:     Epoch: 57
2022-12-31 10:12:36,829 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44108669261137645, 'Total loss': 0.44108669261137645} | train loss {'Reaction outcome loss': 0.2655364334367324, 'Total loss': 0.2655364334367324}
2022-12-31 10:12:36,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:36,829 INFO:     Epoch: 58
2022-12-31 10:12:38,436 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3810468842585882, 'Total loss': 0.3810468842585882} | train loss {'Reaction outcome loss': 0.28557442596618365, 'Total loss': 0.28557442596618365}
2022-12-31 10:12:38,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:38,436 INFO:     Epoch: 59
2022-12-31 10:12:40,045 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3822158306837082, 'Total loss': 0.3822158306837082} | train loss {'Reaction outcome loss': 0.26155082692486653, 'Total loss': 0.26155082692486653}
2022-12-31 10:12:40,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:40,045 INFO:     Epoch: 60
2022-12-31 10:12:41,634 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3531949192285538, 'Total loss': 0.3531949192285538} | train loss {'Reaction outcome loss': 0.2603614105883289, 'Total loss': 0.2603614105883289}
2022-12-31 10:12:41,634 INFO:     Found new best model at epoch 60
2022-12-31 10:12:41,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:41,635 INFO:     Epoch: 61
2022-12-31 10:12:43,242 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.36694857478141785, 'Total loss': 0.36694857478141785} | train loss {'Reaction outcome loss': 0.25947844700822054, 'Total loss': 0.25947844700822054}
2022-12-31 10:12:43,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:43,242 INFO:     Epoch: 62
2022-12-31 10:12:44,838 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3720347364743551, 'Total loss': 0.3720347364743551} | train loss {'Reaction outcome loss': 0.25564174629761366, 'Total loss': 0.25564174629761366}
2022-12-31 10:12:44,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:44,838 INFO:     Epoch: 63
2022-12-31 10:12:46,446 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42994602421919503, 'Total loss': 0.42994602421919503} | train loss {'Reaction outcome loss': 0.255912656904674, 'Total loss': 0.255912656904674}
2022-12-31 10:12:46,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:46,446 INFO:     Epoch: 64
2022-12-31 10:12:48,052 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.38279886345068614, 'Total loss': 0.38279886345068614} | train loss {'Reaction outcome loss': 0.2484740171888573, 'Total loss': 0.2484740171888573}
2022-12-31 10:12:48,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:48,052 INFO:     Epoch: 65
2022-12-31 10:12:49,673 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.403630360464255, 'Total loss': 0.403630360464255} | train loss {'Reaction outcome loss': 0.2528874939893865, 'Total loss': 0.2528874939893865}
2022-12-31 10:12:49,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:49,674 INFO:     Epoch: 66
2022-12-31 10:12:51,388 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3517812013626099, 'Total loss': 0.3517812013626099} | train loss {'Reaction outcome loss': 0.2498750776816767, 'Total loss': 0.2498750776816767}
2022-12-31 10:12:51,389 INFO:     Found new best model at epoch 66
2022-12-31 10:12:51,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:51,389 INFO:     Epoch: 67
2022-12-31 10:12:53,041 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3977455551425616, 'Total loss': 0.3977455551425616} | train loss {'Reaction outcome loss': 0.24820930299060623, 'Total loss': 0.24820930299060623}
2022-12-31 10:12:53,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:53,041 INFO:     Epoch: 68
2022-12-31 10:12:54,625 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3775961091121038, 'Total loss': 0.3775961091121038} | train loss {'Reaction outcome loss': 0.24714115271081685, 'Total loss': 0.24714115271081685}
2022-12-31 10:12:54,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:54,625 INFO:     Epoch: 69
2022-12-31 10:12:56,261 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42431681950887046, 'Total loss': 0.42431681950887046} | train loss {'Reaction outcome loss': 0.24591341855333984, 'Total loss': 0.24591341855333984}
2022-12-31 10:12:56,262 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:56,262 INFO:     Epoch: 70
2022-12-31 10:12:57,909 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3604821801185608, 'Total loss': 0.3604821801185608} | train loss {'Reaction outcome loss': 0.24503281419658932, 'Total loss': 0.24503281419658932}
2022-12-31 10:12:57,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:57,909 INFO:     Epoch: 71
2022-12-31 10:12:59,511 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.36327778498331703, 'Total loss': 0.36327778498331703} | train loss {'Reaction outcome loss': 0.25116365060102247, 'Total loss': 0.25116365060102247}
2022-12-31 10:12:59,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:12:59,511 INFO:     Epoch: 72
2022-12-31 10:13:01,114 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4323205709457397, 'Total loss': 0.4323205709457397} | train loss {'Reaction outcome loss': 0.28407216852233896, 'Total loss': 0.28407216852233896}
2022-12-31 10:13:01,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:01,114 INFO:     Epoch: 73
2022-12-31 10:13:02,715 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3580068930983543, 'Total loss': 0.3580068930983543} | train loss {'Reaction outcome loss': 0.2754502372910687, 'Total loss': 0.2754502372910687}
2022-12-31 10:13:02,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:02,715 INFO:     Epoch: 74
2022-12-31 10:13:04,312 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3785142759482066, 'Total loss': 0.3785142759482066} | train loss {'Reaction outcome loss': 0.24705315646513, 'Total loss': 0.24705315646513}
2022-12-31 10:13:04,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:04,312 INFO:     Epoch: 75
2022-12-31 10:13:05,953 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40165591835975645, 'Total loss': 0.40165591835975645} | train loss {'Reaction outcome loss': 0.23761689810055323, 'Total loss': 0.23761689810055323}
2022-12-31 10:13:05,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:05,953 INFO:     Epoch: 76
2022-12-31 10:13:07,584 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4131370330850283, 'Total loss': 0.4131370330850283} | train loss {'Reaction outcome loss': 0.23640065077368333, 'Total loss': 0.23640065077368333}
2022-12-31 10:13:07,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:07,584 INFO:     Epoch: 77
2022-12-31 10:13:09,198 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39510934154192606, 'Total loss': 0.39510934154192606} | train loss {'Reaction outcome loss': 0.2502235171344617, 'Total loss': 0.2502235171344617}
2022-12-31 10:13:09,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:09,199 INFO:     Epoch: 78
2022-12-31 10:13:10,803 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4012567122777303, 'Total loss': 0.4012567122777303} | train loss {'Reaction outcome loss': 0.3297848415029981, 'Total loss': 0.3297848415029981}
2022-12-31 10:13:10,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:10,803 INFO:     Epoch: 79
2022-12-31 10:13:12,430 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40940677920977275, 'Total loss': 0.40940677920977275} | train loss {'Reaction outcome loss': 0.26110260352488956, 'Total loss': 0.26110260352488956}
2022-12-31 10:13:12,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:12,430 INFO:     Epoch: 80
2022-12-31 10:13:14,029 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.371027151743571, 'Total loss': 0.371027151743571} | train loss {'Reaction outcome loss': 0.23968944091873287, 'Total loss': 0.23968944091873287}
2022-12-31 10:13:14,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:14,030 INFO:     Epoch: 81
2022-12-31 10:13:15,644 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42142154077688854, 'Total loss': 0.42142154077688854} | train loss {'Reaction outcome loss': 0.26206989045106416, 'Total loss': 0.26206989045106416}
2022-12-31 10:13:15,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:15,645 INFO:     Epoch: 82
2022-12-31 10:13:17,251 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.37103054026762644, 'Total loss': 0.37103054026762644} | train loss {'Reaction outcome loss': 0.32686392925139784, 'Total loss': 0.32686392925139784}
2022-12-31 10:13:17,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:17,251 INFO:     Epoch: 83
2022-12-31 10:13:18,867 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3810313393672307, 'Total loss': 0.3810313393672307} | train loss {'Reaction outcome loss': 0.25914876219990285, 'Total loss': 0.25914876219990285}
2022-12-31 10:13:18,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:18,867 INFO:     Epoch: 84
2022-12-31 10:13:20,489 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3834594604869684, 'Total loss': 0.3834594604869684} | train loss {'Reaction outcome loss': 0.24259338120295518, 'Total loss': 0.24259338120295518}
2022-12-31 10:13:20,490 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:20,490 INFO:     Epoch: 85
2022-12-31 10:13:22,089 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3819396493335565, 'Total loss': 0.3819396493335565} | train loss {'Reaction outcome loss': 0.2350176882430695, 'Total loss': 0.2350176882430695}
2022-12-31 10:13:22,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:22,089 INFO:     Epoch: 86
2022-12-31 10:13:23,702 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3946956366300583, 'Total loss': 0.3946956366300583} | train loss {'Reaction outcome loss': 0.23912849686651802, 'Total loss': 0.23912849686651802}
2022-12-31 10:13:23,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:23,702 INFO:     Epoch: 87
2022-12-31 10:13:25,318 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42660247087478637, 'Total loss': 0.42660247087478637} | train loss {'Reaction outcome loss': 0.2312398379334532, 'Total loss': 0.2312398379334532}
2022-12-31 10:13:25,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:25,318 INFO:     Epoch: 88
2022-12-31 10:13:26,911 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4646134555339813, 'Total loss': 0.4646134555339813} | train loss {'Reaction outcome loss': 0.23233118316018564, 'Total loss': 0.23233118316018564}
2022-12-31 10:13:26,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:26,912 INFO:     Epoch: 89
2022-12-31 10:13:28,529 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3905172377824783, 'Total loss': 0.3905172377824783} | train loss {'Reaction outcome loss': 0.2288824997882804, 'Total loss': 0.2288824997882804}
2022-12-31 10:13:28,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:28,530 INFO:     Epoch: 90
2022-12-31 10:13:30,141 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3923174480597178, 'Total loss': 0.3923174480597178} | train loss {'Reaction outcome loss': 0.2283404759414818, 'Total loss': 0.2283404759414818}
2022-12-31 10:13:30,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:30,142 INFO:     Epoch: 91
2022-12-31 10:13:31,790 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39588083724180856, 'Total loss': 0.39588083724180856} | train loss {'Reaction outcome loss': 0.26132947616439406, 'Total loss': 0.26132947616439406}
2022-12-31 10:13:31,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:31,791 INFO:     Epoch: 92
2022-12-31 10:13:33,407 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4411666035652161, 'Total loss': 0.4411666035652161} | train loss {'Reaction outcome loss': 0.22946156372410664, 'Total loss': 0.22946156372410664}
2022-12-31 10:13:33,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:33,407 INFO:     Epoch: 93
2022-12-31 10:13:35,009 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.36795839766661326, 'Total loss': 0.36795839766661326} | train loss {'Reaction outcome loss': 0.2186536117961109, 'Total loss': 0.2186536117961109}
2022-12-31 10:13:35,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:35,009 INFO:     Epoch: 94
2022-12-31 10:13:36,631 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38910594085852307, 'Total loss': 0.38910594085852307} | train loss {'Reaction outcome loss': 0.21976530728136204, 'Total loss': 0.21976530728136204}
2022-12-31 10:13:36,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:36,631 INFO:     Epoch: 95
2022-12-31 10:13:38,260 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3773294905821482, 'Total loss': 0.3773294905821482} | train loss {'Reaction outcome loss': 0.21986528848925524, 'Total loss': 0.21986528848925524}
2022-12-31 10:13:38,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:38,260 INFO:     Epoch: 96
2022-12-31 10:13:39,853 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44766875008742013, 'Total loss': 0.44766875008742013} | train loss {'Reaction outcome loss': 0.22572550700768235, 'Total loss': 0.22572550700768235}
2022-12-31 10:13:39,853 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:39,854 INFO:     Epoch: 97
2022-12-31 10:13:41,450 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3819105878472328, 'Total loss': 0.3819105878472328} | train loss {'Reaction outcome loss': 0.22241434872093901, 'Total loss': 0.22241434872093901}
2022-12-31 10:13:41,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:41,450 INFO:     Epoch: 98
2022-12-31 10:13:43,062 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3948451300462087, 'Total loss': 0.3948451300462087} | train loss {'Reaction outcome loss': 0.21388048345924934, 'Total loss': 0.21388048345924934}
2022-12-31 10:13:43,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:43,062 INFO:     Epoch: 99
2022-12-31 10:13:44,658 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3795717199643453, 'Total loss': 0.3795717199643453} | train loss {'Reaction outcome loss': 0.22222038995106771, 'Total loss': 0.22222038995106771}
2022-12-31 10:13:44,658 INFO:     Best model found after epoch 67 of 100.
2022-12-31 10:13:44,658 INFO:   Done with stage: TRAINING
2022-12-31 10:13:44,658 INFO:   Starting stage: EVALUATION
2022-12-31 10:13:44,785 INFO:   Done with stage: EVALUATION
2022-12-31 10:13:44,785 INFO:   Leaving out SEQ value Fold_6
2022-12-31 10:13:44,798 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 10:13:44,798 INFO:   Starting stage: FEATURE SCALING
2022-12-31 10:13:45,452 INFO:   Done with stage: FEATURE SCALING
2022-12-31 10:13:45,452 INFO:   Starting stage: SCALING TARGETS
2022-12-31 10:13:45,521 INFO:   Done with stage: SCALING TARGETS
2022-12-31 10:13:45,522 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:13:45,522 INFO:     No hyperparam tuning for this model
2022-12-31 10:13:45,522 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:13:45,522 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 10:13:45,523 INFO:     None feature selector for col prot
2022-12-31 10:13:45,523 INFO:     None feature selector for col prot
2022-12-31 10:13:45,523 INFO:     None feature selector for col prot
2022-12-31 10:13:45,523 INFO:     None feature selector for col chem
2022-12-31 10:13:45,523 INFO:     None feature selector for col chem
2022-12-31 10:13:45,523 INFO:     None feature selector for col chem
2022-12-31 10:13:45,523 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 10:13:45,524 INFO:   Starting stage: BUILD MODEL
2022-12-31 10:13:45,525 INFO:     Number of params in model 223921
2022-12-31 10:13:45,528 INFO:   Done with stage: BUILD MODEL
2022-12-31 10:13:45,529 INFO:   Starting stage: TRAINING
2022-12-31 10:13:45,575 INFO:     Val loss before train {'Reaction outcome loss': 1.071174943447113, 'Total loss': 1.071174943447113}
2022-12-31 10:13:45,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:45,575 INFO:     Epoch: 0
2022-12-31 10:13:47,215 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7303732911745707, 'Total loss': 0.7303732911745707} | train loss {'Reaction outcome loss': 0.8098663120708741, 'Total loss': 0.8098663120708741}
2022-12-31 10:13:47,215 INFO:     Found new best model at epoch 0
2022-12-31 10:13:47,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:47,216 INFO:     Epoch: 1
2022-12-31 10:13:48,831 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6481422781944275, 'Total loss': 0.6481422781944275} | train loss {'Reaction outcome loss': 0.5970455949810007, 'Total loss': 0.5970455949810007}
2022-12-31 10:13:48,832 INFO:     Found new best model at epoch 1
2022-12-31 10:13:48,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:48,833 INFO:     Epoch: 2
2022-12-31 10:13:50,448 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5841799954573313, 'Total loss': 0.5841799954573313} | train loss {'Reaction outcome loss': 0.5246462862844502, 'Total loss': 0.5246462862844502}
2022-12-31 10:13:50,449 INFO:     Found new best model at epoch 2
2022-12-31 10:13:50,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:50,450 INFO:     Epoch: 3
2022-12-31 10:13:52,060 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6027971704800924, 'Total loss': 0.6027971704800924} | train loss {'Reaction outcome loss': 0.49960364390581524, 'Total loss': 0.49960364390581524}
2022-12-31 10:13:52,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:52,061 INFO:     Epoch: 4
2022-12-31 10:13:53,657 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5462388952573141, 'Total loss': 0.5462388952573141} | train loss {'Reaction outcome loss': 0.4876300950235408, 'Total loss': 0.4876300950235408}
2022-12-31 10:13:53,658 INFO:     Found new best model at epoch 4
2022-12-31 10:13:53,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:53,658 INFO:     Epoch: 5
2022-12-31 10:13:55,269 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5354685505231221, 'Total loss': 0.5354685505231221} | train loss {'Reaction outcome loss': 0.4707950076579187, 'Total loss': 0.4707950076579187}
2022-12-31 10:13:55,270 INFO:     Found new best model at epoch 5
2022-12-31 10:13:55,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:55,271 INFO:     Epoch: 6
2022-12-31 10:13:56,877 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5459207276503245, 'Total loss': 0.5459207276503245} | train loss {'Reaction outcome loss': 0.4656013213232536, 'Total loss': 0.4656013213232536}
2022-12-31 10:13:56,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:56,878 INFO:     Epoch: 7
2022-12-31 10:13:58,510 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5372814397017162, 'Total loss': 0.5372814397017162} | train loss {'Reaction outcome loss': 0.45203866072617715, 'Total loss': 0.45203866072617715}
2022-12-31 10:13:58,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:13:58,510 INFO:     Epoch: 8
2022-12-31 10:14:00,138 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5440646797418595, 'Total loss': 0.5440646797418595} | train loss {'Reaction outcome loss': 0.4449762814419364, 'Total loss': 0.4449762814419364}
2022-12-31 10:14:00,139 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:00,139 INFO:     Epoch: 9
2022-12-31 10:14:01,762 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5423761606216431, 'Total loss': 0.5423761606216431} | train loss {'Reaction outcome loss': 0.43949955126223583, 'Total loss': 0.43949955126223583}
2022-12-31 10:14:01,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:01,762 INFO:     Epoch: 10
2022-12-31 10:14:03,366 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.548128052552541, 'Total loss': 0.548128052552541} | train loss {'Reaction outcome loss': 0.4315091744603233, 'Total loss': 0.4315091744603233}
2022-12-31 10:14:03,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:03,366 INFO:     Epoch: 11
2022-12-31 10:14:04,980 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5292769134044647, 'Total loss': 0.5292769134044647} | train loss {'Reaction outcome loss': 0.42666373157113896, 'Total loss': 0.42666373157113896}
2022-12-31 10:14:04,980 INFO:     Found new best model at epoch 11
2022-12-31 10:14:04,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:04,981 INFO:     Epoch: 12
2022-12-31 10:14:06,612 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5527117272218068, 'Total loss': 0.5527117272218068} | train loss {'Reaction outcome loss': 0.42004787593757204, 'Total loss': 0.42004787593757204}
2022-12-31 10:14:06,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:06,613 INFO:     Epoch: 13
2022-12-31 10:14:08,274 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5284720619519552, 'Total loss': 0.5284720619519552} | train loss {'Reaction outcome loss': 0.41855342667348117, 'Total loss': 0.41855342667348117}
2022-12-31 10:14:08,274 INFO:     Found new best model at epoch 13
2022-12-31 10:14:08,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:08,275 INFO:     Epoch: 14
2022-12-31 10:14:09,931 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.513617879152298, 'Total loss': 0.513617879152298} | train loss {'Reaction outcome loss': 0.40578443121286073, 'Total loss': 0.40578443121286073}
2022-12-31 10:14:09,932 INFO:     Found new best model at epoch 14
2022-12-31 10:14:09,933 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:09,933 INFO:     Epoch: 15
2022-12-31 10:14:11,570 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5019757737716039, 'Total loss': 0.5019757737716039} | train loss {'Reaction outcome loss': 0.3976272004606061, 'Total loss': 0.3976272004606061}
2022-12-31 10:14:11,570 INFO:     Found new best model at epoch 15
2022-12-31 10:14:11,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:11,571 INFO:     Epoch: 16
2022-12-31 10:14:13,201 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5180868089199067, 'Total loss': 0.5180868089199067} | train loss {'Reaction outcome loss': 0.39406043522409584, 'Total loss': 0.39406043522409584}
2022-12-31 10:14:13,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:13,202 INFO:     Epoch: 17
2022-12-31 10:14:14,811 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5369818945725758, 'Total loss': 0.5369818945725758} | train loss {'Reaction outcome loss': 0.387210536290915, 'Total loss': 0.387210536290915}
2022-12-31 10:14:14,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:14,811 INFO:     Epoch: 18
2022-12-31 10:14:16,408 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4942978978157043, 'Total loss': 0.4942978978157043} | train loss {'Reaction outcome loss': 0.38042329365407734, 'Total loss': 0.38042329365407734}
2022-12-31 10:14:16,408 INFO:     Found new best model at epoch 18
2022-12-31 10:14:16,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:16,409 INFO:     Epoch: 19
2022-12-31 10:14:18,020 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4791504194339116, 'Total loss': 0.4791504194339116} | train loss {'Reaction outcome loss': 0.37574343858051384, 'Total loss': 0.37574343858051384}
2022-12-31 10:14:18,020 INFO:     Found new best model at epoch 19
2022-12-31 10:14:18,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:18,021 INFO:     Epoch: 20
2022-12-31 10:14:19,629 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47701045672098796, 'Total loss': 0.47701045672098796} | train loss {'Reaction outcome loss': 0.37747748416683735, 'Total loss': 0.37747748416683735}
2022-12-31 10:14:19,629 INFO:     Found new best model at epoch 20
2022-12-31 10:14:19,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:19,630 INFO:     Epoch: 21
2022-12-31 10:14:21,233 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5070052047570547, 'Total loss': 0.5070052047570547} | train loss {'Reaction outcome loss': 0.3713602023972501, 'Total loss': 0.3713602023972501}
2022-12-31 10:14:21,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:21,233 INFO:     Epoch: 22
2022-12-31 10:14:22,883 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4946755707263947, 'Total loss': 0.4946755707263947} | train loss {'Reaction outcome loss': 0.36730785866937055, 'Total loss': 0.36730785866937055}
2022-12-31 10:14:22,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:22,884 INFO:     Epoch: 23
2022-12-31 10:14:24,516 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.49656102856000267, 'Total loss': 0.49656102856000267} | train loss {'Reaction outcome loss': 0.35823031262047456, 'Total loss': 0.35823031262047456}
2022-12-31 10:14:24,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:24,517 INFO:     Epoch: 24
2022-12-31 10:14:26,128 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5123565932114919, 'Total loss': 0.5123565932114919} | train loss {'Reaction outcome loss': 0.3504117429256439, 'Total loss': 0.3504117429256439}
2022-12-31 10:14:26,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:26,129 INFO:     Epoch: 25
2022-12-31 10:14:27,739 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4510313292344411, 'Total loss': 0.4510313292344411} | train loss {'Reaction outcome loss': 0.34361215332516265, 'Total loss': 0.34361215332516265}
2022-12-31 10:14:27,740 INFO:     Found new best model at epoch 25
2022-12-31 10:14:27,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:27,741 INFO:     Epoch: 26
2022-12-31 10:14:29,337 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4743902593851089, 'Total loss': 0.4743902593851089} | train loss {'Reaction outcome loss': 0.3413231254215705, 'Total loss': 0.3413231254215705}
2022-12-31 10:14:29,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:29,337 INFO:     Epoch: 27
2022-12-31 10:14:30,937 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5049798975388209, 'Total loss': 0.5049798975388209} | train loss {'Reaction outcome loss': 0.3302854892901996, 'Total loss': 0.3302854892901996}
2022-12-31 10:14:30,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:30,937 INFO:     Epoch: 28
2022-12-31 10:14:32,546 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4832144151131312, 'Total loss': 0.4832144151131312} | train loss {'Reaction outcome loss': 0.33625019664476063, 'Total loss': 0.33625019664476063}
2022-12-31 10:14:32,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:32,546 INFO:     Epoch: 29
2022-12-31 10:14:34,143 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45254321992397306, 'Total loss': 0.45254321992397306} | train loss {'Reaction outcome loss': 0.321955258369661, 'Total loss': 0.321955258369661}
2022-12-31 10:14:34,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:34,144 INFO:     Epoch: 30
2022-12-31 10:14:35,757 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5001271903514862, 'Total loss': 0.5001271903514862} | train loss {'Reaction outcome loss': 0.3185387606655217, 'Total loss': 0.3185387606655217}
2022-12-31 10:14:35,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:35,758 INFO:     Epoch: 31
2022-12-31 10:14:37,370 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46954795718193054, 'Total loss': 0.46954795718193054} | train loss {'Reaction outcome loss': 0.3216593422076332, 'Total loss': 0.3216593422076332}
2022-12-31 10:14:37,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:37,370 INFO:     Epoch: 32
2022-12-31 10:14:38,964 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.44350110987822217, 'Total loss': 0.44350110987822217} | train loss {'Reaction outcome loss': 0.3132974048168651, 'Total loss': 0.3132974048168651}
2022-12-31 10:14:38,964 INFO:     Found new best model at epoch 32
2022-12-31 10:14:38,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:38,965 INFO:     Epoch: 33
2022-12-31 10:14:40,576 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44965962966283163, 'Total loss': 0.44965962966283163} | train loss {'Reaction outcome loss': 0.308473325270608, 'Total loss': 0.308473325270608}
2022-12-31 10:14:40,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:40,576 INFO:     Epoch: 34
2022-12-31 10:14:42,176 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4883518626292547, 'Total loss': 0.4883518626292547} | train loss {'Reaction outcome loss': 0.30587064221985505, 'Total loss': 0.30587064221985505}
2022-12-31 10:14:42,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:42,176 INFO:     Epoch: 35
2022-12-31 10:14:43,837 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4670520762602488, 'Total loss': 0.4670520762602488} | train loss {'Reaction outcome loss': 0.3006351314592663, 'Total loss': 0.3006351314592663}
2022-12-31 10:14:43,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:43,837 INFO:     Epoch: 36
2022-12-31 10:14:45,487 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4577546288569768, 'Total loss': 0.4577546288569768} | train loss {'Reaction outcome loss': 0.30348973406566176, 'Total loss': 0.30348973406566176}
2022-12-31 10:14:45,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:45,487 INFO:     Epoch: 37
2022-12-31 10:14:47,098 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4868768115838369, 'Total loss': 0.4868768115838369} | train loss {'Reaction outcome loss': 0.2935405540202714, 'Total loss': 0.2935405540202714}
2022-12-31 10:14:47,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:47,099 INFO:     Epoch: 38
2022-12-31 10:14:48,731 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4750983436902364, 'Total loss': 0.4750983436902364} | train loss {'Reaction outcome loss': 0.2900588622296545, 'Total loss': 0.2900588622296545}
2022-12-31 10:14:48,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:48,731 INFO:     Epoch: 39
2022-12-31 10:14:50,392 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43726716140906013, 'Total loss': 0.43726716140906013} | train loss {'Reaction outcome loss': 0.2890179233780191, 'Total loss': 0.2890179233780191}
2022-12-31 10:14:50,392 INFO:     Found new best model at epoch 39
2022-12-31 10:14:50,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:50,393 INFO:     Epoch: 40
2022-12-31 10:14:52,021 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44170342485109965, 'Total loss': 0.44170342485109965} | train loss {'Reaction outcome loss': 0.2851767284990648, 'Total loss': 0.2851767284990648}
2022-12-31 10:14:52,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:52,021 INFO:     Epoch: 41
2022-12-31 10:14:53,625 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47057350476582843, 'Total loss': 0.47057350476582843} | train loss {'Reaction outcome loss': 0.2783485392532194, 'Total loss': 0.2783485392532194}
2022-12-31 10:14:53,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:53,625 INFO:     Epoch: 42
2022-12-31 10:14:55,269 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4400775710741679, 'Total loss': 0.4400775710741679} | train loss {'Reaction outcome loss': 0.2855133106965666, 'Total loss': 0.2855133106965666}
2022-12-31 10:14:55,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:55,269 INFO:     Epoch: 43
2022-12-31 10:14:56,856 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4200390974680583, 'Total loss': 0.4200390974680583} | train loss {'Reaction outcome loss': 0.27636454442670627, 'Total loss': 0.27636454442670627}
2022-12-31 10:14:56,856 INFO:     Found new best model at epoch 43
2022-12-31 10:14:56,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:56,857 INFO:     Epoch: 44
2022-12-31 10:14:58,480 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42598728140195213, 'Total loss': 0.42598728140195213} | train loss {'Reaction outcome loss': 0.27137309716281477, 'Total loss': 0.27137309716281477}
2022-12-31 10:14:58,480 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:14:58,480 INFO:     Epoch: 45
2022-12-31 10:15:00,089 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.43190189202626544, 'Total loss': 0.43190189202626544} | train loss {'Reaction outcome loss': 0.27325093586145754, 'Total loss': 0.27325093586145754}
2022-12-31 10:15:00,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:00,089 INFO:     Epoch: 46
2022-12-31 10:15:01,687 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47253407835960387, 'Total loss': 0.47253407835960387} | train loss {'Reaction outcome loss': 0.26355759982382776, 'Total loss': 0.26355759982382776}
2022-12-31 10:15:01,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:01,687 INFO:     Epoch: 47
2022-12-31 10:15:03,299 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4201311399539312, 'Total loss': 0.4201311399539312} | train loss {'Reaction outcome loss': 0.2713682448444384, 'Total loss': 0.2713682448444384}
2022-12-31 10:15:03,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:03,300 INFO:     Epoch: 48
2022-12-31 10:15:04,911 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4205848962068558, 'Total loss': 0.4205848962068558} | train loss {'Reaction outcome loss': 0.26585788831168566, 'Total loss': 0.26585788831168566}
2022-12-31 10:15:04,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:04,912 INFO:     Epoch: 49
2022-12-31 10:15:06,506 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42752182682355244, 'Total loss': 0.42752182682355244} | train loss {'Reaction outcome loss': 0.2585108143408591, 'Total loss': 0.2585108143408591}
2022-12-31 10:15:06,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:06,506 INFO:     Epoch: 50
2022-12-31 10:15:08,119 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3923533380031586, 'Total loss': 0.3923533380031586} | train loss {'Reaction outcome loss': 0.2603979009314565, 'Total loss': 0.2603979009314565}
2022-12-31 10:15:08,119 INFO:     Found new best model at epoch 50
2022-12-31 10:15:08,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:08,120 INFO:     Epoch: 51
2022-12-31 10:15:09,719 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42878390749295553, 'Total loss': 0.42878390749295553} | train loss {'Reaction outcome loss': 0.2613368637738783, 'Total loss': 0.2613368637738783}
2022-12-31 10:15:09,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:09,720 INFO:     Epoch: 52
2022-12-31 10:15:11,340 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4298578977584839, 'Total loss': 0.4298578977584839} | train loss {'Reaction outcome loss': 0.2544778209139294, 'Total loss': 0.2544778209139294}
2022-12-31 10:15:11,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:11,340 INFO:     Epoch: 53
2022-12-31 10:15:12,953 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44782722493012744, 'Total loss': 0.44782722493012744} | train loss {'Reaction outcome loss': 0.2506514158812671, 'Total loss': 0.2506514158812671}
2022-12-31 10:15:12,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:12,953 INFO:     Epoch: 54
2022-12-31 10:15:14,541 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4659781326850255, 'Total loss': 0.4659781326850255} | train loss {'Reaction outcome loss': 0.2534696446321501, 'Total loss': 0.2534696446321501}
2022-12-31 10:15:14,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:14,541 INFO:     Epoch: 55
2022-12-31 10:15:16,174 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4124068796634674, 'Total loss': 0.4124068796634674} | train loss {'Reaction outcome loss': 0.2580413705793744, 'Total loss': 0.2580413705793744}
2022-12-31 10:15:16,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:16,175 INFO:     Epoch: 56
2022-12-31 10:15:17,787 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41837996343771616, 'Total loss': 0.41837996343771616} | train loss {'Reaction outcome loss': 0.24216632778329325, 'Total loss': 0.24216632778329325}
2022-12-31 10:15:17,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:17,787 INFO:     Epoch: 57
2022-12-31 10:15:19,384 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43032535115877785, 'Total loss': 0.43032535115877785} | train loss {'Reaction outcome loss': 0.24422922620838944, 'Total loss': 0.24422922620838944}
2022-12-31 10:15:19,384 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:19,384 INFO:     Epoch: 58
2022-12-31 10:15:20,997 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4430976947148641, 'Total loss': 0.4430976947148641} | train loss {'Reaction outcome loss': 0.24679375932104752, 'Total loss': 0.24679375932104752}
2022-12-31 10:15:20,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:20,998 INFO:     Epoch: 59
2022-12-31 10:15:22,613 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40347055395444237, 'Total loss': 0.40347055395444237} | train loss {'Reaction outcome loss': 0.24207966337619274, 'Total loss': 0.24207966337619274}
2022-12-31 10:15:22,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:22,614 INFO:     Epoch: 60
2022-12-31 10:15:24,230 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42497823139031726, 'Total loss': 0.42497823139031726} | train loss {'Reaction outcome loss': 0.237845799095579, 'Total loss': 0.237845799095579}
2022-12-31 10:15:24,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:24,230 INFO:     Epoch: 61
2022-12-31 10:15:25,887 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4083447108666102, 'Total loss': 0.4083447108666102} | train loss {'Reaction outcome loss': 0.24066958266448243, 'Total loss': 0.24066958266448243}
2022-12-31 10:15:25,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:25,888 INFO:     Epoch: 62
2022-12-31 10:15:27,492 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43131363491217295, 'Total loss': 0.43131363491217295} | train loss {'Reaction outcome loss': 0.23796685212140478, 'Total loss': 0.23796685212140478}
2022-12-31 10:15:27,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:27,492 INFO:     Epoch: 63
2022-12-31 10:15:29,144 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4245476186275482, 'Total loss': 0.4245476186275482} | train loss {'Reaction outcome loss': 0.23874459300351594, 'Total loss': 0.23874459300351594}
2022-12-31 10:15:29,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:29,144 INFO:     Epoch: 64
2022-12-31 10:15:30,760 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42720166643460594, 'Total loss': 0.42720166643460594} | train loss {'Reaction outcome loss': 0.23580504527537402, 'Total loss': 0.23580504527537402}
2022-12-31 10:15:30,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:30,760 INFO:     Epoch: 65
2022-12-31 10:15:32,374 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42107459902763367, 'Total loss': 0.42107459902763367} | train loss {'Reaction outcome loss': 0.23606591765846155, 'Total loss': 0.23606591765846155}
2022-12-31 10:15:32,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:32,374 INFO:     Epoch: 66
2022-12-31 10:15:34,010 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4554249326388041, 'Total loss': 0.4554249326388041} | train loss {'Reaction outcome loss': 0.23534269332347793, 'Total loss': 0.23534269332347793}
2022-12-31 10:15:34,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:34,010 INFO:     Epoch: 67
2022-12-31 10:15:35,650 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43786209523677827, 'Total loss': 0.43786209523677827} | train loss {'Reaction outcome loss': 0.2272689574354392, 'Total loss': 0.2272689574354392}
2022-12-31 10:15:35,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:35,650 INFO:     Epoch: 68
2022-12-31 10:15:37,266 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40875902970631917, 'Total loss': 0.40875902970631917} | train loss {'Reaction outcome loss': 0.23188293971363388, 'Total loss': 0.23188293971363388}
2022-12-31 10:15:37,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:37,266 INFO:     Epoch: 69
2022-12-31 10:15:38,881 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4160203297932943, 'Total loss': 0.4160203297932943} | train loss {'Reaction outcome loss': 0.22613645820384207, 'Total loss': 0.22613645820384207}
2022-12-31 10:15:38,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:38,882 INFO:     Epoch: 70
2022-12-31 10:15:40,497 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43792738517125446, 'Total loss': 0.43792738517125446} | train loss {'Reaction outcome loss': 0.22658141124119396, 'Total loss': 0.22658141124119396}
2022-12-31 10:15:40,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:40,497 INFO:     Epoch: 71
2022-12-31 10:15:42,100 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3930853843688965, 'Total loss': 0.3930853843688965} | train loss {'Reaction outcome loss': 0.2283940475420616, 'Total loss': 0.2283940475420616}
2022-12-31 10:15:42,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:42,100 INFO:     Epoch: 72
2022-12-31 10:15:43,745 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45203479528427126, 'Total loss': 0.45203479528427126} | train loss {'Reaction outcome loss': 0.2265901033386642, 'Total loss': 0.2265901033386642}
2022-12-31 10:15:43,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:43,745 INFO:     Epoch: 73
2022-12-31 10:15:45,380 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4416823506355286, 'Total loss': 0.4416823506355286} | train loss {'Reaction outcome loss': 0.2209629482566127, 'Total loss': 0.2209629482566127}
2022-12-31 10:15:45,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:45,381 INFO:     Epoch: 74
2022-12-31 10:15:46,994 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4281073828538259, 'Total loss': 0.4281073828538259} | train loss {'Reaction outcome loss': 0.22954786824741627, 'Total loss': 0.22954786824741627}
2022-12-31 10:15:46,994 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:46,994 INFO:     Epoch: 75
2022-12-31 10:15:48,609 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43696138858795164, 'Total loss': 0.43696138858795164} | train loss {'Reaction outcome loss': 0.21813260209124657, 'Total loss': 0.21813260209124657}
2022-12-31 10:15:48,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:48,610 INFO:     Epoch: 76
2022-12-31 10:15:50,224 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3804206361373266, 'Total loss': 0.3804206361373266} | train loss {'Reaction outcome loss': 0.21986767263672843, 'Total loss': 0.21986767263672843}
2022-12-31 10:15:50,224 INFO:     Found new best model at epoch 76
2022-12-31 10:15:50,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:50,225 INFO:     Epoch: 77
2022-12-31 10:15:51,820 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4390072206656138, 'Total loss': 0.4390072206656138} | train loss {'Reaction outcome loss': 0.21718238770208634, 'Total loss': 0.21718238770208634}
2022-12-31 10:15:51,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:51,820 INFO:     Epoch: 78
2022-12-31 10:15:53,435 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.425278510649999, 'Total loss': 0.425278510649999} | train loss {'Reaction outcome loss': 0.21950724398858495, 'Total loss': 0.21950724398858495}
2022-12-31 10:15:53,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:53,435 INFO:     Epoch: 79
2022-12-31 10:15:55,041 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42700669169425964, 'Total loss': 0.42700669169425964} | train loss {'Reaction outcome loss': 0.21226428059141558, 'Total loss': 0.21226428059141558}
2022-12-31 10:15:55,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:55,041 INFO:     Epoch: 80
2022-12-31 10:15:56,662 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43379337986310323, 'Total loss': 0.43379337986310323} | train loss {'Reaction outcome loss': 0.21269846415745652, 'Total loss': 0.21269846415745652}
2022-12-31 10:15:56,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:56,662 INFO:     Epoch: 81
2022-12-31 10:15:58,282 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4679400900999705, 'Total loss': 0.4679400900999705} | train loss {'Reaction outcome loss': 0.2088217061846803, 'Total loss': 0.2088217061846803}
2022-12-31 10:15:58,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:58,283 INFO:     Epoch: 82
2022-12-31 10:15:59,881 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3946012447277705, 'Total loss': 0.3946012447277705} | train loss {'Reaction outcome loss': 0.21710152138656658, 'Total loss': 0.21710152138656658}
2022-12-31 10:15:59,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:15:59,881 INFO:     Epoch: 83
2022-12-31 10:16:01,550 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4535052796204885, 'Total loss': 0.4535052796204885} | train loss {'Reaction outcome loss': 0.21435209609810196, 'Total loss': 0.21435209609810196}
2022-12-31 10:16:01,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:01,550 INFO:     Epoch: 84
2022-12-31 10:16:03,216 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4215797712405523, 'Total loss': 0.4215797712405523} | train loss {'Reaction outcome loss': 0.21087338911228232, 'Total loss': 0.21087338911228232}
2022-12-31 10:16:03,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:03,216 INFO:     Epoch: 85
2022-12-31 10:16:04,826 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4085129121939341, 'Total loss': 0.4085129121939341} | train loss {'Reaction outcome loss': 0.20427451453538148, 'Total loss': 0.20427451453538148}
2022-12-31 10:16:04,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:04,826 INFO:     Epoch: 86
2022-12-31 10:16:06,448 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4034184142947197, 'Total loss': 0.4034184142947197} | train loss {'Reaction outcome loss': 0.20809785389620475, 'Total loss': 0.20809785389620475}
2022-12-31 10:16:06,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:06,448 INFO:     Epoch: 87
2022-12-31 10:16:08,069 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44312970836957294, 'Total loss': 0.44312970836957294} | train loss {'Reaction outcome loss': 0.2079792899694899, 'Total loss': 0.2079792899694899}
2022-12-31 10:16:08,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:08,069 INFO:     Epoch: 88
2022-12-31 10:16:09,686 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4346114456653595, 'Total loss': 0.4346114456653595} | train loss {'Reaction outcome loss': 0.2142053027754979, 'Total loss': 0.2142053027754979}
2022-12-31 10:16:09,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:09,687 INFO:     Epoch: 89
2022-12-31 10:16:11,303 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39149191975593567, 'Total loss': 0.39149191975593567} | train loss {'Reaction outcome loss': 0.20844642603467303, 'Total loss': 0.20844642603467303}
2022-12-31 10:16:11,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:11,303 INFO:     Epoch: 90
2022-12-31 10:16:12,921 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41744021475315096, 'Total loss': 0.41744021475315096} | train loss {'Reaction outcome loss': 0.20416295371062057, 'Total loss': 0.20416295371062057}
2022-12-31 10:16:12,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:12,921 INFO:     Epoch: 91
2022-12-31 10:16:14,542 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4513783117135366, 'Total loss': 0.4513783117135366} | train loss {'Reaction outcome loss': 0.20069991707102486, 'Total loss': 0.20069991707102486}
2022-12-31 10:16:14,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:14,542 INFO:     Epoch: 92
2022-12-31 10:16:16,178 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40477726260821023, 'Total loss': 0.40477726260821023} | train loss {'Reaction outcome loss': 0.20200658685087297, 'Total loss': 0.20200658685087297}
2022-12-31 10:16:16,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:16,179 INFO:     Epoch: 93
2022-12-31 10:16:17,816 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4340574949979782, 'Total loss': 0.4340574949979782} | train loss {'Reaction outcome loss': 0.20061449207271373, 'Total loss': 0.20061449207271373}
2022-12-31 10:16:17,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:17,816 INFO:     Epoch: 94
2022-12-31 10:16:19,421 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4432273288567861, 'Total loss': 0.4432273288567861} | train loss {'Reaction outcome loss': 0.19902750093906796, 'Total loss': 0.19902750093906796}
2022-12-31 10:16:19,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:19,421 INFO:     Epoch: 95
2022-12-31 10:16:21,076 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4199808230002721, 'Total loss': 0.4199808230002721} | train loss {'Reaction outcome loss': 0.20276212785056782, 'Total loss': 0.20276212785056782}
2022-12-31 10:16:21,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:21,076 INFO:     Epoch: 96
2022-12-31 10:16:22,705 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4294818709294001, 'Total loss': 0.4294818709294001} | train loss {'Reaction outcome loss': 0.1979912969213154, 'Total loss': 0.1979912969213154}
2022-12-31 10:16:22,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:22,705 INFO:     Epoch: 97
2022-12-31 10:16:24,326 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4465616395076116, 'Total loss': 0.4465616395076116} | train loss {'Reaction outcome loss': 0.19914281239148082, 'Total loss': 0.19914281239148082}
2022-12-31 10:16:24,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:24,326 INFO:     Epoch: 98
2022-12-31 10:16:25,947 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4325227494041125, 'Total loss': 0.4325227494041125} | train loss {'Reaction outcome loss': 0.18984718830408764, 'Total loss': 0.18984718830408764}
2022-12-31 10:16:25,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:25,947 INFO:     Epoch: 99
2022-12-31 10:16:27,550 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44273340503374736, 'Total loss': 0.44273340503374736} | train loss {'Reaction outcome loss': 0.1997261830481166, 'Total loss': 0.1997261830481166}
2022-12-31 10:16:27,550 INFO:     Best model found after epoch 77 of 100.
2022-12-31 10:16:27,550 INFO:   Done with stage: TRAINING
2022-12-31 10:16:27,550 INFO:   Starting stage: EVALUATION
2022-12-31 10:16:27,671 INFO:   Done with stage: EVALUATION
2022-12-31 10:16:27,671 INFO:   Leaving out SEQ value Fold_7
2022-12-31 10:16:27,683 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 10:16:27,684 INFO:   Starting stage: FEATURE SCALING
2022-12-31 10:16:28,333 INFO:   Done with stage: FEATURE SCALING
2022-12-31 10:16:28,334 INFO:   Starting stage: SCALING TARGETS
2022-12-31 10:16:28,404 INFO:   Done with stage: SCALING TARGETS
2022-12-31 10:16:28,404 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:16:28,405 INFO:     No hyperparam tuning for this model
2022-12-31 10:16:28,405 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:16:28,405 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 10:16:28,405 INFO:     None feature selector for col prot
2022-12-31 10:16:28,405 INFO:     None feature selector for col prot
2022-12-31 10:16:28,406 INFO:     None feature selector for col prot
2022-12-31 10:16:28,406 INFO:     None feature selector for col chem
2022-12-31 10:16:28,406 INFO:     None feature selector for col chem
2022-12-31 10:16:28,406 INFO:     None feature selector for col chem
2022-12-31 10:16:28,406 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 10:16:28,406 INFO:   Starting stage: BUILD MODEL
2022-12-31 10:16:28,408 INFO:     Number of params in model 223921
2022-12-31 10:16:28,411 INFO:   Done with stage: BUILD MODEL
2022-12-31 10:16:28,411 INFO:   Starting stage: TRAINING
2022-12-31 10:16:28,458 INFO:     Val loss before train {'Reaction outcome loss': 1.0251702109972636, 'Total loss': 1.0251702109972636}
2022-12-31 10:16:28,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:28,458 INFO:     Epoch: 0
2022-12-31 10:16:30,105 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7683078845342001, 'Total loss': 0.7683078845342001} | train loss {'Reaction outcome loss': 0.8046263888854843, 'Total loss': 0.8046263888854843}
2022-12-31 10:16:30,105 INFO:     Found new best model at epoch 0
2022-12-31 10:16:30,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:30,106 INFO:     Epoch: 1
2022-12-31 10:16:31,710 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6147523403167725, 'Total loss': 0.6147523403167725} | train loss {'Reaction outcome loss': 0.595948715395015, 'Total loss': 0.595948715395015}
2022-12-31 10:16:31,710 INFO:     Found new best model at epoch 1
2022-12-31 10:16:31,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:31,711 INFO:     Epoch: 2
2022-12-31 10:16:33,368 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5846109251181285, 'Total loss': 0.5846109251181285} | train loss {'Reaction outcome loss': 0.5194740703712732, 'Total loss': 0.5194740703712732}
2022-12-31 10:16:33,368 INFO:     Found new best model at epoch 2
2022-12-31 10:16:33,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:33,369 INFO:     Epoch: 3
2022-12-31 10:16:34,989 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5860201179981231, 'Total loss': 0.5860201179981231} | train loss {'Reaction outcome loss': 0.49465661130119315, 'Total loss': 0.49465661130119315}
2022-12-31 10:16:34,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:34,989 INFO:     Epoch: 4
2022-12-31 10:16:36,616 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5755843957265218, 'Total loss': 0.5755843957265218} | train loss {'Reaction outcome loss': 0.4781536915026847, 'Total loss': 0.4781536915026847}
2022-12-31 10:16:36,616 INFO:     Found new best model at epoch 4
2022-12-31 10:16:36,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:36,617 INFO:     Epoch: 5
2022-12-31 10:16:38,252 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5525944312413533, 'Total loss': 0.5525944312413533} | train loss {'Reaction outcome loss': 0.4702818963125294, 'Total loss': 0.4702818963125294}
2022-12-31 10:16:38,252 INFO:     Found new best model at epoch 5
2022-12-31 10:16:38,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:38,253 INFO:     Epoch: 6
2022-12-31 10:16:39,846 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5176629384358724, 'Total loss': 0.5176629384358724} | train loss {'Reaction outcome loss': 0.4604049277111942, 'Total loss': 0.4604049277111942}
2022-12-31 10:16:39,846 INFO:     Found new best model at epoch 6
2022-12-31 10:16:39,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:39,847 INFO:     Epoch: 7
2022-12-31 10:16:41,464 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5653831452131272, 'Total loss': 0.5653831452131272} | train loss {'Reaction outcome loss': 0.4488862784115416, 'Total loss': 0.4488862784115416}
2022-12-31 10:16:41,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:41,464 INFO:     Epoch: 8
2022-12-31 10:16:43,080 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5113984187444051, 'Total loss': 0.5113984187444051} | train loss {'Reaction outcome loss': 0.4483363147461888, 'Total loss': 0.4483363147461888}
2022-12-31 10:16:43,080 INFO:     Found new best model at epoch 8
2022-12-31 10:16:43,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:43,081 INFO:     Epoch: 9
2022-12-31 10:16:44,695 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5465422580639522, 'Total loss': 0.5465422580639522} | train loss {'Reaction outcome loss': 0.4380400155533092, 'Total loss': 0.4380400155533092}
2022-12-31 10:16:44,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:44,696 INFO:     Epoch: 10
2022-12-31 10:16:46,316 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5187346239884695, 'Total loss': 0.5187346239884695} | train loss {'Reaction outcome loss': 0.4327851912067255, 'Total loss': 0.4327851912067255}
2022-12-31 10:16:46,316 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:46,316 INFO:     Epoch: 11
2022-12-31 10:16:47,963 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5371382236480713, 'Total loss': 0.5371382236480713} | train loss {'Reaction outcome loss': 0.42702865293955544, 'Total loss': 0.42702865293955544}
2022-12-31 10:16:47,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:47,963 INFO:     Epoch: 12
2022-12-31 10:16:49,584 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5385396997133891, 'Total loss': 0.5385396997133891} | train loss {'Reaction outcome loss': 0.4242824977431917, 'Total loss': 0.4242824977431917}
2022-12-31 10:16:49,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:49,584 INFO:     Epoch: 13
2022-12-31 10:16:51,235 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5137973159551621, 'Total loss': 0.5137973159551621} | train loss {'Reaction outcome loss': 0.41074248309169864, 'Total loss': 0.41074248309169864}
2022-12-31 10:16:51,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:51,236 INFO:     Epoch: 14
2022-12-31 10:16:52,902 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5310206115245819, 'Total loss': 0.5310206115245819} | train loss {'Reaction outcome loss': 0.414396519533994, 'Total loss': 0.414396519533994}
2022-12-31 10:16:52,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:52,902 INFO:     Epoch: 15
2022-12-31 10:16:54,526 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.534263676404953, 'Total loss': 0.534263676404953} | train loss {'Reaction outcome loss': 0.4005455624863559, 'Total loss': 0.4005455624863559}
2022-12-31 10:16:54,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:54,526 INFO:     Epoch: 16
2022-12-31 10:16:56,176 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5661278267701467, 'Total loss': 0.5661278267701467} | train loss {'Reaction outcome loss': 0.40061694367482775, 'Total loss': 0.40061694367482775}
2022-12-31 10:16:56,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:56,177 INFO:     Epoch: 17
2022-12-31 10:16:57,825 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.487961146235466, 'Total loss': 0.487961146235466} | train loss {'Reaction outcome loss': 0.3925890262215146, 'Total loss': 0.3925890262215146}
2022-12-31 10:16:57,825 INFO:     Found new best model at epoch 17
2022-12-31 10:16:57,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:57,826 INFO:     Epoch: 18
2022-12-31 10:16:59,430 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5020808830857277, 'Total loss': 0.5020808830857277} | train loss {'Reaction outcome loss': 0.385563100045984, 'Total loss': 0.385563100045984}
2022-12-31 10:16:59,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:16:59,430 INFO:     Epoch: 19
2022-12-31 10:17:01,041 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5114829381306966, 'Total loss': 0.5114829381306966} | train loss {'Reaction outcome loss': 0.3833311912385135, 'Total loss': 0.3833311912385135}
2022-12-31 10:17:01,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:01,041 INFO:     Epoch: 20
2022-12-31 10:17:02,651 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5130703866481781, 'Total loss': 0.5130703866481781} | train loss {'Reaction outcome loss': 0.3773329490358649, 'Total loss': 0.3773329490358649}
2022-12-31 10:17:02,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:02,651 INFO:     Epoch: 21
2022-12-31 10:17:04,244 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.531633327404658, 'Total loss': 0.531633327404658} | train loss {'Reaction outcome loss': 0.3683637482541132, 'Total loss': 0.3683637482541132}
2022-12-31 10:17:04,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:04,245 INFO:     Epoch: 22
2022-12-31 10:17:05,854 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5516518826285998, 'Total loss': 0.5516518826285998} | train loss {'Reaction outcome loss': 0.3692589999455622, 'Total loss': 0.3692589999455622}
2022-12-31 10:17:05,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:05,854 INFO:     Epoch: 23
2022-12-31 10:17:07,445 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4757270932197571, 'Total loss': 0.4757270932197571} | train loss {'Reaction outcome loss': 0.3608677620707006, 'Total loss': 0.3608677620707006}
2022-12-31 10:17:07,445 INFO:     Found new best model at epoch 23
2022-12-31 10:17:07,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:07,446 INFO:     Epoch: 24
2022-12-31 10:17:09,081 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5104253540436426, 'Total loss': 0.5104253540436426} | train loss {'Reaction outcome loss': 0.35302009191431294, 'Total loss': 0.35302009191431294}
2022-12-31 10:17:09,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:09,081 INFO:     Epoch: 25
2022-12-31 10:17:10,725 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4791611115137736, 'Total loss': 0.4791611115137736} | train loss {'Reaction outcome loss': 0.3549045341001951, 'Total loss': 0.3549045341001951}
2022-12-31 10:17:10,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:10,726 INFO:     Epoch: 26
2022-12-31 10:17:12,367 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5021556476751964, 'Total loss': 0.5021556476751964} | train loss {'Reaction outcome loss': 0.34473404046215306, 'Total loss': 0.34473404046215306}
2022-12-31 10:17:12,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:12,367 INFO:     Epoch: 27
2022-12-31 10:17:13,973 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5229590783516566, 'Total loss': 0.5229590783516566} | train loss {'Reaction outcome loss': 0.3464143998947815, 'Total loss': 0.3464143998947815}
2022-12-31 10:17:13,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:13,973 INFO:     Epoch: 28
2022-12-31 10:17:15,584 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5182379702727, 'Total loss': 0.5182379702727} | train loss {'Reaction outcome loss': 0.33817050047891234, 'Total loss': 0.33817050047891234}
2022-12-31 10:17:15,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:15,585 INFO:     Epoch: 29
2022-12-31 10:17:17,184 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5043698489665985, 'Total loss': 0.5043698489665985} | train loss {'Reaction outcome loss': 0.3313464426875975, 'Total loss': 0.3313464426875975}
2022-12-31 10:17:17,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:17,185 INFO:     Epoch: 30
2022-12-31 10:17:18,793 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.501585590839386, 'Total loss': 0.501585590839386} | train loss {'Reaction outcome loss': 0.3321667569370046, 'Total loss': 0.3321667569370046}
2022-12-31 10:17:18,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:18,793 INFO:     Epoch: 31
2022-12-31 10:17:20,402 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.494128676255544, 'Total loss': 0.494128676255544} | train loss {'Reaction outcome loss': 0.3239841316204639, 'Total loss': 0.3239841316204639}
2022-12-31 10:17:20,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:20,404 INFO:     Epoch: 32
2022-12-31 10:17:21,993 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5312447488307953, 'Total loss': 0.5312447488307953} | train loss {'Reaction outcome loss': 0.32194228327769236, 'Total loss': 0.32194228327769236}
2022-12-31 10:17:21,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:21,993 INFO:     Epoch: 33
2022-12-31 10:17:23,602 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5156760146220525, 'Total loss': 0.5156760146220525} | train loss {'Reaction outcome loss': 0.3162041489935954, 'Total loss': 0.3162041489935954}
2022-12-31 10:17:23,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:23,602 INFO:     Epoch: 34
2022-12-31 10:17:25,205 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5158498128255208, 'Total loss': 0.5158498128255208} | train loss {'Reaction outcome loss': 0.31562907861996214, 'Total loss': 0.31562907861996214}
2022-12-31 10:17:25,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:25,205 INFO:     Epoch: 35
2022-12-31 10:17:26,835 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5084014713764191, 'Total loss': 0.5084014713764191} | train loss {'Reaction outcome loss': 0.3080559861089779, 'Total loss': 0.3080559861089779}
2022-12-31 10:17:26,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:26,836 INFO:     Epoch: 36
2022-12-31 10:17:28,444 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4842442750930786, 'Total loss': 0.4842442750930786} | train loss {'Reaction outcome loss': 0.3080018239922902, 'Total loss': 0.3080018239922902}
2022-12-31 10:17:28,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:28,444 INFO:     Epoch: 37
2022-12-31 10:17:30,053 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47760841945807136, 'Total loss': 0.47760841945807136} | train loss {'Reaction outcome loss': 0.2996898851750775, 'Total loss': 0.2996898851750775}
2022-12-31 10:17:30,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:30,053 INFO:     Epoch: 38
2022-12-31 10:17:31,681 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5260390857855479, 'Total loss': 0.5260390857855479} | train loss {'Reaction outcome loss': 0.29890521957340654, 'Total loss': 0.29890521957340654}
2022-12-31 10:17:31,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:31,681 INFO:     Epoch: 39
2022-12-31 10:17:33,305 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5382859309514364, 'Total loss': 0.5382859309514364} | train loss {'Reaction outcome loss': 0.29385655101671115, 'Total loss': 0.29385655101671115}
2022-12-31 10:17:33,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:33,306 INFO:     Epoch: 40
2022-12-31 10:17:34,894 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5061818033456802, 'Total loss': 0.5061818033456802} | train loss {'Reaction outcome loss': 0.29306722128434304, 'Total loss': 0.29306722128434304}
2022-12-31 10:17:34,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:34,895 INFO:     Epoch: 41
2022-12-31 10:17:36,536 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.47810264229774474, 'Total loss': 0.47810264229774474} | train loss {'Reaction outcome loss': 0.2895723882833973, 'Total loss': 0.2895723882833973}
2022-12-31 10:17:36,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:36,536 INFO:     Epoch: 42
2022-12-31 10:17:38,143 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.466760927438736, 'Total loss': 0.466760927438736} | train loss {'Reaction outcome loss': 0.2842524904448418, 'Total loss': 0.2842524904448418}
2022-12-31 10:17:38,143 INFO:     Found new best model at epoch 42
2022-12-31 10:17:38,144 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:38,144 INFO:     Epoch: 43
2022-12-31 10:17:39,737 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5421150485674541, 'Total loss': 0.5421150485674541} | train loss {'Reaction outcome loss': 0.27942306034616615, 'Total loss': 0.27942306034616615}
2022-12-31 10:17:39,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:39,738 INFO:     Epoch: 44
2022-12-31 10:17:41,349 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4660654107729594, 'Total loss': 0.4660654107729594} | train loss {'Reaction outcome loss': 0.28357808437158055, 'Total loss': 0.28357808437158055}
2022-12-31 10:17:41,349 INFO:     Found new best model at epoch 44
2022-12-31 10:17:41,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:41,350 INFO:     Epoch: 45
2022-12-31 10:17:42,941 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5255814095338186, 'Total loss': 0.5255814095338186} | train loss {'Reaction outcome loss': 0.2813756517016931, 'Total loss': 0.2813756517016931}
2022-12-31 10:17:42,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:42,941 INFO:     Epoch: 46
2022-12-31 10:17:44,559 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4816189395884673, 'Total loss': 0.4816189395884673} | train loss {'Reaction outcome loss': 0.2748735079521629, 'Total loss': 0.2748735079521629}
2022-12-31 10:17:44,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:44,559 INFO:     Epoch: 47
2022-12-31 10:17:46,176 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5126646776994069, 'Total loss': 0.5126646776994069} | train loss {'Reaction outcome loss': 0.26989174822500034, 'Total loss': 0.26989174822500034}
2022-12-31 10:17:46,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:46,176 INFO:     Epoch: 48
2022-12-31 10:17:47,789 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.49779533545176186, 'Total loss': 0.49779533545176186} | train loss {'Reaction outcome loss': 0.26189485587690714, 'Total loss': 0.26189485587690714}
2022-12-31 10:17:47,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:47,789 INFO:     Epoch: 49
2022-12-31 10:17:49,412 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.48153178493181864, 'Total loss': 0.48153178493181864} | train loss {'Reaction outcome loss': 0.27391069850443933, 'Total loss': 0.27391069850443933}
2022-12-31 10:17:49,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:49,412 INFO:     Epoch: 50
2022-12-31 10:17:51,020 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4964358468850454, 'Total loss': 0.4964358468850454} | train loss {'Reaction outcome loss': 0.26611589998786844, 'Total loss': 0.26611589998786844}
2022-12-31 10:17:51,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:51,020 INFO:     Epoch: 51
2022-12-31 10:17:52,614 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4448384205500285, 'Total loss': 0.4448384205500285} | train loss {'Reaction outcome loss': 0.26404531169615497, 'Total loss': 0.26404531169615497}
2022-12-31 10:17:52,615 INFO:     Found new best model at epoch 51
2022-12-31 10:17:52,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:52,616 INFO:     Epoch: 52
2022-12-31 10:17:54,256 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48984773755073546, 'Total loss': 0.48984773755073546} | train loss {'Reaction outcome loss': 0.265419184825373, 'Total loss': 0.265419184825373}
2022-12-31 10:17:54,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:54,256 INFO:     Epoch: 53
2022-12-31 10:17:55,908 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5041114995876949, 'Total loss': 0.5041114995876949} | train loss {'Reaction outcome loss': 0.2630358999225207, 'Total loss': 0.2630358999225207}
2022-12-31 10:17:55,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:55,908 INFO:     Epoch: 54
2022-12-31 10:17:57,538 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5045386950174967, 'Total loss': 0.5045386950174967} | train loss {'Reaction outcome loss': 0.25158285860658125, 'Total loss': 0.25158285860658125}
2022-12-31 10:17:57,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:57,539 INFO:     Epoch: 55
2022-12-31 10:17:59,150 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5323726902405421, 'Total loss': 0.5323726902405421} | train loss {'Reaction outcome loss': 0.25663647833633296, 'Total loss': 0.25663647833633296}
2022-12-31 10:17:59,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:17:59,150 INFO:     Epoch: 56
2022-12-31 10:18:00,763 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5193923652172089, 'Total loss': 0.5193923652172089} | train loss {'Reaction outcome loss': 0.2528180481818932, 'Total loss': 0.2528180481818932}
2022-12-31 10:18:00,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:00,763 INFO:     Epoch: 57
2022-12-31 10:18:02,394 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.470900171995163, 'Total loss': 0.470900171995163} | train loss {'Reaction outcome loss': 0.25026395352429537, 'Total loss': 0.25026395352429537}
2022-12-31 10:18:02,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:02,394 INFO:     Epoch: 58
2022-12-31 10:18:04,048 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4997347642978032, 'Total loss': 0.4997347642978032} | train loss {'Reaction outcome loss': 0.2498470383834107, 'Total loss': 0.2498470383834107}
2022-12-31 10:18:04,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:04,049 INFO:     Epoch: 59
2022-12-31 10:18:05,670 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.507004960378011, 'Total loss': 0.507004960378011} | train loss {'Reaction outcome loss': 0.24336846372522816, 'Total loss': 0.24336846372522816}
2022-12-31 10:18:05,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:05,670 INFO:     Epoch: 60
2022-12-31 10:18:07,276 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4972022195657094, 'Total loss': 0.4972022195657094} | train loss {'Reaction outcome loss': 0.24865651648451276, 'Total loss': 0.24865651648451276}
2022-12-31 10:18:07,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:07,276 INFO:     Epoch: 61
2022-12-31 10:18:08,895 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47076265811920165, 'Total loss': 0.47076265811920165} | train loss {'Reaction outcome loss': 0.24660208092377073, 'Total loss': 0.24660208092377073}
2022-12-31 10:18:08,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:08,895 INFO:     Epoch: 62
2022-12-31 10:18:10,514 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.54577134847641, 'Total loss': 0.54577134847641} | train loss {'Reaction outcome loss': 0.23628252662637603, 'Total loss': 0.23628252662637603}
2022-12-31 10:18:10,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:10,514 INFO:     Epoch: 63
2022-12-31 10:18:12,133 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4920036186774572, 'Total loss': 0.4920036186774572} | train loss {'Reaction outcome loss': 0.2360323694692622, 'Total loss': 0.2360323694692622}
2022-12-31 10:18:12,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:12,133 INFO:     Epoch: 64
2022-12-31 10:18:13,751 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5333914041519165, 'Total loss': 0.5333914041519165} | train loss {'Reaction outcome loss': 0.24285037370418813, 'Total loss': 0.24285037370418813}
2022-12-31 10:18:13,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:13,752 INFO:     Epoch: 65
2022-12-31 10:18:15,362 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4518405963977178, 'Total loss': 0.4518405963977178} | train loss {'Reaction outcome loss': 0.24219414295917813, 'Total loss': 0.24219414295917813}
2022-12-31 10:18:15,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:15,362 INFO:     Epoch: 66
2022-12-31 10:18:16,962 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5063126683235168, 'Total loss': 0.5063126683235168} | train loss {'Reaction outcome loss': 0.23983420371094766, 'Total loss': 0.23983420371094766}
2022-12-31 10:18:16,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:16,963 INFO:     Epoch: 67
2022-12-31 10:18:18,582 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.493979016939799, 'Total loss': 0.493979016939799} | train loss {'Reaction outcome loss': 0.22946228423165932, 'Total loss': 0.22946228423165932}
2022-12-31 10:18:18,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:18,582 INFO:     Epoch: 68
2022-12-31 10:18:20,193 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49550239245096844, 'Total loss': 0.49550239245096844} | train loss {'Reaction outcome loss': 0.2315556284120905, 'Total loss': 0.2315556284120905}
2022-12-31 10:18:20,193 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:20,194 INFO:     Epoch: 69
2022-12-31 10:18:21,816 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4802686373392741, 'Total loss': 0.4802686373392741} | train loss {'Reaction outcome loss': 0.24346833179842695, 'Total loss': 0.24346833179842695}
2022-12-31 10:18:21,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:21,816 INFO:     Epoch: 70
2022-12-31 10:18:23,433 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4776412844657898, 'Total loss': 0.4776412844657898} | train loss {'Reaction outcome loss': 0.22614981405208365, 'Total loss': 0.22614981405208365}
2022-12-31 10:18:23,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:23,434 INFO:     Epoch: 71
2022-12-31 10:18:25,031 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4699363629023234, 'Total loss': 0.4699363629023234} | train loss {'Reaction outcome loss': 0.22855530224659812, 'Total loss': 0.22855530224659812}
2022-12-31 10:18:25,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:25,032 INFO:     Epoch: 72
2022-12-31 10:18:26,648 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5267946263154347, 'Total loss': 0.5267946263154347} | train loss {'Reaction outcome loss': 0.22872240481299722, 'Total loss': 0.22872240481299722}
2022-12-31 10:18:26,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:26,648 INFO:     Epoch: 73
2022-12-31 10:18:28,247 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4857284645239512, 'Total loss': 0.4857284645239512} | train loss {'Reaction outcome loss': 0.22268678276339002, 'Total loss': 0.22268678276339002}
2022-12-31 10:18:28,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:28,247 INFO:     Epoch: 74
2022-12-31 10:18:29,865 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4717019647359848, 'Total loss': 0.4717019647359848} | train loss {'Reaction outcome loss': 0.22266162834416012, 'Total loss': 0.22266162834416012}
2022-12-31 10:18:29,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:29,866 INFO:     Epoch: 75
2022-12-31 10:18:31,483 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4749452273050944, 'Total loss': 0.4749452273050944} | train loss {'Reaction outcome loss': 0.2177789806647206, 'Total loss': 0.2177789806647206}
2022-12-31 10:18:31,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:31,484 INFO:     Epoch: 76
2022-12-31 10:18:33,100 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.49694031377633413, 'Total loss': 0.49694031377633413} | train loss {'Reaction outcome loss': 0.219184661512717, 'Total loss': 0.219184661512717}
2022-12-31 10:18:33,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:33,101 INFO:     Epoch: 77
2022-12-31 10:18:34,732 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5401230295499165, 'Total loss': 0.5401230295499165} | train loss {'Reaction outcome loss': 0.2187589855884817, 'Total loss': 0.2187589855884817}
2022-12-31 10:18:34,732 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:34,732 INFO:     Epoch: 78
2022-12-31 10:18:36,401 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5482869525750478, 'Total loss': 0.5482869525750478} | train loss {'Reaction outcome loss': 0.2178803532710467, 'Total loss': 0.2178803532710467}
2022-12-31 10:18:36,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:36,401 INFO:     Epoch: 79
2022-12-31 10:18:38,007 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47842079401016235, 'Total loss': 0.47842079401016235} | train loss {'Reaction outcome loss': 0.22024064854338818, 'Total loss': 0.22024064854338818}
2022-12-31 10:18:38,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:38,007 INFO:     Epoch: 80
2022-12-31 10:18:39,627 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4427030816674232, 'Total loss': 0.4427030816674232} | train loss {'Reaction outcome loss': 0.2120394181016335, 'Total loss': 0.2120394181016335}
2022-12-31 10:18:39,628 INFO:     Found new best model at epoch 80
2022-12-31 10:18:39,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:39,629 INFO:     Epoch: 81
2022-12-31 10:18:41,245 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.537270184357961, 'Total loss': 0.537270184357961} | train loss {'Reaction outcome loss': 0.2122581522602467, 'Total loss': 0.2122581522602467}
2022-12-31 10:18:41,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:41,245 INFO:     Epoch: 82
2022-12-31 10:18:42,845 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4774872461954753, 'Total loss': 0.4774872461954753} | train loss {'Reaction outcome loss': 0.22062727835849735, 'Total loss': 0.22062727835849735}
2022-12-31 10:18:42,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:42,845 INFO:     Epoch: 83
2022-12-31 10:18:44,464 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5166774133841197, 'Total loss': 0.5166774133841197} | train loss {'Reaction outcome loss': 0.2109652021395493, 'Total loss': 0.2109652021395493}
2022-12-31 10:18:44,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:44,464 INFO:     Epoch: 84
2022-12-31 10:18:46,069 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4796956926584244, 'Total loss': 0.4796956926584244} | train loss {'Reaction outcome loss': 0.21005353933395246, 'Total loss': 0.21005353933395246}
2022-12-31 10:18:46,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:46,070 INFO:     Epoch: 85
2022-12-31 10:18:47,721 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.47302392224470774, 'Total loss': 0.47302392224470774} | train loss {'Reaction outcome loss': 0.20887319435658008, 'Total loss': 0.20887319435658008}
2022-12-31 10:18:47,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:47,722 INFO:     Epoch: 86
2022-12-31 10:18:49,360 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45727916061878204, 'Total loss': 0.45727916061878204} | train loss {'Reaction outcome loss': 0.20885730066104702, 'Total loss': 0.20885730066104702}
2022-12-31 10:18:49,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:49,360 INFO:     Epoch: 87
2022-12-31 10:18:50,972 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47036420131723083, 'Total loss': 0.47036420131723083} | train loss {'Reaction outcome loss': 0.21109612709893055, 'Total loss': 0.21109612709893055}
2022-12-31 10:18:50,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:50,972 INFO:     Epoch: 88
2022-12-31 10:18:52,574 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4986783047517141, 'Total loss': 0.4986783047517141} | train loss {'Reaction outcome loss': 0.21245316556227875, 'Total loss': 0.21245316556227875}
2022-12-31 10:18:52,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:52,574 INFO:     Epoch: 89
2022-12-31 10:18:54,244 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5353414724270503, 'Total loss': 0.5353414724270503} | train loss {'Reaction outcome loss': 0.20468544460738933, 'Total loss': 0.20468544460738933}
2022-12-31 10:18:54,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:54,244 INFO:     Epoch: 90
2022-12-31 10:18:55,864 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.491289429863294, 'Total loss': 0.491289429863294} | train loss {'Reaction outcome loss': 0.2102876713748228, 'Total loss': 0.2102876713748228}
2022-12-31 10:18:55,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:55,864 INFO:     Epoch: 91
2022-12-31 10:18:57,477 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46110126078128816, 'Total loss': 0.46110126078128816} | train loss {'Reaction outcome loss': 0.21222201373011196, 'Total loss': 0.21222201373011196}
2022-12-31 10:18:57,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:57,477 INFO:     Epoch: 92
2022-12-31 10:18:59,092 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4856751670440038, 'Total loss': 0.4856751670440038} | train loss {'Reaction outcome loss': 0.20556598487192435, 'Total loss': 0.20556598487192435}
2022-12-31 10:18:59,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:18:59,092 INFO:     Epoch: 93
2022-12-31 10:19:00,696 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4733231276273727, 'Total loss': 0.4733231276273727} | train loss {'Reaction outcome loss': 0.2048457221595389, 'Total loss': 0.2048457221595389}
2022-12-31 10:19:00,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:00,696 INFO:     Epoch: 94
2022-12-31 10:19:02,303 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4741747409105301, 'Total loss': 0.4741747409105301} | train loss {'Reaction outcome loss': 0.20329083653590524, 'Total loss': 0.20329083653590524}
2022-12-31 10:19:02,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:02,304 INFO:     Epoch: 95
2022-12-31 10:19:03,920 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.519691667954127, 'Total loss': 0.519691667954127} | train loss {'Reaction outcome loss': 0.2013188224514469, 'Total loss': 0.2013188224514469}
2022-12-31 10:19:03,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:03,920 INFO:     Epoch: 96
2022-12-31 10:19:05,515 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48090420216321944, 'Total loss': 0.48090420216321944} | train loss {'Reaction outcome loss': 0.20541046684883563, 'Total loss': 0.20541046684883563}
2022-12-31 10:19:05,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:05,516 INFO:     Epoch: 97
2022-12-31 10:19:07,132 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.598875246445338, 'Total loss': 0.598875246445338} | train loss {'Reaction outcome loss': 0.2073193681476779, 'Total loss': 0.2073193681476779}
2022-12-31 10:19:07,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:07,132 INFO:     Epoch: 98
2022-12-31 10:19:08,748 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.49777931968371075, 'Total loss': 0.49777931968371075} | train loss {'Reaction outcome loss': 0.20811126974918998, 'Total loss': 0.20811126974918998}
2022-12-31 10:19:08,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:08,749 INFO:     Epoch: 99
2022-12-31 10:19:10,347 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.46195583244164784, 'Total loss': 0.46195583244164784} | train loss {'Reaction outcome loss': 0.20225554894965264, 'Total loss': 0.20225554894965264}
2022-12-31 10:19:10,347 INFO:     Best model found after epoch 81 of 100.
2022-12-31 10:19:10,347 INFO:   Done with stage: TRAINING
2022-12-31 10:19:10,347 INFO:   Starting stage: EVALUATION
2022-12-31 10:19:10,469 INFO:   Done with stage: EVALUATION
2022-12-31 10:19:10,469 INFO:   Leaving out SEQ value Fold_8
2022-12-31 10:19:10,481 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 10:19:10,481 INFO:   Starting stage: FEATURE SCALING
2022-12-31 10:19:11,123 INFO:   Done with stage: FEATURE SCALING
2022-12-31 10:19:11,123 INFO:   Starting stage: SCALING TARGETS
2022-12-31 10:19:11,193 INFO:   Done with stage: SCALING TARGETS
2022-12-31 10:19:11,193 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:19:11,193 INFO:     No hyperparam tuning for this model
2022-12-31 10:19:11,193 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:19:11,193 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 10:19:11,194 INFO:     None feature selector for col prot
2022-12-31 10:19:11,194 INFO:     None feature selector for col prot
2022-12-31 10:19:11,194 INFO:     None feature selector for col prot
2022-12-31 10:19:11,195 INFO:     None feature selector for col chem
2022-12-31 10:19:11,195 INFO:     None feature selector for col chem
2022-12-31 10:19:11,195 INFO:     None feature selector for col chem
2022-12-31 10:19:11,195 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 10:19:11,195 INFO:   Starting stage: BUILD MODEL
2022-12-31 10:19:11,197 INFO:     Number of params in model 223921
2022-12-31 10:19:11,200 INFO:   Done with stage: BUILD MODEL
2022-12-31 10:19:11,200 INFO:   Starting stage: TRAINING
2022-12-31 10:19:11,246 INFO:     Val loss before train {'Reaction outcome loss': 1.0520336290200551, 'Total loss': 1.0520336290200551}
2022-12-31 10:19:11,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:11,246 INFO:     Epoch: 0
2022-12-31 10:19:12,846 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7118243376413981, 'Total loss': 0.7118243376413981} | train loss {'Reaction outcome loss': 0.793419554220526, 'Total loss': 0.793419554220526}
2022-12-31 10:19:12,846 INFO:     Found new best model at epoch 0
2022-12-31 10:19:12,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:12,847 INFO:     Epoch: 1
2022-12-31 10:19:14,462 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5989281555016835, 'Total loss': 0.5989281555016835} | train loss {'Reaction outcome loss': 0.5760213095413154, 'Total loss': 0.5760213095413154}
2022-12-31 10:19:14,462 INFO:     Found new best model at epoch 1
2022-12-31 10:19:14,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:14,463 INFO:     Epoch: 2
2022-12-31 10:19:16,070 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5674919644991557, 'Total loss': 0.5674919644991557} | train loss {'Reaction outcome loss': 0.5193220064587271, 'Total loss': 0.5193220064587271}
2022-12-31 10:19:16,070 INFO:     Found new best model at epoch 2
2022-12-31 10:19:16,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:16,071 INFO:     Epoch: 3
2022-12-31 10:19:17,678 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5799978295962016, 'Total loss': 0.5799978295962016} | train loss {'Reaction outcome loss': 0.5003078381760396, 'Total loss': 0.5003078381760396}
2022-12-31 10:19:17,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:17,678 INFO:     Epoch: 4
2022-12-31 10:19:19,283 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5468669533729553, 'Total loss': 0.5468669533729553} | train loss {'Reaction outcome loss': 0.49628637646632, 'Total loss': 0.49628637646632}
2022-12-31 10:19:19,283 INFO:     Found new best model at epoch 4
2022-12-31 10:19:19,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:19,284 INFO:     Epoch: 5
2022-12-31 10:19:20,936 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5606984247763952, 'Total loss': 0.5606984247763952} | train loss {'Reaction outcome loss': 0.4732279825976363, 'Total loss': 0.4732279825976363}
2022-12-31 10:19:20,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:20,936 INFO:     Epoch: 6
2022-12-31 10:19:22,554 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5298297186692555, 'Total loss': 0.5298297186692555} | train loss {'Reaction outcome loss': 0.46357942403288244, 'Total loss': 0.46357942403288244}
2022-12-31 10:19:22,555 INFO:     Found new best model at epoch 6
2022-12-31 10:19:22,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:22,555 INFO:     Epoch: 7
2022-12-31 10:19:24,163 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5453545212745666, 'Total loss': 0.5453545212745666} | train loss {'Reaction outcome loss': 0.45924292410305445, 'Total loss': 0.45924292410305445}
2022-12-31 10:19:24,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:24,163 INFO:     Epoch: 8
2022-12-31 10:19:25,772 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5095325003067652, 'Total loss': 0.5095325003067652} | train loss {'Reaction outcome loss': 0.4734495149366895, 'Total loss': 0.4734495149366895}
2022-12-31 10:19:25,772 INFO:     Found new best model at epoch 8
2022-12-31 10:19:25,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:25,773 INFO:     Epoch: 9
2022-12-31 10:19:27,381 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.544291889667511, 'Total loss': 0.544291889667511} | train loss {'Reaction outcome loss': 0.45158536991347437, 'Total loss': 0.45158536991347437}
2022-12-31 10:19:27,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:27,381 INFO:     Epoch: 10
2022-12-31 10:19:28,973 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5297167162100475, 'Total loss': 0.5297167162100475} | train loss {'Reaction outcome loss': 0.4570235056343718, 'Total loss': 0.4570235056343718}
2022-12-31 10:19:28,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:28,974 INFO:     Epoch: 11
2022-12-31 10:19:30,582 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5103793472051621, 'Total loss': 0.5103793472051621} | train loss {'Reaction outcome loss': 0.4359641152437768, 'Total loss': 0.4359641152437768}
2022-12-31 10:19:30,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:30,582 INFO:     Epoch: 12
2022-12-31 10:19:32,178 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5168084998925527, 'Total loss': 0.5168084998925527} | train loss {'Reaction outcome loss': 0.42478530903252354, 'Total loss': 0.42478530903252354}
2022-12-31 10:19:32,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:32,178 INFO:     Epoch: 13
2022-12-31 10:19:33,786 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.570642230908076, 'Total loss': 0.570642230908076} | train loss {'Reaction outcome loss': 0.421151062202019, 'Total loss': 0.421151062202019}
2022-12-31 10:19:33,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:33,787 INFO:     Epoch: 14
2022-12-31 10:19:35,396 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5144305159648259, 'Total loss': 0.5144305159648259} | train loss {'Reaction outcome loss': 0.41686496189170336, 'Total loss': 0.41686496189170336}
2022-12-31 10:19:35,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:35,396 INFO:     Epoch: 15
2022-12-31 10:19:36,981 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5427856624126435, 'Total loss': 0.5427856624126435} | train loss {'Reaction outcome loss': 0.4107946311306623, 'Total loss': 0.4107946311306623}
2022-12-31 10:19:36,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:36,982 INFO:     Epoch: 16
2022-12-31 10:19:38,591 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5126775622367858, 'Total loss': 0.5126775622367858} | train loss {'Reaction outcome loss': 0.4092270779807586, 'Total loss': 0.4092270779807586}
2022-12-31 10:19:38,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:38,593 INFO:     Epoch: 17
2022-12-31 10:19:40,185 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.48672624826431277, 'Total loss': 0.48672624826431277} | train loss {'Reaction outcome loss': 0.4020370439579036, 'Total loss': 0.4020370439579036}
2022-12-31 10:19:40,185 INFO:     Found new best model at epoch 17
2022-12-31 10:19:40,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:40,186 INFO:     Epoch: 18
2022-12-31 10:19:41,792 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4943475107351939, 'Total loss': 0.4943475107351939} | train loss {'Reaction outcome loss': 0.3936380567393971, 'Total loss': 0.3936380567393971}
2022-12-31 10:19:41,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:41,793 INFO:     Epoch: 19
2022-12-31 10:19:43,401 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.531930673122406, 'Total loss': 0.531930673122406} | train loss {'Reaction outcome loss': 0.3859023917567633, 'Total loss': 0.3859023917567633}
2022-12-31 10:19:43,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:43,401 INFO:     Epoch: 20
2022-12-31 10:19:45,010 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.505941042304039, 'Total loss': 0.505941042304039} | train loss {'Reaction outcome loss': 0.3892274678418935, 'Total loss': 0.3892274678418935}
2022-12-31 10:19:45,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:45,011 INFO:     Epoch: 21
2022-12-31 10:19:46,605 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5409425258636474, 'Total loss': 0.5409425258636474} | train loss {'Reaction outcome loss': 0.3776178469939834, 'Total loss': 0.3776178469939834}
2022-12-31 10:19:46,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:46,605 INFO:     Epoch: 22
2022-12-31 10:19:48,250 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.48745910127957665, 'Total loss': 0.48745910127957665} | train loss {'Reaction outcome loss': 0.37088212488215766, 'Total loss': 0.37088212488215766}
2022-12-31 10:19:48,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:48,251 INFO:     Epoch: 23
2022-12-31 10:19:49,848 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.48567707737286886, 'Total loss': 0.48567707737286886} | train loss {'Reaction outcome loss': 0.3665489521134051, 'Total loss': 0.3665489521134051}
2022-12-31 10:19:49,848 INFO:     Found new best model at epoch 23
2022-12-31 10:19:49,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:49,849 INFO:     Epoch: 24
2022-12-31 10:19:51,453 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47846561670303345, 'Total loss': 0.47846561670303345} | train loss {'Reaction outcome loss': 0.35606063408372196, 'Total loss': 0.35606063408372196}
2022-12-31 10:19:51,453 INFO:     Found new best model at epoch 24
2022-12-31 10:19:51,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:51,455 INFO:     Epoch: 25
2022-12-31 10:19:53,059 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49190073112646737, 'Total loss': 0.49190073112646737} | train loss {'Reaction outcome loss': 0.35669208775853156, 'Total loss': 0.35669208775853156}
2022-12-31 10:19:53,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:53,060 INFO:     Epoch: 26
2022-12-31 10:19:54,656 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4846742391586304, 'Total loss': 0.4846742391586304} | train loss {'Reaction outcome loss': 0.35198062920666207, 'Total loss': 0.35198062920666207}
2022-12-31 10:19:54,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:54,657 INFO:     Epoch: 27
2022-12-31 10:19:56,251 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4918495625257492, 'Total loss': 0.4918495625257492} | train loss {'Reaction outcome loss': 0.3444079023455202, 'Total loss': 0.3444079023455202}
2022-12-31 10:19:56,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:56,251 INFO:     Epoch: 28
2022-12-31 10:19:57,852 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46378066142400104, 'Total loss': 0.46378066142400104} | train loss {'Reaction outcome loss': 0.34067347050354263, 'Total loss': 0.34067347050354263}
2022-12-31 10:19:57,853 INFO:     Found new best model at epoch 28
2022-12-31 10:19:57,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:57,854 INFO:     Epoch: 29
2022-12-31 10:19:59,483 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4901698817809423, 'Total loss': 0.4901698817809423} | train loss {'Reaction outcome loss': 0.3276795602734268, 'Total loss': 0.3276795602734268}
2022-12-31 10:19:59,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:19:59,483 INFO:     Epoch: 30
2022-12-31 10:20:01,124 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.49811049103736876, 'Total loss': 0.49811049103736876} | train loss {'Reaction outcome loss': 0.3300095805493386, 'Total loss': 0.3300095805493386}
2022-12-31 10:20:01,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:01,124 INFO:     Epoch: 31
2022-12-31 10:20:02,732 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44066705405712125, 'Total loss': 0.44066705405712125} | train loss {'Reaction outcome loss': 0.33273998174168495, 'Total loss': 0.33273998174168495}
2022-12-31 10:20:02,732 INFO:     Found new best model at epoch 31
2022-12-31 10:20:02,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:02,733 INFO:     Epoch: 32
2022-12-31 10:20:04,326 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4376235634088516, 'Total loss': 0.4376235634088516} | train loss {'Reaction outcome loss': 0.3215461474661108, 'Total loss': 0.3215461474661108}
2022-12-31 10:20:04,326 INFO:     Found new best model at epoch 32
2022-12-31 10:20:04,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:04,327 INFO:     Epoch: 33
2022-12-31 10:20:05,934 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4518856078386307, 'Total loss': 0.4518856078386307} | train loss {'Reaction outcome loss': 0.3205746780217126, 'Total loss': 0.3205746780217126}
2022-12-31 10:20:05,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:05,934 INFO:     Epoch: 34
2022-12-31 10:20:07,527 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4526121556758881, 'Total loss': 0.4526121556758881} | train loss {'Reaction outcome loss': 0.31382119847947487, 'Total loss': 0.31382119847947487}
2022-12-31 10:20:07,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:07,527 INFO:     Epoch: 35
2022-12-31 10:20:09,174 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4731701374053955, 'Total loss': 0.4731701374053955} | train loss {'Reaction outcome loss': 0.3046177695127551, 'Total loss': 0.3046177695127551}
2022-12-31 10:20:09,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:09,174 INFO:     Epoch: 36
2022-12-31 10:20:10,833 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5106396754582723, 'Total loss': 0.5106396754582723} | train loss {'Reaction outcome loss': 0.3032928502888999, 'Total loss': 0.3032928502888999}
2022-12-31 10:20:10,834 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:10,834 INFO:     Epoch: 37
2022-12-31 10:20:12,442 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4792583495378494, 'Total loss': 0.4792583495378494} | train loss {'Reaction outcome loss': 0.30969022821796977, 'Total loss': 0.30969022821796977}
2022-12-31 10:20:12,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:12,442 INFO:     Epoch: 38
2022-12-31 10:20:13,658 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4619718035062154, 'Total loss': 0.4619718035062154} | train loss {'Reaction outcome loss': 0.3099035644174918, 'Total loss': 0.3099035644174918}
2022-12-31 10:20:13,658 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:13,658 INFO:     Epoch: 39
2022-12-31 10:20:14,735 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44301847616831463, 'Total loss': 0.44301847616831463} | train loss {'Reaction outcome loss': 0.2934881520535176, 'Total loss': 0.2934881520535176}
2022-12-31 10:20:14,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:14,737 INFO:     Epoch: 40
2022-12-31 10:20:15,825 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.440712304910024, 'Total loss': 0.440712304910024} | train loss {'Reaction outcome loss': 0.2900055172887479, 'Total loss': 0.2900055172887479}
2022-12-31 10:20:15,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:15,826 INFO:     Epoch: 41
2022-12-31 10:20:16,896 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43501296440760295, 'Total loss': 0.43501296440760295} | train loss {'Reaction outcome loss': 0.2914287034908067, 'Total loss': 0.2914287034908067}
2022-12-31 10:20:16,896 INFO:     Found new best model at epoch 41
2022-12-31 10:20:16,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:16,897 INFO:     Epoch: 42
2022-12-31 10:20:18,241 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4938648482163747, 'Total loss': 0.4938648482163747} | train loss {'Reaction outcome loss': 0.31297992809972575, 'Total loss': 0.31297992809972575}
2022-12-31 10:20:18,241 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:18,241 INFO:     Epoch: 43
2022-12-31 10:20:19,856 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4393432170152664, 'Total loss': 0.4393432170152664} | train loss {'Reaction outcome loss': 0.2899393906524062, 'Total loss': 0.2899393906524062}
2022-12-31 10:20:19,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:19,857 INFO:     Epoch: 44
2022-12-31 10:20:21,477 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44429547488689425, 'Total loss': 0.44429547488689425} | train loss {'Reaction outcome loss': 0.28203143641028716, 'Total loss': 0.28203143641028716}
2022-12-31 10:20:21,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:21,478 INFO:     Epoch: 45
2022-12-31 10:20:23,092 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.49788176516691846, 'Total loss': 0.49788176516691846} | train loss {'Reaction outcome loss': 0.3058616280120433, 'Total loss': 0.3058616280120433}
2022-12-31 10:20:23,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:23,092 INFO:     Epoch: 46
2022-12-31 10:20:24,753 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.49988606870174407, 'Total loss': 0.49988606870174407} | train loss {'Reaction outcome loss': 0.28608989424394854, 'Total loss': 0.28608989424394854}
2022-12-31 10:20:24,753 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:24,753 INFO:     Epoch: 47
2022-12-31 10:20:26,398 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4635458141565323, 'Total loss': 0.4635458141565323} | train loss {'Reaction outcome loss': 0.28075972316698916, 'Total loss': 0.28075972316698916}
2022-12-31 10:20:26,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:26,398 INFO:     Epoch: 48
2022-12-31 10:20:28,020 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4252397954463959, 'Total loss': 0.4252397954463959} | train loss {'Reaction outcome loss': 0.2773000425642248, 'Total loss': 0.2773000425642248}
2022-12-31 10:20:28,020 INFO:     Found new best model at epoch 48
2022-12-31 10:20:28,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:28,021 INFO:     Epoch: 49
2022-12-31 10:20:29,633 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4337625324726105, 'Total loss': 0.4337625324726105} | train loss {'Reaction outcome loss': 0.2784900046898511, 'Total loss': 0.2784900046898511}
2022-12-31 10:20:29,633 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:29,633 INFO:     Epoch: 50
2022-12-31 10:20:31,247 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44559807479381563, 'Total loss': 0.44559807479381563} | train loss {'Reaction outcome loss': 0.2722733780833221, 'Total loss': 0.2722733780833221}
2022-12-31 10:20:31,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:31,247 INFO:     Epoch: 51
2022-12-31 10:20:32,838 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41439266204833985, 'Total loss': 0.41439266204833985} | train loss {'Reaction outcome loss': 0.27126012296430846, 'Total loss': 0.27126012296430846}
2022-12-31 10:20:32,839 INFO:     Found new best model at epoch 51
2022-12-31 10:20:32,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:32,839 INFO:     Epoch: 52
2022-12-31 10:20:34,447 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46920403639475505, 'Total loss': 0.46920403639475505} | train loss {'Reaction outcome loss': 0.27449337254438433, 'Total loss': 0.27449337254438433}
2022-12-31 10:20:34,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:34,448 INFO:     Epoch: 53
2022-12-31 10:20:36,037 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42652755479017895, 'Total loss': 0.42652755479017895} | train loss {'Reaction outcome loss': 0.26879679005377105, 'Total loss': 0.26879679005377105}
2022-12-31 10:20:36,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:36,037 INFO:     Epoch: 54
2022-12-31 10:20:37,657 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4265543093283971, 'Total loss': 0.4265543093283971} | train loss {'Reaction outcome loss': 0.29925175204171217, 'Total loss': 0.29925175204171217}
2022-12-31 10:20:37,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:37,657 INFO:     Epoch: 55
2022-12-31 10:20:39,264 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5148779342571894, 'Total loss': 0.5148779342571894} | train loss {'Reaction outcome loss': 0.3306005763132935, 'Total loss': 0.3306005763132935}
2022-12-31 10:20:39,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:39,264 INFO:     Epoch: 56
2022-12-31 10:20:40,864 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4746377199888229, 'Total loss': 0.4746377199888229} | train loss {'Reaction outcome loss': 0.30087341432986053, 'Total loss': 0.30087341432986053}
2022-12-31 10:20:40,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:40,864 INFO:     Epoch: 57
2022-12-31 10:20:42,454 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4213918606440226, 'Total loss': 0.4213918606440226} | train loss {'Reaction outcome loss': 0.27008966722971073, 'Total loss': 0.27008966722971073}
2022-12-31 10:20:42,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:42,454 INFO:     Epoch: 58
2022-12-31 10:20:44,039 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42255498965581256, 'Total loss': 0.42255498965581256} | train loss {'Reaction outcome loss': 0.26016496306671627, 'Total loss': 0.26016496306671627}
2022-12-31 10:20:44,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:44,039 INFO:     Epoch: 59
2022-12-31 10:20:45,667 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4724512214461962, 'Total loss': 0.4724512214461962} | train loss {'Reaction outcome loss': 0.2541408845614912, 'Total loss': 0.2541408845614912}
2022-12-31 10:20:45,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:45,667 INFO:     Epoch: 60
2022-12-31 10:20:47,247 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.502706891298294, 'Total loss': 0.502706891298294} | train loss {'Reaction outcome loss': 0.28455600982019, 'Total loss': 0.28455600982019}
2022-12-31 10:20:47,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:47,247 INFO:     Epoch: 61
2022-12-31 10:20:48,894 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40077332258224485, 'Total loss': 0.40077332258224485} | train loss {'Reaction outcome loss': 0.27196371292550303, 'Total loss': 0.27196371292550303}
2022-12-31 10:20:48,894 INFO:     Found new best model at epoch 61
2022-12-31 10:20:48,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:48,895 INFO:     Epoch: 62
2022-12-31 10:20:50,474 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4592814753452937, 'Total loss': 0.4592814753452937} | train loss {'Reaction outcome loss': 0.2494108463005419, 'Total loss': 0.2494108463005419}
2022-12-31 10:20:50,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:50,475 INFO:     Epoch: 63
2022-12-31 10:20:52,085 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4347076117992401, 'Total loss': 0.4347076117992401} | train loss {'Reaction outcome loss': 0.25039141865420167, 'Total loss': 0.25039141865420167}
2022-12-31 10:20:52,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:52,085 INFO:     Epoch: 64
2022-12-31 10:20:53,684 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4715391417344411, 'Total loss': 0.4715391417344411} | train loss {'Reaction outcome loss': 0.26652852224483004, 'Total loss': 0.26652852224483004}
2022-12-31 10:20:53,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:53,684 INFO:     Epoch: 65
2022-12-31 10:20:55,331 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44290899435679115, 'Total loss': 0.44290899435679115} | train loss {'Reaction outcome loss': 0.2518791080261851, 'Total loss': 0.2518791080261851}
2022-12-31 10:20:55,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:55,331 INFO:     Epoch: 66
2022-12-31 10:20:56,966 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48958747188250223, 'Total loss': 0.48958747188250223} | train loss {'Reaction outcome loss': 0.25477537784077553, 'Total loss': 0.25477537784077553}
2022-12-31 10:20:56,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:56,967 INFO:     Epoch: 67
2022-12-31 10:20:58,582 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5217363953590393, 'Total loss': 0.5217363953590393} | train loss {'Reaction outcome loss': 0.3618003205274758, 'Total loss': 0.3618003205274758}
2022-12-31 10:20:58,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:20:58,582 INFO:     Epoch: 68
2022-12-31 10:21:00,183 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5246968845526377, 'Total loss': 0.5246968845526377} | train loss {'Reaction outcome loss': 0.33143194229342043, 'Total loss': 0.33143194229342043}
2022-12-31 10:21:00,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:00,183 INFO:     Epoch: 69
2022-12-31 10:21:01,794 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5176902661720911, 'Total loss': 0.5176902661720911} | train loss {'Reaction outcome loss': 0.28470348813436064, 'Total loss': 0.28470348813436064}
2022-12-31 10:21:01,794 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:01,794 INFO:     Epoch: 70
2022-12-31 10:21:03,399 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45126690963904065, 'Total loss': 0.45126690963904065} | train loss {'Reaction outcome loss': 0.27363321473492996, 'Total loss': 0.27363321473492996}
2022-12-31 10:21:03,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:03,399 INFO:     Epoch: 71
2022-12-31 10:21:05,035 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.474418643116951, 'Total loss': 0.474418643116951} | train loss {'Reaction outcome loss': 0.2618515614312196, 'Total loss': 0.2618515614312196}
2022-12-31 10:21:05,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:05,036 INFO:     Epoch: 72
2022-12-31 10:21:06,662 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.48392400542895, 'Total loss': 0.48392400542895} | train loss {'Reaction outcome loss': 0.2792621110363499, 'Total loss': 0.2792621110363499}
2022-12-31 10:21:06,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:06,662 INFO:     Epoch: 73
2022-12-31 10:21:08,264 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4451021492481232, 'Total loss': 0.4451021492481232} | train loss {'Reaction outcome loss': 0.2975728951012939, 'Total loss': 0.2975728951012939}
2022-12-31 10:21:08,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:08,264 INFO:     Epoch: 74
2022-12-31 10:21:09,906 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46156655450661976, 'Total loss': 0.46156655450661976} | train loss {'Reaction outcome loss': 0.2583427934407972, 'Total loss': 0.2583427934407972}
2022-12-31 10:21:09,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:09,906 INFO:     Epoch: 75
2022-12-31 10:21:11,568 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4965325007836024, 'Total loss': 0.4965325007836024} | train loss {'Reaction outcome loss': 0.2885542031009749, 'Total loss': 0.2885542031009749}
2022-12-31 10:21:11,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:11,568 INFO:     Epoch: 76
2022-12-31 10:21:13,165 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43082843025525414, 'Total loss': 0.43082843025525414} | train loss {'Reaction outcome loss': 0.25724020438349765, 'Total loss': 0.25724020438349765}
2022-12-31 10:21:13,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:13,165 INFO:     Epoch: 77
2022-12-31 10:21:14,779 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42412697871526084, 'Total loss': 0.42412697871526084} | train loss {'Reaction outcome loss': 0.2712296168140618, 'Total loss': 0.2712296168140618}
2022-12-31 10:21:14,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:14,779 INFO:     Epoch: 78
2022-12-31 10:21:16,394 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4237246334552765, 'Total loss': 0.4237246334552765} | train loss {'Reaction outcome loss': 0.250128621586423, 'Total loss': 0.250128621586423}
2022-12-31 10:21:16,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:16,394 INFO:     Epoch: 79
2022-12-31 10:21:18,004 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44068430463473, 'Total loss': 0.44068430463473} | train loss {'Reaction outcome loss': 0.23674905380492262, 'Total loss': 0.23674905380492262}
2022-12-31 10:21:18,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:18,005 INFO:     Epoch: 80
2022-12-31 10:21:19,632 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45551077524820965, 'Total loss': 0.45551077524820965} | train loss {'Reaction outcome loss': 0.2357173151728036, 'Total loss': 0.2357173151728036}
2022-12-31 10:21:19,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:19,632 INFO:     Epoch: 81
2022-12-31 10:21:21,222 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40869831244150795, 'Total loss': 0.40869831244150795} | train loss {'Reaction outcome loss': 0.2389530010852099, 'Total loss': 0.2389530010852099}
2022-12-31 10:21:21,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:21,223 INFO:     Epoch: 82
2022-12-31 10:21:22,856 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.431700266400973, 'Total loss': 0.431700266400973} | train loss {'Reaction outcome loss': 0.2345388899894728, 'Total loss': 0.2345388899894728}
2022-12-31 10:21:22,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:22,856 INFO:     Epoch: 83
2022-12-31 10:21:24,469 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43095476627349855, 'Total loss': 0.43095476627349855} | train loss {'Reaction outcome loss': 0.2514759468708096, 'Total loss': 0.2514759468708096}
2022-12-31 10:21:24,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:24,470 INFO:     Epoch: 84
2022-12-31 10:21:26,077 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4505094766616821, 'Total loss': 0.4505094766616821} | train loss {'Reaction outcome loss': 0.23122427860052203, 'Total loss': 0.23122427860052203}
2022-12-31 10:21:26,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:26,077 INFO:     Epoch: 85
2022-12-31 10:21:27,683 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44218009784817697, 'Total loss': 0.44218009784817697} | train loss {'Reaction outcome loss': 0.23360869914809565, 'Total loss': 0.23360869914809565}
2022-12-31 10:21:27,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:27,684 INFO:     Epoch: 86
2022-12-31 10:21:29,298 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4665648142496745, 'Total loss': 0.4665648142496745} | train loss {'Reaction outcome loss': 0.2316133847200325, 'Total loss': 0.2316133847200325}
2022-12-31 10:21:29,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:29,299 INFO:     Epoch: 87
2022-12-31 10:21:30,917 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4400532066822052, 'Total loss': 0.4400532066822052} | train loss {'Reaction outcome loss': 0.22799500206357165, 'Total loss': 0.22799500206357165}
2022-12-31 10:21:30,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:30,917 INFO:     Epoch: 88
2022-12-31 10:21:32,530 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45174892743428546, 'Total loss': 0.45174892743428546} | train loss {'Reaction outcome loss': 0.22028596274791146, 'Total loss': 0.22028596274791146}
2022-12-31 10:21:32,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:32,530 INFO:     Epoch: 89
2022-12-31 10:21:34,144 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4550473113854726, 'Total loss': 0.4550473113854726} | train loss {'Reaction outcome loss': 0.22409569568918558, 'Total loss': 0.22409569568918558}
2022-12-31 10:21:34,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:34,145 INFO:     Epoch: 90
2022-12-31 10:21:35,748 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44838685194651284, 'Total loss': 0.44838685194651284} | train loss {'Reaction outcome loss': 0.22021550874532017, 'Total loss': 0.22021550874532017}
2022-12-31 10:21:35,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:35,748 INFO:     Epoch: 91
2022-12-31 10:21:37,371 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38973071177800495, 'Total loss': 0.38973071177800495} | train loss {'Reaction outcome loss': 0.21651364093565423, 'Total loss': 0.21651364093565423}
2022-12-31 10:21:37,372 INFO:     Found new best model at epoch 91
2022-12-31 10:21:37,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:37,373 INFO:     Epoch: 92
2022-12-31 10:21:38,980 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.45623214840888976, 'Total loss': 0.45623214840888976} | train loss {'Reaction outcome loss': 0.21445759587948196, 'Total loss': 0.21445759587948196}
2022-12-31 10:21:38,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:38,981 INFO:     Epoch: 93
2022-12-31 10:21:40,580 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4919866591691971, 'Total loss': 0.4919866591691971} | train loss {'Reaction outcome loss': 0.21554242015501612, 'Total loss': 0.21554242015501612}
2022-12-31 10:21:40,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:40,580 INFO:     Epoch: 94
2022-12-31 10:21:42,191 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46387361685434975, 'Total loss': 0.46387361685434975} | train loss {'Reaction outcome loss': 0.21765501792264252, 'Total loss': 0.21765501792264252}
2022-12-31 10:21:42,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:42,191 INFO:     Epoch: 95
2022-12-31 10:21:43,804 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4546349028746287, 'Total loss': 0.4546349028746287} | train loss {'Reaction outcome loss': 0.21411135464112033, 'Total loss': 0.21411135464112033}
2022-12-31 10:21:43,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:43,804 INFO:     Epoch: 96
2022-12-31 10:21:45,428 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43115261594454446, 'Total loss': 0.43115261594454446} | train loss {'Reaction outcome loss': 0.2150105759091262, 'Total loss': 0.2150105759091262}
2022-12-31 10:21:45,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:45,428 INFO:     Epoch: 97
2022-12-31 10:21:47,047 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4748134324947993, 'Total loss': 0.4748134324947993} | train loss {'Reaction outcome loss': 0.2122732977538059, 'Total loss': 0.2122732977538059}
2022-12-31 10:21:47,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:47,048 INFO:     Epoch: 98
2022-12-31 10:21:48,654 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.424356950322787, 'Total loss': 0.424356950322787} | train loss {'Reaction outcome loss': 0.20930766657440233, 'Total loss': 0.20930766657440233}
2022-12-31 10:21:48,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:48,655 INFO:     Epoch: 99
2022-12-31 10:21:50,296 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.49766299525896707, 'Total loss': 0.49766299525896707} | train loss {'Reaction outcome loss': 0.20739756765491937, 'Total loss': 0.20739756765491937}
2022-12-31 10:21:50,296 INFO:     Best model found after epoch 92 of 100.
2022-12-31 10:21:50,296 INFO:   Done with stage: TRAINING
2022-12-31 10:21:50,296 INFO:   Starting stage: EVALUATION
2022-12-31 10:21:50,425 INFO:   Done with stage: EVALUATION
2022-12-31 10:21:50,425 INFO:   Leaving out SEQ value Fold_9
2022-12-31 10:21:50,437 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 10:21:50,438 INFO:   Starting stage: FEATURE SCALING
2022-12-31 10:21:51,082 INFO:   Done with stage: FEATURE SCALING
2022-12-31 10:21:51,082 INFO:   Starting stage: SCALING TARGETS
2022-12-31 10:21:51,152 INFO:   Done with stage: SCALING TARGETS
2022-12-31 10:21:51,153 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:21:51,153 INFO:     No hyperparam tuning for this model
2022-12-31 10:21:51,153 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:21:51,153 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 10:21:51,153 INFO:     None feature selector for col prot
2022-12-31 10:21:51,154 INFO:     None feature selector for col prot
2022-12-31 10:21:51,154 INFO:     None feature selector for col prot
2022-12-31 10:21:51,154 INFO:     None feature selector for col chem
2022-12-31 10:21:51,154 INFO:     None feature selector for col chem
2022-12-31 10:21:51,154 INFO:     None feature selector for col chem
2022-12-31 10:21:51,154 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 10:21:51,154 INFO:   Starting stage: BUILD MODEL
2022-12-31 10:21:51,156 INFO:     Number of params in model 223921
2022-12-31 10:21:51,159 INFO:   Done with stage: BUILD MODEL
2022-12-31 10:21:51,160 INFO:   Starting stage: TRAINING
2022-12-31 10:21:51,204 INFO:     Val loss before train {'Reaction outcome loss': 1.0073512295881908, 'Total loss': 1.0073512295881908}
2022-12-31 10:21:51,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:51,204 INFO:     Epoch: 0
2022-12-31 10:21:52,832 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6908245245615642, 'Total loss': 0.6908245245615642} | train loss {'Reaction outcome loss': 0.839214093095559, 'Total loss': 0.839214093095559}
2022-12-31 10:21:52,832 INFO:     Found new best model at epoch 0
2022-12-31 10:21:52,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:52,833 INFO:     Epoch: 1
2022-12-31 10:21:54,467 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5391845722993215, 'Total loss': 0.5391845722993215} | train loss {'Reaction outcome loss': 0.6148173158134365, 'Total loss': 0.6148173158134365}
2022-12-31 10:21:54,467 INFO:     Found new best model at epoch 1
2022-12-31 10:21:54,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:54,468 INFO:     Epoch: 2
2022-12-31 10:21:56,102 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5038787464300791, 'Total loss': 0.5038787464300791} | train loss {'Reaction outcome loss': 0.5344232435906406, 'Total loss': 0.5344232435906406}
2022-12-31 10:21:56,103 INFO:     Found new best model at epoch 2
2022-12-31 10:21:56,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:56,103 INFO:     Epoch: 3
2022-12-31 10:21:57,699 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4933513512214025, 'Total loss': 0.4933513512214025} | train loss {'Reaction outcome loss': 0.5097513163347968, 'Total loss': 0.5097513163347968}
2022-12-31 10:21:57,699 INFO:     Found new best model at epoch 3
2022-12-31 10:21:57,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:57,700 INFO:     Epoch: 4
2022-12-31 10:21:59,343 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4587574402491252, 'Total loss': 0.4587574402491252} | train loss {'Reaction outcome loss': 0.49717288305613105, 'Total loss': 0.49717288305613105}
2022-12-31 10:21:59,343 INFO:     Found new best model at epoch 4
2022-12-31 10:21:59,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:21:59,344 INFO:     Epoch: 5
2022-12-31 10:22:01,016 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4921751360098521, 'Total loss': 0.4921751360098521} | train loss {'Reaction outcome loss': 0.48523291079361086, 'Total loss': 0.48523291079361086}
2022-12-31 10:22:01,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:01,016 INFO:     Epoch: 6
2022-12-31 10:22:02,632 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45466336806615193, 'Total loss': 0.45466336806615193} | train loss {'Reaction outcome loss': 0.4752603966729305, 'Total loss': 0.4752603966729305}
2022-12-31 10:22:02,633 INFO:     Found new best model at epoch 6
2022-12-31 10:22:02,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:02,634 INFO:     Epoch: 7
2022-12-31 10:22:04,278 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4471455176671346, 'Total loss': 0.4471455176671346} | train loss {'Reaction outcome loss': 0.46932381579807086, 'Total loss': 0.46932381579807086}
2022-12-31 10:22:04,278 INFO:     Found new best model at epoch 7
2022-12-31 10:22:04,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:04,279 INFO:     Epoch: 8
2022-12-31 10:22:05,944 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4405507395664851, 'Total loss': 0.4405507395664851} | train loss {'Reaction outcome loss': 0.46356730582696865, 'Total loss': 0.46356730582696865}
2022-12-31 10:22:05,944 INFO:     Found new best model at epoch 8
2022-12-31 10:22:05,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:05,945 INFO:     Epoch: 9
2022-12-31 10:22:07,546 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45206270813941957, 'Total loss': 0.45206270813941957} | train loss {'Reaction outcome loss': 0.4543174800298274, 'Total loss': 0.4543174800298274}
2022-12-31 10:22:07,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:07,546 INFO:     Epoch: 10
2022-12-31 10:22:09,162 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.465027646223704, 'Total loss': 0.465027646223704} | train loss {'Reaction outcome loss': 0.44543493751584406, 'Total loss': 0.44543493751584406}
2022-12-31 10:22:09,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:09,163 INFO:     Epoch: 11
2022-12-31 10:22:10,776 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4473084499438604, 'Total loss': 0.4473084499438604} | train loss {'Reaction outcome loss': 0.4466696374844558, 'Total loss': 0.4466696374844558}
2022-12-31 10:22:10,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:10,776 INFO:     Epoch: 12
2022-12-31 10:22:12,380 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42931347091992694, 'Total loss': 0.42931347091992694} | train loss {'Reaction outcome loss': 0.4360940924405191, 'Total loss': 0.4360940924405191}
2022-12-31 10:22:12,380 INFO:     Found new best model at epoch 12
2022-12-31 10:22:12,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:12,381 INFO:     Epoch: 13
2022-12-31 10:22:13,994 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4181238651275635, 'Total loss': 0.4181238651275635} | train loss {'Reaction outcome loss': 0.4322668954945213, 'Total loss': 0.4322668954945213}
2022-12-31 10:22:13,994 INFO:     Found new best model at epoch 13
2022-12-31 10:22:13,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:13,995 INFO:     Epoch: 14
2022-12-31 10:22:15,604 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42567222913106284, 'Total loss': 0.42567222913106284} | train loss {'Reaction outcome loss': 0.42616643022328937, 'Total loss': 0.42616643022328937}
2022-12-31 10:22:15,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:15,604 INFO:     Epoch: 15
2022-12-31 10:22:17,220 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4035777846972148, 'Total loss': 0.4035777846972148} | train loss {'Reaction outcome loss': 0.42300776045244953, 'Total loss': 0.42300776045244953}
2022-12-31 10:22:17,221 INFO:     Found new best model at epoch 15
2022-12-31 10:22:17,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:17,222 INFO:     Epoch: 16
2022-12-31 10:22:18,835 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41474479337533315, 'Total loss': 0.41474479337533315} | train loss {'Reaction outcome loss': 0.4127982113550716, 'Total loss': 0.4127982113550716}
2022-12-31 10:22:18,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:18,835 INFO:     Epoch: 17
2022-12-31 10:22:20,460 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44566017587979634, 'Total loss': 0.44566017587979634} | train loss {'Reaction outcome loss': 0.40888623947055763, 'Total loss': 0.40888623947055763}
2022-12-31 10:22:20,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:20,460 INFO:     Epoch: 18
2022-12-31 10:22:22,094 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42216237584749855, 'Total loss': 0.42216237584749855} | train loss {'Reaction outcome loss': 0.39928802369088473, 'Total loss': 0.39928802369088473}
2022-12-31 10:22:22,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:22,095 INFO:     Epoch: 19
2022-12-31 10:22:23,709 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40709893107414247, 'Total loss': 0.40709893107414247} | train loss {'Reaction outcome loss': 0.3924949959135658, 'Total loss': 0.3924949959135658}
2022-12-31 10:22:23,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:23,709 INFO:     Epoch: 20
2022-12-31 10:22:25,304 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4037336101134618, 'Total loss': 0.4037336101134618} | train loss {'Reaction outcome loss': 0.3905103772555878, 'Total loss': 0.3905103772555878}
2022-12-31 10:22:25,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:25,304 INFO:     Epoch: 21
2022-12-31 10:22:26,920 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40506428678830464, 'Total loss': 0.40506428678830464} | train loss {'Reaction outcome loss': 0.38476125898666763, 'Total loss': 0.38476125898666763}
2022-12-31 10:22:26,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:26,920 INFO:     Epoch: 22
2022-12-31 10:22:28,536 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41103391647338866, 'Total loss': 0.41103391647338866} | train loss {'Reaction outcome loss': 0.38443907732244864, 'Total loss': 0.38443907732244864}
2022-12-31 10:22:28,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:28,536 INFO:     Epoch: 23
2022-12-31 10:22:30,137 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3977890978256861, 'Total loss': 0.3977890978256861} | train loss {'Reaction outcome loss': 0.3796926739521405, 'Total loss': 0.3796926739521405}
2022-12-31 10:22:30,137 INFO:     Found new best model at epoch 23
2022-12-31 10:22:30,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:30,138 INFO:     Epoch: 24
2022-12-31 10:22:31,755 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4108086218436559, 'Total loss': 0.4108086218436559} | train loss {'Reaction outcome loss': 0.3672396225135249, 'Total loss': 0.3672396225135249}
2022-12-31 10:22:31,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:31,755 INFO:     Epoch: 25
2022-12-31 10:22:33,353 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.438404772679011, 'Total loss': 0.438404772679011} | train loss {'Reaction outcome loss': 0.3686067124405062, 'Total loss': 0.3686067124405062}
2022-12-31 10:22:33,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:33,354 INFO:     Epoch: 26
2022-12-31 10:22:34,968 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39167313774426776, 'Total loss': 0.39167313774426776} | train loss {'Reaction outcome loss': 0.36219205102120067, 'Total loss': 0.36219205102120067}
2022-12-31 10:22:34,968 INFO:     Found new best model at epoch 26
2022-12-31 10:22:34,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:34,969 INFO:     Epoch: 27
2022-12-31 10:22:36,584 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.37230102171500523, 'Total loss': 0.37230102171500523} | train loss {'Reaction outcome loss': 0.36505429739878925, 'Total loss': 0.36505429739878925}
2022-12-31 10:22:36,584 INFO:     Found new best model at epoch 27
2022-12-31 10:22:36,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:36,585 INFO:     Epoch: 28
2022-12-31 10:22:38,179 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4279970407485962, 'Total loss': 0.4279970407485962} | train loss {'Reaction outcome loss': 0.35325226669169507, 'Total loss': 0.35325226669169507}
2022-12-31 10:22:38,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:38,179 INFO:     Epoch: 29
2022-12-31 10:22:39,825 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3984171579281489, 'Total loss': 0.3984171579281489} | train loss {'Reaction outcome loss': 0.3528690051677425, 'Total loss': 0.3528690051677425}
2022-12-31 10:22:39,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:39,826 INFO:     Epoch: 30
2022-12-31 10:22:41,465 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4218309005101522, 'Total loss': 0.4218309005101522} | train loss {'Reaction outcome loss': 0.33851427336085577, 'Total loss': 0.33851427336085577}
2022-12-31 10:22:41,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:41,465 INFO:     Epoch: 31
2022-12-31 10:22:43,073 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3868754396835963, 'Total loss': 0.3868754396835963} | train loss {'Reaction outcome loss': 0.33729100174906024, 'Total loss': 0.33729100174906024}
2022-12-31 10:22:43,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:43,074 INFO:     Epoch: 32
2022-12-31 10:22:44,706 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.38298659523328143, 'Total loss': 0.38298659523328143} | train loss {'Reaction outcome loss': 0.33450339387577793, 'Total loss': 0.33450339387577793}
2022-12-31 10:22:44,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:44,706 INFO:     Epoch: 33
2022-12-31 10:22:46,360 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40075568556785585, 'Total loss': 0.40075568556785585} | train loss {'Reaction outcome loss': 0.3328369807734386, 'Total loss': 0.3328369807734386}
2022-12-31 10:22:46,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:46,360 INFO:     Epoch: 34
2022-12-31 10:22:47,968 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3884275992711385, 'Total loss': 0.3884275992711385} | train loss {'Reaction outcome loss': 0.32498143621407694, 'Total loss': 0.32498143621407694}
2022-12-31 10:22:47,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:47,968 INFO:     Epoch: 35
2022-12-31 10:22:49,585 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3995379120111465, 'Total loss': 0.3995379120111465} | train loss {'Reaction outcome loss': 0.3144295310554522, 'Total loss': 0.3144295310554522}
2022-12-31 10:22:49,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:49,586 INFO:     Epoch: 36
2022-12-31 10:22:51,184 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.35918786625067395, 'Total loss': 0.35918786625067395} | train loss {'Reaction outcome loss': 0.3110406527208292, 'Total loss': 0.3110406527208292}
2022-12-31 10:22:51,184 INFO:     Found new best model at epoch 36
2022-12-31 10:22:51,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:51,185 INFO:     Epoch: 37
2022-12-31 10:22:52,820 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.354373707373937, 'Total loss': 0.354373707373937} | train loss {'Reaction outcome loss': 0.3094866492042473, 'Total loss': 0.3094866492042473}
2022-12-31 10:22:52,821 INFO:     Found new best model at epoch 37
2022-12-31 10:22:52,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:52,822 INFO:     Epoch: 38
2022-12-31 10:22:54,435 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.37847804923852285, 'Total loss': 0.37847804923852285} | train loss {'Reaction outcome loss': 0.3037904991838906, 'Total loss': 0.3037904991838906}
2022-12-31 10:22:54,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:54,436 INFO:     Epoch: 39
2022-12-31 10:22:56,045 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4039205034573873, 'Total loss': 0.4039205034573873} | train loss {'Reaction outcome loss': 0.30464403055581374, 'Total loss': 0.30464403055581374}
2022-12-31 10:22:56,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:56,045 INFO:     Epoch: 40
2022-12-31 10:22:57,693 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4051741560300191, 'Total loss': 0.4051741560300191} | train loss {'Reaction outcome loss': 0.2993774565225904, 'Total loss': 0.2993774565225904}
2022-12-31 10:22:57,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:57,693 INFO:     Epoch: 41
2022-12-31 10:22:59,312 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38788909912109376, 'Total loss': 0.38788909912109376} | train loss {'Reaction outcome loss': 0.29570498282513463, 'Total loss': 0.29570498282513463}
2022-12-31 10:22:59,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:22:59,312 INFO:     Epoch: 42
2022-12-31 10:23:00,908 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40319128930568693, 'Total loss': 0.40319128930568693} | train loss {'Reaction outcome loss': 0.2960292645175319, 'Total loss': 0.2960292645175319}
2022-12-31 10:23:00,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:00,909 INFO:     Epoch: 43
2022-12-31 10:23:02,527 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.36761818329493207, 'Total loss': 0.36761818329493207} | train loss {'Reaction outcome loss': 0.29370194660089505, 'Total loss': 0.29370194660089505}
2022-12-31 10:23:02,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:02,527 INFO:     Epoch: 44
2022-12-31 10:23:04,145 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3700274387995402, 'Total loss': 0.3700274387995402} | train loss {'Reaction outcome loss': 0.28749513081426226, 'Total loss': 0.28749513081426226}
2022-12-31 10:23:04,146 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:04,146 INFO:     Epoch: 45
2022-12-31 10:23:05,734 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.38838878870010374, 'Total loss': 0.38838878870010374} | train loss {'Reaction outcome loss': 0.28286466637243, 'Total loss': 0.28286466637243}
2022-12-31 10:23:05,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:05,734 INFO:     Epoch: 46
2022-12-31 10:23:07,386 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3677770326534907, 'Total loss': 0.3677770326534907} | train loss {'Reaction outcome loss': 0.2820365292554728, 'Total loss': 0.2820365292554728}
2022-12-31 10:23:07,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:07,386 INFO:     Epoch: 47
2022-12-31 10:23:09,034 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.37374323507150015, 'Total loss': 0.37374323507150015} | train loss {'Reaction outcome loss': 0.28083152176025544, 'Total loss': 0.28083152176025544}
2022-12-31 10:23:09,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:09,034 INFO:     Epoch: 48
2022-12-31 10:23:10,677 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.36401473979155224, 'Total loss': 0.36401473979155224} | train loss {'Reaction outcome loss': 0.2767630023646441, 'Total loss': 0.2767630023646441}
2022-12-31 10:23:10,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:10,677 INFO:     Epoch: 49
2022-12-31 10:23:12,313 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3788497507572174, 'Total loss': 0.3788497507572174} | train loss {'Reaction outcome loss': 0.27127712603241527, 'Total loss': 0.27127712603241527}
2022-12-31 10:23:12,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:12,314 INFO:     Epoch: 50
2022-12-31 10:23:13,957 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40492804447809855, 'Total loss': 0.40492804447809855} | train loss {'Reaction outcome loss': 0.27023133129849763, 'Total loss': 0.27023133129849763}
2022-12-31 10:23:13,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:13,958 INFO:     Epoch: 51
2022-12-31 10:23:15,560 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3993758837381999, 'Total loss': 0.3993758837381999} | train loss {'Reaction outcome loss': 0.26677414193238375, 'Total loss': 0.26677414193238375}
2022-12-31 10:23:15,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:15,560 INFO:     Epoch: 52
2022-12-31 10:23:17,184 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.37476251075665157, 'Total loss': 0.37476251075665157} | train loss {'Reaction outcome loss': 0.26434835260027906, 'Total loss': 0.26434835260027906}
2022-12-31 10:23:17,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:17,184 INFO:     Epoch: 53
2022-12-31 10:23:18,789 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3647158622741699, 'Total loss': 0.3647158622741699} | train loss {'Reaction outcome loss': 0.26317467361634816, 'Total loss': 0.26317467361634816}
2022-12-31 10:23:18,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:18,789 INFO:     Epoch: 54
2022-12-31 10:23:20,455 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39020073413848877, 'Total loss': 0.39020073413848877} | train loss {'Reaction outcome loss': 0.25544312198239544, 'Total loss': 0.25544312198239544}
2022-12-31 10:23:20,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:20,455 INFO:     Epoch: 55
2022-12-31 10:23:22,110 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4014353995521863, 'Total loss': 0.4014353995521863} | train loss {'Reaction outcome loss': 0.252480557827205, 'Total loss': 0.252480557827205}
2022-12-31 10:23:22,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:22,110 INFO:     Epoch: 56
2022-12-31 10:23:23,734 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38893316288789115, 'Total loss': 0.38893316288789115} | train loss {'Reaction outcome loss': 0.2598451063413482, 'Total loss': 0.2598451063413482}
2022-12-31 10:23:23,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:23,735 INFO:     Epoch: 57
2022-12-31 10:23:25,377 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3495697945356369, 'Total loss': 0.3495697945356369} | train loss {'Reaction outcome loss': 0.25383871555704934, 'Total loss': 0.25383871555704934}
2022-12-31 10:23:25,377 INFO:     Found new best model at epoch 57
2022-12-31 10:23:25,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:25,378 INFO:     Epoch: 58
2022-12-31 10:23:27,008 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3834192956487338, 'Total loss': 0.3834192956487338} | train loss {'Reaction outcome loss': 0.25336179411583426, 'Total loss': 0.25336179411583426}
2022-12-31 10:23:27,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:27,008 INFO:     Epoch: 59
2022-12-31 10:23:28,636 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38104620526234306, 'Total loss': 0.38104620526234306} | train loss {'Reaction outcome loss': 0.2446190737295452, 'Total loss': 0.2446190737295452}
2022-12-31 10:23:28,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:28,636 INFO:     Epoch: 60
2022-12-31 10:23:30,287 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3604252522190412, 'Total loss': 0.3604252522190412} | train loss {'Reaction outcome loss': 0.25023986140286236, 'Total loss': 0.25023986140286236}
2022-12-31 10:23:30,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:30,288 INFO:     Epoch: 61
2022-12-31 10:23:31,894 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3744571477174759, 'Total loss': 0.3744571477174759} | train loss {'Reaction outcome loss': 0.2425287943804092, 'Total loss': 0.2425287943804092}
2022-12-31 10:23:31,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:31,895 INFO:     Epoch: 62
2022-12-31 10:23:33,511 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39630046089490256, 'Total loss': 0.39630046089490256} | train loss {'Reaction outcome loss': 0.246239552402109, 'Total loss': 0.246239552402109}
2022-12-31 10:23:33,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:33,512 INFO:     Epoch: 63
2022-12-31 10:23:35,129 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.37152974754571916, 'Total loss': 0.37152974754571916} | train loss {'Reaction outcome loss': 0.2498345935468424, 'Total loss': 0.2498345935468424}
2022-12-31 10:23:35,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:35,130 INFO:     Epoch: 64
2022-12-31 10:23:36,735 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3934341380993525, 'Total loss': 0.3934341380993525} | train loss {'Reaction outcome loss': 0.24262525852675473, 'Total loss': 0.24262525852675473}
2022-12-31 10:23:36,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:36,735 INFO:     Epoch: 65
2022-12-31 10:23:38,389 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3461373935143153, 'Total loss': 0.3461373935143153} | train loss {'Reaction outcome loss': 0.23248148506460206, 'Total loss': 0.23248148506460206}
2022-12-31 10:23:38,389 INFO:     Found new best model at epoch 65
2022-12-31 10:23:38,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:38,390 INFO:     Epoch: 66
2022-12-31 10:23:40,042 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3809949368238449, 'Total loss': 0.3809949368238449} | train loss {'Reaction outcome loss': 0.23755674838804597, 'Total loss': 0.23755674838804597}
2022-12-31 10:23:40,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:40,042 INFO:     Epoch: 67
2022-12-31 10:23:41,652 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3693241645892461, 'Total loss': 0.3693241645892461} | train loss {'Reaction outcome loss': 0.23905890649150963, 'Total loss': 0.23905890649150963}
2022-12-31 10:23:41,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:41,653 INFO:     Epoch: 68
2022-12-31 10:23:43,309 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.37978555460770924, 'Total loss': 0.37978555460770924} | train loss {'Reaction outcome loss': 0.23585663836731807, 'Total loss': 0.23585663836731807}
2022-12-31 10:23:43,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:43,309 INFO:     Epoch: 69
2022-12-31 10:23:44,965 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.396274234354496, 'Total loss': 0.396274234354496} | train loss {'Reaction outcome loss': 0.23114683503278327, 'Total loss': 0.23114683503278327}
2022-12-31 10:23:44,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:44,965 INFO:     Epoch: 70
2022-12-31 10:23:46,557 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39930277119080226, 'Total loss': 0.39930277119080226} | train loss {'Reaction outcome loss': 0.22660392230975068, 'Total loss': 0.22660392230975068}
2022-12-31 10:23:46,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:46,557 INFO:     Epoch: 71
2022-12-31 10:23:48,168 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39858614802360537, 'Total loss': 0.39858614802360537} | train loss {'Reaction outcome loss': 0.2295944029431696, 'Total loss': 0.2295944029431696}
2022-12-31 10:23:48,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:48,168 INFO:     Epoch: 72
2022-12-31 10:23:49,817 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3893948664267858, 'Total loss': 0.3893948664267858} | train loss {'Reaction outcome loss': 0.22579362801535036, 'Total loss': 0.22579362801535036}
2022-12-31 10:23:49,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:49,817 INFO:     Epoch: 73
2022-12-31 10:23:51,447 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.38563310702641806, 'Total loss': 0.38563310702641806} | train loss {'Reaction outcome loss': 0.2299106724909927, 'Total loss': 0.2299106724909927}
2022-12-31 10:23:51,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:51,447 INFO:     Epoch: 74
2022-12-31 10:23:53,099 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40261901219685875, 'Total loss': 0.40261901219685875} | train loss {'Reaction outcome loss': 0.22372325781450375, 'Total loss': 0.22372325781450375}
2022-12-31 10:23:53,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:53,099 INFO:     Epoch: 75
2022-12-31 10:23:54,750 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3461725970109304, 'Total loss': 0.3461725970109304} | train loss {'Reaction outcome loss': 0.22936885151003458, 'Total loss': 0.22936885151003458}
2022-12-31 10:23:54,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:54,751 INFO:     Epoch: 76
2022-12-31 10:23:56,363 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.359705447157224, 'Total loss': 0.359705447157224} | train loss {'Reaction outcome loss': 0.22338135888134314, 'Total loss': 0.22338135888134314}
2022-12-31 10:23:56,363 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:56,363 INFO:     Epoch: 77
2022-12-31 10:23:57,974 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3292238513628642, 'Total loss': 0.3292238513628642} | train loss {'Reaction outcome loss': 0.22159282436816272, 'Total loss': 0.22159282436816272}
2022-12-31 10:23:57,974 INFO:     Found new best model at epoch 77
2022-12-31 10:23:57,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:57,975 INFO:     Epoch: 78
2022-12-31 10:23:59,587 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3386573284864426, 'Total loss': 0.3386573284864426} | train loss {'Reaction outcome loss': 0.21041428410727195, 'Total loss': 0.21041428410727195}
2022-12-31 10:23:59,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:23:59,587 INFO:     Epoch: 79
2022-12-31 10:24:01,183 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.37056425760189693, 'Total loss': 0.37056425760189693} | train loss {'Reaction outcome loss': 0.21867664354022875, 'Total loss': 0.21867664354022875}
2022-12-31 10:24:01,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:01,183 INFO:     Epoch: 80
2022-12-31 10:24:02,797 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4068167954683304, 'Total loss': 0.4068167954683304} | train loss {'Reaction outcome loss': 0.2156140195938762, 'Total loss': 0.2156140195938762}
2022-12-31 10:24:02,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:02,798 INFO:     Epoch: 81
2022-12-31 10:24:04,389 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3602388083934784, 'Total loss': 0.3602388083934784} | train loss {'Reaction outcome loss': 0.22135128913991933, 'Total loss': 0.22135128913991933}
2022-12-31 10:24:04,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:04,389 INFO:     Epoch: 82
2022-12-31 10:24:06,004 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.34837646087010704, 'Total loss': 0.34837646087010704} | train loss {'Reaction outcome loss': 0.2120591085740375, 'Total loss': 0.2120591085740375}
2022-12-31 10:24:06,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:06,004 INFO:     Epoch: 83
2022-12-31 10:24:07,619 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.37248288094997406, 'Total loss': 0.37248288094997406} | train loss {'Reaction outcome loss': 0.2161531912680675, 'Total loss': 0.2161531912680675}
2022-12-31 10:24:07,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:07,620 INFO:     Epoch: 84
2022-12-31 10:24:09,220 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.36636226425568263, 'Total loss': 0.36636226425568263} | train loss {'Reaction outcome loss': 0.20833303552753013, 'Total loss': 0.20833303552753013}
2022-12-31 10:24:09,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:09,220 INFO:     Epoch: 85
2022-12-31 10:24:10,835 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3639625410238902, 'Total loss': 0.3639625410238902} | train loss {'Reaction outcome loss': 0.21325030102518922, 'Total loss': 0.21325030102518922}
2022-12-31 10:24:10,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:10,836 INFO:     Epoch: 86
2022-12-31 10:24:12,450 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4018886794646581, 'Total loss': 0.4018886794646581} | train loss {'Reaction outcome loss': 0.21409828012089652, 'Total loss': 0.21409828012089652}
2022-12-31 10:24:12,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:12,450 INFO:     Epoch: 87
2022-12-31 10:24:14,049 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.368817992011706, 'Total loss': 0.368817992011706} | train loss {'Reaction outcome loss': 0.21480655403881727, 'Total loss': 0.21480655403881727}
2022-12-31 10:24:14,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:14,049 INFO:     Epoch: 88
2022-12-31 10:24:15,662 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3662936806678772, 'Total loss': 0.3662936806678772} | train loss {'Reaction outcome loss': 0.2128513038447564, 'Total loss': 0.2128513038447564}
2022-12-31 10:24:15,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:15,663 INFO:     Epoch: 89
2022-12-31 10:24:17,276 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3695531028012435, 'Total loss': 0.3695531028012435} | train loss {'Reaction outcome loss': 0.20480315675051203, 'Total loss': 0.20480315675051203}
2022-12-31 10:24:17,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:17,277 INFO:     Epoch: 90
2022-12-31 10:24:18,877 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.38245369096597037, 'Total loss': 0.38245369096597037} | train loss {'Reaction outcome loss': 0.21373412803837538, 'Total loss': 0.21373412803837538}
2022-12-31 10:24:18,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:18,878 INFO:     Epoch: 91
2022-12-31 10:24:20,494 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.37877410153547925, 'Total loss': 0.37877410153547925} | train loss {'Reaction outcome loss': 0.2075734369402973, 'Total loss': 0.2075734369402973}
2022-12-31 10:24:20,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:20,494 INFO:     Epoch: 92
2022-12-31 10:24:22,090 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.36901685893535613, 'Total loss': 0.36901685893535613} | train loss {'Reaction outcome loss': 0.20930189803404067, 'Total loss': 0.20930189803404067}
2022-12-31 10:24:22,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:22,090 INFO:     Epoch: 93
2022-12-31 10:24:23,702 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.36103654007116953, 'Total loss': 0.36103654007116953} | train loss {'Reaction outcome loss': 0.21149598746577325, 'Total loss': 0.21149598746577325}
2022-12-31 10:24:23,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:23,702 INFO:     Epoch: 94
2022-12-31 10:24:25,319 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3777374734481176, 'Total loss': 0.3777374734481176} | train loss {'Reaction outcome loss': 0.21119644945413413, 'Total loss': 0.21119644945413413}
2022-12-31 10:24:25,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:25,319 INFO:     Epoch: 95
2022-12-31 10:24:26,916 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.345380503932635, 'Total loss': 0.345380503932635} | train loss {'Reaction outcome loss': 0.20647320476787615, 'Total loss': 0.20647320476787615}
2022-12-31 10:24:26,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:26,916 INFO:     Epoch: 96
2022-12-31 10:24:28,534 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39275813500086465, 'Total loss': 0.39275813500086465} | train loss {'Reaction outcome loss': 0.20629724879691963, 'Total loss': 0.20629724879691963}
2022-12-31 10:24:28,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:28,534 INFO:     Epoch: 97
2022-12-31 10:24:30,150 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3777431008716424, 'Total loss': 0.3777431008716424} | train loss {'Reaction outcome loss': 0.2027818239915995, 'Total loss': 0.2027818239915995}
2022-12-31 10:24:30,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:30,151 INFO:     Epoch: 98
2022-12-31 10:24:31,741 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3789293328921, 'Total loss': 0.3789293328921} | train loss {'Reaction outcome loss': 0.2083470272068405, 'Total loss': 0.2083470272068405}
2022-12-31 10:24:31,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:31,742 INFO:     Epoch: 99
2022-12-31 10:24:33,357 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3438871165116628, 'Total loss': 0.3438871165116628} | train loss {'Reaction outcome loss': 0.2137747126621352, 'Total loss': 0.2137747126621352}
2022-12-31 10:24:33,357 INFO:     Best model found after epoch 78 of 100.
2022-12-31 10:24:33,357 INFO:   Done with stage: TRAINING
2022-12-31 10:24:33,358 INFO:   Starting stage: EVALUATION
2022-12-31 10:24:33,478 INFO:   Done with stage: EVALUATION
2022-12-31 10:24:33,486 INFO:   Leaving out SEQ value Fold_0
2022-12-31 10:24:33,499 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 10:24:33,499 INFO:   Starting stage: FEATURE SCALING
2022-12-31 10:24:34,133 INFO:   Done with stage: FEATURE SCALING
2022-12-31 10:24:34,134 INFO:   Starting stage: SCALING TARGETS
2022-12-31 10:24:34,202 INFO:   Done with stage: SCALING TARGETS
2022-12-31 10:24:34,202 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:24:34,202 INFO:     No hyperparam tuning for this model
2022-12-31 10:24:34,202 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:24:34,202 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 10:24:34,203 INFO:     None feature selector for col prot
2022-12-31 10:24:34,203 INFO:     None feature selector for col prot
2022-12-31 10:24:34,203 INFO:     None feature selector for col prot
2022-12-31 10:24:34,204 INFO:     None feature selector for col chem
2022-12-31 10:24:34,204 INFO:     None feature selector for col chem
2022-12-31 10:24:34,204 INFO:     None feature selector for col chem
2022-12-31 10:24:34,204 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 10:24:34,204 INFO:   Starting stage: BUILD MODEL
2022-12-31 10:24:34,206 INFO:     Number of params in model 223921
2022-12-31 10:24:34,209 INFO:   Done with stage: BUILD MODEL
2022-12-31 10:24:34,209 INFO:   Starting stage: TRAINING
2022-12-31 10:24:34,254 INFO:     Val loss before train {'Reaction outcome loss': 0.9626852154731751, 'Total loss': 0.9626852154731751}
2022-12-31 10:24:34,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:34,255 INFO:     Epoch: 0
2022-12-31 10:24:35,828 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6814956486225128, 'Total loss': 0.6814956486225128} | train loss {'Reaction outcome loss': 0.8166110453596951, 'Total loss': 0.8166110453596951}
2022-12-31 10:24:35,828 INFO:     Found new best model at epoch 0
2022-12-31 10:24:35,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:35,829 INFO:     Epoch: 1
2022-12-31 10:24:37,455 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5047834664583206, 'Total loss': 0.5047834664583206} | train loss {'Reaction outcome loss': 0.5951639982688166, 'Total loss': 0.5951639982688166}
2022-12-31 10:24:37,455 INFO:     Found new best model at epoch 1
2022-12-31 10:24:37,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:37,456 INFO:     Epoch: 2
2022-12-31 10:24:39,054 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5137989401817322, 'Total loss': 0.5137989401817322} | train loss {'Reaction outcome loss': 0.5210238107255776, 'Total loss': 0.5210238107255776}
2022-12-31 10:24:39,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:39,054 INFO:     Epoch: 3
2022-12-31 10:24:40,631 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5060533901055654, 'Total loss': 0.5060533901055654} | train loss {'Reaction outcome loss': 0.4999404831306778, 'Total loss': 0.4999404831306778}
2022-12-31 10:24:40,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:40,631 INFO:     Epoch: 4
2022-12-31 10:24:42,223 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.470899960398674, 'Total loss': 0.470899960398674} | train loss {'Reaction outcome loss': 0.4830068477640187, 'Total loss': 0.4830068477640187}
2022-12-31 10:24:42,224 INFO:     Found new best model at epoch 4
2022-12-31 10:24:42,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:42,225 INFO:     Epoch: 5
2022-12-31 10:24:43,816 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46274950404961906, 'Total loss': 0.46274950404961906} | train loss {'Reaction outcome loss': 0.47407990139331263, 'Total loss': 0.47407990139331263}
2022-12-31 10:24:43,816 INFO:     Found new best model at epoch 5
2022-12-31 10:24:43,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:43,817 INFO:     Epoch: 6
2022-12-31 10:24:45,394 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45135722160339353, 'Total loss': 0.45135722160339353} | train loss {'Reaction outcome loss': 0.47118543441930827, 'Total loss': 0.47118543441930827}
2022-12-31 10:24:45,394 INFO:     Found new best model at epoch 6
2022-12-31 10:24:45,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:45,395 INFO:     Epoch: 7
2022-12-31 10:24:46,988 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.477324910958608, 'Total loss': 0.477324910958608} | train loss {'Reaction outcome loss': 0.4553924443023483, 'Total loss': 0.4553924443023483}
2022-12-31 10:24:46,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:46,988 INFO:     Epoch: 8
2022-12-31 10:24:48,582 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46138381759325664, 'Total loss': 0.46138381759325664} | train loss {'Reaction outcome loss': 0.4452145824032108, 'Total loss': 0.4452145824032108}
2022-12-31 10:24:48,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:48,583 INFO:     Epoch: 9
2022-12-31 10:24:50,191 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4727018415927887, 'Total loss': 0.4727018415927887} | train loss {'Reaction outcome loss': 0.4455926872953011, 'Total loss': 0.4455926872953011}
2022-12-31 10:24:50,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:50,192 INFO:     Epoch: 10
2022-12-31 10:24:51,818 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4533412704865138, 'Total loss': 0.4533412704865138} | train loss {'Reaction outcome loss': 0.4364994938084244, 'Total loss': 0.4364994938084244}
2022-12-31 10:24:51,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:51,818 INFO:     Epoch: 11
2022-12-31 10:24:53,448 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4619761327902476, 'Total loss': 0.4619761327902476} | train loss {'Reaction outcome loss': 0.4332258527840141, 'Total loss': 0.4332258527840141}
2022-12-31 10:24:53,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:53,448 INFO:     Epoch: 12
2022-12-31 10:24:55,025 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4707697997490565, 'Total loss': 0.4707697997490565} | train loss {'Reaction outcome loss': 0.4253729058388811, 'Total loss': 0.4253729058388811}
2022-12-31 10:24:55,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:55,025 INFO:     Epoch: 13
2022-12-31 10:24:56,616 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4641712089379629, 'Total loss': 0.4641712089379629} | train loss {'Reaction outcome loss': 0.4240601169638825, 'Total loss': 0.4240601169638825}
2022-12-31 10:24:56,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:56,616 INFO:     Epoch: 14
2022-12-31 10:24:58,196 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4646836837132772, 'Total loss': 0.4646836837132772} | train loss {'Reaction outcome loss': 0.40764636867237786, 'Total loss': 0.40764636867237786}
2022-12-31 10:24:58,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:58,196 INFO:     Epoch: 15
2022-12-31 10:24:59,790 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47463758985201515, 'Total loss': 0.47463758985201515} | train loss {'Reaction outcome loss': 0.40792808496821537, 'Total loss': 0.40792808496821537}
2022-12-31 10:24:59,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:24:59,790 INFO:     Epoch: 16
2022-12-31 10:25:01,383 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4839689791202545, 'Total loss': 0.4839689791202545} | train loss {'Reaction outcome loss': 0.4000091421125579, 'Total loss': 0.4000091421125579}
2022-12-31 10:25:01,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:01,384 INFO:     Epoch: 17
2022-12-31 10:25:02,870 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4294221580028534, 'Total loss': 0.4294221580028534} | train loss {'Reaction outcome loss': 0.3971400467039895, 'Total loss': 0.3971400467039895}
2022-12-31 10:25:02,870 INFO:     Found new best model at epoch 17
2022-12-31 10:25:02,871 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:02,871 INFO:     Epoch: 18
2022-12-31 10:25:03,919 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4493609289328257, 'Total loss': 0.4493609289328257} | train loss {'Reaction outcome loss': 0.39027127392426897, 'Total loss': 0.39027127392426897}
2022-12-31 10:25:03,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:03,920 INFO:     Epoch: 19
2022-12-31 10:25:04,964 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4688572227954865, 'Total loss': 0.4688572227954865} | train loss {'Reaction outcome loss': 0.3797215586052324, 'Total loss': 0.3797215586052324}
2022-12-31 10:25:04,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:04,965 INFO:     Epoch: 20
2022-12-31 10:25:06,023 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4629714459180832, 'Total loss': 0.4629714459180832} | train loss {'Reaction outcome loss': 0.3759303582410743, 'Total loss': 0.3759303582410743}
2022-12-31 10:25:06,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:06,024 INFO:     Epoch: 21
2022-12-31 10:25:07,068 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4374775578578313, 'Total loss': 0.4374775578578313} | train loss {'Reaction outcome loss': 0.3680282523379709, 'Total loss': 0.3680282523379709}
2022-12-31 10:25:07,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:07,069 INFO:     Epoch: 22
2022-12-31 10:25:08,623 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44463817377885184, 'Total loss': 0.44463817377885184} | train loss {'Reaction outcome loss': 0.3670457304067855, 'Total loss': 0.3670457304067855}
2022-12-31 10:25:08,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:08,623 INFO:     Epoch: 23
2022-12-31 10:25:10,217 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4307799955209096, 'Total loss': 0.4307799955209096} | train loss {'Reaction outcome loss': 0.35471522844784015, 'Total loss': 0.35471522844784015}
2022-12-31 10:25:10,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:10,217 INFO:     Epoch: 24
2022-12-31 10:25:11,814 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43023839592933655, 'Total loss': 0.43023839592933655} | train loss {'Reaction outcome loss': 0.3516781041330665, 'Total loss': 0.3516781041330665}
2022-12-31 10:25:11,814 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:11,814 INFO:     Epoch: 25
2022-12-31 10:25:13,416 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43001051743825275, 'Total loss': 0.43001051743825275} | train loss {'Reaction outcome loss': 0.3472750580930797, 'Total loss': 0.3472750580930797}
2022-12-31 10:25:13,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:13,416 INFO:     Epoch: 26
2022-12-31 10:25:15,006 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4400852600733439, 'Total loss': 0.4400852600733439} | train loss {'Reaction outcome loss': 0.3388798257784687, 'Total loss': 0.3388798257784687}
2022-12-31 10:25:15,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:15,006 INFO:     Epoch: 27
2022-12-31 10:25:16,589 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4455471058686574, 'Total loss': 0.4455471058686574} | train loss {'Reaction outcome loss': 0.3427262334492955, 'Total loss': 0.3427262334492955}
2022-12-31 10:25:16,591 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:16,591 INFO:     Epoch: 28
2022-12-31 10:25:18,219 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3995657314856847, 'Total loss': 0.3995657314856847} | train loss {'Reaction outcome loss': 0.3321788503523291, 'Total loss': 0.3321788503523291}
2022-12-31 10:25:18,219 INFO:     Found new best model at epoch 28
2022-12-31 10:25:18,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:18,220 INFO:     Epoch: 29
2022-12-31 10:25:19,816 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4131505720317364, 'Total loss': 0.4131505720317364} | train loss {'Reaction outcome loss': 0.3163613403202408, 'Total loss': 0.3163613403202408}
2022-12-31 10:25:19,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:19,817 INFO:     Epoch: 30
2022-12-31 10:25:21,416 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40450344383716585, 'Total loss': 0.40450344383716585} | train loss {'Reaction outcome loss': 0.31419264881388986, 'Total loss': 0.31419264881388986}
2022-12-31 10:25:21,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:21,416 INFO:     Epoch: 31
2022-12-31 10:25:23,001 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4199130843083064, 'Total loss': 0.4199130843083064} | train loss {'Reaction outcome loss': 0.31433005467818603, 'Total loss': 0.31433005467818603}
2022-12-31 10:25:23,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:23,002 INFO:     Epoch: 32
2022-12-31 10:25:24,640 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5068370689948399, 'Total loss': 0.5068370689948399} | train loss {'Reaction outcome loss': 0.30827883335958867, 'Total loss': 0.30827883335958867}
2022-12-31 10:25:24,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:24,640 INFO:     Epoch: 33
2022-12-31 10:25:26,235 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4189435640970866, 'Total loss': 0.4189435640970866} | train loss {'Reaction outcome loss': 0.31183315139182294, 'Total loss': 0.31183315139182294}
2022-12-31 10:25:26,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:26,236 INFO:     Epoch: 34
2022-12-31 10:25:27,833 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42687217593193055, 'Total loss': 0.42687217593193055} | train loss {'Reaction outcome loss': 0.3069562501117696, 'Total loss': 0.3069562501117696}
2022-12-31 10:25:27,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:27,833 INFO:     Epoch: 35
2022-12-31 10:25:29,471 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41906826496124266, 'Total loss': 0.41906826496124266} | train loss {'Reaction outcome loss': 0.2923668206526633, 'Total loss': 0.2923668206526633}
2022-12-31 10:25:29,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:29,471 INFO:     Epoch: 36
2022-12-31 10:25:31,106 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41303242643674215, 'Total loss': 0.41303242643674215} | train loss {'Reaction outcome loss': 0.29559637751620615, 'Total loss': 0.29559637751620615}
2022-12-31 10:25:31,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:31,106 INFO:     Epoch: 37
2022-12-31 10:25:32,695 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45807233452796936, 'Total loss': 0.45807233452796936} | train loss {'Reaction outcome loss': 0.28873556432225844, 'Total loss': 0.28873556432225844}
2022-12-31 10:25:32,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:32,695 INFO:     Epoch: 38
2022-12-31 10:25:34,299 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4520348131656647, 'Total loss': 0.4520348131656647} | train loss {'Reaction outcome loss': 0.28728118242464795, 'Total loss': 0.28728118242464795}
2022-12-31 10:25:34,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:34,299 INFO:     Epoch: 39
2022-12-31 10:25:35,878 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4179370100299517, 'Total loss': 0.4179370100299517} | train loss {'Reaction outcome loss': 0.2851663833198539, 'Total loss': 0.2851663833198539}
2022-12-31 10:25:35,879 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:35,879 INFO:     Epoch: 40
2022-12-31 10:25:37,475 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42470201949278513, 'Total loss': 0.42470201949278513} | train loss {'Reaction outcome loss': 0.2830025069823448, 'Total loss': 0.2830025069823448}
2022-12-31 10:25:37,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:37,475 INFO:     Epoch: 41
2022-12-31 10:25:39,074 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46045308162768683, 'Total loss': 0.46045308162768683} | train loss {'Reaction outcome loss': 0.28048995918981784, 'Total loss': 0.28048995918981784}
2022-12-31 10:25:39,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:39,074 INFO:     Epoch: 42
2022-12-31 10:25:40,680 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4279818604389826, 'Total loss': 0.4279818604389826} | train loss {'Reaction outcome loss': 0.2761999250790716, 'Total loss': 0.2761999250790716}
2022-12-31 10:25:40,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:40,680 INFO:     Epoch: 43
2022-12-31 10:25:42,283 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4004307746887207, 'Total loss': 0.4004307746887207} | train loss {'Reaction outcome loss': 0.2716549475588938, 'Total loss': 0.2716549475588938}
2022-12-31 10:25:42,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:42,283 INFO:     Epoch: 44
2022-12-31 10:25:43,877 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40030429313580196, 'Total loss': 0.40030429313580196} | train loss {'Reaction outcome loss': 0.27122832860552915, 'Total loss': 0.27122832860552915}
2022-12-31 10:25:43,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:43,878 INFO:     Epoch: 45
2022-12-31 10:25:45,504 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4519403656323751, 'Total loss': 0.4519403656323751} | train loss {'Reaction outcome loss': 0.2647009161946765, 'Total loss': 0.2647009161946765}
2022-12-31 10:25:45,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:45,504 INFO:     Epoch: 46
2022-12-31 10:25:47,183 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42525626520315807, 'Total loss': 0.42525626520315807} | train loss {'Reaction outcome loss': 0.2653030161303978, 'Total loss': 0.2653030161303978}
2022-12-31 10:25:47,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:47,184 INFO:     Epoch: 47
2022-12-31 10:25:48,820 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4513198216756185, 'Total loss': 0.4513198216756185} | train loss {'Reaction outcome loss': 0.25694315119163835, 'Total loss': 0.25694315119163835}
2022-12-31 10:25:48,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:48,820 INFO:     Epoch: 48
2022-12-31 10:25:50,428 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4259046218047539, 'Total loss': 0.4259046218047539} | train loss {'Reaction outcome loss': 0.25729223766982773, 'Total loss': 0.25729223766982773}
2022-12-31 10:25:50,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:50,429 INFO:     Epoch: 49
2022-12-31 10:25:52,063 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3932689438263575, 'Total loss': 0.3932689438263575} | train loss {'Reaction outcome loss': 0.25963411217106735, 'Total loss': 0.25963411217106735}
2022-12-31 10:25:52,063 INFO:     Found new best model at epoch 49
2022-12-31 10:25:52,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:52,064 INFO:     Epoch: 50
2022-12-31 10:25:53,668 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.405273482700189, 'Total loss': 0.405273482700189} | train loss {'Reaction outcome loss': 0.2504204596753103, 'Total loss': 0.2504204596753103}
2022-12-31 10:25:53,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:53,669 INFO:     Epoch: 51
2022-12-31 10:25:55,242 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4301540692647298, 'Total loss': 0.4301540692647298} | train loss {'Reaction outcome loss': 0.24465992052896615, 'Total loss': 0.24465992052896615}
2022-12-31 10:25:55,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:55,243 INFO:     Epoch: 52
2022-12-31 10:25:56,880 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.396586083372434, 'Total loss': 0.396586083372434} | train loss {'Reaction outcome loss': 0.24905087227803946, 'Total loss': 0.24905087227803946}
2022-12-31 10:25:56,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:56,881 INFO:     Epoch: 53
2022-12-31 10:25:58,495 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3879374782244364, 'Total loss': 0.3879374782244364} | train loss {'Reaction outcome loss': 0.2552237092333771, 'Total loss': 0.2552237092333771}
2022-12-31 10:25:58,496 INFO:     Found new best model at epoch 53
2022-12-31 10:25:58,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:25:58,497 INFO:     Epoch: 54
2022-12-31 10:26:00,092 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4120943516492844, 'Total loss': 0.4120943516492844} | train loss {'Reaction outcome loss': 0.24143681321700994, 'Total loss': 0.24143681321700994}
2022-12-31 10:26:00,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:00,093 INFO:     Epoch: 55
2022-12-31 10:26:01,671 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41113683581352234, 'Total loss': 0.41113683581352234} | train loss {'Reaction outcome loss': 0.2425214671733769, 'Total loss': 0.2425214671733769}
2022-12-31 10:26:01,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:01,671 INFO:     Epoch: 56
2022-12-31 10:26:03,286 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.401334702471892, 'Total loss': 0.401334702471892} | train loss {'Reaction outcome loss': 0.24345009688315164, 'Total loss': 0.24345009688315164}
2022-12-31 10:26:03,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:03,287 INFO:     Epoch: 57
2022-12-31 10:26:04,920 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3957337329785029, 'Total loss': 0.3957337329785029} | train loss {'Reaction outcome loss': 0.24137704323188666, 'Total loss': 0.24137704323188666}
2022-12-31 10:26:04,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:04,920 INFO:     Epoch: 58
2022-12-31 10:26:06,539 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40586538314819337, 'Total loss': 0.40586538314819337} | train loss {'Reaction outcome loss': 0.23658277027744012, 'Total loss': 0.23658277027744012}
2022-12-31 10:26:06,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:06,539 INFO:     Epoch: 59
2022-12-31 10:26:08,153 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3941920737425486, 'Total loss': 0.3941920737425486} | train loss {'Reaction outcome loss': 0.23699735219923468, 'Total loss': 0.23699735219923468}
2022-12-31 10:26:08,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:08,153 INFO:     Epoch: 60
2022-12-31 10:26:09,746 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4285218209028244, 'Total loss': 0.4285218209028244} | train loss {'Reaction outcome loss': 0.23831628292907764, 'Total loss': 0.23831628292907764}
2022-12-31 10:26:09,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:09,746 INFO:     Epoch: 61
2022-12-31 10:26:11,323 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4242154598236084, 'Total loss': 0.4242154598236084} | train loss {'Reaction outcome loss': 0.2314797256441012, 'Total loss': 0.2314797256441012}
2022-12-31 10:26:11,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:11,323 INFO:     Epoch: 62
2022-12-31 10:26:12,914 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46984252432982127, 'Total loss': 0.46984252432982127} | train loss {'Reaction outcome loss': 0.23140281347054853, 'Total loss': 0.23140281347054853}
2022-12-31 10:26:12,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:12,915 INFO:     Epoch: 63
2022-12-31 10:26:14,506 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.455694842338562, 'Total loss': 0.455694842338562} | train loss {'Reaction outcome loss': 0.23540648809858483, 'Total loss': 0.23540648809858483}
2022-12-31 10:26:14,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:14,506 INFO:     Epoch: 64
2022-12-31 10:26:16,098 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4332736298441887, 'Total loss': 0.4332736298441887} | train loss {'Reaction outcome loss': 0.229212005887806, 'Total loss': 0.229212005887806}
2022-12-31 10:26:16,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:16,099 INFO:     Epoch: 65
2022-12-31 10:26:17,687 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4027348873515924, 'Total loss': 0.4027348873515924} | train loss {'Reaction outcome loss': 0.2241722855608176, 'Total loss': 0.2241722855608176}
2022-12-31 10:26:17,687 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:17,687 INFO:     Epoch: 66
2022-12-31 10:26:19,311 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3923152059316635, 'Total loss': 0.3923152059316635} | train loss {'Reaction outcome loss': 0.22199738394115529, 'Total loss': 0.22199738394115529}
2022-12-31 10:26:19,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:19,312 INFO:     Epoch: 67
2022-12-31 10:26:20,920 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43555243213971456, 'Total loss': 0.43555243213971456} | train loss {'Reaction outcome loss': 0.22373811568194715, 'Total loss': 0.22373811568194715}
2022-12-31 10:26:20,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:20,920 INFO:     Epoch: 68
2022-12-31 10:26:22,509 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42223476866881055, 'Total loss': 0.42223476866881055} | train loss {'Reaction outcome loss': 0.2194566186517477, 'Total loss': 0.2194566186517477}
2022-12-31 10:26:22,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:22,510 INFO:     Epoch: 69
2022-12-31 10:26:24,101 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45453855792681375, 'Total loss': 0.45453855792681375} | train loss {'Reaction outcome loss': 0.2186585710567497, 'Total loss': 0.2186585710567497}
2022-12-31 10:26:24,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:24,101 INFO:     Epoch: 70
2022-12-31 10:26:25,691 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38659883936246237, 'Total loss': 0.38659883936246237} | train loss {'Reaction outcome loss': 0.22431149513861776, 'Total loss': 0.22431149513861776}
2022-12-31 10:26:25,691 INFO:     Found new best model at epoch 70
2022-12-31 10:26:25,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:25,692 INFO:     Epoch: 71
2022-12-31 10:26:27,278 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4321136752764384, 'Total loss': 0.4321136752764384} | train loss {'Reaction outcome loss': 0.22141314860786834, 'Total loss': 0.22141314860786834}
2022-12-31 10:26:27,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:27,278 INFO:     Epoch: 72
2022-12-31 10:26:28,867 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40141337427000207, 'Total loss': 0.40141337427000207} | train loss {'Reaction outcome loss': 0.22040043128178502, 'Total loss': 0.22040043128178502}
2022-12-31 10:26:28,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:28,868 INFO:     Epoch: 73
2022-12-31 10:26:30,485 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44300189018249514, 'Total loss': 0.44300189018249514} | train loss {'Reaction outcome loss': 0.22181807996800346, 'Total loss': 0.22181807996800346}
2022-12-31 10:26:30,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:30,485 INFO:     Epoch: 74
2022-12-31 10:26:32,104 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45524341066678364, 'Total loss': 0.45524341066678364} | train loss {'Reaction outcome loss': 0.22223544574893303, 'Total loss': 0.22223544574893303}
2022-12-31 10:26:32,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:32,104 INFO:     Epoch: 75
2022-12-31 10:26:33,693 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4107064684232076, 'Total loss': 0.4107064684232076} | train loss {'Reaction outcome loss': 0.21030191629853126, 'Total loss': 0.21030191629853126}
2022-12-31 10:26:33,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:33,694 INFO:     Epoch: 76
2022-12-31 10:26:35,265 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42725757559140526, 'Total loss': 0.42725757559140526} | train loss {'Reaction outcome loss': 0.2082558071145611, 'Total loss': 0.2082558071145611}
2022-12-31 10:26:35,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:35,265 INFO:     Epoch: 77
2022-12-31 10:26:36,873 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.48945918877919514, 'Total loss': 0.48945918877919514} | train loss {'Reaction outcome loss': 0.20589904057501007, 'Total loss': 0.20589904057501007}
2022-12-31 10:26:36,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:36,873 INFO:     Epoch: 78
2022-12-31 10:26:38,488 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.427665513753891, 'Total loss': 0.427665513753891} | train loss {'Reaction outcome loss': 0.2141258251125904, 'Total loss': 0.2141258251125904}
2022-12-31 10:26:38,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:38,488 INFO:     Epoch: 79
2022-12-31 10:26:40,102 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41878886222839357, 'Total loss': 0.41878886222839357} | train loss {'Reaction outcome loss': 0.208452606009469, 'Total loss': 0.208452606009469}
2022-12-31 10:26:40,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:40,102 INFO:     Epoch: 80
2022-12-31 10:26:41,693 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41438109974066417, 'Total loss': 0.41438109974066417} | train loss {'Reaction outcome loss': 0.21442793286915351, 'Total loss': 0.21442793286915351}
2022-12-31 10:26:41,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:41,694 INFO:     Epoch: 81
2022-12-31 10:26:43,285 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4332016557455063, 'Total loss': 0.4332016557455063} | train loss {'Reaction outcome loss': 0.21003260808133514, 'Total loss': 0.21003260808133514}
2022-12-31 10:26:43,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:43,285 INFO:     Epoch: 82
2022-12-31 10:26:44,860 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40260841051737467, 'Total loss': 0.40260841051737467} | train loss {'Reaction outcome loss': 0.20503340199943224, 'Total loss': 0.20503340199943224}
2022-12-31 10:26:44,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:44,860 INFO:     Epoch: 83
2022-12-31 10:26:46,451 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43710304697354635, 'Total loss': 0.43710304697354635} | train loss {'Reaction outcome loss': 0.20055530144132838, 'Total loss': 0.20055530144132838}
2022-12-31 10:26:46,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:46,451 INFO:     Epoch: 84
2022-12-31 10:26:48,034 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41125534623861315, 'Total loss': 0.41125534623861315} | train loss {'Reaction outcome loss': 0.20025705960817144, 'Total loss': 0.20025705960817144}
2022-12-31 10:26:48,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:48,035 INFO:     Epoch: 85
2022-12-31 10:26:49,626 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43012799620628356, 'Total loss': 0.43012799620628356} | train loss {'Reaction outcome loss': 0.20397596936808884, 'Total loss': 0.20397596936808884}
2022-12-31 10:26:49,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:49,627 INFO:     Epoch: 86
2022-12-31 10:26:51,220 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4038835426171621, 'Total loss': 0.4038835426171621} | train loss {'Reaction outcome loss': 0.20565972315405842, 'Total loss': 0.20565972315405842}
2022-12-31 10:26:51,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:51,220 INFO:     Epoch: 87
2022-12-31 10:26:52,812 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4204316000143687, 'Total loss': 0.4204316000143687} | train loss {'Reaction outcome loss': 0.2022426069177089, 'Total loss': 0.2022426069177089}
2022-12-31 10:26:52,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:52,812 INFO:     Epoch: 88
2022-12-31 10:26:54,421 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42403043756882347, 'Total loss': 0.42403043756882347} | train loss {'Reaction outcome loss': 0.19788619806568553, 'Total loss': 0.19788619806568553}
2022-12-31 10:26:54,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:54,421 INFO:     Epoch: 89
2022-12-31 10:26:56,038 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4722316533327103, 'Total loss': 0.4722316533327103} | train loss {'Reaction outcome loss': 0.2009414642790917, 'Total loss': 0.2009414642790917}
2022-12-31 10:26:56,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:56,038 INFO:     Epoch: 90
2022-12-31 10:26:57,630 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41256262759367623, 'Total loss': 0.41256262759367623} | train loss {'Reaction outcome loss': 0.1999660704937512, 'Total loss': 0.1999660704937512}
2022-12-31 10:26:57,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:57,630 INFO:     Epoch: 91
2022-12-31 10:26:59,250 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38793795481324195, 'Total loss': 0.38793795481324195} | train loss {'Reaction outcome loss': 0.19585750698635396, 'Total loss': 0.19585750698635396}
2022-12-31 10:26:59,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:26:59,251 INFO:     Epoch: 92
2022-12-31 10:27:00,856 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4383497893810272, 'Total loss': 0.4383497893810272} | train loss {'Reaction outcome loss': 0.19512898986819235, 'Total loss': 0.19512898986819235}
2022-12-31 10:27:00,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:00,856 INFO:     Epoch: 93
2022-12-31 10:27:02,468 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44850196639696754, 'Total loss': 0.44850196639696754} | train loss {'Reaction outcome loss': 0.1946385182698604, 'Total loss': 0.1946385182698604}
2022-12-31 10:27:02,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:02,468 INFO:     Epoch: 94
2022-12-31 10:27:04,063 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4112410436073939, 'Total loss': 0.4112410436073939} | train loss {'Reaction outcome loss': 0.19434764134242152, 'Total loss': 0.19434764134242152}
2022-12-31 10:27:04,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:04,064 INFO:     Epoch: 95
2022-12-31 10:27:05,639 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4509260912736257, 'Total loss': 0.4509260912736257} | train loss {'Reaction outcome loss': 0.1950300565111811, 'Total loss': 0.1950300565111811}
2022-12-31 10:27:05,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:05,640 INFO:     Epoch: 96
2022-12-31 10:27:07,266 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4536194235086441, 'Total loss': 0.4536194235086441} | train loss {'Reaction outcome loss': 0.19223846382305135, 'Total loss': 0.19223846382305135}
2022-12-31 10:27:07,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:07,266 INFO:     Epoch: 97
2022-12-31 10:27:08,888 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.37617031764239073, 'Total loss': 0.37617031764239073} | train loss {'Reaction outcome loss': 0.18477374012751954, 'Total loss': 0.18477374012751954}
2022-12-31 10:27:08,888 INFO:     Found new best model at epoch 97
2022-12-31 10:27:08,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:08,889 INFO:     Epoch: 98
2022-12-31 10:27:10,488 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4047075569629669, 'Total loss': 0.4047075569629669} | train loss {'Reaction outcome loss': 0.1867324814853007, 'Total loss': 0.1867324814853007}
2022-12-31 10:27:10,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:10,489 INFO:     Epoch: 99
2022-12-31 10:27:12,086 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4328453044096629, 'Total loss': 0.4328453044096629} | train loss {'Reaction outcome loss': 0.18982250339616716, 'Total loss': 0.18982250339616716}
2022-12-31 10:27:12,086 INFO:     Best model found after epoch 98 of 100.
2022-12-31 10:27:12,086 INFO:   Done with stage: TRAINING
2022-12-31 10:27:12,086 INFO:   Starting stage: EVALUATION
2022-12-31 10:27:12,220 INFO:   Done with stage: EVALUATION
2022-12-31 10:27:12,220 INFO:   Leaving out SEQ value Fold_1
2022-12-31 10:27:12,233 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2022-12-31 10:27:12,233 INFO:   Starting stage: FEATURE SCALING
2022-12-31 10:27:12,885 INFO:   Done with stage: FEATURE SCALING
2022-12-31 10:27:12,885 INFO:   Starting stage: SCALING TARGETS
2022-12-31 10:27:12,954 INFO:   Done with stage: SCALING TARGETS
2022-12-31 10:27:12,954 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:27:12,954 INFO:     No hyperparam tuning for this model
2022-12-31 10:27:12,954 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:27:12,954 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 10:27:12,955 INFO:     None feature selector for col prot
2022-12-31 10:27:12,955 INFO:     None feature selector for col prot
2022-12-31 10:27:12,955 INFO:     None feature selector for col prot
2022-12-31 10:27:12,956 INFO:     None feature selector for col chem
2022-12-31 10:27:12,956 INFO:     None feature selector for col chem
2022-12-31 10:27:12,956 INFO:     None feature selector for col chem
2022-12-31 10:27:12,956 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 10:27:12,956 INFO:   Starting stage: BUILD MODEL
2022-12-31 10:27:12,958 INFO:     Number of params in model 223921
2022-12-31 10:27:12,961 INFO:   Done with stage: BUILD MODEL
2022-12-31 10:27:12,961 INFO:   Starting stage: TRAINING
2022-12-31 10:27:13,008 INFO:     Val loss before train {'Reaction outcome loss': 0.9758187274138133, 'Total loss': 0.9758187274138133}
2022-12-31 10:27:13,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:13,008 INFO:     Epoch: 0
2022-12-31 10:27:14,582 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6811799188454946, 'Total loss': 0.6811799188454946} | train loss {'Reaction outcome loss': 0.8195640242407682, 'Total loss': 0.8195640242407682}
2022-12-31 10:27:14,583 INFO:     Found new best model at epoch 0
2022-12-31 10:27:14,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:14,583 INFO:     Epoch: 1
2022-12-31 10:27:16,188 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5224776913722357, 'Total loss': 0.5224776913722357} | train loss {'Reaction outcome loss': 0.6045754647562864, 'Total loss': 0.6045754647562864}
2022-12-31 10:27:16,188 INFO:     Found new best model at epoch 1
2022-12-31 10:27:16,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:16,189 INFO:     Epoch: 2
2022-12-31 10:27:17,752 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5526015957196554, 'Total loss': 0.5526015957196554} | train loss {'Reaction outcome loss': 0.5293333550770785, 'Total loss': 0.5293333550770785}
2022-12-31 10:27:17,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:17,752 INFO:     Epoch: 3
2022-12-31 10:27:19,351 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48264864881833397, 'Total loss': 0.48264864881833397} | train loss {'Reaction outcome loss': 0.49757808969249584, 'Total loss': 0.49757808969249584}
2022-12-31 10:27:19,351 INFO:     Found new best model at epoch 3
2022-12-31 10:27:19,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:19,352 INFO:     Epoch: 4
2022-12-31 10:27:20,929 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49526688555876414, 'Total loss': 0.49526688555876414} | train loss {'Reaction outcome loss': 0.4855461127203769, 'Total loss': 0.4855461127203769}
2022-12-31 10:27:20,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:20,929 INFO:     Epoch: 5
2022-12-31 10:27:22,517 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5054070929686229, 'Total loss': 0.5054070929686229} | train loss {'Reaction outcome loss': 0.4698829701465874, 'Total loss': 0.4698829701465874}
2022-12-31 10:27:22,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:22,517 INFO:     Epoch: 6
2022-12-31 10:27:24,101 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48391033709049225, 'Total loss': 0.48391033709049225} | train loss {'Reaction outcome loss': 0.4682102409016162, 'Total loss': 0.4682102409016162}
2022-12-31 10:27:24,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:24,102 INFO:     Epoch: 7
2022-12-31 10:27:25,690 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47680888175964353, 'Total loss': 0.47680888175964353} | train loss {'Reaction outcome loss': 0.4591771814546022, 'Total loss': 0.4591771814546022}
2022-12-31 10:27:25,690 INFO:     Found new best model at epoch 7
2022-12-31 10:27:25,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:25,691 INFO:     Epoch: 8
2022-12-31 10:27:27,268 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5046121686697006, 'Total loss': 0.5046121686697006} | train loss {'Reaction outcome loss': 0.445858302811415, 'Total loss': 0.445858302811415}
2022-12-31 10:27:27,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:27,268 INFO:     Epoch: 9
2022-12-31 10:27:28,863 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4900725026925405, 'Total loss': 0.4900725026925405} | train loss {'Reaction outcome loss': 0.43968405621298123, 'Total loss': 0.43968405621298123}
2022-12-31 10:27:28,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:28,864 INFO:     Epoch: 10
2022-12-31 10:27:30,455 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5100397944450379, 'Total loss': 0.5100397944450379} | train loss {'Reaction outcome loss': 0.4366231766354114, 'Total loss': 0.4366231766354114}
2022-12-31 10:27:30,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:30,456 INFO:     Epoch: 11
2022-12-31 10:27:32,023 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4791095733642578, 'Total loss': 0.4791095733642578} | train loss {'Reaction outcome loss': 0.43039344869746493, 'Total loss': 0.43039344869746493}
2022-12-31 10:27:32,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:32,023 INFO:     Epoch: 12
2022-12-31 10:27:33,601 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4786844829718272, 'Total loss': 0.4786844829718272} | train loss {'Reaction outcome loss': 0.41965601986404716, 'Total loss': 0.41965601986404716}
2022-12-31 10:27:33,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:33,601 INFO:     Epoch: 13
2022-12-31 10:27:35,191 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.513174811999003, 'Total loss': 0.513174811999003} | train loss {'Reaction outcome loss': 0.4153889713197177, 'Total loss': 0.4153889713197177}
2022-12-31 10:27:35,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:35,192 INFO:     Epoch: 14
2022-12-31 10:27:36,804 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4815284182627996, 'Total loss': 0.4815284182627996} | train loss {'Reaction outcome loss': 0.40994199788768354, 'Total loss': 0.40994199788768354}
2022-12-31 10:27:36,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:36,805 INFO:     Epoch: 15
2022-12-31 10:27:38,394 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4701240102450053, 'Total loss': 0.4701240102450053} | train loss {'Reaction outcome loss': 0.40698826181052794, 'Total loss': 0.40698826181052794}
2022-12-31 10:27:38,394 INFO:     Found new best model at epoch 15
2022-12-31 10:27:38,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:38,395 INFO:     Epoch: 16
2022-12-31 10:27:39,963 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4509210973978043, 'Total loss': 0.4509210973978043} | train loss {'Reaction outcome loss': 0.4009567299287258, 'Total loss': 0.4009567299287258}
2022-12-31 10:27:39,963 INFO:     Found new best model at epoch 16
2022-12-31 10:27:39,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:39,964 INFO:     Epoch: 17
2022-12-31 10:27:41,539 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4873712807893753, 'Total loss': 0.4873712807893753} | train loss {'Reaction outcome loss': 0.3923384589297745, 'Total loss': 0.3923384589297745}
2022-12-31 10:27:41,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:41,539 INFO:     Epoch: 18
2022-12-31 10:27:43,160 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4897874663273493, 'Total loss': 0.4897874663273493} | train loss {'Reaction outcome loss': 0.3889531934173345, 'Total loss': 0.3889531934173345}
2022-12-31 10:27:43,161 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:43,161 INFO:     Epoch: 19
2022-12-31 10:27:44,784 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5168070018291473, 'Total loss': 0.5168070018291473} | train loss {'Reaction outcome loss': 0.3827165886759758, 'Total loss': 0.3827165886759758}
2022-12-31 10:27:44,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:44,784 INFO:     Epoch: 20
2022-12-31 10:27:46,411 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45144255378594, 'Total loss': 0.45144255378594} | train loss {'Reaction outcome loss': 0.3796067940298042, 'Total loss': 0.3796067940298042}
2022-12-31 10:27:46,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:46,411 INFO:     Epoch: 21
2022-12-31 10:27:48,010 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4487603192528089, 'Total loss': 0.4487603192528089} | train loss {'Reaction outcome loss': 0.3737441664252334, 'Total loss': 0.3737441664252334}
2022-12-31 10:27:48,010 INFO:     Found new best model at epoch 21
2022-12-31 10:27:48,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:48,011 INFO:     Epoch: 22
2022-12-31 10:27:49,610 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4436074783404668, 'Total loss': 0.4436074783404668} | train loss {'Reaction outcome loss': 0.37092333064308025, 'Total loss': 0.37092333064308025}
2022-12-31 10:27:49,611 INFO:     Found new best model at epoch 22
2022-12-31 10:27:49,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:49,612 INFO:     Epoch: 23
2022-12-31 10:27:51,189 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4548843850692113, 'Total loss': 0.4548843850692113} | train loss {'Reaction outcome loss': 0.363386852797327, 'Total loss': 0.363386852797327}
2022-12-31 10:27:51,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:51,189 INFO:     Epoch: 24
2022-12-31 10:27:52,787 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47062454422314964, 'Total loss': 0.47062454422314964} | train loss {'Reaction outcome loss': 0.3552868696431392, 'Total loss': 0.3552868696431392}
2022-12-31 10:27:52,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:52,787 INFO:     Epoch: 25
2022-12-31 10:27:54,406 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5249713281790416, 'Total loss': 0.5249713281790416} | train loss {'Reaction outcome loss': 0.3488639303349041, 'Total loss': 0.3488639303349041}
2022-12-31 10:27:54,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:54,407 INFO:     Epoch: 26
2022-12-31 10:27:55,989 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47187278072039285, 'Total loss': 0.47187278072039285} | train loss {'Reaction outcome loss': 0.3573871200210054, 'Total loss': 0.3573871200210054}
2022-12-31 10:27:55,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:55,989 INFO:     Epoch: 27
2022-12-31 10:27:57,581 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4724801431099574, 'Total loss': 0.4724801431099574} | train loss {'Reaction outcome loss': 0.3347947457564713, 'Total loss': 0.3347947457564713}
2022-12-31 10:27:57,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:57,581 INFO:     Epoch: 28
2022-12-31 10:27:59,195 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4603751381238302, 'Total loss': 0.4603751381238302} | train loss {'Reaction outcome loss': 0.336438695580537, 'Total loss': 0.336438695580537}
2022-12-31 10:27:59,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:27:59,195 INFO:     Epoch: 29
2022-12-31 10:28:00,797 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46158727606137595, 'Total loss': 0.46158727606137595} | train loss {'Reaction outcome loss': 0.33229202452730866, 'Total loss': 0.33229202452730866}
2022-12-31 10:28:00,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:00,798 INFO:     Epoch: 30
2022-12-31 10:28:02,414 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5105752428372701, 'Total loss': 0.5105752428372701} | train loss {'Reaction outcome loss': 0.3264388676279145, 'Total loss': 0.3264388676279145}
2022-12-31 10:28:02,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:02,414 INFO:     Epoch: 31
2022-12-31 10:28:04,002 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4651054173707962, 'Total loss': 0.4651054173707962} | train loss {'Reaction outcome loss': 0.32252357471253157, 'Total loss': 0.32252357471253157}
2022-12-31 10:28:04,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:04,003 INFO:     Epoch: 32
2022-12-31 10:28:05,606 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4702637890974681, 'Total loss': 0.4702637890974681} | train loss {'Reaction outcome loss': 0.3179837182246671, 'Total loss': 0.3179837182246671}
2022-12-31 10:28:05,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:05,606 INFO:     Epoch: 33
2022-12-31 10:28:07,176 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.49624441464742025, 'Total loss': 0.49624441464742025} | train loss {'Reaction outcome loss': 0.31251309447787784, 'Total loss': 0.31251309447787784}
2022-12-31 10:28:07,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:07,177 INFO:     Epoch: 34
2022-12-31 10:28:08,742 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43529504040877026, 'Total loss': 0.43529504040877026} | train loss {'Reaction outcome loss': 0.3140997556192848, 'Total loss': 0.3140997556192848}
2022-12-31 10:28:08,742 INFO:     Found new best model at epoch 34
2022-12-31 10:28:08,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:08,743 INFO:     Epoch: 35
2022-12-31 10:28:10,324 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4463794191678365, 'Total loss': 0.4463794191678365} | train loss {'Reaction outcome loss': 0.31212562356982726, 'Total loss': 0.31212562356982726}
2022-12-31 10:28:10,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:10,324 INFO:     Epoch: 36
2022-12-31 10:28:11,903 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4858690788348516, 'Total loss': 0.4858690788348516} | train loss {'Reaction outcome loss': 0.3042855204058969, 'Total loss': 0.3042855204058969}
2022-12-31 10:28:11,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:11,904 INFO:     Epoch: 37
2022-12-31 10:28:13,484 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4370011498530706, 'Total loss': 0.4370011498530706} | train loss {'Reaction outcome loss': 0.30210754478769547, 'Total loss': 0.30210754478769547}
2022-12-31 10:28:13,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:13,484 INFO:     Epoch: 38
2022-12-31 10:28:15,041 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4318713963031769, 'Total loss': 0.4318713963031769} | train loss {'Reaction outcome loss': 0.293152986706073, 'Total loss': 0.293152986706073}
2022-12-31 10:28:15,041 INFO:     Found new best model at epoch 38
2022-12-31 10:28:15,042 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:15,042 INFO:     Epoch: 39
2022-12-31 10:28:16,630 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.48367754618326825, 'Total loss': 0.48367754618326825} | train loss {'Reaction outcome loss': 0.29604739906108246, 'Total loss': 0.29604739906108246}
2022-12-31 10:28:16,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:16,630 INFO:     Epoch: 40
2022-12-31 10:28:18,230 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4261059979597727, 'Total loss': 0.4261059979597727} | train loss {'Reaction outcome loss': 0.2938050633756877, 'Total loss': 0.2938050633756877}
2022-12-31 10:28:18,230 INFO:     Found new best model at epoch 40
2022-12-31 10:28:18,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:18,231 INFO:     Epoch: 41
2022-12-31 10:28:19,822 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4189137578010559, 'Total loss': 0.4189137578010559} | train loss {'Reaction outcome loss': 0.28991909602801297, 'Total loss': 0.28991909602801297}
2022-12-31 10:28:19,823 INFO:     Found new best model at epoch 41
2022-12-31 10:28:19,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:19,824 INFO:     Epoch: 42
2022-12-31 10:28:21,435 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4718902190526327, 'Total loss': 0.4718902190526327} | train loss {'Reaction outcome loss': 0.2835041159605848, 'Total loss': 0.2835041159605848}
2022-12-31 10:28:21,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:21,435 INFO:     Epoch: 43
2022-12-31 10:28:23,015 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4587475746870041, 'Total loss': 0.4587475746870041} | train loss {'Reaction outcome loss': 0.2840356759974437, 'Total loss': 0.2840356759974437}
2022-12-31 10:28:23,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:23,015 INFO:     Epoch: 44
2022-12-31 10:28:24,576 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4621223608652751, 'Total loss': 0.4621223608652751} | train loss {'Reaction outcome loss': 0.2864060363443603, 'Total loss': 0.2864060363443603}
2022-12-31 10:28:24,576 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:24,576 INFO:     Epoch: 45
2022-12-31 10:28:26,178 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4451359132925669, 'Total loss': 0.4451359132925669} | train loss {'Reaction outcome loss': 0.2797205244840511, 'Total loss': 0.2797205244840511}
2022-12-31 10:28:26,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:26,178 INFO:     Epoch: 46
2022-12-31 10:28:27,752 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43266741633415223, 'Total loss': 0.43266741633415223} | train loss {'Reaction outcome loss': 0.27684118063275004, 'Total loss': 0.27684118063275004}
2022-12-31 10:28:27,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:27,753 INFO:     Epoch: 47
2022-12-31 10:28:29,358 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42154933710892994, 'Total loss': 0.42154933710892994} | train loss {'Reaction outcome loss': 0.2732226332835166, 'Total loss': 0.2732226332835166}
2022-12-31 10:28:29,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:29,358 INFO:     Epoch: 48
2022-12-31 10:28:30,943 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47902946968873344, 'Total loss': 0.47902946968873344} | train loss {'Reaction outcome loss': 0.27006760874687524, 'Total loss': 0.27006760874687524}
2022-12-31 10:28:30,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:30,943 INFO:     Epoch: 49
2022-12-31 10:28:32,525 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4421294728914897, 'Total loss': 0.4421294728914897} | train loss {'Reaction outcome loss': 0.26363917858068353, 'Total loss': 0.26363917858068353}
2022-12-31 10:28:32,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:32,527 INFO:     Epoch: 50
2022-12-31 10:28:34,111 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4614764054616292, 'Total loss': 0.4614764054616292} | train loss {'Reaction outcome loss': 0.2704254723810402, 'Total loss': 0.2704254723810402}
2022-12-31 10:28:34,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:34,112 INFO:     Epoch: 51
2022-12-31 10:28:35,702 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4145330637693405, 'Total loss': 0.4145330637693405} | train loss {'Reaction outcome loss': 0.26085244853228223, 'Total loss': 0.26085244853228223}
2022-12-31 10:28:35,702 INFO:     Found new best model at epoch 51
2022-12-31 10:28:35,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:35,703 INFO:     Epoch: 52
2022-12-31 10:28:37,297 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4341023961702983, 'Total loss': 0.4341023961702983} | train loss {'Reaction outcome loss': 0.26485952495758824, 'Total loss': 0.26485952495758824}
2022-12-31 10:28:37,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:37,298 INFO:     Epoch: 53
2022-12-31 10:28:38,876 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4224269429842631, 'Total loss': 0.4224269429842631} | train loss {'Reaction outcome loss': 0.26130244111113005, 'Total loss': 0.26130244111113005}
2022-12-31 10:28:38,877 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:38,877 INFO:     Epoch: 54
2022-12-31 10:28:40,453 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4300833780318499, 'Total loss': 0.4300833780318499} | train loss {'Reaction outcome loss': 0.2586435911235334, 'Total loss': 0.2586435911235334}
2022-12-31 10:28:40,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:40,453 INFO:     Epoch: 55
2022-12-31 10:28:42,063 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4348243693510691, 'Total loss': 0.4348243693510691} | train loss {'Reaction outcome loss': 0.2566241923705898, 'Total loss': 0.2566241923705898}
2022-12-31 10:28:42,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:42,063 INFO:     Epoch: 56
2022-12-31 10:28:43,625 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44166648387908936, 'Total loss': 0.44166648387908936} | train loss {'Reaction outcome loss': 0.25309792855184016, 'Total loss': 0.25309792855184016}
2022-12-31 10:28:43,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:43,626 INFO:     Epoch: 57
2022-12-31 10:28:45,202 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43410667926073077, 'Total loss': 0.43410667926073077} | train loss {'Reaction outcome loss': 0.25460229627100744, 'Total loss': 0.25460229627100744}
2022-12-31 10:28:45,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:45,203 INFO:     Epoch: 58
2022-12-31 10:28:46,815 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41990679601828257, 'Total loss': 0.41990679601828257} | train loss {'Reaction outcome loss': 0.2532406060293152, 'Total loss': 0.2532406060293152}
2022-12-31 10:28:46,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:46,815 INFO:     Epoch: 59
2022-12-31 10:28:48,394 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4430408904949824, 'Total loss': 0.4430408904949824} | train loss {'Reaction outcome loss': 0.24478565277428643, 'Total loss': 0.24478565277428643}
2022-12-31 10:28:48,394 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:48,394 INFO:     Epoch: 60
2022-12-31 10:28:49,972 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4082175984978676, 'Total loss': 0.4082175984978676} | train loss {'Reaction outcome loss': 0.25210472680215906, 'Total loss': 0.25210472680215906}
2022-12-31 10:28:49,972 INFO:     Found new best model at epoch 60
2022-12-31 10:28:49,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:49,973 INFO:     Epoch: 61
2022-12-31 10:28:51,541 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43502296408017477, 'Total loss': 0.43502296408017477} | train loss {'Reaction outcome loss': 0.24815221373472926, 'Total loss': 0.24815221373472926}
2022-12-31 10:28:51,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:51,542 INFO:     Epoch: 62
2022-12-31 10:28:53,122 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47799119154612224, 'Total loss': 0.47799119154612224} | train loss {'Reaction outcome loss': 0.24370756926104373, 'Total loss': 0.24370756926104373}
2022-12-31 10:28:53,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:53,122 INFO:     Epoch: 63
2022-12-31 10:28:54,689 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.441687931617101, 'Total loss': 0.441687931617101} | train loss {'Reaction outcome loss': 0.24432645577291282, 'Total loss': 0.24432645577291282}
2022-12-31 10:28:54,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:54,689 INFO:     Epoch: 64
2022-12-31 10:28:56,272 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4119257982199391, 'Total loss': 0.4119257982199391} | train loss {'Reaction outcome loss': 0.2437393378356396, 'Total loss': 0.2437393378356396}
2022-12-31 10:28:56,272 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:56,272 INFO:     Epoch: 65
2022-12-31 10:28:57,855 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4925898899634679, 'Total loss': 0.4925898899634679} | train loss {'Reaction outcome loss': 0.23728435468341041, 'Total loss': 0.23728435468341041}
2022-12-31 10:28:57,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:57,856 INFO:     Epoch: 66
2022-12-31 10:28:59,440 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.49146270950635274, 'Total loss': 0.49146270950635274} | train loss {'Reaction outcome loss': 0.2451448471068896, 'Total loss': 0.2451448471068896}
2022-12-31 10:28:59,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:28:59,440 INFO:     Epoch: 67
2022-12-31 10:29:01,028 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4299999545017878, 'Total loss': 0.4299999545017878} | train loss {'Reaction outcome loss': 0.24404015535715542, 'Total loss': 0.24404015535715542}
2022-12-31 10:29:01,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:01,028 INFO:     Epoch: 68
2022-12-31 10:29:02,647 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4781535009543101, 'Total loss': 0.4781535009543101} | train loss {'Reaction outcome loss': 0.24227402443100607, 'Total loss': 0.24227402443100607}
2022-12-31 10:29:02,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:02,647 INFO:     Epoch: 69
2022-12-31 10:29:04,229 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4264589875936508, 'Total loss': 0.4264589875936508} | train loss {'Reaction outcome loss': 0.24352475159502557, 'Total loss': 0.24352475159502557}
2022-12-31 10:29:04,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:04,229 INFO:     Epoch: 70
2022-12-31 10:29:05,812 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4403633673985799, 'Total loss': 0.4403633673985799} | train loss {'Reaction outcome loss': 0.23418118366868512, 'Total loss': 0.23418118366868512}
2022-12-31 10:29:05,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:05,812 INFO:     Epoch: 71
2022-12-31 10:29:07,394 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4173006425301234, 'Total loss': 0.4173006425301234} | train loss {'Reaction outcome loss': 0.23096985221458977, 'Total loss': 0.23096985221458977}
2022-12-31 10:29:07,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:07,395 INFO:     Epoch: 72
2022-12-31 10:29:08,977 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4286665345231692, 'Total loss': 0.4286665345231692} | train loss {'Reaction outcome loss': 0.23293009664299744, 'Total loss': 0.23293009664299744}
2022-12-31 10:29:08,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:08,977 INFO:     Epoch: 73
2022-12-31 10:29:10,545 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4117207517226537, 'Total loss': 0.4117207517226537} | train loss {'Reaction outcome loss': 0.23495862344314253, 'Total loss': 0.23495862344314253}
2022-12-31 10:29:10,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:10,545 INFO:     Epoch: 74
2022-12-31 10:29:12,130 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5124418169260025, 'Total loss': 0.5124418169260025} | train loss {'Reaction outcome loss': 0.22964707306995163, 'Total loss': 0.22964707306995163}
2022-12-31 10:29:12,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:12,131 INFO:     Epoch: 75
2022-12-31 10:29:13,772 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4310949717958768, 'Total loss': 0.4310949717958768} | train loss {'Reaction outcome loss': 0.22823392518029662, 'Total loss': 0.22823392518029662}
2022-12-31 10:29:13,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:13,773 INFO:     Epoch: 76
2022-12-31 10:29:15,382 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43512640992800394, 'Total loss': 0.43512640992800394} | train loss {'Reaction outcome loss': 0.22800477074521056, 'Total loss': 0.22800477074521056}
2022-12-31 10:29:15,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:15,382 INFO:     Epoch: 77
2022-12-31 10:29:16,999 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3997372448444366, 'Total loss': 0.3997372448444366} | train loss {'Reaction outcome loss': 0.22611160208625766, 'Total loss': 0.22611160208625766}
2022-12-31 10:29:16,999 INFO:     Found new best model at epoch 77
2022-12-31 10:29:16,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:17,000 INFO:     Epoch: 78
2022-12-31 10:29:18,600 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43314771354198456, 'Total loss': 0.43314771354198456} | train loss {'Reaction outcome loss': 0.22041485578206632, 'Total loss': 0.22041485578206632}
2022-12-31 10:29:18,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:18,600 INFO:     Epoch: 79
2022-12-31 10:29:20,228 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4364407420158386, 'Total loss': 0.4364407420158386} | train loss {'Reaction outcome loss': 0.2209899800922378, 'Total loss': 0.2209899800922378}
2022-12-31 10:29:20,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:20,228 INFO:     Epoch: 80
2022-12-31 10:29:21,846 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.48333625892798104, 'Total loss': 0.48333625892798104} | train loss {'Reaction outcome loss': 0.2275916386491918, 'Total loss': 0.2275916386491918}
2022-12-31 10:29:21,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:21,846 INFO:     Epoch: 81
2022-12-31 10:29:23,461 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4339415152867635, 'Total loss': 0.4339415152867635} | train loss {'Reaction outcome loss': 0.22409581079584207, 'Total loss': 0.22409581079584207}
2022-12-31 10:29:23,461 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:23,461 INFO:     Epoch: 82
2022-12-31 10:29:25,043 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3985107779502869, 'Total loss': 0.3985107779502869} | train loss {'Reaction outcome loss': 0.21843509316251947, 'Total loss': 0.21843509316251947}
2022-12-31 10:29:25,043 INFO:     Found new best model at epoch 82
2022-12-31 10:29:25,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:25,044 INFO:     Epoch: 83
2022-12-31 10:29:26,625 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.38983668287595113, 'Total loss': 0.38983668287595113} | train loss {'Reaction outcome loss': 0.22326029182800067, 'Total loss': 0.22326029182800067}
2022-12-31 10:29:26,625 INFO:     Found new best model at epoch 83
2022-12-31 10:29:26,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:26,626 INFO:     Epoch: 84
2022-12-31 10:29:28,204 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45141689280668895, 'Total loss': 0.45141689280668895} | train loss {'Reaction outcome loss': 0.21923097668428704, 'Total loss': 0.21923097668428704}
2022-12-31 10:29:28,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:28,204 INFO:     Epoch: 85
2022-12-31 10:29:29,783 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.37945126940806706, 'Total loss': 0.37945126940806706} | train loss {'Reaction outcome loss': 0.21382178392302506, 'Total loss': 0.21382178392302506}
2022-12-31 10:29:29,783 INFO:     Found new best model at epoch 85
2022-12-31 10:29:29,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:29,784 INFO:     Epoch: 86
2022-12-31 10:29:31,366 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3817885921647151, 'Total loss': 0.3817885921647151} | train loss {'Reaction outcome loss': 0.21561775911888073, 'Total loss': 0.21561775911888073}
2022-12-31 10:29:31,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:31,366 INFO:     Epoch: 87
2022-12-31 10:29:32,950 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4468650450309118, 'Total loss': 0.4468650450309118} | train loss {'Reaction outcome loss': 0.21507762611682124, 'Total loss': 0.21507762611682124}
2022-12-31 10:29:32,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:32,950 INFO:     Epoch: 88
2022-12-31 10:29:34,534 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46828206181526183, 'Total loss': 0.46828206181526183} | train loss {'Reaction outcome loss': 0.21315240306346728, 'Total loss': 0.21315240306346728}
2022-12-31 10:29:34,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:34,534 INFO:     Epoch: 89
2022-12-31 10:29:36,116 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4282954841852188, 'Total loss': 0.4282954841852188} | train loss {'Reaction outcome loss': 0.20605766462553912, 'Total loss': 0.20605766462553912}
2022-12-31 10:29:36,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:36,117 INFO:     Epoch: 90
2022-12-31 10:29:37,681 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4362281382083893, 'Total loss': 0.4362281382083893} | train loss {'Reaction outcome loss': 0.2120871100973379, 'Total loss': 0.2120871100973379}
2022-12-31 10:29:37,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:37,682 INFO:     Epoch: 91
2022-12-31 10:29:39,253 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4140143901109695, 'Total loss': 0.4140143901109695} | train loss {'Reaction outcome loss': 0.20752874489639958, 'Total loss': 0.20752874489639958}
2022-12-31 10:29:39,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:39,253 INFO:     Epoch: 92
2022-12-31 10:29:40,858 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40865979890028636, 'Total loss': 0.40865979890028636} | train loss {'Reaction outcome loss': 0.2194585926844515, 'Total loss': 0.2194585926844515}
2022-12-31 10:29:40,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:40,858 INFO:     Epoch: 93
2022-12-31 10:29:42,439 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44371936122576394, 'Total loss': 0.44371936122576394} | train loss {'Reaction outcome loss': 0.21185416474979632, 'Total loss': 0.21185416474979632}
2022-12-31 10:29:42,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:42,439 INFO:     Epoch: 94
2022-12-31 10:29:44,022 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46262426674366, 'Total loss': 0.46262426674366} | train loss {'Reaction outcome loss': 0.20971018999361354, 'Total loss': 0.20971018999361354}
2022-12-31 10:29:44,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:44,023 INFO:     Epoch: 95
2022-12-31 10:29:45,604 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4058724155028661, 'Total loss': 0.4058724155028661} | train loss {'Reaction outcome loss': 0.206641206469703, 'Total loss': 0.206641206469703}
2022-12-31 10:29:45,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:45,604 INFO:     Epoch: 96
2022-12-31 10:29:47,219 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.379677017359063, 'Total loss': 0.379677017359063} | train loss {'Reaction outcome loss': 0.2088554002537059, 'Total loss': 0.2088554002537059}
2022-12-31 10:29:47,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:47,219 INFO:     Epoch: 97
2022-12-31 10:29:48,796 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4085250308116277, 'Total loss': 0.4085250308116277} | train loss {'Reaction outcome loss': 0.21050807624038076, 'Total loss': 0.21050807624038076}
2022-12-31 10:29:48,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:48,796 INFO:     Epoch: 98
2022-12-31 10:29:50,425 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.40071949462095896, 'Total loss': 0.40071949462095896} | train loss {'Reaction outcome loss': 0.20895699549095217, 'Total loss': 0.20895699549095217}
2022-12-31 10:29:50,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:50,425 INFO:     Epoch: 99
2022-12-31 10:29:52,012 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45813075800736747, 'Total loss': 0.45813075800736747} | train loss {'Reaction outcome loss': 0.1997917399181541, 'Total loss': 0.1997917399181541}
2022-12-31 10:29:52,013 INFO:     Best model found after epoch 86 of 100.
2022-12-31 10:29:52,013 INFO:   Done with stage: TRAINING
2022-12-31 10:29:52,013 INFO:   Starting stage: EVALUATION
2022-12-31 10:29:52,158 INFO:   Done with stage: EVALUATION
2022-12-31 10:29:52,159 INFO:   Leaving out SEQ value Fold_2
2022-12-31 10:29:52,171 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 10:29:52,171 INFO:   Starting stage: FEATURE SCALING
2022-12-31 10:29:52,820 INFO:   Done with stage: FEATURE SCALING
2022-12-31 10:29:52,821 INFO:   Starting stage: SCALING TARGETS
2022-12-31 10:29:52,890 INFO:   Done with stage: SCALING TARGETS
2022-12-31 10:29:52,890 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:29:52,890 INFO:     No hyperparam tuning for this model
2022-12-31 10:29:52,890 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:29:52,890 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 10:29:52,891 INFO:     None feature selector for col prot
2022-12-31 10:29:52,891 INFO:     None feature selector for col prot
2022-12-31 10:29:52,891 INFO:     None feature selector for col prot
2022-12-31 10:29:52,892 INFO:     None feature selector for col chem
2022-12-31 10:29:52,892 INFO:     None feature selector for col chem
2022-12-31 10:29:52,892 INFO:     None feature selector for col chem
2022-12-31 10:29:52,892 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 10:29:52,892 INFO:   Starting stage: BUILD MODEL
2022-12-31 10:29:52,894 INFO:     Number of params in model 223921
2022-12-31 10:29:52,897 INFO:   Done with stage: BUILD MODEL
2022-12-31 10:29:52,897 INFO:   Starting stage: TRAINING
2022-12-31 10:29:52,944 INFO:     Val loss before train {'Reaction outcome loss': 0.9341392954190572, 'Total loss': 0.9341392954190572}
2022-12-31 10:29:52,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:52,944 INFO:     Epoch: 0
2022-12-31 10:29:54,557 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6531626840432485, 'Total loss': 0.6531626840432485} | train loss {'Reaction outcome loss': 0.8156557583074638, 'Total loss': 0.8156557583074638}
2022-12-31 10:29:54,557 INFO:     Found new best model at epoch 0
2022-12-31 10:29:54,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:54,558 INFO:     Epoch: 1
2022-12-31 10:29:56,160 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4979346811771393, 'Total loss': 0.4979346811771393} | train loss {'Reaction outcome loss': 0.601050987974673, 'Total loss': 0.601050987974673}
2022-12-31 10:29:56,161 INFO:     Found new best model at epoch 1
2022-12-31 10:29:56,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:56,162 INFO:     Epoch: 2
2022-12-31 10:29:57,757 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.45803149541219074, 'Total loss': 0.45803149541219074} | train loss {'Reaction outcome loss': 0.5205419794884105, 'Total loss': 0.5205419794884105}
2022-12-31 10:29:57,757 INFO:     Found new best model at epoch 2
2022-12-31 10:29:57,758 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:57,758 INFO:     Epoch: 3
2022-12-31 10:29:59,390 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45336459477742513, 'Total loss': 0.45336459477742513} | train loss {'Reaction outcome loss': 0.49398696605609416, 'Total loss': 0.49398696605609416}
2022-12-31 10:29:59,390 INFO:     Found new best model at epoch 3
2022-12-31 10:29:59,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:29:59,391 INFO:     Epoch: 4
2022-12-31 10:30:01,002 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47756726344426476, 'Total loss': 0.47756726344426476} | train loss {'Reaction outcome loss': 0.4781504960703677, 'Total loss': 0.4781504960703677}
2022-12-31 10:30:01,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:01,002 INFO:     Epoch: 5
2022-12-31 10:30:02,614 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4441317141056061, 'Total loss': 0.4441317141056061} | train loss {'Reaction outcome loss': 0.4868470153946807, 'Total loss': 0.4868470153946807}
2022-12-31 10:30:02,614 INFO:     Found new best model at epoch 5
2022-12-31 10:30:02,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:02,615 INFO:     Epoch: 6
2022-12-31 10:30:04,209 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46300766269365945, 'Total loss': 0.46300766269365945} | train loss {'Reaction outcome loss': 0.4924206564715807, 'Total loss': 0.4924206564715807}
2022-12-31 10:30:04,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:04,209 INFO:     Epoch: 7
2022-12-31 10:30:05,849 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4779257516066233, 'Total loss': 0.4779257516066233} | train loss {'Reaction outcome loss': 0.4758827997948569, 'Total loss': 0.4758827997948569}
2022-12-31 10:30:05,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:05,849 INFO:     Epoch: 8
2022-12-31 10:30:07,470 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4324506382147471, 'Total loss': 0.4324506382147471} | train loss {'Reaction outcome loss': 0.44571858027990424, 'Total loss': 0.44571858027990424}
2022-12-31 10:30:07,471 INFO:     Found new best model at epoch 8
2022-12-31 10:30:07,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:07,471 INFO:     Epoch: 9
2022-12-31 10:30:09,118 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45085657835006715, 'Total loss': 0.45085657835006715} | train loss {'Reaction outcome loss': 0.44057416742114164, 'Total loss': 0.44057416742114164}
2022-12-31 10:30:09,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:09,118 INFO:     Epoch: 10
2022-12-31 10:30:10,774 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4466189424196879, 'Total loss': 0.4466189424196879} | train loss {'Reaction outcome loss': 0.43468138398147066, 'Total loss': 0.43468138398147066}
2022-12-31 10:30:10,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:10,774 INFO:     Epoch: 11
2022-12-31 10:30:12,425 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4318266461292903, 'Total loss': 0.4318266461292903} | train loss {'Reaction outcome loss': 0.4313738268895616, 'Total loss': 0.4313738268895616}
2022-12-31 10:30:12,425 INFO:     Found new best model at epoch 11
2022-12-31 10:30:12,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:12,426 INFO:     Epoch: 12
2022-12-31 10:30:14,028 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41074196646610894, 'Total loss': 0.41074196646610894} | train loss {'Reaction outcome loss': 0.42498620897084405, 'Total loss': 0.42498620897084405}
2022-12-31 10:30:14,029 INFO:     Found new best model at epoch 12
2022-12-31 10:30:14,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:14,030 INFO:     Epoch: 13
2022-12-31 10:30:15,656 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41627712845802306, 'Total loss': 0.41627712845802306} | train loss {'Reaction outcome loss': 0.421919049616766, 'Total loss': 0.421919049616766}
2022-12-31 10:30:15,656 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:15,656 INFO:     Epoch: 14
2022-12-31 10:30:17,300 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40108568171660103, 'Total loss': 0.40108568171660103} | train loss {'Reaction outcome loss': 0.42221711904910963, 'Total loss': 0.42221711904910963}
2022-12-31 10:30:17,300 INFO:     Found new best model at epoch 14
2022-12-31 10:30:17,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:17,301 INFO:     Epoch: 15
2022-12-31 10:30:18,944 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.422052522500356, 'Total loss': 0.422052522500356} | train loss {'Reaction outcome loss': 0.4105265641920741, 'Total loss': 0.4105265641920741}
2022-12-31 10:30:18,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:18,944 INFO:     Epoch: 16
2022-12-31 10:30:20,595 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4311301350593567, 'Total loss': 0.4311301350593567} | train loss {'Reaction outcome loss': 0.4106228367250035, 'Total loss': 0.4106228367250035}
2022-12-31 10:30:20,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:20,595 INFO:     Epoch: 17
2022-12-31 10:30:22,253 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4153460681438446, 'Total loss': 0.4153460681438446} | train loss {'Reaction outcome loss': 0.420893216451657, 'Total loss': 0.420893216451657}
2022-12-31 10:30:22,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:22,253 INFO:     Epoch: 18
2022-12-31 10:30:23,850 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42132820387681325, 'Total loss': 0.42132820387681325} | train loss {'Reaction outcome loss': 0.3960601085922647, 'Total loss': 0.3960601085922647}
2022-12-31 10:30:23,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:23,851 INFO:     Epoch: 19
2022-12-31 10:30:25,448 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4402480959892273, 'Total loss': 0.4402480959892273} | train loss {'Reaction outcome loss': 0.38744535718148615, 'Total loss': 0.38744535718148615}
2022-12-31 10:30:25,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:25,449 INFO:     Epoch: 20
2022-12-31 10:30:27,070 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41550971269607545, 'Total loss': 0.41550971269607545} | train loss {'Reaction outcome loss': 0.38178389031615906, 'Total loss': 0.38178389031615906}
2022-12-31 10:30:27,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:27,070 INFO:     Epoch: 21
2022-12-31 10:30:28,715 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40403113265832263, 'Total loss': 0.40403113265832263} | train loss {'Reaction outcome loss': 0.3792857004258806, 'Total loss': 0.3792857004258806}
2022-12-31 10:30:28,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:28,715 INFO:     Epoch: 22
2022-12-31 10:30:30,360 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4030746559302012, 'Total loss': 0.4030746559302012} | train loss {'Reaction outcome loss': 0.38107442946267733, 'Total loss': 0.38107442946267733}
2022-12-31 10:30:30,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:30,360 INFO:     Epoch: 23
2022-12-31 10:30:31,995 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4112381190061569, 'Total loss': 0.4112381190061569} | train loss {'Reaction outcome loss': 0.410534094064159, 'Total loss': 0.410534094064159}
2022-12-31 10:30:31,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:31,995 INFO:     Epoch: 24
2022-12-31 10:30:33,607 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3981279561916987, 'Total loss': 0.3981279561916987} | train loss {'Reaction outcome loss': 0.3768533475737533, 'Total loss': 0.3768533475737533}
2022-12-31 10:30:33,607 INFO:     Found new best model at epoch 24
2022-12-31 10:30:33,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:33,608 INFO:     Epoch: 25
2022-12-31 10:30:35,218 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4478637039661407, 'Total loss': 0.4478637039661407} | train loss {'Reaction outcome loss': 0.3660136543760967, 'Total loss': 0.3660136543760967}
2022-12-31 10:30:35,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:35,218 INFO:     Epoch: 26
2022-12-31 10:30:36,850 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.40228019456068675, 'Total loss': 0.40228019456068675} | train loss {'Reaction outcome loss': 0.36335734895808436, 'Total loss': 0.36335734895808436}
2022-12-31 10:30:36,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:36,850 INFO:     Epoch: 27
2022-12-31 10:30:38,473 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4113825519879659, 'Total loss': 0.4113825519879659} | train loss {'Reaction outcome loss': 0.3623996697555202, 'Total loss': 0.3623996697555202}
2022-12-31 10:30:38,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:38,474 INFO:     Epoch: 28
2022-12-31 10:30:40,095 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41863242785135907, 'Total loss': 0.41863242785135907} | train loss {'Reaction outcome loss': 0.3652142602320806, 'Total loss': 0.3652142602320806}
2022-12-31 10:30:40,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:40,095 INFO:     Epoch: 29
2022-12-31 10:30:41,720 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3822391519943873, 'Total loss': 0.3822391519943873} | train loss {'Reaction outcome loss': 0.34669095561907126, 'Total loss': 0.34669095561907126}
2022-12-31 10:30:41,720 INFO:     Found new best model at epoch 29
2022-12-31 10:30:41,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:41,721 INFO:     Epoch: 30
2022-12-31 10:30:43,305 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3951078732808431, 'Total loss': 0.3951078732808431} | train loss {'Reaction outcome loss': 0.3446474752228191, 'Total loss': 0.3446474752228191}
2022-12-31 10:30:43,305 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:43,305 INFO:     Epoch: 31
2022-12-31 10:30:44,921 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40867481430371605, 'Total loss': 0.40867481430371605} | train loss {'Reaction outcome loss': 0.3388257828280431, 'Total loss': 0.3388257828280431}
2022-12-31 10:30:44,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:44,922 INFO:     Epoch: 32
2022-12-31 10:30:46,534 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3749065118531386, 'Total loss': 0.3749065118531386} | train loss {'Reaction outcome loss': 0.3351592390069488, 'Total loss': 0.3351592390069488}
2022-12-31 10:30:46,534 INFO:     Found new best model at epoch 32
2022-12-31 10:30:46,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:46,535 INFO:     Epoch: 33
2022-12-31 10:30:48,140 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4259844720363617, 'Total loss': 0.4259844720363617} | train loss {'Reaction outcome loss': 0.35130037255315244, 'Total loss': 0.35130037255315244}
2022-12-31 10:30:48,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:48,141 INFO:     Epoch: 34
2022-12-31 10:30:49,776 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38338904281457264, 'Total loss': 0.38338904281457264} | train loss {'Reaction outcome loss': 0.32598271281365643, 'Total loss': 0.32598271281365643}
2022-12-31 10:30:49,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:49,776 INFO:     Epoch: 35
2022-12-31 10:30:51,409 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43357742627461754, 'Total loss': 0.43357742627461754} | train loss {'Reaction outcome loss': 0.3204733011687336, 'Total loss': 0.3204733011687336}
2022-12-31 10:30:51,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:51,410 INFO:     Epoch: 36
2022-12-31 10:30:53,016 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3886556992928187, 'Total loss': 0.3886556992928187} | train loss {'Reaction outcome loss': 0.3166845469209163, 'Total loss': 0.3166845469209163}
2022-12-31 10:30:53,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:53,016 INFO:     Epoch: 37
2022-12-31 10:30:54,623 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42795264224211377, 'Total loss': 0.42795264224211377} | train loss {'Reaction outcome loss': 0.359953285937292, 'Total loss': 0.359953285937292}
2022-12-31 10:30:54,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:54,623 INFO:     Epoch: 38
2022-12-31 10:30:56,229 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43450440069039664, 'Total loss': 0.43450440069039664} | train loss {'Reaction outcome loss': 0.41617222063032916, 'Total loss': 0.41617222063032916}
2022-12-31 10:30:56,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:56,229 INFO:     Epoch: 39
2022-12-31 10:30:57,835 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.392303870121638, 'Total loss': 0.392303870121638} | train loss {'Reaction outcome loss': 0.33759802636104985, 'Total loss': 0.33759802636104985}
2022-12-31 10:30:57,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:57,835 INFO:     Epoch: 40
2022-12-31 10:30:59,424 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3994956026474635, 'Total loss': 0.3994956026474635} | train loss {'Reaction outcome loss': 0.31839908359140373, 'Total loss': 0.31839908359140373}
2022-12-31 10:30:59,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:30:59,424 INFO:     Epoch: 41
2022-12-31 10:31:01,030 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.36883049706617993, 'Total loss': 0.36883049706617993} | train loss {'Reaction outcome loss': 0.3102894869474424, 'Total loss': 0.3102894869474424}
2022-12-31 10:31:01,031 INFO:     Found new best model at epoch 41
2022-12-31 10:31:01,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:01,032 INFO:     Epoch: 42
2022-12-31 10:31:02,638 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41187514464060465, 'Total loss': 0.41187514464060465} | train loss {'Reaction outcome loss': 0.30537898172856925, 'Total loss': 0.30537898172856925}
2022-12-31 10:31:02,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:02,638 INFO:     Epoch: 43
2022-12-31 10:31:04,246 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3849045189718405, 'Total loss': 0.3849045189718405} | train loss {'Reaction outcome loss': 0.30372534030913445, 'Total loss': 0.30372534030913445}
2022-12-31 10:31:04,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:04,247 INFO:     Epoch: 44
2022-12-31 10:31:05,861 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.412711963057518, 'Total loss': 0.412711963057518} | train loss {'Reaction outcome loss': 0.2890942939470667, 'Total loss': 0.2890942939470667}
2022-12-31 10:31:05,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:05,861 INFO:     Epoch: 45
2022-12-31 10:31:07,484 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3836117227872213, 'Total loss': 0.3836117227872213} | train loss {'Reaction outcome loss': 0.29488042714175483, 'Total loss': 0.29488042714175483}
2022-12-31 10:31:07,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:07,484 INFO:     Epoch: 46
2022-12-31 10:31:09,121 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4138879537582397, 'Total loss': 0.4138879537582397} | train loss {'Reaction outcome loss': 0.28357355789689725, 'Total loss': 0.28357355789689725}
2022-12-31 10:31:09,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:09,121 INFO:     Epoch: 47
2022-12-31 10:31:10,720 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4445699632167816, 'Total loss': 0.4445699632167816} | train loss {'Reaction outcome loss': 0.2840404540251441, 'Total loss': 0.2840404540251441}
2022-12-31 10:31:10,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:10,720 INFO:     Epoch: 48
2022-12-31 10:31:12,328 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3890993018945058, 'Total loss': 0.3890993018945058} | train loss {'Reaction outcome loss': 0.27959759757631336, 'Total loss': 0.27959759757631336}
2022-12-31 10:31:12,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:12,328 INFO:     Epoch: 49
2022-12-31 10:31:13,935 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39914220372835796, 'Total loss': 0.39914220372835796} | train loss {'Reaction outcome loss': 0.2797414750886568, 'Total loss': 0.2797414750886568}
2022-12-31 10:31:13,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:13,936 INFO:     Epoch: 50
2022-12-31 10:31:15,543 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40869164566198984, 'Total loss': 0.40869164566198984} | train loss {'Reaction outcome loss': 0.27953360617950396, 'Total loss': 0.27953360617950396}
2022-12-31 10:31:15,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:15,544 INFO:     Epoch: 51
2022-12-31 10:31:17,138 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42040002942085264, 'Total loss': 0.42040002942085264} | train loss {'Reaction outcome loss': 0.2715889676541522, 'Total loss': 0.2715889676541522}
2022-12-31 10:31:17,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:17,138 INFO:     Epoch: 52
2022-12-31 10:31:18,729 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.35337870518366493, 'Total loss': 0.35337870518366493} | train loss {'Reaction outcome loss': 0.2744616305728045, 'Total loss': 0.2744616305728045}
2022-12-31 10:31:18,729 INFO:     Found new best model at epoch 52
2022-12-31 10:31:18,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:18,730 INFO:     Epoch: 53
2022-12-31 10:31:20,338 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.36525779565175376, 'Total loss': 0.36525779565175376} | train loss {'Reaction outcome loss': 0.26654214817402966, 'Total loss': 0.26654214817402966}
2022-12-31 10:31:20,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:20,339 INFO:     Epoch: 54
2022-12-31 10:31:21,960 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40595469375451404, 'Total loss': 0.40595469375451404} | train loss {'Reaction outcome loss': 0.2623429858797243, 'Total loss': 0.2623429858797243}
2022-12-31 10:31:21,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:21,961 INFO:     Epoch: 55
2022-12-31 10:31:23,604 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.36436110933621724, 'Total loss': 0.36436110933621724} | train loss {'Reaction outcome loss': 0.2632429231428735, 'Total loss': 0.2632429231428735}
2022-12-31 10:31:23,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:23,605 INFO:     Epoch: 56
2022-12-31 10:31:25,254 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38952118046581746, 'Total loss': 0.38952118046581746} | train loss {'Reaction outcome loss': 0.2667730240745173, 'Total loss': 0.2667730240745173}
2022-12-31 10:31:25,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:25,254 INFO:     Epoch: 57
2022-12-31 10:31:26,869 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.38272260427474974, 'Total loss': 0.38272260427474974} | train loss {'Reaction outcome loss': 0.25803191699020134, 'Total loss': 0.25803191699020134}
2022-12-31 10:31:26,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:26,869 INFO:     Epoch: 58
2022-12-31 10:31:28,486 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.39842497458060583, 'Total loss': 0.39842497458060583} | train loss {'Reaction outcome loss': 0.2547752696310467, 'Total loss': 0.2547752696310467}
2022-12-31 10:31:28,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:28,486 INFO:     Epoch: 59
2022-12-31 10:31:30,099 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40542536477247876, 'Total loss': 0.40542536477247876} | train loss {'Reaction outcome loss': 0.2598812843460347, 'Total loss': 0.2598812843460347}
2022-12-31 10:31:30,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:30,100 INFO:     Epoch: 60
2022-12-31 10:31:31,709 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.39784258405367534, 'Total loss': 0.39784258405367534} | train loss {'Reaction outcome loss': 0.2543821636968262, 'Total loss': 0.2543821636968262}
2022-12-31 10:31:31,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:31,709 INFO:     Epoch: 61
2022-12-31 10:31:33,319 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.380769415696462, 'Total loss': 0.380769415696462} | train loss {'Reaction outcome loss': 0.2509994411772091, 'Total loss': 0.2509994411772091}
2022-12-31 10:31:33,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:33,320 INFO:     Epoch: 62
2022-12-31 10:31:34,916 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3670230428377787, 'Total loss': 0.3670230428377787} | train loss {'Reaction outcome loss': 0.24043617300196565, 'Total loss': 0.24043617300196565}
2022-12-31 10:31:34,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:34,917 INFO:     Epoch: 63
2022-12-31 10:31:36,563 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4052256921927134, 'Total loss': 0.4052256921927134} | train loss {'Reaction outcome loss': 0.2493993876285959, 'Total loss': 0.2493993876285959}
2022-12-31 10:31:36,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:36,563 INFO:     Epoch: 64
2022-12-31 10:31:38,198 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3918665851155917, 'Total loss': 0.3918665851155917} | train loss {'Reaction outcome loss': 0.24649994210399134, 'Total loss': 0.24649994210399134}
2022-12-31 10:31:38,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:38,198 INFO:     Epoch: 65
2022-12-31 10:31:39,807 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.470400129755338, 'Total loss': 0.470400129755338} | train loss {'Reaction outcome loss': 0.2493339106440544, 'Total loss': 0.2493339106440544}
2022-12-31 10:31:39,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:39,807 INFO:     Epoch: 66
2022-12-31 10:31:41,414 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.38887185156345366, 'Total loss': 0.38887185156345366} | train loss {'Reaction outcome loss': 0.32566462993555184, 'Total loss': 0.32566462993555184}
2022-12-31 10:31:41,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:41,414 INFO:     Epoch: 67
2022-12-31 10:31:43,022 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3976098865270615, 'Total loss': 0.3976098865270615} | train loss {'Reaction outcome loss': 0.24704843089419398, 'Total loss': 0.24704843089419398}
2022-12-31 10:31:43,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:43,022 INFO:     Epoch: 68
2022-12-31 10:31:44,630 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39565129230419793, 'Total loss': 0.39565129230419793} | train loss {'Reaction outcome loss': 0.23973208735106458, 'Total loss': 0.23973208735106458}
2022-12-31 10:31:44,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:44,631 INFO:     Epoch: 69
2022-12-31 10:31:46,234 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3853777209917704, 'Total loss': 0.3853777209917704} | train loss {'Reaction outcome loss': 0.2434550835379818, 'Total loss': 0.2434550835379818}
2022-12-31 10:31:46,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:46,235 INFO:     Epoch: 70
2022-12-31 10:31:47,881 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4082135438919067, 'Total loss': 0.4082135438919067} | train loss {'Reaction outcome loss': 0.23361278810045696, 'Total loss': 0.23361278810045696}
2022-12-31 10:31:47,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:47,881 INFO:     Epoch: 71
2022-12-31 10:31:49,497 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.37007067203521726, 'Total loss': 0.37007067203521726} | train loss {'Reaction outcome loss': 0.23738321425069286, 'Total loss': 0.23738321425069286}
2022-12-31 10:31:49,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:49,497 INFO:     Epoch: 72
2022-12-31 10:31:51,107 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3879399448633194, 'Total loss': 0.3879399448633194} | train loss {'Reaction outcome loss': 0.2408479311504134, 'Total loss': 0.2408479311504134}
2022-12-31 10:31:51,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:51,107 INFO:     Epoch: 73
2022-12-31 10:31:52,718 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4005766889390846, 'Total loss': 0.4005766889390846} | train loss {'Reaction outcome loss': 0.23557355217095735, 'Total loss': 0.23557355217095735}
2022-12-31 10:31:52,719 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:52,719 INFO:     Epoch: 74
2022-12-31 10:31:54,306 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40641202926635744, 'Total loss': 0.40641202926635744} | train loss {'Reaction outcome loss': 0.23169395666775308, 'Total loss': 0.23169395666775308}
2022-12-31 10:31:54,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:54,306 INFO:     Epoch: 75
2022-12-31 10:31:55,904 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41528545220692953, 'Total loss': 0.41528545220692953} | train loss {'Reaction outcome loss': 0.2253685749500342, 'Total loss': 0.2253685749500342}
2022-12-31 10:31:55,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:55,905 INFO:     Epoch: 76
2022-12-31 10:31:57,512 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3707798977692922, 'Total loss': 0.3707798977692922} | train loss {'Reaction outcome loss': 0.23066165844869355, 'Total loss': 0.23066165844869355}
2022-12-31 10:31:57,512 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:57,512 INFO:     Epoch: 77
2022-12-31 10:31:59,120 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4139082282781601, 'Total loss': 0.4139082282781601} | train loss {'Reaction outcome loss': 0.22680445637735724, 'Total loss': 0.22680445637735724}
2022-12-31 10:31:59,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:31:59,120 INFO:     Epoch: 78
2022-12-31 10:32:00,725 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.425149596730868, 'Total loss': 0.425149596730868} | train loss {'Reaction outcome loss': 0.2323553886777465, 'Total loss': 0.2323553886777465}
2022-12-31 10:32:00,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:00,725 INFO:     Epoch: 79
2022-12-31 10:32:02,313 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3741233264406522, 'Total loss': 0.3741233264406522} | train loss {'Reaction outcome loss': 0.2701591207389382, 'Total loss': 0.2701591207389382}
2022-12-31 10:32:02,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:02,314 INFO:     Epoch: 80
2022-12-31 10:32:03,929 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3690865675608317, 'Total loss': 0.3690865675608317} | train loss {'Reaction outcome loss': 0.24710939412909574, 'Total loss': 0.24710939412909574}
2022-12-31 10:32:03,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:03,929 INFO:     Epoch: 81
2022-12-31 10:32:05,558 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3954344814022382, 'Total loss': 0.3954344814022382} | train loss {'Reaction outcome loss': 0.25022561513427377, 'Total loss': 0.25022561513427377}
2022-12-31 10:32:05,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:05,559 INFO:     Epoch: 82
2022-12-31 10:32:07,174 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3865570763746897, 'Total loss': 0.3865570763746897} | train loss {'Reaction outcome loss': 0.2201061940800898, 'Total loss': 0.2201061940800898}
2022-12-31 10:32:07,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:07,175 INFO:     Epoch: 83
2022-12-31 10:32:08,790 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.39607809682687123, 'Total loss': 0.39607809682687123} | train loss {'Reaction outcome loss': 0.21906262948101832, 'Total loss': 0.21906262948101832}
2022-12-31 10:32:08,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:08,791 INFO:     Epoch: 84
2022-12-31 10:32:10,407 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.37793697516123453, 'Total loss': 0.37793697516123453} | train loss {'Reaction outcome loss': 0.22123001245579318, 'Total loss': 0.22123001245579318}
2022-12-31 10:32:10,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:10,407 INFO:     Epoch: 85
2022-12-31 10:32:12,006 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4429208695888519, 'Total loss': 0.4429208695888519} | train loss {'Reaction outcome loss': 0.22377225921145114, 'Total loss': 0.22377225921145114}
2022-12-31 10:32:12,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:12,006 INFO:     Epoch: 86
2022-12-31 10:32:13,614 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40253600974877674, 'Total loss': 0.40253600974877674} | train loss {'Reaction outcome loss': 0.2186847754696762, 'Total loss': 0.2186847754696762}
2022-12-31 10:32:13,614 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:13,614 INFO:     Epoch: 87
2022-12-31 10:32:15,233 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3983098189036051, 'Total loss': 0.3983098189036051} | train loss {'Reaction outcome loss': 0.21788446435870032, 'Total loss': 0.21788446435870032}
2022-12-31 10:32:15,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:15,233 INFO:     Epoch: 88
2022-12-31 10:32:16,841 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.370295645793279, 'Total loss': 0.370295645793279} | train loss {'Reaction outcome loss': 0.21920536150160394, 'Total loss': 0.21920536150160394}
2022-12-31 10:32:16,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:16,842 INFO:     Epoch: 89
2022-12-31 10:32:18,508 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38713854054609936, 'Total loss': 0.38713854054609936} | train loss {'Reaction outcome loss': 0.21286868205482978, 'Total loss': 0.21286868205482978}
2022-12-31 10:32:18,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:18,509 INFO:     Epoch: 90
2022-12-31 10:32:20,151 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3870840589205424, 'Total loss': 0.3870840589205424} | train loss {'Reaction outcome loss': 0.24474491258413342, 'Total loss': 0.24474491258413342}
2022-12-31 10:32:20,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:20,151 INFO:     Epoch: 91
2022-12-31 10:32:21,752 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39395650749405225, 'Total loss': 0.39395650749405225} | train loss {'Reaction outcome loss': 0.22743107112794372, 'Total loss': 0.22743107112794372}
2022-12-31 10:32:21,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:21,752 INFO:     Epoch: 92
2022-12-31 10:32:23,367 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.37645812928676603, 'Total loss': 0.37645812928676603} | train loss {'Reaction outcome loss': 0.22105978644938898, 'Total loss': 0.22105978644938898}
2022-12-31 10:32:23,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:23,368 INFO:     Epoch: 93
2022-12-31 10:32:25,020 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4319141944249471, 'Total loss': 0.4319141944249471} | train loss {'Reaction outcome loss': 0.25535258494040836, 'Total loss': 0.25535258494040836}
2022-12-31 10:32:25,020 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:25,020 INFO:     Epoch: 94
2022-12-31 10:32:26,676 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3993273119131724, 'Total loss': 0.3993273119131724} | train loss {'Reaction outcome loss': 0.21667802500778108, 'Total loss': 0.21667802500778108}
2022-12-31 10:32:26,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:26,676 INFO:     Epoch: 95
2022-12-31 10:32:28,336 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4314148023724556, 'Total loss': 0.4314148023724556} | train loss {'Reaction outcome loss': 0.2123190863386971, 'Total loss': 0.2123190863386971}
2022-12-31 10:32:28,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:28,337 INFO:     Epoch: 96
2022-12-31 10:32:29,986 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39054446717103325, 'Total loss': 0.39054446717103325} | train loss {'Reaction outcome loss': 0.21753099004812268, 'Total loss': 0.21753099004812268}
2022-12-31 10:32:29,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:29,986 INFO:     Epoch: 97
2022-12-31 10:32:31,620 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.38201649685700734, 'Total loss': 0.38201649685700734} | train loss {'Reaction outcome loss': 0.20698899789240913, 'Total loss': 0.20698899789240913}
2022-12-31 10:32:31,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:31,620 INFO:     Epoch: 98
2022-12-31 10:32:33,287 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4041691462198893, 'Total loss': 0.4041691462198893} | train loss {'Reaction outcome loss': 0.24828405734286577, 'Total loss': 0.24828405734286577}
2022-12-31 10:32:33,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:33,287 INFO:     Epoch: 99
2022-12-31 10:32:34,948 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.38001439174016316, 'Total loss': 0.38001439174016316} | train loss {'Reaction outcome loss': 0.21444224939846934, 'Total loss': 0.21444224939846934}
2022-12-31 10:32:34,948 INFO:     Best model found after epoch 53 of 100.
2022-12-31 10:32:34,948 INFO:   Done with stage: TRAINING
2022-12-31 10:32:34,948 INFO:   Starting stage: EVALUATION
2022-12-31 10:32:35,075 INFO:   Done with stage: EVALUATION
2022-12-31 10:32:35,075 INFO:   Leaving out SEQ value Fold_3
2022-12-31 10:32:35,088 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 10:32:35,088 INFO:   Starting stage: FEATURE SCALING
2022-12-31 10:32:35,730 INFO:   Done with stage: FEATURE SCALING
2022-12-31 10:32:35,731 INFO:   Starting stage: SCALING TARGETS
2022-12-31 10:32:35,800 INFO:   Done with stage: SCALING TARGETS
2022-12-31 10:32:35,800 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:32:35,800 INFO:     No hyperparam tuning for this model
2022-12-31 10:32:35,800 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:32:35,800 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 10:32:35,801 INFO:     None feature selector for col prot
2022-12-31 10:32:35,801 INFO:     None feature selector for col prot
2022-12-31 10:32:35,801 INFO:     None feature selector for col prot
2022-12-31 10:32:35,802 INFO:     None feature selector for col chem
2022-12-31 10:32:35,802 INFO:     None feature selector for col chem
2022-12-31 10:32:35,802 INFO:     None feature selector for col chem
2022-12-31 10:32:35,802 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 10:32:35,802 INFO:   Starting stage: BUILD MODEL
2022-12-31 10:32:35,804 INFO:     Number of params in model 223921
2022-12-31 10:32:35,807 INFO:   Done with stage: BUILD MODEL
2022-12-31 10:32:35,807 INFO:   Starting stage: TRAINING
2022-12-31 10:32:35,852 INFO:     Val loss before train {'Reaction outcome loss': 1.0342862526575725, 'Total loss': 1.0342862526575725}
2022-12-31 10:32:35,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:35,852 INFO:     Epoch: 0
2022-12-31 10:32:37,493 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6978145996729533, 'Total loss': 0.6978145996729533} | train loss {'Reaction outcome loss': 0.8157844313116738, 'Total loss': 0.8157844313116738}
2022-12-31 10:32:37,493 INFO:     Found new best model at epoch 0
2022-12-31 10:32:37,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:37,494 INFO:     Epoch: 1
2022-12-31 10:32:39,100 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5729037870963415, 'Total loss': 0.5729037870963415} | train loss {'Reaction outcome loss': 0.5977446252391452, 'Total loss': 0.5977446252391452}
2022-12-31 10:32:39,100 INFO:     Found new best model at epoch 1
2022-12-31 10:32:39,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:39,101 INFO:     Epoch: 2
2022-12-31 10:32:40,676 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.541225113471349, 'Total loss': 0.541225113471349} | train loss {'Reaction outcome loss': 0.5285310122992967, 'Total loss': 0.5285310122992967}
2022-12-31 10:32:40,677 INFO:     Found new best model at epoch 2
2022-12-31 10:32:40,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:40,678 INFO:     Epoch: 3
2022-12-31 10:32:42,281 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.53134512702624, 'Total loss': 0.53134512702624} | train loss {'Reaction outcome loss': 0.5071032747025892, 'Total loss': 0.5071032747025892}
2022-12-31 10:32:42,281 INFO:     Found new best model at epoch 3
2022-12-31 10:32:42,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:42,282 INFO:     Epoch: 4
2022-12-31 10:32:43,872 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5014103313287099, 'Total loss': 0.5014103313287099} | train loss {'Reaction outcome loss': 0.4876144626638392, 'Total loss': 0.4876144626638392}
2022-12-31 10:32:43,872 INFO:     Found new best model at epoch 4
2022-12-31 10:32:43,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:43,873 INFO:     Epoch: 5
2022-12-31 10:32:45,464 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5269676466782888, 'Total loss': 0.5269676466782888} | train loss {'Reaction outcome loss': 0.4801329228576723, 'Total loss': 0.4801329228576723}
2022-12-31 10:32:45,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:45,464 INFO:     Epoch: 6
2022-12-31 10:32:47,082 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.50033793648084, 'Total loss': 0.50033793648084} | train loss {'Reaction outcome loss': 0.4677661731020435, 'Total loss': 0.4677661731020435}
2022-12-31 10:32:47,083 INFO:     Found new best model at epoch 6
2022-12-31 10:32:47,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:47,084 INFO:     Epoch: 7
2022-12-31 10:32:48,675 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5030681649843852, 'Total loss': 0.5030681649843852} | train loss {'Reaction outcome loss': 0.4609979327235903, 'Total loss': 0.4609979327235903}
2022-12-31 10:32:48,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:48,675 INFO:     Epoch: 8
2022-12-31 10:32:50,255 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5065732638041178, 'Total loss': 0.5065732638041178} | train loss {'Reaction outcome loss': 0.4546299711033538, 'Total loss': 0.4546299711033538}
2022-12-31 10:32:50,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:50,256 INFO:     Epoch: 9
2022-12-31 10:32:51,846 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5176157504320145, 'Total loss': 0.5176157504320145} | train loss {'Reaction outcome loss': 0.44573439690437944, 'Total loss': 0.44573439690437944}
2022-12-31 10:32:51,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:51,846 INFO:     Epoch: 10
2022-12-31 10:32:53,436 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48685179750124613, 'Total loss': 0.48685179750124613} | train loss {'Reaction outcome loss': 0.44262458629660556, 'Total loss': 0.44262458629660556}
2022-12-31 10:32:53,437 INFO:     Found new best model at epoch 10
2022-12-31 10:32:53,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:53,437 INFO:     Epoch: 11
2022-12-31 10:32:55,028 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4705031782388687, 'Total loss': 0.4705031782388687} | train loss {'Reaction outcome loss': 0.43747456049744465, 'Total loss': 0.43747456049744465}
2022-12-31 10:32:55,028 INFO:     Found new best model at epoch 11
2022-12-31 10:32:55,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:55,029 INFO:     Epoch: 12
2022-12-31 10:32:56,599 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4791887124379476, 'Total loss': 0.4791887124379476} | train loss {'Reaction outcome loss': 0.4286086217606024, 'Total loss': 0.4286086217606024}
2022-12-31 10:32:56,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:56,600 INFO:     Epoch: 13
2022-12-31 10:32:58,174 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4887979378302892, 'Total loss': 0.4887979378302892} | train loss {'Reaction outcome loss': 0.4194533838020576, 'Total loss': 0.4194533838020576}
2022-12-31 10:32:58,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:58,174 INFO:     Epoch: 14
2022-12-31 10:32:59,786 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4603200614452362, 'Total loss': 0.4603200614452362} | train loss {'Reaction outcome loss': 0.41796919037570884, 'Total loss': 0.41796919037570884}
2022-12-31 10:32:59,786 INFO:     Found new best model at epoch 14
2022-12-31 10:32:59,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:32:59,787 INFO:     Epoch: 15
2022-12-31 10:33:01,384 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5059044043223063, 'Total loss': 0.5059044043223063} | train loss {'Reaction outcome loss': 0.41181591570704845, 'Total loss': 0.41181591570704845}
2022-12-31 10:33:01,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:01,385 INFO:     Epoch: 16
2022-12-31 10:33:03,033 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5093081414699554, 'Total loss': 0.5093081414699554} | train loss {'Reaction outcome loss': 0.4039862492691466, 'Total loss': 0.4039862492691466}
2022-12-31 10:33:03,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:03,034 INFO:     Epoch: 17
2022-12-31 10:33:04,681 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44321444630622864, 'Total loss': 0.44321444630622864} | train loss {'Reaction outcome loss': 0.4019799909585125, 'Total loss': 0.4019799909585125}
2022-12-31 10:33:04,682 INFO:     Found new best model at epoch 17
2022-12-31 10:33:04,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:04,683 INFO:     Epoch: 18
2022-12-31 10:33:06,258 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4594940721988678, 'Total loss': 0.4594940721988678} | train loss {'Reaction outcome loss': 0.39672999951865645, 'Total loss': 0.39672999951865645}
2022-12-31 10:33:06,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:06,259 INFO:     Epoch: 19
2022-12-31 10:33:07,837 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.453911351164182, 'Total loss': 0.453911351164182} | train loss {'Reaction outcome loss': 0.3921748281971657, 'Total loss': 0.3921748281971657}
2022-12-31 10:33:07,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:07,837 INFO:     Epoch: 20
2022-12-31 10:33:09,430 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46331513424714404, 'Total loss': 0.46331513424714404} | train loss {'Reaction outcome loss': 0.38471963182910457, 'Total loss': 0.38471963182910457}
2022-12-31 10:33:09,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:09,430 INFO:     Epoch: 21
2022-12-31 10:33:11,029 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4543263187011083, 'Total loss': 0.4543263187011083} | train loss {'Reaction outcome loss': 0.37924830309855634, 'Total loss': 0.37924830309855634}
2022-12-31 10:33:11,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:11,029 INFO:     Epoch: 22
2022-12-31 10:33:12,628 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.46319503684838614, 'Total loss': 0.46319503684838614} | train loss {'Reaction outcome loss': 0.3772078226883333, 'Total loss': 0.3772078226883333}
2022-12-31 10:33:12,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:12,629 INFO:     Epoch: 23
2022-12-31 10:33:14,226 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45611792206764223, 'Total loss': 0.45611792206764223} | train loss {'Reaction outcome loss': 0.3732668749933496, 'Total loss': 0.3732668749933496}
2022-12-31 10:33:14,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:14,226 INFO:     Epoch: 24
2022-12-31 10:33:15,833 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45202776889006296, 'Total loss': 0.45202776889006296} | train loss {'Reaction outcome loss': 0.3588719293475151, 'Total loss': 0.3588719293475151}
2022-12-31 10:33:15,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:15,833 INFO:     Epoch: 25
2022-12-31 10:33:17,426 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.43145708243052167, 'Total loss': 0.43145708243052167} | train loss {'Reaction outcome loss': 0.35707416820711707, 'Total loss': 0.35707416820711707}
2022-12-31 10:33:17,426 INFO:     Found new best model at epoch 25
2022-12-31 10:33:17,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:17,427 INFO:     Epoch: 26
2022-12-31 10:33:19,049 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45485021471977233, 'Total loss': 0.45485021471977233} | train loss {'Reaction outcome loss': 0.3556928412217797, 'Total loss': 0.3556928412217797}
2022-12-31 10:33:19,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:19,049 INFO:     Epoch: 27
2022-12-31 10:33:20,670 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.486587921778361, 'Total loss': 0.486587921778361} | train loss {'Reaction outcome loss': 0.3505420844879124, 'Total loss': 0.3505420844879124}
2022-12-31 10:33:20,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:20,671 INFO:     Epoch: 28
2022-12-31 10:33:22,302 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45616612235705056, 'Total loss': 0.45616612235705056} | train loss {'Reaction outcome loss': 0.3471828317303797, 'Total loss': 0.3471828317303797}
2022-12-31 10:33:22,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:22,302 INFO:     Epoch: 29
2022-12-31 10:33:23,912 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4122953494389852, 'Total loss': 0.4122953494389852} | train loss {'Reaction outcome loss': 0.34353634122854626, 'Total loss': 0.34353634122854626}
2022-12-31 10:33:23,912 INFO:     Found new best model at epoch 29
2022-12-31 10:33:23,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:23,913 INFO:     Epoch: 30
2022-12-31 10:33:25,501 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4303214430809021, 'Total loss': 0.4303214430809021} | train loss {'Reaction outcome loss': 0.3399844234843394, 'Total loss': 0.3399844234843394}
2022-12-31 10:33:25,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:25,501 INFO:     Epoch: 31
2022-12-31 10:33:27,119 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4295892372727394, 'Total loss': 0.4295892372727394} | train loss {'Reaction outcome loss': 0.341042534335629, 'Total loss': 0.341042534335629}
2022-12-31 10:33:27,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:27,119 INFO:     Epoch: 32
2022-12-31 10:33:28,712 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4320369929075241, 'Total loss': 0.4320369929075241} | train loss {'Reaction outcome loss': 0.3314436753809234, 'Total loss': 0.3314436753809234}
2022-12-31 10:33:28,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:28,712 INFO:     Epoch: 33
2022-12-31 10:33:30,348 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41704930663108825, 'Total loss': 0.41704930663108825} | train loss {'Reaction outcome loss': 0.3199249526192417, 'Total loss': 0.3199249526192417}
2022-12-31 10:33:30,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:30,349 INFO:     Epoch: 34
2022-12-31 10:33:31,948 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4230752170085907, 'Total loss': 0.4230752170085907} | train loss {'Reaction outcome loss': 0.32757836727650613, 'Total loss': 0.32757836727650613}
2022-12-31 10:33:31,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:31,949 INFO:     Epoch: 35
2022-12-31 10:33:33,536 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4371297796567281, 'Total loss': 0.4371297796567281} | train loss {'Reaction outcome loss': 0.3170022992587788, 'Total loss': 0.3170022992587788}
2022-12-31 10:33:33,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:33,536 INFO:     Epoch: 36
2022-12-31 10:33:35,125 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40769355396429696, 'Total loss': 0.40769355396429696} | train loss {'Reaction outcome loss': 0.3124601294460532, 'Total loss': 0.3124601294460532}
2022-12-31 10:33:35,125 INFO:     Found new best model at epoch 36
2022-12-31 10:33:35,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:35,126 INFO:     Epoch: 37
2022-12-31 10:33:36,722 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.44399320930242536, 'Total loss': 0.44399320930242536} | train loss {'Reaction outcome loss': 0.3117093917378139, 'Total loss': 0.3117093917378139}
2022-12-31 10:33:36,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:36,722 INFO:     Epoch: 38
2022-12-31 10:33:38,321 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4044427514076233, 'Total loss': 0.4044427514076233} | train loss {'Reaction outcome loss': 0.3121803929080893, 'Total loss': 0.3121803929080893}
2022-12-31 10:33:38,321 INFO:     Found new best model at epoch 38
2022-12-31 10:33:38,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:38,322 INFO:     Epoch: 39
2022-12-31 10:33:39,921 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45107375979423525, 'Total loss': 0.45107375979423525} | train loss {'Reaction outcome loss': 0.30978658714846813, 'Total loss': 0.30978658714846813}
2022-12-31 10:33:39,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:39,922 INFO:     Epoch: 40
2022-12-31 10:33:41,564 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40677067240079245, 'Total loss': 0.40677067240079245} | train loss {'Reaction outcome loss': 0.3059051139450772, 'Total loss': 0.3059051139450772}
2022-12-31 10:33:41,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:41,564 INFO:     Epoch: 41
2022-12-31 10:33:43,146 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40262857973575594, 'Total loss': 0.40262857973575594} | train loss {'Reaction outcome loss': 0.30526241429504897, 'Total loss': 0.30526241429504897}
2022-12-31 10:33:43,147 INFO:     Found new best model at epoch 41
2022-12-31 10:33:43,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:43,148 INFO:     Epoch: 42
2022-12-31 10:33:44,743 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40257834394772846, 'Total loss': 0.40257834394772846} | train loss {'Reaction outcome loss': 0.29410543219073787, 'Total loss': 0.29410543219073787}
2022-12-31 10:33:44,743 INFO:     Found new best model at epoch 42
2022-12-31 10:33:44,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:44,744 INFO:     Epoch: 43
2022-12-31 10:33:46,333 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44663532376289367, 'Total loss': 0.44663532376289367} | train loss {'Reaction outcome loss': 0.29438008282217626, 'Total loss': 0.29438008282217626}
2022-12-31 10:33:46,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:46,333 INFO:     Epoch: 44
2022-12-31 10:33:47,930 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3729402912159761, 'Total loss': 0.3729402912159761} | train loss {'Reaction outcome loss': 0.28628505092973894, 'Total loss': 0.28628505092973894}
2022-12-31 10:33:47,931 INFO:     Found new best model at epoch 44
2022-12-31 10:33:47,931 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:47,932 INFO:     Epoch: 45
2022-12-31 10:33:49,515 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45833068192005155, 'Total loss': 0.45833068192005155} | train loss {'Reaction outcome loss': 0.2866193772781463, 'Total loss': 0.2866193772781463}
2022-12-31 10:33:49,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:49,516 INFO:     Epoch: 46
2022-12-31 10:33:51,129 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43727075631419815, 'Total loss': 0.43727075631419815} | train loss {'Reaction outcome loss': 0.2897533406213526, 'Total loss': 0.2897533406213526}
2022-12-31 10:33:51,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:51,129 INFO:     Epoch: 47
2022-12-31 10:33:52,708 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.44030096928278606, 'Total loss': 0.44030096928278606} | train loss {'Reaction outcome loss': 0.2837576691620734, 'Total loss': 0.2837576691620734}
2022-12-31 10:33:52,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:52,708 INFO:     Epoch: 48
2022-12-31 10:33:54,309 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43330807288487755, 'Total loss': 0.43330807288487755} | train loss {'Reaction outcome loss': 0.2809145811112809, 'Total loss': 0.2809145811112809}
2022-12-31 10:33:54,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:54,310 INFO:     Epoch: 49
2022-12-31 10:33:55,901 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4145696332057317, 'Total loss': 0.4145696332057317} | train loss {'Reaction outcome loss': 0.27659013619025546, 'Total loss': 0.27659013619025546}
2022-12-31 10:33:55,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:55,902 INFO:     Epoch: 50
2022-12-31 10:33:57,496 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41546338399251304, 'Total loss': 0.41546338399251304} | train loss {'Reaction outcome loss': 0.26906089486056195, 'Total loss': 0.26906089486056195}
2022-12-31 10:33:57,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:57,496 INFO:     Epoch: 51
2022-12-31 10:33:59,097 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40916742781798043, 'Total loss': 0.40916742781798043} | train loss {'Reaction outcome loss': 0.2752975570413219, 'Total loss': 0.2752975570413219}
2022-12-31 10:33:59,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:33:59,097 INFO:     Epoch: 52
2022-12-31 10:34:00,676 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41961949268976845, 'Total loss': 0.41961949268976845} | train loss {'Reaction outcome loss': 0.27080717322590586, 'Total loss': 0.27080717322590586}
2022-12-31 10:34:00,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:00,676 INFO:     Epoch: 53
2022-12-31 10:34:02,255 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4075813223918279, 'Total loss': 0.4075813223918279} | train loss {'Reaction outcome loss': 0.26527117572097114, 'Total loss': 0.26527117572097114}
2022-12-31 10:34:02,256 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:02,256 INFO:     Epoch: 54
2022-12-31 10:34:03,905 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.47573643227418266, 'Total loss': 0.47573643227418266} | train loss {'Reaction outcome loss': 0.271037910809065, 'Total loss': 0.271037910809065}
2022-12-31 10:34:03,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:03,905 INFO:     Epoch: 55
2022-12-31 10:34:05,511 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43304397612810136, 'Total loss': 0.43304397612810136} | train loss {'Reaction outcome loss': 0.26677600261601775, 'Total loss': 0.26677600261601775}
2022-12-31 10:34:05,511 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:05,511 INFO:     Epoch: 56
2022-12-31 10:34:07,103 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44056195120016733, 'Total loss': 0.44056195120016733} | train loss {'Reaction outcome loss': 0.26786821649406417, 'Total loss': 0.26786821649406417}
2022-12-31 10:34:07,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:07,104 INFO:     Epoch: 57
2022-12-31 10:34:08,695 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3975766529639562, 'Total loss': 0.3975766529639562} | train loss {'Reaction outcome loss': 0.2584112034667106, 'Total loss': 0.2584112034667106}
2022-12-31 10:34:08,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:08,695 INFO:     Epoch: 58
2022-12-31 10:34:10,268 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41065602501233417, 'Total loss': 0.41065602501233417} | train loss {'Reaction outcome loss': 0.2622374502443896, 'Total loss': 0.2622374502443896}
2022-12-31 10:34:10,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:10,268 INFO:     Epoch: 59
2022-12-31 10:34:11,848 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39691934585571287, 'Total loss': 0.39691934585571287} | train loss {'Reaction outcome loss': 0.255173405338993, 'Total loss': 0.255173405338993}
2022-12-31 10:34:11,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:11,848 INFO:     Epoch: 60
2022-12-31 10:34:13,447 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4345815390348434, 'Total loss': 0.4345815390348434} | train loss {'Reaction outcome loss': 0.25124953316026555, 'Total loss': 0.25124953316026555}
2022-12-31 10:34:13,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:13,447 INFO:     Epoch: 61
2022-12-31 10:34:15,046 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4174366965889931, 'Total loss': 0.4174366965889931} | train loss {'Reaction outcome loss': 0.25513761860042156, 'Total loss': 0.25513761860042156}
2022-12-31 10:34:15,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:15,047 INFO:     Epoch: 62
2022-12-31 10:34:16,630 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4197035402059555, 'Total loss': 0.4197035402059555} | train loss {'Reaction outcome loss': 0.2562582887190602, 'Total loss': 0.2562582887190602}
2022-12-31 10:34:16,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:16,630 INFO:     Epoch: 63
2022-12-31 10:34:18,204 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39110970149437585, 'Total loss': 0.39110970149437585} | train loss {'Reaction outcome loss': 0.25172550104312846, 'Total loss': 0.25172550104312846}
2022-12-31 10:34:18,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:18,204 INFO:     Epoch: 64
2022-12-31 10:34:19,781 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4581785798072815, 'Total loss': 0.4581785798072815} | train loss {'Reaction outcome loss': 0.25205692623642995, 'Total loss': 0.25205692623642995}
2022-12-31 10:34:19,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:19,781 INFO:     Epoch: 65
2022-12-31 10:34:21,378 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4418272952238719, 'Total loss': 0.4418272952238719} | train loss {'Reaction outcome loss': 0.24390882278209206, 'Total loss': 0.24390882278209206}
2022-12-31 10:34:21,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:21,378 INFO:     Epoch: 66
2022-12-31 10:34:22,978 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.38441871404647826, 'Total loss': 0.38441871404647826} | train loss {'Reaction outcome loss': 0.24833090732474522, 'Total loss': 0.24833090732474522}
2022-12-31 10:34:22,978 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:22,978 INFO:     Epoch: 67
2022-12-31 10:34:24,578 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4138392021258672, 'Total loss': 0.4138392021258672} | train loss {'Reaction outcome loss': 0.24433110872686128, 'Total loss': 0.24433110872686128}
2022-12-31 10:34:24,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:24,579 INFO:     Epoch: 68
2022-12-31 10:34:26,179 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39220853547255197, 'Total loss': 0.39220853547255197} | train loss {'Reaction outcome loss': 0.2505762761615681, 'Total loss': 0.2505762761615681}
2022-12-31 10:34:26,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:26,181 INFO:     Epoch: 69
2022-12-31 10:34:27,751 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4210001120964686, 'Total loss': 0.4210001120964686} | train loss {'Reaction outcome loss': 0.24891325655297783, 'Total loss': 0.24891325655297783}
2022-12-31 10:34:27,751 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:27,751 INFO:     Epoch: 70
2022-12-31 10:34:29,331 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4089750021696091, 'Total loss': 0.4089750021696091} | train loss {'Reaction outcome loss': 0.23581719949445773, 'Total loss': 0.23581719949445773}
2022-12-31 10:34:29,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:29,331 INFO:     Epoch: 71
2022-12-31 10:34:30,927 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41903383831183116, 'Total loss': 0.41903383831183116} | train loss {'Reaction outcome loss': 0.2378467746188134, 'Total loss': 0.2378467746188134}
2022-12-31 10:34:30,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:30,927 INFO:     Epoch: 72
2022-12-31 10:34:32,523 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41914879679679873, 'Total loss': 0.41914879679679873} | train loss {'Reaction outcome loss': 0.2456268927171117, 'Total loss': 0.2456268927171117}
2022-12-31 10:34:32,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:32,524 INFO:     Epoch: 73
2022-12-31 10:34:34,120 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4060648744304975, 'Total loss': 0.4060648744304975} | train loss {'Reaction outcome loss': 0.23265557667247325, 'Total loss': 0.23265557667247325}
2022-12-31 10:34:34,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:34,120 INFO:     Epoch: 74
2022-12-31 10:34:35,716 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.36878079945842424, 'Total loss': 0.36878079945842424} | train loss {'Reaction outcome loss': 0.23700334458533442, 'Total loss': 0.23700334458533442}
2022-12-31 10:34:35,716 INFO:     Found new best model at epoch 74
2022-12-31 10:34:35,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:35,717 INFO:     Epoch: 75
2022-12-31 10:34:37,290 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4383746564388275, 'Total loss': 0.4383746564388275} | train loss {'Reaction outcome loss': 0.23278773675635184, 'Total loss': 0.23278773675635184}
2022-12-31 10:34:37,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:37,290 INFO:     Epoch: 76
2022-12-31 10:34:38,846 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.40467857122421264, 'Total loss': 0.40467857122421264} | train loss {'Reaction outcome loss': 0.23282471415160338, 'Total loss': 0.23282471415160338}
2022-12-31 10:34:38,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:38,846 INFO:     Epoch: 77
2022-12-31 10:34:40,478 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4223731319109599, 'Total loss': 0.4223731319109599} | train loss {'Reaction outcome loss': 0.2357142237339155, 'Total loss': 0.2357142237339155}
2022-12-31 10:34:40,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:40,479 INFO:     Epoch: 78
2022-12-31 10:34:42,107 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41172154744466144, 'Total loss': 0.41172154744466144} | train loss {'Reaction outcome loss': 0.23284465116158728, 'Total loss': 0.23284465116158728}
2022-12-31 10:34:42,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:42,107 INFO:     Epoch: 79
2022-12-31 10:34:43,726 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42240958859523137, 'Total loss': 0.42240958859523137} | train loss {'Reaction outcome loss': 0.23816882767083444, 'Total loss': 0.23816882767083444}
2022-12-31 10:34:43,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:43,726 INFO:     Epoch: 80
2022-12-31 10:34:45,306 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4558141102393468, 'Total loss': 0.4558141102393468} | train loss {'Reaction outcome loss': 0.2252025608751145, 'Total loss': 0.2252025608751145}
2022-12-31 10:34:45,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:45,307 INFO:     Epoch: 81
2022-12-31 10:34:46,889 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.38259683549404144, 'Total loss': 0.38259683549404144} | train loss {'Reaction outcome loss': 0.23445873004094367, 'Total loss': 0.23445873004094367}
2022-12-31 10:34:46,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:46,889 INFO:     Epoch: 82
2022-12-31 10:34:48,484 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4276927590370178, 'Total loss': 0.4276927590370178} | train loss {'Reaction outcome loss': 0.22646138151159217, 'Total loss': 0.22646138151159217}
2022-12-31 10:34:48,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:48,484 INFO:     Epoch: 83
2022-12-31 10:34:50,079 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40075618823369347, 'Total loss': 0.40075618823369347} | train loss {'Reaction outcome loss': 0.22641080906512318, 'Total loss': 0.22641080906512318}
2022-12-31 10:34:50,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:50,079 INFO:     Epoch: 84
2022-12-31 10:34:51,676 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47661280234654746, 'Total loss': 0.47661280234654746} | train loss {'Reaction outcome loss': 0.2239483160208979, 'Total loss': 0.2239483160208979}
2022-12-31 10:34:51,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:51,676 INFO:     Epoch: 85
2022-12-31 10:34:53,271 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3724966009457906, 'Total loss': 0.3724966009457906} | train loss {'Reaction outcome loss': 0.22381713387348276, 'Total loss': 0.22381713387348276}
2022-12-31 10:34:53,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:53,271 INFO:     Epoch: 86
2022-12-31 10:34:54,860 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4010749494036039, 'Total loss': 0.4010749494036039} | train loss {'Reaction outcome loss': 0.21934411038845886, 'Total loss': 0.21934411038845886}
2022-12-31 10:34:54,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:54,861 INFO:     Epoch: 87
2022-12-31 10:34:56,461 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41871182719866434, 'Total loss': 0.41871182719866434} | train loss {'Reaction outcome loss': 0.22688223779092342, 'Total loss': 0.22688223779092342}
2022-12-31 10:34:56,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:56,462 INFO:     Epoch: 88
2022-12-31 10:34:58,053 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41915163695812224, 'Total loss': 0.41915163695812224} | train loss {'Reaction outcome loss': 0.22440167355791227, 'Total loss': 0.22440167355791227}
2022-12-31 10:34:58,054 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:58,054 INFO:     Epoch: 89
2022-12-31 10:34:59,644 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43409400383631386, 'Total loss': 0.43409400383631386} | train loss {'Reaction outcome loss': 0.22044689333810039, 'Total loss': 0.22044689333810039}
2022-12-31 10:34:59,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:34:59,645 INFO:     Epoch: 90
2022-12-31 10:35:01,252 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.393570897479852, 'Total loss': 0.393570897479852} | train loss {'Reaction outcome loss': 0.20946558293350886, 'Total loss': 0.20946558293350886}
2022-12-31 10:35:01,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:01,253 INFO:     Epoch: 91
2022-12-31 10:35:02,910 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4583909610907237, 'Total loss': 0.4583909610907237} | train loss {'Reaction outcome loss': 0.2131469918435419, 'Total loss': 0.2131469918435419}
2022-12-31 10:35:02,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:02,910 INFO:     Epoch: 92
2022-12-31 10:35:04,482 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40128010970850786, 'Total loss': 0.40128010970850786} | train loss {'Reaction outcome loss': 0.2060711872610417, 'Total loss': 0.2060711872610417}
2022-12-31 10:35:04,483 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:04,483 INFO:     Epoch: 93
2022-12-31 10:35:06,065 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3857628266016642, 'Total loss': 0.3857628266016642} | train loss {'Reaction outcome loss': 0.2271793556055088, 'Total loss': 0.2271793556055088}
2022-12-31 10:35:06,065 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:06,065 INFO:     Epoch: 94
2022-12-31 10:35:07,663 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42202204118172326, 'Total loss': 0.42202204118172326} | train loss {'Reaction outcome loss': 0.21262846297615176, 'Total loss': 0.21262846297615176}
2022-12-31 10:35:07,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:07,664 INFO:     Epoch: 95
2022-12-31 10:35:09,260 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44515039324760436, 'Total loss': 0.44515039324760436} | train loss {'Reaction outcome loss': 0.22066477101446288, 'Total loss': 0.22066477101446288}
2022-12-31 10:35:09,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:09,260 INFO:     Epoch: 96
2022-12-31 10:35:10,857 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3895279804865519, 'Total loss': 0.3895279804865519} | train loss {'Reaction outcome loss': 0.22046667254178515, 'Total loss': 0.22046667254178515}
2022-12-31 10:35:10,857 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:10,857 INFO:     Epoch: 97
2022-12-31 10:35:12,440 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.38676779766877495, 'Total loss': 0.38676779766877495} | train loss {'Reaction outcome loss': 0.2127949005681953, 'Total loss': 0.2127949005681953}
2022-12-31 10:35:12,440 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:12,440 INFO:     Epoch: 98
2022-12-31 10:35:14,016 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42048617601394656, 'Total loss': 0.42048617601394656} | train loss {'Reaction outcome loss': 0.2125779173981685, 'Total loss': 0.2125779173981685}
2022-12-31 10:35:14,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:14,017 INFO:     Epoch: 99
2022-12-31 10:35:15,616 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3987579021602869, 'Total loss': 0.3987579021602869} | train loss {'Reaction outcome loss': 0.20865496224126753, 'Total loss': 0.20865496224126753}
2022-12-31 10:35:15,616 INFO:     Best model found after epoch 75 of 100.
2022-12-31 10:35:15,616 INFO:   Done with stage: TRAINING
2022-12-31 10:35:15,616 INFO:   Starting stage: EVALUATION
2022-12-31 10:35:15,755 INFO:   Done with stage: EVALUATION
2022-12-31 10:35:15,755 INFO:   Leaving out SEQ value Fold_4
2022-12-31 10:35:15,768 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 10:35:15,768 INFO:   Starting stage: FEATURE SCALING
2022-12-31 10:35:16,409 INFO:   Done with stage: FEATURE SCALING
2022-12-31 10:35:16,409 INFO:   Starting stage: SCALING TARGETS
2022-12-31 10:35:16,478 INFO:   Done with stage: SCALING TARGETS
2022-12-31 10:35:16,478 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:35:16,478 INFO:     No hyperparam tuning for this model
2022-12-31 10:35:16,478 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:35:16,478 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 10:35:16,479 INFO:     None feature selector for col prot
2022-12-31 10:35:16,479 INFO:     None feature selector for col prot
2022-12-31 10:35:16,479 INFO:     None feature selector for col prot
2022-12-31 10:35:16,480 INFO:     None feature selector for col chem
2022-12-31 10:35:16,480 INFO:     None feature selector for col chem
2022-12-31 10:35:16,480 INFO:     None feature selector for col chem
2022-12-31 10:35:16,480 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 10:35:16,480 INFO:   Starting stage: BUILD MODEL
2022-12-31 10:35:16,482 INFO:     Number of params in model 223921
2022-12-31 10:35:16,486 INFO:   Done with stage: BUILD MODEL
2022-12-31 10:35:16,486 INFO:   Starting stage: TRAINING
2022-12-31 10:35:16,531 INFO:     Val loss before train {'Reaction outcome loss': 1.0430501381556192, 'Total loss': 1.0430501381556192}
2022-12-31 10:35:16,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:16,531 INFO:     Epoch: 0
2022-12-31 10:35:18,153 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7322990695635477, 'Total loss': 0.7322990695635477} | train loss {'Reaction outcome loss': 0.8365137650217821, 'Total loss': 0.8365137650217821}
2022-12-31 10:35:18,153 INFO:     Found new best model at epoch 0
2022-12-31 10:35:18,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:18,154 INFO:     Epoch: 1
2022-12-31 10:35:19,776 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5818740010261536, 'Total loss': 0.5818740010261536} | train loss {'Reaction outcome loss': 0.6173412976820116, 'Total loss': 0.6173412976820116}
2022-12-31 10:35:19,776 INFO:     Found new best model at epoch 1
2022-12-31 10:35:19,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:19,777 INFO:     Epoch: 2
2022-12-31 10:35:21,374 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5689982175827026, 'Total loss': 0.5689982175827026} | train loss {'Reaction outcome loss': 0.5395315890923303, 'Total loss': 0.5395315890923303}
2022-12-31 10:35:21,374 INFO:     Found new best model at epoch 2
2022-12-31 10:35:21,375 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:21,375 INFO:     Epoch: 3
2022-12-31 10:35:22,470 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5342596411705017, 'Total loss': 0.5342596411705017} | train loss {'Reaction outcome loss': 0.5135455618911702, 'Total loss': 0.5135455618911702}
2022-12-31 10:35:22,470 INFO:     Found new best model at epoch 3
2022-12-31 10:35:22,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:22,471 INFO:     Epoch: 4
2022-12-31 10:35:23,544 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5221754968166351, 'Total loss': 0.5221754968166351} | train loss {'Reaction outcome loss': 0.4963402867532379, 'Total loss': 0.4963402867532379}
2022-12-31 10:35:23,544 INFO:     Found new best model at epoch 4
2022-12-31 10:35:23,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:23,545 INFO:     Epoch: 5
2022-12-31 10:35:24,619 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5476654311021169, 'Total loss': 0.5476654311021169} | train loss {'Reaction outcome loss': 0.48739116571655344, 'Total loss': 0.48739116571655344}
2022-12-31 10:35:24,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:24,619 INFO:     Epoch: 6
2022-12-31 10:35:25,689 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5328689893086751, 'Total loss': 0.5328689893086751} | train loss {'Reaction outcome loss': 0.47457500146399334, 'Total loss': 0.47457500146399334}
2022-12-31 10:35:25,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:25,689 INFO:     Epoch: 7
2022-12-31 10:35:27,211 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5087745452920596, 'Total loss': 0.5087745452920596} | train loss {'Reaction outcome loss': 0.46822640095376794, 'Total loss': 0.46822640095376794}
2022-12-31 10:35:27,211 INFO:     Found new best model at epoch 7
2022-12-31 10:35:27,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:27,212 INFO:     Epoch: 8
2022-12-31 10:35:28,829 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5343105077743531, 'Total loss': 0.5343105077743531} | train loss {'Reaction outcome loss': 0.4585825811116704, 'Total loss': 0.4585825811116704}
2022-12-31 10:35:28,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:28,830 INFO:     Epoch: 9
2022-12-31 10:35:30,458 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5134937802950541, 'Total loss': 0.5134937802950541} | train loss {'Reaction outcome loss': 0.4556970693144127, 'Total loss': 0.4556970693144127}
2022-12-31 10:35:30,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:30,458 INFO:     Epoch: 10
2022-12-31 10:35:32,141 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4957034607728322, 'Total loss': 0.4957034607728322} | train loss {'Reaction outcome loss': 0.44541785274279244, 'Total loss': 0.44541785274279244}
2022-12-31 10:35:32,141 INFO:     Found new best model at epoch 10
2022-12-31 10:35:32,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:32,142 INFO:     Epoch: 11
2022-12-31 10:35:33,818 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49850389957427976, 'Total loss': 0.49850389957427976} | train loss {'Reaction outcome loss': 0.44086112797475463, 'Total loss': 0.44086112797475463}
2022-12-31 10:35:33,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:33,819 INFO:     Epoch: 12
2022-12-31 10:35:35,451 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5196528851985931, 'Total loss': 0.5196528851985931} | train loss {'Reaction outcome loss': 0.43568829406684917, 'Total loss': 0.43568829406684917}
2022-12-31 10:35:35,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:35,451 INFO:     Epoch: 13
2022-12-31 10:35:37,117 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4909971704085668, 'Total loss': 0.4909971704085668} | train loss {'Reaction outcome loss': 0.4315713561452683, 'Total loss': 0.4315713561452683}
2022-12-31 10:35:37,117 INFO:     Found new best model at epoch 13
2022-12-31 10:35:37,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:37,118 INFO:     Epoch: 14
2022-12-31 10:35:38,768 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4874205122391383, 'Total loss': 0.4874205122391383} | train loss {'Reaction outcome loss': 0.42323245866634357, 'Total loss': 0.42323245866634357}
2022-12-31 10:35:38,768 INFO:     Found new best model at epoch 14
2022-12-31 10:35:38,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:38,770 INFO:     Epoch: 15
2022-12-31 10:35:40,421 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4901160180568695, 'Total loss': 0.4901160180568695} | train loss {'Reaction outcome loss': 0.41640076012979343, 'Total loss': 0.41640076012979343}
2022-12-31 10:35:40,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:40,422 INFO:     Epoch: 16
2022-12-31 10:35:42,075 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4649754802385966, 'Total loss': 0.4649754802385966} | train loss {'Reaction outcome loss': 0.41068660590246264, 'Total loss': 0.41068660590246264}
2022-12-31 10:35:42,075 INFO:     Found new best model at epoch 16
2022-12-31 10:35:42,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:42,076 INFO:     Epoch: 17
2022-12-31 10:35:43,730 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4738578379154205, 'Total loss': 0.4738578379154205} | train loss {'Reaction outcome loss': 0.4028870130650403, 'Total loss': 0.4028870130650403}
2022-12-31 10:35:43,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:43,730 INFO:     Epoch: 18
2022-12-31 10:35:45,362 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4682653695344925, 'Total loss': 0.4682653695344925} | train loss {'Reaction outcome loss': 0.3969234458644898, 'Total loss': 0.3969234458644898}
2022-12-31 10:35:45,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:45,362 INFO:     Epoch: 19
2022-12-31 10:35:47,019 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48058908581733706, 'Total loss': 0.48058908581733706} | train loss {'Reaction outcome loss': 0.39616499004704, 'Total loss': 0.39616499004704}
2022-12-31 10:35:47,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:47,019 INFO:     Epoch: 20
2022-12-31 10:35:48,631 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46601725816726686, 'Total loss': 0.46601725816726686} | train loss {'Reaction outcome loss': 0.38708689502215127, 'Total loss': 0.38708689502215127}
2022-12-31 10:35:48,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:48,631 INFO:     Epoch: 21
2022-12-31 10:35:50,245 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46023560166358946, 'Total loss': 0.46023560166358946} | train loss {'Reaction outcome loss': 0.3867417666724873, 'Total loss': 0.3867417666724873}
2022-12-31 10:35:50,245 INFO:     Found new best model at epoch 21
2022-12-31 10:35:50,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:50,246 INFO:     Epoch: 22
2022-12-31 10:35:51,873 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5120581696430843, 'Total loss': 0.5120581696430843} | train loss {'Reaction outcome loss': 0.3823836899567597, 'Total loss': 0.3823836899567597}
2022-12-31 10:35:51,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:51,873 INFO:     Epoch: 23
2022-12-31 10:35:53,514 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.471485165754954, 'Total loss': 0.471485165754954} | train loss {'Reaction outcome loss': 0.36699839931532796, 'Total loss': 0.36699839931532796}
2022-12-31 10:35:53,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:53,515 INFO:     Epoch: 24
2022-12-31 10:35:55,157 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4826381673415502, 'Total loss': 0.4826381673415502} | train loss {'Reaction outcome loss': 0.37008133288540135, 'Total loss': 0.37008133288540135}
2022-12-31 10:35:55,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:55,157 INFO:     Epoch: 25
2022-12-31 10:35:56,796 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4530177007118861, 'Total loss': 0.4530177007118861} | train loss {'Reaction outcome loss': 0.36307529482439105, 'Total loss': 0.36307529482439105}
2022-12-31 10:35:56,797 INFO:     Found new best model at epoch 25
2022-12-31 10:35:56,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:56,797 INFO:     Epoch: 26
2022-12-31 10:35:58,400 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4439632068077723, 'Total loss': 0.4439632068077723} | train loss {'Reaction outcome loss': 0.356922552500606, 'Total loss': 0.356922552500606}
2022-12-31 10:35:58,400 INFO:     Found new best model at epoch 26
2022-12-31 10:35:58,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:35:58,401 INFO:     Epoch: 27
2022-12-31 10:36:00,021 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.48918049136797587, 'Total loss': 0.48918049136797587} | train loss {'Reaction outcome loss': 0.34953908659921223, 'Total loss': 0.34953908659921223}
2022-12-31 10:36:00,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:00,021 INFO:     Epoch: 28
2022-12-31 10:36:01,646 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4533543586730957, 'Total loss': 0.4533543586730957} | train loss {'Reaction outcome loss': 0.35189966534664485, 'Total loss': 0.35189966534664485}
2022-12-31 10:36:01,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:01,646 INFO:     Epoch: 29
2022-12-31 10:36:03,245 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42880258957544964, 'Total loss': 0.42880258957544964} | train loss {'Reaction outcome loss': 0.344417317894822, 'Total loss': 0.344417317894822}
2022-12-31 10:36:03,246 INFO:     Found new best model at epoch 29
2022-12-31 10:36:03,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:03,247 INFO:     Epoch: 30
2022-12-31 10:36:04,896 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47397083838780724, 'Total loss': 0.47397083838780724} | train loss {'Reaction outcome loss': 0.3376416012590973, 'Total loss': 0.3376416012590973}
2022-12-31 10:36:04,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:04,896 INFO:     Epoch: 31
2022-12-31 10:36:06,534 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46610040863355, 'Total loss': 0.46610040863355} | train loss {'Reaction outcome loss': 0.3268896476079841, 'Total loss': 0.3268896476079841}
2022-12-31 10:36:06,534 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:06,534 INFO:     Epoch: 32
2022-12-31 10:36:08,209 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4869983494281769, 'Total loss': 0.4869983494281769} | train loss {'Reaction outcome loss': 0.32644926119151957, 'Total loss': 0.32644926119151957}
2022-12-31 10:36:08,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:08,209 INFO:     Epoch: 33
2022-12-31 10:36:09,834 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41752847532431286, 'Total loss': 0.41752847532431286} | train loss {'Reaction outcome loss': 0.3226346063699963, 'Total loss': 0.3226346063699963}
2022-12-31 10:36:09,835 INFO:     Found new best model at epoch 33
2022-12-31 10:36:09,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:09,836 INFO:     Epoch: 34
2022-12-31 10:36:11,454 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4628449857234955, 'Total loss': 0.4628449857234955} | train loss {'Reaction outcome loss': 0.3179502653946515, 'Total loss': 0.3179502653946515}
2022-12-31 10:36:11,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:11,454 INFO:     Epoch: 35
2022-12-31 10:36:13,055 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42201634248097736, 'Total loss': 0.42201634248097736} | train loss {'Reaction outcome loss': 0.31404573967956034, 'Total loss': 0.31404573967956034}
2022-12-31 10:36:13,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:13,055 INFO:     Epoch: 36
2022-12-31 10:36:14,668 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.412656964858373, 'Total loss': 0.412656964858373} | train loss {'Reaction outcome loss': 0.3128177804018401, 'Total loss': 0.3128177804018401}
2022-12-31 10:36:14,668 INFO:     Found new best model at epoch 36
2022-12-31 10:36:14,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:14,669 INFO:     Epoch: 37
2022-12-31 10:36:16,268 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4149826924006144, 'Total loss': 0.4149826924006144} | train loss {'Reaction outcome loss': 0.3022889699854145, 'Total loss': 0.3022889699854145}
2022-12-31 10:36:16,269 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:16,269 INFO:     Epoch: 38
2022-12-31 10:36:17,883 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43282803893089294, 'Total loss': 0.43282803893089294} | train loss {'Reaction outcome loss': 0.3122301406566632, 'Total loss': 0.3122301406566632}
2022-12-31 10:36:17,883 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:17,884 INFO:     Epoch: 39
2022-12-31 10:36:19,496 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4112976104021072, 'Total loss': 0.4112976104021072} | train loss {'Reaction outcome loss': 0.29938126847632096, 'Total loss': 0.29938126847632096}
2022-12-31 10:36:19,496 INFO:     Found new best model at epoch 39
2022-12-31 10:36:19,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:19,497 INFO:     Epoch: 40
2022-12-31 10:36:21,136 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4254662354787191, 'Total loss': 0.4254662354787191} | train loss {'Reaction outcome loss': 0.29597505639283667, 'Total loss': 0.29597505639283667}
2022-12-31 10:36:21,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:21,136 INFO:     Epoch: 41
2022-12-31 10:36:22,804 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4247135172287623, 'Total loss': 0.4247135172287623} | train loss {'Reaction outcome loss': 0.2987983431465359, 'Total loss': 0.2987983431465359}
2022-12-31 10:36:22,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:22,804 INFO:     Epoch: 42
2022-12-31 10:36:24,439 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44041091899077095, 'Total loss': 0.44041091899077095} | train loss {'Reaction outcome loss': 0.29687922447919846, 'Total loss': 0.29687922447919846}
2022-12-31 10:36:24,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:24,439 INFO:     Epoch: 43
2022-12-31 10:36:26,100 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42584434946378075, 'Total loss': 0.42584434946378075} | train loss {'Reaction outcome loss': 0.2874012494237845, 'Total loss': 0.2874012494237845}
2022-12-31 10:36:26,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:26,101 INFO:     Epoch: 44
2022-12-31 10:36:27,775 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41181385616461436, 'Total loss': 0.41181385616461436} | train loss {'Reaction outcome loss': 0.2836344198118694, 'Total loss': 0.2836344198118694}
2022-12-31 10:36:27,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:27,775 INFO:     Epoch: 45
2022-12-31 10:36:29,453 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41454710960388186, 'Total loss': 0.41454710960388186} | train loss {'Reaction outcome loss': 0.2852034323751281, 'Total loss': 0.2852034323751281}
2022-12-31 10:36:29,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:29,454 INFO:     Epoch: 46
2022-12-31 10:36:31,077 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42836911280949913, 'Total loss': 0.42836911280949913} | train loss {'Reaction outcome loss': 0.276613929023166, 'Total loss': 0.276613929023166}
2022-12-31 10:36:31,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:31,078 INFO:     Epoch: 47
2022-12-31 10:36:32,740 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4063463499148687, 'Total loss': 0.4063463499148687} | train loss {'Reaction outcome loss': 0.28186439464561347, 'Total loss': 0.28186439464561347}
2022-12-31 10:36:32,740 INFO:     Found new best model at epoch 47
2022-12-31 10:36:32,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:32,741 INFO:     Epoch: 48
2022-12-31 10:36:34,363 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41089366873105365, 'Total loss': 0.41089366873105365} | train loss {'Reaction outcome loss': 0.2765160658218585, 'Total loss': 0.2765160658218585}
2022-12-31 10:36:34,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:34,364 INFO:     Epoch: 49
2022-12-31 10:36:35,981 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42830604016780854, 'Total loss': 0.42830604016780854} | train loss {'Reaction outcome loss': 0.276789159725827, 'Total loss': 0.276789159725827}
2022-12-31 10:36:35,982 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:35,982 INFO:     Epoch: 50
2022-12-31 10:36:37,601 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41968296269575756, 'Total loss': 0.41968296269575756} | train loss {'Reaction outcome loss': 0.26778690849131626, 'Total loss': 0.26778690849131626}
2022-12-31 10:36:37,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:37,601 INFO:     Epoch: 51
2022-12-31 10:36:39,199 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4410891205072403, 'Total loss': 0.4410891205072403} | train loss {'Reaction outcome loss': 0.266315400862683, 'Total loss': 0.266315400862683}
2022-12-31 10:36:39,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:39,199 INFO:     Epoch: 52
2022-12-31 10:36:40,814 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.38865635097026824, 'Total loss': 0.38865635097026824} | train loss {'Reaction outcome loss': 0.2718688998142735, 'Total loss': 0.2718688998142735}
2022-12-31 10:36:40,814 INFO:     Found new best model at epoch 52
2022-12-31 10:36:40,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:40,815 INFO:     Epoch: 53
2022-12-31 10:36:42,422 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4282584011554718, 'Total loss': 0.4282584011554718} | train loss {'Reaction outcome loss': 0.2676596812070062, 'Total loss': 0.2676596812070062}
2022-12-31 10:36:42,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:42,422 INFO:     Epoch: 54
2022-12-31 10:36:44,034 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.452316098411878, 'Total loss': 0.452316098411878} | train loss {'Reaction outcome loss': 0.2656806958603945, 'Total loss': 0.2656806958603945}
2022-12-31 10:36:44,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:44,034 INFO:     Epoch: 55
2022-12-31 10:36:45,650 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4321401278177897, 'Total loss': 0.4321401278177897} | train loss {'Reaction outcome loss': 0.2570971149399823, 'Total loss': 0.2570971149399823}
2022-12-31 10:36:45,651 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:45,651 INFO:     Epoch: 56
2022-12-31 10:36:47,266 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4338669280211131, 'Total loss': 0.4338669280211131} | train loss {'Reaction outcome loss': 0.25430898574123745, 'Total loss': 0.25430898574123745}
2022-12-31 10:36:47,266 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:47,266 INFO:     Epoch: 57
2022-12-31 10:36:48,880 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4078033904234568, 'Total loss': 0.4078033904234568} | train loss {'Reaction outcome loss': 0.2573610120503373, 'Total loss': 0.2573610120503373}
2022-12-31 10:36:48,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:48,881 INFO:     Epoch: 58
2022-12-31 10:36:50,502 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.42538670003414153, 'Total loss': 0.42538670003414153} | train loss {'Reaction outcome loss': 0.2604286199240586, 'Total loss': 0.2604286199240586}
2022-12-31 10:36:50,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:50,503 INFO:     Epoch: 59
2022-12-31 10:36:52,111 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4365380644798279, 'Total loss': 0.4365380644798279} | train loss {'Reaction outcome loss': 0.2510200856314024, 'Total loss': 0.2510200856314024}
2022-12-31 10:36:52,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:52,112 INFO:     Epoch: 60
2022-12-31 10:36:53,729 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40452664544185, 'Total loss': 0.40452664544185} | train loss {'Reaction outcome loss': 0.2546077484016169, 'Total loss': 0.2546077484016169}
2022-12-31 10:36:53,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:53,729 INFO:     Epoch: 61
2022-12-31 10:36:55,347 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4335202972094218, 'Total loss': 0.4335202972094218} | train loss {'Reaction outcome loss': 0.25122765097968847, 'Total loss': 0.25122765097968847}
2022-12-31 10:36:55,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:55,347 INFO:     Epoch: 62
2022-12-31 10:36:56,965 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40030510624249777, 'Total loss': 0.40030510624249777} | train loss {'Reaction outcome loss': 0.24811238179568348, 'Total loss': 0.24811238179568348}
2022-12-31 10:36:56,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:56,965 INFO:     Epoch: 63
2022-12-31 10:36:58,607 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39573367734750114, 'Total loss': 0.39573367734750114} | train loss {'Reaction outcome loss': 0.25252381661093193, 'Total loss': 0.25252381661093193}
2022-12-31 10:36:58,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:36:58,607 INFO:     Epoch: 64
2022-12-31 10:37:00,245 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46204545100529987, 'Total loss': 0.46204545100529987} | train loss {'Reaction outcome loss': 0.2411440606649279, 'Total loss': 0.2411440606649279}
2022-12-31 10:37:00,245 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:00,246 INFO:     Epoch: 65
2022-12-31 10:37:01,844 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39221295018990837, 'Total loss': 0.39221295018990837} | train loss {'Reaction outcome loss': 0.24426124121200307, 'Total loss': 0.24426124121200307}
2022-12-31 10:37:01,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:01,845 INFO:     Epoch: 66
2022-12-31 10:37:03,462 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3942466934521993, 'Total loss': 0.3942466934521993} | train loss {'Reaction outcome loss': 0.23634732844113013, 'Total loss': 0.23634732844113013}
2022-12-31 10:37:03,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:03,462 INFO:     Epoch: 67
2022-12-31 10:37:05,080 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4056845188140869, 'Total loss': 0.4056845188140869} | train loss {'Reaction outcome loss': 0.24272077106988388, 'Total loss': 0.24272077106988388}
2022-12-31 10:37:05,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:05,081 INFO:     Epoch: 68
2022-12-31 10:37:06,676 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.38326549033323926, 'Total loss': 0.38326549033323926} | train loss {'Reaction outcome loss': 0.24300256524813305, 'Total loss': 0.24300256524813305}
2022-12-31 10:37:06,676 INFO:     Found new best model at epoch 68
2022-12-31 10:37:06,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:06,677 INFO:     Epoch: 69
2022-12-31 10:37:08,292 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4100268125534058, 'Total loss': 0.4100268125534058} | train loss {'Reaction outcome loss': 0.23311587123180125, 'Total loss': 0.23311587123180125}
2022-12-31 10:37:08,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:08,292 INFO:     Epoch: 70
2022-12-31 10:37:09,889 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40593270858128866, 'Total loss': 0.40593270858128866} | train loss {'Reaction outcome loss': 0.23986412771718596, 'Total loss': 0.23986412771718596}
2022-12-31 10:37:09,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:09,889 INFO:     Epoch: 71
2022-12-31 10:37:11,506 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42565444906552635, 'Total loss': 0.42565444906552635} | train loss {'Reaction outcome loss': 0.2411962108088099, 'Total loss': 0.2411962108088099}
2022-12-31 10:37:11,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:11,507 INFO:     Epoch: 72
2022-12-31 10:37:13,183 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4436424920956294, 'Total loss': 0.4436424920956294} | train loss {'Reaction outcome loss': 0.22907244350882214, 'Total loss': 0.22907244350882214}
2022-12-31 10:37:13,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:13,183 INFO:     Epoch: 73
2022-12-31 10:37:14,846 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41803219815095266, 'Total loss': 0.41803219815095266} | train loss {'Reaction outcome loss': 0.2347479433439914, 'Total loss': 0.2347479433439914}
2022-12-31 10:37:14,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:14,846 INFO:     Epoch: 74
2022-12-31 10:37:16,450 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43404589891433715, 'Total loss': 0.43404589891433715} | train loss {'Reaction outcome loss': 0.2314436586190432, 'Total loss': 0.2314436586190432}
2022-12-31 10:37:16,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:16,450 INFO:     Epoch: 75
2022-12-31 10:37:18,070 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4269176741441091, 'Total loss': 0.4269176741441091} | train loss {'Reaction outcome loss': 0.22502315330860417, 'Total loss': 0.22502315330860417}
2022-12-31 10:37:18,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:18,071 INFO:     Epoch: 76
2022-12-31 10:37:19,691 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.37421190142631533, 'Total loss': 0.37421190142631533} | train loss {'Reaction outcome loss': 0.23060345408315047, 'Total loss': 0.23060345408315047}
2022-12-31 10:37:19,691 INFO:     Found new best model at epoch 76
2022-12-31 10:37:19,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:19,692 INFO:     Epoch: 77
2022-12-31 10:37:21,311 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40246034463246666, 'Total loss': 0.40246034463246666} | train loss {'Reaction outcome loss': 0.2312924638659515, 'Total loss': 0.2312924638659515}
2022-12-31 10:37:21,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:21,312 INFO:     Epoch: 78
2022-12-31 10:37:22,928 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43019950985908506, 'Total loss': 0.43019950985908506} | train loss {'Reaction outcome loss': 0.22540701350822562, 'Total loss': 0.22540701350822562}
2022-12-31 10:37:22,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:22,929 INFO:     Epoch: 79
2022-12-31 10:37:24,522 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40184401869773867, 'Total loss': 0.40184401869773867} | train loss {'Reaction outcome loss': 0.2297507509831272, 'Total loss': 0.2297507509831272}
2022-12-31 10:37:24,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:24,523 INFO:     Epoch: 80
2022-12-31 10:37:26,200 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3968652546405792, 'Total loss': 0.3968652546405792} | train loss {'Reaction outcome loss': 0.22138219985720914, 'Total loss': 0.22138219985720914}
2022-12-31 10:37:26,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:26,200 INFO:     Epoch: 81
2022-12-31 10:37:27,798 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39568643470605214, 'Total loss': 0.39568643470605214} | train loss {'Reaction outcome loss': 0.21704310339468696, 'Total loss': 0.21704310339468696}
2022-12-31 10:37:27,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:27,799 INFO:     Epoch: 82
2022-12-31 10:37:29,423 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.38461945379773776, 'Total loss': 0.38461945379773776} | train loss {'Reaction outcome loss': 0.22765534262203138, 'Total loss': 0.22765534262203138}
2022-12-31 10:37:29,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:29,423 INFO:     Epoch: 83
2022-12-31 10:37:31,080 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4000562032063802, 'Total loss': 0.4000562032063802} | train loss {'Reaction outcome loss': 0.22555401883615914, 'Total loss': 0.22555401883615914}
2022-12-31 10:37:31,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:31,080 INFO:     Epoch: 84
2022-12-31 10:37:32,699 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41905723909536996, 'Total loss': 0.41905723909536996} | train loss {'Reaction outcome loss': 0.22366332886774187, 'Total loss': 0.22366332886774187}
2022-12-31 10:37:32,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:32,700 INFO:     Epoch: 85
2022-12-31 10:37:34,295 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.38640170395374296, 'Total loss': 0.38640170395374296} | train loss {'Reaction outcome loss': 0.21812228871919617, 'Total loss': 0.21812228871919617}
2022-12-31 10:37:34,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:34,296 INFO:     Epoch: 86
2022-12-31 10:37:35,910 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4023615956306458, 'Total loss': 0.4023615956306458} | train loss {'Reaction outcome loss': 0.2150121398861873, 'Total loss': 0.2150121398861873}
2022-12-31 10:37:35,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:35,910 INFO:     Epoch: 87
2022-12-31 10:37:37,515 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41402681072553, 'Total loss': 0.41402681072553} | train loss {'Reaction outcome loss': 0.21687898598611355, 'Total loss': 0.21687898598611355}
2022-12-31 10:37:37,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:37,515 INFO:     Epoch: 88
2022-12-31 10:37:39,130 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3888834228118261, 'Total loss': 0.3888834228118261} | train loss {'Reaction outcome loss': 0.21243096516208743, 'Total loss': 0.21243096516208743}
2022-12-31 10:37:39,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:39,131 INFO:     Epoch: 89
2022-12-31 10:37:40,760 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3862900058428446, 'Total loss': 0.3862900058428446} | train loss {'Reaction outcome loss': 0.21850384549247875, 'Total loss': 0.21850384549247875}
2022-12-31 10:37:40,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:40,761 INFO:     Epoch: 90
2022-12-31 10:37:42,374 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.37723082800706226, 'Total loss': 0.37723082800706226} | train loss {'Reaction outcome loss': 0.20958605714626477, 'Total loss': 0.20958605714626477}
2022-12-31 10:37:42,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:42,374 INFO:     Epoch: 91
2022-12-31 10:37:43,966 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38638138125340143, 'Total loss': 0.38638138125340143} | train loss {'Reaction outcome loss': 0.21442023022537413, 'Total loss': 0.21442023022537413}
2022-12-31 10:37:43,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:43,966 INFO:     Epoch: 92
2022-12-31 10:37:45,574 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41304141680399575, 'Total loss': 0.41304141680399575} | train loss {'Reaction outcome loss': 0.2143422691252365, 'Total loss': 0.2143422691252365}
2022-12-31 10:37:45,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:45,575 INFO:     Epoch: 93
2022-12-31 10:37:47,225 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3730261584122976, 'Total loss': 0.3730261584122976} | train loss {'Reaction outcome loss': 0.2063760766322432, 'Total loss': 0.2063760766322432}
2022-12-31 10:37:47,225 INFO:     Found new best model at epoch 93
2022-12-31 10:37:47,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:47,226 INFO:     Epoch: 94
2022-12-31 10:37:48,870 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3911804368098577, 'Total loss': 0.3911804368098577} | train loss {'Reaction outcome loss': 0.21140908774001935, 'Total loss': 0.21140908774001935}
2022-12-31 10:37:48,870 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:48,870 INFO:     Epoch: 95
2022-12-31 10:37:50,485 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44194147884845736, 'Total loss': 0.44194147884845736} | train loss {'Reaction outcome loss': 0.20768444856043758, 'Total loss': 0.20768444856043758}
2022-12-31 10:37:50,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:50,485 INFO:     Epoch: 96
2022-12-31 10:37:52,080 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4309614549080531, 'Total loss': 0.4309614549080531} | train loss {'Reaction outcome loss': 0.21015185052159138, 'Total loss': 0.21015185052159138}
2022-12-31 10:37:52,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:52,080 INFO:     Epoch: 97
2022-12-31 10:37:53,695 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3743162175019582, 'Total loss': 0.3743162175019582} | train loss {'Reaction outcome loss': 0.21468879522533837, 'Total loss': 0.21468879522533837}
2022-12-31 10:37:53,695 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:53,695 INFO:     Epoch: 98
2022-12-31 10:37:55,306 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.38839313586552937, 'Total loss': 0.38839313586552937} | train loss {'Reaction outcome loss': 0.20535985971481577, 'Total loss': 0.20535985971481577}
2022-12-31 10:37:55,306 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:55,306 INFO:     Epoch: 99
2022-12-31 10:37:56,940 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4037732134262721, 'Total loss': 0.4037732134262721} | train loss {'Reaction outcome loss': 0.2055647209058062, 'Total loss': 0.2055647209058062}
2022-12-31 10:37:56,941 INFO:     Best model found after epoch 94 of 100.
2022-12-31 10:37:56,941 INFO:   Done with stage: TRAINING
2022-12-31 10:37:56,941 INFO:   Starting stage: EVALUATION
2022-12-31 10:37:57,064 INFO:   Done with stage: EVALUATION
2022-12-31 10:37:57,064 INFO:   Leaving out SEQ value Fold_5
2022-12-31 10:37:57,077 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 10:37:57,077 INFO:   Starting stage: FEATURE SCALING
2022-12-31 10:37:57,744 INFO:   Done with stage: FEATURE SCALING
2022-12-31 10:37:57,744 INFO:   Starting stage: SCALING TARGETS
2022-12-31 10:37:57,815 INFO:   Done with stage: SCALING TARGETS
2022-12-31 10:37:57,815 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:37:57,815 INFO:     No hyperparam tuning for this model
2022-12-31 10:37:57,815 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:37:57,815 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 10:37:57,816 INFO:     None feature selector for col prot
2022-12-31 10:37:57,816 INFO:     None feature selector for col prot
2022-12-31 10:37:57,816 INFO:     None feature selector for col prot
2022-12-31 10:37:57,817 INFO:     None feature selector for col chem
2022-12-31 10:37:57,817 INFO:     None feature selector for col chem
2022-12-31 10:37:57,817 INFO:     None feature selector for col chem
2022-12-31 10:37:57,817 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 10:37:57,817 INFO:   Starting stage: BUILD MODEL
2022-12-31 10:37:57,819 INFO:     Number of params in model 223921
2022-12-31 10:37:57,822 INFO:   Done with stage: BUILD MODEL
2022-12-31 10:37:57,822 INFO:   Starting stage: TRAINING
2022-12-31 10:37:57,867 INFO:     Val loss before train {'Reaction outcome loss': 1.0435250520706176, 'Total loss': 1.0435250520706176}
2022-12-31 10:37:57,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:57,867 INFO:     Epoch: 0
2022-12-31 10:37:59,516 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7051918546358744, 'Total loss': 0.7051918546358744} | train loss {'Reaction outcome loss': 0.8106852622379623, 'Total loss': 0.8106852622379623}
2022-12-31 10:37:59,516 INFO:     Found new best model at epoch 0
2022-12-31 10:37:59,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:37:59,517 INFO:     Epoch: 1
2022-12-31 10:38:01,117 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5516928722461064, 'Total loss': 0.5516928722461064} | train loss {'Reaction outcome loss': 0.5990042649209499, 'Total loss': 0.5990042649209499}
2022-12-31 10:38:01,117 INFO:     Found new best model at epoch 1
2022-12-31 10:38:01,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:01,118 INFO:     Epoch: 2
2022-12-31 10:38:02,724 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5514696518580119, 'Total loss': 0.5514696518580119} | train loss {'Reaction outcome loss': 0.5432562117019425, 'Total loss': 0.5432562117019425}
2022-12-31 10:38:02,724 INFO:     Found new best model at epoch 2
2022-12-31 10:38:02,725 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:02,725 INFO:     Epoch: 3
2022-12-31 10:38:04,328 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5048327207565307, 'Total loss': 0.5048327207565307} | train loss {'Reaction outcome loss': 0.5082928695432518, 'Total loss': 0.5082928695432518}
2022-12-31 10:38:04,328 INFO:     Found new best model at epoch 3
2022-12-31 10:38:04,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:04,329 INFO:     Epoch: 4
2022-12-31 10:38:05,941 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4996296584606171, 'Total loss': 0.4996296584606171} | train loss {'Reaction outcome loss': 0.5071996602945138, 'Total loss': 0.5071996602945138}
2022-12-31 10:38:05,941 INFO:     Found new best model at epoch 4
2022-12-31 10:38:05,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:05,942 INFO:     Epoch: 5
2022-12-31 10:38:07,597 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47008405327796937, 'Total loss': 0.47008405327796937} | train loss {'Reaction outcome loss': 0.48897213218404667, 'Total loss': 0.48897213218404667}
2022-12-31 10:38:07,597 INFO:     Found new best model at epoch 5
2022-12-31 10:38:07,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:07,598 INFO:     Epoch: 6
2022-12-31 10:38:09,221 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.496699055035909, 'Total loss': 0.496699055035909} | train loss {'Reaction outcome loss': 0.4713510439960637, 'Total loss': 0.4713510439960637}
2022-12-31 10:38:09,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:09,221 INFO:     Epoch: 7
2022-12-31 10:38:10,859 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5213675121466319, 'Total loss': 0.5213675121466319} | train loss {'Reaction outcome loss': 0.46799035921661847, 'Total loss': 0.46799035921661847}
2022-12-31 10:38:10,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:10,860 INFO:     Epoch: 8
2022-12-31 10:38:12,464 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4810443058609962, 'Total loss': 0.4810443058609962} | train loss {'Reaction outcome loss': 0.4565507741754645, 'Total loss': 0.4565507741754645}
2022-12-31 10:38:12,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:12,464 INFO:     Epoch: 9
2022-12-31 10:38:14,092 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4667536993821462, 'Total loss': 0.4667536993821462} | train loss {'Reaction outcome loss': 0.44969354692728014, 'Total loss': 0.44969354692728014}
2022-12-31 10:38:14,092 INFO:     Found new best model at epoch 9
2022-12-31 10:38:14,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:14,093 INFO:     Epoch: 10
2022-12-31 10:38:15,714 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4832093199094137, 'Total loss': 0.4832093199094137} | train loss {'Reaction outcome loss': 0.44541706050327723, 'Total loss': 0.44541706050327723}
2022-12-31 10:38:15,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:15,714 INFO:     Epoch: 11
2022-12-31 10:38:17,326 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4962678770224253, 'Total loss': 0.4962678770224253} | train loss {'Reaction outcome loss': 0.4405101425945759, 'Total loss': 0.4405101425945759}
2022-12-31 10:38:17,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:17,327 INFO:     Epoch: 12
2022-12-31 10:38:18,924 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.501634939511617, 'Total loss': 0.501634939511617} | train loss {'Reaction outcome loss': 0.430180959659966, 'Total loss': 0.430180959659966}
2022-12-31 10:38:18,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:18,924 INFO:     Epoch: 13
2022-12-31 10:38:20,573 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47282204230626423, 'Total loss': 0.47282204230626423} | train loss {'Reaction outcome loss': 0.4198229440312455, 'Total loss': 0.4198229440312455}
2022-12-31 10:38:20,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:20,573 INFO:     Epoch: 14
2022-12-31 10:38:22,186 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4620130370060603, 'Total loss': 0.4620130370060603} | train loss {'Reaction outcome loss': 0.4198784735117047, 'Total loss': 0.4198784735117047}
2022-12-31 10:38:22,186 INFO:     Found new best model at epoch 14
2022-12-31 10:38:22,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:22,187 INFO:     Epoch: 15
2022-12-31 10:38:23,798 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4622079332669576, 'Total loss': 0.4622079332669576} | train loss {'Reaction outcome loss': 0.4110489851998442, 'Total loss': 0.4110489851998442}
2022-12-31 10:38:23,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:23,798 INFO:     Epoch: 16
2022-12-31 10:38:25,408 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4548778166373571, 'Total loss': 0.4548778166373571} | train loss {'Reaction outcome loss': 0.4011642256476185, 'Total loss': 0.4011642256476185}
2022-12-31 10:38:25,408 INFO:     Found new best model at epoch 16
2022-12-31 10:38:25,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:25,409 INFO:     Epoch: 17
2022-12-31 10:38:27,020 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4375048677126567, 'Total loss': 0.4375048677126567} | train loss {'Reaction outcome loss': 0.39468437198461354, 'Total loss': 0.39468437198461354}
2022-12-31 10:38:27,020 INFO:     Found new best model at epoch 17
2022-12-31 10:38:27,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:27,021 INFO:     Epoch: 18
2022-12-31 10:38:28,610 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44301421344280245, 'Total loss': 0.44301421344280245} | train loss {'Reaction outcome loss': 0.392270244711983, 'Total loss': 0.392270244711983}
2022-12-31 10:38:28,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:28,610 INFO:     Epoch: 19
2022-12-31 10:38:30,220 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4735149800777435, 'Total loss': 0.4735149800777435} | train loss {'Reaction outcome loss': 0.3928071642699449, 'Total loss': 0.3928071642699449}
2022-12-31 10:38:30,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:30,221 INFO:     Epoch: 20
2022-12-31 10:38:31,809 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4525901675224304, 'Total loss': 0.4525901675224304} | train loss {'Reaction outcome loss': 0.420674623935011, 'Total loss': 0.420674623935011}
2022-12-31 10:38:31,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:31,811 INFO:     Epoch: 21
2022-12-31 10:38:33,419 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45105857849121095, 'Total loss': 0.45105857849121095} | train loss {'Reaction outcome loss': 0.38291510845116083, 'Total loss': 0.38291510845116083}
2022-12-31 10:38:33,419 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:33,419 INFO:     Epoch: 22
2022-12-31 10:38:35,028 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47779201765855156, 'Total loss': 0.47779201765855156} | train loss {'Reaction outcome loss': 0.382679445102163, 'Total loss': 0.382679445102163}
2022-12-31 10:38:35,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:35,028 INFO:     Epoch: 23
2022-12-31 10:38:36,619 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42723396023114524, 'Total loss': 0.42723396023114524} | train loss {'Reaction outcome loss': 0.36968746746255865, 'Total loss': 0.36968746746255865}
2022-12-31 10:38:36,620 INFO:     Found new best model at epoch 23
2022-12-31 10:38:36,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:36,620 INFO:     Epoch: 24
2022-12-31 10:38:38,286 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4688133994738261, 'Total loss': 0.4688133994738261} | train loss {'Reaction outcome loss': 0.3607989155191361, 'Total loss': 0.3607989155191361}
2022-12-31 10:38:38,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:38,287 INFO:     Epoch: 25
2022-12-31 10:38:39,862 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42543954849243165, 'Total loss': 0.42543954849243165} | train loss {'Reaction outcome loss': 0.35248979980889894, 'Total loss': 0.35248979980889894}
2022-12-31 10:38:39,862 INFO:     Found new best model at epoch 25
2022-12-31 10:38:39,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:39,863 INFO:     Epoch: 26
2022-12-31 10:38:41,468 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41494493881861366, 'Total loss': 0.41494493881861366} | train loss {'Reaction outcome loss': 0.3537057041683221, 'Total loss': 0.3537057041683221}
2022-12-31 10:38:41,468 INFO:     Found new best model at epoch 26
2022-12-31 10:38:41,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:41,469 INFO:     Epoch: 27
2022-12-31 10:38:43,132 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4616974011063576, 'Total loss': 0.4616974011063576} | train loss {'Reaction outcome loss': 0.3451434462913312, 'Total loss': 0.3451434462913312}
2022-12-31 10:38:43,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:43,132 INFO:     Epoch: 28
2022-12-31 10:38:44,800 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4449840982755025, 'Total loss': 0.4449840982755025} | train loss {'Reaction outcome loss': 0.34517058667531103, 'Total loss': 0.34517058667531103}
2022-12-31 10:38:44,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:44,800 INFO:     Epoch: 29
2022-12-31 10:38:46,418 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45420079628626503, 'Total loss': 0.45420079628626503} | train loss {'Reaction outcome loss': 0.34166449439995317, 'Total loss': 0.34166449439995317}
2022-12-31 10:38:46,418 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:46,418 INFO:     Epoch: 30
2022-12-31 10:38:48,030 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41729464928309123, 'Total loss': 0.41729464928309123} | train loss {'Reaction outcome loss': 0.33333102922219093, 'Total loss': 0.33333102922219093}
2022-12-31 10:38:48,030 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:48,030 INFO:     Epoch: 31
2022-12-31 10:38:49,643 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4557295650243759, 'Total loss': 0.4557295650243759} | train loss {'Reaction outcome loss': 0.33649081883925025, 'Total loss': 0.33649081883925025}
2022-12-31 10:38:49,643 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:49,643 INFO:     Epoch: 32
2022-12-31 10:38:51,320 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4346622476975123, 'Total loss': 0.4346622476975123} | train loss {'Reaction outcome loss': 0.34792439607258857, 'Total loss': 0.34792439607258857}
2022-12-31 10:38:51,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:51,321 INFO:     Epoch: 33
2022-12-31 10:38:52,991 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44820382495721184, 'Total loss': 0.44820382495721184} | train loss {'Reaction outcome loss': 0.32900628555027017, 'Total loss': 0.32900628555027017}
2022-12-31 10:38:52,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:52,991 INFO:     Epoch: 34
2022-12-31 10:38:54,644 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4076607743899027, 'Total loss': 0.4076607743899027} | train loss {'Reaction outcome loss': 0.31516865190359816, 'Total loss': 0.31516865190359816}
2022-12-31 10:38:54,644 INFO:     Found new best model at epoch 34
2022-12-31 10:38:54,645 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:54,645 INFO:     Epoch: 35
2022-12-31 10:38:56,288 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4368403116861979, 'Total loss': 0.4368403116861979} | train loss {'Reaction outcome loss': 0.31598371550933446, 'Total loss': 0.31598371550933446}
2022-12-31 10:38:56,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:56,288 INFO:     Epoch: 36
2022-12-31 10:38:57,952 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.446053558588028, 'Total loss': 0.446053558588028} | train loss {'Reaction outcome loss': 0.3079864833288003, 'Total loss': 0.3079864833288003}
2022-12-31 10:38:57,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:57,952 INFO:     Epoch: 37
2022-12-31 10:38:59,597 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42901740272839867, 'Total loss': 0.42901740272839867} | train loss {'Reaction outcome loss': 0.30682097308243206, 'Total loss': 0.30682097308243206}
2022-12-31 10:38:59,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:38:59,597 INFO:     Epoch: 38
2022-12-31 10:39:01,264 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.44064644277095794, 'Total loss': 0.44064644277095794} | train loss {'Reaction outcome loss': 0.30242333147654554, 'Total loss': 0.30242333147654554}
2022-12-31 10:39:01,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:01,264 INFO:     Epoch: 39
2022-12-31 10:39:02,911 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.436219330628713, 'Total loss': 0.436219330628713} | train loss {'Reaction outcome loss': 0.29849670608811485, 'Total loss': 0.29849670608811485}
2022-12-31 10:39:02,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:02,911 INFO:     Epoch: 40
2022-12-31 10:39:04,533 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4178209523359934, 'Total loss': 0.4178209523359934} | train loss {'Reaction outcome loss': 0.30023385466589336, 'Total loss': 0.30023385466589336}
2022-12-31 10:39:04,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:04,534 INFO:     Epoch: 41
2022-12-31 10:39:06,190 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43290401473641393, 'Total loss': 0.43290401473641393} | train loss {'Reaction outcome loss': 0.29860105086792854, 'Total loss': 0.29860105086792854}
2022-12-31 10:39:06,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:06,191 INFO:     Epoch: 42
2022-12-31 10:39:07,808 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5901735256115596, 'Total loss': 0.5901735256115596} | train loss {'Reaction outcome loss': 0.30452175894617173, 'Total loss': 0.30452175894617173}
2022-12-31 10:39:07,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:07,810 INFO:     Epoch: 43
2022-12-31 10:39:09,475 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43786034484704334, 'Total loss': 0.43786034484704334} | train loss {'Reaction outcome loss': 0.37798871102852677, 'Total loss': 0.37798871102852677}
2022-12-31 10:39:09,475 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:09,476 INFO:     Epoch: 44
2022-12-31 10:39:11,136 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4462397307157516, 'Total loss': 0.4462397307157516} | train loss {'Reaction outcome loss': 0.30462695137037477, 'Total loss': 0.30462695137037477}
2022-12-31 10:39:11,136 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:11,136 INFO:     Epoch: 45
2022-12-31 10:39:12,764 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4372237384319305, 'Total loss': 0.4372237384319305} | train loss {'Reaction outcome loss': 0.2986099263513967, 'Total loss': 0.2986099263513967}
2022-12-31 10:39:12,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:12,764 INFO:     Epoch: 46
2022-12-31 10:39:14,382 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4344247202078501, 'Total loss': 0.4344247202078501} | train loss {'Reaction outcome loss': 0.2853116527658658, 'Total loss': 0.2853116527658658}
2022-12-31 10:39:14,382 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:14,383 INFO:     Epoch: 47
2022-12-31 10:39:15,990 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43800618648529055, 'Total loss': 0.43800618648529055} | train loss {'Reaction outcome loss': 0.2818598842064418, 'Total loss': 0.2818598842064418}
2022-12-31 10:39:15,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:15,990 INFO:     Epoch: 48
2022-12-31 10:39:17,586 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44456881483395894, 'Total loss': 0.44456881483395894} | train loss {'Reaction outcome loss': 0.2785398264375057, 'Total loss': 0.2785398264375057}
2022-12-31 10:39:17,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:17,586 INFO:     Epoch: 49
2022-12-31 10:39:19,193 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3917216072479884, 'Total loss': 0.3917216072479884} | train loss {'Reaction outcome loss': 0.27816152195378707, 'Total loss': 0.27816152195378707}
2022-12-31 10:39:19,193 INFO:     Found new best model at epoch 49
2022-12-31 10:39:19,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:19,194 INFO:     Epoch: 50
2022-12-31 10:39:20,802 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4196963522272805, 'Total loss': 0.4196963522272805} | train loss {'Reaction outcome loss': 0.2734989705069524, 'Total loss': 0.2734989705069524}
2022-12-31 10:39:20,802 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:20,802 INFO:     Epoch: 51
2022-12-31 10:39:22,411 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4375835120677948, 'Total loss': 0.4375835120677948} | train loss {'Reaction outcome loss': 0.2733837455521641, 'Total loss': 0.2733837455521641}
2022-12-31 10:39:22,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:22,412 INFO:     Epoch: 52
2022-12-31 10:39:24,019 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39425779034694036, 'Total loss': 0.39425779034694036} | train loss {'Reaction outcome loss': 0.26889030293871957, 'Total loss': 0.26889030293871957}
2022-12-31 10:39:24,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:24,019 INFO:     Epoch: 53
2022-12-31 10:39:25,619 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42381624480088553, 'Total loss': 0.42381624480088553} | train loss {'Reaction outcome loss': 0.2718943264854201, 'Total loss': 0.2718943264854201}
2022-12-31 10:39:25,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:25,619 INFO:     Epoch: 54
2022-12-31 10:39:27,236 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.39008789559205376, 'Total loss': 0.39008789559205376} | train loss {'Reaction outcome loss': 0.2693534525300282, 'Total loss': 0.2693534525300282}
2022-12-31 10:39:27,237 INFO:     Found new best model at epoch 54
2022-12-31 10:39:27,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:27,238 INFO:     Epoch: 55
2022-12-31 10:39:28,847 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.454081071416537, 'Total loss': 0.454081071416537} | train loss {'Reaction outcome loss': 0.3128766714986684, 'Total loss': 0.3128766714986684}
2022-12-31 10:39:28,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:28,847 INFO:     Epoch: 56
2022-12-31 10:39:30,458 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3890058676401774, 'Total loss': 0.3890058676401774} | train loss {'Reaction outcome loss': 0.27439289078440354, 'Total loss': 0.27439289078440354}
2022-12-31 10:39:30,458 INFO:     Found new best model at epoch 56
2022-12-31 10:39:30,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:30,459 INFO:     Epoch: 57
2022-12-31 10:39:32,046 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46225548585255943, 'Total loss': 0.46225548585255943} | train loss {'Reaction outcome loss': 0.3043779724857945, 'Total loss': 0.3043779724857945}
2022-12-31 10:39:32,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:32,046 INFO:     Epoch: 58
2022-12-31 10:39:33,655 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41548087696234387, 'Total loss': 0.41548087696234387} | train loss {'Reaction outcome loss': 0.29340958468779665, 'Total loss': 0.29340958468779665}
2022-12-31 10:39:33,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:33,655 INFO:     Epoch: 59
2022-12-31 10:39:35,255 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3927251527706782, 'Total loss': 0.3927251527706782} | train loss {'Reaction outcome loss': 0.2613008133729623, 'Total loss': 0.2613008133729623}
2022-12-31 10:39:35,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:35,255 INFO:     Epoch: 60
2022-12-31 10:39:36,864 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42038200199604037, 'Total loss': 0.42038200199604037} | train loss {'Reaction outcome loss': 0.25469876448619616, 'Total loss': 0.25469876448619616}
2022-12-31 10:39:36,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:36,864 INFO:     Epoch: 61
2022-12-31 10:39:38,472 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42596884568532306, 'Total loss': 0.42596884568532306} | train loss {'Reaction outcome loss': 0.2558237427012131, 'Total loss': 0.2558237427012131}
2022-12-31 10:39:38,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:38,473 INFO:     Epoch: 62
2022-12-31 10:39:40,080 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43505567610263823, 'Total loss': 0.43505567610263823} | train loss {'Reaction outcome loss': 0.2502393459106553, 'Total loss': 0.2502393459106553}
2022-12-31 10:39:40,080 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:40,080 INFO:     Epoch: 63
2022-12-31 10:39:41,676 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40743723809719085, 'Total loss': 0.40743723809719085} | train loss {'Reaction outcome loss': 0.2505739879257896, 'Total loss': 0.2505739879257896}
2022-12-31 10:39:41,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:41,676 INFO:     Epoch: 64
2022-12-31 10:39:43,302 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41135902671764296, 'Total loss': 0.41135902671764296} | train loss {'Reaction outcome loss': 0.265787404961884, 'Total loss': 0.265787404961884}
2022-12-31 10:39:43,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:43,302 INFO:     Epoch: 65
2022-12-31 10:39:44,904 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46590602993965147, 'Total loss': 0.46590602993965147} | train loss {'Reaction outcome loss': 0.28442837246415287, 'Total loss': 0.28442837246415287}
2022-12-31 10:39:44,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:44,905 INFO:     Epoch: 66
2022-12-31 10:39:46,509 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4649928758541743, 'Total loss': 0.4649928758541743} | train loss {'Reaction outcome loss': 0.25410442120156024, 'Total loss': 0.25410442120156024}
2022-12-31 10:39:46,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:46,509 INFO:     Epoch: 67
2022-12-31 10:39:48,114 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4262261539697647, 'Total loss': 0.4262261539697647} | train loss {'Reaction outcome loss': 0.2603584722602281, 'Total loss': 0.2603584722602281}
2022-12-31 10:39:48,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:48,114 INFO:     Epoch: 68
2022-12-31 10:39:49,714 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3539588215450446, 'Total loss': 0.3539588215450446} | train loss {'Reaction outcome loss': 0.24841580979409628, 'Total loss': 0.24841580979409628}
2022-12-31 10:39:49,714 INFO:     Found new best model at epoch 68
2022-12-31 10:39:49,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:49,715 INFO:     Epoch: 69
2022-12-31 10:39:51,312 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.38870297372341156, 'Total loss': 0.38870297372341156} | train loss {'Reaction outcome loss': 0.24356699817260538, 'Total loss': 0.24356699817260538}
2022-12-31 10:39:51,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:51,312 INFO:     Epoch: 70
2022-12-31 10:39:52,909 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40024024148782095, 'Total loss': 0.40024024148782095} | train loss {'Reaction outcome loss': 0.24257271561393703, 'Total loss': 0.24257271561393703}
2022-12-31 10:39:52,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:52,909 INFO:     Epoch: 71
2022-12-31 10:39:54,517 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4295900374650955, 'Total loss': 0.4295900374650955} | train loss {'Reaction outcome loss': 0.28020695129922335, 'Total loss': 0.28020695129922335}
2022-12-31 10:39:54,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:54,518 INFO:     Epoch: 72
2022-12-31 10:39:56,125 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41190895636876423, 'Total loss': 0.41190895636876423} | train loss {'Reaction outcome loss': 0.2429778367024509, 'Total loss': 0.2429778367024509}
2022-12-31 10:39:56,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:56,125 INFO:     Epoch: 73
2022-12-31 10:39:57,738 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3812132731080055, 'Total loss': 0.3812132731080055} | train loss {'Reaction outcome loss': 0.24577328815138427, 'Total loss': 0.24577328815138427}
2022-12-31 10:39:57,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:57,739 INFO:     Epoch: 74
2022-12-31 10:39:59,325 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3814398189385732, 'Total loss': 0.3814398189385732} | train loss {'Reaction outcome loss': 0.26670670060886315, 'Total loss': 0.26670670060886315}
2022-12-31 10:39:59,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:39:59,325 INFO:     Epoch: 75
2022-12-31 10:40:00,932 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3986540267864863, 'Total loss': 0.3986540267864863} | train loss {'Reaction outcome loss': 0.2349033322450165, 'Total loss': 0.2349033322450165}
2022-12-31 10:40:00,933 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:00,933 INFO:     Epoch: 76
2022-12-31 10:40:02,526 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3620169868071874, 'Total loss': 0.3620169868071874} | train loss {'Reaction outcome loss': 0.23572371808805273, 'Total loss': 0.23572371808805273}
2022-12-31 10:40:02,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:02,527 INFO:     Epoch: 77
2022-12-31 10:40:04,133 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40852148135503136, 'Total loss': 0.40852148135503136} | train loss {'Reaction outcome loss': 0.228530593800183, 'Total loss': 0.228530593800183}
2022-12-31 10:40:04,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:04,134 INFO:     Epoch: 78
2022-12-31 10:40:05,742 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41470139821370444, 'Total loss': 0.41470139821370444} | train loss {'Reaction outcome loss': 0.23521901299945835, 'Total loss': 0.23521901299945835}
2022-12-31 10:40:05,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:05,742 INFO:     Epoch: 79
2022-12-31 10:40:07,350 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41301996807257335, 'Total loss': 0.41301996807257335} | train loss {'Reaction outcome loss': 0.23092962650960122, 'Total loss': 0.23092962650960122}
2022-12-31 10:40:07,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:07,350 INFO:     Epoch: 80
2022-12-31 10:40:08,980 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4138443022966385, 'Total loss': 0.4138443022966385} | train loss {'Reaction outcome loss': 0.22709504134305145, 'Total loss': 0.22709504134305145}
2022-12-31 10:40:08,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:08,982 INFO:     Epoch: 81
2022-12-31 10:40:10,533 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4206402083237966, 'Total loss': 0.4206402083237966} | train loss {'Reaction outcome loss': 0.2303613758404685, 'Total loss': 0.2303613758404685}
2022-12-31 10:40:10,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:10,533 INFO:     Epoch: 82
2022-12-31 10:40:11,603 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4082651565472285, 'Total loss': 0.4082651565472285} | train loss {'Reaction outcome loss': 0.2286739540151388, 'Total loss': 0.2286739540151388}
2022-12-31 10:40:11,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:11,604 INFO:     Epoch: 83
2022-12-31 10:40:12,666 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40746485590934756, 'Total loss': 0.40746485590934756} | train loss {'Reaction outcome loss': 0.22411218240447034, 'Total loss': 0.22411218240447034}
2022-12-31 10:40:12,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:12,666 INFO:     Epoch: 84
2022-12-31 10:40:13,729 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4118178963661194, 'Total loss': 0.4118178963661194} | train loss {'Reaction outcome loss': 0.23379460556189652, 'Total loss': 0.23379460556189652}
2022-12-31 10:40:13,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:13,730 INFO:     Epoch: 85
2022-12-31 10:40:14,806 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4043219953775406, 'Total loss': 0.4043219953775406} | train loss {'Reaction outcome loss': 0.25529207803049137, 'Total loss': 0.25529207803049137}
2022-12-31 10:40:14,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:14,806 INFO:     Epoch: 86
2022-12-31 10:40:16,330 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41136056383450825, 'Total loss': 0.41136056383450825} | train loss {'Reaction outcome loss': 0.22513696164284172, 'Total loss': 0.22513696164284172}
2022-12-31 10:40:16,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:16,331 INFO:     Epoch: 87
2022-12-31 10:40:17,936 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41767425735791525, 'Total loss': 0.41767425735791525} | train loss {'Reaction outcome loss': 0.21968810984984707, 'Total loss': 0.21968810984984707}
2022-12-31 10:40:17,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:17,937 INFO:     Epoch: 88
2022-12-31 10:40:19,544 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3871321807305018, 'Total loss': 0.3871321807305018} | train loss {'Reaction outcome loss': 0.22429419385751817, 'Total loss': 0.22429419385751817}
2022-12-31 10:40:19,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:19,545 INFO:     Epoch: 89
2022-12-31 10:40:21,153 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45138201117515564, 'Total loss': 0.45138201117515564} | train loss {'Reaction outcome loss': 0.23545947821432914, 'Total loss': 0.23545947821432914}
2022-12-31 10:40:21,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:21,153 INFO:     Epoch: 90
2022-12-31 10:40:22,765 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41325329144795736, 'Total loss': 0.41325329144795736} | train loss {'Reaction outcome loss': 0.2509740121608627, 'Total loss': 0.2509740121608627}
2022-12-31 10:40:22,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:22,765 INFO:     Epoch: 91
2022-12-31 10:40:24,340 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43938661317030586, 'Total loss': 0.43938661317030586} | train loss {'Reaction outcome loss': 0.2558386568756153, 'Total loss': 0.2558386568756153}
2022-12-31 10:40:24,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:24,340 INFO:     Epoch: 92
2022-12-31 10:40:26,004 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40650109698375064, 'Total loss': 0.40650109698375064} | train loss {'Reaction outcome loss': 0.22695974265630153, 'Total loss': 0.22695974265630153}
2022-12-31 10:40:26,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:26,004 INFO:     Epoch: 93
2022-12-31 10:40:27,666 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.38901768028736117, 'Total loss': 0.38901768028736117} | train loss {'Reaction outcome loss': 0.2207102207315114, 'Total loss': 0.2207102207315114}
2022-12-31 10:40:27,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:27,666 INFO:     Epoch: 94
2022-12-31 10:40:29,281 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4205725332101186, 'Total loss': 0.4205725332101186} | train loss {'Reaction outcome loss': 0.2213797752578419, 'Total loss': 0.2213797752578419}
2022-12-31 10:40:29,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:29,282 INFO:     Epoch: 95
2022-12-31 10:40:30,893 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3945110678672791, 'Total loss': 0.3945110678672791} | train loss {'Reaction outcome loss': 0.22395845943155682, 'Total loss': 0.22395845943155682}
2022-12-31 10:40:30,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:30,893 INFO:     Epoch: 96
2022-12-31 10:40:32,499 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.392440469066302, 'Total loss': 0.392440469066302} | train loss {'Reaction outcome loss': 0.21645503521026316, 'Total loss': 0.21645503521026316}
2022-12-31 10:40:32,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:32,499 INFO:     Epoch: 97
2022-12-31 10:40:34,081 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.37631386319796245, 'Total loss': 0.37631386319796245} | train loss {'Reaction outcome loss': 0.22085427561790746, 'Total loss': 0.22085427561790746}
2022-12-31 10:40:34,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:34,082 INFO:     Epoch: 98
2022-12-31 10:40:35,696 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4241749276717504, 'Total loss': 0.4241749276717504} | train loss {'Reaction outcome loss': 0.21774221554590875, 'Total loss': 0.21774221554590875}
2022-12-31 10:40:35,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:35,697 INFO:     Epoch: 99
2022-12-31 10:40:37,312 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3927852590878805, 'Total loss': 0.3927852590878805} | train loss {'Reaction outcome loss': 0.21668471261079464, 'Total loss': 0.21668471261079464}
2022-12-31 10:40:37,312 INFO:     Best model found after epoch 69 of 100.
2022-12-31 10:40:37,312 INFO:   Done with stage: TRAINING
2022-12-31 10:40:37,312 INFO:   Starting stage: EVALUATION
2022-12-31 10:40:37,439 INFO:   Done with stage: EVALUATION
2022-12-31 10:40:37,439 INFO:   Leaving out SEQ value Fold_6
2022-12-31 10:40:37,451 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 10:40:37,451 INFO:   Starting stage: FEATURE SCALING
2022-12-31 10:40:38,098 INFO:   Done with stage: FEATURE SCALING
2022-12-31 10:40:38,098 INFO:   Starting stage: SCALING TARGETS
2022-12-31 10:40:38,168 INFO:   Done with stage: SCALING TARGETS
2022-12-31 10:40:38,168 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:40:38,168 INFO:     No hyperparam tuning for this model
2022-12-31 10:40:38,168 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:40:38,168 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 10:40:38,169 INFO:     None feature selector for col prot
2022-12-31 10:40:38,169 INFO:     None feature selector for col prot
2022-12-31 10:40:38,169 INFO:     None feature selector for col prot
2022-12-31 10:40:38,170 INFO:     None feature selector for col chem
2022-12-31 10:40:38,170 INFO:     None feature selector for col chem
2022-12-31 10:40:38,170 INFO:     None feature selector for col chem
2022-12-31 10:40:38,170 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 10:40:38,170 INFO:   Starting stage: BUILD MODEL
2022-12-31 10:40:38,172 INFO:     Number of params in model 223921
2022-12-31 10:40:38,175 INFO:   Done with stage: BUILD MODEL
2022-12-31 10:40:38,175 INFO:   Starting stage: TRAINING
2022-12-31 10:40:38,222 INFO:     Val loss before train {'Reaction outcome loss': 0.9712448755900065, 'Total loss': 0.9712448755900065}
2022-12-31 10:40:38,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:38,222 INFO:     Epoch: 0
2022-12-31 10:40:39,845 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6746786753336589, 'Total loss': 0.6746786753336589} | train loss {'Reaction outcome loss': 0.8119606873834176, 'Total loss': 0.8119606873834176}
2022-12-31 10:40:39,845 INFO:     Found new best model at epoch 0
2022-12-31 10:40:39,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:39,846 INFO:     Epoch: 1
2022-12-31 10:40:41,457 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5710410336653392, 'Total loss': 0.5710410336653392} | train loss {'Reaction outcome loss': 0.5987485366392652, 'Total loss': 0.5987485366392652}
2022-12-31 10:40:41,457 INFO:     Found new best model at epoch 1
2022-12-31 10:40:41,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:41,458 INFO:     Epoch: 2
2022-12-31 10:40:43,048 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.575258469581604, 'Total loss': 0.575258469581604} | train loss {'Reaction outcome loss': 0.5334337849156521, 'Total loss': 0.5334337849156521}
2022-12-31 10:40:43,048 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:43,048 INFO:     Epoch: 3
2022-12-31 10:40:44,672 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5227775871753693, 'Total loss': 0.5227775871753693} | train loss {'Reaction outcome loss': 0.510716070229396, 'Total loss': 0.510716070229396}
2022-12-31 10:40:44,672 INFO:     Found new best model at epoch 3
2022-12-31 10:40:44,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:44,673 INFO:     Epoch: 4
2022-12-31 10:40:46,295 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5464069237311681, 'Total loss': 0.5464069237311681} | train loss {'Reaction outcome loss': 0.48905306059315745, 'Total loss': 0.48905306059315745}
2022-12-31 10:40:46,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:46,296 INFO:     Epoch: 5
2022-12-31 10:40:47,919 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5182976027329763, 'Total loss': 0.5182976027329763} | train loss {'Reaction outcome loss': 0.4827317711678653, 'Total loss': 0.4827317711678653}
2022-12-31 10:40:47,919 INFO:     Found new best model at epoch 5
2022-12-31 10:40:47,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:47,920 INFO:     Epoch: 6
2022-12-31 10:40:49,539 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5000443210204443, 'Total loss': 0.5000443210204443} | train loss {'Reaction outcome loss': 0.4745023450158563, 'Total loss': 0.4745023450158563}
2022-12-31 10:40:49,539 INFO:     Found new best model at epoch 6
2022-12-31 10:40:49,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:49,540 INFO:     Epoch: 7
2022-12-31 10:40:51,130 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5189097404479981, 'Total loss': 0.5189097404479981} | train loss {'Reaction outcome loss': 0.464299710164862, 'Total loss': 0.464299710164862}
2022-12-31 10:40:51,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:51,130 INFO:     Epoch: 8
2022-12-31 10:40:52,748 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49856544137001035, 'Total loss': 0.49856544137001035} | train loss {'Reaction outcome loss': 0.4526336895375906, 'Total loss': 0.4526336895375906}
2022-12-31 10:40:52,749 INFO:     Found new best model at epoch 8
2022-12-31 10:40:52,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:52,750 INFO:     Epoch: 9
2022-12-31 10:40:54,372 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5124249219894409, 'Total loss': 0.5124249219894409} | train loss {'Reaction outcome loss': 0.4465171319805758, 'Total loss': 0.4465171319805758}
2022-12-31 10:40:54,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:54,372 INFO:     Epoch: 10
2022-12-31 10:40:55,992 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48149164716402687, 'Total loss': 0.48149164716402687} | train loss {'Reaction outcome loss': 0.44250179259678085, 'Total loss': 0.44250179259678085}
2022-12-31 10:40:55,992 INFO:     Found new best model at epoch 10
2022-12-31 10:40:55,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:55,993 INFO:     Epoch: 11
2022-12-31 10:40:57,615 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4826981087525686, 'Total loss': 0.4826981087525686} | train loss {'Reaction outcome loss': 0.4363841751207083, 'Total loss': 0.4363841751207083}
2022-12-31 10:40:57,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:57,615 INFO:     Epoch: 12
2022-12-31 10:40:59,242 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5245872636636099, 'Total loss': 0.5245872636636099} | train loss {'Reaction outcome loss': 0.42888824894540145, 'Total loss': 0.42888824894540145}
2022-12-31 10:40:59,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:40:59,242 INFO:     Epoch: 13
2022-12-31 10:41:00,840 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4880228618780772, 'Total loss': 0.4880228618780772} | train loss {'Reaction outcome loss': 0.4219326182177781, 'Total loss': 0.4219326182177781}
2022-12-31 10:41:00,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:00,841 INFO:     Epoch: 14
2022-12-31 10:41:02,507 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.49621941645940143, 'Total loss': 0.49621941645940143} | train loss {'Reaction outcome loss': 0.41630257994259307, 'Total loss': 0.41630257994259307}
2022-12-31 10:41:02,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:02,507 INFO:     Epoch: 15
2022-12-31 10:41:04,118 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4913852155208588, 'Total loss': 0.4913852155208588} | train loss {'Reaction outcome loss': 0.4150920543913807, 'Total loss': 0.4150920543913807}
2022-12-31 10:41:04,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:04,119 INFO:     Epoch: 16
2022-12-31 10:41:05,742 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46899452805519104, 'Total loss': 0.46899452805519104} | train loss {'Reaction outcome loss': 0.41042198488213094, 'Total loss': 0.41042198488213094}
2022-12-31 10:41:05,743 INFO:     Found new best model at epoch 16
2022-12-31 10:41:05,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:05,744 INFO:     Epoch: 17
2022-12-31 10:41:07,366 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4816405495007833, 'Total loss': 0.4816405495007833} | train loss {'Reaction outcome loss': 0.39887256602948323, 'Total loss': 0.39887256602948323}
2022-12-31 10:41:07,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:07,366 INFO:     Epoch: 18
2022-12-31 10:41:08,966 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4589927911758423, 'Total loss': 0.4589927911758423} | train loss {'Reaction outcome loss': 0.3940293915058732, 'Total loss': 0.3940293915058732}
2022-12-31 10:41:08,966 INFO:     Found new best model at epoch 18
2022-12-31 10:41:08,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:08,967 INFO:     Epoch: 19
2022-12-31 10:41:10,569 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4806535621484121, 'Total loss': 0.4806535621484121} | train loss {'Reaction outcome loss': 0.38924052383387564, 'Total loss': 0.38924052383387564}
2022-12-31 10:41:10,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:10,569 INFO:     Epoch: 20
2022-12-31 10:41:12,195 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.48808733324209846, 'Total loss': 0.48808733324209846} | train loss {'Reaction outcome loss': 0.38169592484455245, 'Total loss': 0.38169592484455245}
2022-12-31 10:41:12,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:12,195 INFO:     Epoch: 21
2022-12-31 10:41:13,824 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47816573878129326, 'Total loss': 0.47816573878129326} | train loss {'Reaction outcome loss': 0.3814186670343368, 'Total loss': 0.3814186670343368}
2022-12-31 10:41:13,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:13,824 INFO:     Epoch: 22
2022-12-31 10:41:15,469 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47528624534606934, 'Total loss': 0.47528624534606934} | train loss {'Reaction outcome loss': 0.3764521635073617, 'Total loss': 0.3764521635073617}
2022-12-31 10:41:15,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:15,469 INFO:     Epoch: 23
2022-12-31 10:41:17,097 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46697324911753335, 'Total loss': 0.46697324911753335} | train loss {'Reaction outcome loss': 0.3727292946744912, 'Total loss': 0.3727292946744912}
2022-12-31 10:41:17,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:17,097 INFO:     Epoch: 24
2022-12-31 10:41:18,691 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4888528565565745, 'Total loss': 0.4888528565565745} | train loss {'Reaction outcome loss': 0.3637802391060853, 'Total loss': 0.3637802391060853}
2022-12-31 10:41:18,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:18,691 INFO:     Epoch: 25
2022-12-31 10:41:20,367 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4308351834615072, 'Total loss': 0.4308351834615072} | train loss {'Reaction outcome loss': 0.3620167310057134, 'Total loss': 0.3620167310057134}
2022-12-31 10:41:20,367 INFO:     Found new best model at epoch 25
2022-12-31 10:41:20,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:20,368 INFO:     Epoch: 26
2022-12-31 10:41:21,991 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4719722290833791, 'Total loss': 0.4719722290833791} | train loss {'Reaction outcome loss': 0.34891512725058443, 'Total loss': 0.34891512725058443}
2022-12-31 10:41:21,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:21,993 INFO:     Epoch: 27
2022-12-31 10:41:23,636 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4863080302874247, 'Total loss': 0.4863080302874247} | train loss {'Reaction outcome loss': 0.35765009896580924, 'Total loss': 0.35765009896580924}
2022-12-31 10:41:23,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:23,637 INFO:     Epoch: 28
2022-12-31 10:41:25,279 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4354215800762177, 'Total loss': 0.4354215800762177} | train loss {'Reaction outcome loss': 0.34844995515979155, 'Total loss': 0.34844995515979155}
2022-12-31 10:41:25,279 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:25,279 INFO:     Epoch: 29
2022-12-31 10:41:26,895 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45874221523602804, 'Total loss': 0.45874221523602804} | train loss {'Reaction outcome loss': 0.33810829594462355, 'Total loss': 0.33810829594462355}
2022-12-31 10:41:26,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:26,895 INFO:     Epoch: 30
2022-12-31 10:41:28,505 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4711889326572418, 'Total loss': 0.4711889326572418} | train loss {'Reaction outcome loss': 0.3365634131894215, 'Total loss': 0.3365634131894215}
2022-12-31 10:41:28,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:28,506 INFO:     Epoch: 31
2022-12-31 10:41:30,132 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.461723401149114, 'Total loss': 0.461723401149114} | train loss {'Reaction outcome loss': 0.3328222894926794, 'Total loss': 0.3328222894926794}
2022-12-31 10:41:30,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:30,133 INFO:     Epoch: 32
2022-12-31 10:41:31,789 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4289807180563609, 'Total loss': 0.4289807180563609} | train loss {'Reaction outcome loss': 0.3239796512931693, 'Total loss': 0.3239796512931693}
2022-12-31 10:41:31,789 INFO:     Found new best model at epoch 32
2022-12-31 10:41:31,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:31,790 INFO:     Epoch: 33
2022-12-31 10:41:33,421 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47098685006300606, 'Total loss': 0.47098685006300606} | train loss {'Reaction outcome loss': 0.32280174940017586, 'Total loss': 0.32280174940017586}
2022-12-31 10:41:33,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:33,422 INFO:     Epoch: 34
2022-12-31 10:41:35,077 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46922168334325154, 'Total loss': 0.46922168334325154} | train loss {'Reaction outcome loss': 0.32667818501430296, 'Total loss': 0.32667818501430296}
2022-12-31 10:41:35,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:35,077 INFO:     Epoch: 35
2022-12-31 10:41:36,672 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4740835169951121, 'Total loss': 0.4740835169951121} | train loss {'Reaction outcome loss': 0.30997279896955626, 'Total loss': 0.30997279896955626}
2022-12-31 10:41:36,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:36,672 INFO:     Epoch: 36
2022-12-31 10:41:38,295 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43653015891710917, 'Total loss': 0.43653015891710917} | train loss {'Reaction outcome loss': 0.30983822304580616, 'Total loss': 0.30983822304580616}
2022-12-31 10:41:38,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:38,295 INFO:     Epoch: 37
2022-12-31 10:41:39,939 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4476390371719996, 'Total loss': 0.4476390371719996} | train loss {'Reaction outcome loss': 0.3031917799412128, 'Total loss': 0.3031917799412128}
2022-12-31 10:41:39,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:39,939 INFO:     Epoch: 38
2022-12-31 10:41:41,598 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41718710760275524, 'Total loss': 0.41718710760275524} | train loss {'Reaction outcome loss': 0.3015311496997998, 'Total loss': 0.3015311496997998}
2022-12-31 10:41:41,599 INFO:     Found new best model at epoch 38
2022-12-31 10:41:41,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:41,600 INFO:     Epoch: 39
2022-12-31 10:41:43,234 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.424360195795695, 'Total loss': 0.424360195795695} | train loss {'Reaction outcome loss': 0.29274763045866137, 'Total loss': 0.29274763045866137}
2022-12-31 10:41:43,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:43,235 INFO:     Epoch: 40
2022-12-31 10:41:44,861 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4376236786444982, 'Total loss': 0.4376236786444982} | train loss {'Reaction outcome loss': 0.29713527671320344, 'Total loss': 0.29713527671320344}
2022-12-31 10:41:44,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:44,861 INFO:     Epoch: 41
2022-12-31 10:41:46,441 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4249359766642253, 'Total loss': 0.4249359766642253} | train loss {'Reaction outcome loss': 0.2915410774924695, 'Total loss': 0.2915410774924695}
2022-12-31 10:41:46,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:46,441 INFO:     Epoch: 42
2022-12-31 10:41:48,107 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43102377851804097, 'Total loss': 0.43102377851804097} | train loss {'Reaction outcome loss': 0.28230931847911017, 'Total loss': 0.28230931847911017}
2022-12-31 10:41:48,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:48,107 INFO:     Epoch: 43
2022-12-31 10:41:49,727 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4337380717198054, 'Total loss': 0.4337380717198054} | train loss {'Reaction outcome loss': 0.2841402264143801, 'Total loss': 0.2841402264143801}
2022-12-31 10:41:49,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:49,727 INFO:     Epoch: 44
2022-12-31 10:41:51,364 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44145532250404357, 'Total loss': 0.44145532250404357} | train loss {'Reaction outcome loss': 0.2780883572861176, 'Total loss': 0.2780883572861176}
2022-12-31 10:41:51,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:51,364 INFO:     Epoch: 45
2022-12-31 10:41:52,987 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4302766730388006, 'Total loss': 0.4302766730388006} | train loss {'Reaction outcome loss': 0.27968041703696717, 'Total loss': 0.27968041703696717}
2022-12-31 10:41:52,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:52,988 INFO:     Epoch: 46
2022-12-31 10:41:54,600 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40937408010164894, 'Total loss': 0.40937408010164894} | train loss {'Reaction outcome loss': 0.2752460354555815, 'Total loss': 0.2752460354555815}
2022-12-31 10:41:54,600 INFO:     Found new best model at epoch 46
2022-12-31 10:41:54,601 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:54,601 INFO:     Epoch: 47
2022-12-31 10:41:56,225 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41668189167976377, 'Total loss': 0.41668189167976377} | train loss {'Reaction outcome loss': 0.27385812652186364, 'Total loss': 0.27385812652186364}
2022-12-31 10:41:56,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:56,225 INFO:     Epoch: 48
2022-12-31 10:41:57,883 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.416840069492658, 'Total loss': 0.416840069492658} | train loss {'Reaction outcome loss': 0.27423609135544685, 'Total loss': 0.27423609135544685}
2022-12-31 10:41:57,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:57,884 INFO:     Epoch: 49
2022-12-31 10:41:59,519 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41513267358144124, 'Total loss': 0.41513267358144124} | train loss {'Reaction outcome loss': 0.2666791617493767, 'Total loss': 0.2666791617493767}
2022-12-31 10:41:59,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:41:59,519 INFO:     Epoch: 50
2022-12-31 10:42:01,188 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41118444701035817, 'Total loss': 0.41118444701035817} | train loss {'Reaction outcome loss': 0.26347823106492146, 'Total loss': 0.26347823106492146}
2022-12-31 10:42:01,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:01,188 INFO:     Epoch: 51
2022-12-31 10:42:02,808 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4583306610584259, 'Total loss': 0.4583306610584259} | train loss {'Reaction outcome loss': 0.2631553666740118, 'Total loss': 0.2631553666740118}
2022-12-31 10:42:02,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:02,808 INFO:     Epoch: 52
2022-12-31 10:42:04,413 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4374440386891365, 'Total loss': 0.4374440386891365} | train loss {'Reaction outcome loss': 0.26094620294922743, 'Total loss': 0.26094620294922743}
2022-12-31 10:42:04,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:04,414 INFO:     Epoch: 53
2022-12-31 10:42:06,086 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4147533987959226, 'Total loss': 0.4147533987959226} | train loss {'Reaction outcome loss': 0.25633312554001164, 'Total loss': 0.25633312554001164}
2022-12-31 10:42:06,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:06,086 INFO:     Epoch: 54
2022-12-31 10:42:07,717 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4296918685237567, 'Total loss': 0.4296918685237567} | train loss {'Reaction outcome loss': 0.25732137870702504, 'Total loss': 0.25732137870702504}
2022-12-31 10:42:07,717 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:07,717 INFO:     Epoch: 55
2022-12-31 10:42:09,345 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4194343437751134, 'Total loss': 0.4194343437751134} | train loss {'Reaction outcome loss': 0.2560447400523222, 'Total loss': 0.2560447400523222}
2022-12-31 10:42:09,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:09,345 INFO:     Epoch: 56
2022-12-31 10:42:11,019 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46476908127466837, 'Total loss': 0.46476908127466837} | train loss {'Reaction outcome loss': 0.25337475579944757, 'Total loss': 0.25337475579944757}
2022-12-31 10:42:11,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:11,019 INFO:     Epoch: 57
2022-12-31 10:42:12,679 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4322490870952606, 'Total loss': 0.4322490870952606} | train loss {'Reaction outcome loss': 0.2546974878206795, 'Total loss': 0.2546974878206795}
2022-12-31 10:42:12,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:12,679 INFO:     Epoch: 58
2022-12-31 10:42:14,298 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41083795626958214, 'Total loss': 0.41083795626958214} | train loss {'Reaction outcome loss': 0.24694867706470972, 'Total loss': 0.24694867706470972}
2022-12-31 10:42:14,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:14,298 INFO:     Epoch: 59
2022-12-31 10:42:15,945 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4298296550909678, 'Total loss': 0.4298296550909678} | train loss {'Reaction outcome loss': 0.24688284130034033, 'Total loss': 0.24688284130034033}
2022-12-31 10:42:15,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:15,945 INFO:     Epoch: 60
2022-12-31 10:42:17,612 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44586661259333293, 'Total loss': 0.44586661259333293} | train loss {'Reaction outcome loss': 0.24686035918683782, 'Total loss': 0.24686035918683782}
2022-12-31 10:42:17,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:17,613 INFO:     Epoch: 61
2022-12-31 10:42:19,236 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4508453071117401, 'Total loss': 0.4508453071117401} | train loss {'Reaction outcome loss': 0.2388365147870693, 'Total loss': 0.2388365147870693}
2022-12-31 10:42:19,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:19,236 INFO:     Epoch: 62
2022-12-31 10:42:20,860 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4235472172498703, 'Total loss': 0.4235472172498703} | train loss {'Reaction outcome loss': 0.2440025891422795, 'Total loss': 0.2440025891422795}
2022-12-31 10:42:20,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:20,860 INFO:     Epoch: 63
2022-12-31 10:42:22,451 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44590676923592887, 'Total loss': 0.44590676923592887} | train loss {'Reaction outcome loss': 0.23967109890890034, 'Total loss': 0.23967109890890034}
2022-12-31 10:42:22,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:22,451 INFO:     Epoch: 64
2022-12-31 10:42:24,074 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43304500430822374, 'Total loss': 0.43304500430822374} | train loss {'Reaction outcome loss': 0.244391874850657, 'Total loss': 0.244391874850657}
2022-12-31 10:42:24,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:24,074 INFO:     Epoch: 65
2022-12-31 10:42:25,698 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46559440592924756, 'Total loss': 0.46559440592924756} | train loss {'Reaction outcome loss': 0.23256032774056767, 'Total loss': 0.23256032774056767}
2022-12-31 10:42:25,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:25,699 INFO:     Epoch: 66
2022-12-31 10:42:27,322 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4116118798653285, 'Total loss': 0.4116118798653285} | train loss {'Reaction outcome loss': 0.24155516989717415, 'Total loss': 0.24155516989717415}
2022-12-31 10:42:27,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:27,322 INFO:     Epoch: 67
2022-12-31 10:42:28,944 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41101975987354916, 'Total loss': 0.41101975987354916} | train loss {'Reaction outcome loss': 0.23391171115776693, 'Total loss': 0.23391171115776693}
2022-12-31 10:42:28,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:28,944 INFO:     Epoch: 68
2022-12-31 10:42:30,569 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40149805943171185, 'Total loss': 0.40149805943171185} | train loss {'Reaction outcome loss': 0.23755764631077056, 'Total loss': 0.23755764631077056}
2022-12-31 10:42:30,569 INFO:     Found new best model at epoch 68
2022-12-31 10:42:30,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:30,570 INFO:     Epoch: 69
2022-12-31 10:42:32,172 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.43080567320187885, 'Total loss': 0.43080567320187885} | train loss {'Reaction outcome loss': 0.2362906975328707, 'Total loss': 0.2362906975328707}
2022-12-31 10:42:32,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:32,172 INFO:     Epoch: 70
2022-12-31 10:42:33,849 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3970016082127889, 'Total loss': 0.3970016082127889} | train loss {'Reaction outcome loss': 0.23103961296083694, 'Total loss': 0.23103961296083694}
2022-12-31 10:42:33,851 INFO:     Found new best model at epoch 70
2022-12-31 10:42:33,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:33,852 INFO:     Epoch: 71
2022-12-31 10:42:35,487 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39148129324118297, 'Total loss': 0.39148129324118297} | train loss {'Reaction outcome loss': 0.22253745424456975, 'Total loss': 0.22253745424456975}
2022-12-31 10:42:35,487 INFO:     Found new best model at epoch 71
2022-12-31 10:42:35,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:35,488 INFO:     Epoch: 72
2022-12-31 10:42:37,133 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.431397279103597, 'Total loss': 0.431397279103597} | train loss {'Reaction outcome loss': 0.22529424593148464, 'Total loss': 0.22529424593148464}
2022-12-31 10:42:37,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:37,133 INFO:     Epoch: 73
2022-12-31 10:42:38,794 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4005056361357371, 'Total loss': 0.4005056361357371} | train loss {'Reaction outcome loss': 0.2240015680797479, 'Total loss': 0.2240015680797479}
2022-12-31 10:42:38,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:38,795 INFO:     Epoch: 74
2022-12-31 10:42:40,397 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42292801986138023, 'Total loss': 0.42292801986138023} | train loss {'Reaction outcome loss': 0.22425034552113243, 'Total loss': 0.22425034552113243}
2022-12-31 10:42:40,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:40,398 INFO:     Epoch: 75
2022-12-31 10:42:42,006 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3794552147388458, 'Total loss': 0.3794552147388458} | train loss {'Reaction outcome loss': 0.22346642464130365, 'Total loss': 0.22346642464130365}
2022-12-31 10:42:42,006 INFO:     Found new best model at epoch 75
2022-12-31 10:42:42,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:42,007 INFO:     Epoch: 76
2022-12-31 10:42:43,626 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4368198166290919, 'Total loss': 0.4368198166290919} | train loss {'Reaction outcome loss': 0.21947243373962086, 'Total loss': 0.21947243373962086}
2022-12-31 10:42:43,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:43,627 INFO:     Epoch: 77
2022-12-31 10:42:45,246 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4718080500761668, 'Total loss': 0.4718080500761668} | train loss {'Reaction outcome loss': 0.2280525500291037, 'Total loss': 0.2280525500291037}
2022-12-31 10:42:45,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:45,246 INFO:     Epoch: 78
2022-12-31 10:42:46,866 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.44824223816394804, 'Total loss': 0.44824223816394804} | train loss {'Reaction outcome loss': 0.22213444954275224, 'Total loss': 0.22213444954275224}
2022-12-31 10:42:46,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:46,866 INFO:     Epoch: 79
2022-12-31 10:42:48,481 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4408703863620758, 'Total loss': 0.4408703863620758} | train loss {'Reaction outcome loss': 0.2266965969482484, 'Total loss': 0.2266965969482484}
2022-12-31 10:42:48,481 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:48,482 INFO:     Epoch: 80
2022-12-31 10:42:50,067 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44950947364171345, 'Total loss': 0.44950947364171345} | train loss {'Reaction outcome loss': 0.2239613751157957, 'Total loss': 0.2239613751157957}
2022-12-31 10:42:50,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:50,068 INFO:     Epoch: 81
2022-12-31 10:42:51,698 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45404505332310996, 'Total loss': 0.45404505332310996} | train loss {'Reaction outcome loss': 0.22445643482736516, 'Total loss': 0.22445643482736516}
2022-12-31 10:42:51,698 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:51,699 INFO:     Epoch: 82
2022-12-31 10:42:53,318 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4019618411858877, 'Total loss': 0.4019618411858877} | train loss {'Reaction outcome loss': 0.21295754099769068, 'Total loss': 0.21295754099769068}
2022-12-31 10:42:53,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:53,318 INFO:     Epoch: 83
2022-12-31 10:42:54,936 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42483847041924794, 'Total loss': 0.42483847041924794} | train loss {'Reaction outcome loss': 0.21432812416435149, 'Total loss': 0.21432812416435149}
2022-12-31 10:42:54,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:54,937 INFO:     Epoch: 84
2022-12-31 10:42:56,555 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4268934597571691, 'Total loss': 0.4268934597571691} | train loss {'Reaction outcome loss': 0.21990968830318658, 'Total loss': 0.21990968830318658}
2022-12-31 10:42:56,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:56,555 INFO:     Epoch: 85
2022-12-31 10:42:58,157 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41981805165608727, 'Total loss': 0.41981805165608727} | train loss {'Reaction outcome loss': 0.21222096937792612, 'Total loss': 0.21222096937792612}
2022-12-31 10:42:58,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:58,158 INFO:     Epoch: 86
2022-12-31 10:42:59,764 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4168450896938642, 'Total loss': 0.4168450896938642} | train loss {'Reaction outcome loss': 0.21486482902393014, 'Total loss': 0.21486482902393014}
2022-12-31 10:42:59,765 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:42:59,765 INFO:     Epoch: 87
2022-12-31 10:43:01,413 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43398569424947103, 'Total loss': 0.43398569424947103} | train loss {'Reaction outcome loss': 0.2158935497101356, 'Total loss': 0.2158935497101356}
2022-12-31 10:43:01,413 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:01,413 INFO:     Epoch: 88
2022-12-31 10:43:03,044 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4044834683338801, 'Total loss': 0.4044834683338801} | train loss {'Reaction outcome loss': 0.208227006846279, 'Total loss': 0.208227006846279}
2022-12-31 10:43:03,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:03,044 INFO:     Epoch: 89
2022-12-31 10:43:04,669 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4204704691966375, 'Total loss': 0.4204704691966375} | train loss {'Reaction outcome loss': 0.20944201399232615, 'Total loss': 0.20944201399232615}
2022-12-31 10:43:04,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:04,669 INFO:     Epoch: 90
2022-12-31 10:43:06,275 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44520600835482277, 'Total loss': 0.44520600835482277} | train loss {'Reaction outcome loss': 0.21011893646220006, 'Total loss': 0.21011893646220006}
2022-12-31 10:43:06,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:06,275 INFO:     Epoch: 91
2022-12-31 10:43:07,882 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4420981496572495, 'Total loss': 0.4420981496572495} | train loss {'Reaction outcome loss': 0.21494898935679063, 'Total loss': 0.21494898935679063}
2022-12-31 10:43:07,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:07,882 INFO:     Epoch: 92
2022-12-31 10:43:09,525 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4445244630177816, 'Total loss': 0.4445244630177816} | train loss {'Reaction outcome loss': 0.2047423538533359, 'Total loss': 0.2047423538533359}
2022-12-31 10:43:09,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:09,526 INFO:     Epoch: 93
2022-12-31 10:43:11,172 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39973053137461345, 'Total loss': 0.39973053137461345} | train loss {'Reaction outcome loss': 0.20330731170285588, 'Total loss': 0.20330731170285588}
2022-12-31 10:43:11,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:11,173 INFO:     Epoch: 94
2022-12-31 10:43:12,847 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4436284422874451, 'Total loss': 0.4436284422874451} | train loss {'Reaction outcome loss': 0.20437351924901834, 'Total loss': 0.20437351924901834}
2022-12-31 10:43:12,847 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:12,847 INFO:     Epoch: 95
2022-12-31 10:43:14,516 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4109579672416051, 'Total loss': 0.4109579672416051} | train loss {'Reaction outcome loss': 0.20951240496972193, 'Total loss': 0.20951240496972193}
2022-12-31 10:43:14,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:14,516 INFO:     Epoch: 96
2022-12-31 10:43:16,130 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4505794515212377, 'Total loss': 0.4505794515212377} | train loss {'Reaction outcome loss': 0.2030689639009078, 'Total loss': 0.2030689639009078}
2022-12-31 10:43:16,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:16,131 INFO:     Epoch: 97
2022-12-31 10:43:17,730 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4607816775639852, 'Total loss': 0.4607816775639852} | train loss {'Reaction outcome loss': 0.20598073147022122, 'Total loss': 0.20598073147022122}
2022-12-31 10:43:17,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:17,730 INFO:     Epoch: 98
2022-12-31 10:43:19,403 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4118990292151769, 'Total loss': 0.4118990292151769} | train loss {'Reaction outcome loss': 0.20702583930498855, 'Total loss': 0.20702583930498855}
2022-12-31 10:43:19,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:19,404 INFO:     Epoch: 99
2022-12-31 10:43:21,076 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4691192517677943, 'Total loss': 0.4691192517677943} | train loss {'Reaction outcome loss': 0.20874305519978062, 'Total loss': 0.20874305519978062}
2022-12-31 10:43:21,076 INFO:     Best model found after epoch 76 of 100.
2022-12-31 10:43:21,077 INFO:   Done with stage: TRAINING
2022-12-31 10:43:21,077 INFO:   Starting stage: EVALUATION
2022-12-31 10:43:21,199 INFO:   Done with stage: EVALUATION
2022-12-31 10:43:21,199 INFO:   Leaving out SEQ value Fold_7
2022-12-31 10:43:21,212 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 10:43:21,212 INFO:   Starting stage: FEATURE SCALING
2022-12-31 10:43:21,853 INFO:   Done with stage: FEATURE SCALING
2022-12-31 10:43:21,853 INFO:   Starting stage: SCALING TARGETS
2022-12-31 10:43:21,922 INFO:   Done with stage: SCALING TARGETS
2022-12-31 10:43:21,922 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:43:21,923 INFO:     No hyperparam tuning for this model
2022-12-31 10:43:21,923 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:43:21,923 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 10:43:21,923 INFO:     None feature selector for col prot
2022-12-31 10:43:21,923 INFO:     None feature selector for col prot
2022-12-31 10:43:21,924 INFO:     None feature selector for col prot
2022-12-31 10:43:21,924 INFO:     None feature selector for col chem
2022-12-31 10:43:21,924 INFO:     None feature selector for col chem
2022-12-31 10:43:21,924 INFO:     None feature selector for col chem
2022-12-31 10:43:21,924 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 10:43:21,924 INFO:   Starting stage: BUILD MODEL
2022-12-31 10:43:21,926 INFO:     Number of params in model 223921
2022-12-31 10:43:21,929 INFO:   Done with stage: BUILD MODEL
2022-12-31 10:43:21,929 INFO:   Starting stage: TRAINING
2022-12-31 10:43:21,974 INFO:     Val loss before train {'Reaction outcome loss': 1.0403983831405639, 'Total loss': 1.0403983831405639}
2022-12-31 10:43:21,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:21,974 INFO:     Epoch: 0
2022-12-31 10:43:23,576 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6770643909772237, 'Total loss': 0.6770643909772237} | train loss {'Reaction outcome loss': 0.8107461447480822, 'Total loss': 0.8107461447480822}
2022-12-31 10:43:23,576 INFO:     Found new best model at epoch 0
2022-12-31 10:43:23,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:23,577 INFO:     Epoch: 1
2022-12-31 10:43:25,158 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5734498222668966, 'Total loss': 0.5734498222668966} | train loss {'Reaction outcome loss': 0.6023499137946289, 'Total loss': 0.6023499137946289}
2022-12-31 10:43:25,158 INFO:     Found new best model at epoch 1
2022-12-31 10:43:25,159 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:25,159 INFO:     Epoch: 2
2022-12-31 10:43:26,753 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5035430312156677, 'Total loss': 0.5035430312156677} | train loss {'Reaction outcome loss': 0.5328398153294612, 'Total loss': 0.5328398153294612}
2022-12-31 10:43:26,753 INFO:     Found new best model at epoch 2
2022-12-31 10:43:26,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:26,754 INFO:     Epoch: 3
2022-12-31 10:43:28,349 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5060884873072307, 'Total loss': 0.5060884873072307} | train loss {'Reaction outcome loss': 0.5048622462871301, 'Total loss': 0.5048622462871301}
2022-12-31 10:43:28,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:28,350 INFO:     Epoch: 4
2022-12-31 10:43:29,947 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5098161121209462, 'Total loss': 0.5098161121209462} | train loss {'Reaction outcome loss': 0.4885391240572407, 'Total loss': 0.4885391240572407}
2022-12-31 10:43:29,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:29,947 INFO:     Epoch: 5
2022-12-31 10:43:31,544 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4553913285334905, 'Total loss': 0.4553913285334905} | train loss {'Reaction outcome loss': 0.47754160945650437, 'Total loss': 0.47754160945650437}
2022-12-31 10:43:31,544 INFO:     Found new best model at epoch 5
2022-12-31 10:43:31,545 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:31,545 INFO:     Epoch: 6
2022-12-31 10:43:33,160 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4890869230031967, 'Total loss': 0.4890869230031967} | train loss {'Reaction outcome loss': 0.4640122678973814, 'Total loss': 0.4640122678973814}
2022-12-31 10:43:33,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:33,160 INFO:     Epoch: 7
2022-12-31 10:43:34,750 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4721502164999644, 'Total loss': 0.4721502164999644} | train loss {'Reaction outcome loss': 0.4588068104790945, 'Total loss': 0.4588068104790945}
2022-12-31 10:43:34,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:34,750 INFO:     Epoch: 8
2022-12-31 10:43:36,364 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4347560981909434, 'Total loss': 0.4347560981909434} | train loss {'Reaction outcome loss': 0.45053097472464954, 'Total loss': 0.45053097472464954}
2022-12-31 10:43:36,365 INFO:     Found new best model at epoch 8
2022-12-31 10:43:36,365 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:36,366 INFO:     Epoch: 9
2022-12-31 10:43:37,964 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4266821836431821, 'Total loss': 0.4266821836431821} | train loss {'Reaction outcome loss': 0.4458433719229524, 'Total loss': 0.4458433719229524}
2022-12-31 10:43:37,965 INFO:     Found new best model at epoch 9
2022-12-31 10:43:37,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:37,965 INFO:     Epoch: 10
2022-12-31 10:43:39,566 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47956556181112925, 'Total loss': 0.47956556181112925} | train loss {'Reaction outcome loss': 0.43822209406508145, 'Total loss': 0.43822209406508145}
2022-12-31 10:43:39,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:39,566 INFO:     Epoch: 11
2022-12-31 10:43:41,176 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4171594828367233, 'Total loss': 0.4171594828367233} | train loss {'Reaction outcome loss': 0.4312430217753362, 'Total loss': 0.4312430217753362}
2022-12-31 10:43:41,176 INFO:     Found new best model at epoch 11
2022-12-31 10:43:41,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:41,177 INFO:     Epoch: 12
2022-12-31 10:43:42,776 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4241671482721964, 'Total loss': 0.4241671482721964} | train loss {'Reaction outcome loss': 0.4255434475621603, 'Total loss': 0.4255434475621603}
2022-12-31 10:43:42,776 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:42,776 INFO:     Epoch: 13
2022-12-31 10:43:44,355 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4306993126869202, 'Total loss': 0.4306993126869202} | train loss {'Reaction outcome loss': 0.4218083981179843, 'Total loss': 0.4218083981179843}
2022-12-31 10:43:44,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:44,356 INFO:     Epoch: 14
2022-12-31 10:43:45,993 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42307683726151785, 'Total loss': 0.42307683726151785} | train loss {'Reaction outcome loss': 0.42078558529598, 'Total loss': 0.42078558529598}
2022-12-31 10:43:45,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:45,993 INFO:     Epoch: 15
2022-12-31 10:43:47,634 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42144223749637605, 'Total loss': 0.42144223749637605} | train loss {'Reaction outcome loss': 0.41037073173988475, 'Total loss': 0.41037073173988475}
2022-12-31 10:43:47,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:47,634 INFO:     Epoch: 16
2022-12-31 10:43:49,250 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42251418232917787, 'Total loss': 0.42251418232917787} | train loss {'Reaction outcome loss': 0.4062839002504836, 'Total loss': 0.4062839002504836}
2022-12-31 10:43:49,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:49,250 INFO:     Epoch: 17
2022-12-31 10:43:50,849 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4449231008688609, 'Total loss': 0.4449231008688609} | train loss {'Reaction outcome loss': 0.4019623773757124, 'Total loss': 0.4019623773757124}
2022-12-31 10:43:50,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:50,850 INFO:     Epoch: 18
2022-12-31 10:43:52,435 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.40215750684340795, 'Total loss': 0.40215750684340795} | train loss {'Reaction outcome loss': 0.39035462120371145, 'Total loss': 0.39035462120371145}
2022-12-31 10:43:52,436 INFO:     Found new best model at epoch 18
2022-12-31 10:43:52,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:52,436 INFO:     Epoch: 19
2022-12-31 10:43:54,012 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.39598100682099663, 'Total loss': 0.39598100682099663} | train loss {'Reaction outcome loss': 0.3859182331629478, 'Total loss': 0.3859182331629478}
2022-12-31 10:43:54,013 INFO:     Found new best model at epoch 19
2022-12-31 10:43:54,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:54,013 INFO:     Epoch: 20
2022-12-31 10:43:55,609 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41247572253147763, 'Total loss': 0.41247572253147763} | train loss {'Reaction outcome loss': 0.38073141040810704, 'Total loss': 0.38073141040810704}
2022-12-31 10:43:55,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:55,610 INFO:     Epoch: 21
2022-12-31 10:43:57,209 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4288636088371277, 'Total loss': 0.4288636088371277} | train loss {'Reaction outcome loss': 0.37398882667078587, 'Total loss': 0.37398882667078587}
2022-12-31 10:43:57,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:57,209 INFO:     Epoch: 22
2022-12-31 10:43:58,801 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4136840840180715, 'Total loss': 0.4136840840180715} | train loss {'Reaction outcome loss': 0.3785144307643828, 'Total loss': 0.3785144307643828}
2022-12-31 10:43:58,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:43:58,801 INFO:     Epoch: 23
2022-12-31 10:44:00,400 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40255792339642843, 'Total loss': 0.40255792339642843} | train loss {'Reaction outcome loss': 0.3623899693607631, 'Total loss': 0.3623899693607631}
2022-12-31 10:44:00,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:00,400 INFO:     Epoch: 24
2022-12-31 10:44:01,967 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40917641123135884, 'Total loss': 0.40917641123135884} | train loss {'Reaction outcome loss': 0.36887310752577157, 'Total loss': 0.36887310752577157}
2022-12-31 10:44:01,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:01,967 INFO:     Epoch: 25
2022-12-31 10:44:03,559 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.38221372067928316, 'Total loss': 0.38221372067928316} | train loss {'Reaction outcome loss': 0.3629970590509202, 'Total loss': 0.3629970590509202}
2022-12-31 10:44:03,560 INFO:     Found new best model at epoch 25
2022-12-31 10:44:03,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:03,561 INFO:     Epoch: 26
2022-12-31 10:44:05,152 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4319228410720825, 'Total loss': 0.4319228410720825} | train loss {'Reaction outcome loss': 0.3536497815410151, 'Total loss': 0.3536497815410151}
2022-12-31 10:44:05,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:05,152 INFO:     Epoch: 27
2022-12-31 10:44:06,744 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3859799265861511, 'Total loss': 0.3859799265861511} | train loss {'Reaction outcome loss': 0.3466922546716502, 'Total loss': 0.3466922546716502}
2022-12-31 10:44:06,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:06,744 INFO:     Epoch: 28
2022-12-31 10:44:08,336 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3907320042451223, 'Total loss': 0.3907320042451223} | train loss {'Reaction outcome loss': 0.34197026387835944, 'Total loss': 0.34197026387835944}
2022-12-31 10:44:08,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:08,336 INFO:     Epoch: 29
2022-12-31 10:44:09,929 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.37266291479269664, 'Total loss': 0.37266291479269664} | train loss {'Reaction outcome loss': 0.343429692823739, 'Total loss': 0.343429692823739}
2022-12-31 10:44:09,929 INFO:     Found new best model at epoch 29
2022-12-31 10:44:09,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:09,930 INFO:     Epoch: 30
2022-12-31 10:44:11,494 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39918040384848913, 'Total loss': 0.39918040384848913} | train loss {'Reaction outcome loss': 0.33361086252070693, 'Total loss': 0.33361086252070693}
2022-12-31 10:44:11,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:11,494 INFO:     Epoch: 31
2022-12-31 10:44:13,068 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.37586528062820435, 'Total loss': 0.37586528062820435} | train loss {'Reaction outcome loss': 0.3340471854882084, 'Total loss': 0.3340471854882084}
2022-12-31 10:44:13,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:13,068 INFO:     Epoch: 32
2022-12-31 10:44:14,668 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3930658201376597, 'Total loss': 0.3930658201376597} | train loss {'Reaction outcome loss': 0.32387877802235365, 'Total loss': 0.32387877802235365}
2022-12-31 10:44:14,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:14,668 INFO:     Epoch: 33
2022-12-31 10:44:16,260 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.379960302511851, 'Total loss': 0.379960302511851} | train loss {'Reaction outcome loss': 0.325714031669454, 'Total loss': 0.325714031669454}
2022-12-31 10:44:16,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:16,262 INFO:     Epoch: 34
2022-12-31 10:44:17,854 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3840030739704768, 'Total loss': 0.3840030739704768} | train loss {'Reaction outcome loss': 0.3212181212802003, 'Total loss': 0.3212181212802003}
2022-12-31 10:44:17,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:17,854 INFO:     Epoch: 35
2022-12-31 10:44:19,426 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4037848363320033, 'Total loss': 0.4037848363320033} | train loss {'Reaction outcome loss': 0.31480861762470574, 'Total loss': 0.31480861762470574}
2022-12-31 10:44:19,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:19,427 INFO:     Epoch: 36
2022-12-31 10:44:21,026 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4087270975112915, 'Total loss': 0.4087270975112915} | train loss {'Reaction outcome loss': 0.3042445769057657, 'Total loss': 0.3042445769057657}
2022-12-31 10:44:21,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:21,027 INFO:     Epoch: 37
2022-12-31 10:44:22,621 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3784017026424408, 'Total loss': 0.3784017026424408} | train loss {'Reaction outcome loss': 0.3045979780654838, 'Total loss': 0.3045979780654838}
2022-12-31 10:44:22,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:22,622 INFO:     Epoch: 38
2022-12-31 10:44:24,215 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41177675475676856, 'Total loss': 0.41177675475676856} | train loss {'Reaction outcome loss': 0.30416012142043913, 'Total loss': 0.30416012142043913}
2022-12-31 10:44:24,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:24,215 INFO:     Epoch: 39
2022-12-31 10:44:25,811 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3715380767981211, 'Total loss': 0.3715380767981211} | train loss {'Reaction outcome loss': 0.30143268596734446, 'Total loss': 0.30143268596734446}
2022-12-31 10:44:25,811 INFO:     Found new best model at epoch 39
2022-12-31 10:44:25,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:25,812 INFO:     Epoch: 40
2022-12-31 10:44:27,386 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.38722907404104867, 'Total loss': 0.38722907404104867} | train loss {'Reaction outcome loss': 0.30034547478613194, 'Total loss': 0.30034547478613194}
2022-12-31 10:44:27,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:27,386 INFO:     Epoch: 41
2022-12-31 10:44:28,966 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4276729037364324, 'Total loss': 0.4276729037364324} | train loss {'Reaction outcome loss': 0.29552861992405716, 'Total loss': 0.29552861992405716}
2022-12-31 10:44:28,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:28,967 INFO:     Epoch: 42
2022-12-31 10:44:30,559 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42382533649603527, 'Total loss': 0.42382533649603527} | train loss {'Reaction outcome loss': 0.28784021433361257, 'Total loss': 0.28784021433361257}
2022-12-31 10:44:30,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:30,559 INFO:     Epoch: 43
2022-12-31 10:44:32,152 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3593070968985558, 'Total loss': 0.3593070968985558} | train loss {'Reaction outcome loss': 0.2879311876221947, 'Total loss': 0.2879311876221947}
2022-12-31 10:44:32,152 INFO:     Found new best model at epoch 43
2022-12-31 10:44:32,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:32,153 INFO:     Epoch: 44
2022-12-31 10:44:33,746 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.389022034406662, 'Total loss': 0.389022034406662} | train loss {'Reaction outcome loss': 0.2809654016074908, 'Total loss': 0.2809654016074908}
2022-12-31 10:44:33,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:33,746 INFO:     Epoch: 45
2022-12-31 10:44:35,339 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3639693905909856, 'Total loss': 0.3639693905909856} | train loss {'Reaction outcome loss': 0.28607970764384655, 'Total loss': 0.28607970764384655}
2022-12-31 10:44:35,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:35,340 INFO:     Epoch: 46
2022-12-31 10:44:36,933 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3958671510219574, 'Total loss': 0.3958671510219574} | train loss {'Reaction outcome loss': 0.2774870108921815, 'Total loss': 0.2774870108921815}
2022-12-31 10:44:36,933 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:36,933 INFO:     Epoch: 47
2022-12-31 10:44:38,492 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3785105655590693, 'Total loss': 0.3785105655590693} | train loss {'Reaction outcome loss': 0.2722381913327496, 'Total loss': 0.2722381913327496}
2022-12-31 10:44:38,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:38,492 INFO:     Epoch: 48
2022-12-31 10:44:40,086 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4302881121635437, 'Total loss': 0.4302881121635437} | train loss {'Reaction outcome loss': 0.2735267528026861, 'Total loss': 0.2735267528026861}
2022-12-31 10:44:40,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:40,086 INFO:     Epoch: 49
2022-12-31 10:44:41,682 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39555237789948783, 'Total loss': 0.39555237789948783} | train loss {'Reaction outcome loss': 0.2710218684217573, 'Total loss': 0.2710218684217573}
2022-12-31 10:44:41,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:41,682 INFO:     Epoch: 50
2022-12-31 10:44:43,275 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3774712453285853, 'Total loss': 0.3774712453285853} | train loss {'Reaction outcome loss': 0.2708363144855647, 'Total loss': 0.2708363144855647}
2022-12-31 10:44:43,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:43,275 INFO:     Epoch: 51
2022-12-31 10:44:44,869 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3664017697175344, 'Total loss': 0.3664017697175344} | train loss {'Reaction outcome loss': 0.25648662609721185, 'Total loss': 0.25648662609721185}
2022-12-31 10:44:44,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:44,869 INFO:     Epoch: 52
2022-12-31 10:44:46,433 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3753266433874766, 'Total loss': 0.3753266433874766} | train loss {'Reaction outcome loss': 0.2567745814657342, 'Total loss': 0.2567745814657342}
2022-12-31 10:44:46,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:46,433 INFO:     Epoch: 53
2022-12-31 10:44:48,024 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3783018346875906, 'Total loss': 0.3783018346875906} | train loss {'Reaction outcome loss': 0.26301013474373053, 'Total loss': 0.26301013474373053}
2022-12-31 10:44:48,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:48,025 INFO:     Epoch: 54
2022-12-31 10:44:49,621 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4026230176289876, 'Total loss': 0.4026230176289876} | train loss {'Reaction outcome loss': 0.25177096740009575, 'Total loss': 0.25177096740009575}
2022-12-31 10:44:49,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:49,621 INFO:     Epoch: 55
2022-12-31 10:44:51,217 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38180165489514667, 'Total loss': 0.38180165489514667} | train loss {'Reaction outcome loss': 0.25505046845570095, 'Total loss': 0.25505046845570095}
2022-12-31 10:44:51,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:51,218 INFO:     Epoch: 56
2022-12-31 10:44:52,812 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3762457917133967, 'Total loss': 0.3762457917133967} | train loss {'Reaction outcome loss': 0.2520331272610674, 'Total loss': 0.2520331272610674}
2022-12-31 10:44:52,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:52,812 INFO:     Epoch: 57
2022-12-31 10:44:54,408 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3842975159486135, 'Total loss': 0.3842975159486135} | train loss {'Reaction outcome loss': 0.24722400176454418, 'Total loss': 0.24722400176454418}
2022-12-31 10:44:54,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:54,409 INFO:     Epoch: 58
2022-12-31 10:44:55,969 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40962039232254027, 'Total loss': 0.40962039232254027} | train loss {'Reaction outcome loss': 0.2508204477859566, 'Total loss': 0.2508204477859566}
2022-12-31 10:44:55,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:55,969 INFO:     Epoch: 59
2022-12-31 10:44:57,564 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3885564237833023, 'Total loss': 0.3885564237833023} | train loss {'Reaction outcome loss': 0.24656361965530546, 'Total loss': 0.24656361965530546}
2022-12-31 10:44:57,565 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:57,565 INFO:     Epoch: 60
2022-12-31 10:44:59,160 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4400624046723048, 'Total loss': 0.4400624046723048} | train loss {'Reaction outcome loss': 0.24229620193151663, 'Total loss': 0.24229620193151663}
2022-12-31 10:44:59,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:44:59,160 INFO:     Epoch: 61
2022-12-31 10:45:00,757 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3968923509120941, 'Total loss': 0.3968923509120941} | train loss {'Reaction outcome loss': 0.2474269323581218, 'Total loss': 0.2474269323581218}
2022-12-31 10:45:00,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:00,757 INFO:     Epoch: 62
2022-12-31 10:45:02,354 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3706419060627619, 'Total loss': 0.3706419060627619} | train loss {'Reaction outcome loss': 0.23926223928693438, 'Total loss': 0.23926223928693438}
2022-12-31 10:45:02,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:02,354 INFO:     Epoch: 63
2022-12-31 10:45:03,950 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.36745639741420744, 'Total loss': 0.36745639741420744} | train loss {'Reaction outcome loss': 0.23984601419337476, 'Total loss': 0.23984601419337476}
2022-12-31 10:45:03,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:03,951 INFO:     Epoch: 64
2022-12-31 10:45:05,508 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41199709872404733, 'Total loss': 0.41199709872404733} | train loss {'Reaction outcome loss': 0.2371712573634012, 'Total loss': 0.2371712573634012}
2022-12-31 10:45:05,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:05,508 INFO:     Epoch: 65
2022-12-31 10:45:07,104 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.33306794222444297, 'Total loss': 0.33306794222444297} | train loss {'Reaction outcome loss': 0.23427171037144903, 'Total loss': 0.23427171037144903}
2022-12-31 10:45:07,104 INFO:     Found new best model at epoch 65
2022-12-31 10:45:07,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:07,105 INFO:     Epoch: 66
2022-12-31 10:45:08,699 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.36343236168225607, 'Total loss': 0.36343236168225607} | train loss {'Reaction outcome loss': 0.23290826313632684, 'Total loss': 0.23290826313632684}
2022-12-31 10:45:08,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:08,699 INFO:     Epoch: 67
2022-12-31 10:45:10,293 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4309528827667236, 'Total loss': 0.4309528827667236} | train loss {'Reaction outcome loss': 0.23076614666131945, 'Total loss': 0.23076614666131945}
2022-12-31 10:45:10,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:10,294 INFO:     Epoch: 68
2022-12-31 10:45:11,889 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3909771203994751, 'Total loss': 0.3909771203994751} | train loss {'Reaction outcome loss': 0.22759332796762677, 'Total loss': 0.22759332796762677}
2022-12-31 10:45:11,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:11,889 INFO:     Epoch: 69
2022-12-31 10:45:13,449 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4134456525246302, 'Total loss': 0.4134456525246302} | train loss {'Reaction outcome loss': 0.23173447007680462, 'Total loss': 0.23173447007680462}
2022-12-31 10:45:13,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:13,449 INFO:     Epoch: 70
2022-12-31 10:45:15,043 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.36867867360512413, 'Total loss': 0.36867867360512413} | train loss {'Reaction outcome loss': 0.2241353248551923, 'Total loss': 0.2241353248551923}
2022-12-31 10:45:15,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:15,043 INFO:     Epoch: 71
2022-12-31 10:45:16,638 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.35263344111541906, 'Total loss': 0.35263344111541906} | train loss {'Reaction outcome loss': 0.2277487051285749, 'Total loss': 0.2277487051285749}
2022-12-31 10:45:16,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:16,638 INFO:     Epoch: 72
2022-12-31 10:45:18,235 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3627418955167135, 'Total loss': 0.3627418955167135} | train loss {'Reaction outcome loss': 0.2273125256527297, 'Total loss': 0.2273125256527297}
2022-12-31 10:45:18,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:18,236 INFO:     Epoch: 73
2022-12-31 10:45:19,832 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3723325528204441, 'Total loss': 0.3723325528204441} | train loss {'Reaction outcome loss': 0.2318296837076599, 'Total loss': 0.2318296837076599}
2022-12-31 10:45:19,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:19,832 INFO:     Epoch: 74
2022-12-31 10:45:21,428 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3865185469388962, 'Total loss': 0.3865185469388962} | train loss {'Reaction outcome loss': 0.2196311684202974, 'Total loss': 0.2196311684202974}
2022-12-31 10:45:21,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:21,429 INFO:     Epoch: 75
2022-12-31 10:45:22,989 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4347120384375254, 'Total loss': 0.4347120384375254} | train loss {'Reaction outcome loss': 0.22007991712757924, 'Total loss': 0.22007991712757924}
2022-12-31 10:45:22,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:22,990 INFO:     Epoch: 76
2022-12-31 10:45:24,587 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.38689659064014753, 'Total loss': 0.38689659064014753} | train loss {'Reaction outcome loss': 0.2225785999062614, 'Total loss': 0.2225785999062614}
2022-12-31 10:45:24,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:24,588 INFO:     Epoch: 77
2022-12-31 10:45:26,194 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3772028307120005, 'Total loss': 0.3772028307120005} | train loss {'Reaction outcome loss': 0.22237917031739315, 'Total loss': 0.22237917031739315}
2022-12-31 10:45:26,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:26,194 INFO:     Epoch: 78
2022-12-31 10:45:27,790 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3847932537396749, 'Total loss': 0.3847932537396749} | train loss {'Reaction outcome loss': 0.2201798658709239, 'Total loss': 0.2201798658709239}
2022-12-31 10:45:27,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:27,791 INFO:     Epoch: 79
2022-12-31 10:45:29,385 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3808460791905721, 'Total loss': 0.3808460791905721} | train loss {'Reaction outcome loss': 0.2200570254838162, 'Total loss': 0.2200570254838162}
2022-12-31 10:45:29,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:29,386 INFO:     Epoch: 80
2022-12-31 10:45:30,973 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.366389403740565, 'Total loss': 0.366389403740565} | train loss {'Reaction outcome loss': 0.22085593596617453, 'Total loss': 0.22085593596617453}
2022-12-31 10:45:30,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:30,974 INFO:     Epoch: 81
2022-12-31 10:45:32,529 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.36582392305135725, 'Total loss': 0.36582392305135725} | train loss {'Reaction outcome loss': 0.21679819328880387, 'Total loss': 0.21679819328880387}
2022-12-31 10:45:32,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:32,529 INFO:     Epoch: 82
2022-12-31 10:45:34,121 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.38287750085194905, 'Total loss': 0.38287750085194905} | train loss {'Reaction outcome loss': 0.22661766164467065, 'Total loss': 0.22661766164467065}
2022-12-31 10:45:34,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:34,122 INFO:     Epoch: 83
2022-12-31 10:45:35,750 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3829060430328051, 'Total loss': 0.3829060430328051} | train loss {'Reaction outcome loss': 0.2121047950859596, 'Total loss': 0.2121047950859596}
2022-12-31 10:45:35,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:35,750 INFO:     Epoch: 84
2022-12-31 10:45:37,376 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3929703722397486, 'Total loss': 0.3929703722397486} | train loss {'Reaction outcome loss': 0.20577696803277426, 'Total loss': 0.20577696803277426}
2022-12-31 10:45:37,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:37,376 INFO:     Epoch: 85
2022-12-31 10:45:38,984 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.37726306716601055, 'Total loss': 0.37726306716601055} | train loss {'Reaction outcome loss': 0.21611004280619814, 'Total loss': 0.21611004280619814}
2022-12-31 10:45:38,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:38,984 INFO:     Epoch: 86
2022-12-31 10:45:40,551 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4077049225568771, 'Total loss': 0.4077049225568771} | train loss {'Reaction outcome loss': 0.20554009959591132, 'Total loss': 0.20554009959591132}
2022-12-31 10:45:40,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:40,552 INFO:     Epoch: 87
2022-12-31 10:45:42,167 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4043001929918925, 'Total loss': 0.4043001929918925} | train loss {'Reaction outcome loss': 0.21471462177153486, 'Total loss': 0.21471462177153486}
2022-12-31 10:45:42,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:42,167 INFO:     Epoch: 88
2022-12-31 10:45:43,800 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3586467906832695, 'Total loss': 0.3586467906832695} | train loss {'Reaction outcome loss': 0.2100438665272328, 'Total loss': 0.2100438665272328}
2022-12-31 10:45:43,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:43,800 INFO:     Epoch: 89
2022-12-31 10:45:45,441 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3833501289288203, 'Total loss': 0.3833501289288203} | train loss {'Reaction outcome loss': 0.21236489838274725, 'Total loss': 0.21236489838274725}
2022-12-31 10:45:45,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:45,441 INFO:     Epoch: 90
2022-12-31 10:45:47,090 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4049008627732595, 'Total loss': 0.4049008627732595} | train loss {'Reaction outcome loss': 0.1997887670694694, 'Total loss': 0.1997887670694694}
2022-12-31 10:45:47,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:47,090 INFO:     Epoch: 91
2022-12-31 10:45:48,733 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3734023635586103, 'Total loss': 0.3734023635586103} | train loss {'Reaction outcome loss': 0.20961161084255597, 'Total loss': 0.20961161084255597}
2022-12-31 10:45:48,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:48,733 INFO:     Epoch: 92
2022-12-31 10:45:50,278 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4072517777482669, 'Total loss': 0.4072517777482669} | train loss {'Reaction outcome loss': 0.21027022430224576, 'Total loss': 0.21027022430224576}
2022-12-31 10:45:50,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:50,278 INFO:     Epoch: 93
2022-12-31 10:45:51,879 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39238386948903403, 'Total loss': 0.39238386948903403} | train loss {'Reaction outcome loss': 0.20643040819270334, 'Total loss': 0.20643040819270334}
2022-12-31 10:45:51,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:51,880 INFO:     Epoch: 94
2022-12-31 10:45:53,477 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4152418156464895, 'Total loss': 0.4152418156464895} | train loss {'Reaction outcome loss': 0.20845702180407777, 'Total loss': 0.20845702180407777}
2022-12-31 10:45:53,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:53,477 INFO:     Epoch: 95
2022-12-31 10:45:55,073 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3975919405619303, 'Total loss': 0.3975919405619303} | train loss {'Reaction outcome loss': 0.20755223294951186, 'Total loss': 0.20755223294951186}
2022-12-31 10:45:55,073 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:55,073 INFO:     Epoch: 96
2022-12-31 10:45:56,679 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.37636370162169136, 'Total loss': 0.37636370162169136} | train loss {'Reaction outcome loss': 0.20632682953464943, 'Total loss': 0.20632682953464943}
2022-12-31 10:45:56,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:56,679 INFO:     Epoch: 97
2022-12-31 10:45:58,311 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3702798197666804, 'Total loss': 0.3702798197666804} | train loss {'Reaction outcome loss': 0.2022608151509814, 'Total loss': 0.2022608151509814}
2022-12-31 10:45:58,313 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:58,313 INFO:     Epoch: 98
2022-12-31 10:45:59,851 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.37203304717938107, 'Total loss': 0.37203304717938107} | train loss {'Reaction outcome loss': 0.20103325681883272, 'Total loss': 0.20103325681883272}
2022-12-31 10:45:59,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:45:59,851 INFO:     Epoch: 99
2022-12-31 10:46:01,448 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3644157548745473, 'Total loss': 0.3644157548745473} | train loss {'Reaction outcome loss': 0.2010991396994269, 'Total loss': 0.2010991396994269}
2022-12-31 10:46:01,448 INFO:     Best model found after epoch 66 of 100.
2022-12-31 10:46:01,448 INFO:   Done with stage: TRAINING
2022-12-31 10:46:01,448 INFO:   Starting stage: EVALUATION
2022-12-31 10:46:01,581 INFO:   Done with stage: EVALUATION
2022-12-31 10:46:01,581 INFO:   Leaving out SEQ value Fold_8
2022-12-31 10:46:01,594 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 10:46:01,594 INFO:   Starting stage: FEATURE SCALING
2022-12-31 10:46:02,237 INFO:   Done with stage: FEATURE SCALING
2022-12-31 10:46:02,237 INFO:   Starting stage: SCALING TARGETS
2022-12-31 10:46:02,306 INFO:   Done with stage: SCALING TARGETS
2022-12-31 10:46:02,306 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:46:02,306 INFO:     No hyperparam tuning for this model
2022-12-31 10:46:02,306 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:46:02,306 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 10:46:02,307 INFO:     None feature selector for col prot
2022-12-31 10:46:02,307 INFO:     None feature selector for col prot
2022-12-31 10:46:02,307 INFO:     None feature selector for col prot
2022-12-31 10:46:02,308 INFO:     None feature selector for col chem
2022-12-31 10:46:02,308 INFO:     None feature selector for col chem
2022-12-31 10:46:02,308 INFO:     None feature selector for col chem
2022-12-31 10:46:02,308 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 10:46:02,308 INFO:   Starting stage: BUILD MODEL
2022-12-31 10:46:02,310 INFO:     Number of params in model 223921
2022-12-31 10:46:02,313 INFO:   Done with stage: BUILD MODEL
2022-12-31 10:46:02,313 INFO:   Starting stage: TRAINING
2022-12-31 10:46:02,359 INFO:     Val loss before train {'Reaction outcome loss': 0.9372050444285075, 'Total loss': 0.9372050444285075}
2022-12-31 10:46:02,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:02,359 INFO:     Epoch: 0
2022-12-31 10:46:03,969 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.633927971124649, 'Total loss': 0.633927971124649} | train loss {'Reaction outcome loss': 0.8017272842705034, 'Total loss': 0.8017272842705034}
2022-12-31 10:46:03,969 INFO:     Found new best model at epoch 0
2022-12-31 10:46:03,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:03,970 INFO:     Epoch: 1
2022-12-31 10:46:05,585 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4914971391359965, 'Total loss': 0.4914971391359965} | train loss {'Reaction outcome loss': 0.592355969096349, 'Total loss': 0.592355969096349}
2022-12-31 10:46:05,586 INFO:     Found new best model at epoch 1
2022-12-31 10:46:05,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:05,587 INFO:     Epoch: 2
2022-12-31 10:46:07,191 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5036023457845052, 'Total loss': 0.5036023457845052} | train loss {'Reaction outcome loss': 0.5282059707527557, 'Total loss': 0.5282059707527557}
2022-12-31 10:46:07,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:07,191 INFO:     Epoch: 3
2022-12-31 10:46:08,736 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.46476269563039146, 'Total loss': 0.46476269563039146} | train loss {'Reaction outcome loss': 0.5072397239210373, 'Total loss': 0.5072397239210373}
2022-12-31 10:46:08,736 INFO:     Found new best model at epoch 3
2022-12-31 10:46:08,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:08,737 INFO:     Epoch: 4
2022-12-31 10:46:10,354 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44107129573822024, 'Total loss': 0.44107129573822024} | train loss {'Reaction outcome loss': 0.4931992965915143, 'Total loss': 0.4931992965915143}
2022-12-31 10:46:10,354 INFO:     Found new best model at epoch 4
2022-12-31 10:46:10,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:10,355 INFO:     Epoch: 5
2022-12-31 10:46:11,974 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43280363976955416, 'Total loss': 0.43280363976955416} | train loss {'Reaction outcome loss': 0.4836785999876497, 'Total loss': 0.4836785999876497}
2022-12-31 10:46:11,974 INFO:     Found new best model at epoch 5
2022-12-31 10:46:11,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:11,975 INFO:     Epoch: 6
2022-12-31 10:46:13,594 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42504546443621316, 'Total loss': 0.42504546443621316} | train loss {'Reaction outcome loss': 0.47113827914537504, 'Total loss': 0.47113827914537504}
2022-12-31 10:46:13,594 INFO:     Found new best model at epoch 6
2022-12-31 10:46:13,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:13,595 INFO:     Epoch: 7
2022-12-31 10:46:15,213 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.41433189511299134, 'Total loss': 0.41433189511299134} | train loss {'Reaction outcome loss': 0.4618900952463976, 'Total loss': 0.4618900952463976}
2022-12-31 10:46:15,214 INFO:     Found new best model at epoch 7
2022-12-31 10:46:15,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:15,215 INFO:     Epoch: 8
2022-12-31 10:46:16,759 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.421009960770607, 'Total loss': 0.421009960770607} | train loss {'Reaction outcome loss': 0.45719101578535154, 'Total loss': 0.45719101578535154}
2022-12-31 10:46:16,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:16,759 INFO:     Epoch: 9
2022-12-31 10:46:18,408 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4271300137042999, 'Total loss': 0.4271300137042999} | train loss {'Reaction outcome loss': 0.44793485018966, 'Total loss': 0.44793485018966}
2022-12-31 10:46:18,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:18,408 INFO:     Epoch: 10
2022-12-31 10:46:20,061 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3918179452419281, 'Total loss': 0.3918179452419281} | train loss {'Reaction outcome loss': 0.43930585897571345, 'Total loss': 0.43930585897571345}
2022-12-31 10:46:20,062 INFO:     Found new best model at epoch 10
2022-12-31 10:46:20,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:20,063 INFO:     Epoch: 11
2022-12-31 10:46:21,677 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4405348519484202, 'Total loss': 0.4405348519484202} | train loss {'Reaction outcome loss': 0.4327083799167661, 'Total loss': 0.4327083799167661}
2022-12-31 10:46:21,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:21,678 INFO:     Epoch: 12
2022-12-31 10:46:23,288 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39281688729921976, 'Total loss': 0.39281688729921976} | train loss {'Reaction outcome loss': 0.43020556716497194, 'Total loss': 0.43020556716497194}
2022-12-31 10:46:23,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:23,288 INFO:     Epoch: 13
2022-12-31 10:46:24,898 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.3955260415871938, 'Total loss': 0.3955260415871938} | train loss {'Reaction outcome loss': 0.41849959660523206, 'Total loss': 0.41849959660523206}
2022-12-31 10:46:24,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:24,899 INFO:     Epoch: 14
2022-12-31 10:46:26,449 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41796086231867474, 'Total loss': 0.41796086231867474} | train loss {'Reaction outcome loss': 0.41272205496307746, 'Total loss': 0.41272205496307746}
2022-12-31 10:46:26,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:26,449 INFO:     Epoch: 15
2022-12-31 10:46:28,105 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4062565599878629, 'Total loss': 0.4062565599878629} | train loss {'Reaction outcome loss': 0.41134635638781836, 'Total loss': 0.41134635638781836}
2022-12-31 10:46:28,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:28,105 INFO:     Epoch: 16
2022-12-31 10:46:29,750 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4419258793195089, 'Total loss': 0.4419258793195089} | train loss {'Reaction outcome loss': 0.4036798133693017, 'Total loss': 0.4036798133693017}
2022-12-31 10:46:29,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:29,750 INFO:     Epoch: 17
2022-12-31 10:46:31,391 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.38630112210909523, 'Total loss': 0.38630112210909523} | train loss {'Reaction outcome loss': 0.39986524868097545, 'Total loss': 0.39986524868097545}
2022-12-31 10:46:31,391 INFO:     Found new best model at epoch 17
2022-12-31 10:46:31,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:31,392 INFO:     Epoch: 18
2022-12-31 10:46:33,003 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4016606420278549, 'Total loss': 0.4016606420278549} | train loss {'Reaction outcome loss': 0.39718930514710904, 'Total loss': 0.39718930514710904}
2022-12-31 10:46:33,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:33,004 INFO:     Epoch: 19
2022-12-31 10:46:34,551 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.38452591747045517, 'Total loss': 0.38452591747045517} | train loss {'Reaction outcome loss': 0.38979723831699215, 'Total loss': 0.38979723831699215}
2022-12-31 10:46:34,551 INFO:     Found new best model at epoch 19
2022-12-31 10:46:34,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:34,552 INFO:     Epoch: 20
2022-12-31 10:46:36,161 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4118935078382492, 'Total loss': 0.4118935078382492} | train loss {'Reaction outcome loss': 0.3774482812530728, 'Total loss': 0.3774482812530728}
2022-12-31 10:46:36,162 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:36,162 INFO:     Epoch: 21
2022-12-31 10:46:37,777 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40180829763412473, 'Total loss': 0.40180829763412473} | train loss {'Reaction outcome loss': 0.3795882244779315, 'Total loss': 0.3795882244779315}
2022-12-31 10:46:37,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:37,778 INFO:     Epoch: 22
2022-12-31 10:46:39,395 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.37376398344834644, 'Total loss': 0.37376398344834644} | train loss {'Reaction outcome loss': 0.3665112635450243, 'Total loss': 0.3665112635450243}
2022-12-31 10:46:39,395 INFO:     Found new best model at epoch 22
2022-12-31 10:46:39,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:39,396 INFO:     Epoch: 23
2022-12-31 10:46:41,051 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.39446529547373455, 'Total loss': 0.39446529547373455} | train loss {'Reaction outcome loss': 0.3625744240163466, 'Total loss': 0.3625744240163466}
2022-12-31 10:46:41,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:41,051 INFO:     Epoch: 24
2022-12-31 10:46:42,693 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3936462233463923, 'Total loss': 0.3936462233463923} | train loss {'Reaction outcome loss': 0.35839520112379364, 'Total loss': 0.35839520112379364}
2022-12-31 10:46:42,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:42,694 INFO:     Epoch: 25
2022-12-31 10:46:44,223 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40070608456929524, 'Total loss': 0.40070608456929524} | train loss {'Reaction outcome loss': 0.3503282538443696, 'Total loss': 0.3503282538443696}
2022-12-31 10:46:44,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:44,223 INFO:     Epoch: 26
2022-12-31 10:46:45,841 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3891182988882065, 'Total loss': 0.3891182988882065} | train loss {'Reaction outcome loss': 0.34994412163803723, 'Total loss': 0.34994412163803723}
2022-12-31 10:46:45,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:45,841 INFO:     Epoch: 27
2022-12-31 10:46:47,461 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3572355955839157, 'Total loss': 0.3572355955839157} | train loss {'Reaction outcome loss': 0.3440176238598376, 'Total loss': 0.3440176238598376}
2022-12-31 10:46:47,461 INFO:     Found new best model at epoch 27
2022-12-31 10:46:47,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:47,462 INFO:     Epoch: 28
2022-12-31 10:46:49,080 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3486324389775594, 'Total loss': 0.3486324389775594} | train loss {'Reaction outcome loss': 0.3369752687506297, 'Total loss': 0.3369752687506297}
2022-12-31 10:46:49,081 INFO:     Found new best model at epoch 28
2022-12-31 10:46:49,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:49,081 INFO:     Epoch: 29
2022-12-31 10:46:50,701 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.37126708726088203, 'Total loss': 0.37126708726088203} | train loss {'Reaction outcome loss': 0.33183215304348446, 'Total loss': 0.33183215304348446}
2022-12-31 10:46:50,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:50,701 INFO:     Epoch: 30
2022-12-31 10:46:52,320 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.365042374531428, 'Total loss': 0.365042374531428} | train loss {'Reaction outcome loss': 0.326508256421838, 'Total loss': 0.326508256421838}
2022-12-31 10:46:52,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:52,321 INFO:     Epoch: 31
2022-12-31 10:46:53,851 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.36434856355190276, 'Total loss': 0.36434856355190276} | train loss {'Reaction outcome loss': 0.3262136427463715, 'Total loss': 0.3262136427463715}
2022-12-31 10:46:53,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:53,852 INFO:     Epoch: 32
2022-12-31 10:46:55,470 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.37862414022286733, 'Total loss': 0.37862414022286733} | train loss {'Reaction outcome loss': 0.31687778635253117, 'Total loss': 0.31687778635253117}
2022-12-31 10:46:55,470 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:55,470 INFO:     Epoch: 33
2022-12-31 10:46:57,090 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40583404203255974, 'Total loss': 0.40583404203255974} | train loss {'Reaction outcome loss': 0.3122698227313451, 'Total loss': 0.3122698227313451}
2022-12-31 10:46:57,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:57,090 INFO:     Epoch: 34
2022-12-31 10:46:58,711 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.36427225172519684, 'Total loss': 0.36427225172519684} | train loss {'Reaction outcome loss': 0.31154330784878576, 'Total loss': 0.31154330784878576}
2022-12-31 10:46:58,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:46:58,711 INFO:     Epoch: 35
2022-12-31 10:47:00,333 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.39893590013186137, 'Total loss': 0.39893590013186137} | train loss {'Reaction outcome loss': 0.3096047457347923, 'Total loss': 0.3096047457347923}
2022-12-31 10:47:00,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:00,333 INFO:     Epoch: 36
2022-12-31 10:47:01,855 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4056271423896154, 'Total loss': 0.4056271423896154} | train loss {'Reaction outcome loss': 0.3020408858245891, 'Total loss': 0.3020408858245891}
2022-12-31 10:47:01,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:01,855 INFO:     Epoch: 37
2022-12-31 10:47:03,476 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3697481870651245, 'Total loss': 0.3697481870651245} | train loss {'Reaction outcome loss': 0.3004955926957113, 'Total loss': 0.3004955926957113}
2022-12-31 10:47:03,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:03,476 INFO:     Epoch: 38
2022-12-31 10:47:05,105 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.35587380329767865, 'Total loss': 0.35587380329767865} | train loss {'Reaction outcome loss': 0.29723677027042594, 'Total loss': 0.29723677027042594}
2022-12-31 10:47:05,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:05,105 INFO:     Epoch: 39
2022-12-31 10:47:06,745 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40663008093833924, 'Total loss': 0.40663008093833924} | train loss {'Reaction outcome loss': 0.29336786774467905, 'Total loss': 0.29336786774467905}
2022-12-31 10:47:06,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:06,745 INFO:     Epoch: 40
2022-12-31 10:47:08,387 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3629927049080531, 'Total loss': 0.3629927049080531} | train loss {'Reaction outcome loss': 0.2908849675840419, 'Total loss': 0.2908849675840419}
2022-12-31 10:47:08,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:08,388 INFO:     Epoch: 41
2022-12-31 10:47:10,048 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3988892157872518, 'Total loss': 0.3988892157872518} | train loss {'Reaction outcome loss': 0.28951217606663704, 'Total loss': 0.28951217606663704}
2022-12-31 10:47:10,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:10,049 INFO:     Epoch: 42
2022-12-31 10:47:11,592 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3806624541680018, 'Total loss': 0.3806624541680018} | train loss {'Reaction outcome loss': 0.28181174256929636, 'Total loss': 0.28181174256929636}
2022-12-31 10:47:11,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:11,592 INFO:     Epoch: 43
2022-12-31 10:47:13,210 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.387649467587471, 'Total loss': 0.387649467587471} | train loss {'Reaction outcome loss': 0.278461479188518, 'Total loss': 0.278461479188518}
2022-12-31 10:47:13,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:13,211 INFO:     Epoch: 44
2022-12-31 10:47:14,821 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.33786045511563617, 'Total loss': 0.33786045511563617} | train loss {'Reaction outcome loss': 0.27844123664019554, 'Total loss': 0.27844123664019554}
2022-12-31 10:47:14,821 INFO:     Found new best model at epoch 44
2022-12-31 10:47:14,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:14,822 INFO:     Epoch: 45
2022-12-31 10:47:16,462 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3848079562187195, 'Total loss': 0.3848079562187195} | train loss {'Reaction outcome loss': 0.2773055194840104, 'Total loss': 0.2773055194840104}
2022-12-31 10:47:16,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:16,463 INFO:     Epoch: 46
2022-12-31 10:47:18,112 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.36833659509817757, 'Total loss': 0.36833659509817757} | train loss {'Reaction outcome loss': 0.2748012374750328, 'Total loss': 0.2748012374750328}
2022-12-31 10:47:18,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:18,112 INFO:     Epoch: 47
2022-12-31 10:47:19,756 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.38094136913617455, 'Total loss': 0.38094136913617455} | train loss {'Reaction outcome loss': 0.26730400974784946, 'Total loss': 0.26730400974784946}
2022-12-31 10:47:19,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:19,756 INFO:     Epoch: 48
2022-12-31 10:47:21,336 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.357471023996671, 'Total loss': 0.357471023996671} | train loss {'Reaction outcome loss': 0.2757546751077425, 'Total loss': 0.2757546751077425}
2022-12-31 10:47:21,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:21,337 INFO:     Epoch: 49
2022-12-31 10:47:22,952 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4603467752536138, 'Total loss': 0.4603467752536138} | train loss {'Reaction outcome loss': 0.26373815083277785, 'Total loss': 0.26373815083277785}
2022-12-31 10:47:22,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:22,952 INFO:     Epoch: 50
2022-12-31 10:47:24,563 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39278774758179985, 'Total loss': 0.39278774758179985} | train loss {'Reaction outcome loss': 0.25819341391862943, 'Total loss': 0.25819341391862943}
2022-12-31 10:47:24,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:24,563 INFO:     Epoch: 51
2022-12-31 10:47:26,175 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3795151387651761, 'Total loss': 0.3795151387651761} | train loss {'Reaction outcome loss': 0.2549147197660664, 'Total loss': 0.2549147197660664}
2022-12-31 10:47:26,175 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:26,175 INFO:     Epoch: 52
2022-12-31 10:47:27,786 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.36776607036590575, 'Total loss': 0.36776607036590575} | train loss {'Reaction outcome loss': 0.26013758566755035, 'Total loss': 0.26013758566755035}
2022-12-31 10:47:27,786 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:27,786 INFO:     Epoch: 53
2022-12-31 10:47:29,318 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3317219366629918, 'Total loss': 0.3317219366629918} | train loss {'Reaction outcome loss': 0.2525743550893309, 'Total loss': 0.2525743550893309}
2022-12-31 10:47:29,319 INFO:     Found new best model at epoch 53
2022-12-31 10:47:29,320 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:29,320 INFO:     Epoch: 54
2022-12-31 10:47:30,977 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3732724597056707, 'Total loss': 0.3732724597056707} | train loss {'Reaction outcome loss': 0.25442861999630495, 'Total loss': 0.25442861999630495}
2022-12-31 10:47:30,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:30,977 INFO:     Epoch: 55
2022-12-31 10:47:32,592 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3871100922425588, 'Total loss': 0.3871100922425588} | train loss {'Reaction outcome loss': 0.2522709974514771, 'Total loss': 0.2522709974514771}
2022-12-31 10:47:32,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:32,593 INFO:     Epoch: 56
2022-12-31 10:47:34,207 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.36617813756068546, 'Total loss': 0.36617813756068546} | train loss {'Reaction outcome loss': 0.24840791308277352, 'Total loss': 0.24840791308277352}
2022-12-31 10:47:34,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:34,207 INFO:     Epoch: 57
2022-12-31 10:47:35,822 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3662101584176222, 'Total loss': 0.3662101584176222} | train loss {'Reaction outcome loss': 0.24928359488287558, 'Total loss': 0.24928359488287558}
2022-12-31 10:47:35,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:35,822 INFO:     Epoch: 58
2022-12-31 10:47:37,473 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3679189811150233, 'Total loss': 0.3679189811150233} | train loss {'Reaction outcome loss': 0.2511009031752064, 'Total loss': 0.2511009031752064}
2022-12-31 10:47:37,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:37,474 INFO:     Epoch: 59
2022-12-31 10:47:39,022 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39709568917751314, 'Total loss': 0.39709568917751314} | train loss {'Reaction outcome loss': 0.2509138446825721, 'Total loss': 0.2509138446825721}
2022-12-31 10:47:39,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:39,022 INFO:     Epoch: 60
2022-12-31 10:47:40,661 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3506743053595225, 'Total loss': 0.3506743053595225} | train loss {'Reaction outcome loss': 0.24188239374181209, 'Total loss': 0.24188239374181209}
2022-12-31 10:47:40,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:40,661 INFO:     Epoch: 61
2022-12-31 10:47:42,282 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3688890188932419, 'Total loss': 0.3688890188932419} | train loss {'Reaction outcome loss': 0.24383338999393184, 'Total loss': 0.24383338999393184}
2022-12-31 10:47:42,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:42,282 INFO:     Epoch: 62
2022-12-31 10:47:43,900 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.35653473138809205, 'Total loss': 0.35653473138809205} | train loss {'Reaction outcome loss': 0.2409532716101042, 'Total loss': 0.2409532716101042}
2022-12-31 10:47:43,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:43,900 INFO:     Epoch: 63
2022-12-31 10:47:45,518 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41527576744556427, 'Total loss': 0.41527576744556427} | train loss {'Reaction outcome loss': 0.24025370629121034, 'Total loss': 0.24025370629121034}
2022-12-31 10:47:45,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:45,519 INFO:     Epoch: 64
2022-12-31 10:47:47,099 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.37944179475307466, 'Total loss': 0.37944179475307466} | train loss {'Reaction outcome loss': 0.2291320918887746, 'Total loss': 0.2291320918887746}
2022-12-31 10:47:47,100 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:47,100 INFO:     Epoch: 65
2022-12-31 10:47:48,692 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3596714993317922, 'Total loss': 0.3596714993317922} | train loss {'Reaction outcome loss': 0.23993347981937957, 'Total loss': 0.23993347981937957}
2022-12-31 10:47:48,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:48,692 INFO:     Epoch: 66
2022-12-31 10:47:50,309 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4038237422704697, 'Total loss': 0.4038237422704697} | train loss {'Reaction outcome loss': 0.23266100808843593, 'Total loss': 0.23266100808843593}
2022-12-31 10:47:50,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:50,309 INFO:     Epoch: 67
2022-12-31 10:47:51,926 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39059873620669044, 'Total loss': 0.39059873620669044} | train loss {'Reaction outcome loss': 0.23777288530653995, 'Total loss': 0.23777288530653995}
2022-12-31 10:47:51,927 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:51,927 INFO:     Epoch: 68
2022-12-31 10:47:53,540 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3999206165472666, 'Total loss': 0.3999206165472666} | train loss {'Reaction outcome loss': 0.23415987608476882, 'Total loss': 0.23415987608476882}
2022-12-31 10:47:53,540 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:53,540 INFO:     Epoch: 69
2022-12-31 10:47:55,211 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3717787394920985, 'Total loss': 0.3717787394920985} | train loss {'Reaction outcome loss': 0.22677433502857006, 'Total loss': 0.22677433502857006}
2022-12-31 10:47:55,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:55,212 INFO:     Epoch: 70
2022-12-31 10:47:56,743 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.37634331434965135, 'Total loss': 0.37634331434965135} | train loss {'Reaction outcome loss': 0.2312681419431948, 'Total loss': 0.2312681419431948}
2022-12-31 10:47:56,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:56,743 INFO:     Epoch: 71
2022-12-31 10:47:58,359 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.33582436144351957, 'Total loss': 0.33582436144351957} | train loss {'Reaction outcome loss': 0.22936272813134997, 'Total loss': 0.22936272813134997}
2022-12-31 10:47:58,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:58,360 INFO:     Epoch: 72
2022-12-31 10:47:59,979 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3751255085070928, 'Total loss': 0.3751255085070928} | train loss {'Reaction outcome loss': 0.23079160953929062, 'Total loss': 0.23079160953929062}
2022-12-31 10:47:59,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:47:59,979 INFO:     Epoch: 73
2022-12-31 10:48:01,594 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3787196919322014, 'Total loss': 0.3787196919322014} | train loss {'Reaction outcome loss': 0.22488496734320257, 'Total loss': 0.22488496734320257}
2022-12-31 10:48:01,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:01,594 INFO:     Epoch: 74
2022-12-31 10:48:03,270 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.385539311170578, 'Total loss': 0.385539311170578} | train loss {'Reaction outcome loss': 0.2247344978046116, 'Total loss': 0.2247344978046116}
2022-12-31 10:48:03,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:03,270 INFO:     Epoch: 75
2022-12-31 10:48:04,918 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3679522273441156, 'Total loss': 0.3679522273441156} | train loss {'Reaction outcome loss': 0.22262319710630157, 'Total loss': 0.22262319710630157}
2022-12-31 10:48:04,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:04,919 INFO:     Epoch: 76
2022-12-31 10:48:06,449 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.37113589346408843, 'Total loss': 0.37113589346408843} | train loss {'Reaction outcome loss': 0.21443001562830344, 'Total loss': 0.21443001562830344}
2022-12-31 10:48:06,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:06,449 INFO:     Epoch: 77
2022-12-31 10:48:08,062 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.35833305716514585, 'Total loss': 0.35833305716514585} | train loss {'Reaction outcome loss': 0.2297100429070125, 'Total loss': 0.2297100429070125}
2022-12-31 10:48:08,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:08,063 INFO:     Epoch: 78
2022-12-31 10:48:09,696 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3741553068161011, 'Total loss': 0.3741553068161011} | train loss {'Reaction outcome loss': 0.21263871304287377, 'Total loss': 0.21263871304287377}
2022-12-31 10:48:09,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:09,696 INFO:     Epoch: 79
2022-12-31 10:48:11,339 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3664085974295934, 'Total loss': 0.3664085974295934} | train loss {'Reaction outcome loss': 0.2200371443969786, 'Total loss': 0.2200371443969786}
2022-12-31 10:48:11,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:11,339 INFO:     Epoch: 80
2022-12-31 10:48:12,999 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42504777808984123, 'Total loss': 0.42504777808984123} | train loss {'Reaction outcome loss': 0.21768953292109475, 'Total loss': 0.21768953292109475}
2022-12-31 10:48:12,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:12,999 INFO:     Epoch: 81
2022-12-31 10:48:14,568 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3833992520968119, 'Total loss': 0.3833992520968119} | train loss {'Reaction outcome loss': 0.22161530368433532, 'Total loss': 0.22161530368433532}
2022-12-31 10:48:14,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:14,568 INFO:     Epoch: 82
2022-12-31 10:48:16,179 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.37516937255859373, 'Total loss': 0.37516937255859373} | train loss {'Reaction outcome loss': 0.21548710965184958, 'Total loss': 0.21548710965184958}
2022-12-31 10:48:16,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:16,181 INFO:     Epoch: 83
2022-12-31 10:48:17,792 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3909831563631693, 'Total loss': 0.3909831563631693} | train loss {'Reaction outcome loss': 0.21132288134189503, 'Total loss': 0.21132288134189503}
2022-12-31 10:48:17,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:17,792 INFO:     Epoch: 84
2022-12-31 10:48:19,404 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3811555027961731, 'Total loss': 0.3811555027961731} | train loss {'Reaction outcome loss': 0.21938992626561585, 'Total loss': 0.21938992626561585}
2022-12-31 10:48:19,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:19,404 INFO:     Epoch: 85
2022-12-31 10:48:21,016 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.37558289567629494, 'Total loss': 0.37558289567629494} | train loss {'Reaction outcome loss': 0.20456438612475292, 'Total loss': 0.20456438612475292}
2022-12-31 10:48:21,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:21,016 INFO:     Epoch: 86
2022-12-31 10:48:22,629 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4281922976175944, 'Total loss': 0.4281922976175944} | train loss {'Reaction outcome loss': 0.21099042619447417, 'Total loss': 0.21099042619447417}
2022-12-31 10:48:22,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:22,630 INFO:     Epoch: 87
2022-12-31 10:48:24,164 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3705487444996834, 'Total loss': 0.3705487444996834} | train loss {'Reaction outcome loss': 0.21390873258294613, 'Total loss': 0.21390873258294613}
2022-12-31 10:48:24,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:24,164 INFO:     Epoch: 88
2022-12-31 10:48:25,775 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.37985935211181643, 'Total loss': 0.37985935211181643} | train loss {'Reaction outcome loss': 0.20855978387492013, 'Total loss': 0.20855978387492013}
2022-12-31 10:48:25,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:25,775 INFO:     Epoch: 89
2022-12-31 10:48:27,415 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40991272727648415, 'Total loss': 0.40991272727648415} | train loss {'Reaction outcome loss': 0.21103316305931455, 'Total loss': 0.21103316305931455}
2022-12-31 10:48:27,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:27,416 INFO:     Epoch: 90
2022-12-31 10:48:29,005 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4156596173842748, 'Total loss': 0.4156596173842748} | train loss {'Reaction outcome loss': 0.20872783626594482, 'Total loss': 0.20872783626594482}
2022-12-31 10:48:29,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:29,006 INFO:     Epoch: 91
2022-12-31 10:48:30,667 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.36656767427921294, 'Total loss': 0.36656767427921294} | train loss {'Reaction outcome loss': 0.20991588755097199, 'Total loss': 0.20991588755097199}
2022-12-31 10:48:30,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:30,667 INFO:     Epoch: 92
2022-12-31 10:48:32,300 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3719834218422572, 'Total loss': 0.3719834218422572} | train loss {'Reaction outcome loss': 0.20786329570633194, 'Total loss': 0.20786329570633194}
2022-12-31 10:48:32,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:32,300 INFO:     Epoch: 93
2022-12-31 10:48:33,844 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.37594331602255504, 'Total loss': 0.37594331602255504} | train loss {'Reaction outcome loss': 0.2058151183979391, 'Total loss': 0.2058151183979391}
2022-12-31 10:48:33,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:33,844 INFO:     Epoch: 94
2022-12-31 10:48:35,471 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40940207839012144, 'Total loss': 0.40940207839012144} | train loss {'Reaction outcome loss': 0.20279223620824327, 'Total loss': 0.20279223620824327}
2022-12-31 10:48:35,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:35,472 INFO:     Epoch: 95
2022-12-31 10:48:37,135 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3766026268402735, 'Total loss': 0.3766026268402735} | train loss {'Reaction outcome loss': 0.20058049735636702, 'Total loss': 0.20058049735636702}
2022-12-31 10:48:37,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:37,135 INFO:     Epoch: 96
2022-12-31 10:48:38,735 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39230539177854856, 'Total loss': 0.39230539177854856} | train loss {'Reaction outcome loss': 0.203874482937991, 'Total loss': 0.203874482937991}
2022-12-31 10:48:38,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:38,735 INFO:     Epoch: 97
2022-12-31 10:48:40,380 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.37995641827583315, 'Total loss': 0.37995641827583315} | train loss {'Reaction outcome loss': 0.2046944443203697, 'Total loss': 0.2046944443203697}
2022-12-31 10:48:40,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:40,381 INFO:     Epoch: 98
2022-12-31 10:48:41,975 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.34558577636877696, 'Total loss': 0.34558577636877696} | train loss {'Reaction outcome loss': 0.2018377348605799, 'Total loss': 0.2018377348605799}
2022-12-31 10:48:41,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:41,976 INFO:     Epoch: 99
2022-12-31 10:48:43,606 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.36855667928854624, 'Total loss': 0.36855667928854624} | train loss {'Reaction outcome loss': 0.1976580990794441, 'Total loss': 0.1976580990794441}
2022-12-31 10:48:43,606 INFO:     Best model found after epoch 54 of 100.
2022-12-31 10:48:43,606 INFO:   Done with stage: TRAINING
2022-12-31 10:48:43,607 INFO:   Starting stage: EVALUATION
2022-12-31 10:48:43,728 INFO:   Done with stage: EVALUATION
2022-12-31 10:48:43,728 INFO:   Leaving out SEQ value Fold_9
2022-12-31 10:48:43,740 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 10:48:43,741 INFO:   Starting stage: FEATURE SCALING
2022-12-31 10:48:44,386 INFO:   Done with stage: FEATURE SCALING
2022-12-31 10:48:44,387 INFO:   Starting stage: SCALING TARGETS
2022-12-31 10:48:44,456 INFO:   Done with stage: SCALING TARGETS
2022-12-31 10:48:44,456 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:48:44,457 INFO:     No hyperparam tuning for this model
2022-12-31 10:48:44,457 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:48:44,457 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 10:48:44,457 INFO:     None feature selector for col prot
2022-12-31 10:48:44,457 INFO:     None feature selector for col prot
2022-12-31 10:48:44,458 INFO:     None feature selector for col prot
2022-12-31 10:48:44,458 INFO:     None feature selector for col chem
2022-12-31 10:48:44,458 INFO:     None feature selector for col chem
2022-12-31 10:48:44,458 INFO:     None feature selector for col chem
2022-12-31 10:48:44,458 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 10:48:44,458 INFO:   Starting stage: BUILD MODEL
2022-12-31 10:48:44,460 INFO:     Number of params in model 223921
2022-12-31 10:48:44,463 INFO:   Done with stage: BUILD MODEL
2022-12-31 10:48:44,464 INFO:   Starting stage: TRAINING
2022-12-31 10:48:44,510 INFO:     Val loss before train {'Reaction outcome loss': 0.9633055329322815, 'Total loss': 0.9633055329322815}
2022-12-31 10:48:44,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:44,510 INFO:     Epoch: 0
2022-12-31 10:48:46,123 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.655723504225413, 'Total loss': 0.655723504225413} | train loss {'Reaction outcome loss': 0.822324063250984, 'Total loss': 0.822324063250984}
2022-12-31 10:48:46,124 INFO:     Found new best model at epoch 0
2022-12-31 10:48:46,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:46,125 INFO:     Epoch: 1
2022-12-31 10:48:47,742 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5721898516019185, 'Total loss': 0.5721898516019185} | train loss {'Reaction outcome loss': 0.5981999432425136, 'Total loss': 0.5981999432425136}
2022-12-31 10:48:47,742 INFO:     Found new best model at epoch 1
2022-12-31 10:48:47,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:47,743 INFO:     Epoch: 2
2022-12-31 10:48:49,359 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5309226870536804, 'Total loss': 0.5309226870536804} | train loss {'Reaction outcome loss': 0.5309372521612955, 'Total loss': 0.5309372521612955}
2022-12-31 10:48:49,359 INFO:     Found new best model at epoch 2
2022-12-31 10:48:49,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:49,361 INFO:     Epoch: 3
2022-12-31 10:48:50,914 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5140223264694214, 'Total loss': 0.5140223264694214} | train loss {'Reaction outcome loss': 0.5308964568476253, 'Total loss': 0.5308964568476253}
2022-12-31 10:48:50,914 INFO:     Found new best model at epoch 3
2022-12-31 10:48:50,915 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:50,915 INFO:     Epoch: 4
2022-12-31 10:48:52,520 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4970558007558187, 'Total loss': 0.4970558007558187} | train loss {'Reaction outcome loss': 0.4855199217580367, 'Total loss': 0.4855199217580367}
2022-12-31 10:48:52,521 INFO:     Found new best model at epoch 4
2022-12-31 10:48:52,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:52,522 INFO:     Epoch: 5
2022-12-31 10:48:54,124 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5084476510683695, 'Total loss': 0.5084476510683695} | train loss {'Reaction outcome loss': 0.47794855652382073, 'Total loss': 0.47794855652382073}
2022-12-31 10:48:54,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:54,124 INFO:     Epoch: 6
2022-12-31 10:48:55,730 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5095705429712931, 'Total loss': 0.5095705429712931} | train loss {'Reaction outcome loss': 0.47058013667339, 'Total loss': 0.47058013667339}
2022-12-31 10:48:55,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:55,730 INFO:     Epoch: 7
2022-12-31 10:48:57,336 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4810446709394455, 'Total loss': 0.4810446709394455} | train loss {'Reaction outcome loss': 0.4578316025686892, 'Total loss': 0.4578316025686892}
2022-12-31 10:48:57,336 INFO:     Found new best model at epoch 7
2022-12-31 10:48:57,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:57,337 INFO:     Epoch: 8
2022-12-31 10:48:58,941 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48839831749598184, 'Total loss': 0.48839831749598184} | train loss {'Reaction outcome loss': 0.45383804334425437, 'Total loss': 0.45383804334425437}
2022-12-31 10:48:58,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:48:58,942 INFO:     Epoch: 9
2022-12-31 10:49:00,496 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4666717708110809, 'Total loss': 0.4666717708110809} | train loss {'Reaction outcome loss': 0.44671815655707126, 'Total loss': 0.44671815655707126}
2022-12-31 10:49:00,496 INFO:     Found new best model at epoch 9
2022-12-31 10:49:00,497 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:00,497 INFO:     Epoch: 10
2022-12-31 10:49:02,104 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48565670450528464, 'Total loss': 0.48565670450528464} | train loss {'Reaction outcome loss': 0.44241313375127705, 'Total loss': 0.44241313375127705}
2022-12-31 10:49:02,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:02,104 INFO:     Epoch: 11
2022-12-31 10:49:03,713 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47182806928952536, 'Total loss': 0.47182806928952536} | train loss {'Reaction outcome loss': 0.4340832955608873, 'Total loss': 0.4340832955608873}
2022-12-31 10:49:03,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:03,714 INFO:     Epoch: 12
2022-12-31 10:49:05,321 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4452648719151815, 'Total loss': 0.4452648719151815} | train loss {'Reaction outcome loss': 0.4286980922498396, 'Total loss': 0.4286980922498396}
2022-12-31 10:49:05,322 INFO:     Found new best model at epoch 12
2022-12-31 10:49:05,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:05,323 INFO:     Epoch: 13
2022-12-31 10:49:06,929 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.46685105363527934, 'Total loss': 0.46685105363527934} | train loss {'Reaction outcome loss': 0.4215373307166189, 'Total loss': 0.4215373307166189}
2022-12-31 10:49:06,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:06,929 INFO:     Epoch: 14
2022-12-31 10:49:08,500 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46821275949478147, 'Total loss': 0.46821275949478147} | train loss {'Reaction outcome loss': 0.4242306327179666, 'Total loss': 0.4242306327179666}
2022-12-31 10:49:08,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:08,500 INFO:     Epoch: 15
2022-12-31 10:49:10,104 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5117811928192775, 'Total loss': 0.5117811928192775} | train loss {'Reaction outcome loss': 0.41300981942618237, 'Total loss': 0.41300981942618237}
2022-12-31 10:49:10,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:10,104 INFO:     Epoch: 16
2022-12-31 10:49:11,711 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.510089119275411, 'Total loss': 0.510089119275411} | train loss {'Reaction outcome loss': 0.4116661072357733, 'Total loss': 0.4116661072357733}
2022-12-31 10:49:11,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:11,712 INFO:     Epoch: 17
2022-12-31 10:49:13,314 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4737098594506582, 'Total loss': 0.4737098594506582} | train loss {'Reaction outcome loss': 0.40032255671373435, 'Total loss': 0.40032255671373435}
2022-12-31 10:49:13,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:13,314 INFO:     Epoch: 18
2022-12-31 10:49:14,918 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47178630034128827, 'Total loss': 0.47178630034128827} | train loss {'Reaction outcome loss': 0.3986782098620914, 'Total loss': 0.3986782098620914}
2022-12-31 10:49:14,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:14,918 INFO:     Epoch: 19
2022-12-31 10:49:16,525 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.462570517261823, 'Total loss': 0.462570517261823} | train loss {'Reaction outcome loss': 0.39057461742144683, 'Total loss': 0.39057461742144683}
2022-12-31 10:49:16,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:16,525 INFO:     Epoch: 20
2022-12-31 10:49:18,075 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41735740900039675, 'Total loss': 0.41735740900039675} | train loss {'Reaction outcome loss': 0.382942794052803, 'Total loss': 0.382942794052803}
2022-12-31 10:49:18,076 INFO:     Found new best model at epoch 20
2022-12-31 10:49:18,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:18,077 INFO:     Epoch: 21
2022-12-31 10:49:19,681 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4666083345810572, 'Total loss': 0.4666083345810572} | train loss {'Reaction outcome loss': 0.38395244765021175, 'Total loss': 0.38395244765021175}
2022-12-31 10:49:19,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:19,681 INFO:     Epoch: 22
2022-12-31 10:49:21,288 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45588756203651426, 'Total loss': 0.45588756203651426} | train loss {'Reaction outcome loss': 0.3728956821652136, 'Total loss': 0.3728956821652136}
2022-12-31 10:49:21,288 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:21,288 INFO:     Epoch: 23
2022-12-31 10:49:22,894 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4331134806076686, 'Total loss': 0.4331134806076686} | train loss {'Reaction outcome loss': 0.3672703605354426, 'Total loss': 0.3672703605354426}
2022-12-31 10:49:22,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:22,895 INFO:     Epoch: 24
2022-12-31 10:49:24,501 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4514835119247437, 'Total loss': 0.4514835119247437} | train loss {'Reaction outcome loss': 0.3625193669096283, 'Total loss': 0.3625193669096283}
2022-12-31 10:49:24,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:24,502 INFO:     Epoch: 25
2022-12-31 10:49:26,108 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42711492876211804, 'Total loss': 0.42711492876211804} | train loss {'Reaction outcome loss': 0.3631941154059293, 'Total loss': 0.3631941154059293}
2022-12-31 10:49:26,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:26,108 INFO:     Epoch: 26
2022-12-31 10:49:27,680 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4451436271270116, 'Total loss': 0.4451436271270116} | train loss {'Reaction outcome loss': 0.358584179111041, 'Total loss': 0.358584179111041}
2022-12-31 10:49:27,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:27,680 INFO:     Epoch: 27
2022-12-31 10:49:29,291 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44523942867914834, 'Total loss': 0.44523942867914834} | train loss {'Reaction outcome loss': 0.3501722673629073, 'Total loss': 0.3501722673629073}
2022-12-31 10:49:29,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:29,291 INFO:     Epoch: 28
2022-12-31 10:49:30,898 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46028691132863364, 'Total loss': 0.46028691132863364} | train loss {'Reaction outcome loss': 0.3485095969846715, 'Total loss': 0.3485095969846715}
2022-12-31 10:49:30,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:30,898 INFO:     Epoch: 29
2022-12-31 10:49:32,520 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43715401689211525, 'Total loss': 0.43715401689211525} | train loss {'Reaction outcome loss': 0.3354047463720538, 'Total loss': 0.3354047463720538}
2022-12-31 10:49:32,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:32,520 INFO:     Epoch: 30
2022-12-31 10:49:34,129 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3937050792078177, 'Total loss': 0.3937050792078177} | train loss {'Reaction outcome loss': 0.3344055782717592, 'Total loss': 0.3344055782717592}
2022-12-31 10:49:34,129 INFO:     Found new best model at epoch 30
2022-12-31 10:49:34,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:34,130 INFO:     Epoch: 31
2022-12-31 10:49:35,696 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4486328606804212, 'Total loss': 0.4486328606804212} | train loss {'Reaction outcome loss': 0.3358833858867423, 'Total loss': 0.3358833858867423}
2022-12-31 10:49:35,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:35,697 INFO:     Epoch: 32
2022-12-31 10:49:37,342 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4221237063407898, 'Total loss': 0.4221237063407898} | train loss {'Reaction outcome loss': 0.32302123474685196, 'Total loss': 0.32302123474685196}
2022-12-31 10:49:37,343 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:37,343 INFO:     Epoch: 33
2022-12-31 10:49:38,956 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44293043365081153, 'Total loss': 0.44293043365081153} | train loss {'Reaction outcome loss': 0.3187406260378497, 'Total loss': 0.3187406260378497}
2022-12-31 10:49:38,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:38,956 INFO:     Epoch: 34
2022-12-31 10:49:40,613 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46270681818326315, 'Total loss': 0.46270681818326315} | train loss {'Reaction outcome loss': 0.31982611214861856, 'Total loss': 0.31982611214861856}
2022-12-31 10:49:40,613 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:40,613 INFO:     Epoch: 35
2022-12-31 10:49:42,272 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41372957626978557, 'Total loss': 0.41372957626978557} | train loss {'Reaction outcome loss': 0.30908317329949175, 'Total loss': 0.30908317329949175}
2022-12-31 10:49:42,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:42,273 INFO:     Epoch: 36
2022-12-31 10:49:43,907 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42194308936595915, 'Total loss': 0.42194308936595915} | train loss {'Reaction outcome loss': 0.3091985598692428, 'Total loss': 0.3091985598692428}
2022-12-31 10:49:43,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:43,907 INFO:     Epoch: 37
2022-12-31 10:49:45,494 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4758472005526225, 'Total loss': 0.4758472005526225} | train loss {'Reaction outcome loss': 0.31441828276476136, 'Total loss': 0.31441828276476136}
2022-12-31 10:49:45,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:45,495 INFO:     Epoch: 38
2022-12-31 10:49:47,099 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46285358468691506, 'Total loss': 0.46285358468691506} | train loss {'Reaction outcome loss': 0.335098705234249, 'Total loss': 0.335098705234249}
2022-12-31 10:49:47,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:47,099 INFO:     Epoch: 39
2022-12-31 10:49:48,706 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43329060077667236, 'Total loss': 0.43329060077667236} | train loss {'Reaction outcome loss': 0.30100551217564964, 'Total loss': 0.30100551217564964}
2022-12-31 10:49:48,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:48,706 INFO:     Epoch: 40
2022-12-31 10:49:50,314 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4177991817394892, 'Total loss': 0.4177991817394892} | train loss {'Reaction outcome loss': 0.2975814881223335, 'Total loss': 0.2975814881223335}
2022-12-31 10:49:50,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:50,314 INFO:     Epoch: 41
2022-12-31 10:49:51,922 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4255713005860647, 'Total loss': 0.4255713005860647} | train loss {'Reaction outcome loss': 0.2881676371157021, 'Total loss': 0.2881676371157021}
2022-12-31 10:49:51,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:51,923 INFO:     Epoch: 42
2022-12-31 10:49:53,515 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4716862211624781, 'Total loss': 0.4716862211624781} | train loss {'Reaction outcome loss': 0.2912230114991384, 'Total loss': 0.2912230114991384}
2022-12-31 10:49:53,516 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:53,516 INFO:     Epoch: 43
2022-12-31 10:49:55,143 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4620734403530757, 'Total loss': 0.4620734403530757} | train loss {'Reaction outcome loss': 0.2810435055040559, 'Total loss': 0.2810435055040559}
2022-12-31 10:49:55,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:55,143 INFO:     Epoch: 44
2022-12-31 10:49:56,781 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4552523831526438, 'Total loss': 0.4552523831526438} | train loss {'Reaction outcome loss': 0.28540785934234486, 'Total loss': 0.28540785934234486}
2022-12-31 10:49:56,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:56,781 INFO:     Epoch: 45
2022-12-31 10:49:58,414 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4644908865292867, 'Total loss': 0.4644908865292867} | train loss {'Reaction outcome loss': 0.2879607090321572, 'Total loss': 0.2879607090321572}
2022-12-31 10:49:58,414 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:49:58,415 INFO:     Epoch: 46
2022-12-31 10:50:00,027 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5040660987297694, 'Total loss': 0.5040660987297694} | train loss {'Reaction outcome loss': 0.3067059414866178, 'Total loss': 0.3067059414866178}
2022-12-31 10:50:00,027 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:00,028 INFO:     Epoch: 47
2022-12-31 10:50:01,639 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4331174850463867, 'Total loss': 0.4331174850463867} | train loss {'Reaction outcome loss': 0.3140972525440663, 'Total loss': 0.3140972525440663}
2022-12-31 10:50:01,639 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:01,639 INFO:     Epoch: 48
2022-12-31 10:50:03,226 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42052570581436155, 'Total loss': 0.42052570581436155} | train loss {'Reaction outcome loss': 0.2729587578602756, 'Total loss': 0.2729587578602756}
2022-12-31 10:50:03,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:03,226 INFO:     Epoch: 49
2022-12-31 10:50:04,882 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4465268204609553, 'Total loss': 0.4465268204609553} | train loss {'Reaction outcome loss': 0.26752188631276047, 'Total loss': 0.26752188631276047}
2022-12-31 10:50:04,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:04,882 INFO:     Epoch: 50
2022-12-31 10:50:06,532 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44214648405710855, 'Total loss': 0.44214648405710855} | train loss {'Reaction outcome loss': 0.2745744438396524, 'Total loss': 0.2745744438396524}
2022-12-31 10:50:06,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:06,532 INFO:     Epoch: 51
2022-12-31 10:50:08,145 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42264991799990337, 'Total loss': 0.42264991799990337} | train loss {'Reaction outcome loss': 0.30768932478056976, 'Total loss': 0.30768932478056976}
2022-12-31 10:50:08,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:08,145 INFO:     Epoch: 52
2022-12-31 10:50:09,756 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4198636700709661, 'Total loss': 0.4198636700709661} | train loss {'Reaction outcome loss': 0.26867443059429363, 'Total loss': 0.26867443059429363}
2022-12-31 10:50:09,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:09,757 INFO:     Epoch: 53
2022-12-31 10:50:11,370 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4804050326347351, 'Total loss': 0.4804050326347351} | train loss {'Reaction outcome loss': 0.26449322433652106, 'Total loss': 0.26449322433652106}
2022-12-31 10:50:11,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:11,370 INFO:     Epoch: 54
2022-12-31 10:50:12,943 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42627049585183463, 'Total loss': 0.42627049585183463} | train loss {'Reaction outcome loss': 0.24793260318874408, 'Total loss': 0.24793260318874408}
2022-12-31 10:50:12,943 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:12,944 INFO:     Epoch: 55
2022-12-31 10:50:14,600 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4758024593194326, 'Total loss': 0.4758024593194326} | train loss {'Reaction outcome loss': 0.26008711271224194, 'Total loss': 0.26008711271224194}
2022-12-31 10:50:14,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:14,600 INFO:     Epoch: 56
2022-12-31 10:50:16,222 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42707307388385135, 'Total loss': 0.42707307388385135} | train loss {'Reaction outcome loss': 0.25482207065953477, 'Total loss': 0.25482207065953477}
2022-12-31 10:50:16,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:16,222 INFO:     Epoch: 57
2022-12-31 10:50:17,838 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4547173917293549, 'Total loss': 0.4547173917293549} | train loss {'Reaction outcome loss': 0.250228237664408, 'Total loss': 0.250228237664408}
2022-12-31 10:50:17,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:17,838 INFO:     Epoch: 58
2022-12-31 10:50:19,449 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.43977109690507254, 'Total loss': 0.43977109690507254} | train loss {'Reaction outcome loss': 0.24767444413737394, 'Total loss': 0.24767444413737394}
2022-12-31 10:50:19,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:19,450 INFO:     Epoch: 59
2022-12-31 10:50:21,024 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43554434974988304, 'Total loss': 0.43554434974988304} | train loss {'Reaction outcome loss': 0.24489132973594943, 'Total loss': 0.24489132973594943}
2022-12-31 10:50:21,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:21,024 INFO:     Epoch: 60
2022-12-31 10:50:22,683 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4406483391920725, 'Total loss': 0.4406483391920725} | train loss {'Reaction outcome loss': 0.24498121102384385, 'Total loss': 0.24498121102384385}
2022-12-31 10:50:22,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:22,683 INFO:     Epoch: 61
2022-12-31 10:50:24,328 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.429179847240448, 'Total loss': 0.429179847240448} | train loss {'Reaction outcome loss': 0.2493891852327447, 'Total loss': 0.2493891852327447}
2022-12-31 10:50:24,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:24,329 INFO:     Epoch: 62
2022-12-31 10:50:25,947 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4654558002948761, 'Total loss': 0.4654558002948761} | train loss {'Reaction outcome loss': 0.2400723653968864, 'Total loss': 0.2400723653968864}
2022-12-31 10:50:25,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:25,947 INFO:     Epoch: 63
2022-12-31 10:50:27,555 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4796753505865733, 'Total loss': 0.4796753505865733} | train loss {'Reaction outcome loss': 0.24723126062045872, 'Total loss': 0.24723126062045872}
2022-12-31 10:50:27,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:27,555 INFO:     Epoch: 64
2022-12-31 10:50:29,164 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42953546047210694, 'Total loss': 0.42953546047210694} | train loss {'Reaction outcome loss': 0.24396427749973332, 'Total loss': 0.24396427749973332}
2022-12-31 10:50:29,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:29,164 INFO:     Epoch: 65
2022-12-31 10:50:30,534 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.43627550403277077, 'Total loss': 0.43627550403277077} | train loss {'Reaction outcome loss': 0.23807823669462316, 'Total loss': 0.23807823669462316}
2022-12-31 10:50:30,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:30,535 INFO:     Epoch: 66
2022-12-31 10:50:31,608 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5105300327142079, 'Total loss': 0.5105300327142079} | train loss {'Reaction outcome loss': 0.24104673218407432, 'Total loss': 0.24104673218407432}
2022-12-31 10:50:31,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:31,609 INFO:     Epoch: 67
2022-12-31 10:50:32,673 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4501185049613317, 'Total loss': 0.4501185049613317} | train loss {'Reaction outcome loss': 0.23439836078509013, 'Total loss': 0.23439836078509013}
2022-12-31 10:50:32,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:32,673 INFO:     Epoch: 68
2022-12-31 10:50:33,739 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4525705377260844, 'Total loss': 0.4525705377260844} | train loss {'Reaction outcome loss': 0.23924085104406095, 'Total loss': 0.23924085104406095}
2022-12-31 10:50:33,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:33,740 INFO:     Epoch: 69
2022-12-31 10:50:34,894 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44721176226933795, 'Total loss': 0.44721176226933795} | train loss {'Reaction outcome loss': 0.24036136386997026, 'Total loss': 0.24036136386997026}
2022-12-31 10:50:34,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:34,895 INFO:     Epoch: 70
2022-12-31 10:50:36,488 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44963892474770545, 'Total loss': 0.44963892474770545} | train loss {'Reaction outcome loss': 0.25085603489698266, 'Total loss': 0.25085603489698266}
2022-12-31 10:50:36,488 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:36,488 INFO:     Epoch: 71
2022-12-31 10:50:38,147 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4459263096253077, 'Total loss': 0.4459263096253077} | train loss {'Reaction outcome loss': 0.2337262225548224, 'Total loss': 0.2337262225548224}
2022-12-31 10:50:38,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:38,147 INFO:     Epoch: 72
2022-12-31 10:50:39,782 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4511870197951794, 'Total loss': 0.4511870197951794} | train loss {'Reaction outcome loss': 0.23287693161114145, 'Total loss': 0.23287693161114145}
2022-12-31 10:50:39,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:39,782 INFO:     Epoch: 73
2022-12-31 10:50:41,390 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41998359362284343, 'Total loss': 0.41998359362284343} | train loss {'Reaction outcome loss': 0.24279916497703263, 'Total loss': 0.24279916497703263}
2022-12-31 10:50:41,390 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:41,390 INFO:     Epoch: 74
2022-12-31 10:50:42,998 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4797334829966227, 'Total loss': 0.4797334829966227} | train loss {'Reaction outcome loss': 0.25840820802672615, 'Total loss': 0.25840820802672615}
2022-12-31 10:50:42,999 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:42,999 INFO:     Epoch: 75
2022-12-31 10:50:44,592 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4047042677799861, 'Total loss': 0.4047042677799861} | train loss {'Reaction outcome loss': 0.3194030987216283, 'Total loss': 0.3194030987216283}
2022-12-31 10:50:44,593 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:44,593 INFO:     Epoch: 76
2022-12-31 10:50:46,179 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4522962023814519, 'Total loss': 0.4522962023814519} | train loss {'Reaction outcome loss': 0.255663069612954, 'Total loss': 0.255663069612954}
2022-12-31 10:50:46,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:46,179 INFO:     Epoch: 77
2022-12-31 10:50:47,809 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4675709128379822, 'Total loss': 0.4675709128379822} | train loss {'Reaction outcome loss': 0.28823702306608145, 'Total loss': 0.28823702306608145}
2022-12-31 10:50:47,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:47,809 INFO:     Epoch: 78
2022-12-31 10:50:49,417 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4319054514169693, 'Total loss': 0.4319054514169693} | train loss {'Reaction outcome loss': 0.23698272099157464, 'Total loss': 0.23698272099157464}
2022-12-31 10:50:49,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:49,417 INFO:     Epoch: 79
2022-12-31 10:50:51,025 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42801329096158347, 'Total loss': 0.42801329096158347} | train loss {'Reaction outcome loss': 0.22686258598190287, 'Total loss': 0.22686258598190287}
2022-12-31 10:50:51,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:51,025 INFO:     Epoch: 80
2022-12-31 10:50:52,634 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.49660857319831847, 'Total loss': 0.49660857319831847} | train loss {'Reaction outcome loss': 0.22608790193023026, 'Total loss': 0.22608790193023026}
2022-12-31 10:50:52,634 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:52,634 INFO:     Epoch: 81
2022-12-31 10:50:54,280 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44347819288571677, 'Total loss': 0.44347819288571677} | train loss {'Reaction outcome loss': 0.23825858050849344, 'Total loss': 0.23825858050849344}
2022-12-31 10:50:54,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:54,281 INFO:     Epoch: 82
2022-12-31 10:50:55,899 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4237093210220337, 'Total loss': 0.4237093210220337} | train loss {'Reaction outcome loss': 0.22567196006117307, 'Total loss': 0.22567196006117307}
2022-12-31 10:50:55,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:55,900 INFO:     Epoch: 83
2022-12-31 10:50:57,501 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4350093394517899, 'Total loss': 0.4350093394517899} | train loss {'Reaction outcome loss': 0.2264979782335433, 'Total loss': 0.2264979782335433}
2022-12-31 10:50:57,501 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:57,501 INFO:     Epoch: 84
2022-12-31 10:50:59,145 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.46857194701830546, 'Total loss': 0.46857194701830546} | train loss {'Reaction outcome loss': 0.2207804933541279, 'Total loss': 0.2207804933541279}
2022-12-31 10:50:59,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:50:59,145 INFO:     Epoch: 85
2022-12-31 10:51:00,799 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4463720838228861, 'Total loss': 0.4463720838228861} | train loss {'Reaction outcome loss': 0.21398565393157196, 'Total loss': 0.21398565393157196}
2022-12-31 10:51:00,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:00,800 INFO:     Epoch: 86
2022-12-31 10:51:02,421 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4640648439526558, 'Total loss': 0.4640648439526558} | train loss {'Reaction outcome loss': 0.22630498321761505, 'Total loss': 0.22630498321761505}
2022-12-31 10:51:02,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:02,422 INFO:     Epoch: 87
2022-12-31 10:51:04,010 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4287988156080246, 'Total loss': 0.4287988156080246} | train loss {'Reaction outcome loss': 0.21856035858829695, 'Total loss': 0.21856035858829695}
2022-12-31 10:51:04,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:04,010 INFO:     Epoch: 88
2022-12-31 10:51:05,650 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45633913079897565, 'Total loss': 0.45633913079897565} | train loss {'Reaction outcome loss': 0.22578004481729821, 'Total loss': 0.22578004481729821}
2022-12-31 10:51:05,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:05,650 INFO:     Epoch: 89
2022-12-31 10:51:07,298 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.412178643544515, 'Total loss': 0.412178643544515} | train loss {'Reaction outcome loss': 0.2128834469223638, 'Total loss': 0.2128834469223638}
2022-12-31 10:51:07,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:07,299 INFO:     Epoch: 90
2022-12-31 10:51:08,923 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4218995958566666, 'Total loss': 0.4218995958566666} | train loss {'Reaction outcome loss': 0.2169506040078451, 'Total loss': 0.2169506040078451}
2022-12-31 10:51:08,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:08,923 INFO:     Epoch: 91
2022-12-31 10:51:10,579 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.42308995525042215, 'Total loss': 0.42308995525042215} | train loss {'Reaction outcome loss': 0.217552134750962, 'Total loss': 0.217552134750962}
2022-12-31 10:51:10,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:10,580 INFO:     Epoch: 92
2022-12-31 10:51:12,215 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43097371657689415, 'Total loss': 0.43097371657689415} | train loss {'Reaction outcome loss': 0.2119239545410391, 'Total loss': 0.2119239545410391}
2022-12-31 10:51:12,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:12,215 INFO:     Epoch: 93
2022-12-31 10:51:13,816 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4609104881683985, 'Total loss': 0.4609104881683985} | train loss {'Reaction outcome loss': 0.219027875220754, 'Total loss': 0.219027875220754}
2022-12-31 10:51:13,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:13,817 INFO:     Epoch: 94
2022-12-31 10:51:15,442 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4593235562245051, 'Total loss': 0.4593235562245051} | train loss {'Reaction outcome loss': 0.2507023590262996, 'Total loss': 0.2507023590262996}
2022-12-31 10:51:15,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:15,442 INFO:     Epoch: 95
2022-12-31 10:51:17,103 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.39689179162184396, 'Total loss': 0.39689179162184396} | train loss {'Reaction outcome loss': 0.21283920494876668, 'Total loss': 0.21283920494876668}
2022-12-31 10:51:17,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:17,103 INFO:     Epoch: 96
2022-12-31 10:51:18,764 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.48112266858418784, 'Total loss': 0.48112266858418784} | train loss {'Reaction outcome loss': 0.2094941896899347, 'Total loss': 0.2094941896899347}
2022-12-31 10:51:18,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:18,764 INFO:     Epoch: 97
2022-12-31 10:51:20,396 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43971933126449586, 'Total loss': 0.43971933126449586} | train loss {'Reaction outcome loss': 0.2071968085281011, 'Total loss': 0.2071968085281011}
2022-12-31 10:51:20,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:20,396 INFO:     Epoch: 98
2022-12-31 10:51:22,021 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.437889305750529, 'Total loss': 0.437889305750529} | train loss {'Reaction outcome loss': 0.21231572579700445, 'Total loss': 0.21231572579700445}
2022-12-31 10:51:22,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:22,021 INFO:     Epoch: 99
2022-12-31 10:51:23,639 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43691393236319226, 'Total loss': 0.43691393236319226} | train loss {'Reaction outcome loss': 0.21341581041834465, 'Total loss': 0.21341581041834465}
2022-12-31 10:51:23,640 INFO:     Best model found after epoch 31 of 100.
2022-12-31 10:51:23,640 INFO:   Done with stage: TRAINING
2022-12-31 10:51:23,640 INFO:   Starting stage: EVALUATION
2022-12-31 10:51:23,766 INFO:   Done with stage: EVALUATION
2022-12-31 10:51:23,774 INFO:   Leaving out SEQ value Fold_0
2022-12-31 10:51:23,787 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 10:51:23,787 INFO:   Starting stage: FEATURE SCALING
2022-12-31 10:51:24,429 INFO:   Done with stage: FEATURE SCALING
2022-12-31 10:51:24,429 INFO:   Starting stage: SCALING TARGETS
2022-12-31 10:51:24,498 INFO:   Done with stage: SCALING TARGETS
2022-12-31 10:51:24,498 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:51:24,498 INFO:     No hyperparam tuning for this model
2022-12-31 10:51:24,498 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:51:24,498 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 10:51:24,499 INFO:     None feature selector for col prot
2022-12-31 10:51:24,499 INFO:     None feature selector for col prot
2022-12-31 10:51:24,499 INFO:     None feature selector for col prot
2022-12-31 10:51:24,500 INFO:     None feature selector for col chem
2022-12-31 10:51:24,500 INFO:     None feature selector for col chem
2022-12-31 10:51:24,500 INFO:     None feature selector for col chem
2022-12-31 10:51:24,500 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 10:51:24,500 INFO:   Starting stage: BUILD MODEL
2022-12-31 10:51:24,502 INFO:     Number of params in model 223921
2022-12-31 10:51:24,505 INFO:   Done with stage: BUILD MODEL
2022-12-31 10:51:24,505 INFO:   Starting stage: TRAINING
2022-12-31 10:51:24,551 INFO:     Val loss before train {'Reaction outcome loss': 0.9815777242183685, 'Total loss': 0.9815777242183685}
2022-12-31 10:51:24,551 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:24,551 INFO:     Epoch: 0
2022-12-31 10:51:26,155 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6988749623298645, 'Total loss': 0.6988749623298645} | train loss {'Reaction outcome loss': 0.8149009116374664, 'Total loss': 0.8149009116374664}
2022-12-31 10:51:26,156 INFO:     Found new best model at epoch 0
2022-12-31 10:51:26,156 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:26,157 INFO:     Epoch: 1
2022-12-31 10:51:27,753 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.575313397248586, 'Total loss': 0.575313397248586} | train loss {'Reaction outcome loss': 0.5961692525196249, 'Total loss': 0.5961692525196249}
2022-12-31 10:51:27,753 INFO:     Found new best model at epoch 1
2022-12-31 10:51:27,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:27,754 INFO:     Epoch: 2
2022-12-31 10:51:29,325 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5465567668279012, 'Total loss': 0.5465567668279012} | train loss {'Reaction outcome loss': 0.524466550290367, 'Total loss': 0.524466550290367}
2022-12-31 10:51:29,325 INFO:     Found new best model at epoch 2
2022-12-31 10:51:29,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:29,326 INFO:     Epoch: 3
2022-12-31 10:51:30,952 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.551593174537023, 'Total loss': 0.551593174537023} | train loss {'Reaction outcome loss': 0.5041726367534513, 'Total loss': 0.5041726367534513}
2022-12-31 10:51:30,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:30,953 INFO:     Epoch: 4
2022-12-31 10:51:32,580 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4912118256092072, 'Total loss': 0.4912118256092072} | train loss {'Reaction outcome loss': 0.48695605884503274, 'Total loss': 0.48695605884503274}
2022-12-31 10:51:32,580 INFO:     Found new best model at epoch 4
2022-12-31 10:51:32,581 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:32,581 INFO:     Epoch: 5
2022-12-31 10:51:34,188 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.518118491768837, 'Total loss': 0.518118491768837} | train loss {'Reaction outcome loss': 0.4798685174680104, 'Total loss': 0.4798685174680104}
2022-12-31 10:51:34,188 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:34,188 INFO:     Epoch: 6
2022-12-31 10:51:35,783 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.508493842681249, 'Total loss': 0.508493842681249} | train loss {'Reaction outcome loss': 0.46692337503615955, 'Total loss': 0.46692337503615955}
2022-12-31 10:51:35,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:35,784 INFO:     Epoch: 7
2022-12-31 10:51:37,420 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5491745909055074, 'Total loss': 0.5491745909055074} | train loss {'Reaction outcome loss': 0.45925912328988966, 'Total loss': 0.45925912328988966}
2022-12-31 10:51:37,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:37,421 INFO:     Epoch: 8
2022-12-31 10:51:39,013 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5003072361151377, 'Total loss': 0.5003072361151377} | train loss {'Reaction outcome loss': 0.45030514460845583, 'Total loss': 0.45030514460845583}
2022-12-31 10:51:39,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:39,013 INFO:     Epoch: 9
2022-12-31 10:51:40,614 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4850835969050725, 'Total loss': 0.4850835969050725} | train loss {'Reaction outcome loss': 0.45146351128164, 'Total loss': 0.45146351128164}
2022-12-31 10:51:40,614 INFO:     Found new best model at epoch 9
2022-12-31 10:51:40,615 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:40,615 INFO:     Epoch: 10
2022-12-31 10:51:42,217 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45246606643001236, 'Total loss': 0.45246606643001236} | train loss {'Reaction outcome loss': 0.4424316913542086, 'Total loss': 0.4424316913542086}
2022-12-31 10:51:42,217 INFO:     Found new best model at epoch 10
2022-12-31 10:51:42,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:42,218 INFO:     Epoch: 11
2022-12-31 10:51:43,825 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48059300184249876, 'Total loss': 0.48059300184249876} | train loss {'Reaction outcome loss': 0.4291774094322302, 'Total loss': 0.4291774094322302}
2022-12-31 10:51:43,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:43,825 INFO:     Epoch: 12
2022-12-31 10:51:45,428 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46618182261784874, 'Total loss': 0.46618182261784874} | train loss {'Reaction outcome loss': 0.4265482164647457, 'Total loss': 0.4265482164647457}
2022-12-31 10:51:45,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:45,428 INFO:     Epoch: 13
2022-12-31 10:51:47,037 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4602097908655802, 'Total loss': 0.4602097908655802} | train loss {'Reaction outcome loss': 0.4162595210066677, 'Total loss': 0.4162595210066677}
2022-12-31 10:51:47,037 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:47,037 INFO:     Epoch: 14
2022-12-31 10:51:48,622 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5092531283696492, 'Total loss': 0.5092531283696492} | train loss {'Reaction outcome loss': 0.4168778214685238, 'Total loss': 0.4168778214685238}
2022-12-31 10:51:48,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:48,622 INFO:     Epoch: 15
2022-12-31 10:51:50,206 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48099754750728607, 'Total loss': 0.48099754750728607} | train loss {'Reaction outcome loss': 0.4036613293264034, 'Total loss': 0.4036613293264034}
2022-12-31 10:51:50,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:50,207 INFO:     Epoch: 16
2022-12-31 10:51:51,842 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46272937059402464, 'Total loss': 0.46272937059402464} | train loss {'Reaction outcome loss': 0.4012894489850006, 'Total loss': 0.4012894489850006}
2022-12-31 10:51:51,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:51,843 INFO:     Epoch: 17
2022-12-31 10:51:53,446 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44175585160652797, 'Total loss': 0.44175585160652797} | train loss {'Reaction outcome loss': 0.3968585798938344, 'Total loss': 0.3968585798938344}
2022-12-31 10:51:53,446 INFO:     Found new best model at epoch 17
2022-12-31 10:51:53,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:53,447 INFO:     Epoch: 18
2022-12-31 10:51:55,050 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45834634602069857, 'Total loss': 0.45834634602069857} | train loss {'Reaction outcome loss': 0.3909277044998033, 'Total loss': 0.3909277044998033}
2022-12-31 10:51:55,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:55,050 INFO:     Epoch: 19
2022-12-31 10:51:56,634 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43780287404855095, 'Total loss': 0.43780287404855095} | train loss {'Reaction outcome loss': 0.3813135115171436, 'Total loss': 0.3813135115171436}
2022-12-31 10:51:56,634 INFO:     Found new best model at epoch 19
2022-12-31 10:51:56,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:56,635 INFO:     Epoch: 20
2022-12-31 10:51:58,248 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4518987496693929, 'Total loss': 0.4518987496693929} | train loss {'Reaction outcome loss': 0.3798970941209445, 'Total loss': 0.3798970941209445}
2022-12-31 10:51:58,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:58,248 INFO:     Epoch: 21
2022-12-31 10:51:59,845 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45284808774789176, 'Total loss': 0.45284808774789176} | train loss {'Reaction outcome loss': 0.3710841704567854, 'Total loss': 0.3710841704567854}
2022-12-31 10:51:59,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:51:59,845 INFO:     Epoch: 22
2022-12-31 10:52:01,440 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43494000236193336, 'Total loss': 0.43494000236193336} | train loss {'Reaction outcome loss': 0.3639304321667139, 'Total loss': 0.3639304321667139}
2022-12-31 10:52:01,441 INFO:     Found new best model at epoch 22
2022-12-31 10:52:01,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:01,442 INFO:     Epoch: 23
2022-12-31 10:52:03,034 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4398695786794027, 'Total loss': 0.4398695786794027} | train loss {'Reaction outcome loss': 0.35663853854919875, 'Total loss': 0.35663853854919875}
2022-12-31 10:52:03,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:03,035 INFO:     Epoch: 24
2022-12-31 10:52:04,629 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4274827261765798, 'Total loss': 0.4274827261765798} | train loss {'Reaction outcome loss': 0.3558488270662127, 'Total loss': 0.3558488270662127}
2022-12-31 10:52:04,629 INFO:     Found new best model at epoch 24
2022-12-31 10:52:04,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:04,630 INFO:     Epoch: 25
2022-12-31 10:52:06,225 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4249221503734589, 'Total loss': 0.4249221503734589} | train loss {'Reaction outcome loss': 0.3548787259598718, 'Total loss': 0.3548787259598718}
2022-12-31 10:52:06,226 INFO:     Found new best model at epoch 25
2022-12-31 10:52:06,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:06,227 INFO:     Epoch: 26
2022-12-31 10:52:07,817 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.41667454739411675, 'Total loss': 0.41667454739411675} | train loss {'Reaction outcome loss': 0.34249693533256104, 'Total loss': 0.34249693533256104}
2022-12-31 10:52:07,817 INFO:     Found new best model at epoch 26
2022-12-31 10:52:07,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:07,818 INFO:     Epoch: 27
2022-12-31 10:52:09,410 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4343493809302648, 'Total loss': 0.4343493809302648} | train loss {'Reaction outcome loss': 0.3443945436636462, 'Total loss': 0.3443945436636462}
2022-12-31 10:52:09,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:09,410 INFO:     Epoch: 28
2022-12-31 10:52:10,988 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4358778605858485, 'Total loss': 0.4358778605858485} | train loss {'Reaction outcome loss': 0.3345118931011997, 'Total loss': 0.3345118931011997}
2022-12-31 10:52:10,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:10,989 INFO:     Epoch: 29
2022-12-31 10:52:12,584 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4355565001567205, 'Total loss': 0.4355565001567205} | train loss {'Reaction outcome loss': 0.3330875162279954, 'Total loss': 0.3330875162279954}
2022-12-31 10:52:12,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:12,585 INFO:     Epoch: 30
2022-12-31 10:52:14,200 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.384423620502154, 'Total loss': 0.384423620502154} | train loss {'Reaction outcome loss': 0.32400742140564603, 'Total loss': 0.32400742140564603}
2022-12-31 10:52:14,200 INFO:     Found new best model at epoch 30
2022-12-31 10:52:14,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:14,201 INFO:     Epoch: 31
2022-12-31 10:52:15,807 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4217706710100174, 'Total loss': 0.4217706710100174} | train loss {'Reaction outcome loss': 0.3202113437255586, 'Total loss': 0.3202113437255586}
2022-12-31 10:52:15,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:15,807 INFO:     Epoch: 32
2022-12-31 10:52:17,408 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.428636493285497, 'Total loss': 0.428636493285497} | train loss {'Reaction outcome loss': 0.3161394550417462, 'Total loss': 0.3161394550417462}
2022-12-31 10:52:17,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:17,409 INFO:     Epoch: 33
2022-12-31 10:52:19,041 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4197336932023366, 'Total loss': 0.4197336932023366} | train loss {'Reaction outcome loss': 0.31477882870792473, 'Total loss': 0.31477882870792473}
2022-12-31 10:52:19,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:19,041 INFO:     Epoch: 34
2022-12-31 10:52:20,657 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.43253250618775685, 'Total loss': 0.43253250618775685} | train loss {'Reaction outcome loss': 0.31119025168247033, 'Total loss': 0.31119025168247033}
2022-12-31 10:52:20,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:20,657 INFO:     Epoch: 35
2022-12-31 10:52:22,281 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4289631883303324, 'Total loss': 0.4289631883303324} | train loss {'Reaction outcome loss': 0.30791856428730663, 'Total loss': 0.30791856428730663}
2022-12-31 10:52:22,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:22,281 INFO:     Epoch: 36
2022-12-31 10:52:23,882 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4315058251221975, 'Total loss': 0.4315058251221975} | train loss {'Reaction outcome loss': 0.2997786464291985, 'Total loss': 0.2997786464291985}
2022-12-31 10:52:23,882 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:23,882 INFO:     Epoch: 37
2022-12-31 10:52:25,491 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42287262876828513, 'Total loss': 0.42287262876828513} | train loss {'Reaction outcome loss': 0.3003712111513001, 'Total loss': 0.3003712111513001}
2022-12-31 10:52:25,492 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:25,492 INFO:     Epoch: 38
2022-12-31 10:52:27,144 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41015963355700175, 'Total loss': 0.41015963355700175} | train loss {'Reaction outcome loss': 0.2960733249239678, 'Total loss': 0.2960733249239678}
2022-12-31 10:52:27,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:27,145 INFO:     Epoch: 39
2022-12-31 10:52:28,797 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39466286897659303, 'Total loss': 0.39466286897659303} | train loss {'Reaction outcome loss': 0.28753506305226445, 'Total loss': 0.28753506305226445}
2022-12-31 10:52:28,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:28,798 INFO:     Epoch: 40
2022-12-31 10:52:30,409 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.37757960756619774, 'Total loss': 0.37757960756619774} | train loss {'Reaction outcome loss': 0.29110881252499826, 'Total loss': 0.29110881252499826}
2022-12-31 10:52:30,409 INFO:     Found new best model at epoch 40
2022-12-31 10:52:30,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:30,410 INFO:     Epoch: 41
2022-12-31 10:52:32,041 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38414209683736167, 'Total loss': 0.38414209683736167} | train loss {'Reaction outcome loss': 0.2833147603121117, 'Total loss': 0.2833147603121117}
2022-12-31 10:52:32,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:32,041 INFO:     Epoch: 42
2022-12-31 10:52:33,625 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40119216839472455, 'Total loss': 0.40119216839472455} | train loss {'Reaction outcome loss': 0.2852303890348242, 'Total loss': 0.2852303890348242}
2022-12-31 10:52:33,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:33,625 INFO:     Epoch: 43
2022-12-31 10:52:35,216 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4306316673755646, 'Total loss': 0.4306316673755646} | train loss {'Reaction outcome loss': 0.2867163815501615, 'Total loss': 0.2867163815501615}
2022-12-31 10:52:35,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:35,217 INFO:     Epoch: 44
2022-12-31 10:52:36,869 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3969486378133297, 'Total loss': 0.3969486378133297} | train loss {'Reaction outcome loss': 0.2810400560307894, 'Total loss': 0.2810400560307894}
2022-12-31 10:52:36,870 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:36,870 INFO:     Epoch: 45
2022-12-31 10:52:38,530 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4290899684031804, 'Total loss': 0.4290899684031804} | train loss {'Reaction outcome loss': 0.2780352269917944, 'Total loss': 0.2780352269917944}
2022-12-31 10:52:38,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:38,530 INFO:     Epoch: 46
2022-12-31 10:52:40,176 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44642894764741264, 'Total loss': 0.44642894764741264} | train loss {'Reaction outcome loss': 0.27382969668638096, 'Total loss': 0.27382969668638096}
2022-12-31 10:52:40,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:40,176 INFO:     Epoch: 47
2022-12-31 10:52:41,812 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4074783012270927, 'Total loss': 0.4074783012270927} | train loss {'Reaction outcome loss': 0.2659235182524162, 'Total loss': 0.2659235182524162}
2022-12-31 10:52:41,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:41,812 INFO:     Epoch: 48
2022-12-31 10:52:43,397 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39976764619350436, 'Total loss': 0.39976764619350436} | train loss {'Reaction outcome loss': 0.264776514652763, 'Total loss': 0.264776514652763}
2022-12-31 10:52:43,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:43,398 INFO:     Epoch: 49
2022-12-31 10:52:44,984 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.378679358959198, 'Total loss': 0.378679358959198} | train loss {'Reaction outcome loss': 0.26482635089298234, 'Total loss': 0.26482635089298234}
2022-12-31 10:52:44,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:44,984 INFO:     Epoch: 50
2022-12-31 10:52:46,586 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42101516922314963, 'Total loss': 0.42101516922314963} | train loss {'Reaction outcome loss': 0.2619206605302374, 'Total loss': 0.2619206605302374}
2022-12-31 10:52:46,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:46,586 INFO:     Epoch: 51
2022-12-31 10:52:48,191 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43062877257665, 'Total loss': 0.43062877257665} | train loss {'Reaction outcome loss': 0.2713375335532057, 'Total loss': 0.2713375335532057}
2022-12-31 10:52:48,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:48,191 INFO:     Epoch: 52
2022-12-31 10:52:49,789 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.37974499464035033, 'Total loss': 0.37974499464035033} | train loss {'Reaction outcome loss': 0.26236168129614346, 'Total loss': 0.26236168129614346}
2022-12-31 10:52:49,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:49,789 INFO:     Epoch: 53
2022-12-31 10:52:51,415 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39858346432447433, 'Total loss': 0.39858346432447433} | train loss {'Reaction outcome loss': 0.247924040404767, 'Total loss': 0.247924040404767}
2022-12-31 10:52:51,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:51,415 INFO:     Epoch: 54
2022-12-31 10:52:53,000 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.38783033192157745, 'Total loss': 0.38783033192157745} | train loss {'Reaction outcome loss': 0.25239459909226775, 'Total loss': 0.25239459909226775}
2022-12-31 10:52:53,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:53,000 INFO:     Epoch: 55
2022-12-31 10:52:54,599 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4042791744073232, 'Total loss': 0.4042791744073232} | train loss {'Reaction outcome loss': 0.24807944727966386, 'Total loss': 0.24807944727966386}
2022-12-31 10:52:54,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:54,600 INFO:     Epoch: 56
2022-12-31 10:52:56,201 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39961100518703463, 'Total loss': 0.39961100518703463} | train loss {'Reaction outcome loss': 0.24830469255247256, 'Total loss': 0.24830469255247256}
2022-12-31 10:52:56,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:56,202 INFO:     Epoch: 57
2022-12-31 10:52:57,803 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3630085031191508, 'Total loss': 0.3630085031191508} | train loss {'Reaction outcome loss': 0.2503169139262533, 'Total loss': 0.2503169139262533}
2022-12-31 10:52:57,803 INFO:     Found new best model at epoch 57
2022-12-31 10:52:57,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:57,804 INFO:     Epoch: 58
2022-12-31 10:52:59,404 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.39702115058898924, 'Total loss': 0.39702115058898924} | train loss {'Reaction outcome loss': 0.24688532717362807, 'Total loss': 0.24688532717362807}
2022-12-31 10:52:59,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:52:59,404 INFO:     Epoch: 59
2022-12-31 10:53:01,025 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3859005699555079, 'Total loss': 0.3859005699555079} | train loss {'Reaction outcome loss': 0.25195853024666764, 'Total loss': 0.25195853024666764}
2022-12-31 10:53:01,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:01,025 INFO:     Epoch: 60
2022-12-31 10:53:02,626 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3642078657944997, 'Total loss': 0.3642078657944997} | train loss {'Reaction outcome loss': 0.24427089013539963, 'Total loss': 0.24427089013539963}
2022-12-31 10:53:02,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:02,626 INFO:     Epoch: 61
2022-12-31 10:53:04,223 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3899619738260905, 'Total loss': 0.3899619738260905} | train loss {'Reaction outcome loss': 0.24281970773191347, 'Total loss': 0.24281970773191347}
2022-12-31 10:53:04,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:04,224 INFO:     Epoch: 62
2022-12-31 10:53:05,822 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3753655751546224, 'Total loss': 0.3753655751546224} | train loss {'Reaction outcome loss': 0.2374663707412725, 'Total loss': 0.2374663707412725}
2022-12-31 10:53:05,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:05,822 INFO:     Epoch: 63
2022-12-31 10:53:07,419 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.41534473896026614, 'Total loss': 0.41534473896026614} | train loss {'Reaction outcome loss': 0.23774233497815192, 'Total loss': 0.23774233497815192}
2022-12-31 10:53:07,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:07,420 INFO:     Epoch: 64
2022-12-31 10:53:09,014 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3926446706056595, 'Total loss': 0.3926446706056595} | train loss {'Reaction outcome loss': 0.23480149183123217, 'Total loss': 0.23480149183123217}
2022-12-31 10:53:09,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:09,015 INFO:     Epoch: 65
2022-12-31 10:53:10,616 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.36412615664303305, 'Total loss': 0.36412615664303305} | train loss {'Reaction outcome loss': 0.22714339461803001, 'Total loss': 0.22714339461803001}
2022-12-31 10:53:10,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:10,617 INFO:     Epoch: 66
2022-12-31 10:53:12,236 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3727682739496231, 'Total loss': 0.3727682739496231} | train loss {'Reaction outcome loss': 0.23089555385148655, 'Total loss': 0.23089555385148655}
2022-12-31 10:53:12,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:12,236 INFO:     Epoch: 67
2022-12-31 10:53:13,871 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3819093808531761, 'Total loss': 0.3819093808531761} | train loss {'Reaction outcome loss': 0.23367319952859714, 'Total loss': 0.23367319952859714}
2022-12-31 10:53:13,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:13,872 INFO:     Epoch: 68
2022-12-31 10:53:15,468 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45131669839223226, 'Total loss': 0.45131669839223226} | train loss {'Reaction outcome loss': 0.22637327952840686, 'Total loss': 0.22637327952840686}
2022-12-31 10:53:15,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:15,469 INFO:     Epoch: 69
2022-12-31 10:53:17,064 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4117648109793663, 'Total loss': 0.4117648109793663} | train loss {'Reaction outcome loss': 0.22335982939269203, 'Total loss': 0.22335982939269203}
2022-12-31 10:53:17,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:17,064 INFO:     Epoch: 70
2022-12-31 10:53:18,641 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39262388994296393, 'Total loss': 0.39262388994296393} | train loss {'Reaction outcome loss': 0.22864808143544807, 'Total loss': 0.22864808143544807}
2022-12-31 10:53:18,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:18,642 INFO:     Epoch: 71
2022-12-31 10:53:20,251 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3581915333867073, 'Total loss': 0.3581915333867073} | train loss {'Reaction outcome loss': 0.22348552429708687, 'Total loss': 0.22348552429708687}
2022-12-31 10:53:20,251 INFO:     Found new best model at epoch 71
2022-12-31 10:53:20,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:20,252 INFO:     Epoch: 72
2022-12-31 10:53:21,838 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3593550682067871, 'Total loss': 0.3593550682067871} | train loss {'Reaction outcome loss': 0.22723770469263957, 'Total loss': 0.22723770469263957}
2022-12-31 10:53:21,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:21,838 INFO:     Epoch: 73
2022-12-31 10:53:23,432 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3869720036784808, 'Total loss': 0.3869720036784808} | train loss {'Reaction outcome loss': 0.2167078649122132, 'Total loss': 0.2167078649122132}
2022-12-31 10:53:23,432 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:23,432 INFO:     Epoch: 74
2022-12-31 10:53:25,083 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4057256837685903, 'Total loss': 0.4057256837685903} | train loss {'Reaction outcome loss': 0.22235291804710444, 'Total loss': 0.22235291804710444}
2022-12-31 10:53:25,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:25,084 INFO:     Epoch: 75
2022-12-31 10:53:26,732 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3909249352912108, 'Total loss': 0.3909249352912108} | train loss {'Reaction outcome loss': 0.22017780539790427, 'Total loss': 0.22017780539790427}
2022-12-31 10:53:26,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:26,733 INFO:     Epoch: 76
2022-12-31 10:53:28,350 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3848913033803304, 'Total loss': 0.3848913033803304} | train loss {'Reaction outcome loss': 0.21783807352321208, 'Total loss': 0.21783807352321208}
2022-12-31 10:53:28,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:28,350 INFO:     Epoch: 77
2022-12-31 10:53:29,972 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3782043864329656, 'Total loss': 0.3782043864329656} | train loss {'Reaction outcome loss': 0.21990634821844798, 'Total loss': 0.21990634821844798}
2022-12-31 10:53:29,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:29,972 INFO:     Epoch: 78
2022-12-31 10:53:31,624 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39692525466283163, 'Total loss': 0.39692525466283163} | train loss {'Reaction outcome loss': 0.2110011919136465, 'Total loss': 0.2110011919136465}
2022-12-31 10:53:31,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:31,624 INFO:     Epoch: 79
2022-12-31 10:53:33,260 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3835830221573512, 'Total loss': 0.3835830221573512} | train loss {'Reaction outcome loss': 0.21977635369683704, 'Total loss': 0.21977635369683704}
2022-12-31 10:53:33,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:33,260 INFO:     Epoch: 80
2022-12-31 10:53:34,857 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3839011530081431, 'Total loss': 0.3839011530081431} | train loss {'Reaction outcome loss': 0.21425747123621677, 'Total loss': 0.21425747123621677}
2022-12-31 10:53:34,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:34,858 INFO:     Epoch: 81
2022-12-31 10:53:36,446 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3850603183110555, 'Total loss': 0.3850603183110555} | train loss {'Reaction outcome loss': 0.2152075319666497, 'Total loss': 0.2152075319666497}
2022-12-31 10:53:36,446 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:36,446 INFO:     Epoch: 82
2022-12-31 10:53:38,050 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3591106817126274, 'Total loss': 0.3591106817126274} | train loss {'Reaction outcome loss': 0.2118576360988791, 'Total loss': 0.2118576360988791}
2022-12-31 10:53:38,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:38,051 INFO:     Epoch: 83
2022-12-31 10:53:39,669 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.38270311454931893, 'Total loss': 0.38270311454931893} | train loss {'Reaction outcome loss': 0.21057399257636852, 'Total loss': 0.21057399257636852}
2022-12-31 10:53:39,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:39,669 INFO:     Epoch: 84
2022-12-31 10:53:41,281 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40124160548051196, 'Total loss': 0.40124160548051196} | train loss {'Reaction outcome loss': 0.20829328309989323, 'Total loss': 0.20829328309989323}
2022-12-31 10:53:41,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:41,281 INFO:     Epoch: 85
2022-12-31 10:53:42,880 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41074277261892955, 'Total loss': 0.41074277261892955} | train loss {'Reaction outcome loss': 0.20579106623755536, 'Total loss': 0.20579106623755536}
2022-12-31 10:53:42,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:42,881 INFO:     Epoch: 86
2022-12-31 10:53:44,478 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4358012855052948, 'Total loss': 0.4358012855052948} | train loss {'Reaction outcome loss': 0.20794360423256664, 'Total loss': 0.20794360423256664}
2022-12-31 10:53:44,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:44,478 INFO:     Epoch: 87
2022-12-31 10:53:46,058 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.35449242939551673, 'Total loss': 0.35449242939551673} | train loss {'Reaction outcome loss': 0.20458062577068153, 'Total loss': 0.20458062577068153}
2022-12-31 10:53:46,058 INFO:     Found new best model at epoch 87
2022-12-31 10:53:46,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:46,059 INFO:     Epoch: 88
2022-12-31 10:53:47,642 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4055886020263036, 'Total loss': 0.4055886020263036} | train loss {'Reaction outcome loss': 0.20717272518651328, 'Total loss': 0.20717272518651328}
2022-12-31 10:53:47,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:47,642 INFO:     Epoch: 89
2022-12-31 10:53:49,240 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4044093946615855, 'Total loss': 0.4044093946615855} | train loss {'Reaction outcome loss': 0.2091056433757835, 'Total loss': 0.2091056433757835}
2022-12-31 10:53:49,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:49,240 INFO:     Epoch: 90
2022-12-31 10:53:50,837 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.39997046689192456, 'Total loss': 0.39997046689192456} | train loss {'Reaction outcome loss': 0.20640185668411917, 'Total loss': 0.20640185668411917}
2022-12-31 10:53:50,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:50,837 INFO:     Epoch: 91
2022-12-31 10:53:52,434 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3855462481578191, 'Total loss': 0.3855462481578191} | train loss {'Reaction outcome loss': 0.20094362426766732, 'Total loss': 0.20094362426766732}
2022-12-31 10:53:52,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:52,434 INFO:     Epoch: 92
2022-12-31 10:53:54,031 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3954483956098557, 'Total loss': 0.3954483956098557} | train loss {'Reaction outcome loss': 0.20076248568421515, 'Total loss': 0.20076248568421515}
2022-12-31 10:53:54,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:54,031 INFO:     Epoch: 93
2022-12-31 10:53:55,631 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3900603582461675, 'Total loss': 0.3900603582461675} | train loss {'Reaction outcome loss': 0.19641382572832553, 'Total loss': 0.19641382572832553}
2022-12-31 10:53:55,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:55,631 INFO:     Epoch: 94
2022-12-31 10:53:57,223 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4186714440584183, 'Total loss': 0.4186714440584183} | train loss {'Reaction outcome loss': 0.19954770120934848, 'Total loss': 0.19954770120934848}
2022-12-31 10:53:57,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:57,224 INFO:     Epoch: 95
2022-12-31 10:53:58,868 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3715982089440028, 'Total loss': 0.3715982089440028} | train loss {'Reaction outcome loss': 0.19641040644207358, 'Total loss': 0.19641040644207358}
2022-12-31 10:53:58,868 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:53:58,868 INFO:     Epoch: 96
2022-12-31 10:54:00,465 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46013164321581523, 'Total loss': 0.46013164321581523} | train loss {'Reaction outcome loss': 0.19537273171718103, 'Total loss': 0.19537273171718103}
2022-12-31 10:54:00,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:00,465 INFO:     Epoch: 97
2022-12-31 10:54:02,056 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3760230243206024, 'Total loss': 0.3760230243206024} | train loss {'Reaction outcome loss': 0.1990388267721138, 'Total loss': 0.1990388267721138}
2022-12-31 10:54:02,057 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:02,057 INFO:     Epoch: 98
2022-12-31 10:54:03,638 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4175340006748835, 'Total loss': 0.4175340006748835} | train loss {'Reaction outcome loss': 0.1997612877069109, 'Total loss': 0.1997612877069109}
2022-12-31 10:54:03,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:03,638 INFO:     Epoch: 99
2022-12-31 10:54:05,210 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.35792797108491264, 'Total loss': 0.35792797108491264} | train loss {'Reaction outcome loss': 0.1977259280010514, 'Total loss': 0.1977259280010514}
2022-12-31 10:54:05,210 INFO:     Best model found after epoch 88 of 100.
2022-12-31 10:54:05,210 INFO:   Done with stage: TRAINING
2022-12-31 10:54:05,210 INFO:   Starting stage: EVALUATION
2022-12-31 10:54:05,344 INFO:   Done with stage: EVALUATION
2022-12-31 10:54:05,344 INFO:   Leaving out SEQ value Fold_1
2022-12-31 10:54:05,357 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 10:54:05,357 INFO:   Starting stage: FEATURE SCALING
2022-12-31 10:54:06,000 INFO:   Done with stage: FEATURE SCALING
2022-12-31 10:54:06,001 INFO:   Starting stage: SCALING TARGETS
2022-12-31 10:54:06,070 INFO:   Done with stage: SCALING TARGETS
2022-12-31 10:54:06,070 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:54:06,070 INFO:     No hyperparam tuning for this model
2022-12-31 10:54:06,070 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:54:06,070 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 10:54:06,071 INFO:     None feature selector for col prot
2022-12-31 10:54:06,071 INFO:     None feature selector for col prot
2022-12-31 10:54:06,071 INFO:     None feature selector for col prot
2022-12-31 10:54:06,071 INFO:     None feature selector for col chem
2022-12-31 10:54:06,071 INFO:     None feature selector for col chem
2022-12-31 10:54:06,072 INFO:     None feature selector for col chem
2022-12-31 10:54:06,072 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 10:54:06,072 INFO:   Starting stage: BUILD MODEL
2022-12-31 10:54:06,073 INFO:     Number of params in model 223921
2022-12-31 10:54:06,076 INFO:   Done with stage: BUILD MODEL
2022-12-31 10:54:06,077 INFO:   Starting stage: TRAINING
2022-12-31 10:54:06,122 INFO:     Val loss before train {'Reaction outcome loss': 0.9685873508453369, 'Total loss': 0.9685873508453369}
2022-12-31 10:54:06,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:06,123 INFO:     Epoch: 0
2022-12-31 10:54:07,744 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6378799299399058, 'Total loss': 0.6378799299399058} | train loss {'Reaction outcome loss': 0.8206052590895744, 'Total loss': 0.8206052590895744}
2022-12-31 10:54:07,745 INFO:     Found new best model at epoch 0
2022-12-31 10:54:07,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:07,745 INFO:     Epoch: 1
2022-12-31 10:54:09,363 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5533757686614991, 'Total loss': 0.5533757686614991} | train loss {'Reaction outcome loss': 0.6017961926812673, 'Total loss': 0.6017961926812673}
2022-12-31 10:54:09,363 INFO:     Found new best model at epoch 1
2022-12-31 10:54:09,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:09,364 INFO:     Epoch: 2
2022-12-31 10:54:10,972 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.481383748849233, 'Total loss': 0.481383748849233} | train loss {'Reaction outcome loss': 0.521917324486005, 'Total loss': 0.521917324486005}
2022-12-31 10:54:10,972 INFO:     Found new best model at epoch 2
2022-12-31 10:54:10,973 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:10,973 INFO:     Epoch: 3
2022-12-31 10:54:12,555 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.45823410153388977, 'Total loss': 0.45823410153388977} | train loss {'Reaction outcome loss': 0.49949673862352856, 'Total loss': 0.49949673862352856}
2022-12-31 10:54:12,555 INFO:     Found new best model at epoch 3
2022-12-31 10:54:12,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:12,556 INFO:     Epoch: 4
2022-12-31 10:54:14,137 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47840973138809206, 'Total loss': 0.47840973138809206} | train loss {'Reaction outcome loss': 0.48326508140694485, 'Total loss': 0.48326508140694485}
2022-12-31 10:54:14,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:14,138 INFO:     Epoch: 5
2022-12-31 10:54:15,733 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48420483072598774, 'Total loss': 0.48420483072598774} | train loss {'Reaction outcome loss': 0.47979476278389455, 'Total loss': 0.47979476278389455}
2022-12-31 10:54:15,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:15,734 INFO:     Epoch: 6
2022-12-31 10:54:17,336 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4581238408883413, 'Total loss': 0.4581238408883413} | train loss {'Reaction outcome loss': 0.45990512492882946, 'Total loss': 0.45990512492882946}
2022-12-31 10:54:17,336 INFO:     Found new best model at epoch 6
2022-12-31 10:54:17,337 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:17,337 INFO:     Epoch: 7
2022-12-31 10:54:18,935 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4409385522206624, 'Total loss': 0.4409385522206624} | train loss {'Reaction outcome loss': 0.45486011016216593, 'Total loss': 0.45486011016216593}
2022-12-31 10:54:18,935 INFO:     Found new best model at epoch 7
2022-12-31 10:54:18,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:18,936 INFO:     Epoch: 8
2022-12-31 10:54:20,531 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.44509495397408805, 'Total loss': 0.44509495397408805} | train loss {'Reaction outcome loss': 0.4485787959755772, 'Total loss': 0.4485787959755772}
2022-12-31 10:54:20,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:20,532 INFO:     Epoch: 9
2022-12-31 10:54:22,110 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42464078068733213, 'Total loss': 0.42464078068733213} | train loss {'Reaction outcome loss': 0.44229229683749866, 'Total loss': 0.44229229683749866}
2022-12-31 10:54:22,110 INFO:     Found new best model at epoch 9
2022-12-31 10:54:22,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:22,111 INFO:     Epoch: 10
2022-12-31 10:54:23,686 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4496210058530172, 'Total loss': 0.4496210058530172} | train loss {'Reaction outcome loss': 0.43782923446737065, 'Total loss': 0.43782923446737065}
2022-12-31 10:54:23,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:23,686 INFO:     Epoch: 11
2022-12-31 10:54:25,281 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4338717132806778, 'Total loss': 0.4338717132806778} | train loss {'Reaction outcome loss': 0.4313783037075161, 'Total loss': 0.4313783037075161}
2022-12-31 10:54:25,281 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:25,281 INFO:     Epoch: 12
2022-12-31 10:54:26,880 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4459104100863139, 'Total loss': 0.4459104100863139} | train loss {'Reaction outcome loss': 0.4170520685232469, 'Total loss': 0.4170520685232469}
2022-12-31 10:54:26,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:26,880 INFO:     Epoch: 13
2022-12-31 10:54:28,479 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43063606023788453, 'Total loss': 0.43063606023788453} | train loss {'Reaction outcome loss': 0.417233900704088, 'Total loss': 0.417233900704088}
2022-12-31 10:54:28,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:28,479 INFO:     Epoch: 14
2022-12-31 10:54:30,077 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.41628765215476354, 'Total loss': 0.41628765215476354} | train loss {'Reaction outcome loss': 0.41077924517058106, 'Total loss': 0.41077924517058106}
2022-12-31 10:54:30,077 INFO:     Found new best model at epoch 14
2022-12-31 10:54:30,078 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:30,078 INFO:     Epoch: 15
2022-12-31 10:54:31,656 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.40443956702947614, 'Total loss': 0.40443956702947614} | train loss {'Reaction outcome loss': 0.4107447050674988, 'Total loss': 0.4107447050674988}
2022-12-31 10:54:31,657 INFO:     Found new best model at epoch 15
2022-12-31 10:54:31,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:31,657 INFO:     Epoch: 16
2022-12-31 10:54:33,233 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40775304238001503, 'Total loss': 0.40775304238001503} | train loss {'Reaction outcome loss': 0.39826229943411195, 'Total loss': 0.39826229943411195}
2022-12-31 10:54:33,234 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:33,234 INFO:     Epoch: 17
2022-12-31 10:54:34,828 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4210558513800303, 'Total loss': 0.4210558513800303} | train loss {'Reaction outcome loss': 0.3946432396225686, 'Total loss': 0.3946432396225686}
2022-12-31 10:54:34,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:34,828 INFO:     Epoch: 18
2022-12-31 10:54:36,426 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4183849294980367, 'Total loss': 0.4183849294980367} | train loss {'Reaction outcome loss': 0.39390375932855326, 'Total loss': 0.39390375932855326}
2022-12-31 10:54:36,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:36,426 INFO:     Epoch: 19
2022-12-31 10:54:38,025 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4431580980618795, 'Total loss': 0.4431580980618795} | train loss {'Reaction outcome loss': 0.3821747889266397, 'Total loss': 0.3821747889266397}
2022-12-31 10:54:38,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:38,025 INFO:     Epoch: 20
2022-12-31 10:54:39,641 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4001912251114845, 'Total loss': 0.4001912251114845} | train loss {'Reaction outcome loss': 0.3813854355609765, 'Total loss': 0.3813854355609765}
2022-12-31 10:54:39,641 INFO:     Found new best model at epoch 20
2022-12-31 10:54:39,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:39,642 INFO:     Epoch: 21
2022-12-31 10:54:41,249 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4051540235678355, 'Total loss': 0.4051540235678355} | train loss {'Reaction outcome loss': 0.37320543836503134, 'Total loss': 0.37320543836503134}
2022-12-31 10:54:41,249 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:41,249 INFO:     Epoch: 22
2022-12-31 10:54:42,906 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3953792413075765, 'Total loss': 0.3953792413075765} | train loss {'Reaction outcome loss': 0.3706912164216059, 'Total loss': 0.3706912164216059}
2022-12-31 10:54:42,906 INFO:     Found new best model at epoch 22
2022-12-31 10:54:42,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:42,907 INFO:     Epoch: 23
2022-12-31 10:54:44,547 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4061981836954753, 'Total loss': 0.4061981836954753} | train loss {'Reaction outcome loss': 0.3616154774561198, 'Total loss': 0.3616154774561198}
2022-12-31 10:54:44,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:44,548 INFO:     Epoch: 24
2022-12-31 10:54:46,155 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41628970205783844, 'Total loss': 0.41628970205783844} | train loss {'Reaction outcome loss': 0.36208674565882143, 'Total loss': 0.36208674565882143}
2022-12-31 10:54:46,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:46,155 INFO:     Epoch: 25
2022-12-31 10:54:47,763 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40629536658525467, 'Total loss': 0.40629536658525467} | train loss {'Reaction outcome loss': 0.35647343084161737, 'Total loss': 0.35647343084161737}
2022-12-31 10:54:47,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:47,763 INFO:     Epoch: 26
2022-12-31 10:54:49,346 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42449307143688203, 'Total loss': 0.42449307143688203} | train loss {'Reaction outcome loss': 0.3536469926037928, 'Total loss': 0.3536469926037928}
2022-12-31 10:54:49,346 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:49,346 INFO:     Epoch: 27
2022-12-31 10:54:50,922 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39879586193710564, 'Total loss': 0.39879586193710564} | train loss {'Reaction outcome loss': 0.3425675031259982, 'Total loss': 0.3425675031259982}
2022-12-31 10:54:50,923 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:50,923 INFO:     Epoch: 28
2022-12-31 10:54:52,572 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41362020174662273, 'Total loss': 0.41362020174662273} | train loss {'Reaction outcome loss': 0.3468938114760566, 'Total loss': 0.3468938114760566}
2022-12-31 10:54:52,572 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:52,572 INFO:     Epoch: 29
2022-12-31 10:54:54,183 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4301501035690308, 'Total loss': 0.4301501035690308} | train loss {'Reaction outcome loss': 0.32944852899569665, 'Total loss': 0.32944852899569665}
2022-12-31 10:54:54,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:54,183 INFO:     Epoch: 30
2022-12-31 10:54:55,794 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3805357257525126, 'Total loss': 0.3805357257525126} | train loss {'Reaction outcome loss': 0.3369276748195182, 'Total loss': 0.3369276748195182}
2022-12-31 10:54:55,794 INFO:     Found new best model at epoch 30
2022-12-31 10:54:55,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:55,795 INFO:     Epoch: 31
2022-12-31 10:54:57,403 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4424777328968048, 'Total loss': 0.4424777328968048} | train loss {'Reaction outcome loss': 0.3225418387429558, 'Total loss': 0.3225418387429558}
2022-12-31 10:54:57,404 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:57,404 INFO:     Epoch: 32
2022-12-31 10:54:59,012 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3802533974250158, 'Total loss': 0.3802533974250158} | train loss {'Reaction outcome loss': 0.32000117974668524, 'Total loss': 0.32000117974668524}
2022-12-31 10:54:59,012 INFO:     Found new best model at epoch 32
2022-12-31 10:54:59,012 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:54:59,013 INFO:     Epoch: 33
2022-12-31 10:55:00,602 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.414179664850235, 'Total loss': 0.414179664850235} | train loss {'Reaction outcome loss': 0.32004516309358344, 'Total loss': 0.32004516309358344}
2022-12-31 10:55:00,602 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:00,602 INFO:     Epoch: 34
2022-12-31 10:55:02,208 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.41652325391769407, 'Total loss': 0.41652325391769407} | train loss {'Reaction outcome loss': 0.3153155618449197, 'Total loss': 0.3153155618449197}
2022-12-31 10:55:02,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:02,208 INFO:     Epoch: 35
2022-12-31 10:55:03,816 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4001575142145157, 'Total loss': 0.4001575142145157} | train loss {'Reaction outcome loss': 0.3129788150154326, 'Total loss': 0.3129788150154326}
2022-12-31 10:55:03,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:03,817 INFO:     Epoch: 36
2022-12-31 10:55:05,423 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42278380890687306, 'Total loss': 0.42278380890687306} | train loss {'Reaction outcome loss': 0.3060971514532601, 'Total loss': 0.3060971514532601}
2022-12-31 10:55:05,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:05,423 INFO:     Epoch: 37
2022-12-31 10:55:07,009 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3794017881155014, 'Total loss': 0.3794017881155014} | train loss {'Reaction outcome loss': 0.30634030854043953, 'Total loss': 0.30634030854043953}
2022-12-31 10:55:07,009 INFO:     Found new best model at epoch 37
2022-12-31 10:55:07,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:07,010 INFO:     Epoch: 38
2022-12-31 10:55:08,627 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40971490144729616, 'Total loss': 0.40971490144729616} | train loss {'Reaction outcome loss': 0.2999730079713529, 'Total loss': 0.2999730079713529}
2022-12-31 10:55:08,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:08,627 INFO:     Epoch: 39
2022-12-31 10:55:10,233 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3815613249937693, 'Total loss': 0.3815613249937693} | train loss {'Reaction outcome loss': 0.2977862582290477, 'Total loss': 0.2977862582290477}
2022-12-31 10:55:10,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:10,233 INFO:     Epoch: 40
2022-12-31 10:55:11,839 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3851993461449941, 'Total loss': 0.3851993461449941} | train loss {'Reaction outcome loss': 0.2938036658957492, 'Total loss': 0.2938036658957492}
2022-12-31 10:55:11,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:11,840 INFO:     Epoch: 41
2022-12-31 10:55:13,445 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3839255462090174, 'Total loss': 0.3839255462090174} | train loss {'Reaction outcome loss': 0.2864741903124717, 'Total loss': 0.2864741903124717}
2022-12-31 10:55:13,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:13,445 INFO:     Epoch: 42
2022-12-31 10:55:15,047 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4062012255191803, 'Total loss': 0.4062012255191803} | train loss {'Reaction outcome loss': 0.28287107667063166, 'Total loss': 0.28287107667063166}
2022-12-31 10:55:15,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:15,047 INFO:     Epoch: 43
2022-12-31 10:55:16,619 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4164835085471471, 'Total loss': 0.4164835085471471} | train loss {'Reaction outcome loss': 0.28166649245867764, 'Total loss': 0.28166649245867764}
2022-12-31 10:55:16,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:16,619 INFO:     Epoch: 44
2022-12-31 10:55:17,903 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.38380254109700523, 'Total loss': 0.38380254109700523} | train loss {'Reaction outcome loss': 0.2821401304082714, 'Total loss': 0.2821401304082714}
2022-12-31 10:55:17,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:17,903 INFO:     Epoch: 45
2022-12-31 10:55:18,968 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.38605883916219075, 'Total loss': 0.38605883916219075} | train loss {'Reaction outcome loss': 0.27555370043936, 'Total loss': 0.27555370043936}
2022-12-31 10:55:18,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:18,968 INFO:     Epoch: 46
2022-12-31 10:55:20,024 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3799476306885481, 'Total loss': 0.3799476306885481} | train loss {'Reaction outcome loss': 0.2726306852741833, 'Total loss': 0.2726306852741833}
2022-12-31 10:55:20,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:20,024 INFO:     Epoch: 47
2022-12-31 10:55:21,080 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3927988767623901, 'Total loss': 0.3927988767623901} | train loss {'Reaction outcome loss': 0.277564463620312, 'Total loss': 0.277564463620312}
2022-12-31 10:55:21,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:21,081 INFO:     Epoch: 48
2022-12-31 10:55:22,342 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40036675284306206, 'Total loss': 0.40036675284306206} | train loss {'Reaction outcome loss': 0.2707876452673091, 'Total loss': 0.2707876452673091}
2022-12-31 10:55:22,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:22,342 INFO:     Epoch: 49
2022-12-31 10:55:23,915 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.35713673730691275, 'Total loss': 0.35713673730691275} | train loss {'Reaction outcome loss': 0.2706646248018437, 'Total loss': 0.2706646248018437}
2022-12-31 10:55:23,915 INFO:     Found new best model at epoch 49
2022-12-31 10:55:23,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:23,916 INFO:     Epoch: 50
2022-12-31 10:55:25,512 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4031405617793401, 'Total loss': 0.4031405617793401} | train loss {'Reaction outcome loss': 0.2639906986813693, 'Total loss': 0.2639906986813693}
2022-12-31 10:55:25,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:25,513 INFO:     Epoch: 51
2022-12-31 10:55:27,110 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3846083074808121, 'Total loss': 0.3846083074808121} | train loss {'Reaction outcome loss': 0.26097053060321695, 'Total loss': 0.26097053060321695}
2022-12-31 10:55:27,111 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:27,111 INFO:     Epoch: 52
2022-12-31 10:55:28,712 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3931179871161779, 'Total loss': 0.3931179871161779} | train loss {'Reaction outcome loss': 0.26565285400915756, 'Total loss': 0.26565285400915756}
2022-12-31 10:55:28,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:28,712 INFO:     Epoch: 53
2022-12-31 10:55:30,321 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.40723486940066017, 'Total loss': 0.40723486940066017} | train loss {'Reaction outcome loss': 0.259282448464991, 'Total loss': 0.259282448464991}
2022-12-31 10:55:30,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:30,321 INFO:     Epoch: 54
2022-12-31 10:55:31,907 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40381104648113253, 'Total loss': 0.40381104648113253} | train loss {'Reaction outcome loss': 0.2499485380852418, 'Total loss': 0.2499485380852418}
2022-12-31 10:55:31,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:31,907 INFO:     Epoch: 55
2022-12-31 10:55:33,557 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40458371490240097, 'Total loss': 0.40458371490240097} | train loss {'Reaction outcome loss': 0.25346439768199935, 'Total loss': 0.25346439768199935}
2022-12-31 10:55:33,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:33,558 INFO:     Epoch: 56
2022-12-31 10:55:35,209 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4123131692409515, 'Total loss': 0.4123131692409515} | train loss {'Reaction outcome loss': 0.25284974411619404, 'Total loss': 0.25284974411619404}
2022-12-31 10:55:35,209 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:35,209 INFO:     Epoch: 57
2022-12-31 10:55:36,861 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3888510356346766, 'Total loss': 0.3888510356346766} | train loss {'Reaction outcome loss': 0.2616306822475073, 'Total loss': 0.2616306822475073}
2022-12-31 10:55:36,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:36,862 INFO:     Epoch: 58
2022-12-31 10:55:38,444 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41373629371325177, 'Total loss': 0.41373629371325177} | train loss {'Reaction outcome loss': 0.25090941416956214, 'Total loss': 0.25090941416956214}
2022-12-31 10:55:38,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:38,444 INFO:     Epoch: 59
2022-12-31 10:55:40,049 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42851496040821074, 'Total loss': 0.42851496040821074} | train loss {'Reaction outcome loss': 0.2498425958460591, 'Total loss': 0.2498425958460591}
2022-12-31 10:55:40,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:40,050 INFO:     Epoch: 60
2022-12-31 10:55:41,635 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40461459855238596, 'Total loss': 0.40461459855238596} | train loss {'Reaction outcome loss': 0.24634536583126135, 'Total loss': 0.24634536583126135}
2022-12-31 10:55:41,635 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:41,635 INFO:     Epoch: 61
2022-12-31 10:55:43,231 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4129415233929952, 'Total loss': 0.4129415233929952} | train loss {'Reaction outcome loss': 0.24175933796069482, 'Total loss': 0.24175933796069482}
2022-12-31 10:55:43,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:43,231 INFO:     Epoch: 62
2022-12-31 10:55:44,829 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40475607812404635, 'Total loss': 0.40475607812404635} | train loss {'Reaction outcome loss': 0.23904969094552264, 'Total loss': 0.23904969094552264}
2022-12-31 10:55:44,829 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:44,829 INFO:     Epoch: 63
2022-12-31 10:55:46,431 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4167655939857165, 'Total loss': 0.4167655939857165} | train loss {'Reaction outcome loss': 0.24553850545364359, 'Total loss': 0.24553850545364359}
2022-12-31 10:55:46,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:46,431 INFO:     Epoch: 64
2022-12-31 10:55:48,039 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3877061833937963, 'Total loss': 0.3877061833937963} | train loss {'Reaction outcome loss': 0.2474116006403835, 'Total loss': 0.2474116006403835}
2022-12-31 10:55:48,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:48,040 INFO:     Epoch: 65
2022-12-31 10:55:49,623 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41704241931438446, 'Total loss': 0.41704241931438446} | train loss {'Reaction outcome loss': 0.23680931626118884, 'Total loss': 0.23680931626118884}
2022-12-31 10:55:49,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:49,623 INFO:     Epoch: 66
2022-12-31 10:55:51,217 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40313606162865956, 'Total loss': 0.40313606162865956} | train loss {'Reaction outcome loss': 0.23674232589529595, 'Total loss': 0.23674232589529595}
2022-12-31 10:55:51,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:51,218 INFO:     Epoch: 67
2022-12-31 10:55:52,820 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41171921193599703, 'Total loss': 0.41171921193599703} | train loss {'Reaction outcome loss': 0.23651424224359274, 'Total loss': 0.23651424224359274}
2022-12-31 10:55:52,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:52,820 INFO:     Epoch: 68
2022-12-31 10:55:54,422 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3730859895547231, 'Total loss': 0.3730859895547231} | train loss {'Reaction outcome loss': 0.23216683414159683, 'Total loss': 0.23216683414159683}
2022-12-31 10:55:54,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:54,422 INFO:     Epoch: 69
2022-12-31 10:55:56,025 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40357908805211384, 'Total loss': 0.40357908805211384} | train loss {'Reaction outcome loss': 0.23612309646976254, 'Total loss': 0.23612309646976254}
2022-12-31 10:55:56,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:56,025 INFO:     Epoch: 70
2022-12-31 10:55:57,628 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41912662188212074, 'Total loss': 0.41912662188212074} | train loss {'Reaction outcome loss': 0.23488152176685576, 'Total loss': 0.23488152176685576}
2022-12-31 10:55:57,628 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:57,628 INFO:     Epoch: 71
2022-12-31 10:55:59,199 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42489360670248666, 'Total loss': 0.42489360670248666} | train loss {'Reaction outcome loss': 0.22692556340709655, 'Total loss': 0.22692556340709655}
2022-12-31 10:55:59,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:55:59,199 INFO:     Epoch: 72
2022-12-31 10:56:00,807 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4038902123769124, 'Total loss': 0.4038902123769124} | train loss {'Reaction outcome loss': 0.23403659413983352, 'Total loss': 0.23403659413983352}
2022-12-31 10:56:00,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:00,808 INFO:     Epoch: 73
2022-12-31 10:56:02,412 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4519140154123306, 'Total loss': 0.4519140154123306} | train loss {'Reaction outcome loss': 0.22752764591280997, 'Total loss': 0.22752764591280997}
2022-12-31 10:56:02,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:02,412 INFO:     Epoch: 74
2022-12-31 10:56:04,017 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.38943361937999726, 'Total loss': 0.38943361937999726} | train loss {'Reaction outcome loss': 0.224387730696123, 'Total loss': 0.224387730696123}
2022-12-31 10:56:04,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:04,017 INFO:     Epoch: 75
2022-12-31 10:56:05,621 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41751077473163606, 'Total loss': 0.41751077473163606} | train loss {'Reaction outcome loss': 0.22385412152775014, 'Total loss': 0.22385412152775014}
2022-12-31 10:56:05,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:05,622 INFO:     Epoch: 76
2022-12-31 10:56:07,204 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4124785512685776, 'Total loss': 0.4124785512685776} | train loss {'Reaction outcome loss': 0.22609606989231096, 'Total loss': 0.22609606989231096}
2022-12-31 10:56:07,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:07,204 INFO:     Epoch: 77
2022-12-31 10:56:08,804 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4104971925417582, 'Total loss': 0.4104971925417582} | train loss {'Reaction outcome loss': 0.2265713779242152, 'Total loss': 0.2265713779242152}
2022-12-31 10:56:08,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:08,804 INFO:     Epoch: 78
2022-12-31 10:56:10,411 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.38251346796751023, 'Total loss': 0.38251346796751023} | train loss {'Reaction outcome loss': 0.21958912016456797, 'Total loss': 0.21958912016456797}
2022-12-31 10:56:10,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:10,412 INFO:     Epoch: 79
2022-12-31 10:56:12,024 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42205047408739726, 'Total loss': 0.42205047408739726} | train loss {'Reaction outcome loss': 0.22431440557604723, 'Total loss': 0.22431440557604723}
2022-12-31 10:56:12,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:12,024 INFO:     Epoch: 80
2022-12-31 10:56:13,660 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40023214717706046, 'Total loss': 0.40023214717706046} | train loss {'Reaction outcome loss': 0.22342389174839006, 'Total loss': 0.22342389174839006}
2022-12-31 10:56:13,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:13,661 INFO:     Epoch: 81
2022-12-31 10:56:15,303 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3851277301708857, 'Total loss': 0.3851277301708857} | train loss {'Reaction outcome loss': 0.2191873058323225, 'Total loss': 0.2191873058323225}
2022-12-31 10:56:15,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:15,303 INFO:     Epoch: 82
2022-12-31 10:56:16,905 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3956448569893837, 'Total loss': 0.3956448569893837} | train loss {'Reaction outcome loss': 0.21937344539366718, 'Total loss': 0.21937344539366718}
2022-12-31 10:56:16,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:16,905 INFO:     Epoch: 83
2022-12-31 10:56:18,508 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3849888801574707, 'Total loss': 0.3849888801574707} | train loss {'Reaction outcome loss': 0.21464523952794226, 'Total loss': 0.21464523952794226}
2022-12-31 10:56:18,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:18,508 INFO:     Epoch: 84
2022-12-31 10:56:20,104 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4165079027414322, 'Total loss': 0.4165079027414322} | train loss {'Reaction outcome loss': 0.21410164896425973, 'Total loss': 0.21410164896425973}
2022-12-31 10:56:20,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:20,104 INFO:     Epoch: 85
2022-12-31 10:56:21,701 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.37594426174958545, 'Total loss': 0.37594426174958545} | train loss {'Reaction outcome loss': 0.22793306681551856, 'Total loss': 0.22793306681551856}
2022-12-31 10:56:21,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:21,702 INFO:     Epoch: 86
2022-12-31 10:56:23,296 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42024429043134054, 'Total loss': 0.42024429043134054} | train loss {'Reaction outcome loss': 0.21016136081005535, 'Total loss': 0.21016136081005535}
2022-12-31 10:56:23,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:23,297 INFO:     Epoch: 87
2022-12-31 10:56:24,895 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.393874258796374, 'Total loss': 0.393874258796374} | train loss {'Reaction outcome loss': 0.2128230206410054, 'Total loss': 0.2128230206410054}
2022-12-31 10:56:24,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:24,895 INFO:     Epoch: 88
2022-12-31 10:56:26,456 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42000338236490886, 'Total loss': 0.42000338236490886} | train loss {'Reaction outcome loss': 0.20746495177711013, 'Total loss': 0.20746495177711013}
2022-12-31 10:56:26,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:26,456 INFO:     Epoch: 89
2022-12-31 10:56:28,050 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39910224874814354, 'Total loss': 0.39910224874814354} | train loss {'Reaction outcome loss': 0.21018193686639305, 'Total loss': 0.21018193686639305}
2022-12-31 10:56:28,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:28,051 INFO:     Epoch: 90
2022-12-31 10:56:29,645 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4498004208008448, 'Total loss': 0.4498004208008448} | train loss {'Reaction outcome loss': 0.2080665266780305, 'Total loss': 0.2080665266780305}
2022-12-31 10:56:29,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:29,646 INFO:     Epoch: 91
2022-12-31 10:56:31,243 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.40604111353556316, 'Total loss': 0.40604111353556316} | train loss {'Reaction outcome loss': 0.20600705547598155, 'Total loss': 0.20600705547598155}
2022-12-31 10:56:31,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:31,243 INFO:     Epoch: 92
2022-12-31 10:56:32,839 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41387028296788536, 'Total loss': 0.41387028296788536} | train loss {'Reaction outcome loss': 0.20321330941370586, 'Total loss': 0.20321330941370586}
2022-12-31 10:56:32,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:32,839 INFO:     Epoch: 93
2022-12-31 10:56:34,420 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.37518221934636437, 'Total loss': 0.37518221934636437} | train loss {'Reaction outcome loss': 0.20755233120744246, 'Total loss': 0.20755233120744246}
2022-12-31 10:56:34,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:34,421 INFO:     Epoch: 94
2022-12-31 10:56:36,010 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38376120875279107, 'Total loss': 0.38376120875279107} | train loss {'Reaction outcome loss': 0.2024332536180524, 'Total loss': 0.2024332536180524}
2022-12-31 10:56:36,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:36,010 INFO:     Epoch: 95
2022-12-31 10:56:37,608 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4043744032581647, 'Total loss': 0.4043744032581647} | train loss {'Reaction outcome loss': 0.19503593690231116, 'Total loss': 0.19503593690231116}
2022-12-31 10:56:37,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:37,608 INFO:     Epoch: 96
2022-12-31 10:56:39,221 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40309603959321977, 'Total loss': 0.40309603959321977} | train loss {'Reaction outcome loss': 0.19786395060483122, 'Total loss': 0.19786395060483122}
2022-12-31 10:56:39,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:39,221 INFO:     Epoch: 97
2022-12-31 10:56:40,818 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.402523464212815, 'Total loss': 0.402523464212815} | train loss {'Reaction outcome loss': 0.20691428488514718, 'Total loss': 0.20691428488514718}
2022-12-31 10:56:40,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:40,818 INFO:     Epoch: 98
2022-12-31 10:56:42,416 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.37781051695346834, 'Total loss': 0.37781051695346834} | train loss {'Reaction outcome loss': 0.2019473985993188, 'Total loss': 0.2019473985993188}
2022-12-31 10:56:42,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:42,417 INFO:     Epoch: 99
2022-12-31 10:56:44,009 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3873125950495402, 'Total loss': 0.3873125950495402} | train loss {'Reaction outcome loss': 0.204152436641446, 'Total loss': 0.204152436641446}
2022-12-31 10:56:44,009 INFO:     Best model found after epoch 50 of 100.
2022-12-31 10:56:44,009 INFO:   Done with stage: TRAINING
2022-12-31 10:56:44,009 INFO:   Starting stage: EVALUATION
2022-12-31 10:56:44,141 INFO:   Done with stage: EVALUATION
2022-12-31 10:56:44,141 INFO:   Leaving out SEQ value Fold_2
2022-12-31 10:56:44,154 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 10:56:44,154 INFO:   Starting stage: FEATURE SCALING
2022-12-31 10:56:44,800 INFO:   Done with stage: FEATURE SCALING
2022-12-31 10:56:44,800 INFO:   Starting stage: SCALING TARGETS
2022-12-31 10:56:44,869 INFO:   Done with stage: SCALING TARGETS
2022-12-31 10:56:44,869 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:56:44,869 INFO:     No hyperparam tuning for this model
2022-12-31 10:56:44,869 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:56:44,869 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 10:56:44,870 INFO:     None feature selector for col prot
2022-12-31 10:56:44,870 INFO:     None feature selector for col prot
2022-12-31 10:56:44,870 INFO:     None feature selector for col prot
2022-12-31 10:56:44,870 INFO:     None feature selector for col chem
2022-12-31 10:56:44,871 INFO:     None feature selector for col chem
2022-12-31 10:56:44,871 INFO:     None feature selector for col chem
2022-12-31 10:56:44,871 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 10:56:44,871 INFO:   Starting stage: BUILD MODEL
2022-12-31 10:56:44,872 INFO:     Number of params in model 223921
2022-12-31 10:56:44,876 INFO:   Done with stage: BUILD MODEL
2022-12-31 10:56:44,876 INFO:   Starting stage: TRAINING
2022-12-31 10:56:44,921 INFO:     Val loss before train {'Reaction outcome loss': 0.938801908493042, 'Total loss': 0.938801908493042}
2022-12-31 10:56:44,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:44,921 INFO:     Epoch: 0
2022-12-31 10:56:46,567 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6552303632100424, 'Total loss': 0.6552303632100424} | train loss {'Reaction outcome loss': 0.8151090444888973, 'Total loss': 0.8151090444888973}
2022-12-31 10:56:46,567 INFO:     Found new best model at epoch 0
2022-12-31 10:56:46,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:46,568 INFO:     Epoch: 1
2022-12-31 10:56:48,173 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5193994522094727, 'Total loss': 0.5193994522094727} | train loss {'Reaction outcome loss': 0.6071641213544037, 'Total loss': 0.6071641213544037}
2022-12-31 10:56:48,173 INFO:     Found new best model at epoch 1
2022-12-31 10:56:48,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:48,174 INFO:     Epoch: 2
2022-12-31 10:56:49,777 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4952832798163096, 'Total loss': 0.4952832798163096} | train loss {'Reaction outcome loss': 0.5360375594278541, 'Total loss': 0.5360375594278541}
2022-12-31 10:56:49,777 INFO:     Found new best model at epoch 2
2022-12-31 10:56:49,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:49,778 INFO:     Epoch: 3
2022-12-31 10:56:51,384 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48615590333938596, 'Total loss': 0.48615590333938596} | train loss {'Reaction outcome loss': 0.5076464368435352, 'Total loss': 0.5076464368435352}
2022-12-31 10:56:51,384 INFO:     Found new best model at epoch 3
2022-12-31 10:56:51,385 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:51,385 INFO:     Epoch: 4
2022-12-31 10:56:52,953 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.526057646671931, 'Total loss': 0.526057646671931} | train loss {'Reaction outcome loss': 0.49235263076759334, 'Total loss': 0.49235263076759334}
2022-12-31 10:56:52,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:52,954 INFO:     Epoch: 5
2022-12-31 10:56:54,568 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4888829787572225, 'Total loss': 0.4888829787572225} | train loss {'Reaction outcome loss': 0.47904804088951397, 'Total loss': 0.47904804088951397}
2022-12-31 10:56:54,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:54,569 INFO:     Epoch: 6
2022-12-31 10:56:56,179 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.45540674130121866, 'Total loss': 0.45540674130121866} | train loss {'Reaction outcome loss': 0.47495788537755446, 'Total loss': 0.47495788537755446}
2022-12-31 10:56:56,180 INFO:     Found new best model at epoch 6
2022-12-31 10:56:56,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:56,180 INFO:     Epoch: 7
2022-12-31 10:56:57,792 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4571529765923818, 'Total loss': 0.4571529765923818} | train loss {'Reaction outcome loss': 0.46327927560913307, 'Total loss': 0.46327927560913307}
2022-12-31 10:56:57,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:57,793 INFO:     Epoch: 8
2022-12-31 10:56:59,403 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47843942046165466, 'Total loss': 0.47843942046165466} | train loss {'Reaction outcome loss': 0.46069379178199754, 'Total loss': 0.46069379178199754}
2022-12-31 10:56:59,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:56:59,404 INFO:     Epoch: 9
2022-12-31 10:57:01,002 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4953457057476044, 'Total loss': 0.4953457057476044} | train loss {'Reaction outcome loss': 0.4495610591240119, 'Total loss': 0.4495610591240119}
2022-12-31 10:57:01,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:01,002 INFO:     Epoch: 10
2022-12-31 10:57:02,616 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47385849555333454, 'Total loss': 0.47385849555333454} | train loss {'Reaction outcome loss': 0.44322145447485906, 'Total loss': 0.44322145447485906}
2022-12-31 10:57:02,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:02,617 INFO:     Epoch: 11
2022-12-31 10:57:04,230 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4218797629078229, 'Total loss': 0.4218797629078229} | train loss {'Reaction outcome loss': 0.43601331350046035, 'Total loss': 0.43601331350046035}
2022-12-31 10:57:04,230 INFO:     Found new best model at epoch 11
2022-12-31 10:57:04,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:04,231 INFO:     Epoch: 12
2022-12-31 10:57:05,841 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4402643213669459, 'Total loss': 0.4402643213669459} | train loss {'Reaction outcome loss': 0.4358601790027946, 'Total loss': 0.4358601790027946}
2022-12-31 10:57:05,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:05,841 INFO:     Epoch: 13
2022-12-31 10:57:07,449 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5061387519041697, 'Total loss': 0.5061387519041697} | train loss {'Reaction outcome loss': 0.42502154338644293, 'Total loss': 0.42502154338644293}
2022-12-31 10:57:07,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:07,449 INFO:     Epoch: 14
2022-12-31 10:57:09,058 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45652371644973755, 'Total loss': 0.45652371644973755} | train loss {'Reaction outcome loss': 0.42072781823588995, 'Total loss': 0.42072781823588995}
2022-12-31 10:57:09,058 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:09,058 INFO:     Epoch: 15
2022-12-31 10:57:10,646 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46236865321795145, 'Total loss': 0.46236865321795145} | train loss {'Reaction outcome loss': 0.4138003552629464, 'Total loss': 0.4138003552629464}
2022-12-31 10:57:10,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:10,647 INFO:     Epoch: 16
2022-12-31 10:57:12,238 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4305123329162598, 'Total loss': 0.4305123329162598} | train loss {'Reaction outcome loss': 0.4166913756360874, 'Total loss': 0.4166913756360874}
2022-12-31 10:57:12,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:12,238 INFO:     Epoch: 17
2022-12-31 10:57:13,848 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42828440070152285, 'Total loss': 0.42828440070152285} | train loss {'Reaction outcome loss': 0.40245836107794236, 'Total loss': 0.40245836107794236}
2022-12-31 10:57:13,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:13,848 INFO:     Epoch: 18
2022-12-31 10:57:15,463 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4462649583816528, 'Total loss': 0.4462649583816528} | train loss {'Reaction outcome loss': 0.401526471529075, 'Total loss': 0.401526471529075}
2022-12-31 10:57:15,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:15,463 INFO:     Epoch: 19
2022-12-31 10:57:17,068 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4412769754727682, 'Total loss': 0.4412769754727682} | train loss {'Reaction outcome loss': 0.3875846285769459, 'Total loss': 0.3875846285769459}
2022-12-31 10:57:17,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:17,069 INFO:     Epoch: 20
2022-12-31 10:57:18,675 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4260394245386124, 'Total loss': 0.4260394245386124} | train loss {'Reaction outcome loss': 0.3882588764983297, 'Total loss': 0.3882588764983297}
2022-12-31 10:57:18,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:18,675 INFO:     Epoch: 21
2022-12-31 10:57:20,275 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4169872462749481, 'Total loss': 0.4169872462749481} | train loss {'Reaction outcome loss': 0.38308097054992896, 'Total loss': 0.38308097054992896}
2022-12-31 10:57:20,275 INFO:     Found new best model at epoch 21
2022-12-31 10:57:20,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:20,276 INFO:     Epoch: 22
2022-12-31 10:57:21,898 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4388796309630076, 'Total loss': 0.4388796309630076} | train loss {'Reaction outcome loss': 0.38235511206516676, 'Total loss': 0.38235511206516676}
2022-12-31 10:57:21,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:21,898 INFO:     Epoch: 23
2022-12-31 10:57:23,525 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45701003074645996, 'Total loss': 0.45701003074645996} | train loss {'Reaction outcome loss': 0.36691674347157066, 'Total loss': 0.36691674347157066}
2022-12-31 10:57:23,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:23,525 INFO:     Epoch: 24
2022-12-31 10:57:25,139 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43766678074995674, 'Total loss': 0.43766678074995674} | train loss {'Reaction outcome loss': 0.3611368041323579, 'Total loss': 0.3611368041323579}
2022-12-31 10:57:25,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:25,140 INFO:     Epoch: 25
2022-12-31 10:57:26,747 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4475938638051351, 'Total loss': 0.4475938638051351} | train loss {'Reaction outcome loss': 0.36065566539764404, 'Total loss': 0.36065566539764404}
2022-12-31 10:57:26,747 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:26,747 INFO:     Epoch: 26
2022-12-31 10:57:28,346 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4639284511407216, 'Total loss': 0.4639284511407216} | train loss {'Reaction outcome loss': 0.3906851599863528, 'Total loss': 0.3906851599863528}
2022-12-31 10:57:28,347 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:28,347 INFO:     Epoch: 27
2022-12-31 10:57:29,947 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4514906485875448, 'Total loss': 0.4514906485875448} | train loss {'Reaction outcome loss': 0.3584284353499348, 'Total loss': 0.3584284353499348}
2022-12-31 10:57:29,947 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:29,947 INFO:     Epoch: 28
2022-12-31 10:57:31,552 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41189124584198, 'Total loss': 0.41189124584198} | train loss {'Reaction outcome loss': 0.34304603550961055, 'Total loss': 0.34304603550961055}
2022-12-31 10:57:31,552 INFO:     Found new best model at epoch 28
2022-12-31 10:57:31,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:31,553 INFO:     Epoch: 29
2022-12-31 10:57:33,204 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43815365036328635, 'Total loss': 0.43815365036328635} | train loss {'Reaction outcome loss': 0.3401024120993089, 'Total loss': 0.3401024120993089}
2022-12-31 10:57:33,204 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:33,204 INFO:     Epoch: 30
2022-12-31 10:57:34,844 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40503598352273307, 'Total loss': 0.40503598352273307} | train loss {'Reaction outcome loss': 0.33559588988184286, 'Total loss': 0.33559588988184286}
2022-12-31 10:57:34,844 INFO:     Found new best model at epoch 30
2022-12-31 10:57:34,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:34,845 INFO:     Epoch: 31
2022-12-31 10:57:36,459 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42351877093315127, 'Total loss': 0.42351877093315127} | train loss {'Reaction outcome loss': 0.3352714878008727, 'Total loss': 0.3352714878008727}
2022-12-31 10:57:36,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:36,459 INFO:     Epoch: 32
2022-12-31 10:57:38,051 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4224656860033671, 'Total loss': 0.4224656860033671} | train loss {'Reaction outcome loss': 0.3276913832701014, 'Total loss': 0.3276913832701014}
2022-12-31 10:57:38,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:38,051 INFO:     Epoch: 33
2022-12-31 10:57:39,654 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.39935968120892845, 'Total loss': 0.39935968120892845} | train loss {'Reaction outcome loss': 0.3215120415839076, 'Total loss': 0.3215120415839076}
2022-12-31 10:57:39,654 INFO:     Found new best model at epoch 33
2022-12-31 10:57:39,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:39,655 INFO:     Epoch: 34
2022-12-31 10:57:41,261 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4282889460523923, 'Total loss': 0.4282889460523923} | train loss {'Reaction outcome loss': 0.32174362390693545, 'Total loss': 0.32174362390693545}
2022-12-31 10:57:41,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:41,261 INFO:     Epoch: 35
2022-12-31 10:57:42,867 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42552057405312854, 'Total loss': 0.42552057405312854} | train loss {'Reaction outcome loss': 0.3210381237870973, 'Total loss': 0.3210381237870973}
2022-12-31 10:57:42,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:42,867 INFO:     Epoch: 36
2022-12-31 10:57:44,474 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43590001910924914, 'Total loss': 0.43590001910924914} | train loss {'Reaction outcome loss': 0.31233944251215545, 'Total loss': 0.31233944251215545}
2022-12-31 10:57:44,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:44,474 INFO:     Epoch: 37
2022-12-31 10:57:46,066 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43062080840269723, 'Total loss': 0.43062080840269723} | train loss {'Reaction outcome loss': 0.33577783627138624, 'Total loss': 0.33577783627138624}
2022-12-31 10:57:46,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:46,066 INFO:     Epoch: 38
2022-12-31 10:57:47,676 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.431013626853625, 'Total loss': 0.431013626853625} | train loss {'Reaction outcome loss': 0.343341457090624, 'Total loss': 0.343341457090624}
2022-12-31 10:57:47,677 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:47,677 INFO:     Epoch: 39
2022-12-31 10:57:49,283 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.41932896176973977, 'Total loss': 0.41932896176973977} | train loss {'Reaction outcome loss': 0.3108012710387508, 'Total loss': 0.3108012710387508}
2022-12-31 10:57:49,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:49,283 INFO:     Epoch: 40
2022-12-31 10:57:50,889 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44018650650978086, 'Total loss': 0.44018650650978086} | train loss {'Reaction outcome loss': 0.30456825385909475, 'Total loss': 0.30456825385909475}
2022-12-31 10:57:50,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:50,889 INFO:     Epoch: 41
2022-12-31 10:57:52,498 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4438279181718826, 'Total loss': 0.4438279181718826} | train loss {'Reaction outcome loss': 0.30580337214211095, 'Total loss': 0.30580337214211095}
2022-12-31 10:57:52,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:52,498 INFO:     Epoch: 42
2022-12-31 10:57:54,106 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4045917217930158, 'Total loss': 0.4045917217930158} | train loss {'Reaction outcome loss': 0.3000975335404898, 'Total loss': 0.3000975335404898}
2022-12-31 10:57:54,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:54,106 INFO:     Epoch: 43
2022-12-31 10:57:55,700 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43401140371958413, 'Total loss': 0.43401140371958413} | train loss {'Reaction outcome loss': 0.29738059811348067, 'Total loss': 0.29738059811348067}
2022-12-31 10:57:55,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:55,701 INFO:     Epoch: 44
2022-12-31 10:57:57,297 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44776214758555094, 'Total loss': 0.44776214758555094} | train loss {'Reaction outcome loss': 0.2854532743821029, 'Total loss': 0.2854532743821029}
2022-12-31 10:57:57,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:57,297 INFO:     Epoch: 45
2022-12-31 10:57:58,903 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4206573814153671, 'Total loss': 0.4206573814153671} | train loss {'Reaction outcome loss': 0.2924573620039946, 'Total loss': 0.2924573620039946}
2022-12-31 10:57:58,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:57:58,903 INFO:     Epoch: 46
2022-12-31 10:58:00,509 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.464150936404864, 'Total loss': 0.464150936404864} | train loss {'Reaction outcome loss': 0.28575186853877443, 'Total loss': 0.28575186853877443}
2022-12-31 10:58:00,509 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:00,510 INFO:     Epoch: 47
2022-12-31 10:58:02,117 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4148969779411952, 'Total loss': 0.4148969779411952} | train loss {'Reaction outcome loss': 0.2843220333494516, 'Total loss': 0.2843220333494516}
2022-12-31 10:58:02,117 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:02,117 INFO:     Epoch: 48
2022-12-31 10:58:03,720 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44050941069920857, 'Total loss': 0.44050941069920857} | train loss {'Reaction outcome loss': 0.28093277936318045, 'Total loss': 0.28093277936318045}
2022-12-31 10:58:03,720 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:03,720 INFO:     Epoch: 49
2022-12-31 10:58:05,295 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4415702571471532, 'Total loss': 0.4415702571471532} | train loss {'Reaction outcome loss': 0.27949460760008654, 'Total loss': 0.27949460760008654}
2022-12-31 10:58:05,296 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:05,296 INFO:     Epoch: 50
2022-12-31 10:58:06,902 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39126489609479903, 'Total loss': 0.39126489609479903} | train loss {'Reaction outcome loss': 0.27557500090493914, 'Total loss': 0.27557500090493914}
2022-12-31 10:58:06,903 INFO:     Found new best model at epoch 50
2022-12-31 10:58:06,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:06,904 INFO:     Epoch: 51
2022-12-31 10:58:08,510 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4207090616226196, 'Total loss': 0.4207090616226196} | train loss {'Reaction outcome loss': 0.29560475448227447, 'Total loss': 0.29560475448227447}
2022-12-31 10:58:08,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:08,510 INFO:     Epoch: 52
2022-12-31 10:58:10,118 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42936504681905113, 'Total loss': 0.42936504681905113} | train loss {'Reaction outcome loss': 0.30546772952420986, 'Total loss': 0.30546772952420986}
2022-12-31 10:58:10,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:10,118 INFO:     Epoch: 53
2022-12-31 10:58:11,726 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44262205362319945, 'Total loss': 0.44262205362319945} | train loss {'Reaction outcome loss': 0.2730417560070645, 'Total loss': 0.2730417560070645}
2022-12-31 10:58:11,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:11,727 INFO:     Epoch: 54
2022-12-31 10:58:13,326 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.43862381180127463, 'Total loss': 0.43862381180127463} | train loss {'Reaction outcome loss': 0.26693155697627674, 'Total loss': 0.26693155697627674}
2022-12-31 10:58:13,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:13,327 INFO:     Epoch: 55
2022-12-31 10:58:14,953 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40232119957606, 'Total loss': 0.40232119957606} | train loss {'Reaction outcome loss': 0.26819290041870164, 'Total loss': 0.26819290041870164}
2022-12-31 10:58:14,953 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:14,953 INFO:     Epoch: 56
2022-12-31 10:58:16,596 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3814849947889646, 'Total loss': 0.3814849947889646} | train loss {'Reaction outcome loss': 0.267083777880728, 'Total loss': 0.267083777880728}
2022-12-31 10:58:16,596 INFO:     Found new best model at epoch 56
2022-12-31 10:58:16,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:16,597 INFO:     Epoch: 57
2022-12-31 10:58:18,266 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4589991599321365, 'Total loss': 0.4589991599321365} | train loss {'Reaction outcome loss': 0.26441402443046885, 'Total loss': 0.26441402443046885}
2022-12-31 10:58:18,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:18,267 INFO:     Epoch: 58
2022-12-31 10:58:19,926 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4453891704479853, 'Total loss': 0.4453891704479853} | train loss {'Reaction outcome loss': 0.2566849775646098, 'Total loss': 0.2566849775646098}
2022-12-31 10:58:19,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:19,926 INFO:     Epoch: 59
2022-12-31 10:58:21,596 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41863561371962227, 'Total loss': 0.41863561371962227} | train loss {'Reaction outcome loss': 0.2737938464497742, 'Total loss': 0.2737938464497742}
2022-12-31 10:58:21,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:21,596 INFO:     Epoch: 60
2022-12-31 10:58:23,214 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4347562869389852, 'Total loss': 0.4347562869389852} | train loss {'Reaction outcome loss': 0.44458484691373695, 'Total loss': 0.44458484691373695}
2022-12-31 10:58:23,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:23,214 INFO:     Epoch: 61
2022-12-31 10:58:24,815 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4292430480321248, 'Total loss': 0.4292430480321248} | train loss {'Reaction outcome loss': 0.30845687235811003, 'Total loss': 0.30845687235811003}
2022-12-31 10:58:24,816 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:24,816 INFO:     Epoch: 62
2022-12-31 10:58:26,426 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47025664150714874, 'Total loss': 0.47025664150714874} | train loss {'Reaction outcome loss': 0.27889298539662705, 'Total loss': 0.27889298539662705}
2022-12-31 10:58:26,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:26,426 INFO:     Epoch: 63
2022-12-31 10:58:28,038 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42150525053342186, 'Total loss': 0.42150525053342186} | train loss {'Reaction outcome loss': 0.2692885397460697, 'Total loss': 0.2692885397460697}
2022-12-31 10:58:28,038 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:28,038 INFO:     Epoch: 64
2022-12-31 10:58:29,648 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4615686664978663, 'Total loss': 0.4615686664978663} | train loss {'Reaction outcome loss': 0.2626008200163926, 'Total loss': 0.2626008200163926}
2022-12-31 10:58:29,648 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:29,648 INFO:     Epoch: 65
2022-12-31 10:58:31,270 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4759518673022588, 'Total loss': 0.4759518673022588} | train loss {'Reaction outcome loss': 0.253784423816335, 'Total loss': 0.253784423816335}
2022-12-31 10:58:31,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:31,270 INFO:     Epoch: 66
2022-12-31 10:58:32,863 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44457493325074515, 'Total loss': 0.44457493325074515} | train loss {'Reaction outcome loss': 0.25637013367984607, 'Total loss': 0.25637013367984607}
2022-12-31 10:58:32,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:32,863 INFO:     Epoch: 67
2022-12-31 10:58:34,476 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.44913540879885355, 'Total loss': 0.44913540879885355} | train loss {'Reaction outcome loss': 0.25781938239199825, 'Total loss': 0.25781938239199825}
2022-12-31 10:58:34,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:34,476 INFO:     Epoch: 68
2022-12-31 10:58:36,114 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4305472066005071, 'Total loss': 0.4305472066005071} | train loss {'Reaction outcome loss': 0.24768676295700748, 'Total loss': 0.24768676295700748}
2022-12-31 10:58:36,114 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:36,114 INFO:     Epoch: 69
2022-12-31 10:58:37,781 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4594778001308441, 'Total loss': 0.4594778001308441} | train loss {'Reaction outcome loss': 0.2530766866925726, 'Total loss': 0.2530766866925726}
2022-12-31 10:58:37,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:37,782 INFO:     Epoch: 70
2022-12-31 10:58:39,452 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.505869788924853, 'Total loss': 0.505869788924853} | train loss {'Reaction outcome loss': 0.24799550591379174, 'Total loss': 0.24799550591379174}
2022-12-31 10:58:39,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:39,452 INFO:     Epoch: 71
2022-12-31 10:58:41,062 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42333592971165973, 'Total loss': 0.42333592971165973} | train loss {'Reaction outcome loss': 0.2461590411899058, 'Total loss': 0.2461590411899058}
2022-12-31 10:58:41,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:41,064 INFO:     Epoch: 72
2022-12-31 10:58:42,690 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4731895675261815, 'Total loss': 0.4731895675261815} | train loss {'Reaction outcome loss': 0.24047279495246493, 'Total loss': 0.24047279495246493}
2022-12-31 10:58:42,690 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:42,690 INFO:     Epoch: 73
2022-12-31 10:58:44,343 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.46287530461947124, 'Total loss': 0.46287530461947124} | train loss {'Reaction outcome loss': 0.23856121800718424, 'Total loss': 0.23856121800718424}
2022-12-31 10:58:44,343 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:44,343 INFO:     Epoch: 74
2022-12-31 10:58:46,016 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45661744475364685, 'Total loss': 0.45661744475364685} | train loss {'Reaction outcome loss': 0.2367724579880419, 'Total loss': 0.2367724579880419}
2022-12-31 10:58:46,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:46,016 INFO:     Epoch: 75
2022-12-31 10:58:47,667 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4742004017035166, 'Total loss': 0.4742004017035166} | train loss {'Reaction outcome loss': 0.23757859329508274, 'Total loss': 0.23757859329508274}
2022-12-31 10:58:47,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:47,668 INFO:     Epoch: 76
2022-12-31 10:58:49,268 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4446531077226003, 'Total loss': 0.4446531077226003} | train loss {'Reaction outcome loss': 0.24225493283449687, 'Total loss': 0.24225493283449687}
2022-12-31 10:58:49,268 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:49,268 INFO:     Epoch: 77
2022-12-31 10:58:50,845 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43815515637397767, 'Total loss': 0.43815515637397767} | train loss {'Reaction outcome loss': 0.23266448327880082, 'Total loss': 0.23266448327880082}
2022-12-31 10:58:50,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:50,845 INFO:     Epoch: 78
2022-12-31 10:58:52,493 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46188260515530905, 'Total loss': 0.46188260515530905} | train loss {'Reaction outcome loss': 0.233264596029809, 'Total loss': 0.233264596029809}
2022-12-31 10:58:52,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:52,493 INFO:     Epoch: 79
2022-12-31 10:58:54,099 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44874005764722824, 'Total loss': 0.44874005764722824} | train loss {'Reaction outcome loss': 0.24178843121415516, 'Total loss': 0.24178843121415516}
2022-12-31 10:58:54,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:54,099 INFO:     Epoch: 80
2022-12-31 10:58:55,704 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42214951713879906, 'Total loss': 0.42214951713879906} | train loss {'Reaction outcome loss': 0.2370268393550878, 'Total loss': 0.2370268393550878}
2022-12-31 10:58:55,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:55,704 INFO:     Epoch: 81
2022-12-31 10:58:57,310 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44856730898221336, 'Total loss': 0.44856730898221336} | train loss {'Reaction outcome loss': 0.2522149117202903, 'Total loss': 0.2522149117202903}
2022-12-31 10:58:57,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:57,310 INFO:     Epoch: 82
2022-12-31 10:58:58,902 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.5132255017757416, 'Total loss': 0.5132255017757416} | train loss {'Reaction outcome loss': 0.23339036880465952, 'Total loss': 0.23339036880465952}
2022-12-31 10:58:58,902 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:58:58,902 INFO:     Epoch: 83
2022-12-31 10:59:00,492 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4509173432985942, 'Total loss': 0.4509173432985942} | train loss {'Reaction outcome loss': 0.3051608961967218, 'Total loss': 0.3051608961967218}
2022-12-31 10:59:00,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:00,493 INFO:     Epoch: 84
2022-12-31 10:59:02,099 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4452783991893133, 'Total loss': 0.4452783991893133} | train loss {'Reaction outcome loss': 0.24186048548047742, 'Total loss': 0.24186048548047742}
2022-12-31 10:59:02,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:02,099 INFO:     Epoch: 85
2022-12-31 10:59:03,706 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4712502340475718, 'Total loss': 0.4712502340475718} | train loss {'Reaction outcome loss': 0.2248150030133294, 'Total loss': 0.2248150030133294}
2022-12-31 10:59:03,706 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:03,706 INFO:     Epoch: 86
2022-12-31 10:59:05,313 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4656022697687149, 'Total loss': 0.4656022697687149} | train loss {'Reaction outcome loss': 0.22403891670262016, 'Total loss': 0.22403891670262016}
2022-12-31 10:59:05,314 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:05,314 INFO:     Epoch: 87
2022-12-31 10:59:06,920 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.495338703195254, 'Total loss': 0.495338703195254} | train loss {'Reaction outcome loss': 0.22497459166524808, 'Total loss': 0.22497459166524808}
2022-12-31 10:59:06,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:06,920 INFO:     Epoch: 88
2022-12-31 10:59:08,536 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46920080184936525, 'Total loss': 0.46920080184936525} | train loss {'Reaction outcome loss': 0.22413741998657907, 'Total loss': 0.22413741998657907}
2022-12-31 10:59:08,536 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:08,536 INFO:     Epoch: 89
2022-12-31 10:59:10,127 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.45341741740703584, 'Total loss': 0.45341741740703584} | train loss {'Reaction outcome loss': 0.22069500232169378, 'Total loss': 0.22069500232169378}
2022-12-31 10:59:10,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:10,127 INFO:     Epoch: 90
2022-12-31 10:59:11,734 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4230573316415151, 'Total loss': 0.4230573316415151} | train loss {'Reaction outcome loss': 0.22260715395205424, 'Total loss': 0.22260715395205424}
2022-12-31 10:59:11,734 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:11,734 INFO:     Epoch: 91
2022-12-31 10:59:13,338 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.445553328593572, 'Total loss': 0.445553328593572} | train loss {'Reaction outcome loss': 0.21767836921186984, 'Total loss': 0.21767836921186984}
2022-12-31 10:59:13,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:13,338 INFO:     Epoch: 92
2022-12-31 10:59:14,945 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.46461041768391925, 'Total loss': 0.46461041768391925} | train loss {'Reaction outcome loss': 0.22550512397551295, 'Total loss': 0.22550512397551295}
2022-12-31 10:59:14,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:14,946 INFO:     Epoch: 93
2022-12-31 10:59:16,538 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45901234249273937, 'Total loss': 0.45901234249273937} | train loss {'Reaction outcome loss': 0.21551716055356615, 'Total loss': 0.21551716055356615}
2022-12-31 10:59:16,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:16,539 INFO:     Epoch: 94
2022-12-31 10:59:18,131 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4282301917672157, 'Total loss': 0.4282301917672157} | train loss {'Reaction outcome loss': 0.21458792855770772, 'Total loss': 0.21458792855770772}
2022-12-31 10:59:18,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:18,131 INFO:     Epoch: 95
2022-12-31 10:59:19,760 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4577655871709188, 'Total loss': 0.4577655871709188} | train loss {'Reaction outcome loss': 0.21332242382788166, 'Total loss': 0.21332242382788166}
2022-12-31 10:59:19,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:19,760 INFO:     Epoch: 96
2022-12-31 10:59:21,375 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45830888152122495, 'Total loss': 0.45830888152122495} | train loss {'Reaction outcome loss': 0.2138317179515202, 'Total loss': 0.2138317179515202}
2022-12-31 10:59:21,375 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:21,375 INFO:     Epoch: 97
2022-12-31 10:59:22,980 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4520902355511983, 'Total loss': 0.4520902355511983} | train loss {'Reaction outcome loss': 0.21301107195892285, 'Total loss': 0.21301107195892285}
2022-12-31 10:59:22,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:22,981 INFO:     Epoch: 98
2022-12-31 10:59:24,585 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4283903926610947, 'Total loss': 0.4283903926610947} | train loss {'Reaction outcome loss': 0.20910623429370098, 'Total loss': 0.20910623429370098}
2022-12-31 10:59:24,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:24,585 INFO:     Epoch: 99
2022-12-31 10:59:26,169 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4562512904405594, 'Total loss': 0.4562512904405594} | train loss {'Reaction outcome loss': 0.22898628879203528, 'Total loss': 0.22898628879203528}
2022-12-31 10:59:26,169 INFO:     Best model found after epoch 57 of 100.
2022-12-31 10:59:26,169 INFO:   Done with stage: TRAINING
2022-12-31 10:59:26,169 INFO:   Starting stage: EVALUATION
2022-12-31 10:59:26,298 INFO:   Done with stage: EVALUATION
2022-12-31 10:59:26,298 INFO:   Leaving out SEQ value Fold_3
2022-12-31 10:59:26,311 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2022-12-31 10:59:26,311 INFO:   Starting stage: FEATURE SCALING
2022-12-31 10:59:26,958 INFO:   Done with stage: FEATURE SCALING
2022-12-31 10:59:26,958 INFO:   Starting stage: SCALING TARGETS
2022-12-31 10:59:27,028 INFO:   Done with stage: SCALING TARGETS
2022-12-31 10:59:27,028 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:59:27,028 INFO:     No hyperparam tuning for this model
2022-12-31 10:59:27,028 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 10:59:27,028 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 10:59:27,029 INFO:     None feature selector for col prot
2022-12-31 10:59:27,029 INFO:     None feature selector for col prot
2022-12-31 10:59:27,029 INFO:     None feature selector for col prot
2022-12-31 10:59:27,029 INFO:     None feature selector for col chem
2022-12-31 10:59:27,029 INFO:     None feature selector for col chem
2022-12-31 10:59:27,029 INFO:     None feature selector for col chem
2022-12-31 10:59:27,030 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 10:59:27,030 INFO:   Starting stage: BUILD MODEL
2022-12-31 10:59:27,031 INFO:     Number of params in model 223921
2022-12-31 10:59:27,035 INFO:   Done with stage: BUILD MODEL
2022-12-31 10:59:27,035 INFO:   Starting stage: TRAINING
2022-12-31 10:59:27,079 INFO:     Val loss before train {'Reaction outcome loss': 1.0499327619870504, 'Total loss': 1.0499327619870504}
2022-12-31 10:59:27,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:27,079 INFO:     Epoch: 0
2022-12-31 10:59:28,722 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6871942241986593, 'Total loss': 0.6871942241986593} | train loss {'Reaction outcome loss': 0.8032595419535672, 'Total loss': 0.8032595419535672}
2022-12-31 10:59:28,722 INFO:     Found new best model at epoch 0
2022-12-31 10:59:28,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:28,723 INFO:     Epoch: 1
2022-12-31 10:59:30,329 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6018274903297425, 'Total loss': 0.6018274903297425} | train loss {'Reaction outcome loss': 0.5847693296679615, 'Total loss': 0.5847693296679615}
2022-12-31 10:59:30,329 INFO:     Found new best model at epoch 1
2022-12-31 10:59:30,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:30,330 INFO:     Epoch: 2
2022-12-31 10:59:31,928 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5819329182306926, 'Total loss': 0.5819329182306926} | train loss {'Reaction outcome loss': 0.5192848158470036, 'Total loss': 0.5192848158470036}
2022-12-31 10:59:31,929 INFO:     Found new best model at epoch 2
2022-12-31 10:59:31,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:31,929 INFO:     Epoch: 3
2022-12-31 10:59:33,528 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5456725130478541, 'Total loss': 0.5456725130478541} | train loss {'Reaction outcome loss': 0.4985102204619533, 'Total loss': 0.4985102204619533}
2022-12-31 10:59:33,529 INFO:     Found new best model at epoch 3
2022-12-31 10:59:33,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:33,529 INFO:     Epoch: 4
2022-12-31 10:59:35,114 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5561273107926051, 'Total loss': 0.5561273107926051} | train loss {'Reaction outcome loss': 0.4802203449237086, 'Total loss': 0.4802203449237086}
2022-12-31 10:59:35,115 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:35,115 INFO:     Epoch: 5
2022-12-31 10:59:36,693 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.583074559768041, 'Total loss': 0.583074559768041} | train loss {'Reaction outcome loss': 0.46941590276512785, 'Total loss': 0.46941590276512785}
2022-12-31 10:59:36,693 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:36,693 INFO:     Epoch: 6
2022-12-31 10:59:38,306 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5331965982913971, 'Total loss': 0.5331965982913971} | train loss {'Reaction outcome loss': 0.45774273122966724, 'Total loss': 0.45774273122966724}
2022-12-31 10:59:38,306 INFO:     Found new best model at epoch 6
2022-12-31 10:59:38,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:38,307 INFO:     Epoch: 7
2022-12-31 10:59:39,912 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5279375632603963, 'Total loss': 0.5279375632603963} | train loss {'Reaction outcome loss': 0.4538101237947053, 'Total loss': 0.4538101237947053}
2022-12-31 10:59:39,912 INFO:     Found new best model at epoch 7
2022-12-31 10:59:39,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:39,913 INFO:     Epoch: 8
2022-12-31 10:59:41,560 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5511584540208181, 'Total loss': 0.5511584540208181} | train loss {'Reaction outcome loss': 0.4424522241210415, 'Total loss': 0.4424522241210415}
2022-12-31 10:59:41,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:41,561 INFO:     Epoch: 9
2022-12-31 10:59:43,190 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5052848855654398, 'Total loss': 0.5052848855654398} | train loss {'Reaction outcome loss': 0.4415866953939417, 'Total loss': 0.4415866953939417}
2022-12-31 10:59:43,190 INFO:     Found new best model at epoch 9
2022-12-31 10:59:43,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:43,191 INFO:     Epoch: 10
2022-12-31 10:59:44,759 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5177808860937755, 'Total loss': 0.5177808860937755} | train loss {'Reaction outcome loss': 0.43339112564160004, 'Total loss': 0.43339112564160004}
2022-12-31 10:59:44,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:44,760 INFO:     Epoch: 11
2022-12-31 10:59:46,367 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5412894268830617, 'Total loss': 0.5412894268830617} | train loss {'Reaction outcome loss': 0.4225989357180839, 'Total loss': 0.4225989357180839}
2022-12-31 10:59:46,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:46,367 INFO:     Epoch: 12
2022-12-31 10:59:47,963 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4921142896016439, 'Total loss': 0.4921142896016439} | train loss {'Reaction outcome loss': 0.4212264115684224, 'Total loss': 0.4212264115684224}
2022-12-31 10:59:47,964 INFO:     Found new best model at epoch 12
2022-12-31 10:59:47,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:47,965 INFO:     Epoch: 13
2022-12-31 10:59:49,591 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4838055888811747, 'Total loss': 0.4838055888811747} | train loss {'Reaction outcome loss': 0.4154269400521787, 'Total loss': 0.4154269400521787}
2022-12-31 10:59:49,591 INFO:     Found new best model at epoch 13
2022-12-31 10:59:49,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:49,592 INFO:     Epoch: 14
2022-12-31 10:59:51,212 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.49921560684839883, 'Total loss': 0.49921560684839883} | train loss {'Reaction outcome loss': 0.40605724431628726, 'Total loss': 0.40605724431628726}
2022-12-31 10:59:51,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:51,213 INFO:     Epoch: 15
2022-12-31 10:59:52,792 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5035988012949626, 'Total loss': 0.5035988012949626} | train loss {'Reaction outcome loss': 0.39977915103744416, 'Total loss': 0.39977915103744416}
2022-12-31 10:59:52,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:52,792 INFO:     Epoch: 16
2022-12-31 10:59:54,391 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4885141591231028, 'Total loss': 0.4885141591231028} | train loss {'Reaction outcome loss': 0.39735853707377056, 'Total loss': 0.39735853707377056}
2022-12-31 10:59:54,391 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:54,391 INFO:     Epoch: 17
2022-12-31 10:59:56,031 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4756802330414454, 'Total loss': 0.4756802330414454} | train loss {'Reaction outcome loss': 0.3929207281474649, 'Total loss': 0.3929207281474649}
2022-12-31 10:59:56,031 INFO:     Found new best model at epoch 17
2022-12-31 10:59:56,032 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:56,032 INFO:     Epoch: 18
2022-12-31 10:59:57,636 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4840703755617142, 'Total loss': 0.4840703755617142} | train loss {'Reaction outcome loss': 0.3845852664841788, 'Total loss': 0.3845852664841788}
2022-12-31 10:59:57,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:57,636 INFO:     Epoch: 19
2022-12-31 10:59:59,256 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44053789029518764, 'Total loss': 0.44053789029518764} | train loss {'Reaction outcome loss': 0.38524611435667444, 'Total loss': 0.38524611435667444}
2022-12-31 10:59:59,256 INFO:     Found new best model at epoch 19
2022-12-31 10:59:59,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 10:59:59,257 INFO:     Epoch: 20
2022-12-31 11:00:00,901 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5029248336950938, 'Total loss': 0.5029248336950938} | train loss {'Reaction outcome loss': 0.3760121599329214, 'Total loss': 0.3760121599329214}
2022-12-31 11:00:00,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:00,901 INFO:     Epoch: 21
2022-12-31 11:00:02,493 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.49867599407831825, 'Total loss': 0.49867599407831825} | train loss {'Reaction outcome loss': 0.3696451161845322, 'Total loss': 0.3696451161845322}
2022-12-31 11:00:02,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:02,494 INFO:     Epoch: 22
2022-12-31 11:00:04,123 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4763636112213135, 'Total loss': 0.4763636112213135} | train loss {'Reaction outcome loss': 0.3640712740810683, 'Total loss': 0.3640712740810683}
2022-12-31 11:00:04,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:04,123 INFO:     Epoch: 23
2022-12-31 11:00:05,744 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.48938426772753396, 'Total loss': 0.48938426772753396} | train loss {'Reaction outcome loss': 0.3591654634878148, 'Total loss': 0.3591654634878148}
2022-12-31 11:00:05,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:05,744 INFO:     Epoch: 24
2022-12-31 11:00:07,349 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4545449326435725, 'Total loss': 0.4545449326435725} | train loss {'Reaction outcome loss': 0.3586257437148886, 'Total loss': 0.3586257437148886}
2022-12-31 11:00:07,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:07,350 INFO:     Epoch: 25
2022-12-31 11:00:08,955 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4468636989593506, 'Total loss': 0.4468636989593506} | train loss {'Reaction outcome loss': 0.3538312500573858, 'Total loss': 0.3538312500573858}
2022-12-31 11:00:08,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:08,955 INFO:     Epoch: 26
2022-12-31 11:00:10,541 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47625323235988615, 'Total loss': 0.47625323235988615} | train loss {'Reaction outcome loss': 0.3457439052090593, 'Total loss': 0.3457439052090593}
2022-12-31 11:00:10,541 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:10,541 INFO:     Epoch: 27
2022-12-31 11:00:12,126 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45296181639035543, 'Total loss': 0.45296181639035543} | train loss {'Reaction outcome loss': 0.33869128687864675, 'Total loss': 0.33869128687864675}
2022-12-31 11:00:12,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:12,127 INFO:     Epoch: 28
2022-12-31 11:00:13,728 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44343660672505697, 'Total loss': 0.44343660672505697} | train loss {'Reaction outcome loss': 0.3389348376297603, 'Total loss': 0.3389348376297603}
2022-12-31 11:00:13,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:13,729 INFO:     Epoch: 29
2022-12-31 11:00:15,357 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4520756870508194, 'Total loss': 0.4520756870508194} | train loss {'Reaction outcome loss': 0.3323059463805526, 'Total loss': 0.3323059463805526}
2022-12-31 11:00:15,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:15,357 INFO:     Epoch: 30
2022-12-31 11:00:17,014 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46887742082277933, 'Total loss': 0.46887742082277933} | train loss {'Reaction outcome loss': 0.3261173020667621, 'Total loss': 0.3261173020667621}
2022-12-31 11:00:17,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:17,015 INFO:     Epoch: 31
2022-12-31 11:00:18,629 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.45164134005705514, 'Total loss': 0.45164134005705514} | train loss {'Reaction outcome loss': 0.32313255432748444, 'Total loss': 0.32313255432748444}
2022-12-31 11:00:18,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:18,629 INFO:     Epoch: 32
2022-12-31 11:00:20,220 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4274484674135844, 'Total loss': 0.4274484674135844} | train loss {'Reaction outcome loss': 0.3200213576592233, 'Total loss': 0.3200213576592233}
2022-12-31 11:00:20,221 INFO:     Found new best model at epoch 32
2022-12-31 11:00:20,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:20,222 INFO:     Epoch: 33
2022-12-31 11:00:21,844 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43840991457303363, 'Total loss': 0.43840991457303363} | train loss {'Reaction outcome loss': 0.31305640759150477, 'Total loss': 0.31305640759150477}
2022-12-31 11:00:21,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:21,844 INFO:     Epoch: 34
2022-12-31 11:00:23,494 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46760307153066, 'Total loss': 0.46760307153066} | train loss {'Reaction outcome loss': 0.3048267656814878, 'Total loss': 0.3048267656814878}
2022-12-31 11:00:23,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:23,495 INFO:     Epoch: 35
2022-12-31 11:00:25,134 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.47112860133250556, 'Total loss': 0.47112860133250556} | train loss {'Reaction outcome loss': 0.3064357021918697, 'Total loss': 0.3064357021918697}
2022-12-31 11:00:25,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:25,134 INFO:     Epoch: 36
2022-12-31 11:00:26,737 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45408854881922406, 'Total loss': 0.45408854881922406} | train loss {'Reaction outcome loss': 0.3095711121050111, 'Total loss': 0.3095711121050111}
2022-12-31 11:00:26,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:26,737 INFO:     Epoch: 37
2022-12-31 11:00:28,340 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42353911300500235, 'Total loss': 0.42353911300500235} | train loss {'Reaction outcome loss': 0.29731755328439446, 'Total loss': 0.29731755328439446}
2022-12-31 11:00:28,340 INFO:     Found new best model at epoch 37
2022-12-31 11:00:28,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:28,341 INFO:     Epoch: 38
2022-12-31 11:00:29,935 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4288628617922465, 'Total loss': 0.4288628617922465} | train loss {'Reaction outcome loss': 0.29329153503814753, 'Total loss': 0.29329153503814753}
2022-12-31 11:00:29,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:29,936 INFO:     Epoch: 39
2022-12-31 11:00:31,526 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.47875436544418337, 'Total loss': 0.47875436544418337} | train loss {'Reaction outcome loss': 0.2905788062289901, 'Total loss': 0.2905788062289901}
2022-12-31 11:00:31,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:31,526 INFO:     Epoch: 40
2022-12-31 11:00:33,129 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4646000305811564, 'Total loss': 0.4646000305811564} | train loss {'Reaction outcome loss': 0.29233837978792016, 'Total loss': 0.29233837978792016}
2022-12-31 11:00:33,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:33,129 INFO:     Epoch: 41
2022-12-31 11:00:34,748 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44028103947639463, 'Total loss': 0.44028103947639463} | train loss {'Reaction outcome loss': 0.28967103534752, 'Total loss': 0.28967103534752}
2022-12-31 11:00:34,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:34,749 INFO:     Epoch: 42
2022-12-31 11:00:36,360 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.48729250530401863, 'Total loss': 0.48729250530401863} | train loss {'Reaction outcome loss': 0.27794822974361644, 'Total loss': 0.27794822974361644}
2022-12-31 11:00:36,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:36,360 INFO:     Epoch: 43
2022-12-31 11:00:37,946 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.456395677725474, 'Total loss': 0.456395677725474} | train loss {'Reaction outcome loss': 0.279161892695366, 'Total loss': 0.279161892695366}
2022-12-31 11:00:37,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:37,946 INFO:     Epoch: 44
2022-12-31 11:00:39,555 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42156679729620616, 'Total loss': 0.42156679729620616} | train loss {'Reaction outcome loss': 0.2777453965242327, 'Total loss': 0.2777453965242327}
2022-12-31 11:00:39,555 INFO:     Found new best model at epoch 44
2022-12-31 11:00:39,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:39,556 INFO:     Epoch: 45
2022-12-31 11:00:41,157 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4581683417161306, 'Total loss': 0.4581683417161306} | train loss {'Reaction outcome loss': 0.2726109678156837, 'Total loss': 0.2726109678156837}
2022-12-31 11:00:41,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:41,158 INFO:     Epoch: 46
2022-12-31 11:00:42,753 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46119020879268646, 'Total loss': 0.46119020879268646} | train loss {'Reaction outcome loss': 0.26764798694609726, 'Total loss': 0.26764798694609726}
2022-12-31 11:00:42,754 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:42,754 INFO:     Epoch: 47
2022-12-31 11:00:44,350 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41421341300010683, 'Total loss': 0.41421341300010683} | train loss {'Reaction outcome loss': 0.27252939038903173, 'Total loss': 0.27252939038903173}
2022-12-31 11:00:44,350 INFO:     Found new best model at epoch 47
2022-12-31 11:00:44,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:44,351 INFO:     Epoch: 48
2022-12-31 11:00:45,956 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4141672134399414, 'Total loss': 0.4141672134399414} | train loss {'Reaction outcome loss': 0.2654752874624555, 'Total loss': 0.2654752874624555}
2022-12-31 11:00:45,956 INFO:     Found new best model at epoch 48
2022-12-31 11:00:45,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:45,957 INFO:     Epoch: 49
2022-12-31 11:00:47,558 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4523615558942159, 'Total loss': 0.4523615558942159} | train loss {'Reaction outcome loss': 0.2593243357854603, 'Total loss': 0.2593243357854603}
2022-12-31 11:00:47,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:47,559 INFO:     Epoch: 50
2022-12-31 11:00:49,140 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.439557820558548, 'Total loss': 0.439557820558548} | train loss {'Reaction outcome loss': 0.25682133833204746, 'Total loss': 0.25682133833204746}
2022-12-31 11:00:49,141 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:49,141 INFO:     Epoch: 51
2022-12-31 11:00:50,733 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45448708136876426, 'Total loss': 0.45448708136876426} | train loss {'Reaction outcome loss': 0.25419328895390686, 'Total loss': 0.25419328895390686}
2022-12-31 11:00:50,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:50,733 INFO:     Epoch: 52
2022-12-31 11:00:52,327 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4444929361343384, 'Total loss': 0.4444929361343384} | train loss {'Reaction outcome loss': 0.2584945826662065, 'Total loss': 0.2584945826662065}
2022-12-31 11:00:52,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:52,327 INFO:     Epoch: 53
2022-12-31 11:00:53,924 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45245949427286786, 'Total loss': 0.45245949427286786} | train loss {'Reaction outcome loss': 0.2560398958650601, 'Total loss': 0.2560398958650601}
2022-12-31 11:00:53,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:53,924 INFO:     Epoch: 54
2022-12-31 11:00:55,519 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4731006721655528, 'Total loss': 0.4731006721655528} | train loss {'Reaction outcome loss': 0.25303051362398765, 'Total loss': 0.25303051362398765}
2022-12-31 11:00:55,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:55,519 INFO:     Epoch: 55
2022-12-31 11:00:57,121 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42181862791379293, 'Total loss': 0.42181862791379293} | train loss {'Reaction outcome loss': 0.24626020331234827, 'Total loss': 0.24626020331234827}
2022-12-31 11:00:57,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:57,122 INFO:     Epoch: 56
2022-12-31 11:00:58,712 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43595574498176576, 'Total loss': 0.43595574498176576} | train loss {'Reaction outcome loss': 0.24266044357043765, 'Total loss': 0.24266044357043765}
2022-12-31 11:00:58,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:00:58,714 INFO:     Epoch: 57
2022-12-31 11:01:00,310 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.49236825356880826, 'Total loss': 0.49236825356880826} | train loss {'Reaction outcome loss': 0.2404650887406438, 'Total loss': 0.2404650887406438}
2022-12-31 11:01:00,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:00,310 INFO:     Epoch: 58
2022-12-31 11:01:01,935 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4423449476559957, 'Total loss': 0.4423449476559957} | train loss {'Reaction outcome loss': 0.24338158369608168, 'Total loss': 0.24338158369608168}
2022-12-31 11:01:01,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:01,936 INFO:     Epoch: 59
2022-12-31 11:01:03,543 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44426517287890116, 'Total loss': 0.44426517287890116} | train loss {'Reaction outcome loss': 0.2404719485092337, 'Total loss': 0.2404719485092337}
2022-12-31 11:01:03,543 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:03,543 INFO:     Epoch: 60
2022-12-31 11:01:05,124 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42889664471149447, 'Total loss': 0.42889664471149447} | train loss {'Reaction outcome loss': 0.24109017870722027, 'Total loss': 0.24109017870722027}
2022-12-31 11:01:05,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:05,125 INFO:     Epoch: 61
2022-12-31 11:01:06,691 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4949493328730265, 'Total loss': 0.4949493328730265} | train loss {'Reaction outcome loss': 0.23663627628209818, 'Total loss': 0.23663627628209818}
2022-12-31 11:01:06,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:06,692 INFO:     Epoch: 62
2022-12-31 11:01:08,322 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4331637839476267, 'Total loss': 0.4331637839476267} | train loss {'Reaction outcome loss': 0.2338423767011531, 'Total loss': 0.2338423767011531}
2022-12-31 11:01:08,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:08,322 INFO:     Epoch: 63
2022-12-31 11:01:09,937 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4114958425362905, 'Total loss': 0.4114958425362905} | train loss {'Reaction outcome loss': 0.23174048467355707, 'Total loss': 0.23174048467355707}
2022-12-31 11:01:09,937 INFO:     Found new best model at epoch 63
2022-12-31 11:01:09,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:09,938 INFO:     Epoch: 64
2022-12-31 11:01:11,542 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4245136012633642, 'Total loss': 0.4245136012633642} | train loss {'Reaction outcome loss': 0.22995829636598156, 'Total loss': 0.22995829636598156}
2022-12-31 11:01:11,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:11,542 INFO:     Epoch: 65
2022-12-31 11:01:13,177 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44628000954786934, 'Total loss': 0.44628000954786934} | train loss {'Reaction outcome loss': 0.22763633786489929, 'Total loss': 0.22763633786489929}
2022-12-31 11:01:13,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:13,177 INFO:     Epoch: 66
2022-12-31 11:01:14,770 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39032176733016966, 'Total loss': 0.39032176733016966} | train loss {'Reaction outcome loss': 0.23392635409169607, 'Total loss': 0.23392635409169607}
2022-12-31 11:01:14,770 INFO:     Found new best model at epoch 66
2022-12-31 11:01:14,771 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:14,771 INFO:     Epoch: 67
2022-12-31 11:01:16,386 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42725243270397184, 'Total loss': 0.42725243270397184} | train loss {'Reaction outcome loss': 0.2265030873164426, 'Total loss': 0.2265030873164426}
2022-12-31 11:01:16,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:16,386 INFO:     Epoch: 68
2022-12-31 11:01:18,027 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43039240191380185, 'Total loss': 0.43039240191380185} | train loss {'Reaction outcome loss': 0.22320642586063294, 'Total loss': 0.22320642586063294}
2022-12-31 11:01:18,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:18,028 INFO:     Epoch: 69
2022-12-31 11:01:19,659 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4212466220060984, 'Total loss': 0.4212466220060984} | train loss {'Reaction outcome loss': 0.22432958008381573, 'Total loss': 0.22432958008381573}
2022-12-31 11:01:19,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:19,659 INFO:     Epoch: 70
2022-12-31 11:01:21,263 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43819681704044344, 'Total loss': 0.43819681704044344} | train loss {'Reaction outcome loss': 0.2181913595592236, 'Total loss': 0.2181913595592236}
2022-12-31 11:01:21,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:21,263 INFO:     Epoch: 71
2022-12-31 11:01:22,860 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3845885306596756, 'Total loss': 0.3845885306596756} | train loss {'Reaction outcome loss': 0.22159116979634022, 'Total loss': 0.22159116979634022}
2022-12-31 11:01:22,860 INFO:     Found new best model at epoch 71
2022-12-31 11:01:22,861 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:22,861 INFO:     Epoch: 72
2022-12-31 11:01:24,451 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4751928001642227, 'Total loss': 0.4751928001642227} | train loss {'Reaction outcome loss': 0.22123114056341406, 'Total loss': 0.22123114056341406}
2022-12-31 11:01:24,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:24,452 INFO:     Epoch: 73
2022-12-31 11:01:26,081 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4406695644060771, 'Total loss': 0.4406695644060771} | train loss {'Reaction outcome loss': 0.21810691582079786, 'Total loss': 0.21810691582079786}
2022-12-31 11:01:26,081 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:26,081 INFO:     Epoch: 74
2022-12-31 11:01:27,712 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43970707803964615, 'Total loss': 0.43970707803964615} | train loss {'Reaction outcome loss': 0.21747302883950465, 'Total loss': 0.21747302883950465}
2022-12-31 11:01:27,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:27,712 INFO:     Epoch: 75
2022-12-31 11:01:29,349 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.442382471760114, 'Total loss': 0.442382471760114} | train loss {'Reaction outcome loss': 0.21725452884379096, 'Total loss': 0.21725452884379096}
2022-12-31 11:01:29,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:29,350 INFO:     Epoch: 76
2022-12-31 11:01:30,990 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4338580866654714, 'Total loss': 0.4338580866654714} | train loss {'Reaction outcome loss': 0.22324550155563838, 'Total loss': 0.22324550155563838}
2022-12-31 11:01:30,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:30,990 INFO:     Epoch: 77
2022-12-31 11:01:32,604 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4752631773551305, 'Total loss': 0.4752631773551305} | train loss {'Reaction outcome loss': 0.21578296352463372, 'Total loss': 0.21578296352463372}
2022-12-31 11:01:32,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:32,604 INFO:     Epoch: 78
2022-12-31 11:01:34,190 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3950160284837087, 'Total loss': 0.3950160284837087} | train loss {'Reaction outcome loss': 0.21674488974993464, 'Total loss': 0.21674488974993464}
2022-12-31 11:01:34,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:34,190 INFO:     Epoch: 79
2022-12-31 11:01:35,791 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41539364655812583, 'Total loss': 0.41539364655812583} | train loss {'Reaction outcome loss': 0.21542710553936278, 'Total loss': 0.21542710553936278}
2022-12-31 11:01:35,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:35,792 INFO:     Epoch: 80
2022-12-31 11:01:37,389 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4277713030576706, 'Total loss': 0.4277713030576706} | train loss {'Reaction outcome loss': 0.2137373497974753, 'Total loss': 0.2137373497974753}
2022-12-31 11:01:37,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:37,389 INFO:     Epoch: 81
2022-12-31 11:01:38,990 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39491559863090514, 'Total loss': 0.39491559863090514} | train loss {'Reaction outcome loss': 0.21369460991916867, 'Total loss': 0.21369460991916867}
2022-12-31 11:01:38,990 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:38,990 INFO:     Epoch: 82
2022-12-31 11:01:40,590 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4272301097710927, 'Total loss': 0.4272301097710927} | train loss {'Reaction outcome loss': 0.2117750903754665, 'Total loss': 0.2117750903754665}
2022-12-31 11:01:40,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:40,591 INFO:     Epoch: 83
2022-12-31 11:01:42,170 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41449610392252606, 'Total loss': 0.41449610392252606} | train loss {'Reaction outcome loss': 0.2093255079222204, 'Total loss': 0.2093255079222204}
2022-12-31 11:01:42,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:42,170 INFO:     Epoch: 84
2022-12-31 11:01:43,752 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40001754065354667, 'Total loss': 0.40001754065354667} | train loss {'Reaction outcome loss': 0.20973546730939055, 'Total loss': 0.20973546730939055}
2022-12-31 11:01:43,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:43,752 INFO:     Epoch: 85
2022-12-31 11:01:45,350 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4294262131055196, 'Total loss': 0.4294262131055196} | train loss {'Reaction outcome loss': 0.20663692643118164, 'Total loss': 0.20663692643118164}
2022-12-31 11:01:45,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:45,350 INFO:     Epoch: 86
2022-12-31 11:01:46,949 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4156294902165731, 'Total loss': 0.4156294902165731} | train loss {'Reaction outcome loss': 0.20343222768882113, 'Total loss': 0.20343222768882113}
2022-12-31 11:01:46,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:46,950 INFO:     Epoch: 87
2022-12-31 11:01:48,548 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4747526968518893, 'Total loss': 0.4747526968518893} | train loss {'Reaction outcome loss': 0.20447470334759593, 'Total loss': 0.20447470334759593}
2022-12-31 11:01:48,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:48,549 INFO:     Epoch: 88
2022-12-31 11:01:50,135 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4380737642447154, 'Total loss': 0.4380737642447154} | train loss {'Reaction outcome loss': 0.20640864145065094, 'Total loss': 0.20640864145065094}
2022-12-31 11:01:50,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:50,135 INFO:     Epoch: 89
2022-12-31 11:01:51,725 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4194812814394633, 'Total loss': 0.4194812814394633} | train loss {'Reaction outcome loss': 0.2050212867435639, 'Total loss': 0.2050212867435639}
2022-12-31 11:01:51,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:51,726 INFO:     Epoch: 90
2022-12-31 11:01:53,368 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4988705426454544, 'Total loss': 0.4988705426454544} | train loss {'Reaction outcome loss': 0.20316604114253156, 'Total loss': 0.20316604114253156}
2022-12-31 11:01:53,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:53,368 INFO:     Epoch: 91
2022-12-31 11:01:54,984 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38562114437421163, 'Total loss': 0.38562114437421163} | train loss {'Reaction outcome loss': 0.20292800196861155, 'Total loss': 0.20292800196861155}
2022-12-31 11:01:54,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:54,984 INFO:     Epoch: 92
2022-12-31 11:01:56,582 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40172949731349944, 'Total loss': 0.40172949731349944} | train loss {'Reaction outcome loss': 0.20202507685366883, 'Total loss': 0.20202507685366883}
2022-12-31 11:01:56,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:56,583 INFO:     Epoch: 93
2022-12-31 11:01:58,181 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.47560302416483563, 'Total loss': 0.47560302416483563} | train loss {'Reaction outcome loss': 0.19482719134131488, 'Total loss': 0.19482719134131488}
2022-12-31 11:01:58,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:58,181 INFO:     Epoch: 94
2022-12-31 11:01:59,776 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3921174625555674, 'Total loss': 0.3921174625555674} | train loss {'Reaction outcome loss': 0.20665680838028228, 'Total loss': 0.20665680838028228}
2022-12-31 11:01:59,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:01:59,777 INFO:     Epoch: 95
2022-12-31 11:02:01,393 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4156363685925802, 'Total loss': 0.4156363685925802} | train loss {'Reaction outcome loss': 0.19742739963324835, 'Total loss': 0.19742739963324835}
2022-12-31 11:02:01,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:01,394 INFO:     Epoch: 96
2022-12-31 11:02:03,029 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42138652900854745, 'Total loss': 0.42138652900854745} | train loss {'Reaction outcome loss': 0.19838130711000004, 'Total loss': 0.19838130711000004}
2022-12-31 11:02:03,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:03,029 INFO:     Epoch: 97
2022-12-31 11:02:04,637 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4327681948741277, 'Total loss': 0.4327681948741277} | train loss {'Reaction outcome loss': 0.19879567605463694, 'Total loss': 0.19879567605463694}
2022-12-31 11:02:04,637 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:04,637 INFO:     Epoch: 98
2022-12-31 11:02:06,238 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41834033926328024, 'Total loss': 0.41834033926328024} | train loss {'Reaction outcome loss': 0.19074554598625124, 'Total loss': 0.19074554598625124}
2022-12-31 11:02:06,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:06,239 INFO:     Epoch: 99
2022-12-31 11:02:07,839 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48133177161216734, 'Total loss': 0.48133177161216734} | train loss {'Reaction outcome loss': 0.19571499229429196, 'Total loss': 0.19571499229429196}
2022-12-31 11:02:07,839 INFO:     Best model found after epoch 72 of 100.
2022-12-31 11:02:07,839 INFO:   Done with stage: TRAINING
2022-12-31 11:02:07,839 INFO:   Starting stage: EVALUATION
2022-12-31 11:02:07,972 INFO:   Done with stage: EVALUATION
2022-12-31 11:02:07,972 INFO:   Leaving out SEQ value Fold_4
2022-12-31 11:02:07,985 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 11:02:07,985 INFO:   Starting stage: FEATURE SCALING
2022-12-31 11:02:08,644 INFO:   Done with stage: FEATURE SCALING
2022-12-31 11:02:08,644 INFO:   Starting stage: SCALING TARGETS
2022-12-31 11:02:08,714 INFO:   Done with stage: SCALING TARGETS
2022-12-31 11:02:08,714 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:02:08,714 INFO:     No hyperparam tuning for this model
2022-12-31 11:02:08,714 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:02:08,714 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 11:02:08,715 INFO:     None feature selector for col prot
2022-12-31 11:02:08,715 INFO:     None feature selector for col prot
2022-12-31 11:02:08,715 INFO:     None feature selector for col prot
2022-12-31 11:02:08,716 INFO:     None feature selector for col chem
2022-12-31 11:02:08,716 INFO:     None feature selector for col chem
2022-12-31 11:02:08,716 INFO:     None feature selector for col chem
2022-12-31 11:02:08,716 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 11:02:08,716 INFO:   Starting stage: BUILD MODEL
2022-12-31 11:02:08,718 INFO:     Number of params in model 223921
2022-12-31 11:02:08,721 INFO:   Done with stage: BUILD MODEL
2022-12-31 11:02:08,721 INFO:   Starting stage: TRAINING
2022-12-31 11:02:08,766 INFO:     Val loss before train {'Reaction outcome loss': 0.8300597707430521, 'Total loss': 0.8300597707430521}
2022-12-31 11:02:08,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:08,766 INFO:     Epoch: 0
2022-12-31 11:02:10,375 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.5838080863157908, 'Total loss': 0.5838080863157908} | train loss {'Reaction outcome loss': 0.8231625291316406, 'Total loss': 0.8231625291316406}
2022-12-31 11:02:10,376 INFO:     Found new best model at epoch 0
2022-12-31 11:02:10,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:10,376 INFO:     Epoch: 1
2022-12-31 11:02:11,986 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5262383917967478, 'Total loss': 0.5262383917967478} | train loss {'Reaction outcome loss': 0.5946430416501033, 'Total loss': 0.5946430416501033}
2022-12-31 11:02:11,986 INFO:     Found new best model at epoch 1
2022-12-31 11:02:11,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:11,987 INFO:     Epoch: 2
2022-12-31 11:02:13,597 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.468513152996699, 'Total loss': 0.468513152996699} | train loss {'Reaction outcome loss': 0.531217059555617, 'Total loss': 0.531217059555617}
2022-12-31 11:02:13,597 INFO:     Found new best model at epoch 2
2022-12-31 11:02:13,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:13,598 INFO:     Epoch: 3
2022-12-31 11:02:15,214 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5722986419995626, 'Total loss': 0.5722986419995626} | train loss {'Reaction outcome loss': 0.5106627027085726, 'Total loss': 0.5106627027085726}
2022-12-31 11:02:15,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:15,214 INFO:     Epoch: 4
2022-12-31 11:02:16,855 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4771154721577962, 'Total loss': 0.4771154721577962} | train loss {'Reaction outcome loss': 0.5221341025409355, 'Total loss': 0.5221341025409355}
2022-12-31 11:02:16,856 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:16,856 INFO:     Epoch: 5
2022-12-31 11:02:18,469 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4544600466887156, 'Total loss': 0.4544600466887156} | train loss {'Reaction outcome loss': 0.48945909695348877, 'Total loss': 0.48945909695348877}
2022-12-31 11:02:18,470 INFO:     Found new best model at epoch 5
2022-12-31 11:02:18,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:18,471 INFO:     Epoch: 6
2022-12-31 11:02:20,093 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4514270673195521, 'Total loss': 0.4514270673195521} | train loss {'Reaction outcome loss': 0.4892838322490022, 'Total loss': 0.4892838322490022}
2022-12-31 11:02:20,093 INFO:     Found new best model at epoch 6
2022-12-31 11:02:20,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:20,094 INFO:     Epoch: 7
2022-12-31 11:02:21,703 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4720248172680537, 'Total loss': 0.4720248172680537} | train loss {'Reaction outcome loss': 0.47005695675202797, 'Total loss': 0.47005695675202797}
2022-12-31 11:02:21,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:21,703 INFO:     Epoch: 8
2022-12-31 11:02:23,340 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42766532401243845, 'Total loss': 0.42766532401243845} | train loss {'Reaction outcome loss': 0.46873703167058417, 'Total loss': 0.46873703167058417}
2022-12-31 11:02:23,341 INFO:     Found new best model at epoch 8
2022-12-31 11:02:23,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:23,342 INFO:     Epoch: 9
2022-12-31 11:02:24,980 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4391180396080017, 'Total loss': 0.4391180396080017} | train loss {'Reaction outcome loss': 0.45803473281262413, 'Total loss': 0.45803473281262413}
2022-12-31 11:02:24,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:24,981 INFO:     Epoch: 10
2022-12-31 11:02:26,589 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41281635463237765, 'Total loss': 0.41281635463237765} | train loss {'Reaction outcome loss': 0.45062582215894875, 'Total loss': 0.45062582215894875}
2022-12-31 11:02:26,589 INFO:     Found new best model at epoch 10
2022-12-31 11:02:26,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:26,590 INFO:     Epoch: 11
2022-12-31 11:02:28,197 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4314274708429972, 'Total loss': 0.4314274708429972} | train loss {'Reaction outcome loss': 0.4572846453258957, 'Total loss': 0.4572846453258957}
2022-12-31 11:02:28,197 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:28,198 INFO:     Epoch: 12
2022-12-31 11:02:29,843 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4437218517065048, 'Total loss': 0.4437218517065048} | train loss {'Reaction outcome loss': 0.4789771931650846, 'Total loss': 0.4789771931650846}
2022-12-31 11:02:29,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:29,844 INFO:     Epoch: 13
2022-12-31 11:02:31,465 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4505695035060247, 'Total loss': 0.4505695035060247} | train loss {'Reaction outcome loss': 0.4699697433412518, 'Total loss': 0.4699697433412518}
2022-12-31 11:02:31,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:31,466 INFO:     Epoch: 14
2022-12-31 11:02:33,096 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4290128489335378, 'Total loss': 0.4290128489335378} | train loss {'Reaction outcome loss': 0.4357463615959969, 'Total loss': 0.4357463615959969}
2022-12-31 11:02:33,096 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:33,096 INFO:     Epoch: 15
2022-12-31 11:02:34,713 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4052402496337891, 'Total loss': 0.4052402496337891} | train loss {'Reaction outcome loss': 0.4350714623325747, 'Total loss': 0.4350714623325747}
2022-12-31 11:02:34,713 INFO:     Found new best model at epoch 15
2022-12-31 11:02:34,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:34,714 INFO:     Epoch: 16
2022-12-31 11:02:36,340 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4635900318622589, 'Total loss': 0.4635900318622589} | train loss {'Reaction outcome loss': 0.4176870332474051, 'Total loss': 0.4176870332474051}
2022-12-31 11:02:36,341 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:36,341 INFO:     Epoch: 17
2022-12-31 11:02:37,935 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4456688125928243, 'Total loss': 0.4456688125928243} | train loss {'Reaction outcome loss': 0.4175568757227797, 'Total loss': 0.4175568757227797}
2022-12-31 11:02:37,935 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:37,936 INFO:     Epoch: 18
2022-12-31 11:02:39,548 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42761988441149396, 'Total loss': 0.42761988441149396} | train loss {'Reaction outcome loss': 0.40533990791553387, 'Total loss': 0.40533990791553387}
2022-12-31 11:02:39,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:39,548 INFO:     Epoch: 19
2022-12-31 11:02:41,178 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4925739824771881, 'Total loss': 0.4925739824771881} | train loss {'Reaction outcome loss': 0.40473482679521694, 'Total loss': 0.40473482679521694}
2022-12-31 11:02:41,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:41,178 INFO:     Epoch: 20
2022-12-31 11:02:42,825 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.437138827641805, 'Total loss': 0.437138827641805} | train loss {'Reaction outcome loss': 0.4168967440238465, 'Total loss': 0.4168967440238465}
2022-12-31 11:02:42,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:42,826 INFO:     Epoch: 21
2022-12-31 11:02:44,446 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4034992148478826, 'Total loss': 0.4034992148478826} | train loss {'Reaction outcome loss': 0.3915950177891226, 'Total loss': 0.3915950177891226}
2022-12-31 11:02:44,447 INFO:     Found new best model at epoch 21
2022-12-31 11:02:44,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:44,448 INFO:     Epoch: 22
2022-12-31 11:02:46,069 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41306925415992735, 'Total loss': 0.41306925415992735} | train loss {'Reaction outcome loss': 0.3862575134599878, 'Total loss': 0.3862575134599878}
2022-12-31 11:02:46,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:46,070 INFO:     Epoch: 23
2022-12-31 11:02:47,683 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46576182047526044, 'Total loss': 0.46576182047526044} | train loss {'Reaction outcome loss': 0.4001914310282555, 'Total loss': 0.4001914310282555}
2022-12-31 11:02:47,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:47,683 INFO:     Epoch: 24
2022-12-31 11:02:49,294 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4029866794745127, 'Total loss': 0.4029866794745127} | train loss {'Reaction outcome loss': 0.4011594943172447, 'Total loss': 0.4011594943172447}
2022-12-31 11:02:49,294 INFO:     Found new best model at epoch 24
2022-12-31 11:02:49,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:49,295 INFO:     Epoch: 25
2022-12-31 11:02:50,909 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.40057950615882876, 'Total loss': 0.40057950615882876} | train loss {'Reaction outcome loss': 0.3727311992242112, 'Total loss': 0.3727311992242112}
2022-12-31 11:02:50,909 INFO:     Found new best model at epoch 25
2022-12-31 11:02:50,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:50,910 INFO:     Epoch: 26
2022-12-31 11:02:52,559 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4221034735441208, 'Total loss': 0.4221034735441208} | train loss {'Reaction outcome loss': 0.3678317705573434, 'Total loss': 0.3678317705573434}
2022-12-31 11:02:52,559 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:52,559 INFO:     Epoch: 27
2022-12-31 11:02:54,186 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4046225259701411, 'Total loss': 0.4046225259701411} | train loss {'Reaction outcome loss': 0.36770724904709967, 'Total loss': 0.36770724904709967}
2022-12-31 11:02:54,186 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:54,186 INFO:     Epoch: 28
2022-12-31 11:02:55,816 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.38851310809453327, 'Total loss': 0.38851310809453327} | train loss {'Reaction outcome loss': 0.36942600504751655, 'Total loss': 0.36942600504751655}
2022-12-31 11:02:55,817 INFO:     Found new best model at epoch 28
2022-12-31 11:02:55,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:55,818 INFO:     Epoch: 29
2022-12-31 11:02:57,471 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4063518077135086, 'Total loss': 0.4063518077135086} | train loss {'Reaction outcome loss': 0.3526416483155512, 'Total loss': 0.3526416483155512}
2022-12-31 11:02:57,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:57,471 INFO:     Epoch: 30
2022-12-31 11:02:59,118 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4153498182694117, 'Total loss': 0.4153498182694117} | train loss {'Reaction outcome loss': 0.3462530816559329, 'Total loss': 0.3462530816559329}
2022-12-31 11:02:59,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:02:59,119 INFO:     Epoch: 31
2022-12-31 11:03:00,747 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38136124511559805, 'Total loss': 0.38136124511559805} | train loss {'Reaction outcome loss': 0.3421180002860374, 'Total loss': 0.3421180002860374}
2022-12-31 11:03:00,747 INFO:     Found new best model at epoch 31
2022-12-31 11:03:00,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:00,748 INFO:     Epoch: 32
2022-12-31 11:03:02,373 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41594060361385343, 'Total loss': 0.41594060361385343} | train loss {'Reaction outcome loss': 0.3350319687586676, 'Total loss': 0.3350319687586676}
2022-12-31 11:03:02,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:02,374 INFO:     Epoch: 33
2022-12-31 11:03:04,002 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.38760612768431507, 'Total loss': 0.38760612768431507} | train loss {'Reaction outcome loss': 0.3346650855669725, 'Total loss': 0.3346650855669725}
2022-12-31 11:03:04,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:04,003 INFO:     Epoch: 34
2022-12-31 11:03:05,630 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.390730208158493, 'Total loss': 0.390730208158493} | train loss {'Reaction outcome loss': 0.3238441829185383, 'Total loss': 0.3238441829185383}
2022-12-31 11:03:05,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:05,631 INFO:     Epoch: 35
2022-12-31 11:03:07,281 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4208778113126755, 'Total loss': 0.4208778113126755} | train loss {'Reaction outcome loss': 0.3214400445576757, 'Total loss': 0.3214400445576757}
2022-12-31 11:03:07,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:07,282 INFO:     Epoch: 36
2022-12-31 11:03:08,925 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44234399795532225, 'Total loss': 0.44234399795532225} | train loss {'Reaction outcome loss': 0.3259920271234148, 'Total loss': 0.3259920271234148}
2022-12-31 11:03:08,925 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:08,925 INFO:     Epoch: 37
2022-12-31 11:03:10,574 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.38342906335989635, 'Total loss': 0.38342906335989635} | train loss {'Reaction outcome loss': 0.3151401619195341, 'Total loss': 0.3151401619195341}
2022-12-31 11:03:10,575 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:10,575 INFO:     Epoch: 38
2022-12-31 11:03:12,200 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.358491147061189, 'Total loss': 0.358491147061189} | train loss {'Reaction outcome loss': 0.31067701137584186, 'Total loss': 0.31067701137584186}
2022-12-31 11:03:12,200 INFO:     Found new best model at epoch 38
2022-12-31 11:03:12,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:12,201 INFO:     Epoch: 39
2022-12-31 11:03:13,798 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.422251495718956, 'Total loss': 0.422251495718956} | train loss {'Reaction outcome loss': 0.30489886786107084, 'Total loss': 0.30489886786107084}
2022-12-31 11:03:13,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:13,799 INFO:     Epoch: 40
2022-12-31 11:03:15,410 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.37741224765777587, 'Total loss': 0.37741224765777587} | train loss {'Reaction outcome loss': 0.3069825461758571, 'Total loss': 0.3069825461758571}
2022-12-31 11:03:15,410 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:15,411 INFO:     Epoch: 41
2022-12-31 11:03:17,028 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.416871186097463, 'Total loss': 0.416871186097463} | train loss {'Reaction outcome loss': 0.3005222072664554, 'Total loss': 0.3005222072664554}
2022-12-31 11:03:17,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:17,028 INFO:     Epoch: 42
2022-12-31 11:03:18,669 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4211300323406855, 'Total loss': 0.4211300323406855} | train loss {'Reaction outcome loss': 0.29909078233200764, 'Total loss': 0.29909078233200764}
2022-12-31 11:03:18,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:18,669 INFO:     Epoch: 43
2022-12-31 11:03:20,290 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4225471387306849, 'Total loss': 0.4225471387306849} | train loss {'Reaction outcome loss': 0.2989391318684363, 'Total loss': 0.2989391318684363}
2022-12-31 11:03:20,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:20,290 INFO:     Epoch: 44
2022-12-31 11:03:21,913 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4849873557686806, 'Total loss': 0.4849873557686806} | train loss {'Reaction outcome loss': 0.29969591134484264, 'Total loss': 0.29969591134484264}
2022-12-31 11:03:21,913 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:21,913 INFO:     Epoch: 45
2022-12-31 11:03:23,519 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.36965124383568765, 'Total loss': 0.36965124383568765} | train loss {'Reaction outcome loss': 0.3361251634660352, 'Total loss': 0.3361251634660352}
2022-12-31 11:03:23,519 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:23,519 INFO:     Epoch: 46
2022-12-31 11:03:25,170 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4075469444195429, 'Total loss': 0.4075469444195429} | train loss {'Reaction outcome loss': 0.292187699670161, 'Total loss': 0.292187699670161}
2022-12-31 11:03:25,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:25,171 INFO:     Epoch: 47
2022-12-31 11:03:26,787 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3836154321829478, 'Total loss': 0.3836154321829478} | train loss {'Reaction outcome loss': 0.3083603086516909, 'Total loss': 0.3083603086516909}
2022-12-31 11:03:26,788 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:26,788 INFO:     Epoch: 48
2022-12-31 11:03:28,395 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3949521747728189, 'Total loss': 0.3949521747728189} | train loss {'Reaction outcome loss': 0.2847596361298465, 'Total loss': 0.2847596361298465}
2022-12-31 11:03:28,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:28,395 INFO:     Epoch: 49
2022-12-31 11:03:29,985 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4163323710362116, 'Total loss': 0.4163323710362116} | train loss {'Reaction outcome loss': 0.28485215396326763, 'Total loss': 0.28485215396326763}
2022-12-31 11:03:29,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:29,985 INFO:     Epoch: 50
2022-12-31 11:03:31,577 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4308769186337789, 'Total loss': 0.4308769186337789} | train loss {'Reaction outcome loss': 0.27813618992070627, 'Total loss': 0.27813618992070627}
2022-12-31 11:03:31,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:31,577 INFO:     Epoch: 51
2022-12-31 11:03:33,189 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4457619736591975, 'Total loss': 0.4457619736591975} | train loss {'Reaction outcome loss': 0.2764479390082314, 'Total loss': 0.2764479390082314}
2022-12-31 11:03:33,189 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:33,189 INFO:     Epoch: 52
2022-12-31 11:03:34,804 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.38399697045485176, 'Total loss': 0.38399697045485176} | train loss {'Reaction outcome loss': 0.2714939696808764, 'Total loss': 0.2714939696808764}
2022-12-31 11:03:34,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:34,804 INFO:     Epoch: 53
2022-12-31 11:03:36,437 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38124929890036585, 'Total loss': 0.38124929890036585} | train loss {'Reaction outcome loss': 0.26892686552921496, 'Total loss': 0.26892686552921496}
2022-12-31 11:03:36,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:36,437 INFO:     Epoch: 54
2022-12-31 11:03:38,051 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4066687852144241, 'Total loss': 0.4066687852144241} | train loss {'Reaction outcome loss': 0.2709820197076715, 'Total loss': 0.2709820197076715}
2022-12-31 11:03:38,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:38,051 INFO:     Epoch: 55
2022-12-31 11:03:39,664 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.408634340763092, 'Total loss': 0.408634340763092} | train loss {'Reaction outcome loss': 0.26569427201063617, 'Total loss': 0.26569427201063617}
2022-12-31 11:03:39,664 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:39,664 INFO:     Epoch: 56
2022-12-31 11:03:41,273 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38538230309883753, 'Total loss': 0.38538230309883753} | train loss {'Reaction outcome loss': 0.2702105600197894, 'Total loss': 0.2702105600197894}
2022-12-31 11:03:41,273 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:41,273 INFO:     Epoch: 57
2022-12-31 11:03:42,928 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.36741474469502766, 'Total loss': 0.36741474469502766} | train loss {'Reaction outcome loss': 0.2613612802225111, 'Total loss': 0.2613612802225111}
2022-12-31 11:03:42,929 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:42,929 INFO:     Epoch: 58
2022-12-31 11:03:44,569 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3868765244881312, 'Total loss': 0.3868765244881312} | train loss {'Reaction outcome loss': 0.26986171008236165, 'Total loss': 0.26986171008236165}
2022-12-31 11:03:44,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:44,570 INFO:     Epoch: 59
2022-12-31 11:03:46,224 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40148604412873584, 'Total loss': 0.40148604412873584} | train loss {'Reaction outcome loss': 0.31445977829592436, 'Total loss': 0.31445977829592436}
2022-12-31 11:03:46,225 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:46,225 INFO:     Epoch: 60
2022-12-31 11:03:47,835 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3870072434345881, 'Total loss': 0.3870072434345881} | train loss {'Reaction outcome loss': 0.2681061667812885, 'Total loss': 0.2681061667812885}
2022-12-31 11:03:47,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:47,836 INFO:     Epoch: 61
2022-12-31 11:03:49,459 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4101539671421051, 'Total loss': 0.4101539671421051} | train loss {'Reaction outcome loss': 0.26154903667655005, 'Total loss': 0.26154903667655005}
2022-12-31 11:03:49,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:49,460 INFO:     Epoch: 62
2022-12-31 11:03:51,053 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.378887082139651, 'Total loss': 0.378887082139651} | train loss {'Reaction outcome loss': 0.2568949718231612, 'Total loss': 0.2568949718231612}
2022-12-31 11:03:51,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:51,053 INFO:     Epoch: 63
2022-12-31 11:03:52,682 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3827656244238218, 'Total loss': 0.3827656244238218} | train loss {'Reaction outcome loss': 0.24998456853510054, 'Total loss': 0.24998456853510054}
2022-12-31 11:03:52,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:52,682 INFO:     Epoch: 64
2022-12-31 11:03:54,298 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3993877410888672, 'Total loss': 0.3993877410888672} | train loss {'Reaction outcome loss': 0.2480760227882074, 'Total loss': 0.2480760227882074}
2022-12-31 11:03:54,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:54,299 INFO:     Epoch: 65
2022-12-31 11:03:55,936 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3776180110871792, 'Total loss': 0.3776180110871792} | train loss {'Reaction outcome loss': 0.253885955530374, 'Total loss': 0.253885955530374}
2022-12-31 11:03:55,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:55,936 INFO:     Epoch: 66
2022-12-31 11:03:57,560 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40030150512854257, 'Total loss': 0.40030150512854257} | train loss {'Reaction outcome loss': 0.25126643754217937, 'Total loss': 0.25126643754217937}
2022-12-31 11:03:57,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:57,561 INFO:     Epoch: 67
2022-12-31 11:03:59,164 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38297688215970993, 'Total loss': 0.38297688215970993} | train loss {'Reaction outcome loss': 0.2583692648879968, 'Total loss': 0.2583692648879968}
2022-12-31 11:03:59,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:03:59,164 INFO:     Epoch: 68
2022-12-31 11:04:00,775 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.37202382485071817, 'Total loss': 0.37202382485071817} | train loss {'Reaction outcome loss': 0.3028456451492789, 'Total loss': 0.3028456451492789}
2022-12-31 11:04:00,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:00,775 INFO:     Epoch: 69
2022-12-31 11:04:02,383 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4228702448308468, 'Total loss': 0.4228702448308468} | train loss {'Reaction outcome loss': 0.251690484131214, 'Total loss': 0.251690484131214}
2022-12-31 11:04:02,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:02,384 INFO:     Epoch: 70
2022-12-31 11:04:03,992 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3961366375287374, 'Total loss': 0.3961366375287374} | train loss {'Reaction outcome loss': 0.24227250123458097, 'Total loss': 0.24227250123458097}
2022-12-31 11:04:03,992 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:03,992 INFO:     Epoch: 71
2022-12-31 11:04:05,599 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3966947098573049, 'Total loss': 0.3966947098573049} | train loss {'Reaction outcome loss': 0.24201871083873877, 'Total loss': 0.24201871083873877}
2022-12-31 11:04:05,599 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:05,599 INFO:     Epoch: 72
2022-12-31 11:04:07,195 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3743333677450816, 'Total loss': 0.3743333677450816} | train loss {'Reaction outcome loss': 0.24457647364908844, 'Total loss': 0.24457647364908844}
2022-12-31 11:04:07,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:07,195 INFO:     Epoch: 73
2022-12-31 11:04:08,796 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40089141925175986, 'Total loss': 0.40089141925175986} | train loss {'Reaction outcome loss': 0.24293403716191, 'Total loss': 0.24293403716191}
2022-12-31 11:04:08,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:08,796 INFO:     Epoch: 74
2022-12-31 11:04:10,406 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3839268734057744, 'Total loss': 0.3839268734057744} | train loss {'Reaction outcome loss': 0.292040961743518, 'Total loss': 0.292040961743518}
2022-12-31 11:04:10,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:10,406 INFO:     Epoch: 75
2022-12-31 11:04:12,017 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.36883917103211084, 'Total loss': 0.36883917103211084} | train loss {'Reaction outcome loss': 0.24739121029531394, 'Total loss': 0.24739121029531394}
2022-12-31 11:04:12,017 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:12,017 INFO:     Epoch: 76
2022-12-31 11:04:13,624 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42130786577860513, 'Total loss': 0.42130786577860513} | train loss {'Reaction outcome loss': 0.25129145882733545, 'Total loss': 0.25129145882733545}
2022-12-31 11:04:13,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:13,625 INFO:     Epoch: 77
2022-12-31 11:04:15,219 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3809865991274516, 'Total loss': 0.3809865991274516} | train loss {'Reaction outcome loss': 0.2353038994411506, 'Total loss': 0.2353038994411506}
2022-12-31 11:04:15,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:15,219 INFO:     Epoch: 78
2022-12-31 11:04:16,815 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4110064893960953, 'Total loss': 0.4110064893960953} | train loss {'Reaction outcome loss': 0.23871212917636486, 'Total loss': 0.23871212917636486}
2022-12-31 11:04:16,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:16,815 INFO:     Epoch: 79
2022-12-31 11:04:18,425 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39683796763420104, 'Total loss': 0.39683796763420104} | train loss {'Reaction outcome loss': 0.3036878393031657, 'Total loss': 0.3036878393031657}
2022-12-31 11:04:18,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:18,425 INFO:     Epoch: 80
2022-12-31 11:04:20,043 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.37343999842802683, 'Total loss': 0.37343999842802683} | train loss {'Reaction outcome loss': 0.2504391282504978, 'Total loss': 0.2504391282504978}
2022-12-31 11:04:20,044 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:20,044 INFO:     Epoch: 81
2022-12-31 11:04:21,661 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3741943374276161, 'Total loss': 0.3741943374276161} | train loss {'Reaction outcome loss': 0.23636320574155104, 'Total loss': 0.23636320574155104}
2022-12-31 11:04:21,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:21,661 INFO:     Epoch: 82
2022-12-31 11:04:23,283 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3927031656106313, 'Total loss': 0.3927031656106313} | train loss {'Reaction outcome loss': 0.23591257380093852, 'Total loss': 0.23591257380093852}
2022-12-31 11:04:23,283 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:23,283 INFO:     Epoch: 83
2022-12-31 11:04:24,884 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4006614089012146, 'Total loss': 0.4006614089012146} | train loss {'Reaction outcome loss': 0.23498187108645283, 'Total loss': 0.23498187108645283}
2022-12-31 11:04:24,884 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:24,884 INFO:     Epoch: 84
2022-12-31 11:04:26,498 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38815310212473075, 'Total loss': 0.38815310212473075} | train loss {'Reaction outcome loss': 0.22794978964425947, 'Total loss': 0.22794978964425947}
2022-12-31 11:04:26,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:26,498 INFO:     Epoch: 85
2022-12-31 11:04:28,119 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3825801680485407, 'Total loss': 0.3825801680485407} | train loss {'Reaction outcome loss': 0.23330414582022163, 'Total loss': 0.23330414582022163}
2022-12-31 11:04:28,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:28,119 INFO:     Epoch: 86
2022-12-31 11:04:29,733 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.39463043212890625, 'Total loss': 0.39463043212890625} | train loss {'Reaction outcome loss': 0.2252364992349665, 'Total loss': 0.2252364992349665}
2022-12-31 11:04:29,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:29,733 INFO:     Epoch: 87
2022-12-31 11:04:31,350 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39073690672715505, 'Total loss': 0.39073690672715505} | train loss {'Reaction outcome loss': 0.22894776432329547, 'Total loss': 0.22894776432329547}
2022-12-31 11:04:31,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:31,351 INFO:     Epoch: 88
2022-12-31 11:04:32,956 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.36854826509952543, 'Total loss': 0.36854826509952543} | train loss {'Reaction outcome loss': 0.2252799294318707, 'Total loss': 0.2252799294318707}
2022-12-31 11:04:32,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:32,957 INFO:     Epoch: 89
2022-12-31 11:04:34,556 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.37446151624123253, 'Total loss': 0.37446151624123253} | train loss {'Reaction outcome loss': 0.21792174321350447, 'Total loss': 0.21792174321350447}
2022-12-31 11:04:34,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:34,557 INFO:     Epoch: 90
2022-12-31 11:04:36,153 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3874082843462626, 'Total loss': 0.3874082843462626} | train loss {'Reaction outcome loss': 0.21835166289457592, 'Total loss': 0.21835166289457592}
2022-12-31 11:04:36,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:36,154 INFO:     Epoch: 91
2022-12-31 11:04:37,763 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38274645805358887, 'Total loss': 0.38274645805358887} | train loss {'Reaction outcome loss': 0.21836047709339124, 'Total loss': 0.21836047709339124}
2022-12-31 11:04:37,763 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:37,763 INFO:     Epoch: 92
2022-12-31 11:04:39,370 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.37567778180042904, 'Total loss': 0.37567778180042904} | train loss {'Reaction outcome loss': 0.2182188196246621, 'Total loss': 0.2182188196246621}
2022-12-31 11:04:39,370 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:39,370 INFO:     Epoch: 93
2022-12-31 11:04:40,977 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3835087686777115, 'Total loss': 0.3835087686777115} | train loss {'Reaction outcome loss': 0.22137129653002258, 'Total loss': 0.22137129653002258}
2022-12-31 11:04:40,977 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:40,977 INFO:     Epoch: 94
2022-12-31 11:04:42,586 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.37726887067159015, 'Total loss': 0.37726887067159015} | train loss {'Reaction outcome loss': 0.21169899094282932, 'Total loss': 0.21169899094282932}
2022-12-31 11:04:42,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:42,586 INFO:     Epoch: 95
2022-12-31 11:04:44,180 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3966166024406751, 'Total loss': 0.3966166024406751} | train loss {'Reaction outcome loss': 0.2208544677705504, 'Total loss': 0.2208544677705504}
2022-12-31 11:04:44,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:44,182 INFO:     Epoch: 96
2022-12-31 11:04:45,787 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40106961131095886, 'Total loss': 0.40106961131095886} | train loss {'Reaction outcome loss': 0.20988910135138608, 'Total loss': 0.20988910135138608}
2022-12-31 11:04:45,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:45,787 INFO:     Epoch: 97
2022-12-31 11:04:47,392 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3783136914173762, 'Total loss': 0.3783136914173762} | train loss {'Reaction outcome loss': 0.21269987107160082, 'Total loss': 0.21269987107160082}
2022-12-31 11:04:47,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:47,392 INFO:     Epoch: 98
2022-12-31 11:04:48,997 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3691887935002645, 'Total loss': 0.3691887935002645} | train loss {'Reaction outcome loss': 0.2121958167453936, 'Total loss': 0.2121958167453936}
2022-12-31 11:04:48,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:48,997 INFO:     Epoch: 99
2022-12-31 11:04:50,603 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3568104267120361, 'Total loss': 0.3568104267120361} | train loss {'Reaction outcome loss': 0.22365053358109857, 'Total loss': 0.22365053358109857}
2022-12-31 11:04:50,603 INFO:     Found new best model at epoch 99
2022-12-31 11:04:50,604 INFO:     Best model found after epoch 100 of 100.
2022-12-31 11:04:50,604 INFO:   Done with stage: TRAINING
2022-12-31 11:04:50,604 INFO:   Starting stage: EVALUATION
2022-12-31 11:04:50,731 INFO:   Done with stage: EVALUATION
2022-12-31 11:04:50,732 INFO:   Leaving out SEQ value Fold_5
2022-12-31 11:04:50,744 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 11:04:50,744 INFO:   Starting stage: FEATURE SCALING
2022-12-31 11:04:51,422 INFO:   Done with stage: FEATURE SCALING
2022-12-31 11:04:51,422 INFO:   Starting stage: SCALING TARGETS
2022-12-31 11:04:51,492 INFO:   Done with stage: SCALING TARGETS
2022-12-31 11:04:51,492 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:04:51,492 INFO:     No hyperparam tuning for this model
2022-12-31 11:04:51,493 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:04:51,493 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 11:04:51,493 INFO:     None feature selector for col prot
2022-12-31 11:04:51,493 INFO:     None feature selector for col prot
2022-12-31 11:04:51,494 INFO:     None feature selector for col prot
2022-12-31 11:04:51,494 INFO:     None feature selector for col chem
2022-12-31 11:04:51,494 INFO:     None feature selector for col chem
2022-12-31 11:04:51,494 INFO:     None feature selector for col chem
2022-12-31 11:04:51,494 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 11:04:51,494 INFO:   Starting stage: BUILD MODEL
2022-12-31 11:04:51,496 INFO:     Number of params in model 223921
2022-12-31 11:04:51,499 INFO:   Done with stage: BUILD MODEL
2022-12-31 11:04:51,500 INFO:   Starting stage: TRAINING
2022-12-31 11:04:51,544 INFO:     Val loss before train {'Reaction outcome loss': 0.9774961829185486, 'Total loss': 0.9774961829185486}
2022-12-31 11:04:51,544 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:51,544 INFO:     Epoch: 0
2022-12-31 11:04:53,146 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6771873752276103, 'Total loss': 0.6771873752276103} | train loss {'Reaction outcome loss': 0.8191403939190324, 'Total loss': 0.8191403939190324}
2022-12-31 11:04:53,147 INFO:     Found new best model at epoch 0
2022-12-31 11:04:53,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:53,148 INFO:     Epoch: 1
2022-12-31 11:04:54,760 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5559126694997152, 'Total loss': 0.5559126694997152} | train loss {'Reaction outcome loss': 0.6037063067140132, 'Total loss': 0.6037063067140132}
2022-12-31 11:04:54,760 INFO:     Found new best model at epoch 1
2022-12-31 11:04:54,761 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:54,761 INFO:     Epoch: 2
2022-12-31 11:04:56,372 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5233439604441324, 'Total loss': 0.5233439604441324} | train loss {'Reaction outcome loss': 0.5280609933477877, 'Total loss': 0.5280609933477877}
2022-12-31 11:04:56,373 INFO:     Found new best model at epoch 2
2022-12-31 11:04:56,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:56,374 INFO:     Epoch: 3
2022-12-31 11:04:57,986 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5018606762091319, 'Total loss': 0.5018606762091319} | train loss {'Reaction outcome loss': 0.5080776580942237, 'Total loss': 0.5080776580942237}
2022-12-31 11:04:57,986 INFO:     Found new best model at epoch 3
2022-12-31 11:04:57,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:57,987 INFO:     Epoch: 4
2022-12-31 11:04:59,593 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5012918551762898, 'Total loss': 0.5012918551762898} | train loss {'Reaction outcome loss': 0.49050039117517025, 'Total loss': 0.49050039117517025}
2022-12-31 11:04:59,593 INFO:     Found new best model at epoch 4
2022-12-31 11:04:59,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:04:59,594 INFO:     Epoch: 5
2022-12-31 11:05:01,229 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48359623551368713, 'Total loss': 0.48359623551368713} | train loss {'Reaction outcome loss': 0.4829251914678498, 'Total loss': 0.4829251914678498}
2022-12-31 11:05:01,230 INFO:     Found new best model at epoch 5
2022-12-31 11:05:01,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:01,230 INFO:     Epoch: 6
2022-12-31 11:05:02,825 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47452065348625183, 'Total loss': 0.47452065348625183} | train loss {'Reaction outcome loss': 0.47662535702493647, 'Total loss': 0.47662535702493647}
2022-12-31 11:05:02,826 INFO:     Found new best model at epoch 6
2022-12-31 11:05:02,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:02,827 INFO:     Epoch: 7
2022-12-31 11:05:04,441 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4691733201344808, 'Total loss': 0.4691733201344808} | train loss {'Reaction outcome loss': 0.46722489380233984, 'Total loss': 0.46722489380233984}
2022-12-31 11:05:04,441 INFO:     Found new best model at epoch 7
2022-12-31 11:05:04,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:04,442 INFO:     Epoch: 8
2022-12-31 11:05:06,054 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48192716439565025, 'Total loss': 0.48192716439565025} | train loss {'Reaction outcome loss': 0.4604016029232246, 'Total loss': 0.4604016029232246}
2022-12-31 11:05:06,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:06,055 INFO:     Epoch: 9
2022-12-31 11:05:07,672 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4650955557823181, 'Total loss': 0.4650955557823181} | train loss {'Reaction outcome loss': 0.4515790675736506, 'Total loss': 0.4515790675736506}
2022-12-31 11:05:07,672 INFO:     Found new best model at epoch 9
2022-12-31 11:05:07,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:07,673 INFO:     Epoch: 10
2022-12-31 11:05:09,284 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4623671968777974, 'Total loss': 0.4623671968777974} | train loss {'Reaction outcome loss': 0.44443270063787593, 'Total loss': 0.44443270063787593}
2022-12-31 11:05:09,285 INFO:     Found new best model at epoch 10
2022-12-31 11:05:09,285 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:09,285 INFO:     Epoch: 11
2022-12-31 11:05:10,889 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47097510695457456, 'Total loss': 0.47097510695457456} | train loss {'Reaction outcome loss': 0.4349324117122144, 'Total loss': 0.4349324117122144}
2022-12-31 11:05:10,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:10,890 INFO:     Epoch: 12
2022-12-31 11:05:12,503 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4613653928041458, 'Total loss': 0.4613653928041458} | train loss {'Reaction outcome loss': 0.4293805140773312, 'Total loss': 0.4293805140773312}
2022-12-31 11:05:12,503 INFO:     Found new best model at epoch 12
2022-12-31 11:05:12,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:12,504 INFO:     Epoch: 13
2022-12-31 11:05:14,117 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4391715109348297, 'Total loss': 0.4391715109348297} | train loss {'Reaction outcome loss': 0.42492210399695685, 'Total loss': 0.42492210399695685}
2022-12-31 11:05:14,117 INFO:     Found new best model at epoch 13
2022-12-31 11:05:14,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:14,118 INFO:     Epoch: 14
2022-12-31 11:05:15,747 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42860150933265684, 'Total loss': 0.42860150933265684} | train loss {'Reaction outcome loss': 0.4137759637423801, 'Total loss': 0.4137759637423801}
2022-12-31 11:05:15,749 INFO:     Found new best model at epoch 14
2022-12-31 11:05:15,749 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:15,750 INFO:     Epoch: 15
2022-12-31 11:05:17,393 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44705819884936016, 'Total loss': 0.44705819884936016} | train loss {'Reaction outcome loss': 0.40813969438794717, 'Total loss': 0.40813969438794717}
2022-12-31 11:05:17,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:17,393 INFO:     Epoch: 16
2022-12-31 11:05:18,991 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4523996313412984, 'Total loss': 0.4523996313412984} | train loss {'Reaction outcome loss': 0.40665724496979144, 'Total loss': 0.40665724496979144}
2022-12-31 11:05:18,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:18,991 INFO:     Epoch: 17
2022-12-31 11:05:20,587 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4424038072427114, 'Total loss': 0.4424038072427114} | train loss {'Reaction outcome loss': 0.3952099865954706, 'Total loss': 0.3952099865954706}
2022-12-31 11:05:20,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:20,587 INFO:     Epoch: 18
2022-12-31 11:05:22,202 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4434784114360809, 'Total loss': 0.4434784114360809} | train loss {'Reaction outcome loss': 0.3929791488425826, 'Total loss': 0.3929791488425826}
2022-12-31 11:05:22,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:22,202 INFO:     Epoch: 19
2022-12-31 11:05:23,817 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4237752546866735, 'Total loss': 0.4237752546866735} | train loss {'Reaction outcome loss': 0.3874230861717613, 'Total loss': 0.3874230861717613}
2022-12-31 11:05:23,817 INFO:     Found new best model at epoch 19
2022-12-31 11:05:23,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:23,818 INFO:     Epoch: 20
2022-12-31 11:05:25,435 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42734520335992177, 'Total loss': 0.42734520335992177} | train loss {'Reaction outcome loss': 0.3753898958759618, 'Total loss': 0.3753898958759618}
2022-12-31 11:05:25,435 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:25,435 INFO:     Epoch: 21
2022-12-31 11:05:27,039 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46315936048825584, 'Total loss': 0.46315936048825584} | train loss {'Reaction outcome loss': 0.3697049112634108, 'Total loss': 0.3697049112634108}
2022-12-31 11:05:27,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:27,039 INFO:     Epoch: 22
2022-12-31 11:05:28,679 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4293100694815318, 'Total loss': 0.4293100694815318} | train loss {'Reaction outcome loss': 0.36622070574911064, 'Total loss': 0.36622070574911064}
2022-12-31 11:05:28,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:28,680 INFO:     Epoch: 23
2022-12-31 11:05:30,322 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4214743753274282, 'Total loss': 0.4214743753274282} | train loss {'Reaction outcome loss': 0.35966392455871354, 'Total loss': 0.35966392455871354}
2022-12-31 11:05:30,323 INFO:     Found new best model at epoch 23
2022-12-31 11:05:30,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:30,324 INFO:     Epoch: 24
2022-12-31 11:05:31,963 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44142644306023915, 'Total loss': 0.44142644306023915} | train loss {'Reaction outcome loss': 0.3586632251093964, 'Total loss': 0.3586632251093964}
2022-12-31 11:05:31,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:31,963 INFO:     Epoch: 25
2022-12-31 11:05:33,577 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4432200362284978, 'Total loss': 0.4432200362284978} | train loss {'Reaction outcome loss': 0.3415819363742529, 'Total loss': 0.3415819363742529}
2022-12-31 11:05:33,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:33,577 INFO:     Epoch: 26
2022-12-31 11:05:35,190 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4070855796337128, 'Total loss': 0.4070855796337128} | train loss {'Reaction outcome loss': 0.3413799801700167, 'Total loss': 0.3413799801700167}
2022-12-31 11:05:35,191 INFO:     Found new best model at epoch 26
2022-12-31 11:05:35,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:35,192 INFO:     Epoch: 27
2022-12-31 11:05:36,795 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4322928080956141, 'Total loss': 0.4322928080956141} | train loss {'Reaction outcome loss': 0.3390869548282038, 'Total loss': 0.3390869548282038}
2022-12-31 11:05:36,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:36,795 INFO:     Epoch: 28
2022-12-31 11:05:38,191 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.40424878398577374, 'Total loss': 0.40424878398577374} | train loss {'Reaction outcome loss': 0.3370826003891466, 'Total loss': 0.3370826003891466}
2022-12-31 11:05:38,191 INFO:     Found new best model at epoch 28
2022-12-31 11:05:38,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:38,192 INFO:     Epoch: 29
2022-12-31 11:05:39,297 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4441845943530401, 'Total loss': 0.4441845943530401} | train loss {'Reaction outcome loss': 0.32805884624444726, 'Total loss': 0.32805884624444726}
2022-12-31 11:05:39,297 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:39,297 INFO:     Epoch: 30
2022-12-31 11:05:40,397 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40958766142527264, 'Total loss': 0.40958766142527264} | train loss {'Reaction outcome loss': 0.323454000190277, 'Total loss': 0.323454000190277}
2022-12-31 11:05:40,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:40,397 INFO:     Epoch: 31
2022-12-31 11:05:41,501 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4027022828658422, 'Total loss': 0.4027022828658422} | train loss {'Reaction outcome loss': 0.3142602252723508, 'Total loss': 0.3142602252723508}
2022-12-31 11:05:41,501 INFO:     Found new best model at epoch 31
2022-12-31 11:05:41,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:41,502 INFO:     Epoch: 32
2022-12-31 11:05:42,740 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3901126851638158, 'Total loss': 0.3901126851638158} | train loss {'Reaction outcome loss': 0.31980646678687, 'Total loss': 0.31980646678687}
2022-12-31 11:05:42,740 INFO:     Found new best model at epoch 32
2022-12-31 11:05:42,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:42,741 INFO:     Epoch: 33
2022-12-31 11:05:44,356 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4001434604326884, 'Total loss': 0.4001434604326884} | train loss {'Reaction outcome loss': 0.3127210564400315, 'Total loss': 0.3127210564400315}
2022-12-31 11:05:44,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:44,357 INFO:     Epoch: 34
2022-12-31 11:05:45,970 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.36914680699507396, 'Total loss': 0.36914680699507396} | train loss {'Reaction outcome loss': 0.3056196462941299, 'Total loss': 0.3056196462941299}
2022-12-31 11:05:45,970 INFO:     Found new best model at epoch 34
2022-12-31 11:05:45,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:45,971 INFO:     Epoch: 35
2022-12-31 11:05:47,586 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4245552043120066, 'Total loss': 0.4245552043120066} | train loss {'Reaction outcome loss': 0.2983442805572968, 'Total loss': 0.2983442805572968}
2022-12-31 11:05:47,586 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:47,587 INFO:     Epoch: 36
2022-12-31 11:05:49,200 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41106143593788147, 'Total loss': 0.41106143593788147} | train loss {'Reaction outcome loss': 0.2957475386048913, 'Total loss': 0.2957475386048913}
2022-12-31 11:05:49,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:49,200 INFO:     Epoch: 37
2022-12-31 11:05:50,814 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.38338348592321075, 'Total loss': 0.38338348592321075} | train loss {'Reaction outcome loss': 0.2967326768576453, 'Total loss': 0.2967326768576453}
2022-12-31 11:05:50,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:50,816 INFO:     Epoch: 38
2022-12-31 11:05:52,401 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39955734809239707, 'Total loss': 0.39955734809239707} | train loss {'Reaction outcome loss': 0.2988898395980954, 'Total loss': 0.2988898395980954}
2022-12-31 11:05:52,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:52,401 INFO:     Epoch: 39
2022-12-31 11:05:54,014 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3749659389257431, 'Total loss': 0.3749659389257431} | train loss {'Reaction outcome loss': 0.2856358740922561, 'Total loss': 0.2856358740922561}
2022-12-31 11:05:54,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:54,014 INFO:     Epoch: 40
2022-12-31 11:05:55,632 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39965638518333435, 'Total loss': 0.39965638518333435} | train loss {'Reaction outcome loss': 0.28604388563802957, 'Total loss': 0.28604388563802957}
2022-12-31 11:05:55,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:55,632 INFO:     Epoch: 41
2022-12-31 11:05:57,252 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42785369555155434, 'Total loss': 0.42785369555155434} | train loss {'Reaction outcome loss': 0.275748599912393, 'Total loss': 0.275748599912393}
2022-12-31 11:05:57,253 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:57,253 INFO:     Epoch: 42
2022-12-31 11:05:58,894 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39730562071005504, 'Total loss': 0.39730562071005504} | train loss {'Reaction outcome loss': 0.28252228938500373, 'Total loss': 0.28252228938500373}
2022-12-31 11:05:58,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:05:58,894 INFO:     Epoch: 43
2022-12-31 11:06:00,507 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39735166529814403, 'Total loss': 0.39735166529814403} | train loss {'Reaction outcome loss': 0.2792381880811621, 'Total loss': 0.2792381880811621}
2022-12-31 11:06:00,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:00,508 INFO:     Epoch: 44
2022-12-31 11:06:02,105 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3879265864690145, 'Total loss': 0.3879265864690145} | train loss {'Reaction outcome loss': 0.2741681150117022, 'Total loss': 0.2741681150117022}
2022-12-31 11:06:02,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:02,105 INFO:     Epoch: 45
2022-12-31 11:06:03,746 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4048176015416781, 'Total loss': 0.4048176015416781} | train loss {'Reaction outcome loss': 0.27969203549117816, 'Total loss': 0.27969203549117816}
2022-12-31 11:06:03,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:03,746 INFO:     Epoch: 46
2022-12-31 11:06:05,397 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4067155679066976, 'Total loss': 0.4067155679066976} | train loss {'Reaction outcome loss': 0.2709442433037052, 'Total loss': 0.2709442433037052}
2022-12-31 11:06:05,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:05,397 INFO:     Epoch: 47
2022-12-31 11:06:07,045 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39226480225721994, 'Total loss': 0.39226480225721994} | train loss {'Reaction outcome loss': 0.2673688479480653, 'Total loss': 0.2673688479480653}
2022-12-31 11:06:07,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:07,045 INFO:     Epoch: 48
2022-12-31 11:06:08,662 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40582200288772585, 'Total loss': 0.40582200288772585} | train loss {'Reaction outcome loss': 0.2650104731048999, 'Total loss': 0.2650104731048999}
2022-12-31 11:06:08,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:08,662 INFO:     Epoch: 49
2022-12-31 11:06:10,257 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40745602051417035, 'Total loss': 0.40745602051417035} | train loss {'Reaction outcome loss': 0.2659692451196457, 'Total loss': 0.2659692451196457}
2022-12-31 11:06:10,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:10,258 INFO:     Epoch: 50
2022-12-31 11:06:11,872 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39932156006495156, 'Total loss': 0.39932156006495156} | train loss {'Reaction outcome loss': 0.2677804873079492, 'Total loss': 0.2677804873079492}
2022-12-31 11:06:11,872 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:11,872 INFO:     Epoch: 51
2022-12-31 11:06:13,489 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3877409815788269, 'Total loss': 0.3877409815788269} | train loss {'Reaction outcome loss': 0.26464276478393844, 'Total loss': 0.26464276478393844}
2022-12-31 11:06:13,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:13,489 INFO:     Epoch: 52
2022-12-31 11:06:15,137 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3935861001412074, 'Total loss': 0.3935861001412074} | train loss {'Reaction outcome loss': 0.2629855835427016, 'Total loss': 0.2629855835427016}
2022-12-31 11:06:15,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:15,138 INFO:     Epoch: 53
2022-12-31 11:06:16,745 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.38161078294118245, 'Total loss': 0.38161078294118245} | train loss {'Reaction outcome loss': 0.25960518979208563, 'Total loss': 0.25960518979208563}
2022-12-31 11:06:16,745 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:16,745 INFO:     Epoch: 54
2022-12-31 11:06:18,353 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.394859091937542, 'Total loss': 0.394859091937542} | train loss {'Reaction outcome loss': 0.2555574985752252, 'Total loss': 0.2555574985752252}
2022-12-31 11:06:18,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:18,353 INFO:     Epoch: 55
2022-12-31 11:06:19,914 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39716718196868894, 'Total loss': 0.39716718196868894} | train loss {'Reaction outcome loss': 0.2573631001965879, 'Total loss': 0.2573631001965879}
2022-12-31 11:06:19,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:19,915 INFO:     Epoch: 56
2022-12-31 11:06:21,532 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39159401655197146, 'Total loss': 0.39159401655197146} | train loss {'Reaction outcome loss': 0.24570531572891055, 'Total loss': 0.24570531572891055}
2022-12-31 11:06:21,533 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:21,533 INFO:     Epoch: 57
2022-12-31 11:06:23,177 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3785990263024966, 'Total loss': 0.3785990263024966} | train loss {'Reaction outcome loss': 0.2502135688351595, 'Total loss': 0.2502135688351595}
2022-12-31 11:06:23,177 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:23,177 INFO:     Epoch: 58
2022-12-31 11:06:24,835 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38642570475737253, 'Total loss': 0.38642570475737253} | train loss {'Reaction outcome loss': 0.2589346598094121, 'Total loss': 0.2589346598094121}
2022-12-31 11:06:24,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:24,835 INFO:     Epoch: 59
2022-12-31 11:06:26,498 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40805239975452423, 'Total loss': 0.40805239975452423} | train loss {'Reaction outcome loss': 0.24923180711425383, 'Total loss': 0.24923180711425383}
2022-12-31 11:06:26,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:26,498 INFO:     Epoch: 60
2022-12-31 11:06:28,102 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4146820108095805, 'Total loss': 0.4146820108095805} | train loss {'Reaction outcome loss': 0.24733221370202324, 'Total loss': 0.24733221370202324}
2022-12-31 11:06:28,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:28,103 INFO:     Epoch: 61
2022-12-31 11:06:29,715 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.37794969975948334, 'Total loss': 0.37794969975948334} | train loss {'Reaction outcome loss': 0.2391877789924506, 'Total loss': 0.2391877789924506}
2022-12-31 11:06:29,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:29,715 INFO:     Epoch: 62
2022-12-31 11:06:31,328 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.37474620540936787, 'Total loss': 0.37474620540936787} | train loss {'Reaction outcome loss': 0.24983452209389168, 'Total loss': 0.24983452209389168}
2022-12-31 11:06:31,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:31,329 INFO:     Epoch: 63
2022-12-31 11:06:32,969 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.38869377921024956, 'Total loss': 0.38869377921024956} | train loss {'Reaction outcome loss': 0.24509563906259485, 'Total loss': 0.24509563906259485}
2022-12-31 11:06:32,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:32,970 INFO:     Epoch: 64
2022-12-31 11:06:34,638 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4025949850678444, 'Total loss': 0.4025949850678444} | train loss {'Reaction outcome loss': 0.23899954923223501, 'Total loss': 0.23899954923223501}
2022-12-31 11:06:34,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:34,638 INFO:     Epoch: 65
2022-12-31 11:06:36,237 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3716318070888519, 'Total loss': 0.3716318070888519} | train loss {'Reaction outcome loss': 0.23290350839549454, 'Total loss': 0.23290350839549454}
2022-12-31 11:06:36,238 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:36,238 INFO:     Epoch: 66
2022-12-31 11:06:37,820 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3894565771023432, 'Total loss': 0.3894565771023432} | train loss {'Reaction outcome loss': 0.23895138276182787, 'Total loss': 0.23895138276182787}
2022-12-31 11:06:37,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:37,820 INFO:     Epoch: 67
2022-12-31 11:06:39,434 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40105821788311, 'Total loss': 0.40105821788311} | train loss {'Reaction outcome loss': 0.22879382732596637, 'Total loss': 0.22879382732596637}
2022-12-31 11:06:39,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:39,434 INFO:     Epoch: 68
2022-12-31 11:06:41,048 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.409631684422493, 'Total loss': 0.409631684422493} | train loss {'Reaction outcome loss': 0.23552808095616984, 'Total loss': 0.23552808095616984}
2022-12-31 11:06:41,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:41,049 INFO:     Epoch: 69
2022-12-31 11:06:42,662 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.37289507885773976, 'Total loss': 0.37289507885773976} | train loss {'Reaction outcome loss': 0.23459081509106858, 'Total loss': 0.23459081509106858}
2022-12-31 11:06:42,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:42,662 INFO:     Epoch: 70
2022-12-31 11:06:44,275 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.37604783177375795, 'Total loss': 0.37604783177375795} | train loss {'Reaction outcome loss': 0.2309321457325121, 'Total loss': 0.2309321457325121}
2022-12-31 11:06:44,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:44,276 INFO:     Epoch: 71
2022-12-31 11:06:45,862 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3940629949172338, 'Total loss': 0.3940629949172338} | train loss {'Reaction outcome loss': 0.23679480592078034, 'Total loss': 0.23679480592078034}
2022-12-31 11:06:45,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:45,862 INFO:     Epoch: 72
2022-12-31 11:06:47,505 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.36966095119714737, 'Total loss': 0.36966095119714737} | train loss {'Reaction outcome loss': 0.22742174759453385, 'Total loss': 0.22742174759453385}
2022-12-31 11:06:47,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:47,505 INFO:     Epoch: 73
2022-12-31 11:06:49,156 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3678883989651998, 'Total loss': 0.3678883989651998} | train loss {'Reaction outcome loss': 0.2248007473115564, 'Total loss': 0.2248007473115564}
2022-12-31 11:06:49,156 INFO:     Found new best model at epoch 73
2022-12-31 11:06:49,157 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:49,157 INFO:     Epoch: 74
2022-12-31 11:06:50,771 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3520985047022502, 'Total loss': 0.3520985047022502} | train loss {'Reaction outcome loss': 0.22983218125649307, 'Total loss': 0.22983218125649307}
2022-12-31 11:06:50,771 INFO:     Found new best model at epoch 74
2022-12-31 11:06:50,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:50,772 INFO:     Epoch: 75
2022-12-31 11:06:52,385 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.36922204767664274, 'Total loss': 0.36922204767664274} | train loss {'Reaction outcome loss': 0.22697538891908065, 'Total loss': 0.22697538891908065}
2022-12-31 11:06:52,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:52,386 INFO:     Epoch: 76
2022-12-31 11:06:54,001 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.36512911021709443, 'Total loss': 0.36512911021709443} | train loss {'Reaction outcome loss': 0.23107576719905495, 'Total loss': 0.23107576719905495}
2022-12-31 11:06:54,001 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:54,001 INFO:     Epoch: 77
2022-12-31 11:06:55,573 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3708566983540853, 'Total loss': 0.3708566983540853} | train loss {'Reaction outcome loss': 0.22402768597571643, 'Total loss': 0.22402768597571643}
2022-12-31 11:06:55,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:55,574 INFO:     Epoch: 78
2022-12-31 11:06:57,208 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40295915901660917, 'Total loss': 0.40295915901660917} | train loss {'Reaction outcome loss': 0.2225801821811535, 'Total loss': 0.2225801821811535}
2022-12-31 11:06:57,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:57,208 INFO:     Epoch: 79
2022-12-31 11:06:58,866 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4126781274875005, 'Total loss': 0.4126781274875005} | train loss {'Reaction outcome loss': 0.22723476981428126, 'Total loss': 0.22723476981428126}
2022-12-31 11:06:58,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:06:58,866 INFO:     Epoch: 80
2022-12-31 11:07:00,458 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.38805257777373, 'Total loss': 0.38805257777373} | train loss {'Reaction outcome loss': 0.22197503479540565, 'Total loss': 0.22197503479540565}
2022-12-31 11:07:00,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:00,458 INFO:     Epoch: 81
2022-12-31 11:07:02,107 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40903898179531095, 'Total loss': 0.40903898179531095} | train loss {'Reaction outcome loss': 0.2218130248185207, 'Total loss': 0.2218130248185207}
2022-12-31 11:07:02,107 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:02,107 INFO:     Epoch: 82
2022-12-31 11:07:03,755 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.38625922600428264, 'Total loss': 0.38625922600428264} | train loss {'Reaction outcome loss': 0.22046434084484723, 'Total loss': 0.22046434084484723}
2022-12-31 11:07:03,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:03,756 INFO:     Epoch: 83
2022-12-31 11:07:05,323 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3830632895231247, 'Total loss': 0.3830632895231247} | train loss {'Reaction outcome loss': 0.22031722263523817, 'Total loss': 0.22031722263523817}
2022-12-31 11:07:05,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:05,323 INFO:     Epoch: 84
2022-12-31 11:07:06,936 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3827596535285314, 'Total loss': 0.3827596535285314} | train loss {'Reaction outcome loss': 0.21656373945411148, 'Total loss': 0.21656373945411148}
2022-12-31 11:07:06,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:06,937 INFO:     Epoch: 85
2022-12-31 11:07:08,549 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40349834859371186, 'Total loss': 0.40349834859371186} | train loss {'Reaction outcome loss': 0.2151870772255995, 'Total loss': 0.2151870772255995}
2022-12-31 11:07:08,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:08,549 INFO:     Epoch: 86
2022-12-31 11:07:10,168 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3996442317962646, 'Total loss': 0.3996442317962646} | train loss {'Reaction outcome loss': 0.21547034493099482, 'Total loss': 0.21547034493099482}
2022-12-31 11:07:10,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:10,168 INFO:     Epoch: 87
2022-12-31 11:07:11,820 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4263264079888662, 'Total loss': 0.4263264079888662} | train loss {'Reaction outcome loss': 0.21621838340448343, 'Total loss': 0.21621838340448343}
2022-12-31 11:07:11,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:11,821 INFO:     Epoch: 88
2022-12-31 11:07:13,395 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3990832338730494, 'Total loss': 0.3990832338730494} | train loss {'Reaction outcome loss': 0.20857852014598674, 'Total loss': 0.20857852014598674}
2022-12-31 11:07:13,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:13,395 INFO:     Epoch: 89
2022-12-31 11:07:15,009 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39460790852705635, 'Total loss': 0.39460790852705635} | train loss {'Reaction outcome loss': 0.20755739548388155, 'Total loss': 0.20755739548388155}
2022-12-31 11:07:15,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:15,009 INFO:     Epoch: 90
2022-12-31 11:07:16,616 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3889066283901533, 'Total loss': 0.3889066283901533} | train loss {'Reaction outcome loss': 0.21061969017576332, 'Total loss': 0.21061969017576332}
2022-12-31 11:07:16,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:16,617 INFO:     Epoch: 91
2022-12-31 11:07:18,236 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41603562732537586, 'Total loss': 0.41603562732537586} | train loss {'Reaction outcome loss': 0.21651206801675718, 'Total loss': 0.21651206801675718}
2022-12-31 11:07:18,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:18,236 INFO:     Epoch: 92
2022-12-31 11:07:19,848 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42016084293524425, 'Total loss': 0.42016084293524425} | train loss {'Reaction outcome loss': 0.21094595851706147, 'Total loss': 0.21094595851706147}
2022-12-31 11:07:19,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:19,848 INFO:     Epoch: 93
2022-12-31 11:07:21,460 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3706703851620356, 'Total loss': 0.3706703851620356} | train loss {'Reaction outcome loss': 0.20926141957433, 'Total loss': 0.20926141957433}
2022-12-31 11:07:21,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:21,460 INFO:     Epoch: 94
2022-12-31 11:07:23,042 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4124746630589167, 'Total loss': 0.4124746630589167} | train loss {'Reaction outcome loss': 0.20961978377955914, 'Total loss': 0.20961978377955914}
2022-12-31 11:07:23,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:23,043 INFO:     Epoch: 95
2022-12-31 11:07:24,661 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.38748430609703066, 'Total loss': 0.38748430609703066} | train loss {'Reaction outcome loss': 0.2060599935708386, 'Total loss': 0.2060599935708386}
2022-12-31 11:07:24,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:24,661 INFO:     Epoch: 96
2022-12-31 11:07:26,322 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.38876636425654093, 'Total loss': 0.38876636425654093} | train loss {'Reaction outcome loss': 0.21689831119851086, 'Total loss': 0.21689831119851086}
2022-12-31 11:07:26,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:26,322 INFO:     Epoch: 97
2022-12-31 11:07:27,938 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3707932323217392, 'Total loss': 0.3707932323217392} | train loss {'Reaction outcome loss': 0.20259530535001402, 'Total loss': 0.20259530535001402}
2022-12-31 11:07:27,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:27,938 INFO:     Epoch: 98
2022-12-31 11:07:29,567 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39834601283073423, 'Total loss': 0.39834601283073423} | train loss {'Reaction outcome loss': 0.2104914358511083, 'Total loss': 0.2104914358511083}
2022-12-31 11:07:29,568 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:29,568 INFO:     Epoch: 99
2022-12-31 11:07:31,190 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4110735237598419, 'Total loss': 0.4110735237598419} | train loss {'Reaction outcome loss': 0.20624320435636956, 'Total loss': 0.20624320435636956}
2022-12-31 11:07:31,190 INFO:     Best model found after epoch 75 of 100.
2022-12-31 11:07:31,191 INFO:   Done with stage: TRAINING
2022-12-31 11:07:31,191 INFO:   Starting stage: EVALUATION
2022-12-31 11:07:31,310 INFO:   Done with stage: EVALUATION
2022-12-31 11:07:31,310 INFO:   Leaving out SEQ value Fold_6
2022-12-31 11:07:31,322 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 11:07:31,322 INFO:   Starting stage: FEATURE SCALING
2022-12-31 11:07:31,971 INFO:   Done with stage: FEATURE SCALING
2022-12-31 11:07:31,971 INFO:   Starting stage: SCALING TARGETS
2022-12-31 11:07:32,040 INFO:   Done with stage: SCALING TARGETS
2022-12-31 11:07:32,040 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:07:32,040 INFO:     No hyperparam tuning for this model
2022-12-31 11:07:32,040 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:07:32,040 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 11:07:32,041 INFO:     None feature selector for col prot
2022-12-31 11:07:32,041 INFO:     None feature selector for col prot
2022-12-31 11:07:32,041 INFO:     None feature selector for col prot
2022-12-31 11:07:32,042 INFO:     None feature selector for col chem
2022-12-31 11:07:32,042 INFO:     None feature selector for col chem
2022-12-31 11:07:32,042 INFO:     None feature selector for col chem
2022-12-31 11:07:32,042 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 11:07:32,042 INFO:   Starting stage: BUILD MODEL
2022-12-31 11:07:32,044 INFO:     Number of params in model 223921
2022-12-31 11:07:32,047 INFO:   Done with stage: BUILD MODEL
2022-12-31 11:07:32,047 INFO:   Starting stage: TRAINING
2022-12-31 11:07:32,092 INFO:     Val loss before train {'Reaction outcome loss': 0.984417716662089, 'Total loss': 0.984417716662089}
2022-12-31 11:07:32,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:32,092 INFO:     Epoch: 0
2022-12-31 11:07:33,698 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6434049765268962, 'Total loss': 0.6434049765268962} | train loss {'Reaction outcome loss': 0.8231082691446595, 'Total loss': 0.8231082691446595}
2022-12-31 11:07:33,698 INFO:     Found new best model at epoch 0
2022-12-31 11:07:33,699 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:33,699 INFO:     Epoch: 1
2022-12-31 11:07:35,306 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5129867792129517, 'Total loss': 0.5129867792129517} | train loss {'Reaction outcome loss': 0.6028088091170766, 'Total loss': 0.6028088091170766}
2022-12-31 11:07:35,306 INFO:     Found new best model at epoch 1
2022-12-31 11:07:35,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:35,307 INFO:     Epoch: 2
2022-12-31 11:07:36,914 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5178835233052571, 'Total loss': 0.5178835233052571} | train loss {'Reaction outcome loss': 0.5324117984568727, 'Total loss': 0.5324117984568727}
2022-12-31 11:07:36,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:36,914 INFO:     Epoch: 3
2022-12-31 11:07:38,521 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4940709958473841, 'Total loss': 0.4940709958473841} | train loss {'Reaction outcome loss': 0.516122323618839, 'Total loss': 0.516122323618839}
2022-12-31 11:07:38,521 INFO:     Found new best model at epoch 3
2022-12-31 11:07:38,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:38,522 INFO:     Epoch: 4
2022-12-31 11:07:40,075 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49233601490656537, 'Total loss': 0.49233601490656537} | train loss {'Reaction outcome loss': 0.4825787803789169, 'Total loss': 0.4825787803789169}
2022-12-31 11:07:40,075 INFO:     Found new best model at epoch 4
2022-12-31 11:07:40,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:40,076 INFO:     Epoch: 5
2022-12-31 11:07:41,683 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4748684674501419, 'Total loss': 0.4748684674501419} | train loss {'Reaction outcome loss': 0.48118829586799594, 'Total loss': 0.48118829586799594}
2022-12-31 11:07:41,683 INFO:     Found new best model at epoch 5
2022-12-31 11:07:41,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:41,684 INFO:     Epoch: 6
2022-12-31 11:07:43,293 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4932940423488617, 'Total loss': 0.4932940423488617} | train loss {'Reaction outcome loss': 0.5019350509712661, 'Total loss': 0.5019350509712661}
2022-12-31 11:07:43,293 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:43,294 INFO:     Epoch: 7
2022-12-31 11:07:44,904 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47163692613442737, 'Total loss': 0.47163692613442737} | train loss {'Reaction outcome loss': 0.4670777953339762, 'Total loss': 0.4670777953339762}
2022-12-31 11:07:44,904 INFO:     Found new best model at epoch 7
2022-12-31 11:07:44,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:44,905 INFO:     Epoch: 8
2022-12-31 11:07:46,517 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.465578497449557, 'Total loss': 0.465578497449557} | train loss {'Reaction outcome loss': 0.4444224185047104, 'Total loss': 0.4444224185047104}
2022-12-31 11:07:46,517 INFO:     Found new best model at epoch 8
2022-12-31 11:07:46,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:46,518 INFO:     Epoch: 9
2022-12-31 11:07:48,128 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45428015987078346, 'Total loss': 0.45428015987078346} | train loss {'Reaction outcome loss': 0.4378837675625539, 'Total loss': 0.4378837675625539}
2022-12-31 11:07:48,128 INFO:     Found new best model at epoch 9
2022-12-31 11:07:48,129 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:48,129 INFO:     Epoch: 10
2022-12-31 11:07:49,683 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4884067098299662, 'Total loss': 0.4884067098299662} | train loss {'Reaction outcome loss': 0.4352030993871175, 'Total loss': 0.4352030993871175}
2022-12-31 11:07:49,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:49,684 INFO:     Epoch: 11
2022-12-31 11:07:51,340 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46749228139718374, 'Total loss': 0.46749228139718374} | train loss {'Reaction outcome loss': 0.4271881469249965, 'Total loss': 0.4271881469249965}
2022-12-31 11:07:51,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:51,340 INFO:     Epoch: 12
2022-12-31 11:07:52,992 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46870733896891276, 'Total loss': 0.46870733896891276} | train loss {'Reaction outcome loss': 0.4245682252651971, 'Total loss': 0.4245682252651971}
2022-12-31 11:07:52,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:52,994 INFO:     Epoch: 13
2022-12-31 11:07:54,587 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4712308088938395, 'Total loss': 0.4712308088938395} | train loss {'Reaction outcome loss': 0.42286806310648506, 'Total loss': 0.42286806310648506}
2022-12-31 11:07:54,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:54,588 INFO:     Epoch: 14
2022-12-31 11:07:56,202 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4619923690954844, 'Total loss': 0.4619923690954844} | train loss {'Reaction outcome loss': 0.4174094550681479, 'Total loss': 0.4174094550681479}
2022-12-31 11:07:56,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:56,202 INFO:     Epoch: 15
2022-12-31 11:07:57,812 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42651877254247667, 'Total loss': 0.42651877254247667} | train loss {'Reaction outcome loss': 0.4097106944479189, 'Total loss': 0.4097106944479189}
2022-12-31 11:07:57,812 INFO:     Found new best model at epoch 15
2022-12-31 11:07:57,813 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:57,813 INFO:     Epoch: 16
2022-12-31 11:07:59,388 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4595940967400869, 'Total loss': 0.4595940967400869} | train loss {'Reaction outcome loss': 0.4064925370764905, 'Total loss': 0.4064925370764905}
2022-12-31 11:07:59,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:07:59,389 INFO:     Epoch: 17
2022-12-31 11:08:00,980 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42640497386455534, 'Total loss': 0.42640497386455534} | train loss {'Reaction outcome loss': 0.395403442789625, 'Total loss': 0.395403442789625}
2022-12-31 11:08:00,980 INFO:     Found new best model at epoch 17
2022-12-31 11:08:00,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:00,981 INFO:     Epoch: 18
2022-12-31 11:08:02,608 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4507761001586914, 'Total loss': 0.4507761001586914} | train loss {'Reaction outcome loss': 0.39048711777381273, 'Total loss': 0.39048711777381273}
2022-12-31 11:08:02,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:02,608 INFO:     Epoch: 19
2022-12-31 11:08:04,211 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4452508568763733, 'Total loss': 0.4452508568763733} | train loss {'Reaction outcome loss': 0.3923335348431399, 'Total loss': 0.3923335348431399}
2022-12-31 11:08:04,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:04,211 INFO:     Epoch: 20
2022-12-31 11:08:05,851 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44703827301661175, 'Total loss': 0.44703827301661175} | train loss {'Reaction outcome loss': 0.37945086367266334, 'Total loss': 0.37945086367266334}
2022-12-31 11:08:05,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:05,851 INFO:     Epoch: 21
2022-12-31 11:08:07,393 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43983569244543713, 'Total loss': 0.43983569244543713} | train loss {'Reaction outcome loss': 0.3794899504105358, 'Total loss': 0.3794899504105358}
2022-12-31 11:08:07,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:07,393 INFO:     Epoch: 22
2022-12-31 11:08:09,002 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.468345053990682, 'Total loss': 0.468345053990682} | train loss {'Reaction outcome loss': 0.3684310532812758, 'Total loss': 0.3684310532812758}
2022-12-31 11:08:09,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:09,003 INFO:     Epoch: 23
2022-12-31 11:08:10,611 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4395052274068197, 'Total loss': 0.4395052274068197} | train loss {'Reaction outcome loss': 0.3662925881449221, 'Total loss': 0.3662925881449221}
2022-12-31 11:08:10,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:10,612 INFO:     Epoch: 24
2022-12-31 11:08:12,219 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45077805817127226, 'Total loss': 0.45077805817127226} | train loss {'Reaction outcome loss': 0.35805330767513055, 'Total loss': 0.35805330767513055}
2022-12-31 11:08:12,220 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:12,220 INFO:     Epoch: 25
2022-12-31 11:08:13,826 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4532868246237437, 'Total loss': 0.4532868246237437} | train loss {'Reaction outcome loss': 0.3491367161125485, 'Total loss': 0.3491367161125485}
2022-12-31 11:08:13,826 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:13,827 INFO:     Epoch: 26
2022-12-31 11:08:15,432 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45009325047334037, 'Total loss': 0.45009325047334037} | train loss {'Reaction outcome loss': 0.352764659014571, 'Total loss': 0.352764659014571}
2022-12-31 11:08:15,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:15,433 INFO:     Epoch: 27
2022-12-31 11:08:16,966 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41541686455408733, 'Total loss': 0.41541686455408733} | train loss {'Reaction outcome loss': 0.34332249029788386, 'Total loss': 0.34332249029788386}
2022-12-31 11:08:16,966 INFO:     Found new best model at epoch 27
2022-12-31 11:08:16,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:16,967 INFO:     Epoch: 28
2022-12-31 11:08:18,606 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4299506147702535, 'Total loss': 0.4299506147702535} | train loss {'Reaction outcome loss': 0.3446530591531157, 'Total loss': 0.3446530591531157}
2022-12-31 11:08:18,607 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:18,607 INFO:     Epoch: 29
2022-12-31 11:08:20,213 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44675741096337634, 'Total loss': 0.44675741096337634} | train loss {'Reaction outcome loss': 0.34543864256229956, 'Total loss': 0.34543864256229956}
2022-12-31 11:08:20,213 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:20,213 INFO:     Epoch: 30
2022-12-31 11:08:21,820 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4516367574532827, 'Total loss': 0.4516367574532827} | train loss {'Reaction outcome loss': 0.3434240101791068, 'Total loss': 0.3434240101791068}
2022-12-31 11:08:21,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:21,820 INFO:     Epoch: 31
2022-12-31 11:08:23,427 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44042469064394635, 'Total loss': 0.44042469064394635} | train loss {'Reaction outcome loss': 0.3259023617829898, 'Total loss': 0.3259023617829898}
2022-12-31 11:08:23,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:23,427 INFO:     Epoch: 32
2022-12-31 11:08:25,031 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4427412728468577, 'Total loss': 0.4427412728468577} | train loss {'Reaction outcome loss': 0.3204191009635511, 'Total loss': 0.3204191009635511}
2022-12-31 11:08:25,031 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:25,031 INFO:     Epoch: 33
2022-12-31 11:08:26,586 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44058359464009605, 'Total loss': 0.44058359464009605} | train loss {'Reaction outcome loss': 0.3123957634281818, 'Total loss': 0.3123957634281818}
2022-12-31 11:08:26,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:26,587 INFO:     Epoch: 34
2022-12-31 11:08:28,239 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4192004332939784, 'Total loss': 0.4192004332939784} | train loss {'Reaction outcome loss': 0.3101815521334082, 'Total loss': 0.3101815521334082}
2022-12-31 11:08:28,239 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:28,239 INFO:     Epoch: 35
2022-12-31 11:08:29,878 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.400806271036466, 'Total loss': 0.400806271036466} | train loss {'Reaction outcome loss': 0.3184517246293093, 'Total loss': 0.3184517246293093}
2022-12-31 11:08:29,879 INFO:     Found new best model at epoch 35
2022-12-31 11:08:29,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:29,880 INFO:     Epoch: 36
2022-12-31 11:08:31,529 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46354314088821413, 'Total loss': 0.46354314088821413} | train loss {'Reaction outcome loss': 0.30182286962298205, 'Total loss': 0.30182286962298205}
2022-12-31 11:08:31,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:31,529 INFO:     Epoch: 37
2022-12-31 11:08:33,155 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4270893474419912, 'Total loss': 0.4270893474419912} | train loss {'Reaction outcome loss': 0.3020482947353942, 'Total loss': 0.3020482947353942}
2022-12-31 11:08:33,155 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:33,155 INFO:     Epoch: 38
2022-12-31 11:08:34,714 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40407303273677825, 'Total loss': 0.40407303273677825} | train loss {'Reaction outcome loss': 0.29787834473899094, 'Total loss': 0.29787834473899094}
2022-12-31 11:08:34,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:34,714 INFO:     Epoch: 39
2022-12-31 11:08:36,354 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40202326079209644, 'Total loss': 0.40202326079209644} | train loss {'Reaction outcome loss': 0.2938580691968483, 'Total loss': 0.2938580691968483}
2022-12-31 11:08:36,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:36,355 INFO:     Epoch: 40
2022-12-31 11:08:37,971 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42700164318084716, 'Total loss': 0.42700164318084716} | train loss {'Reaction outcome loss': 0.2915927681764963, 'Total loss': 0.2915927681764963}
2022-12-31 11:08:37,971 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:37,971 INFO:     Epoch: 41
2022-12-31 11:08:39,581 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4028109629948934, 'Total loss': 0.4028109629948934} | train loss {'Reaction outcome loss': 0.2841484105734128, 'Total loss': 0.2841484105734128}
2022-12-31 11:08:39,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:39,582 INFO:     Epoch: 42
2022-12-31 11:08:41,189 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3899915764729182, 'Total loss': 0.3899915764729182} | train loss {'Reaction outcome loss': 0.291859155078756, 'Total loss': 0.291859155078756}
2022-12-31 11:08:41,189 INFO:     Found new best model at epoch 42
2022-12-31 11:08:41,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:41,190 INFO:     Epoch: 43
2022-12-31 11:08:42,799 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41239167054494225, 'Total loss': 0.41239167054494225} | train loss {'Reaction outcome loss': 0.27634736637612706, 'Total loss': 0.27634736637612706}
2022-12-31 11:08:42,799 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:42,799 INFO:     Epoch: 44
2022-12-31 11:08:44,333 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.39988917907079063, 'Total loss': 0.39988917907079063} | train loss {'Reaction outcome loss': 0.2791318998510099, 'Total loss': 0.2791318998510099}
2022-12-31 11:08:44,333 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:44,333 INFO:     Epoch: 45
2022-12-31 11:08:45,945 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39729772210121156, 'Total loss': 0.39729772210121156} | train loss {'Reaction outcome loss': 0.28010700383911963, 'Total loss': 0.28010700383911963}
2022-12-31 11:08:45,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:45,946 INFO:     Epoch: 46
2022-12-31 11:08:47,555 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46366581320762634, 'Total loss': 0.46366581320762634} | train loss {'Reaction outcome loss': 0.272572801115187, 'Total loss': 0.272572801115187}
2022-12-31 11:08:47,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:47,555 INFO:     Epoch: 47
2022-12-31 11:08:49,164 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42103682160377504, 'Total loss': 0.42103682160377504} | train loss {'Reaction outcome loss': 0.27158868945865094, 'Total loss': 0.27158868945865094}
2022-12-31 11:08:49,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:49,165 INFO:     Epoch: 48
2022-12-31 11:08:50,779 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39918562322854995, 'Total loss': 0.39918562322854995} | train loss {'Reaction outcome loss': 0.2742252848414785, 'Total loss': 0.2742252848414785}
2022-12-31 11:08:50,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:50,779 INFO:     Epoch: 49
2022-12-31 11:08:52,392 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4259562383095423, 'Total loss': 0.4259562383095423} | train loss {'Reaction outcome loss': 0.2635815521007053, 'Total loss': 0.2635815521007053}
2022-12-31 11:08:52,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:52,392 INFO:     Epoch: 50
2022-12-31 11:08:53,954 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4075511445601781, 'Total loss': 0.4075511445601781} | train loss {'Reaction outcome loss': 0.2617162421330526, 'Total loss': 0.2617162421330526}
2022-12-31 11:08:53,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:53,954 INFO:     Epoch: 51
2022-12-31 11:08:55,561 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4160715440909068, 'Total loss': 0.4160715440909068} | train loss {'Reaction outcome loss': 0.2598998777406371, 'Total loss': 0.2598998777406371}
2022-12-31 11:08:55,561 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:55,561 INFO:     Epoch: 52
2022-12-31 11:08:57,169 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4004137833913167, 'Total loss': 0.4004137833913167} | train loss {'Reaction outcome loss': 0.25884693414242804, 'Total loss': 0.25884693414242804}
2022-12-31 11:08:57,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:57,169 INFO:     Epoch: 53
2022-12-31 11:08:58,779 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43448698123296103, 'Total loss': 0.43448698123296103} | train loss {'Reaction outcome loss': 0.273543538444716, 'Total loss': 0.273543538444716}
2022-12-31 11:08:58,779 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:08:58,779 INFO:     Epoch: 54
2022-12-31 11:09:00,412 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4174530724684397, 'Total loss': 0.4174530724684397} | train loss {'Reaction outcome loss': 0.3899150266425104, 'Total loss': 0.3899150266425104}
2022-12-31 11:09:00,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:00,413 INFO:     Epoch: 55
2022-12-31 11:09:01,945 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44972014129161836, 'Total loss': 0.44972014129161836} | train loss {'Reaction outcome loss': 0.289475749368253, 'Total loss': 0.289475749368253}
2022-12-31 11:09:01,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:01,945 INFO:     Epoch: 56
2022-12-31 11:09:03,579 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42216171125570934, 'Total loss': 0.42216171125570934} | train loss {'Reaction outcome loss': 0.2947754886919174, 'Total loss': 0.2947754886919174}
2022-12-31 11:09:03,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:03,579 INFO:     Epoch: 57
2022-12-31 11:09:05,188 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.37167217607299485, 'Total loss': 0.37167217607299485} | train loss {'Reaction outcome loss': 0.2659744838576602, 'Total loss': 0.2659744838576602}
2022-12-31 11:09:05,189 INFO:     Found new best model at epoch 57
2022-12-31 11:09:05,190 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:05,190 INFO:     Epoch: 58
2022-12-31 11:09:06,797 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4206831763188044, 'Total loss': 0.4206831763188044} | train loss {'Reaction outcome loss': 0.2913937662319834, 'Total loss': 0.2913937662319834}
2022-12-31 11:09:06,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:06,797 INFO:     Epoch: 59
2022-12-31 11:09:08,408 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3833787391583125, 'Total loss': 0.3833787391583125} | train loss {'Reaction outcome loss': 0.25720062636073504, 'Total loss': 0.25720062636073504}
2022-12-31 11:09:08,408 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:08,409 INFO:     Epoch: 60
2022-12-31 11:09:10,019 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41092379788557687, 'Total loss': 0.41092379788557687} | train loss {'Reaction outcome loss': 0.26866272982695827, 'Total loss': 0.26866272982695827}
2022-12-31 11:09:10,019 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:10,019 INFO:     Epoch: 61
2022-12-31 11:09:11,554 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42699048618475594, 'Total loss': 0.42699048618475594} | train loss {'Reaction outcome loss': 0.25998251638889813, 'Total loss': 0.25998251638889813}
2022-12-31 11:09:11,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:11,555 INFO:     Epoch: 62
2022-12-31 11:09:13,166 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40922469943761824, 'Total loss': 0.40922469943761824} | train loss {'Reaction outcome loss': 0.24948229018532994, 'Total loss': 0.24948229018532994}
2022-12-31 11:09:13,166 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:13,166 INFO:     Epoch: 63
2022-12-31 11:09:14,780 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39040214543541274, 'Total loss': 0.39040214543541274} | train loss {'Reaction outcome loss': 0.24240896677551116, 'Total loss': 0.24240896677551116}
2022-12-31 11:09:14,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:14,780 INFO:     Epoch: 64
2022-12-31 11:09:16,395 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4190439512332281, 'Total loss': 0.4190439512332281} | train loss {'Reaction outcome loss': 0.24434831957710296, 'Total loss': 0.24434831957710296}
2022-12-31 11:09:16,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:16,395 INFO:     Epoch: 65
2022-12-31 11:09:18,008 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4121411701043447, 'Total loss': 0.4121411701043447} | train loss {'Reaction outcome loss': 0.23729874217938035, 'Total loss': 0.23729874217938035}
2022-12-31 11:09:18,008 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:18,008 INFO:     Epoch: 66
2022-12-31 11:09:19,570 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41192906300226845, 'Total loss': 0.41192906300226845} | train loss {'Reaction outcome loss': 0.24012935407069785, 'Total loss': 0.24012935407069785}
2022-12-31 11:09:19,570 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:19,570 INFO:     Epoch: 67
2022-12-31 11:09:21,150 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3886165787776311, 'Total loss': 0.3886165787776311} | train loss {'Reaction outcome loss': 0.24045320503759338, 'Total loss': 0.24045320503759338}
2022-12-31 11:09:21,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:21,150 INFO:     Epoch: 68
2022-12-31 11:09:22,762 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4455122768878937, 'Total loss': 0.4455122768878937} | train loss {'Reaction outcome loss': 0.23284305680496892, 'Total loss': 0.23284305680496892}
2022-12-31 11:09:22,762 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:22,762 INFO:     Epoch: 69
2022-12-31 11:09:24,372 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41456059614817303, 'Total loss': 0.41456059614817303} | train loss {'Reaction outcome loss': 0.24010993894594518, 'Total loss': 0.24010993894594518}
2022-12-31 11:09:24,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:24,373 INFO:     Epoch: 70
2022-12-31 11:09:26,016 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45123246908187864, 'Total loss': 0.45123246908187864} | train loss {'Reaction outcome loss': 0.2777778573985468, 'Total loss': 0.2777778573985468}
2022-12-31 11:09:26,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:26,016 INFO:     Epoch: 71
2022-12-31 11:09:27,674 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3995568484067917, 'Total loss': 0.3995568484067917} | train loss {'Reaction outcome loss': 0.2389689789195973, 'Total loss': 0.2389689789195973}
2022-12-31 11:09:27,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:27,674 INFO:     Epoch: 72
2022-12-31 11:09:29,200 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44930979013442995, 'Total loss': 0.44930979013442995} | train loss {'Reaction outcome loss': 0.23421721002744997, 'Total loss': 0.23421721002744997}
2022-12-31 11:09:29,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:29,200 INFO:     Epoch: 73
2022-12-31 11:09:30,835 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3998129963874817, 'Total loss': 0.3998129963874817} | train loss {'Reaction outcome loss': 0.2318896927965292, 'Total loss': 0.2318896927965292}
2022-12-31 11:09:30,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:30,835 INFO:     Epoch: 74
2022-12-31 11:09:32,458 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3881762703259786, 'Total loss': 0.3881762703259786} | train loss {'Reaction outcome loss': 0.26074715063441545, 'Total loss': 0.26074715063441545}
2022-12-31 11:09:32,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:32,458 INFO:     Epoch: 75
2022-12-31 11:09:34,102 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3932664646456639, 'Total loss': 0.3932664646456639} | train loss {'Reaction outcome loss': 0.2421348298886332, 'Total loss': 0.2421348298886332}
2022-12-31 11:09:34,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:34,102 INFO:     Epoch: 76
2022-12-31 11:09:35,755 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.37122024645407997, 'Total loss': 0.37122024645407997} | train loss {'Reaction outcome loss': 0.22849622821651291, 'Total loss': 0.22849622821651291}
2022-12-31 11:09:35,756 INFO:     Found new best model at epoch 76
2022-12-31 11:09:35,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:35,757 INFO:     Epoch: 77
2022-12-31 11:09:37,379 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39090393781661986, 'Total loss': 0.39090393781661986} | train loss {'Reaction outcome loss': 0.22544818935389427, 'Total loss': 0.22544818935389427}
2022-12-31 11:09:37,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:37,379 INFO:     Epoch: 78
2022-12-31 11:09:38,919 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4122275158762932, 'Total loss': 0.4122275158762932} | train loss {'Reaction outcome loss': 0.22362966798380882, 'Total loss': 0.22362966798380882}
2022-12-31 11:09:38,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:38,920 INFO:     Epoch: 79
2022-12-31 11:09:40,569 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39725111722946166, 'Total loss': 0.39725111722946166} | train loss {'Reaction outcome loss': 0.22119762498777415, 'Total loss': 0.22119762498777415}
2022-12-31 11:09:40,569 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:40,570 INFO:     Epoch: 80
2022-12-31 11:09:42,182 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40592454572518666, 'Total loss': 0.40592454572518666} | train loss {'Reaction outcome loss': 0.24321894070295536, 'Total loss': 0.24321894070295536}
2022-12-31 11:09:42,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:42,183 INFO:     Epoch: 81
2022-12-31 11:09:43,833 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4174515922864278, 'Total loss': 0.4174515922864278} | train loss {'Reaction outcome loss': 0.22365564258391227, 'Total loss': 0.22365564258391227}
2022-12-31 11:09:43,833 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:43,833 INFO:     Epoch: 82
2022-12-31 11:09:45,489 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.38633008499940236, 'Total loss': 0.38633008499940236} | train loss {'Reaction outcome loss': 0.21392319004930407, 'Total loss': 0.21392319004930407}
2022-12-31 11:09:45,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:45,489 INFO:     Epoch: 83
2022-12-31 11:09:47,083 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3892404779791832, 'Total loss': 0.3892404779791832} | train loss {'Reaction outcome loss': 0.2128132594548399, 'Total loss': 0.2128132594548399}
2022-12-31 11:09:47,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:47,083 INFO:     Epoch: 84
2022-12-31 11:09:48,710 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4323906242847443, 'Total loss': 0.4323906242847443} | train loss {'Reaction outcome loss': 0.2153502288603467, 'Total loss': 0.2153502288603467}
2022-12-31 11:09:48,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:48,711 INFO:     Epoch: 85
2022-12-31 11:09:50,335 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42443559169769285, 'Total loss': 0.42443559169769285} | train loss {'Reaction outcome loss': 0.21410737644064415, 'Total loss': 0.21410737644064415}
2022-12-31 11:09:50,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:50,336 INFO:     Epoch: 86
2022-12-31 11:09:51,988 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38186255991458895, 'Total loss': 0.38186255991458895} | train loss {'Reaction outcome loss': 0.21612863838537663, 'Total loss': 0.21612863838537663}
2022-12-31 11:09:51,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:51,988 INFO:     Epoch: 87
2022-12-31 11:09:53,580 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4218374898036321, 'Total loss': 0.4218374898036321} | train loss {'Reaction outcome loss': 0.20937706972978523, 'Total loss': 0.20937706972978523}
2022-12-31 11:09:53,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:53,581 INFO:     Epoch: 88
2022-12-31 11:09:55,220 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3984788248936335, 'Total loss': 0.3984788248936335} | train loss {'Reaction outcome loss': 0.2122339391988108, 'Total loss': 0.2122339391988108}
2022-12-31 11:09:55,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:55,221 INFO:     Epoch: 89
2022-12-31 11:09:56,782 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4329502910375595, 'Total loss': 0.4329502910375595} | train loss {'Reaction outcome loss': 0.21023499514178737, 'Total loss': 0.21023499514178737}
2022-12-31 11:09:56,782 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:56,782 INFO:     Epoch: 90
2022-12-31 11:09:58,392 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41847757399082186, 'Total loss': 0.41847757399082186} | train loss {'Reaction outcome loss': 0.2141365927890402, 'Total loss': 0.2141365927890402}
2022-12-31 11:09:58,392 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:09:58,392 INFO:     Epoch: 91
2022-12-31 11:10:00,001 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4159463346004486, 'Total loss': 0.4159463346004486} | train loss {'Reaction outcome loss': 0.20990834548275164, 'Total loss': 0.20990834548275164}
2022-12-31 11:10:00,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:00,002 INFO:     Epoch: 92
2022-12-31 11:10:01,612 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.42090876897176105, 'Total loss': 0.42090876897176105} | train loss {'Reaction outcome loss': 0.2128482596574189, 'Total loss': 0.2128482596574189}
2022-12-31 11:10:01,612 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:01,612 INFO:     Epoch: 93
2022-12-31 11:10:03,222 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3982024349272251, 'Total loss': 0.3982024349272251} | train loss {'Reaction outcome loss': 0.20735048809075268, 'Total loss': 0.20735048809075268}
2022-12-31 11:10:03,223 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:03,223 INFO:     Epoch: 94
2022-12-31 11:10:04,832 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40837524831295013, 'Total loss': 0.40837524831295013} | train loss {'Reaction outcome loss': 0.20154699166237877, 'Total loss': 0.20154699166237877}
2022-12-31 11:10:04,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:04,832 INFO:     Epoch: 95
2022-12-31 11:10:06,395 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4262436384956042, 'Total loss': 0.4262436384956042} | train loss {'Reaction outcome loss': 0.20823250957967146, 'Total loss': 0.20823250957967146}
2022-12-31 11:10:06,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:06,396 INFO:     Epoch: 96
2022-12-31 11:10:07,986 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39688492187609276, 'Total loss': 0.39688492187609276} | train loss {'Reaction outcome loss': 0.20914450187937936, 'Total loss': 0.20914450187937936}
2022-12-31 11:10:07,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:07,986 INFO:     Epoch: 97
2022-12-31 11:10:09,627 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3988684043288231, 'Total loss': 0.3988684043288231} | train loss {'Reaction outcome loss': 0.21618025788146938, 'Total loss': 0.21618025788146938}
2022-12-31 11:10:09,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:09,627 INFO:     Epoch: 98
2022-12-31 11:10:11,215 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4188677797714869, 'Total loss': 0.4188677797714869} | train loss {'Reaction outcome loss': 0.1983487167022574, 'Total loss': 0.1983487167022574}
2022-12-31 11:10:11,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:11,215 INFO:     Epoch: 99
2022-12-31 11:10:12,850 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44393217464288076, 'Total loss': 0.44393217464288076} | train loss {'Reaction outcome loss': 0.20372071167524985, 'Total loss': 0.20372071167524985}
2022-12-31 11:10:12,851 INFO:     Best model found after epoch 77 of 100.
2022-12-31 11:10:12,851 INFO:   Done with stage: TRAINING
2022-12-31 11:10:12,851 INFO:   Starting stage: EVALUATION
2022-12-31 11:10:12,979 INFO:   Done with stage: EVALUATION
2022-12-31 11:10:12,979 INFO:   Leaving out SEQ value Fold_7
2022-12-31 11:10:12,991 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 11:10:12,991 INFO:   Starting stage: FEATURE SCALING
2022-12-31 11:10:13,647 INFO:   Done with stage: FEATURE SCALING
2022-12-31 11:10:13,647 INFO:   Starting stage: SCALING TARGETS
2022-12-31 11:10:13,717 INFO:   Done with stage: SCALING TARGETS
2022-12-31 11:10:13,717 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:10:13,717 INFO:     No hyperparam tuning for this model
2022-12-31 11:10:13,717 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:10:13,717 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 11:10:13,718 INFO:     None feature selector for col prot
2022-12-31 11:10:13,718 INFO:     None feature selector for col prot
2022-12-31 11:10:13,718 INFO:     None feature selector for col prot
2022-12-31 11:10:13,719 INFO:     None feature selector for col chem
2022-12-31 11:10:13,719 INFO:     None feature selector for col chem
2022-12-31 11:10:13,719 INFO:     None feature selector for col chem
2022-12-31 11:10:13,719 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 11:10:13,719 INFO:   Starting stage: BUILD MODEL
2022-12-31 11:10:13,721 INFO:     Number of params in model 223921
2022-12-31 11:10:13,724 INFO:   Done with stage: BUILD MODEL
2022-12-31 11:10:13,724 INFO:   Starting stage: TRAINING
2022-12-31 11:10:13,769 INFO:     Val loss before train {'Reaction outcome loss': 1.0154608607292175, 'Total loss': 1.0154608607292175}
2022-12-31 11:10:13,769 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:13,769 INFO:     Epoch: 0
2022-12-31 11:10:15,339 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7377452095349629, 'Total loss': 0.7377452095349629} | train loss {'Reaction outcome loss': 0.8230406164691069, 'Total loss': 0.8230406164691069}
2022-12-31 11:10:15,339 INFO:     Found new best model at epoch 0
2022-12-31 11:10:15,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:15,340 INFO:     Epoch: 1
2022-12-31 11:10:16,954 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6063628713289897, 'Total loss': 0.6063628713289897} | train loss {'Reaction outcome loss': 0.6130563134084577, 'Total loss': 0.6130563134084577}
2022-12-31 11:10:16,955 INFO:     Found new best model at epoch 1
2022-12-31 11:10:16,955 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:16,955 INFO:     Epoch: 2
2022-12-31 11:10:18,566 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5410995086034139, 'Total loss': 0.5410995086034139} | train loss {'Reaction outcome loss': 0.5489181212109068, 'Total loss': 0.5489181212109068}
2022-12-31 11:10:18,567 INFO:     Found new best model at epoch 2
2022-12-31 11:10:18,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:18,567 INFO:     Epoch: 3
2022-12-31 11:10:20,229 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5455565830071767, 'Total loss': 0.5455565830071767} | train loss {'Reaction outcome loss': 0.5150346722777771, 'Total loss': 0.5150346722777771}
2022-12-31 11:10:20,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:20,229 INFO:     Epoch: 4
2022-12-31 11:10:21,855 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5588198165098827, 'Total loss': 0.5588198165098827} | train loss {'Reaction outcome loss': 0.48799188796808757, 'Total loss': 0.48799188796808757}
2022-12-31 11:10:21,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:21,855 INFO:     Epoch: 5
2022-12-31 11:10:23,359 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5309359500805537, 'Total loss': 0.5309359500805537} | train loss {'Reaction outcome loss': 0.4835819623203597, 'Total loss': 0.4835819623203597}
2022-12-31 11:10:23,359 INFO:     Found new best model at epoch 5
2022-12-31 11:10:23,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:23,360 INFO:     Epoch: 6
2022-12-31 11:10:24,429 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5319198310375214, 'Total loss': 0.5319198310375214} | train loss {'Reaction outcome loss': 0.46692094173973286, 'Total loss': 0.46692094173973286}
2022-12-31 11:10:24,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:24,429 INFO:     Epoch: 7
2022-12-31 11:10:25,492 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5141712586085002, 'Total loss': 0.5141712586085002} | train loss {'Reaction outcome loss': 0.4608927402072025, 'Total loss': 0.4608927402072025}
2022-12-31 11:10:25,493 INFO:     Found new best model at epoch 7
2022-12-31 11:10:25,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:25,494 INFO:     Epoch: 8
2022-12-31 11:10:26,556 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5350960711638133, 'Total loss': 0.5350960711638133} | train loss {'Reaction outcome loss': 0.46611787443575653, 'Total loss': 0.46611787443575653}
2022-12-31 11:10:26,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:26,556 INFO:     Epoch: 9
2022-12-31 11:10:27,626 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5421489993731181, 'Total loss': 0.5421489993731181} | train loss {'Reaction outcome loss': 0.4500754509607087, 'Total loss': 0.4500754509607087}
2022-12-31 11:10:27,626 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:27,626 INFO:     Epoch: 10
2022-12-31 11:10:29,109 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5109582205613454, 'Total loss': 0.5109582205613454} | train loss {'Reaction outcome loss': 0.4479122158625852, 'Total loss': 0.4479122158625852}
2022-12-31 11:10:29,109 INFO:     Found new best model at epoch 10
2022-12-31 11:10:29,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:29,110 INFO:     Epoch: 11
2022-12-31 11:10:30,733 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5217416922251383, 'Total loss': 0.5217416922251383} | train loss {'Reaction outcome loss': 0.45897716815596906, 'Total loss': 0.45897716815596906}
2022-12-31 11:10:30,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:30,734 INFO:     Epoch: 12
2022-12-31 11:10:32,382 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4884762724240621, 'Total loss': 0.4884762724240621} | train loss {'Reaction outcome loss': 0.4348349241954236, 'Total loss': 0.4348349241954236}
2022-12-31 11:10:32,382 INFO:     Found new best model at epoch 12
2022-12-31 11:10:32,383 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:32,383 INFO:     Epoch: 13
2022-12-31 11:10:34,043 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.508119261264801, 'Total loss': 0.508119261264801} | train loss {'Reaction outcome loss': 0.43033381848447566, 'Total loss': 0.43033381848447566}
2022-12-31 11:10:34,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:34,044 INFO:     Epoch: 14
2022-12-31 11:10:35,686 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5141286393006642, 'Total loss': 0.5141286393006642} | train loss {'Reaction outcome loss': 0.4252072998686977, 'Total loss': 0.4252072998686977}
2022-12-31 11:10:35,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:35,686 INFO:     Epoch: 15
2022-12-31 11:10:37,321 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.6035391807556152, 'Total loss': 0.6035391807556152} | train loss {'Reaction outcome loss': 0.42441344228775607, 'Total loss': 0.42441344228775607}
2022-12-31 11:10:37,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:37,322 INFO:     Epoch: 16
2022-12-31 11:10:38,983 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5079125543435414, 'Total loss': 0.5079125543435414} | train loss {'Reaction outcome loss': 0.4454042402946431, 'Total loss': 0.4454042402946431}
2022-12-31 11:10:38,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:38,983 INFO:     Epoch: 17
2022-12-31 11:10:40,616 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4915916879971822, 'Total loss': 0.4915916879971822} | train loss {'Reaction outcome loss': 0.41195551685961906, 'Total loss': 0.41195551685961906}
2022-12-31 11:10:40,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:40,616 INFO:     Epoch: 18
2022-12-31 11:10:42,249 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5093115478754043, 'Total loss': 0.5093115478754043} | train loss {'Reaction outcome loss': 0.3993376385944852, 'Total loss': 0.3993376385944852}
2022-12-31 11:10:42,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:42,250 INFO:     Epoch: 19
2022-12-31 11:10:43,866 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48983566562334696, 'Total loss': 0.48983566562334696} | train loss {'Reaction outcome loss': 0.39462308375136607, 'Total loss': 0.39462308375136607}
2022-12-31 11:10:43,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:43,867 INFO:     Epoch: 20
2022-12-31 11:10:45,490 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.455954239765803, 'Total loss': 0.455954239765803} | train loss {'Reaction outcome loss': 0.3899659589464452, 'Total loss': 0.3899659589464452}
2022-12-31 11:10:45,490 INFO:     Found new best model at epoch 20
2022-12-31 11:10:45,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:45,491 INFO:     Epoch: 21
2022-12-31 11:10:47,120 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4857149879137675, 'Total loss': 0.4857149879137675} | train loss {'Reaction outcome loss': 0.38250377452493634, 'Total loss': 0.38250377452493634}
2022-12-31 11:10:47,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:47,120 INFO:     Epoch: 22
2022-12-31 11:10:48,721 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.48849301040172577, 'Total loss': 0.48849301040172577} | train loss {'Reaction outcome loss': 0.3793773514225377, 'Total loss': 0.3793773514225377}
2022-12-31 11:10:48,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:48,721 INFO:     Epoch: 23
2022-12-31 11:10:50,345 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46111366947491966, 'Total loss': 0.46111366947491966} | train loss {'Reaction outcome loss': 0.3725339173190836, 'Total loss': 0.3725339173190836}
2022-12-31 11:10:50,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:50,345 INFO:     Epoch: 24
2022-12-31 11:10:51,964 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.497349480787913, 'Total loss': 0.497349480787913} | train loss {'Reaction outcome loss': 0.37048472122536413, 'Total loss': 0.37048472122536413}
2022-12-31 11:10:51,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:51,964 INFO:     Epoch: 25
2022-12-31 11:10:53,581 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.49071494142214456, 'Total loss': 0.49071494142214456} | train loss {'Reaction outcome loss': 0.36987001656730106, 'Total loss': 0.36987001656730106}
2022-12-31 11:10:53,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:53,582 INFO:     Epoch: 26
2022-12-31 11:10:55,200 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47935856183369957, 'Total loss': 0.47935856183369957} | train loss {'Reaction outcome loss': 0.3824135791847779, 'Total loss': 0.3824135791847779}
2022-12-31 11:10:55,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:55,200 INFO:     Epoch: 27
2022-12-31 11:10:56,810 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46697944800059, 'Total loss': 0.46697944800059} | train loss {'Reaction outcome loss': 0.35715984018600505, 'Total loss': 0.35715984018600505}
2022-12-31 11:10:56,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:56,811 INFO:     Epoch: 28
2022-12-31 11:10:58,408 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4524214337269465, 'Total loss': 0.4524214337269465} | train loss {'Reaction outcome loss': 0.3572192043605922, 'Total loss': 0.3572192043605922}
2022-12-31 11:10:58,408 INFO:     Found new best model at epoch 28
2022-12-31 11:10:58,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:10:58,409 INFO:     Epoch: 29
2022-12-31 11:11:00,021 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4808709740638733, 'Total loss': 0.4808709740638733} | train loss {'Reaction outcome loss': 0.34276905704451643, 'Total loss': 0.34276905704451643}
2022-12-31 11:11:00,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:00,022 INFO:     Epoch: 30
2022-12-31 11:11:01,639 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4394748498996099, 'Total loss': 0.4394748498996099} | train loss {'Reaction outcome loss': 0.3518637716888275, 'Total loss': 0.3518637716888275}
2022-12-31 11:11:01,639 INFO:     Found new best model at epoch 30
2022-12-31 11:11:01,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:01,640 INFO:     Epoch: 31
2022-12-31 11:11:03,253 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42400909463564557, 'Total loss': 0.42400909463564557} | train loss {'Reaction outcome loss': 0.32989727667249413, 'Total loss': 0.32989727667249413}
2022-12-31 11:11:03,254 INFO:     Found new best model at epoch 31
2022-12-31 11:11:03,254 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:03,255 INFO:     Epoch: 32
2022-12-31 11:11:04,855 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4698213815689087, 'Total loss': 0.4698213815689087} | train loss {'Reaction outcome loss': 0.3251530774913313, 'Total loss': 0.3251530774913313}
2022-12-31 11:11:04,855 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:04,855 INFO:     Epoch: 33
2022-12-31 11:11:06,449 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4558602303266525, 'Total loss': 0.4558602303266525} | train loss {'Reaction outcome loss': 0.32311427632795536, 'Total loss': 0.32311427632795536}
2022-12-31 11:11:06,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:06,450 INFO:     Epoch: 34
2022-12-31 11:11:08,084 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4433485507965088, 'Total loss': 0.4433485507965088} | train loss {'Reaction outcome loss': 0.32268184258778027, 'Total loss': 0.32268184258778027}
2022-12-31 11:11:08,086 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:08,086 INFO:     Epoch: 35
2022-12-31 11:11:09,697 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4679134984811147, 'Total loss': 0.4679134984811147} | train loss {'Reaction outcome loss': 0.3224296494103644, 'Total loss': 0.3224296494103644}
2022-12-31 11:11:09,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:09,698 INFO:     Epoch: 36
2022-12-31 11:11:11,328 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43272002339363097, 'Total loss': 0.43272002339363097} | train loss {'Reaction outcome loss': 0.3155590236888004, 'Total loss': 0.3155590236888004}
2022-12-31 11:11:11,328 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:11,328 INFO:     Epoch: 37
2022-12-31 11:11:12,960 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4674760937690735, 'Total loss': 0.4674760937690735} | train loss {'Reaction outcome loss': 0.3055098333606493, 'Total loss': 0.3055098333606493}
2022-12-31 11:11:12,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:12,960 INFO:     Epoch: 38
2022-12-31 11:11:14,574 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46073527733484904, 'Total loss': 0.46073527733484904} | train loss {'Reaction outcome loss': 0.3059046472797332, 'Total loss': 0.3059046472797332}
2022-12-31 11:11:14,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:14,575 INFO:     Epoch: 39
2022-12-31 11:11:16,207 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43913648227850594, 'Total loss': 0.43913648227850594} | train loss {'Reaction outcome loss': 0.30037605133501516, 'Total loss': 0.30037605133501516}
2022-12-31 11:11:16,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:16,207 INFO:     Epoch: 40
2022-12-31 11:11:17,838 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4565275589625041, 'Total loss': 0.4565275589625041} | train loss {'Reaction outcome loss': 0.3077294342717547, 'Total loss': 0.3077294342717547}
2022-12-31 11:11:17,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:17,839 INFO:     Epoch: 41
2022-12-31 11:11:19,454 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.46545350551605225, 'Total loss': 0.46545350551605225} | train loss {'Reaction outcome loss': 0.28955559662300284, 'Total loss': 0.28955559662300284}
2022-12-31 11:11:19,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:19,454 INFO:     Epoch: 42
2022-12-31 11:11:21,067 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43219710389773053, 'Total loss': 0.43219710389773053} | train loss {'Reaction outcome loss': 0.2943974479592567, 'Total loss': 0.2943974479592567}
2022-12-31 11:11:21,067 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:21,067 INFO:     Epoch: 43
2022-12-31 11:11:22,659 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44017609556516013, 'Total loss': 0.44017609556516013} | train loss {'Reaction outcome loss': 0.2955959897125701, 'Total loss': 0.2955959897125701}
2022-12-31 11:11:22,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:22,660 INFO:     Epoch: 44
2022-12-31 11:11:24,318 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41843620240688323, 'Total loss': 0.41843620240688323} | train loss {'Reaction outcome loss': 0.28283843439219153, 'Total loss': 0.28283843439219153}
2022-12-31 11:11:24,318 INFO:     Found new best model at epoch 44
2022-12-31 11:11:24,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:24,319 INFO:     Epoch: 45
2022-12-31 11:11:25,945 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42986280818780265, 'Total loss': 0.42986280818780265} | train loss {'Reaction outcome loss': 0.28544471059707366, 'Total loss': 0.28544471059707366}
2022-12-31 11:11:25,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:25,945 INFO:     Epoch: 46
2022-12-31 11:11:27,564 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.414336089293162, 'Total loss': 0.414336089293162} | train loss {'Reaction outcome loss': 0.27792710029693873, 'Total loss': 0.27792710029693873}
2022-12-31 11:11:27,565 INFO:     Found new best model at epoch 46
2022-12-31 11:11:27,566 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:27,566 INFO:     Epoch: 47
2022-12-31 11:11:29,178 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4094074149926504, 'Total loss': 0.4094074149926504} | train loss {'Reaction outcome loss': 0.277760818148036, 'Total loss': 0.277760818148036}
2022-12-31 11:11:29,178 INFO:     Found new best model at epoch 47
2022-12-31 11:11:29,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:29,179 INFO:     Epoch: 48
2022-12-31 11:11:30,791 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43070944348971046, 'Total loss': 0.43070944348971046} | train loss {'Reaction outcome loss': 0.27360144627206295, 'Total loss': 0.27360144627206295}
2022-12-31 11:11:30,791 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:30,792 INFO:     Epoch: 49
2022-12-31 11:11:32,397 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.455850758155187, 'Total loss': 0.455850758155187} | train loss {'Reaction outcome loss': 0.27402675656628783, 'Total loss': 0.27402675656628783}
2022-12-31 11:11:32,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:32,398 INFO:     Epoch: 50
2022-12-31 11:11:34,022 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4565738131602605, 'Total loss': 0.4565738131602605} | train loss {'Reaction outcome loss': 0.30740427694188943, 'Total loss': 0.30740427694188943}
2022-12-31 11:11:34,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:34,022 INFO:     Epoch: 51
2022-12-31 11:11:35,636 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4571899563074112, 'Total loss': 0.4571899563074112} | train loss {'Reaction outcome loss': 0.28236113784694916, 'Total loss': 0.28236113784694916}
2022-12-31 11:11:35,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:35,636 INFO:     Epoch: 52
2022-12-31 11:11:37,247 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44607484141985576, 'Total loss': 0.44607484141985576} | train loss {'Reaction outcome loss': 0.2715651234274433, 'Total loss': 0.2715651234274433}
2022-12-31 11:11:37,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:37,247 INFO:     Epoch: 53
2022-12-31 11:11:38,858 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43048285047213236, 'Total loss': 0.43048285047213236} | train loss {'Reaction outcome loss': 0.26418557334197784, 'Total loss': 0.26418557334197784}
2022-12-31 11:11:38,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:38,859 INFO:     Epoch: 54
2022-12-31 11:11:40,470 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4142778148253759, 'Total loss': 0.4142778148253759} | train loss {'Reaction outcome loss': 0.26506953343630524, 'Total loss': 0.26506953343630524}
2022-12-31 11:11:40,471 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:40,471 INFO:     Epoch: 55
2022-12-31 11:11:42,097 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44873277842998505, 'Total loss': 0.44873277842998505} | train loss {'Reaction outcome loss': 0.261536544639024, 'Total loss': 0.261536544639024}
2022-12-31 11:11:42,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:42,098 INFO:     Epoch: 56
2022-12-31 11:11:43,740 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46528255144755043, 'Total loss': 0.46528255144755043} | train loss {'Reaction outcome loss': 0.252351814127431, 'Total loss': 0.252351814127431}
2022-12-31 11:11:43,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:43,740 INFO:     Epoch: 57
2022-12-31 11:11:45,397 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4193958123524984, 'Total loss': 0.4193958123524984} | train loss {'Reaction outcome loss': 0.2589588221293314, 'Total loss': 0.2589588221293314}
2022-12-31 11:11:45,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:45,398 INFO:     Epoch: 58
2022-12-31 11:11:47,068 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4552650213241577, 'Total loss': 0.4552650213241577} | train loss {'Reaction outcome loss': 0.2568264502613443, 'Total loss': 0.2568264502613443}
2022-12-31 11:11:47,068 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:47,069 INFO:     Epoch: 59
2022-12-31 11:11:48,723 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.46398775378863016, 'Total loss': 0.46398775378863016} | train loss {'Reaction outcome loss': 0.2634951929710265, 'Total loss': 0.2634951929710265}
2022-12-31 11:11:48,723 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:48,723 INFO:     Epoch: 60
2022-12-31 11:11:50,298 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4374973992506663, 'Total loss': 0.4374973992506663} | train loss {'Reaction outcome loss': 0.27900709055593587, 'Total loss': 0.27900709055593587}
2022-12-31 11:11:50,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:50,299 INFO:     Epoch: 61
2022-12-31 11:11:51,910 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43726390500863394, 'Total loss': 0.43726390500863394} | train loss {'Reaction outcome loss': 0.25248427324644895, 'Total loss': 0.25248427324644895}
2022-12-31 11:11:51,910 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:51,910 INFO:     Epoch: 62
2022-12-31 11:11:53,556 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44228576819101967, 'Total loss': 0.44228576819101967} | train loss {'Reaction outcome loss': 0.2660271756256512, 'Total loss': 0.2660271756256512}
2022-12-31 11:11:53,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:53,556 INFO:     Epoch: 63
2022-12-31 11:11:55,165 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44871317346890766, 'Total loss': 0.44871317346890766} | train loss {'Reaction outcome loss': 0.25257672147774324, 'Total loss': 0.25257672147774324}
2022-12-31 11:11:55,165 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:55,166 INFO:     Epoch: 64
2022-12-31 11:11:56,777 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40319134294986725, 'Total loss': 0.40319134294986725} | train loss {'Reaction outcome loss': 0.24675843207122575, 'Total loss': 0.24675843207122575}
2022-12-31 11:11:56,777 INFO:     Found new best model at epoch 64
2022-12-31 11:11:56,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:56,778 INFO:     Epoch: 65
2022-12-31 11:11:58,425 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4124868333339691, 'Total loss': 0.4124868333339691} | train loss {'Reaction outcome loss': 0.2432116543548519, 'Total loss': 0.2432116543548519}
2022-12-31 11:11:58,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:11:58,426 INFO:     Epoch: 66
2022-12-31 11:12:00,023 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4305908073981603, 'Total loss': 0.4305908073981603} | train loss {'Reaction outcome loss': 0.24261837655111498, 'Total loss': 0.24261837655111498}
2022-12-31 11:12:00,023 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:00,024 INFO:     Epoch: 67
2022-12-31 11:12:01,616 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42201676964759827, 'Total loss': 0.42201676964759827} | train loss {'Reaction outcome loss': 0.2510761819860857, 'Total loss': 0.2510761819860857}
2022-12-31 11:12:01,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:01,616 INFO:     Epoch: 68
2022-12-31 11:12:03,229 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4297416239976883, 'Total loss': 0.4297416239976883} | train loss {'Reaction outcome loss': 0.2553453464972098, 'Total loss': 0.2553453464972098}
2022-12-31 11:12:03,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:03,229 INFO:     Epoch: 69
2022-12-31 11:12:04,840 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40080522894859316, 'Total loss': 0.40080522894859316} | train loss {'Reaction outcome loss': 0.24273675681510265, 'Total loss': 0.24273675681510265}
2022-12-31 11:12:04,841 INFO:     Found new best model at epoch 69
2022-12-31 11:12:04,841 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:04,841 INFO:     Epoch: 70
2022-12-31 11:12:06,452 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.47295842866102855, 'Total loss': 0.47295842866102855} | train loss {'Reaction outcome loss': 0.24674657726849336, 'Total loss': 0.24674657726849336}
2022-12-31 11:12:06,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:06,453 INFO:     Epoch: 71
2022-12-31 11:12:08,050 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.45684311985969545, 'Total loss': 0.45684311985969545} | train loss {'Reaction outcome loss': 0.2793514837196225, 'Total loss': 0.2793514837196225}
2022-12-31 11:12:08,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:08,050 INFO:     Epoch: 72
2022-12-31 11:12:09,661 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4594204306602478, 'Total loss': 0.4594204306602478} | train loss {'Reaction outcome loss': 0.24064448792019422, 'Total loss': 0.24064448792019422}
2022-12-31 11:12:09,663 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:09,663 INFO:     Epoch: 73
2022-12-31 11:12:11,252 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42101808786392214, 'Total loss': 0.42101808786392214} | train loss {'Reaction outcome loss': 0.2452664431082245, 'Total loss': 0.2452664431082245}
2022-12-31 11:12:11,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:11,252 INFO:     Epoch: 74
2022-12-31 11:12:12,870 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.408353782693545, 'Total loss': 0.408353782693545} | train loss {'Reaction outcome loss': 0.23604514650669708, 'Total loss': 0.23604514650669708}
2022-12-31 11:12:12,870 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:12,870 INFO:     Epoch: 75
2022-12-31 11:12:14,485 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4333494206269582, 'Total loss': 0.4333494206269582} | train loss {'Reaction outcome loss': 0.23344846440992062, 'Total loss': 0.23344846440992062}
2022-12-31 11:12:14,485 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:14,485 INFO:     Epoch: 76
2022-12-31 11:12:16,098 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4558369070291519, 'Total loss': 0.4558369070291519} | train loss {'Reaction outcome loss': 0.23591277643066386, 'Total loss': 0.23591277643066386}
2022-12-31 11:12:16,099 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:16,099 INFO:     Epoch: 77
2022-12-31 11:12:17,696 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4632729430993398, 'Total loss': 0.4632729430993398} | train loss {'Reaction outcome loss': 0.2606466844749841, 'Total loss': 0.2606466844749841}
2022-12-31 11:12:17,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:17,696 INFO:     Epoch: 78
2022-12-31 11:12:19,284 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43353788057963055, 'Total loss': 0.43353788057963055} | train loss {'Reaction outcome loss': 0.24012332101204042, 'Total loss': 0.24012332101204042}
2022-12-31 11:12:19,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:19,284 INFO:     Epoch: 79
2022-12-31 11:12:20,894 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4430608054002126, 'Total loss': 0.4430608054002126} | train loss {'Reaction outcome loss': 0.23346233206288214, 'Total loss': 0.23346233206288214}
2022-12-31 11:12:20,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:20,894 INFO:     Epoch: 80
2022-12-31 11:12:22,503 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43927303453286487, 'Total loss': 0.43927303453286487} | train loss {'Reaction outcome loss': 0.22673934994547407, 'Total loss': 0.22673934994547407}
2022-12-31 11:12:22,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:22,503 INFO:     Epoch: 81
2022-12-31 11:12:24,111 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4434604783852895, 'Total loss': 0.4434604783852895} | train loss {'Reaction outcome loss': 0.22838324571398846, 'Total loss': 0.22838324571398846}
2022-12-31 11:12:24,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:24,112 INFO:     Epoch: 82
2022-12-31 11:12:25,721 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4520426372687022, 'Total loss': 0.4520426372687022} | train loss {'Reaction outcome loss': 0.23494686095880857, 'Total loss': 0.23494686095880857}
2022-12-31 11:12:25,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:25,721 INFO:     Epoch: 83
2022-12-31 11:12:27,321 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4475559333960215, 'Total loss': 0.4475559333960215} | train loss {'Reaction outcome loss': 0.2405879930078484, 'Total loss': 0.2405879930078484}
2022-12-31 11:12:27,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:27,321 INFO:     Epoch: 84
2022-12-31 11:12:28,908 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44361304144064584, 'Total loss': 0.44361304144064584} | train loss {'Reaction outcome loss': 0.23538720115628667, 'Total loss': 0.23538720115628667}
2022-12-31 11:12:28,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:28,909 INFO:     Epoch: 85
2022-12-31 11:12:30,524 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44002593159675596, 'Total loss': 0.44002593159675596} | train loss {'Reaction outcome loss': 0.22793416465646116, 'Total loss': 0.22793416465646116}
2022-12-31 11:12:30,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:30,524 INFO:     Epoch: 86
2022-12-31 11:12:32,164 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44957926670710247, 'Total loss': 0.44957926670710247} | train loss {'Reaction outcome loss': 0.2281597505325276, 'Total loss': 0.2281597505325276}
2022-12-31 11:12:32,164 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:32,164 INFO:     Epoch: 87
2022-12-31 11:12:33,775 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.424153333902359, 'Total loss': 0.424153333902359} | train loss {'Reaction outcome loss': 0.23005960329665223, 'Total loss': 0.23005960329665223}
2022-12-31 11:12:33,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:33,775 INFO:     Epoch: 88
2022-12-31 11:12:35,373 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4828538358211517, 'Total loss': 0.4828538358211517} | train loss {'Reaction outcome loss': 0.26851039379497693, 'Total loss': 0.26851039379497693}
2022-12-31 11:12:35,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:35,373 INFO:     Epoch: 89
2022-12-31 11:12:36,979 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4291189859310786, 'Total loss': 0.4291189859310786} | train loss {'Reaction outcome loss': 0.2500268629401166, 'Total loss': 0.2500268629401166}
2022-12-31 11:12:36,979 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:36,979 INFO:     Epoch: 90
2022-12-31 11:12:38,616 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4438368171453476, 'Total loss': 0.4438368171453476} | train loss {'Reaction outcome loss': 0.2554706296806757, 'Total loss': 0.2554706296806757}
2022-12-31 11:12:38,616 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:38,616 INFO:     Epoch: 91
2022-12-31 11:12:40,230 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41729702750841774, 'Total loss': 0.41729702750841774} | train loss {'Reaction outcome loss': 0.2259851285497712, 'Total loss': 0.2259851285497712}
2022-12-31 11:12:40,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:40,231 INFO:     Epoch: 92
2022-12-31 11:12:41,840 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44397821724414827, 'Total loss': 0.44397821724414827} | train loss {'Reaction outcome loss': 0.22645860221034483, 'Total loss': 0.22645860221034483}
2022-12-31 11:12:41,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:41,840 INFO:     Epoch: 93
2022-12-31 11:12:43,452 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4196141973137856, 'Total loss': 0.4196141973137856} | train loss {'Reaction outcome loss': 0.21969761247274236, 'Total loss': 0.21969761247274236}
2022-12-31 11:12:43,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:43,452 INFO:     Epoch: 94
2022-12-31 11:12:45,046 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.49536997377872466, 'Total loss': 0.49536997377872466} | train loss {'Reaction outcome loss': 0.22175611468145215, 'Total loss': 0.22175611468145215}
2022-12-31 11:12:45,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:45,046 INFO:     Epoch: 95
2022-12-31 11:12:46,648 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4317574679851532, 'Total loss': 0.4317574679851532} | train loss {'Reaction outcome loss': 0.21444584498775826, 'Total loss': 0.21444584498775826}
2022-12-31 11:12:46,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:46,649 INFO:     Epoch: 96
2022-12-31 11:12:48,315 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.46264469226201377, 'Total loss': 0.46264469226201377} | train loss {'Reaction outcome loss': 0.21896260029946765, 'Total loss': 0.21896260029946765}
2022-12-31 11:12:48,315 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:48,315 INFO:     Epoch: 97
2022-12-31 11:12:49,970 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42684418950229885, 'Total loss': 0.42684418950229885} | train loss {'Reaction outcome loss': 0.2378794329267913, 'Total loss': 0.2378794329267913}
2022-12-31 11:12:49,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:49,970 INFO:     Epoch: 98
2022-12-31 11:12:51,579 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4202339748541514, 'Total loss': 0.4202339748541514} | train loss {'Reaction outcome loss': 0.2714681590315076, 'Total loss': 0.2714681590315076}
2022-12-31 11:12:51,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:51,579 INFO:     Epoch: 99
2022-12-31 11:12:53,171 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44887510935465497, 'Total loss': 0.44887510935465497} | train loss {'Reaction outcome loss': 0.23128501354786105, 'Total loss': 0.23128501354786105}
2022-12-31 11:12:53,171 INFO:     Best model found after epoch 70 of 100.
2022-12-31 11:12:53,171 INFO:   Done with stage: TRAINING
2022-12-31 11:12:53,171 INFO:   Starting stage: EVALUATION
2022-12-31 11:12:53,298 INFO:   Done with stage: EVALUATION
2022-12-31 11:12:53,298 INFO:   Leaving out SEQ value Fold_8
2022-12-31 11:12:53,310 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 11:12:53,310 INFO:   Starting stage: FEATURE SCALING
2022-12-31 11:12:53,946 INFO:   Done with stage: FEATURE SCALING
2022-12-31 11:12:53,946 INFO:   Starting stage: SCALING TARGETS
2022-12-31 11:12:54,015 INFO:   Done with stage: SCALING TARGETS
2022-12-31 11:12:54,015 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:12:54,015 INFO:     No hyperparam tuning for this model
2022-12-31 11:12:54,015 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:12:54,015 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 11:12:54,016 INFO:     None feature selector for col prot
2022-12-31 11:12:54,016 INFO:     None feature selector for col prot
2022-12-31 11:12:54,016 INFO:     None feature selector for col prot
2022-12-31 11:12:54,017 INFO:     None feature selector for col chem
2022-12-31 11:12:54,017 INFO:     None feature selector for col chem
2022-12-31 11:12:54,017 INFO:     None feature selector for col chem
2022-12-31 11:12:54,017 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 11:12:54,017 INFO:   Starting stage: BUILD MODEL
2022-12-31 11:12:54,019 INFO:     Number of params in model 223921
2022-12-31 11:12:54,022 INFO:   Done with stage: BUILD MODEL
2022-12-31 11:12:54,022 INFO:   Starting stage: TRAINING
2022-12-31 11:12:54,068 INFO:     Val loss before train {'Reaction outcome loss': 1.0167501330375672, 'Total loss': 1.0167501330375672}
2022-12-31 11:12:54,069 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:54,069 INFO:     Epoch: 0
2022-12-31 11:12:55,645 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7053884585698446, 'Total loss': 0.7053884585698446} | train loss {'Reaction outcome loss': 0.7971821677335452, 'Total loss': 0.7971821677335452}
2022-12-31 11:12:55,646 INFO:     Found new best model at epoch 0
2022-12-31 11:12:55,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:55,647 INFO:     Epoch: 1
2022-12-31 11:12:57,298 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5655518551667531, 'Total loss': 0.5655518551667531} | train loss {'Reaction outcome loss': 0.5950974114648588, 'Total loss': 0.5950974114648588}
2022-12-31 11:12:57,298 INFO:     Found new best model at epoch 1
2022-12-31 11:12:57,299 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:57,299 INFO:     Epoch: 2
2022-12-31 11:12:58,913 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5490430851777395, 'Total loss': 0.5490430851777395} | train loss {'Reaction outcome loss': 0.5251251191664965, 'Total loss': 0.5251251191664965}
2022-12-31 11:12:58,914 INFO:     Found new best model at epoch 2
2022-12-31 11:12:58,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:12:58,915 INFO:     Epoch: 3
2022-12-31 11:13:00,506 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5418099582195282, 'Total loss': 0.5418099582195282} | train loss {'Reaction outcome loss': 0.5020568452147773, 'Total loss': 0.5020568452147773}
2022-12-31 11:13:00,506 INFO:     Found new best model at epoch 3
2022-12-31 11:13:00,507 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:00,507 INFO:     Epoch: 4
2022-12-31 11:13:02,089 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5167353252569834, 'Total loss': 0.5167353252569834} | train loss {'Reaction outcome loss': 0.4901690096645565, 'Total loss': 0.4901690096645565}
2022-12-31 11:13:02,089 INFO:     Found new best model at epoch 4
2022-12-31 11:13:02,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:02,090 INFO:     Epoch: 5
2022-12-31 11:13:03,709 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5351764678955078, 'Total loss': 0.5351764678955078} | train loss {'Reaction outcome loss': 0.4724685782805467, 'Total loss': 0.4724685782805467}
2022-12-31 11:13:03,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:03,709 INFO:     Epoch: 6
2022-12-31 11:13:05,318 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5178586095571518, 'Total loss': 0.5178586095571518} | train loss {'Reaction outcome loss': 0.4629479741657173, 'Total loss': 0.4629479741657173}
2022-12-31 11:13:05,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:05,318 INFO:     Epoch: 7
2022-12-31 11:13:06,927 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5060623695453008, 'Total loss': 0.5060623695453008} | train loss {'Reaction outcome loss': 0.4546177112412103, 'Total loss': 0.4546177112412103}
2022-12-31 11:13:06,928 INFO:     Found new best model at epoch 7
2022-12-31 11:13:06,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:06,928 INFO:     Epoch: 8
2022-12-31 11:13:08,576 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49135815699895224, 'Total loss': 0.49135815699895224} | train loss {'Reaction outcome loss': 0.44813680067494677, 'Total loss': 0.44813680067494677}
2022-12-31 11:13:08,576 INFO:     Found new best model at epoch 8
2022-12-31 11:13:08,577 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:08,577 INFO:     Epoch: 9
2022-12-31 11:13:10,180 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.514078692595164, 'Total loss': 0.514078692595164} | train loss {'Reaction outcome loss': 0.4395628073713282, 'Total loss': 0.4395628073713282}
2022-12-31 11:13:10,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:10,180 INFO:     Epoch: 10
2022-12-31 11:13:11,759 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49895153641700746, 'Total loss': 0.49895153641700746} | train loss {'Reaction outcome loss': 0.4379217180358621, 'Total loss': 0.4379217180358621}
2022-12-31 11:13:11,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:11,759 INFO:     Epoch: 11
2022-12-31 11:13:13,359 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5065700302521388, 'Total loss': 0.5065700302521388} | train loss {'Reaction outcome loss': 0.4273181600775911, 'Total loss': 0.4273181600775911}
2022-12-31 11:13:13,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:13,359 INFO:     Epoch: 12
2022-12-31 11:13:14,936 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5070787360270818, 'Total loss': 0.5070787360270818} | train loss {'Reaction outcome loss': 0.4209529912515438, 'Total loss': 0.4209529912515438}
2022-12-31 11:13:14,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:14,937 INFO:     Epoch: 13
2022-12-31 11:13:16,545 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5144371668497721, 'Total loss': 0.5144371668497721} | train loss {'Reaction outcome loss': 0.4135663614168272, 'Total loss': 0.4135663614168272}
2022-12-31 11:13:16,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:16,546 INFO:     Epoch: 14
2022-12-31 11:13:18,142 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4737701952457428, 'Total loss': 0.4737701952457428} | train loss {'Reaction outcome loss': 0.41077468192184363, 'Total loss': 0.41077468192184363}
2022-12-31 11:13:18,143 INFO:     Found new best model at epoch 14
2022-12-31 11:13:18,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:18,143 INFO:     Epoch: 15
2022-12-31 11:13:19,739 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4675269911686579, 'Total loss': 0.4675269911686579} | train loss {'Reaction outcome loss': 0.3999021603783845, 'Total loss': 0.3999021603783845}
2022-12-31 11:13:19,739 INFO:     Found new best model at epoch 15
2022-12-31 11:13:19,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:19,740 INFO:     Epoch: 16
2022-12-31 11:13:21,317 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5060552398363749, 'Total loss': 0.5060552398363749} | train loss {'Reaction outcome loss': 0.3966050356585573, 'Total loss': 0.3966050356585573}
2022-12-31 11:13:21,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:21,317 INFO:     Epoch: 17
2022-12-31 11:13:22,894 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.48673983216285704, 'Total loss': 0.48673983216285704} | train loss {'Reaction outcome loss': 0.3921402694705205, 'Total loss': 0.3921402694705205}
2022-12-31 11:13:22,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:22,895 INFO:     Epoch: 18
2022-12-31 11:13:24,493 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5020443459351858, 'Total loss': 0.5020443459351858} | train loss {'Reaction outcome loss': 0.39356650966100204, 'Total loss': 0.39356650966100204}
2022-12-31 11:13:24,493 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:24,493 INFO:     Epoch: 19
2022-12-31 11:13:26,092 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49789292613665265, 'Total loss': 0.49789292613665265} | train loss {'Reaction outcome loss': 0.3791718750700846, 'Total loss': 0.3791718750700846}
2022-12-31 11:13:26,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:26,092 INFO:     Epoch: 20
2022-12-31 11:13:27,689 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47659705181916556, 'Total loss': 0.47659705181916556} | train loss {'Reaction outcome loss': 0.3838161375550997, 'Total loss': 0.3838161375550997}
2022-12-31 11:13:27,689 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:27,689 INFO:     Epoch: 21
2022-12-31 11:13:29,286 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47776402632395426, 'Total loss': 0.47776402632395426} | train loss {'Reaction outcome loss': 0.37609017061772365, 'Total loss': 0.37609017061772365}
2022-12-31 11:13:29,286 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:29,287 INFO:     Epoch: 22
2022-12-31 11:13:30,872 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4439772268136342, 'Total loss': 0.4439772268136342} | train loss {'Reaction outcome loss': 0.373379083834725, 'Total loss': 0.373379083834725}
2022-12-31 11:13:30,872 INFO:     Found new best model at epoch 22
2022-12-31 11:13:30,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:30,873 INFO:     Epoch: 23
2022-12-31 11:13:32,452 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46321588158607485, 'Total loss': 0.46321588158607485} | train loss {'Reaction outcome loss': 0.35758444256125355, 'Total loss': 0.35758444256125355}
2022-12-31 11:13:32,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:32,452 INFO:     Epoch: 24
2022-12-31 11:13:34,051 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.44417848289012907, 'Total loss': 0.44417848289012907} | train loss {'Reaction outcome loss': 0.35439698242551676, 'Total loss': 0.35439698242551676}
2022-12-31 11:13:34,052 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:34,052 INFO:     Epoch: 25
2022-12-31 11:13:35,652 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.443795249859492, 'Total loss': 0.443795249859492} | train loss {'Reaction outcome loss': 0.3567182374879336, 'Total loss': 0.3567182374879336}
2022-12-31 11:13:35,653 INFO:     Found new best model at epoch 25
2022-12-31 11:13:35,654 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:35,654 INFO:     Epoch: 26
2022-12-31 11:13:37,258 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4870088795820872, 'Total loss': 0.4870088795820872} | train loss {'Reaction outcome loss': 0.3474464672839358, 'Total loss': 0.3474464672839358}
2022-12-31 11:13:37,258 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:37,258 INFO:     Epoch: 27
2022-12-31 11:13:38,836 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5107881426811218, 'Total loss': 0.5107881426811218} | train loss {'Reaction outcome loss': 0.34481723049839774, 'Total loss': 0.34481723049839774}
2022-12-31 11:13:38,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:38,837 INFO:     Epoch: 28
2022-12-31 11:13:40,436 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.45028121769428253, 'Total loss': 0.45028121769428253} | train loss {'Reaction outcome loss': 0.35174557610309165, 'Total loss': 0.35174557610309165}
2022-12-31 11:13:40,436 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:40,436 INFO:     Epoch: 29
2022-12-31 11:13:42,022 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4891107171773911, 'Total loss': 0.4891107171773911} | train loss {'Reaction outcome loss': 0.3411229914361304, 'Total loss': 0.3411229914361304}
2022-12-31 11:13:42,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:42,022 INFO:     Epoch: 30
2022-12-31 11:13:43,623 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43452652792135876, 'Total loss': 0.43452652792135876} | train loss {'Reaction outcome loss': 0.33437865246564913, 'Total loss': 0.33437865246564913}
2022-12-31 11:13:43,623 INFO:     Found new best model at epoch 30
2022-12-31 11:13:43,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:43,624 INFO:     Epoch: 31
2022-12-31 11:13:45,225 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4189403613408407, 'Total loss': 0.4189403613408407} | train loss {'Reaction outcome loss': 0.3243732795719699, 'Total loss': 0.3243732795719699}
2022-12-31 11:13:45,225 INFO:     Found new best model at epoch 31
2022-12-31 11:13:45,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:45,226 INFO:     Epoch: 32
2022-12-31 11:13:46,827 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41521225894490876, 'Total loss': 0.41521225894490876} | train loss {'Reaction outcome loss': 0.3201939009825934, 'Total loss': 0.3201939009825934}
2022-12-31 11:13:46,828 INFO:     Found new best model at epoch 32
2022-12-31 11:13:46,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:46,829 INFO:     Epoch: 33
2022-12-31 11:13:48,454 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4327522685130437, 'Total loss': 0.4327522685130437} | train loss {'Reaction outcome loss': 0.3228977367882327, 'Total loss': 0.3228977367882327}
2022-12-31 11:13:48,454 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:48,454 INFO:     Epoch: 34
2022-12-31 11:13:50,106 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4630946606397629, 'Total loss': 0.4630946606397629} | train loss {'Reaction outcome loss': 0.32546236226846886, 'Total loss': 0.32546236226846886}
2022-12-31 11:13:50,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:50,106 INFO:     Epoch: 35
2022-12-31 11:13:51,748 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45860333343346915, 'Total loss': 0.45860333343346915} | train loss {'Reaction outcome loss': 0.31183525962216074, 'Total loss': 0.31183525962216074}
2022-12-31 11:13:51,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:51,748 INFO:     Epoch: 36
2022-12-31 11:13:53,357 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4501683150728544, 'Total loss': 0.4501683150728544} | train loss {'Reaction outcome loss': 0.30560448610193125, 'Total loss': 0.30560448610193125}
2022-12-31 11:13:53,358 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:53,358 INFO:     Epoch: 37
2022-12-31 11:13:54,984 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4187572956085205, 'Total loss': 0.4187572956085205} | train loss {'Reaction outcome loss': 0.3083899588948423, 'Total loss': 0.3083899588948423}
2022-12-31 11:13:54,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:54,984 INFO:     Epoch: 38
2022-12-31 11:13:56,624 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45005626380443575, 'Total loss': 0.45005626380443575} | train loss {'Reaction outcome loss': 0.3018446253005402, 'Total loss': 0.3018446253005402}
2022-12-31 11:13:56,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:56,625 INFO:     Epoch: 39
2022-12-31 11:13:58,200 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46250553329785665, 'Total loss': 0.46250553329785665} | train loss {'Reaction outcome loss': 0.2980363040671244, 'Total loss': 0.2980363040671244}
2022-12-31 11:13:58,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:58,200 INFO:     Epoch: 40
2022-12-31 11:13:59,776 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4415365735689799, 'Total loss': 0.4415365735689799} | train loss {'Reaction outcome loss': 0.2938179173148595, 'Total loss': 0.2938179173148595}
2022-12-31 11:13:59,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:13:59,777 INFO:     Epoch: 41
2022-12-31 11:14:01,401 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4830080926418304, 'Total loss': 0.4830080926418304} | train loss {'Reaction outcome loss': 0.2907538939908747, 'Total loss': 0.2907538939908747}
2022-12-31 11:14:01,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:01,401 INFO:     Epoch: 42
2022-12-31 11:14:03,024 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43078478227059047, 'Total loss': 0.43078478227059047} | train loss {'Reaction outcome loss': 0.2982265784681498, 'Total loss': 0.2982265784681498}
2022-12-31 11:14:03,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:03,024 INFO:     Epoch: 43
2022-12-31 11:14:04,619 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4565026124318441, 'Total loss': 0.4565026124318441} | train loss {'Reaction outcome loss': 0.2867690782052475, 'Total loss': 0.2867690782052475}
2022-12-31 11:14:04,619 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:04,620 INFO:     Epoch: 44
2022-12-31 11:14:06,201 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4623143513997396, 'Total loss': 0.4623143513997396} | train loss {'Reaction outcome loss': 0.28836096157985075, 'Total loss': 0.28836096157985075}
2022-12-31 11:14:06,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:06,201 INFO:     Epoch: 45
2022-12-31 11:14:07,801 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46990099946657815, 'Total loss': 0.46990099946657815} | train loss {'Reaction outcome loss': 0.2749730282507482, 'Total loss': 0.2749730282507482}
2022-12-31 11:14:07,801 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:07,801 INFO:     Epoch: 46
2022-12-31 11:14:09,429 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5458147943019866, 'Total loss': 0.5458147943019866} | train loss {'Reaction outcome loss': 0.279073286574716, 'Total loss': 0.279073286574716}
2022-12-31 11:14:09,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:09,429 INFO:     Epoch: 47
2022-12-31 11:14:11,055 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4204950115333001, 'Total loss': 0.4204950115333001} | train loss {'Reaction outcome loss': 0.2774563824737465, 'Total loss': 0.2774563824737465}
2022-12-31 11:14:11,055 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:11,055 INFO:     Epoch: 48
2022-12-31 11:14:12,669 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47640876173973085, 'Total loss': 0.47640876173973085} | train loss {'Reaction outcome loss': 0.2645226049990881, 'Total loss': 0.2645226049990881}
2022-12-31 11:14:12,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:12,669 INFO:     Epoch: 49
2022-12-31 11:14:14,301 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4275018354256948, 'Total loss': 0.4275018354256948} | train loss {'Reaction outcome loss': 0.26522676908025594, 'Total loss': 0.26522676908025594}
2022-12-31 11:14:14,301 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:14,301 INFO:     Epoch: 50
2022-12-31 11:14:15,896 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4243347664674123, 'Total loss': 0.4243347664674123} | train loss {'Reaction outcome loss': 0.26248303579760124, 'Total loss': 0.26248303579760124}
2022-12-31 11:14:15,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:15,897 INFO:     Epoch: 51
2022-12-31 11:14:17,469 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43746763666470845, 'Total loss': 0.43746763666470845} | train loss {'Reaction outcome loss': 0.2609514071991592, 'Total loss': 0.2609514071991592}
2022-12-31 11:14:17,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:17,469 INFO:     Epoch: 52
2022-12-31 11:14:19,071 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4858951469262441, 'Total loss': 0.4858951469262441} | train loss {'Reaction outcome loss': 0.26104241825176244, 'Total loss': 0.26104241825176244}
2022-12-31 11:14:19,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:19,071 INFO:     Epoch: 53
2022-12-31 11:14:20,665 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4404181877772013, 'Total loss': 0.4404181877772013} | train loss {'Reaction outcome loss': 0.2549185574996275, 'Total loss': 0.2549185574996275}
2022-12-31 11:14:20,665 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:20,665 INFO:     Epoch: 54
2022-12-31 11:14:22,258 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41152517398198446, 'Total loss': 0.41152517398198446} | train loss {'Reaction outcome loss': 0.253209835457387, 'Total loss': 0.253209835457387}
2022-12-31 11:14:22,258 INFO:     Found new best model at epoch 54
2022-12-31 11:14:22,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:22,259 INFO:     Epoch: 55
2022-12-31 11:14:23,853 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3838986019293467, 'Total loss': 0.3838986019293467} | train loss {'Reaction outcome loss': 0.2475906554677766, 'Total loss': 0.2475906554677766}
2022-12-31 11:14:23,854 INFO:     Found new best model at epoch 55
2022-12-31 11:14:23,854 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:23,855 INFO:     Epoch: 56
2022-12-31 11:14:25,429 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4596875786781311, 'Total loss': 0.4596875786781311} | train loss {'Reaction outcome loss': 0.2553723212740906, 'Total loss': 0.2553723212740906}
2022-12-31 11:14:25,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:25,430 INFO:     Epoch: 57
2022-12-31 11:14:26,998 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43166226545969644, 'Total loss': 0.43166226545969644} | train loss {'Reaction outcome loss': 0.25123602869637285, 'Total loss': 0.25123602869637285}
2022-12-31 11:14:26,998 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:26,999 INFO:     Epoch: 58
2022-12-31 11:14:28,589 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4428525254130363, 'Total loss': 0.4428525254130363} | train loss {'Reaction outcome loss': 0.24660743111505723, 'Total loss': 0.24660743111505723}
2022-12-31 11:14:28,589 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:28,589 INFO:     Epoch: 59
2022-12-31 11:14:30,181 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.404614619910717, 'Total loss': 0.404614619910717} | train loss {'Reaction outcome loss': 0.24054241078076782, 'Total loss': 0.24054241078076782}
2022-12-31 11:14:30,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:30,182 INFO:     Epoch: 60
2022-12-31 11:14:31,775 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.418846716483434, 'Total loss': 0.418846716483434} | train loss {'Reaction outcome loss': 0.2422764316856206, 'Total loss': 0.2422764316856206}
2022-12-31 11:14:31,775 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:31,776 INFO:     Epoch: 61
2022-12-31 11:14:33,349 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4175472170114517, 'Total loss': 0.4175472170114517} | train loss {'Reaction outcome loss': 0.2444009699623336, 'Total loss': 0.2444009699623336}
2022-12-31 11:14:33,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:33,349 INFO:     Epoch: 62
2022-12-31 11:14:34,948 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4226745903491974, 'Total loss': 0.4226745903491974} | train loss {'Reaction outcome loss': 0.2480371534728851, 'Total loss': 0.2480371534728851}
2022-12-31 11:14:34,948 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:34,948 INFO:     Epoch: 63
2022-12-31 11:14:36,526 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4179902891318003, 'Total loss': 0.4179902891318003} | train loss {'Reaction outcome loss': 0.2405291205688274, 'Total loss': 0.2405291205688274}
2022-12-31 11:14:36,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:36,526 INFO:     Epoch: 64
2022-12-31 11:14:38,126 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.46773375769456227, 'Total loss': 0.46773375769456227} | train loss {'Reaction outcome loss': 0.23294982424640392, 'Total loss': 0.23294982424640392}
2022-12-31 11:14:38,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:38,126 INFO:     Epoch: 65
2022-12-31 11:14:39,725 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45046197474002836, 'Total loss': 0.45046197474002836} | train loss {'Reaction outcome loss': 0.24082495049733818, 'Total loss': 0.24082495049733818}
2022-12-31 11:14:39,726 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:39,726 INFO:     Epoch: 66
2022-12-31 11:14:41,323 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4300042112668355, 'Total loss': 0.4300042112668355} | train loss {'Reaction outcome loss': 0.2326807375492412, 'Total loss': 0.2326807375492412}
2022-12-31 11:14:41,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:41,323 INFO:     Epoch: 67
2022-12-31 11:14:42,916 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4696847955385844, 'Total loss': 0.4696847955385844} | train loss {'Reaction outcome loss': 0.23173444382436983, 'Total loss': 0.23173444382436983}
2022-12-31 11:14:42,916 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:42,916 INFO:     Epoch: 68
2022-12-31 11:14:44,524 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4605856021245321, 'Total loss': 0.4605856021245321} | train loss {'Reaction outcome loss': 0.22453743641711635, 'Total loss': 0.22453743641711635}
2022-12-31 11:14:44,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:44,524 INFO:     Epoch: 69
2022-12-31 11:14:46,120 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4475850661595662, 'Total loss': 0.4475850661595662} | train loss {'Reaction outcome loss': 0.22945309475391776, 'Total loss': 0.22945309475391776}
2022-12-31 11:14:46,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:46,120 INFO:     Epoch: 70
2022-12-31 11:14:47,714 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41143541733423866, 'Total loss': 0.41143541733423866} | train loss {'Reaction outcome loss': 0.22353191948035261, 'Total loss': 0.22353191948035261}
2022-12-31 11:14:47,714 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:47,715 INFO:     Epoch: 71
2022-12-31 11:14:49,309 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4197958320379257, 'Total loss': 0.4197958320379257} | train loss {'Reaction outcome loss': 0.23486001962870906, 'Total loss': 0.23486001962870906}
2022-12-31 11:14:49,309 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:49,309 INFO:     Epoch: 72
2022-12-31 11:14:50,903 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4173322151104609, 'Total loss': 0.4173322151104609} | train loss {'Reaction outcome loss': 0.22051576045324733, 'Total loss': 0.22051576045324733}
2022-12-31 11:14:50,903 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:50,903 INFO:     Epoch: 73
2022-12-31 11:14:52,479 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4242340197165807, 'Total loss': 0.4242340197165807} | train loss {'Reaction outcome loss': 0.2281627486640717, 'Total loss': 0.2281627486640717}
2022-12-31 11:14:52,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:52,479 INFO:     Epoch: 74
2022-12-31 11:14:54,061 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4137806760768096, 'Total loss': 0.4137806760768096} | train loss {'Reaction outcome loss': 0.22700478584120126, 'Total loss': 0.22700478584120126}
2022-12-31 11:14:54,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:54,061 INFO:     Epoch: 75
2022-12-31 11:14:55,683 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47226299345493317, 'Total loss': 0.47226299345493317} | train loss {'Reaction outcome loss': 0.21722258874402814, 'Total loss': 0.21722258874402814}
2022-12-31 11:14:55,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:55,683 INFO:     Epoch: 76
2022-12-31 11:14:57,274 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41362052659193677, 'Total loss': 0.41362052659193677} | train loss {'Reaction outcome loss': 0.22832214521182762, 'Total loss': 0.22832214521182762}
2022-12-31 11:14:57,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:57,274 INFO:     Epoch: 77
2022-12-31 11:14:58,861 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.437693735708793, 'Total loss': 0.437693735708793} | train loss {'Reaction outcome loss': 0.21665104036475277, 'Total loss': 0.21665104036475277}
2022-12-31 11:14:58,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:14:58,862 INFO:     Epoch: 78
2022-12-31 11:15:00,468 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4595009783903758, 'Total loss': 0.4595009783903758} | train loss {'Reaction outcome loss': 0.21629095855322514, 'Total loss': 0.21629095855322514}
2022-12-31 11:15:00,468 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:00,468 INFO:     Epoch: 79
2022-12-31 11:15:02,092 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46608848770459493, 'Total loss': 0.46608848770459493} | train loss {'Reaction outcome loss': 0.21671675426046272, 'Total loss': 0.21671675426046272}
2022-12-31 11:15:02,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:02,092 INFO:     Epoch: 80
2022-12-31 11:15:03,696 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40990838905175525, 'Total loss': 0.40990838905175525} | train loss {'Reaction outcome loss': 0.21194115454406093, 'Total loss': 0.21194115454406093}
2022-12-31 11:15:03,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:03,696 INFO:     Epoch: 81
2022-12-31 11:15:05,310 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42669519086678825, 'Total loss': 0.42669519086678825} | train loss {'Reaction outcome loss': 0.2128451684619481, 'Total loss': 0.2128451684619481}
2022-12-31 11:15:05,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:05,311 INFO:     Epoch: 82
2022-12-31 11:15:06,881 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4384790867567062, 'Total loss': 0.4384790867567062} | train loss {'Reaction outcome loss': 0.2081685468977515, 'Total loss': 0.2081685468977515}
2022-12-31 11:15:06,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:06,881 INFO:     Epoch: 83
2022-12-31 11:15:08,471 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4818767637014389, 'Total loss': 0.4818767637014389} | train loss {'Reaction outcome loss': 0.21310879264176982, 'Total loss': 0.21310879264176982}
2022-12-31 11:15:08,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:08,472 INFO:     Epoch: 84
2022-12-31 11:15:10,059 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.463268722097079, 'Total loss': 0.463268722097079} | train loss {'Reaction outcome loss': 0.2135899524603571, 'Total loss': 0.2135899524603571}
2022-12-31 11:15:10,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:10,059 INFO:     Epoch: 85
2022-12-31 11:15:11,620 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43901901443799335, 'Total loss': 0.43901901443799335} | train loss {'Reaction outcome loss': 0.2114865739758198, 'Total loss': 0.2114865739758198}
2022-12-31 11:15:11,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:11,620 INFO:     Epoch: 86
2022-12-31 11:15:13,230 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4694557358821233, 'Total loss': 0.4694557358821233} | train loss {'Reaction outcome loss': 0.21308665968232102, 'Total loss': 0.21308665968232102}
2022-12-31 11:15:13,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:13,230 INFO:     Epoch: 87
2022-12-31 11:15:14,818 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4115888958175977, 'Total loss': 0.4115888958175977} | train loss {'Reaction outcome loss': 0.21186403000911513, 'Total loss': 0.21186403000911513}
2022-12-31 11:15:14,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:14,818 INFO:     Epoch: 88
2022-12-31 11:15:16,406 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.46735963026682537, 'Total loss': 0.46735963026682537} | train loss {'Reaction outcome loss': 0.2067138777411246, 'Total loss': 0.2067138777411246}
2022-12-31 11:15:16,406 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:16,406 INFO:     Epoch: 89
2022-12-31 11:15:17,994 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43104596237341564, 'Total loss': 0.43104596237341564} | train loss {'Reaction outcome loss': 0.20145522344570893, 'Total loss': 0.20145522344570893}
2022-12-31 11:15:17,995 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:17,996 INFO:     Epoch: 90
2022-12-31 11:15:19,600 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41227720975875853, 'Total loss': 0.41227720975875853} | train loss {'Reaction outcome loss': 0.2028963113469737, 'Total loss': 0.2028963113469737}
2022-12-31 11:15:19,600 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:19,600 INFO:     Epoch: 91
2022-12-31 11:15:21,214 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39449259638786316, 'Total loss': 0.39449259638786316} | train loss {'Reaction outcome loss': 0.20638603637602193, 'Total loss': 0.20638603637602193}
2022-12-31 11:15:21,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:21,215 INFO:     Epoch: 92
2022-12-31 11:15:22,806 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47241850892702736, 'Total loss': 0.47241850892702736} | train loss {'Reaction outcome loss': 0.20600024744486198, 'Total loss': 0.20600024744486198}
2022-12-31 11:15:22,806 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:22,806 INFO:     Epoch: 93
2022-12-31 11:15:24,397 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.43993149598439535, 'Total loss': 0.43993149598439535} | train loss {'Reaction outcome loss': 0.2006812884980615, 'Total loss': 0.2006812884980615}
2022-12-31 11:15:24,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:24,397 INFO:     Epoch: 94
2022-12-31 11:15:25,986 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.45943915049235023, 'Total loss': 0.45943915049235023} | train loss {'Reaction outcome loss': 0.20478496259767495, 'Total loss': 0.20478496259767495}
2022-12-31 11:15:25,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:25,986 INFO:     Epoch: 95
2022-12-31 11:15:27,582 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43472861250241596, 'Total loss': 0.43472861250241596} | train loss {'Reaction outcome loss': 0.21411828445645917, 'Total loss': 0.21411828445645917}
2022-12-31 11:15:27,582 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:27,582 INFO:     Epoch: 96
2022-12-31 11:15:29,171 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4078502689798673, 'Total loss': 0.4078502689798673} | train loss {'Reaction outcome loss': 0.20047191542406112, 'Total loss': 0.20047191542406112}
2022-12-31 11:15:29,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:29,172 INFO:     Epoch: 97
2022-12-31 11:15:30,748 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4756888926029205, 'Total loss': 0.4756888926029205} | train loss {'Reaction outcome loss': 0.1993869189957614, 'Total loss': 0.1993869189957614}
2022-12-31 11:15:30,748 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:30,748 INFO:     Epoch: 98
2022-12-31 11:15:32,336 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4147606352965037, 'Total loss': 0.4147606352965037} | train loss {'Reaction outcome loss': 0.19659833980539998, 'Total loss': 0.19659833980539998}
2022-12-31 11:15:32,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:32,336 INFO:     Epoch: 99
2022-12-31 11:15:33,926 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.38795437042911846, 'Total loss': 0.38795437042911846} | train loss {'Reaction outcome loss': 0.19705471198582825, 'Total loss': 0.19705471198582825}
2022-12-31 11:15:33,926 INFO:     Best model found after epoch 56 of 100.
2022-12-31 11:15:33,927 INFO:   Done with stage: TRAINING
2022-12-31 11:15:33,927 INFO:   Starting stage: EVALUATION
2022-12-31 11:15:34,065 INFO:   Done with stage: EVALUATION
2022-12-31 11:15:34,066 INFO:   Leaving out SEQ value Fold_9
2022-12-31 11:15:34,078 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 11:15:34,078 INFO:   Starting stage: FEATURE SCALING
2022-12-31 11:15:34,723 INFO:   Done with stage: FEATURE SCALING
2022-12-31 11:15:34,723 INFO:   Starting stage: SCALING TARGETS
2022-12-31 11:15:34,792 INFO:   Done with stage: SCALING TARGETS
2022-12-31 11:15:34,792 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:15:34,792 INFO:     No hyperparam tuning for this model
2022-12-31 11:15:34,792 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:15:34,792 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 11:15:34,793 INFO:     None feature selector for col prot
2022-12-31 11:15:34,793 INFO:     None feature selector for col prot
2022-12-31 11:15:34,793 INFO:     None feature selector for col prot
2022-12-31 11:15:34,794 INFO:     None feature selector for col chem
2022-12-31 11:15:34,794 INFO:     None feature selector for col chem
2022-12-31 11:15:34,794 INFO:     None feature selector for col chem
2022-12-31 11:15:34,794 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 11:15:34,794 INFO:   Starting stage: BUILD MODEL
2022-12-31 11:15:34,796 INFO:     Number of params in model 223921
2022-12-31 11:15:34,799 INFO:   Done with stage: BUILD MODEL
2022-12-31 11:15:34,799 INFO:   Starting stage: TRAINING
2022-12-31 11:15:34,845 INFO:     Val loss before train {'Reaction outcome loss': 0.9893220424652099, 'Total loss': 0.9893220424652099}
2022-12-31 11:15:34,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:34,845 INFO:     Epoch: 0
2022-12-31 11:15:36,460 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6254578689734142, 'Total loss': 0.6254578689734142} | train loss {'Reaction outcome loss': 0.8245215149245401, 'Total loss': 0.8245215149245401}
2022-12-31 11:15:36,461 INFO:     Found new best model at epoch 0
2022-12-31 11:15:36,462 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:36,462 INFO:     Epoch: 1
2022-12-31 11:15:38,093 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.46721669236818947, 'Total loss': 0.46721669236818947} | train loss {'Reaction outcome loss': 0.6062008340613566, 'Total loss': 0.6062008340613566}
2022-12-31 11:15:38,093 INFO:     Found new best model at epoch 1
2022-12-31 11:15:38,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:38,094 INFO:     Epoch: 2
2022-12-31 11:15:39,694 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49802604715029397, 'Total loss': 0.49802604715029397} | train loss {'Reaction outcome loss': 0.5334428508151863, 'Total loss': 0.5334428508151863}
2022-12-31 11:15:39,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:39,694 INFO:     Epoch: 3
2022-12-31 11:15:41,294 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4519606669743856, 'Total loss': 0.4519606669743856} | train loss {'Reaction outcome loss': 0.5271217853532754, 'Total loss': 0.5271217853532754}
2022-12-31 11:15:41,294 INFO:     Found new best model at epoch 3
2022-12-31 11:15:41,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:41,295 INFO:     Epoch: 4
2022-12-31 11:15:42,933 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.42516658306121824, 'Total loss': 0.42516658306121824} | train loss {'Reaction outcome loss': 0.4916684702713636, 'Total loss': 0.4916684702713636}
2022-12-31 11:15:42,933 INFO:     Found new best model at epoch 4
2022-12-31 11:15:42,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:42,934 INFO:     Epoch: 5
2022-12-31 11:15:44,547 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.41992162068684896, 'Total loss': 0.41992162068684896} | train loss {'Reaction outcome loss': 0.4768210013913315, 'Total loss': 0.4768210013913315}
2022-12-31 11:15:44,547 INFO:     Found new best model at epoch 5
2022-12-31 11:15:44,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:44,548 INFO:     Epoch: 6
2022-12-31 11:15:46,148 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4332665582497915, 'Total loss': 0.4332665582497915} | train loss {'Reaction outcome loss': 0.46698664144919283, 'Total loss': 0.46698664144919283}
2022-12-31 11:15:46,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:46,148 INFO:     Epoch: 7
2022-12-31 11:15:47,742 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.430398162206014, 'Total loss': 0.430398162206014} | train loss {'Reaction outcome loss': 0.4589530736936823, 'Total loss': 0.4589530736936823}
2022-12-31 11:15:47,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:47,742 INFO:     Epoch: 8
2022-12-31 11:15:49,352 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.41035378475983936, 'Total loss': 0.41035378475983936} | train loss {'Reaction outcome loss': 0.4541410949721045, 'Total loss': 0.4541410949721045}
2022-12-31 11:15:49,353 INFO:     Found new best model at epoch 8
2022-12-31 11:15:49,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:49,354 INFO:     Epoch: 9
2022-12-31 11:15:50,963 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4271805206934611, 'Total loss': 0.4271805206934611} | train loss {'Reaction outcome loss': 0.44157676157614123, 'Total loss': 0.44157676157614123}
2022-12-31 11:15:50,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:50,964 INFO:     Epoch: 10
2022-12-31 11:15:52,573 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3947995369633039, 'Total loss': 0.3947995369633039} | train loss {'Reaction outcome loss': 0.43945190882094315, 'Total loss': 0.43945190882094315}
2022-12-31 11:15:52,573 INFO:     Found new best model at epoch 10
2022-12-31 11:15:52,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:52,574 INFO:     Epoch: 11
2022-12-31 11:15:54,182 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.38520945807298024, 'Total loss': 0.38520945807298024} | train loss {'Reaction outcome loss': 0.4343624591584439, 'Total loss': 0.4343624591584439}
2022-12-31 11:15:54,182 INFO:     Found new best model at epoch 11
2022-12-31 11:15:54,183 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:54,183 INFO:     Epoch: 12
2022-12-31 11:15:55,804 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39489046633243563, 'Total loss': 0.39489046633243563} | train loss {'Reaction outcome loss': 0.423854293456922, 'Total loss': 0.423854293456922}
2022-12-31 11:15:55,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:55,804 INFO:     Epoch: 13
2022-12-31 11:15:57,420 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4174462705850601, 'Total loss': 0.4174462705850601} | train loss {'Reaction outcome loss': 0.42393159553192666, 'Total loss': 0.42393159553192666}
2022-12-31 11:15:57,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:57,420 INFO:     Epoch: 14
2022-12-31 11:15:59,058 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43769046664237976, 'Total loss': 0.43769046664237976} | train loss {'Reaction outcome loss': 0.49257533158769534, 'Total loss': 0.49257533158769534}
2022-12-31 11:15:59,059 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:15:59,059 INFO:     Epoch: 15
2022-12-31 11:16:00,679 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42150591413180033, 'Total loss': 0.42150591413180033} | train loss {'Reaction outcome loss': 0.448358911589004, 'Total loss': 0.448358911589004}
2022-12-31 11:16:00,679 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:00,679 INFO:     Epoch: 16
2022-12-31 11:16:02,311 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4147356738646825, 'Total loss': 0.4147356738646825} | train loss {'Reaction outcome loss': 0.4721047839932684, 'Total loss': 0.4721047839932684}
2022-12-31 11:16:02,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:02,312 INFO:     Epoch: 17
2022-12-31 11:16:03,941 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41243262887001036, 'Total loss': 0.41243262887001036} | train loss {'Reaction outcome loss': 0.4268839815631509, 'Total loss': 0.4268839815631509}
2022-12-31 11:16:03,941 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:03,941 INFO:     Epoch: 18
2022-12-31 11:16:05,570 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41844861110051473, 'Total loss': 0.41844861110051473} | train loss {'Reaction outcome loss': 0.414201467729889, 'Total loss': 0.414201467729889}
2022-12-31 11:16:05,571 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:05,571 INFO:     Epoch: 19
2022-12-31 11:16:07,184 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40505815545717877, 'Total loss': 0.40505815545717877} | train loss {'Reaction outcome loss': 0.4022829850082812, 'Total loss': 0.4022829850082812}
2022-12-31 11:16:07,184 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:07,184 INFO:     Epoch: 20
2022-12-31 11:16:08,797 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39651751120885215, 'Total loss': 0.39651751120885215} | train loss {'Reaction outcome loss': 0.39979728624778055, 'Total loss': 0.39979728624778055}
2022-12-31 11:16:08,797 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:08,797 INFO:     Epoch: 21
2022-12-31 11:16:10,411 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4222721854845683, 'Total loss': 0.4222721854845683} | train loss {'Reaction outcome loss': 0.39105039592022484, 'Total loss': 0.39105039592022484}
2022-12-31 11:16:10,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:10,411 INFO:     Epoch: 22
2022-12-31 11:16:12,023 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.39855742156505586, 'Total loss': 0.39855742156505586} | train loss {'Reaction outcome loss': 0.38462264380971156, 'Total loss': 0.38462264380971156}
2022-12-31 11:16:12,024 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:12,024 INFO:     Epoch: 23
2022-12-31 11:16:13,618 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3920212576786677, 'Total loss': 0.3920212576786677} | train loss {'Reaction outcome loss': 0.3811406113639258, 'Total loss': 0.3811406113639258}
2022-12-31 11:16:13,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:13,618 INFO:     Epoch: 24
2022-12-31 11:16:15,219 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3930755168199539, 'Total loss': 0.3930755168199539} | train loss {'Reaction outcome loss': 0.37631470000074396, 'Total loss': 0.37631470000074396}
2022-12-31 11:16:15,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:15,219 INFO:     Epoch: 25
2022-12-31 11:16:16,836 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3761590530474981, 'Total loss': 0.3761590530474981} | train loss {'Reaction outcome loss': 0.36921142513587046, 'Total loss': 0.36921142513587046}
2022-12-31 11:16:16,836 INFO:     Found new best model at epoch 25
2022-12-31 11:16:16,837 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:16,837 INFO:     Epoch: 26
2022-12-31 11:16:18,452 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3874157855908076, 'Total loss': 0.3874157855908076} | train loss {'Reaction outcome loss': 0.3650669571814934, 'Total loss': 0.3650669571814934}
2022-12-31 11:16:18,452 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:18,452 INFO:     Epoch: 27
2022-12-31 11:16:20,109 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3714381148417791, 'Total loss': 0.3714381148417791} | train loss {'Reaction outcome loss': 0.37231074422057986, 'Total loss': 0.37231074422057986}
2022-12-31 11:16:20,109 INFO:     Found new best model at epoch 27
2022-12-31 11:16:20,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:20,110 INFO:     Epoch: 28
2022-12-31 11:16:21,688 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.39556785523891447, 'Total loss': 0.39556785523891447} | train loss {'Reaction outcome loss': 0.40094125954656984, 'Total loss': 0.40094125954656984}
2022-12-31 11:16:21,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:21,688 INFO:     Epoch: 29
2022-12-31 11:16:23,303 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39023628532886506, 'Total loss': 0.39023628532886506} | train loss {'Reaction outcome loss': 0.35688294877088966, 'Total loss': 0.35688294877088966}
2022-12-31 11:16:23,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:23,303 INFO:     Epoch: 30
2022-12-31 11:16:24,941 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3646028449138006, 'Total loss': 0.3646028449138006} | train loss {'Reaction outcome loss': 0.34960575310000475, 'Total loss': 0.34960575310000475}
2022-12-31 11:16:24,941 INFO:     Found new best model at epoch 30
2022-12-31 11:16:24,942 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:24,943 INFO:     Epoch: 31
2022-12-31 11:16:26,573 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.36621799468994143, 'Total loss': 0.36621799468994143} | train loss {'Reaction outcome loss': 0.3385189905791354, 'Total loss': 0.3385189905791354}
2022-12-31 11:16:26,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:26,573 INFO:     Epoch: 32
2022-12-31 11:16:28,204 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3558779666821162, 'Total loss': 0.3558779666821162} | train loss {'Reaction outcome loss': 0.33872073614106013, 'Total loss': 0.33872073614106013}
2022-12-31 11:16:28,204 INFO:     Found new best model at epoch 32
2022-12-31 11:16:28,205 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:28,205 INFO:     Epoch: 33
2022-12-31 11:16:29,819 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3825610021750132, 'Total loss': 0.3825610021750132} | train loss {'Reaction outcome loss': 0.3303714809210404, 'Total loss': 0.3303714809210404}
2022-12-31 11:16:29,819 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:29,819 INFO:     Epoch: 34
2022-12-31 11:16:31,417 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4137176503737768, 'Total loss': 0.4137176503737768} | train loss {'Reaction outcome loss': 0.327976864697437, 'Total loss': 0.327976864697437}
2022-12-31 11:16:31,417 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:31,417 INFO:     Epoch: 35
2022-12-31 11:16:33,046 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3591813951730728, 'Total loss': 0.3591813951730728} | train loss {'Reaction outcome loss': 0.32185203124485584, 'Total loss': 0.32185203124485584}
2022-12-31 11:16:33,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:33,046 INFO:     Epoch: 36
2022-12-31 11:16:34,662 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3589156672358513, 'Total loss': 0.3589156672358513} | train loss {'Reaction outcome loss': 0.33687341016163863, 'Total loss': 0.33687341016163863}
2022-12-31 11:16:34,662 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:34,662 INFO:     Epoch: 37
2022-12-31 11:16:36,278 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.34593669505168995, 'Total loss': 0.34593669505168995} | train loss {'Reaction outcome loss': 0.3213477638158677, 'Total loss': 0.3213477638158677}
2022-12-31 11:16:36,279 INFO:     Found new best model at epoch 37
2022-12-31 11:16:36,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:36,280 INFO:     Epoch: 38
2022-12-31 11:16:37,893 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3977303892374039, 'Total loss': 0.3977303892374039} | train loss {'Reaction outcome loss': 0.31287572706492356, 'Total loss': 0.31287572706492356}
2022-12-31 11:16:37,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:37,894 INFO:     Epoch: 39
2022-12-31 11:16:39,510 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3628866096337636, 'Total loss': 0.3628866096337636} | train loss {'Reaction outcome loss': 0.3096466874931534, 'Total loss': 0.3096466874931534}
2022-12-31 11:16:39,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:39,510 INFO:     Epoch: 40
2022-12-31 11:16:41,108 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3718536953131358, 'Total loss': 0.3718536953131358} | train loss {'Reaction outcome loss': 0.306814745898642, 'Total loss': 0.306814745898642}
2022-12-31 11:16:41,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:41,108 INFO:     Epoch: 41
2022-12-31 11:16:42,706 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40525535941123964, 'Total loss': 0.40525535941123964} | train loss {'Reaction outcome loss': 0.3031886739992078, 'Total loss': 0.3031886739992078}
2022-12-31 11:16:42,707 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:42,707 INFO:     Epoch: 42
2022-12-31 11:16:44,322 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.37367333968480426, 'Total loss': 0.37367333968480426} | train loss {'Reaction outcome loss': 0.2986056861898734, 'Total loss': 0.2986056861898734}
2022-12-31 11:16:44,322 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:44,323 INFO:     Epoch: 43
2022-12-31 11:16:45,938 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3541479547818502, 'Total loss': 0.3541479547818502} | train loss {'Reaction outcome loss': 0.30003169269419866, 'Total loss': 0.30003169269419866}
2022-12-31 11:16:45,939 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:45,939 INFO:     Epoch: 44
2022-12-31 11:16:47,554 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.33784599701563517, 'Total loss': 0.33784599701563517} | train loss {'Reaction outcome loss': 0.2974081493589504, 'Total loss': 0.2974081493589504}
2022-12-31 11:16:47,555 INFO:     Found new best model at epoch 44
2022-12-31 11:16:47,555 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:47,556 INFO:     Epoch: 45
2022-12-31 11:16:49,152 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.36799008746941886, 'Total loss': 0.36799008746941886} | train loss {'Reaction outcome loss': 0.29260732537111017, 'Total loss': 0.29260732537111017}
2022-12-31 11:16:49,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:49,152 INFO:     Epoch: 46
2022-12-31 11:16:50,755 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3851722329854965, 'Total loss': 0.3851722329854965} | train loss {'Reaction outcome loss': 0.2824871156624505, 'Total loss': 0.2824871156624505}
2022-12-31 11:16:50,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:50,755 INFO:     Epoch: 47
2022-12-31 11:16:52,409 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3767317180832227, 'Total loss': 0.3767317180832227} | train loss {'Reaction outcome loss': 0.291680983607691, 'Total loss': 0.291680983607691}
2022-12-31 11:16:52,409 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:52,409 INFO:     Epoch: 48
2022-12-31 11:16:54,079 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3644199579954147, 'Total loss': 0.3644199579954147} | train loss {'Reaction outcome loss': 0.28163552916220913, 'Total loss': 0.28163552916220913}
2022-12-31 11:16:54,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:54,079 INFO:     Epoch: 49
2022-12-31 11:16:55,696 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.36650804976622264, 'Total loss': 0.36650804976622264} | train loss {'Reaction outcome loss': 0.2760408388423747, 'Total loss': 0.2760408388423747}
2022-12-31 11:16:55,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:55,696 INFO:     Epoch: 50
2022-12-31 11:16:57,310 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40459751784801484, 'Total loss': 0.40459751784801484} | train loss {'Reaction outcome loss': 0.29708233451727184, 'Total loss': 0.29708233451727184}
2022-12-31 11:16:57,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:57,310 INFO:     Epoch: 51
2022-12-31 11:16:58,906 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3453424245119095, 'Total loss': 0.3453424245119095} | train loss {'Reaction outcome loss': 0.27237563669819115, 'Total loss': 0.27237563669819115}
2022-12-31 11:16:58,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:16:58,906 INFO:     Epoch: 52
2022-12-31 11:17:00,515 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3701862802108129, 'Total loss': 0.3701862802108129} | train loss {'Reaction outcome loss': 0.27691495122954896, 'Total loss': 0.27691495122954896}
2022-12-31 11:17:00,515 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:00,515 INFO:     Epoch: 53
2022-12-31 11:17:02,152 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.37951011856396993, 'Total loss': 0.37951011856396993} | train loss {'Reaction outcome loss': 0.2783169944083498, 'Total loss': 0.2783169944083498}
2022-12-31 11:17:02,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:02,152 INFO:     Epoch: 54
2022-12-31 11:17:03,764 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3805913746356964, 'Total loss': 0.3805913746356964} | train loss {'Reaction outcome loss': 0.26916438490856753, 'Total loss': 0.26916438490856753}
2022-12-31 11:17:03,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:03,764 INFO:     Epoch: 55
2022-12-31 11:17:05,376 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3336379021406174, 'Total loss': 0.3336379021406174} | train loss {'Reaction outcome loss': 0.26564005136073765, 'Total loss': 0.26564005136073765}
2022-12-31 11:17:05,376 INFO:     Found new best model at epoch 55
2022-12-31 11:17:05,377 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:05,377 INFO:     Epoch: 56
2022-12-31 11:17:06,967 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.36352127194404604, 'Total loss': 0.36352127194404604} | train loss {'Reaction outcome loss': 0.26371595180303237, 'Total loss': 0.26371595180303237}
2022-12-31 11:17:06,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:06,968 INFO:     Epoch: 57
2022-12-31 11:17:08,580 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3689478566249212, 'Total loss': 0.3689478566249212} | train loss {'Reaction outcome loss': 0.26607518655372836, 'Total loss': 0.26607518655372836}
2022-12-31 11:17:08,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:08,580 INFO:     Epoch: 58
2022-12-31 11:17:10,178 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3693751126527786, 'Total loss': 0.3693751126527786} | train loss {'Reaction outcome loss': 0.2718143362123384, 'Total loss': 0.2718143362123384}
2022-12-31 11:17:10,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:10,178 INFO:     Epoch: 59
2022-12-31 11:17:11,790 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.38384814113378524, 'Total loss': 0.38384814113378524} | train loss {'Reaction outcome loss': 0.26331585565155063, 'Total loss': 0.26331585565155063}
2022-12-31 11:17:11,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:11,790 INFO:     Epoch: 60
2022-12-31 11:17:13,402 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.381970950961113, 'Total loss': 0.381970950961113} | train loss {'Reaction outcome loss': 0.2559227541795986, 'Total loss': 0.2559227541795986}
2022-12-31 11:17:13,403 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:13,403 INFO:     Epoch: 61
2022-12-31 11:17:15,014 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38694968521595, 'Total loss': 0.38694968521595} | train loss {'Reaction outcome loss': 0.2596728796463298, 'Total loss': 0.2596728796463298}
2022-12-31 11:17:15,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:15,015 INFO:     Epoch: 62
2022-12-31 11:17:16,606 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.35945823093255364, 'Total loss': 0.35945823093255364} | train loss {'Reaction outcome loss': 0.25756302244954515, 'Total loss': 0.25756302244954515}
2022-12-31 11:17:16,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:16,607 INFO:     Epoch: 63
2022-12-31 11:17:18,198 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3973203619321187, 'Total loss': 0.3973203619321187} | train loss {'Reaction outcome loss': 0.25043347058817744, 'Total loss': 0.25043347058817744}
2022-12-31 11:17:18,198 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:18,198 INFO:     Epoch: 64
2022-12-31 11:17:19,810 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3734569102525711, 'Total loss': 0.3734569102525711} | train loss {'Reaction outcome loss': 0.27231513955832826, 'Total loss': 0.27231513955832826}
2022-12-31 11:17:19,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:19,811 INFO:     Epoch: 65
2022-12-31 11:17:21,422 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3772929638624191, 'Total loss': 0.3772929638624191} | train loss {'Reaction outcome loss': 0.3284297686481875, 'Total loss': 0.3284297686481875}
2022-12-31 11:17:21,422 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:21,423 INFO:     Epoch: 66
2022-12-31 11:17:23,035 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3586439942320188, 'Total loss': 0.3586439942320188} | train loss {'Reaction outcome loss': 0.277824165112258, 'Total loss': 0.277824165112258}
2022-12-31 11:17:23,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:23,035 INFO:     Epoch: 67
2022-12-31 11:17:24,647 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3745271960894267, 'Total loss': 0.3745271960894267} | train loss {'Reaction outcome loss': 0.25941201607507747, 'Total loss': 0.25941201607507747}
2022-12-31 11:17:24,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:24,647 INFO:     Epoch: 68
2022-12-31 11:17:26,245 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39052232007185617, 'Total loss': 0.39052232007185617} | train loss {'Reaction outcome loss': 0.25579174433021207, 'Total loss': 0.25579174433021207}
2022-12-31 11:17:26,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:26,246 INFO:     Epoch: 69
2022-12-31 11:17:27,862 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.35380892306566236, 'Total loss': 0.35380892306566236} | train loss {'Reaction outcome loss': 0.25192331241998833, 'Total loss': 0.25192331241998833}
2022-12-31 11:17:27,862 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:27,862 INFO:     Epoch: 70
2022-12-31 11:17:29,527 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3914829343557358, 'Total loss': 0.3914829343557358} | train loss {'Reaction outcome loss': 0.2539510167586833, 'Total loss': 0.2539510167586833}
2022-12-31 11:17:29,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:29,528 INFO:     Epoch: 71
2022-12-31 11:17:31,147 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3997158755858739, 'Total loss': 0.3997158755858739} | train loss {'Reaction outcome loss': 0.24804181417963211, 'Total loss': 0.24804181417963211}
2022-12-31 11:17:31,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:31,148 INFO:     Epoch: 72
2022-12-31 11:17:32,764 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3630243291457494, 'Total loss': 0.3630243291457494} | train loss {'Reaction outcome loss': 0.24713458655405438, 'Total loss': 0.24713458655405438}
2022-12-31 11:17:32,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:32,764 INFO:     Epoch: 73
2022-12-31 11:17:34,359 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.35285776608313124, 'Total loss': 0.35285776608313124} | train loss {'Reaction outcome loss': 0.24755037079929657, 'Total loss': 0.24755037079929657}
2022-12-31 11:17:34,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:34,359 INFO:     Epoch: 74
2022-12-31 11:17:35,969 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3823575963576635, 'Total loss': 0.3823575963576635} | train loss {'Reaction outcome loss': 0.23739645598064837, 'Total loss': 0.23739645598064837}
2022-12-31 11:17:35,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:35,969 INFO:     Epoch: 75
2022-12-31 11:17:37,620 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.35245643357435863, 'Total loss': 0.35245643357435863} | train loss {'Reaction outcome loss': 0.23588531166973079, 'Total loss': 0.23588531166973079}
2022-12-31 11:17:37,621 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:37,621 INFO:     Epoch: 76
2022-12-31 11:17:39,252 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4005648026863734, 'Total loss': 0.4005648026863734} | train loss {'Reaction outcome loss': 0.237859863291859, 'Total loss': 0.237859863291859}
2022-12-31 11:17:39,252 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:39,252 INFO:     Epoch: 77
2022-12-31 11:17:40,869 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3547747736175855, 'Total loss': 0.3547747736175855} | train loss {'Reaction outcome loss': 0.23528952063128783, 'Total loss': 0.23528952063128783}
2022-12-31 11:17:40,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:40,869 INFO:     Epoch: 78
2022-12-31 11:17:42,486 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4067443867524465, 'Total loss': 0.4067443867524465} | train loss {'Reaction outcome loss': 0.22856159641072527, 'Total loss': 0.22856159641072527}
2022-12-31 11:17:42,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:42,486 INFO:     Epoch: 79
2022-12-31 11:17:44,084 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.39491147299607593, 'Total loss': 0.39491147299607593} | train loss {'Reaction outcome loss': 0.22507599334752793, 'Total loss': 0.22507599334752793}
2022-12-31 11:17:44,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:44,084 INFO:     Epoch: 80
2022-12-31 11:17:45,690 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.37160735030968983, 'Total loss': 0.37160735030968983} | train loss {'Reaction outcome loss': 0.2305113191239903, 'Total loss': 0.2305113191239903}
2022-12-31 11:17:45,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:45,691 INFO:     Epoch: 81
2022-12-31 11:17:47,348 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.36696449319521585, 'Total loss': 0.36696449319521585} | train loss {'Reaction outcome loss': 0.23829623546782017, 'Total loss': 0.23829623546782017}
2022-12-31 11:17:47,349 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:47,349 INFO:     Epoch: 82
2022-12-31 11:17:48,966 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.36967793504397073, 'Total loss': 0.36967793504397073} | train loss {'Reaction outcome loss': 0.22503396288611574, 'Total loss': 0.22503396288611574}
2022-12-31 11:17:48,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:48,966 INFO:     Epoch: 83
2022-12-31 11:17:50,584 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3441925677160422, 'Total loss': 0.3441925677160422} | train loss {'Reaction outcome loss': 0.23026447456525773, 'Total loss': 0.23026447456525773}
2022-12-31 11:17:50,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:50,584 INFO:     Epoch: 84
2022-12-31 11:17:52,178 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.35963335235913596, 'Total loss': 0.35963335235913596} | train loss {'Reaction outcome loss': 0.2318068516577351, 'Total loss': 0.2318068516577351}
2022-12-31 11:17:52,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:52,178 INFO:     Epoch: 85
2022-12-31 11:17:53,852 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3480304797490438, 'Total loss': 0.3480304797490438} | train loss {'Reaction outcome loss': 0.2253862505549214, 'Total loss': 0.2253862505549214}
2022-12-31 11:17:53,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:53,852 INFO:     Epoch: 86
2022-12-31 11:17:55,486 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.34462054669857023, 'Total loss': 0.34462054669857023} | train loss {'Reaction outcome loss': 0.2218181146443754, 'Total loss': 0.2218181146443754}
2022-12-31 11:17:55,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:55,486 INFO:     Epoch: 87
2022-12-31 11:17:57,157 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.34595180427034694, 'Total loss': 0.34595180427034694} | train loss {'Reaction outcome loss': 0.21624415681994372, 'Total loss': 0.21624415681994372}
2022-12-31 11:17:57,158 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:57,158 INFO:     Epoch: 88
2022-12-31 11:17:58,817 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3727066695690155, 'Total loss': 0.3727066695690155} | train loss {'Reaction outcome loss': 0.21782210619615702, 'Total loss': 0.21782210619615702}
2022-12-31 11:17:58,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:17:58,817 INFO:     Epoch: 89
2022-12-31 11:18:00,490 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3823945154746374, 'Total loss': 0.3823945154746374} | train loss {'Reaction outcome loss': 0.21831606926423483, 'Total loss': 0.21831606926423483}
2022-12-31 11:18:00,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:00,491 INFO:     Epoch: 90
2022-12-31 11:18:02,119 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.360789155960083, 'Total loss': 0.360789155960083} | train loss {'Reaction outcome loss': 0.21506226824409247, 'Total loss': 0.21506226824409247}
2022-12-31 11:18:02,119 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:02,119 INFO:     Epoch: 91
2022-12-31 11:18:03,718 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38036461571852365, 'Total loss': 0.38036461571852365} | train loss {'Reaction outcome loss': 0.21712194554266465, 'Total loss': 0.21712194554266465}
2022-12-31 11:18:03,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:03,718 INFO:     Epoch: 92
2022-12-31 11:18:05,364 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3852246065934499, 'Total loss': 0.3852246065934499} | train loss {'Reaction outcome loss': 0.22701637543450223, 'Total loss': 0.22701637543450223}
2022-12-31 11:18:05,364 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:05,364 INFO:     Epoch: 93
2022-12-31 11:18:06,980 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3466336647669474, 'Total loss': 0.3466336647669474} | train loss {'Reaction outcome loss': 0.21788852983550844, 'Total loss': 0.21788852983550844}
2022-12-31 11:18:06,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:06,981 INFO:     Epoch: 94
2022-12-31 11:18:08,595 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3979734708865484, 'Total loss': 0.3979734708865484} | train loss {'Reaction outcome loss': 0.21614502236142458, 'Total loss': 0.21614502236142458}
2022-12-31 11:18:08,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:08,596 INFO:     Epoch: 95
2022-12-31 11:18:10,259 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.37314146061738335, 'Total loss': 0.37314146061738335} | train loss {'Reaction outcome loss': 0.22084505142984068, 'Total loss': 0.22084505142984068}
2022-12-31 11:18:10,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:10,259 INFO:     Epoch: 96
2022-12-31 11:18:11,852 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40779048999150597, 'Total loss': 0.40779048999150597} | train loss {'Reaction outcome loss': 0.20953606576496395, 'Total loss': 0.20953606576496395}
2022-12-31 11:18:11,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:11,852 INFO:     Epoch: 97
2022-12-31 11:18:13,460 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.35185820460319517, 'Total loss': 0.35185820460319517} | train loss {'Reaction outcome loss': 0.20584491637714233, 'Total loss': 0.20584491637714233}
2022-12-31 11:18:13,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:13,461 INFO:     Epoch: 98
2022-12-31 11:18:15,112 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4151859194040298, 'Total loss': 0.4151859194040298} | train loss {'Reaction outcome loss': 0.20617684276869008, 'Total loss': 0.20617684276869008}
2022-12-31 11:18:15,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:15,113 INFO:     Epoch: 99
2022-12-31 11:18:16,725 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3829447341461976, 'Total loss': 0.3829447341461976} | train loss {'Reaction outcome loss': 0.21021803344964332, 'Total loss': 0.21021803344964332}
2022-12-31 11:18:16,725 INFO:     Best model found after epoch 56 of 100.
2022-12-31 11:18:16,725 INFO:   Done with stage: TRAINING
2022-12-31 11:18:16,725 INFO:   Starting stage: EVALUATION
2022-12-31 11:18:16,852 INFO:   Done with stage: EVALUATION
2022-12-31 11:18:16,860 INFO:   Leaving out SEQ value Fold_0
2022-12-31 11:18:16,873 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 11:18:16,873 INFO:   Starting stage: FEATURE SCALING
2022-12-31 11:18:17,515 INFO:   Done with stage: FEATURE SCALING
2022-12-31 11:18:17,515 INFO:   Starting stage: SCALING TARGETS
2022-12-31 11:18:17,584 INFO:   Done with stage: SCALING TARGETS
2022-12-31 11:18:17,585 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:18:17,585 INFO:     No hyperparam tuning for this model
2022-12-31 11:18:17,585 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:18:17,585 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 11:18:17,585 INFO:     None feature selector for col prot
2022-12-31 11:18:17,586 INFO:     None feature selector for col prot
2022-12-31 11:18:17,586 INFO:     None feature selector for col prot
2022-12-31 11:18:17,586 INFO:     None feature selector for col chem
2022-12-31 11:18:17,586 INFO:     None feature selector for col chem
2022-12-31 11:18:17,586 INFO:     None feature selector for col chem
2022-12-31 11:18:17,586 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 11:18:17,586 INFO:   Starting stage: BUILD MODEL
2022-12-31 11:18:17,588 INFO:     Number of params in model 223921
2022-12-31 11:18:17,591 INFO:   Done with stage: BUILD MODEL
2022-12-31 11:18:17,591 INFO:   Starting stage: TRAINING
2022-12-31 11:18:17,636 INFO:     Val loss before train {'Reaction outcome loss': 1.0541543424129487, 'Total loss': 1.0541543424129487}
2022-12-31 11:18:17,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:17,636 INFO:     Epoch: 0
2022-12-31 11:18:19,243 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6996428827444713, 'Total loss': 0.6996428827444713} | train loss {'Reaction outcome loss': 0.8271827105509674, 'Total loss': 0.8271827105509674}
2022-12-31 11:18:19,243 INFO:     Found new best model at epoch 0
2022-12-31 11:18:19,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:19,244 INFO:     Epoch: 1
2022-12-31 11:18:20,835 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5753629446029663, 'Total loss': 0.5753629446029663} | train loss {'Reaction outcome loss': 0.605243577307851, 'Total loss': 0.605243577307851}
2022-12-31 11:18:20,835 INFO:     Found new best model at epoch 1
2022-12-31 11:18:20,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:20,836 INFO:     Epoch: 2
2022-12-31 11:18:22,440 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5620637148618698, 'Total loss': 0.5620637148618698} | train loss {'Reaction outcome loss': 0.5332372027138869, 'Total loss': 0.5332372027138869}
2022-12-31 11:18:22,440 INFO:     Found new best model at epoch 2
2022-12-31 11:18:22,441 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:22,441 INFO:     Epoch: 3
2022-12-31 11:18:24,073 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5051386555035909, 'Total loss': 0.5051386555035909} | train loss {'Reaction outcome loss': 0.5081047043204308, 'Total loss': 0.5081047043204308}
2022-12-31 11:18:24,073 INFO:     Found new best model at epoch 3
2022-12-31 11:18:24,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:24,074 INFO:     Epoch: 4
2022-12-31 11:18:25,701 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5252492189407348, 'Total loss': 0.5252492189407348} | train loss {'Reaction outcome loss': 0.49393463710357144, 'Total loss': 0.49393463710357144}
2022-12-31 11:18:25,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:25,701 INFO:     Epoch: 5
2022-12-31 11:18:27,338 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.49533690015474957, 'Total loss': 0.49533690015474957} | train loss {'Reaction outcome loss': 0.488887518428374, 'Total loss': 0.488887518428374}
2022-12-31 11:18:27,339 INFO:     Found new best model at epoch 5
2022-12-31 11:18:27,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:27,340 INFO:     Epoch: 6
2022-12-31 11:18:28,928 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5008292535940806, 'Total loss': 0.5008292535940806} | train loss {'Reaction outcome loss': 0.5507376157827135, 'Total loss': 0.5507376157827135}
2022-12-31 11:18:28,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:28,928 INFO:     Epoch: 7
2022-12-31 11:18:30,582 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4665201723575592, 'Total loss': 0.4665201723575592} | train loss {'Reaction outcome loss': 0.48948214787473576, 'Total loss': 0.48948214787473576}
2022-12-31 11:18:30,582 INFO:     Found new best model at epoch 7
2022-12-31 11:18:30,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:30,583 INFO:     Epoch: 8
2022-12-31 11:18:32,215 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45527761379877724, 'Total loss': 0.45527761379877724} | train loss {'Reaction outcome loss': 0.4739909703046947, 'Total loss': 0.4739909703046947}
2022-12-31 11:18:32,215 INFO:     Found new best model at epoch 8
2022-12-31 11:18:32,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:32,216 INFO:     Epoch: 9
2022-12-31 11:18:33,806 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44212233225504555, 'Total loss': 0.44212233225504555} | train loss {'Reaction outcome loss': 0.4630762086776288, 'Total loss': 0.4630762086776288}
2022-12-31 11:18:33,806 INFO:     Found new best model at epoch 9
2022-12-31 11:18:33,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:33,807 INFO:     Epoch: 10
2022-12-31 11:18:35,427 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.43407038152217864, 'Total loss': 0.43407038152217864} | train loss {'Reaction outcome loss': 0.45645911916685494, 'Total loss': 0.45645911916685494}
2022-12-31 11:18:35,427 INFO:     Found new best model at epoch 10
2022-12-31 11:18:35,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:35,428 INFO:     Epoch: 11
2022-12-31 11:18:37,034 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4313127279281616, 'Total loss': 0.4313127279281616} | train loss {'Reaction outcome loss': 0.4476431600962077, 'Total loss': 0.4476431600962077}
2022-12-31 11:18:37,034 INFO:     Found new best model at epoch 11
2022-12-31 11:18:37,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:37,035 INFO:     Epoch: 12
2022-12-31 11:18:38,624 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44808022379875184, 'Total loss': 0.44808022379875184} | train loss {'Reaction outcome loss': 0.4463694374198499, 'Total loss': 0.4463694374198499}
2022-12-31 11:18:38,625 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:38,626 INFO:     Epoch: 13
2022-12-31 11:18:40,221 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49434500336647036, 'Total loss': 0.49434500336647036} | train loss {'Reaction outcome loss': 0.4546299828891305, 'Total loss': 0.4546299828891305}
2022-12-31 11:18:40,221 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:40,221 INFO:     Epoch: 14
2022-12-31 11:18:41,875 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4419466565052668, 'Total loss': 0.4419466565052668} | train loss {'Reaction outcome loss': 0.4515519176164399, 'Total loss': 0.4515519176164399}
2022-12-31 11:18:41,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:41,875 INFO:     Epoch: 15
2022-12-31 11:18:43,522 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.422373511393865, 'Total loss': 0.422373511393865} | train loss {'Reaction outcome loss': 0.42468970286704527, 'Total loss': 0.42468970286704527}
2022-12-31 11:18:43,522 INFO:     Found new best model at epoch 15
2022-12-31 11:18:43,523 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:43,523 INFO:     Epoch: 16
2022-12-31 11:18:45,178 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.42256544133027396, 'Total loss': 0.42256544133027396} | train loss {'Reaction outcome loss': 0.4099663362392913, 'Total loss': 0.4099663362392913}
2022-12-31 11:18:45,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:45,179 INFO:     Epoch: 17
2022-12-31 11:18:46,779 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4057931701342265, 'Total loss': 0.4057931701342265} | train loss {'Reaction outcome loss': 0.40436733466576436, 'Total loss': 0.40436733466576436}
2022-12-31 11:18:46,780 INFO:     Found new best model at epoch 17
2022-12-31 11:18:46,780 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:46,780 INFO:     Epoch: 18
2022-12-31 11:18:48,388 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4378860572973887, 'Total loss': 0.4378860572973887} | train loss {'Reaction outcome loss': 0.39766908450016103, 'Total loss': 0.39766908450016103}
2022-12-31 11:18:48,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:48,388 INFO:     Epoch: 19
2022-12-31 11:18:50,006 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4099581648906072, 'Total loss': 0.4099581648906072} | train loss {'Reaction outcome loss': 0.3969421000422343, 'Total loss': 0.3969421000422343}
2022-12-31 11:18:50,006 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:50,006 INFO:     Epoch: 20
2022-12-31 11:18:51,654 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41181116302808124, 'Total loss': 0.41181116302808124} | train loss {'Reaction outcome loss': 0.38609679117528856, 'Total loss': 0.38609679117528856}
2022-12-31 11:18:51,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:51,655 INFO:     Epoch: 21
2022-12-31 11:18:53,264 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4056890030701955, 'Total loss': 0.4056890030701955} | train loss {'Reaction outcome loss': 0.3818736871353526, 'Total loss': 0.3818736871353526}
2022-12-31 11:18:53,264 INFO:     Found new best model at epoch 21
2022-12-31 11:18:53,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:53,265 INFO:     Epoch: 22
2022-12-31 11:18:54,875 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43554596801598866, 'Total loss': 0.43554596801598866} | train loss {'Reaction outcome loss': 0.3754073324329827, 'Total loss': 0.3754073324329827}
2022-12-31 11:18:54,875 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:54,876 INFO:     Epoch: 23
2022-12-31 11:18:56,482 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4197426736354828, 'Total loss': 0.4197426736354828} | train loss {'Reaction outcome loss': 0.36936549251170264, 'Total loss': 0.36936549251170264}
2022-12-31 11:18:56,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:56,482 INFO:     Epoch: 24
2022-12-31 11:18:58,124 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39875134428342185, 'Total loss': 0.39875134428342185} | train loss {'Reaction outcome loss': 0.3665661229275376, 'Total loss': 0.3665661229275376}
2022-12-31 11:18:58,125 INFO:     Found new best model at epoch 24
2022-12-31 11:18:58,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:58,126 INFO:     Epoch: 25
2022-12-31 11:18:59,741 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4046507885058721, 'Total loss': 0.4046507885058721} | train loss {'Reaction outcome loss': 0.3593820349298134, 'Total loss': 0.3593820349298134}
2022-12-31 11:18:59,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:18:59,741 INFO:     Epoch: 26
2022-12-31 11:19:01,356 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4177131712436676, 'Total loss': 0.4177131712436676} | train loss {'Reaction outcome loss': 0.35246383063275827, 'Total loss': 0.35246383063275827}
2022-12-31 11:19:01,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:01,357 INFO:     Epoch: 27
2022-12-31 11:19:02,972 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4214831123749415, 'Total loss': 0.4214831123749415} | train loss {'Reaction outcome loss': 0.3507501240009847, 'Total loss': 0.3507501240009847}
2022-12-31 11:19:02,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:02,972 INFO:     Epoch: 28
2022-12-31 11:19:04,588 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4127063771088918, 'Total loss': 0.4127063771088918} | train loss {'Reaction outcome loss': 0.37337421587711805, 'Total loss': 0.37337421587711805}
2022-12-31 11:19:04,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:04,588 INFO:     Epoch: 29
2022-12-31 11:19:06,222 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40026068886121113, 'Total loss': 0.40026068886121113} | train loss {'Reaction outcome loss': 0.3433642240192242, 'Total loss': 0.3433642240192242}
2022-12-31 11:19:06,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:06,222 INFO:     Epoch: 30
2022-12-31 11:19:07,850 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4240457753340403, 'Total loss': 0.4240457753340403} | train loss {'Reaction outcome loss': 0.337635222201546, 'Total loss': 0.337635222201546}
2022-12-31 11:19:07,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:07,850 INFO:     Epoch: 31
2022-12-31 11:19:09,517 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4164322316646576, 'Total loss': 0.4164322316646576} | train loss {'Reaction outcome loss': 0.3266696249526264, 'Total loss': 0.3266696249526264}
2022-12-31 11:19:09,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:09,517 INFO:     Epoch: 32
2022-12-31 11:19:11,179 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43406373461087544, 'Total loss': 0.43406373461087544} | train loss {'Reaction outcome loss': 0.3266273210284071, 'Total loss': 0.3266273210284071}
2022-12-31 11:19:11,179 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:11,180 INFO:     Epoch: 33
2022-12-31 11:19:12,850 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41060102681318916, 'Total loss': 0.41060102681318916} | train loss {'Reaction outcome loss': 0.33972080730735255, 'Total loss': 0.33972080730735255}
2022-12-31 11:19:12,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:12,851 INFO:     Epoch: 34
2022-12-31 11:19:14,479 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.39002209107081093, 'Total loss': 0.39002209107081093} | train loss {'Reaction outcome loss': 0.3262711429050651, 'Total loss': 0.3262711429050651}
2022-12-31 11:19:14,480 INFO:     Found new best model at epoch 34
2022-12-31 11:19:14,481 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:14,481 INFO:     Epoch: 35
2022-12-31 11:19:16,140 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4275353034337362, 'Total loss': 0.4275353034337362} | train loss {'Reaction outcome loss': 0.3155906493033188, 'Total loss': 0.3155906493033188}
2022-12-31 11:19:16,140 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:16,140 INFO:     Epoch: 36
2022-12-31 11:19:17,738 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38927112221717836, 'Total loss': 0.38927112221717836} | train loss {'Reaction outcome loss': 0.3184666166873311, 'Total loss': 0.3184666166873311}
2022-12-31 11:19:17,738 INFO:     Found new best model at epoch 36
2022-12-31 11:19:17,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:17,739 INFO:     Epoch: 37
2022-12-31 11:19:19,354 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4207207977771759, 'Total loss': 0.4207207977771759} | train loss {'Reaction outcome loss': 0.30968014375590114, 'Total loss': 0.30968014375590114}
2022-12-31 11:19:19,354 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:19,354 INFO:     Epoch: 38
2022-12-31 11:19:20,972 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4369105319182078, 'Total loss': 0.4369105319182078} | train loss {'Reaction outcome loss': 0.314858369866683, 'Total loss': 0.314858369866683}
2022-12-31 11:19:20,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:20,972 INFO:     Epoch: 39
2022-12-31 11:19:22,588 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46202897032101947, 'Total loss': 0.46202897032101947} | train loss {'Reaction outcome loss': 0.33350416267479677, 'Total loss': 0.33350416267479677}
2022-12-31 11:19:22,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:22,588 INFO:     Epoch: 40
2022-12-31 11:19:24,217 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.41868744095166527, 'Total loss': 0.41868744095166527} | train loss {'Reaction outcome loss': 0.3661492247682464, 'Total loss': 0.3661492247682464}
2022-12-31 11:19:24,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:24,217 INFO:     Epoch: 41
2022-12-31 11:19:25,818 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4372701366742452, 'Total loss': 0.4372701366742452} | train loss {'Reaction outcome loss': 0.3149299541744741, 'Total loss': 0.3149299541744741}
2022-12-31 11:19:25,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:25,818 INFO:     Epoch: 42
2022-12-31 11:19:27,433 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38899044742186867, 'Total loss': 0.38899044742186867} | train loss {'Reaction outcome loss': 0.30380548644124233, 'Total loss': 0.30380548644124233}
2022-12-31 11:19:27,433 INFO:     Found new best model at epoch 42
2022-12-31 11:19:27,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:27,434 INFO:     Epoch: 43
2022-12-31 11:19:29,046 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4209051797787348, 'Total loss': 0.4209051797787348} | train loss {'Reaction outcome loss': 0.2974397720567852, 'Total loss': 0.2974397720567852}
2022-12-31 11:19:29,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:29,046 INFO:     Epoch: 44
2022-12-31 11:19:30,661 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4130653565128644, 'Total loss': 0.4130653565128644} | train loss {'Reaction outcome loss': 0.29028773888189724, 'Total loss': 0.29028773888189724}
2022-12-31 11:19:30,661 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:30,661 INFO:     Epoch: 45
2022-12-31 11:19:32,275 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39764561752478284, 'Total loss': 0.39764561752478284} | train loss {'Reaction outcome loss': 0.29118602243724506, 'Total loss': 0.29118602243724506}
2022-12-31 11:19:32,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:32,275 INFO:     Epoch: 46
2022-12-31 11:19:33,885 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4089385529359182, 'Total loss': 0.4089385529359182} | train loss {'Reaction outcome loss': 0.2968114162592784, 'Total loss': 0.2968114162592784}
2022-12-31 11:19:33,886 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:33,886 INFO:     Epoch: 47
2022-12-31 11:19:35,481 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4106704115867615, 'Total loss': 0.4106704115867615} | train loss {'Reaction outcome loss': 0.28484413529867714, 'Total loss': 0.28484413529867714}
2022-12-31 11:19:35,481 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:35,481 INFO:     Epoch: 48
2022-12-31 11:19:37,101 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.402322411040465, 'Total loss': 0.402322411040465} | train loss {'Reaction outcome loss': 0.2812488663933344, 'Total loss': 0.2812488663933344}
2022-12-31 11:19:37,101 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:37,101 INFO:     Epoch: 49
2022-12-31 11:19:38,744 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4145789384841919, 'Total loss': 0.4145789384841919} | train loss {'Reaction outcome loss': 0.2804502897416714, 'Total loss': 0.2804502897416714}
2022-12-31 11:19:38,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:38,744 INFO:     Epoch: 50
2022-12-31 11:19:40,366 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4119914968808492, 'Total loss': 0.4119914968808492} | train loss {'Reaction outcome loss': 0.29250997329211753, 'Total loss': 0.29250997329211753}
2022-12-31 11:19:40,366 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:40,367 INFO:     Epoch: 51
2022-12-31 11:19:41,983 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4269008199373881, 'Total loss': 0.4269008199373881} | train loss {'Reaction outcome loss': 0.3195822466488766, 'Total loss': 0.3195822466488766}
2022-12-31 11:19:41,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:41,983 INFO:     Epoch: 52
2022-12-31 11:19:43,595 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4049398829539617, 'Total loss': 0.4049398829539617} | train loss {'Reaction outcome loss': 0.3037238183871681, 'Total loss': 0.3037238183871681}
2022-12-31 11:19:43,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:43,595 INFO:     Epoch: 53
2022-12-31 11:19:45,199 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39301833460728325, 'Total loss': 0.39301833460728325} | train loss {'Reaction outcome loss': 0.2757026272407476, 'Total loss': 0.2757026272407476}
2022-12-31 11:19:45,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:45,199 INFO:     Epoch: 54
2022-12-31 11:19:46,843 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41749429404735566, 'Total loss': 0.41749429404735566} | train loss {'Reaction outcome loss': 0.27282874360832426, 'Total loss': 0.27282874360832426}
2022-12-31 11:19:46,843 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:46,844 INFO:     Epoch: 55
2022-12-31 11:19:48,460 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4180546412865321, 'Total loss': 0.4180546412865321} | train loss {'Reaction outcome loss': 0.26818766294172086, 'Total loss': 0.26818766294172086}
2022-12-31 11:19:48,460 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:48,460 INFO:     Epoch: 56
2022-12-31 11:19:50,075 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39144452214241027, 'Total loss': 0.39144452214241027} | train loss {'Reaction outcome loss': 0.2686313433957327, 'Total loss': 0.2686313433957327}
2022-12-31 11:19:50,075 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:50,076 INFO:     Epoch: 57
2022-12-31 11:19:51,699 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4090466966231664, 'Total loss': 0.4090466966231664} | train loss {'Reaction outcome loss': 0.26820858986868346, 'Total loss': 0.26820858986868346}
2022-12-31 11:19:51,700 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:51,701 INFO:     Epoch: 58
2022-12-31 11:19:53,326 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40064311822255455, 'Total loss': 0.40064311822255455} | train loss {'Reaction outcome loss': 0.2610594792083999, 'Total loss': 0.2610594792083999}
2022-12-31 11:19:53,326 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:53,326 INFO:     Epoch: 59
2022-12-31 11:19:54,944 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44833042124907174, 'Total loss': 0.44833042124907174} | train loss {'Reaction outcome loss': 0.2596610990998162, 'Total loss': 0.2596610990998162}
2022-12-31 11:19:54,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:54,944 INFO:     Epoch: 60
2022-12-31 11:19:56,564 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4047377914190292, 'Total loss': 0.4047377914190292} | train loss {'Reaction outcome loss': 0.255786565773567, 'Total loss': 0.255786565773567}
2022-12-31 11:19:56,564 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:56,564 INFO:     Epoch: 61
2022-12-31 11:19:58,180 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43026522795359295, 'Total loss': 0.43026522795359295} | train loss {'Reaction outcome loss': 0.254929403592225, 'Total loss': 0.254929403592225}
2022-12-31 11:19:58,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:58,180 INFO:     Epoch: 62
2022-12-31 11:19:59,777 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44264001250267027, 'Total loss': 0.44264001250267027} | train loss {'Reaction outcome loss': 0.2556745420763458, 'Total loss': 0.2556745420763458}
2022-12-31 11:19:59,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:19:59,777 INFO:     Epoch: 63
2022-12-31 11:20:01,392 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40538075466950735, 'Total loss': 0.40538075466950735} | train loss {'Reaction outcome loss': 0.24903588133615878, 'Total loss': 0.24903588133615878}
2022-12-31 11:20:01,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:01,393 INFO:     Epoch: 64
2022-12-31 11:20:02,991 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4093581815560659, 'Total loss': 0.4093581815560659} | train loss {'Reaction outcome loss': 0.24614858420935218, 'Total loss': 0.24614858420935218}
2022-12-31 11:20:02,991 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:02,991 INFO:     Epoch: 65
2022-12-31 11:20:04,609 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40793640514214835, 'Total loss': 0.40793640514214835} | train loss {'Reaction outcome loss': 0.2518792522523259, 'Total loss': 0.2518792522523259}
2022-12-31 11:20:04,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:04,610 INFO:     Epoch: 66
2022-12-31 11:20:06,227 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3905463447173437, 'Total loss': 0.3905463447173437} | train loss {'Reaction outcome loss': 0.24988833594851304, 'Total loss': 0.24988833594851304}
2022-12-31 11:20:06,227 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:06,227 INFO:     Epoch: 67
2022-12-31 11:20:07,889 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3952219784259796, 'Total loss': 0.3952219784259796} | train loss {'Reaction outcome loss': 0.24649814982589358, 'Total loss': 0.24649814982589358}
2022-12-31 11:20:07,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:07,889 INFO:     Epoch: 68
2022-12-31 11:20:09,486 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3894623736540476, 'Total loss': 0.3894623736540476} | train loss {'Reaction outcome loss': 0.2412984178998791, 'Total loss': 0.2412984178998791}
2022-12-31 11:20:09,486 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:09,486 INFO:     Epoch: 69
2022-12-31 11:20:11,086 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4154076471924782, 'Total loss': 0.4154076471924782} | train loss {'Reaction outcome loss': 0.24520637987864494, 'Total loss': 0.24520637987864494}
2022-12-31 11:20:11,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:11,087 INFO:     Epoch: 70
2022-12-31 11:20:12,737 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41635762800772985, 'Total loss': 0.41635762800772985} | train loss {'Reaction outcome loss': 0.24375749009182665, 'Total loss': 0.24375749009182665}
2022-12-31 11:20:12,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:12,738 INFO:     Epoch: 71
2022-12-31 11:20:14,402 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3993067423502604, 'Total loss': 0.3993067423502604} | train loss {'Reaction outcome loss': 0.24411996096149896, 'Total loss': 0.24411996096149896}
2022-12-31 11:20:14,402 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:14,402 INFO:     Epoch: 72
2022-12-31 11:20:16,060 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.38779179056485497, 'Total loss': 0.38779179056485497} | train loss {'Reaction outcome loss': 0.24049969949503092, 'Total loss': 0.24049969949503092}
2022-12-31 11:20:16,060 INFO:     Found new best model at epoch 72
2022-12-31 11:20:16,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:16,061 INFO:     Epoch: 73
2022-12-31 11:20:17,648 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3743107517560323, 'Total loss': 0.3743107517560323} | train loss {'Reaction outcome loss': 0.2525223380062675, 'Total loss': 0.2525223380062675}
2022-12-31 11:20:17,648 INFO:     Found new best model at epoch 73
2022-12-31 11:20:17,649 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:17,649 INFO:     Epoch: 74
2022-12-31 11:20:19,260 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40475464463233946, 'Total loss': 0.40475464463233946} | train loss {'Reaction outcome loss': 0.2349705434781965, 'Total loss': 0.2349705434781965}
2022-12-31 11:20:19,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:19,260 INFO:     Epoch: 75
2022-12-31 11:20:20,838 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4198302745819092, 'Total loss': 0.4198302745819092} | train loss {'Reaction outcome loss': 0.23914671003391655, 'Total loss': 0.23914671003391655}
2022-12-31 11:20:20,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:20,839 INFO:     Epoch: 76
2022-12-31 11:20:22,450 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3855442672967911, 'Total loss': 0.3855442672967911} | train loss {'Reaction outcome loss': 0.2303023413950923, 'Total loss': 0.2303023413950923}
2022-12-31 11:20:22,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:22,450 INFO:     Epoch: 77
2022-12-31 11:20:24,062 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.41886007686456045, 'Total loss': 0.41886007686456045} | train loss {'Reaction outcome loss': 0.22913123085838405, 'Total loss': 0.22913123085838405}
2022-12-31 11:20:24,062 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:24,062 INFO:     Epoch: 78
2022-12-31 11:20:25,692 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4289185136556625, 'Total loss': 0.4289185136556625} | train loss {'Reaction outcome loss': 0.2352836463918641, 'Total loss': 0.2352836463918641}
2022-12-31 11:20:25,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:25,693 INFO:     Epoch: 79
2022-12-31 11:20:27,316 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42146233717600506, 'Total loss': 0.42146233717600506} | train loss {'Reaction outcome loss': 0.23087379662530916, 'Total loss': 0.23087379662530916}
2022-12-31 11:20:27,317 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:27,317 INFO:     Epoch: 80
2022-12-31 11:20:28,937 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.37889143576224643, 'Total loss': 0.37889143576224643} | train loss {'Reaction outcome loss': 0.22812644341299176, 'Total loss': 0.22812644341299176}
2022-12-31 11:20:28,937 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:28,937 INFO:     Epoch: 81
2022-12-31 11:20:30,526 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41292439500490824, 'Total loss': 0.41292439500490824} | train loss {'Reaction outcome loss': 0.22722298747596695, 'Total loss': 0.22722298747596695}
2022-12-31 11:20:30,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:30,526 INFO:     Epoch: 82
2022-12-31 11:20:32,134 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3875573257605235, 'Total loss': 0.3875573257605235} | train loss {'Reaction outcome loss': 0.22472537881053606, 'Total loss': 0.22472537881053606}
2022-12-31 11:20:32,134 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:32,134 INFO:     Epoch: 83
2022-12-31 11:20:33,743 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41438358227411903, 'Total loss': 0.41438358227411903} | train loss {'Reaction outcome loss': 0.22399406474795652, 'Total loss': 0.22399406474795652}
2022-12-31 11:20:33,743 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:33,744 INFO:     Epoch: 84
2022-12-31 11:20:35,357 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4046742210785548, 'Total loss': 0.4046742210785548} | train loss {'Reaction outcome loss': 0.2292727240972032, 'Total loss': 0.2292727240972032}
2022-12-31 11:20:35,357 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:35,357 INFO:     Epoch: 85
2022-12-31 11:20:36,963 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.38291052877902987, 'Total loss': 0.38291052877902987} | train loss {'Reaction outcome loss': 0.21825432990664156, 'Total loss': 0.21825432990664156}
2022-12-31 11:20:36,963 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:36,963 INFO:     Epoch: 86
2022-12-31 11:20:38,597 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4017234141627947, 'Total loss': 0.4017234141627947} | train loss {'Reaction outcome loss': 0.21637630499469157, 'Total loss': 0.21637630499469157}
2022-12-31 11:20:38,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:38,597 INFO:     Epoch: 87
2022-12-31 11:20:40,257 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3943892220656077, 'Total loss': 0.3943892220656077} | train loss {'Reaction outcome loss': 0.2151685944940571, 'Total loss': 0.2151685944940571}
2022-12-31 11:20:40,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:40,257 INFO:     Epoch: 88
2022-12-31 11:20:41,873 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3597481302917004, 'Total loss': 0.3597481302917004} | train loss {'Reaction outcome loss': 0.22095020555286243, 'Total loss': 0.22095020555286243}
2022-12-31 11:20:41,873 INFO:     Found new best model at epoch 88
2022-12-31 11:20:41,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:41,874 INFO:     Epoch: 89
2022-12-31 11:20:43,487 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3811230719089508, 'Total loss': 0.3811230719089508} | train loss {'Reaction outcome loss': 0.22099238088246595, 'Total loss': 0.22099238088246595}
2022-12-31 11:20:43,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:43,487 INFO:     Epoch: 90
2022-12-31 11:20:45,084 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4463617871205012, 'Total loss': 0.4463617871205012} | train loss {'Reaction outcome loss': 0.2141410540223436, 'Total loss': 0.2141410540223436}
2022-12-31 11:20:45,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:45,084 INFO:     Epoch: 91
2022-12-31 11:20:46,696 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.405234295129776, 'Total loss': 0.405234295129776} | train loss {'Reaction outcome loss': 0.22472227092046101, 'Total loss': 0.22472227092046101}
2022-12-31 11:20:46,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:46,697 INFO:     Epoch: 92
2022-12-31 11:20:47,965 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.38528425445159276, 'Total loss': 0.38528425445159276} | train loss {'Reaction outcome loss': 0.2182012861174872, 'Total loss': 0.2182012861174872}
2022-12-31 11:20:47,965 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:47,965 INFO:     Epoch: 93
2022-12-31 11:20:49,043 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42899573445320127, 'Total loss': 0.42899573445320127} | train loss {'Reaction outcome loss': 0.21547252288007218, 'Total loss': 0.21547252288007218}
2022-12-31 11:20:49,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:49,044 INFO:     Epoch: 94
2022-12-31 11:20:50,118 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3888741890589396, 'Total loss': 0.3888741890589396} | train loss {'Reaction outcome loss': 0.21808742445243487, 'Total loss': 0.21808742445243487}
2022-12-31 11:20:50,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:50,118 INFO:     Epoch: 95
2022-12-31 11:20:51,196 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4025991946458817, 'Total loss': 0.4025991946458817} | train loss {'Reaction outcome loss': 0.2152137864259598, 'Total loss': 0.2152137864259598}
2022-12-31 11:20:51,196 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:51,196 INFO:     Epoch: 96
2022-12-31 11:20:52,539 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41220128486553825, 'Total loss': 0.41220128486553825} | train loss {'Reaction outcome loss': 0.21413978834132888, 'Total loss': 0.21413978834132888}
2022-12-31 11:20:52,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:52,539 INFO:     Epoch: 97
2022-12-31 11:20:54,151 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40053976476192477, 'Total loss': 0.40053976476192477} | train loss {'Reaction outcome loss': 0.2174314541094329, 'Total loss': 0.2174314541094329}
2022-12-31 11:20:54,151 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:54,151 INFO:     Epoch: 98
2022-12-31 11:20:55,783 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4140999436378479, 'Total loss': 0.4140999436378479} | train loss {'Reaction outcome loss': 0.2096067293686497, 'Total loss': 0.2096067293686497}
2022-12-31 11:20:55,783 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:55,783 INFO:     Epoch: 99
2022-12-31 11:20:57,412 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.39003747602303823, 'Total loss': 0.39003747602303823} | train loss {'Reaction outcome loss': 0.2024463195843371, 'Total loss': 0.2024463195843371}
2022-12-31 11:20:57,412 INFO:     Best model found after epoch 89 of 100.
2022-12-31 11:20:57,413 INFO:   Done with stage: TRAINING
2022-12-31 11:20:57,413 INFO:   Starting stage: EVALUATION
2022-12-31 11:20:57,541 INFO:   Done with stage: EVALUATION
2022-12-31 11:20:57,541 INFO:   Leaving out SEQ value Fold_1
2022-12-31 11:20:57,554 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 11:20:57,554 INFO:   Starting stage: FEATURE SCALING
2022-12-31 11:20:58,196 INFO:   Done with stage: FEATURE SCALING
2022-12-31 11:20:58,196 INFO:   Starting stage: SCALING TARGETS
2022-12-31 11:20:58,266 INFO:   Done with stage: SCALING TARGETS
2022-12-31 11:20:58,266 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:20:58,266 INFO:     No hyperparam tuning for this model
2022-12-31 11:20:58,266 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:20:58,266 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 11:20:58,267 INFO:     None feature selector for col prot
2022-12-31 11:20:58,267 INFO:     None feature selector for col prot
2022-12-31 11:20:58,267 INFO:     None feature selector for col prot
2022-12-31 11:20:58,268 INFO:     None feature selector for col chem
2022-12-31 11:20:58,268 INFO:     None feature selector for col chem
2022-12-31 11:20:58,268 INFO:     None feature selector for col chem
2022-12-31 11:20:58,268 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 11:20:58,268 INFO:   Starting stage: BUILD MODEL
2022-12-31 11:20:58,270 INFO:     Number of params in model 223921
2022-12-31 11:20:58,273 INFO:   Done with stage: BUILD MODEL
2022-12-31 11:20:58,273 INFO:   Starting stage: TRAINING
2022-12-31 11:20:58,317 INFO:     Val loss before train {'Reaction outcome loss': 0.9691816687583923, 'Total loss': 0.9691816687583923}
2022-12-31 11:20:58,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:58,318 INFO:     Epoch: 0
2022-12-31 11:20:59,933 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6752461870511373, 'Total loss': 0.6752461870511373} | train loss {'Reaction outcome loss': 0.798627573672844, 'Total loss': 0.798627573672844}
2022-12-31 11:20:59,933 INFO:     Found new best model at epoch 0
2022-12-31 11:20:59,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:20:59,934 INFO:     Epoch: 1
2022-12-31 11:21:01,505 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5676081240177154, 'Total loss': 0.5676081240177154} | train loss {'Reaction outcome loss': 0.5880968019145244, 'Total loss': 0.5880968019145244}
2022-12-31 11:21:01,505 INFO:     Found new best model at epoch 1
2022-12-31 11:21:01,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:01,506 INFO:     Epoch: 2
2022-12-31 11:21:03,134 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5714191575845082, 'Total loss': 0.5714191575845082} | train loss {'Reaction outcome loss': 0.5276058811316455, 'Total loss': 0.5276058811316455}
2022-12-31 11:21:03,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:03,135 INFO:     Epoch: 3
2022-12-31 11:21:04,765 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.494167223572731, 'Total loss': 0.494167223572731} | train loss {'Reaction outcome loss': 0.5047152976702015, 'Total loss': 0.5047152976702015}
2022-12-31 11:21:04,766 INFO:     Found new best model at epoch 3
2022-12-31 11:21:04,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:04,766 INFO:     Epoch: 4
2022-12-31 11:21:06,372 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5328846722841263, 'Total loss': 0.5328846722841263} | train loss {'Reaction outcome loss': 0.48559768209436344, 'Total loss': 0.48559768209436344}
2022-12-31 11:21:06,372 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:06,372 INFO:     Epoch: 5
2022-12-31 11:21:07,983 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5286182701587677, 'Total loss': 0.5286182701587677} | train loss {'Reaction outcome loss': 0.47164785519134306, 'Total loss': 0.47164785519134306}
2022-12-31 11:21:07,983 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:07,983 INFO:     Epoch: 6
2022-12-31 11:21:09,584 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5039255201816559, 'Total loss': 0.5039255201816559} | train loss {'Reaction outcome loss': 0.48552845548028534, 'Total loss': 0.48552845548028534}
2022-12-31 11:21:09,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:09,585 INFO:     Epoch: 7
2022-12-31 11:21:11,153 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.530287096897761, 'Total loss': 0.530287096897761} | train loss {'Reaction outcome loss': 0.48254620578592183, 'Total loss': 0.48254620578592183}
2022-12-31 11:21:11,154 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:11,154 INFO:     Epoch: 8
2022-12-31 11:21:12,766 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49500697453816733, 'Total loss': 0.49500697453816733} | train loss {'Reaction outcome loss': 0.4543434043188809, 'Total loss': 0.4543434043188809}
2022-12-31 11:21:12,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:12,766 INFO:     Epoch: 9
2022-12-31 11:21:14,378 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49673245549201966, 'Total loss': 0.49673245549201966} | train loss {'Reaction outcome loss': 0.44504492534780066, 'Total loss': 0.44504492534780066}
2022-12-31 11:21:14,378 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:14,378 INFO:     Epoch: 10
2022-12-31 11:21:16,010 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.478298681974411, 'Total loss': 0.478298681974411} | train loss {'Reaction outcome loss': 0.43675595673772954, 'Total loss': 0.43675595673772954}
2022-12-31 11:21:16,011 INFO:     Found new best model at epoch 10
2022-12-31 11:21:16,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:16,012 INFO:     Epoch: 11
2022-12-31 11:21:17,646 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5069570322831471, 'Total loss': 0.5069570322831471} | train loss {'Reaction outcome loss': 0.43380130930007366, 'Total loss': 0.43380130930007366}
2022-12-31 11:21:17,647 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:17,647 INFO:     Epoch: 12
2022-12-31 11:21:19,233 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.49121691087881725, 'Total loss': 0.49121691087881725} | train loss {'Reaction outcome loss': 0.4387330045093499, 'Total loss': 0.4387330045093499}
2022-12-31 11:21:19,233 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:19,233 INFO:     Epoch: 13
2022-12-31 11:21:20,894 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5156383623679479, 'Total loss': 0.5156383623679479} | train loss {'Reaction outcome loss': 0.4216721952467671, 'Total loss': 0.4216721952467671}
2022-12-31 11:21:20,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:20,895 INFO:     Epoch: 14
2022-12-31 11:21:22,537 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.47390108108520507, 'Total loss': 0.47390108108520507} | train loss {'Reaction outcome loss': 0.419457893130248, 'Total loss': 0.419457893130248}
2022-12-31 11:21:22,537 INFO:     Found new best model at epoch 14
2022-12-31 11:21:22,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:22,538 INFO:     Epoch: 15
2022-12-31 11:21:24,178 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.47788122296333313, 'Total loss': 0.47788122296333313} | train loss {'Reaction outcome loss': 0.41041002780084324, 'Total loss': 0.41041002780084324}
2022-12-31 11:21:24,178 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:24,179 INFO:     Epoch: 16
2022-12-31 11:21:25,803 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.524919734398524, 'Total loss': 0.524919734398524} | train loss {'Reaction outcome loss': 0.40699430541945214, 'Total loss': 0.40699430541945214}
2022-12-31 11:21:25,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:25,804 INFO:     Epoch: 17
2022-12-31 11:21:27,450 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4751702070236206, 'Total loss': 0.4751702070236206} | train loss {'Reaction outcome loss': 0.39890746530223964, 'Total loss': 0.39890746530223964}
2022-12-31 11:21:27,450 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:27,450 INFO:     Epoch: 18
2022-12-31 11:21:29,045 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5018466432889302, 'Total loss': 0.5018466432889302} | train loss {'Reaction outcome loss': 0.3964113562597313, 'Total loss': 0.3964113562597313}
2022-12-31 11:21:29,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:29,045 INFO:     Epoch: 19
2022-12-31 11:21:30,691 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.49977493584156035, 'Total loss': 0.49977493584156035} | train loss {'Reaction outcome loss': 0.40307540347988624, 'Total loss': 0.40307540347988624}
2022-12-31 11:21:30,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:30,692 INFO:     Epoch: 20
2022-12-31 11:21:32,337 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4796744644641876, 'Total loss': 0.4796744644641876} | train loss {'Reaction outcome loss': 0.38517390865303425, 'Total loss': 0.38517390865303425}
2022-12-31 11:21:32,338 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:32,338 INFO:     Epoch: 21
2022-12-31 11:21:33,987 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4874775578578313, 'Total loss': 0.4874775578578313} | train loss {'Reaction outcome loss': 0.3767219755281458, 'Total loss': 0.3767219755281458}
2022-12-31 11:21:33,987 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:33,987 INFO:     Epoch: 22
2022-12-31 11:21:35,640 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4754676312208176, 'Total loss': 0.4754676312208176} | train loss {'Reaction outcome loss': 0.3754986206970542, 'Total loss': 0.3754986206970542}
2022-12-31 11:21:35,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:35,640 INFO:     Epoch: 23
2022-12-31 11:21:37,263 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46713804205258685, 'Total loss': 0.46713804205258685} | train loss {'Reaction outcome loss': 0.3696807999892727, 'Total loss': 0.3696807999892727}
2022-12-31 11:21:37,263 INFO:     Found new best model at epoch 23
2022-12-31 11:21:37,264 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:37,264 INFO:     Epoch: 24
2022-12-31 11:21:38,900 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46814022660255433, 'Total loss': 0.46814022660255433} | train loss {'Reaction outcome loss': 0.361763308874156, 'Total loss': 0.361763308874156}
2022-12-31 11:21:38,901 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:38,901 INFO:     Epoch: 25
2022-12-31 11:21:40,512 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4634858459234238, 'Total loss': 0.4634858459234238} | train loss {'Reaction outcome loss': 0.35705781853555335, 'Total loss': 0.35705781853555335}
2022-12-31 11:21:40,512 INFO:     Found new best model at epoch 25
2022-12-31 11:21:40,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:40,513 INFO:     Epoch: 26
2022-12-31 11:21:42,131 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47778888543446857, 'Total loss': 0.47778888543446857} | train loss {'Reaction outcome loss': 0.3554718724883877, 'Total loss': 0.3554718724883877}
2022-12-31 11:21:42,131 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:42,131 INFO:     Epoch: 27
2022-12-31 11:21:43,777 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44451558689276377, 'Total loss': 0.44451558689276377} | train loss {'Reaction outcome loss': 0.34390214975228184, 'Total loss': 0.34390214975228184}
2022-12-31 11:21:43,777 INFO:     Found new best model at epoch 27
2022-12-31 11:21:43,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:43,778 INFO:     Epoch: 28
2022-12-31 11:21:45,428 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4794330616792043, 'Total loss': 0.4794330616792043} | train loss {'Reaction outcome loss': 0.33940095247943763, 'Total loss': 0.33940095247943763}
2022-12-31 11:21:45,429 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:45,429 INFO:     Epoch: 29
2022-12-31 11:21:47,004 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44831528266270954, 'Total loss': 0.44831528266270954} | train loss {'Reaction outcome loss': 0.33495994983915833, 'Total loss': 0.33495994983915833}
2022-12-31 11:21:47,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:47,005 INFO:     Epoch: 30
2022-12-31 11:21:48,609 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.46820621291796366, 'Total loss': 0.46820621291796366} | train loss {'Reaction outcome loss': 0.35126265702580195, 'Total loss': 0.35126265702580195}
2022-12-31 11:21:48,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:48,609 INFO:     Epoch: 31
2022-12-31 11:21:50,239 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4279948661724726, 'Total loss': 0.4279948661724726} | train loss {'Reaction outcome loss': 0.36366069979587756, 'Total loss': 0.36366069979587756}
2022-12-31 11:21:50,239 INFO:     Found new best model at epoch 31
2022-12-31 11:21:50,240 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:50,240 INFO:     Epoch: 32
2022-12-31 11:21:51,881 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43549082179864246, 'Total loss': 0.43549082179864246} | train loss {'Reaction outcome loss': 0.3562719553651666, 'Total loss': 0.3562719553651666}
2022-12-31 11:21:51,881 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:51,881 INFO:     Epoch: 33
2022-12-31 11:21:53,518 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4666519323984782, 'Total loss': 0.4666519323984782} | train loss {'Reaction outcome loss': 0.32182563153648935, 'Total loss': 0.32182563153648935}
2022-12-31 11:21:53,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:53,519 INFO:     Epoch: 34
2022-12-31 11:21:55,152 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45480802953243255, 'Total loss': 0.45480802953243255} | train loss {'Reaction outcome loss': 0.31648164265282935, 'Total loss': 0.31648164265282935}
2022-12-31 11:21:55,152 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:55,152 INFO:     Epoch: 35
2022-12-31 11:21:56,729 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4618673712015152, 'Total loss': 0.4618673712015152} | train loss {'Reaction outcome loss': 0.30918728118463745, 'Total loss': 0.30918728118463745}
2022-12-31 11:21:56,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:56,730 INFO:     Epoch: 36
2022-12-31 11:21:58,352 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47759421467781066, 'Total loss': 0.47759421467781066} | train loss {'Reaction outcome loss': 0.30466301020646497, 'Total loss': 0.30466301020646497}
2022-12-31 11:21:58,353 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:58,353 INFO:     Epoch: 37
2022-12-31 11:21:59,985 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47034655809402465, 'Total loss': 0.47034655809402465} | train loss {'Reaction outcome loss': 0.3089253326263819, 'Total loss': 0.3089253326263819}
2022-12-31 11:21:59,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:21:59,985 INFO:     Epoch: 38
2022-12-31 11:22:01,610 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41427978277206423, 'Total loss': 0.41427978277206423} | train loss {'Reaction outcome loss': 0.304542480369096, 'Total loss': 0.304542480369096}
2022-12-31 11:22:01,611 INFO:     Found new best model at epoch 38
2022-12-31 11:22:01,611 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:01,612 INFO:     Epoch: 39
2022-12-31 11:22:03,215 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42536542216936746, 'Total loss': 0.42536542216936746} | train loss {'Reaction outcome loss': 0.2909466068746912, 'Total loss': 0.2909466068746912}
2022-12-31 11:22:03,215 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:03,215 INFO:     Epoch: 40
2022-12-31 11:22:04,800 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46332329710324605, 'Total loss': 0.46332329710324605} | train loss {'Reaction outcome loss': 0.2876053806664287, 'Total loss': 0.2876053806664287}
2022-12-31 11:22:04,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:04,800 INFO:     Epoch: 41
2022-12-31 11:22:06,396 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43940133253733316, 'Total loss': 0.43940133253733316} | train loss {'Reaction outcome loss': 0.29020065328349237, 'Total loss': 0.29020065328349237}
2022-12-31 11:22:06,396 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:06,397 INFO:     Epoch: 42
2022-12-31 11:22:08,003 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4816228628158569, 'Total loss': 0.4816228628158569} | train loss {'Reaction outcome loss': 0.2878560172189348, 'Total loss': 0.2878560172189348}
2022-12-31 11:22:08,003 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:08,003 INFO:     Epoch: 43
2022-12-31 11:22:09,609 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39999168515205386, 'Total loss': 0.39999168515205386} | train loss {'Reaction outcome loss': 0.2859908719057811, 'Total loss': 0.2859908719057811}
2022-12-31 11:22:09,609 INFO:     Found new best model at epoch 43
2022-12-31 11:22:09,610 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:09,610 INFO:     Epoch: 44
2022-12-31 11:22:11,213 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4427372972170512, 'Total loss': 0.4427372972170512} | train loss {'Reaction outcome loss': 0.2786546385664817, 'Total loss': 0.2786546385664817}
2022-12-31 11:22:11,214 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:11,214 INFO:     Epoch: 45
2022-12-31 11:22:12,820 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.42847427825133005, 'Total loss': 0.42847427825133005} | train loss {'Reaction outcome loss': 0.27816846100883424, 'Total loss': 0.27816846100883424}
2022-12-31 11:22:12,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:12,820 INFO:     Epoch: 46
2022-12-31 11:22:14,398 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.423867396513621, 'Total loss': 0.423867396513621} | train loss {'Reaction outcome loss': 0.2742630302512924, 'Total loss': 0.2742630302512924}
2022-12-31 11:22:14,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:14,399 INFO:     Epoch: 47
2022-12-31 11:22:15,988 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4538436512152354, 'Total loss': 0.4538436512152354} | train loss {'Reaction outcome loss': 0.27562123659130966, 'Total loss': 0.27562123659130966}
2022-12-31 11:22:15,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:15,988 INFO:     Epoch: 48
2022-12-31 11:22:17,640 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41443781852722167, 'Total loss': 0.41443781852722167} | train loss {'Reaction outcome loss': 0.27020394000514963, 'Total loss': 0.27020394000514963}
2022-12-31 11:22:17,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:17,640 INFO:     Epoch: 49
2022-12-31 11:22:19,284 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4596140876412392, 'Total loss': 0.4596140876412392} | train loss {'Reaction outcome loss': 0.2696901547412078, 'Total loss': 0.2696901547412078}
2022-12-31 11:22:19,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:19,284 INFO:     Epoch: 50
2022-12-31 11:22:20,894 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.44374411503473915, 'Total loss': 0.44374411503473915} | train loss {'Reaction outcome loss': 0.30960804704522743, 'Total loss': 0.30960804704522743}
2022-12-31 11:22:20,895 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:20,895 INFO:     Epoch: 51
2022-12-31 11:22:22,494 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4247763633728027, 'Total loss': 0.4247763633728027} | train loss {'Reaction outcome loss': 0.2858281948848752, 'Total loss': 0.2858281948848752}
2022-12-31 11:22:22,494 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:22,494 INFO:     Epoch: 52
2022-12-31 11:22:24,083 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4259720355272293, 'Total loss': 0.4259720355272293} | train loss {'Reaction outcome loss': 0.2697959669656458, 'Total loss': 0.2697959669656458}
2022-12-31 11:22:24,083 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:24,083 INFO:     Epoch: 53
2022-12-31 11:22:25,691 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46982390284538267, 'Total loss': 0.46982390284538267} | train loss {'Reaction outcome loss': 0.2572505812133676, 'Total loss': 0.2572505812133676}
2022-12-31 11:22:25,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:25,691 INFO:     Epoch: 54
2022-12-31 11:22:27,298 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4589938173691432, 'Total loss': 0.4589938173691432} | train loss {'Reaction outcome loss': 0.264135578053369, 'Total loss': 0.264135578053369}
2022-12-31 11:22:27,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:27,299 INFO:     Epoch: 55
2022-12-31 11:22:28,909 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4433996359507243, 'Total loss': 0.4433996359507243} | train loss {'Reaction outcome loss': 0.3141669469710984, 'Total loss': 0.3141669469710984}
2022-12-31 11:22:28,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:28,909 INFO:     Epoch: 56
2022-12-31 11:22:30,517 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41199780205885567, 'Total loss': 0.41199780205885567} | train loss {'Reaction outcome loss': 0.2694398118149273, 'Total loss': 0.2694398118149273}
2022-12-31 11:22:30,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:30,517 INFO:     Epoch: 57
2022-12-31 11:22:32,111 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40136500597000124, 'Total loss': 0.40136500597000124} | train loss {'Reaction outcome loss': 0.2605103244355448, 'Total loss': 0.2605103244355448}
2022-12-31 11:22:32,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:32,112 INFO:     Epoch: 58
2022-12-31 11:22:33,758 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45590966641902925, 'Total loss': 0.45590966641902925} | train loss {'Reaction outcome loss': 0.256943758559393, 'Total loss': 0.256943758559393}
2022-12-31 11:22:33,759 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:33,759 INFO:     Epoch: 59
2022-12-31 11:22:35,387 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42458330194155375, 'Total loss': 0.42458330194155375} | train loss {'Reaction outcome loss': 0.2544232255104757, 'Total loss': 0.2544232255104757}
2022-12-31 11:22:35,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:35,387 INFO:     Epoch: 60
2022-12-31 11:22:37,008 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41032766103744506, 'Total loss': 0.41032766103744506} | train loss {'Reaction outcome loss': 0.24970360062729594, 'Total loss': 0.24970360062729594}
2022-12-31 11:22:37,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:37,009 INFO:     Epoch: 61
2022-12-31 11:22:38,630 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4317403048276901, 'Total loss': 0.4317403048276901} | train loss {'Reaction outcome loss': 0.24654222579767415, 'Total loss': 0.24654222579767415}
2022-12-31 11:22:38,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:38,630 INFO:     Epoch: 62
2022-12-31 11:22:40,258 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42866241733233135, 'Total loss': 0.42866241733233135} | train loss {'Reaction outcome loss': 0.24824274320450268, 'Total loss': 0.24824274320450268}
2022-12-31 11:22:40,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:40,259 INFO:     Epoch: 63
2022-12-31 11:22:41,874 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4192153811454773, 'Total loss': 0.4192153811454773} | train loss {'Reaction outcome loss': 0.23688062146773492, 'Total loss': 0.23688062146773492}
2022-12-31 11:22:41,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:41,874 INFO:     Epoch: 64
2022-12-31 11:22:43,527 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42159908612569175, 'Total loss': 0.42159908612569175} | train loss {'Reaction outcome loss': 0.2362543790584533, 'Total loss': 0.2362543790584533}
2022-12-31 11:22:43,527 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:43,528 INFO:     Epoch: 65
2022-12-31 11:22:45,186 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.46446717977523805, 'Total loss': 0.46446717977523805} | train loss {'Reaction outcome loss': 0.24283420707755451, 'Total loss': 0.24283420707755451}
2022-12-31 11:22:45,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:45,187 INFO:     Epoch: 66
2022-12-31 11:22:46,836 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4436346252759298, 'Total loss': 0.4436346252759298} | train loss {'Reaction outcome loss': 0.23416300802964016, 'Total loss': 0.23416300802964016}
2022-12-31 11:22:46,836 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:46,836 INFO:     Epoch: 67
2022-12-31 11:22:48,455 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43184644281864165, 'Total loss': 0.43184644281864165} | train loss {'Reaction outcome loss': 0.2398448170370613, 'Total loss': 0.2398448170370613}
2022-12-31 11:22:48,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:48,455 INFO:     Epoch: 68
2022-12-31 11:22:50,043 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4390688369671504, 'Total loss': 0.4390688369671504} | train loss {'Reaction outcome loss': 0.23976625998814902, 'Total loss': 0.23976625998814902}
2022-12-31 11:22:50,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:50,043 INFO:     Epoch: 69
2022-12-31 11:22:51,684 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4605020314455032, 'Total loss': 0.4605020314455032} | train loss {'Reaction outcome loss': 0.27438887883170904, 'Total loss': 0.27438887883170904}
2022-12-31 11:22:51,685 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:51,685 INFO:     Epoch: 70
2022-12-31 11:22:53,303 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44540952444076537, 'Total loss': 0.44540952444076537} | train loss {'Reaction outcome loss': 0.23602239912050182, 'Total loss': 0.23602239912050182}
2022-12-31 11:22:53,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:53,303 INFO:     Epoch: 71
2022-12-31 11:22:54,920 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42858016764124235, 'Total loss': 0.42858016764124235} | train loss {'Reaction outcome loss': 0.22872464132555964, 'Total loss': 0.22872464132555964}
2022-12-31 11:22:54,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:54,920 INFO:     Epoch: 72
2022-12-31 11:22:56,539 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4757264057795207, 'Total loss': 0.4757264057795207} | train loss {'Reaction outcome loss': 0.2316278328012297, 'Total loss': 0.2316278328012297}
2022-12-31 11:22:56,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:56,539 INFO:     Epoch: 73
2022-12-31 11:22:58,153 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45276530186335245, 'Total loss': 0.45276530186335245} | train loss {'Reaction outcome loss': 0.2311380256108258, 'Total loss': 0.2311380256108258}
2022-12-31 11:22:58,153 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:58,154 INFO:     Epoch: 74
2022-12-31 11:22:59,736 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4304852455854416, 'Total loss': 0.4304852455854416} | train loss {'Reaction outcome loss': 0.2283494657823357, 'Total loss': 0.2283494657823357}
2022-12-31 11:22:59,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:22:59,736 INFO:     Epoch: 75
2022-12-31 11:23:01,398 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43084876040617626, 'Total loss': 0.43084876040617626} | train loss {'Reaction outcome loss': 0.22941577608962424, 'Total loss': 0.22941577608962424}
2022-12-31 11:23:01,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:01,398 INFO:     Epoch: 76
2022-12-31 11:23:03,013 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42112437387307483, 'Total loss': 0.42112437387307483} | train loss {'Reaction outcome loss': 0.22586847867100057, 'Total loss': 0.22586847867100057}
2022-12-31 11:23:03,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:03,013 INFO:     Epoch: 77
2022-12-31 11:23:04,630 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47142491936683656, 'Total loss': 0.47142491936683656} | train loss {'Reaction outcome loss': 0.2216780936194719, 'Total loss': 0.2216780936194719}
2022-12-31 11:23:04,631 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:04,631 INFO:     Epoch: 78
2022-12-31 11:23:06,242 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4111122210820516, 'Total loss': 0.4111122210820516} | train loss {'Reaction outcome loss': 0.2222375021505075, 'Total loss': 0.2222375021505075}
2022-12-31 11:23:06,242 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:06,242 INFO:     Epoch: 79
2022-12-31 11:23:07,858 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44170132478078206, 'Total loss': 0.44170132478078206} | train loss {'Reaction outcome loss': 0.22064600696793987, 'Total loss': 0.22064600696793987}
2022-12-31 11:23:07,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:07,859 INFO:     Epoch: 80
2022-12-31 11:23:09,459 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46621687213579815, 'Total loss': 0.46621687213579815} | train loss {'Reaction outcome loss': 0.22427427375193962, 'Total loss': 0.22427427375193962}
2022-12-31 11:23:09,459 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:09,459 INFO:     Epoch: 81
2022-12-31 11:23:11,103 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43341435889403024, 'Total loss': 0.43341435889403024} | train loss {'Reaction outcome loss': 0.21446567078131973, 'Total loss': 0.21446567078131973}
2022-12-31 11:23:11,103 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:11,103 INFO:     Epoch: 82
2022-12-31 11:23:12,740 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40223219792048137, 'Total loss': 0.40223219792048137} | train loss {'Reaction outcome loss': 0.2156165307117761, 'Total loss': 0.2156165307117761}
2022-12-31 11:23:12,741 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:12,741 INFO:     Epoch: 83
2022-12-31 11:23:14,387 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.42609690229098, 'Total loss': 0.42609690229098} | train loss {'Reaction outcome loss': 0.22452759123626637, 'Total loss': 0.22452759123626637}
2022-12-31 11:23:14,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:14,388 INFO:     Epoch: 84
2022-12-31 11:23:16,009 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44397236555814745, 'Total loss': 0.44397236555814745} | train loss {'Reaction outcome loss': 0.21980713147912984, 'Total loss': 0.21980713147912984}
2022-12-31 11:23:16,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:16,011 INFO:     Epoch: 85
2022-12-31 11:23:17,598 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42894530793031055, 'Total loss': 0.42894530793031055} | train loss {'Reaction outcome loss': 0.2145605027457139, 'Total loss': 0.2145605027457139}
2022-12-31 11:23:17,598 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:17,599 INFO:     Epoch: 86
2022-12-31 11:23:19,228 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4572241147359212, 'Total loss': 0.4572241147359212} | train loss {'Reaction outcome loss': 0.2095414799149549, 'Total loss': 0.2095414799149549}
2022-12-31 11:23:19,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:19,228 INFO:     Epoch: 87
2022-12-31 11:23:20,845 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3969979166984558, 'Total loss': 0.3969979166984558} | train loss {'Reaction outcome loss': 0.2108255108798561, 'Total loss': 0.2108255108798561}
2022-12-31 11:23:20,845 INFO:     Found new best model at epoch 87
2022-12-31 11:23:20,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:20,846 INFO:     Epoch: 88
2022-12-31 11:23:22,469 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4016015734523535, 'Total loss': 0.4016015734523535} | train loss {'Reaction outcome loss': 0.2109226721095974, 'Total loss': 0.2109226721095974}
2022-12-31 11:23:22,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:22,470 INFO:     Epoch: 89
2022-12-31 11:23:24,086 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41783732970555626, 'Total loss': 0.41783732970555626} | train loss {'Reaction outcome loss': 0.22608059861670263, 'Total loss': 0.22608059861670263}
2022-12-31 11:23:24,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:24,087 INFO:     Epoch: 90
2022-12-31 11:23:25,702 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44893054018417994, 'Total loss': 0.44893054018417994} | train loss {'Reaction outcome loss': 0.23491940189800833, 'Total loss': 0.23491940189800833}
2022-12-31 11:23:25,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:25,702 INFO:     Epoch: 91
2022-12-31 11:23:27,292 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.43263400892416637, 'Total loss': 0.43263400892416637} | train loss {'Reaction outcome loss': 0.20366366076374054, 'Total loss': 0.20366366076374054}
2022-12-31 11:23:27,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:27,293 INFO:     Epoch: 92
2022-12-31 11:23:28,959 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4133978128433228, 'Total loss': 0.4133978128433228} | train loss {'Reaction outcome loss': 0.21115765985614152, 'Total loss': 0.21115765985614152}
2022-12-31 11:23:28,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:28,959 INFO:     Epoch: 93
2022-12-31 11:23:30,573 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.408389750123024, 'Total loss': 0.408389750123024} | train loss {'Reaction outcome loss': 0.20899552007495004, 'Total loss': 0.20899552007495004}
2022-12-31 11:23:30,574 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:30,574 INFO:     Epoch: 94
2022-12-31 11:23:32,187 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4349215974410375, 'Total loss': 0.4349215974410375} | train loss {'Reaction outcome loss': 0.20294526243763528, 'Total loss': 0.20294526243763528}
2022-12-31 11:23:32,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:32,187 INFO:     Epoch: 95
2022-12-31 11:23:33,815 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4330125351746877, 'Total loss': 0.4330125351746877} | train loss {'Reaction outcome loss': 0.1980307152936829, 'Total loss': 0.1980307152936829}
2022-12-31 11:23:33,815 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:33,815 INFO:     Epoch: 96
2022-12-31 11:23:35,455 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4510429322719574, 'Total loss': 0.4510429322719574} | train loss {'Reaction outcome loss': 0.20965225105528193, 'Total loss': 0.20965225105528193}
2022-12-31 11:23:35,456 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:35,456 INFO:     Epoch: 97
2022-12-31 11:23:37,050 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4311103900273641, 'Total loss': 0.4311103900273641} | train loss {'Reaction outcome loss': 0.2088051762643179, 'Total loss': 0.2088051762643179}
2022-12-31 11:23:37,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:37,050 INFO:     Epoch: 98
2022-12-31 11:23:38,691 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44117119113604225, 'Total loss': 0.44117119113604225} | train loss {'Reaction outcome loss': 0.20027075293269198, 'Total loss': 0.20027075293269198}
2022-12-31 11:23:38,692 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:38,692 INFO:     Epoch: 99
2022-12-31 11:23:40,303 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4347171535094579, 'Total loss': 0.4347171535094579} | train loss {'Reaction outcome loss': 0.2013029969137911, 'Total loss': 0.2013029969137911}
2022-12-31 11:23:40,303 INFO:     Best model found after epoch 88 of 100.
2022-12-31 11:23:40,303 INFO:   Done with stage: TRAINING
2022-12-31 11:23:40,303 INFO:   Starting stage: EVALUATION
2022-12-31 11:23:40,432 INFO:   Done with stage: EVALUATION
2022-12-31 11:23:40,432 INFO:   Leaving out SEQ value Fold_2
2022-12-31 11:23:40,445 INFO:   examples: 20,544| examples in train: 17,236 | examples in val: 908| examples in test: 2,400
2022-12-31 11:23:40,445 INFO:   Starting stage: FEATURE SCALING
2022-12-31 11:23:41,080 INFO:   Done with stage: FEATURE SCALING
2022-12-31 11:23:41,080 INFO:   Starting stage: SCALING TARGETS
2022-12-31 11:23:41,149 INFO:   Done with stage: SCALING TARGETS
2022-12-31 11:23:41,149 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:23:41,149 INFO:     No hyperparam tuning for this model
2022-12-31 11:23:41,149 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:23:41,149 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 11:23:41,150 INFO:     None feature selector for col prot
2022-12-31 11:23:41,150 INFO:     None feature selector for col prot
2022-12-31 11:23:41,150 INFO:     None feature selector for col prot
2022-12-31 11:23:41,151 INFO:     None feature selector for col chem
2022-12-31 11:23:41,151 INFO:     None feature selector for col chem
2022-12-31 11:23:41,151 INFO:     None feature selector for col chem
2022-12-31 11:23:41,151 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 11:23:41,151 INFO:   Starting stage: BUILD MODEL
2022-12-31 11:23:41,153 INFO:     Number of params in model 223921
2022-12-31 11:23:41,156 INFO:   Done with stage: BUILD MODEL
2022-12-31 11:23:41,156 INFO:   Starting stage: TRAINING
2022-12-31 11:23:41,199 INFO:     Val loss before train {'Reaction outcome loss': 1.021997594833374, 'Total loss': 1.021997594833374}
2022-12-31 11:23:41,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:41,200 INFO:     Epoch: 0
2022-12-31 11:23:42,802 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6722035547097523, 'Total loss': 0.6722035547097523} | train loss {'Reaction outcome loss': 0.8111239466402266, 'Total loss': 0.8111239466402266}
2022-12-31 11:23:42,802 INFO:     Found new best model at epoch 0
2022-12-31 11:23:42,803 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:42,803 INFO:     Epoch: 1
2022-12-31 11:23:44,361 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5370388825734457, 'Total loss': 0.5370388825734457} | train loss {'Reaction outcome loss': 0.5852197818734027, 'Total loss': 0.5852197818734027}
2022-12-31 11:23:44,362 INFO:     Found new best model at epoch 1
2022-12-31 11:23:44,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:44,362 INFO:     Epoch: 2
2022-12-31 11:23:45,965 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5547284305095672, 'Total loss': 0.5547284305095672} | train loss {'Reaction outcome loss': 0.516286782865171, 'Total loss': 0.516286782865171}
2022-12-31 11:23:45,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:45,967 INFO:     Epoch: 3
2022-12-31 11:23:47,547 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4610689401626587, 'Total loss': 0.4610689401626587} | train loss {'Reaction outcome loss': 0.4887177847601749, 'Total loss': 0.4887177847601749}
2022-12-31 11:23:47,547 INFO:     Found new best model at epoch 3
2022-12-31 11:23:47,548 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:47,548 INFO:     Epoch: 4
2022-12-31 11:23:49,128 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.46792524456977846, 'Total loss': 0.46792524456977846} | train loss {'Reaction outcome loss': 0.47940701682258535, 'Total loss': 0.47940701682258535}
2022-12-31 11:23:49,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:49,129 INFO:     Epoch: 5
2022-12-31 11:23:50,710 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4324476768573125, 'Total loss': 0.4324476768573125} | train loss {'Reaction outcome loss': 0.4709858798318439, 'Total loss': 0.4709858798318439}
2022-12-31 11:23:50,710 INFO:     Found new best model at epoch 5
2022-12-31 11:23:50,711 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:50,711 INFO:     Epoch: 6
2022-12-31 11:23:52,291 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47392962376276654, 'Total loss': 0.47392962376276654} | train loss {'Reaction outcome loss': 0.46235787559438635, 'Total loss': 0.46235787559438635}
2022-12-31 11:23:52,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:52,292 INFO:     Epoch: 7
2022-12-31 11:23:53,851 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.514122474193573, 'Total loss': 0.514122474193573} | train loss {'Reaction outcome loss': 0.45184171249469124, 'Total loss': 0.45184171249469124}
2022-12-31 11:23:53,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:53,852 INFO:     Epoch: 8
2022-12-31 11:23:55,475 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4210081378618876, 'Total loss': 0.4210081378618876} | train loss {'Reaction outcome loss': 0.44149455063872867, 'Total loss': 0.44149455063872867}
2022-12-31 11:23:55,475 INFO:     Found new best model at epoch 8
2022-12-31 11:23:55,476 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:55,476 INFO:     Epoch: 9
2022-12-31 11:23:57,089 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4869386295477549, 'Total loss': 0.4869386295477549} | train loss {'Reaction outcome loss': 0.4353825395030004, 'Total loss': 0.4353825395030004}
2022-12-31 11:23:57,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:57,089 INFO:     Epoch: 10
2022-12-31 11:23:58,669 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42994084358215334, 'Total loss': 0.42994084358215334} | train loss {'Reaction outcome loss': 0.43231993756360476, 'Total loss': 0.43231993756360476}
2022-12-31 11:23:58,669 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:23:58,669 INFO:     Epoch: 11
2022-12-31 11:24:00,248 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.504272214571635, 'Total loss': 0.504272214571635} | train loss {'Reaction outcome loss': 0.4261203983315715, 'Total loss': 0.4261203983315715}
2022-12-31 11:24:00,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:00,248 INFO:     Epoch: 12
2022-12-31 11:24:01,846 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.47359773715337117, 'Total loss': 0.47359773715337117} | train loss {'Reaction outcome loss': 0.4195585500586916, 'Total loss': 0.4195585500586916}
2022-12-31 11:24:01,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:01,846 INFO:     Epoch: 13
2022-12-31 11:24:03,399 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4628763874371847, 'Total loss': 0.4628763874371847} | train loss {'Reaction outcome loss': 0.41492582962468816, 'Total loss': 0.41492582962468816}
2022-12-31 11:24:03,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:03,399 INFO:     Epoch: 14
2022-12-31 11:24:04,996 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42531549334526064, 'Total loss': 0.42531549334526064} | train loss {'Reaction outcome loss': 0.4126485835070963, 'Total loss': 0.4126485835070963}
2022-12-31 11:24:04,997 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:04,997 INFO:     Epoch: 15
2022-12-31 11:24:06,578 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43756433327992755, 'Total loss': 0.43756433327992755} | train loss {'Reaction outcome loss': 0.39699162015760386, 'Total loss': 0.39699162015760386}
2022-12-31 11:24:06,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:06,579 INFO:     Epoch: 16
2022-12-31 11:24:08,163 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4643995612859726, 'Total loss': 0.4643995612859726} | train loss {'Reaction outcome loss': 0.3991948454192391, 'Total loss': 0.3991948454192391}
2022-12-31 11:24:08,163 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:08,163 INFO:     Epoch: 17
2022-12-31 11:24:09,743 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3946310803294182, 'Total loss': 0.3946310803294182} | train loss {'Reaction outcome loss': 0.3927205140116038, 'Total loss': 0.3927205140116038}
2022-12-31 11:24:09,744 INFO:     Found new best model at epoch 17
2022-12-31 11:24:09,744 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:09,745 INFO:     Epoch: 18
2022-12-31 11:24:11,321 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4251954530676206, 'Total loss': 0.4251954530676206} | train loss {'Reaction outcome loss': 0.3861895628825382, 'Total loss': 0.3861895628825382}
2022-12-31 11:24:11,321 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:11,321 INFO:     Epoch: 19
2022-12-31 11:24:12,899 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4624965180953344, 'Total loss': 0.4624965180953344} | train loss {'Reaction outcome loss': 0.3784998303210294, 'Total loss': 0.3784998303210294}
2022-12-31 11:24:12,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:12,899 INFO:     Epoch: 20
2022-12-31 11:24:14,517 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41480684479077656, 'Total loss': 0.41480684479077656} | train loss {'Reaction outcome loss': 0.37687534049705224, 'Total loss': 0.37687534049705224}
2022-12-31 11:24:14,517 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:14,517 INFO:     Epoch: 21
2022-12-31 11:24:16,094 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4348386218150457, 'Total loss': 0.4348386218150457} | train loss {'Reaction outcome loss': 0.3661850831298916, 'Total loss': 0.3661850831298916}
2022-12-31 11:24:16,094 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:16,095 INFO:     Epoch: 22
2022-12-31 11:24:17,670 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40797980030377706, 'Total loss': 0.40797980030377706} | train loss {'Reaction outcome loss': 0.3633952493192973, 'Total loss': 0.3633952493192973}
2022-12-31 11:24:17,671 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:17,671 INFO:     Epoch: 23
2022-12-31 11:24:19,248 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.419427764415741, 'Total loss': 0.419427764415741} | train loss {'Reaction outcome loss': 0.355591088478212, 'Total loss': 0.355591088478212}
2022-12-31 11:24:19,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:19,248 INFO:     Epoch: 24
2022-12-31 11:24:20,799 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.38795386254787445, 'Total loss': 0.38795386254787445} | train loss {'Reaction outcome loss': 0.35118749798447996, 'Total loss': 0.35118749798447996}
2022-12-31 11:24:20,800 INFO:     Found new best model at epoch 24
2022-12-31 11:24:20,800 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:20,800 INFO:     Epoch: 25
2022-12-31 11:24:22,410 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.38867935091257094, 'Total loss': 0.38867935091257094} | train loss {'Reaction outcome loss': 0.343585192412138, 'Total loss': 0.343585192412138}
2022-12-31 11:24:22,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:22,411 INFO:     Epoch: 26
2022-12-31 11:24:24,015 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43727720379829405, 'Total loss': 0.43727720379829405} | train loss {'Reaction outcome loss': 0.34591034910193197, 'Total loss': 0.34591034910193197}
2022-12-31 11:24:24,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:24,016 INFO:     Epoch: 27
2022-12-31 11:24:25,594 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.428825635711352, 'Total loss': 0.428825635711352} | train loss {'Reaction outcome loss': 0.3332892489378099, 'Total loss': 0.3332892489378099}
2022-12-31 11:24:25,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:25,594 INFO:     Epoch: 28
2022-12-31 11:24:27,171 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3798915525277456, 'Total loss': 0.3798915525277456} | train loss {'Reaction outcome loss': 0.3322861588663525, 'Total loss': 0.3322861588663525}
2022-12-31 11:24:27,171 INFO:     Found new best model at epoch 28
2022-12-31 11:24:27,172 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:27,172 INFO:     Epoch: 29
2022-12-31 11:24:28,749 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4042442778746287, 'Total loss': 0.4042442778746287} | train loss {'Reaction outcome loss': 0.3270057821439372, 'Total loss': 0.3270057821439372}
2022-12-31 11:24:28,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:28,750 INFO:     Epoch: 30
2022-12-31 11:24:30,309 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.38059392316887775, 'Total loss': 0.38059392316887775} | train loss {'Reaction outcome loss': 0.3167539690655691, 'Total loss': 0.3167539690655691}
2022-12-31 11:24:30,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:30,310 INFO:     Epoch: 31
2022-12-31 11:24:31,889 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4172597825527191, 'Total loss': 0.4172597825527191} | train loss {'Reaction outcome loss': 0.31649094797946786, 'Total loss': 0.31649094797946786}
2022-12-31 11:24:31,890 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:31,890 INFO:     Epoch: 32
2022-12-31 11:24:33,500 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4283040940761566, 'Total loss': 0.4283040940761566} | train loss {'Reaction outcome loss': 0.31252280076344807, 'Total loss': 0.31252280076344807}
2022-12-31 11:24:33,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:33,501 INFO:     Epoch: 33
2022-12-31 11:24:35,104 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3799975464741389, 'Total loss': 0.3799975464741389} | train loss {'Reaction outcome loss': 0.3095754930542575, 'Total loss': 0.3095754930542575}
2022-12-31 11:24:35,105 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:35,105 INFO:     Epoch: 34
2022-12-31 11:24:36,721 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4016243447860082, 'Total loss': 0.4016243447860082} | train loss {'Reaction outcome loss': 0.3029846018525185, 'Total loss': 0.3029846018525185}
2022-12-31 11:24:36,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:36,722 INFO:     Epoch: 35
2022-12-31 11:24:38,329 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4061452587445577, 'Total loss': 0.4061452587445577} | train loss {'Reaction outcome loss': 0.300498833603881, 'Total loss': 0.300498833603881}
2022-12-31 11:24:38,329 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:38,329 INFO:     Epoch: 36
2022-12-31 11:24:39,899 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40254111687342325, 'Total loss': 0.40254111687342325} | train loss {'Reaction outcome loss': 0.2935680611679951, 'Total loss': 0.2935680611679951}
2022-12-31 11:24:39,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:39,899 INFO:     Epoch: 37
2022-12-31 11:24:41,501 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.473907874027888, 'Total loss': 0.473907874027888} | train loss {'Reaction outcome loss': 0.29306371316865637, 'Total loss': 0.29306371316865637}
2022-12-31 11:24:41,502 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:41,502 INFO:     Epoch: 38
2022-12-31 11:24:43,124 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3879964143037796, 'Total loss': 0.3879964143037796} | train loss {'Reaction outcome loss': 0.2912565844892352, 'Total loss': 0.2912565844892352}
2022-12-31 11:24:43,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:43,124 INFO:     Epoch: 39
2022-12-31 11:24:44,745 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3627074658870697, 'Total loss': 0.3627074658870697} | train loss {'Reaction outcome loss': 0.28481573612877614, 'Total loss': 0.28481573612877614}
2022-12-31 11:24:44,746 INFO:     Found new best model at epoch 39
2022-12-31 11:24:44,746 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:44,747 INFO:     Epoch: 40
2022-12-31 11:24:46,362 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.37356004615624744, 'Total loss': 0.37356004615624744} | train loss {'Reaction outcome loss': 0.2841213928190646, 'Total loss': 0.2841213928190646}
2022-12-31 11:24:46,362 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:46,363 INFO:     Epoch: 41
2022-12-31 11:24:47,949 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3407335285252581, 'Total loss': 0.3407335285252581} | train loss {'Reaction outcome loss': 0.2778741483611089, 'Total loss': 0.2778741483611089}
2022-12-31 11:24:47,949 INFO:     Found new best model at epoch 41
2022-12-31 11:24:47,950 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:47,950 INFO:     Epoch: 42
2022-12-31 11:24:49,503 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3538996865351995, 'Total loss': 0.3538996865351995} | train loss {'Reaction outcome loss': 0.274821307565327, 'Total loss': 0.274821307565327}
2022-12-31 11:24:49,503 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:49,503 INFO:     Epoch: 43
2022-12-31 11:24:51,079 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3749900509913762, 'Total loss': 0.3749900509913762} | train loss {'Reaction outcome loss': 0.2759001584240684, 'Total loss': 0.2759001584240684}
2022-12-31 11:24:51,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:51,079 INFO:     Epoch: 44
2022-12-31 11:24:52,654 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.36228900998830793, 'Total loss': 0.36228900998830793} | train loss {'Reaction outcome loss': 0.283702613937634, 'Total loss': 0.283702613937634}
2022-12-31 11:24:52,655 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:52,655 INFO:     Epoch: 45
2022-12-31 11:24:54,229 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4079628015557925, 'Total loss': 0.4079628015557925} | train loss {'Reaction outcome loss': 0.26782046867603504, 'Total loss': 0.26782046867603504}
2022-12-31 11:24:54,230 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:54,230 INFO:     Epoch: 46
2022-12-31 11:24:55,805 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3938949257135391, 'Total loss': 0.3938949257135391} | train loss {'Reaction outcome loss': 0.2663184186098752, 'Total loss': 0.2663184186098752}
2022-12-31 11:24:55,805 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:55,805 INFO:     Epoch: 47
2022-12-31 11:24:57,351 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3805136928955714, 'Total loss': 0.3805136928955714} | train loss {'Reaction outcome loss': 0.2644163917612146, 'Total loss': 0.2644163917612146}
2022-12-31 11:24:57,351 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:57,352 INFO:     Epoch: 48
2022-12-31 11:24:58,980 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.36865428388118743, 'Total loss': 0.36865428388118743} | train loss {'Reaction outcome loss': 0.2563369040687879, 'Total loss': 0.2563369040687879}
2022-12-31 11:24:58,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:24:58,981 INFO:     Epoch: 49
2022-12-31 11:25:00,604 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.34182861596345904, 'Total loss': 0.34182861596345904} | train loss {'Reaction outcome loss': 0.25316784715762847, 'Total loss': 0.25316784715762847}
2022-12-31 11:25:00,604 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:00,605 INFO:     Epoch: 50
2022-12-31 11:25:02,231 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40235021511713664, 'Total loss': 0.40235021511713664} | train loss {'Reaction outcome loss': 0.253730121999979, 'Total loss': 0.253730121999979}
2022-12-31 11:25:02,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:02,231 INFO:     Epoch: 51
2022-12-31 11:25:03,857 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.33628051380316415, 'Total loss': 0.33628051380316415} | train loss {'Reaction outcome loss': 0.2550394215448587, 'Total loss': 0.2550394215448587}
2022-12-31 11:25:03,857 INFO:     Found new best model at epoch 51
2022-12-31 11:25:03,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:03,858 INFO:     Epoch: 52
2022-12-31 11:25:05,484 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.34038312236468, 'Total loss': 0.34038312236468} | train loss {'Reaction outcome loss': 0.25455356619700237, 'Total loss': 0.25455356619700237}
2022-12-31 11:25:05,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:05,484 INFO:     Epoch: 53
2022-12-31 11:25:07,070 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4562919477621714, 'Total loss': 0.4562919477621714} | train loss {'Reaction outcome loss': 0.24750208900896487, 'Total loss': 0.24750208900896487}
2022-12-31 11:25:07,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:07,070 INFO:     Epoch: 54
2022-12-31 11:25:08,688 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3446205457051595, 'Total loss': 0.3446205457051595} | train loss {'Reaction outcome loss': 0.2528593452302394, 'Total loss': 0.2528593452302394}
2022-12-31 11:25:08,688 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:08,688 INFO:     Epoch: 55
2022-12-31 11:25:10,280 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37697688142458596, 'Total loss': 0.37697688142458596} | train loss {'Reaction outcome loss': 0.25168318857473354, 'Total loss': 0.25168318857473354}
2022-12-31 11:25:10,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:10,280 INFO:     Epoch: 56
2022-12-31 11:25:11,899 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.34895666340986886, 'Total loss': 0.34895666340986886} | train loss {'Reaction outcome loss': 0.24571585159886766, 'Total loss': 0.24571585159886766}
2022-12-31 11:25:11,899 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:11,899 INFO:     Epoch: 57
2022-12-31 11:25:13,496 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4103977789481481, 'Total loss': 0.4103977789481481} | train loss {'Reaction outcome loss': 0.2373936685974951, 'Total loss': 0.2373936685974951}
2022-12-31 11:25:13,496 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:13,496 INFO:     Epoch: 58
2022-12-31 11:25:15,104 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3370142469803492, 'Total loss': 0.3370142469803492} | train loss {'Reaction outcome loss': 0.2409845286083442, 'Total loss': 0.2409845286083442}
2022-12-31 11:25:15,104 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:15,104 INFO:     Epoch: 59
2022-12-31 11:25:16,680 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3307375252246857, 'Total loss': 0.3307375252246857} | train loss {'Reaction outcome loss': 0.2396058984376766, 'Total loss': 0.2396058984376766}
2022-12-31 11:25:16,680 INFO:     Found new best model at epoch 59
2022-12-31 11:25:16,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:16,681 INFO:     Epoch: 60
2022-12-31 11:25:18,261 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4386324961980184, 'Total loss': 0.4386324961980184} | train loss {'Reaction outcome loss': 0.23622750427435946, 'Total loss': 0.23622750427435946}
2022-12-31 11:25:18,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:18,261 INFO:     Epoch: 61
2022-12-31 11:25:19,845 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.35919895420471826, 'Total loss': 0.35919895420471826} | train loss {'Reaction outcome loss': 0.23684348381917786, 'Total loss': 0.23684348381917786}
2022-12-31 11:25:19,845 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:19,845 INFO:     Epoch: 62
2022-12-31 11:25:21,442 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3349126120253156, 'Total loss': 0.3349126120253156} | train loss {'Reaction outcome loss': 0.23832484395415696, 'Total loss': 0.23832484395415696}
2022-12-31 11:25:21,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:21,442 INFO:     Epoch: 63
2022-12-31 11:25:23,026 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3693357894817988, 'Total loss': 0.3693357894817988} | train loss {'Reaction outcome loss': 0.2320281688399889, 'Total loss': 0.2320281688399889}
2022-12-31 11:25:23,026 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:23,026 INFO:     Epoch: 64
2022-12-31 11:25:24,593 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3778669287761052, 'Total loss': 0.3778669287761052} | train loss {'Reaction outcome loss': 0.22426585646139252, 'Total loss': 0.22426585646139252}
2022-12-31 11:25:24,594 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:24,594 INFO:     Epoch: 65
2022-12-31 11:25:26,201 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.37586341897646586, 'Total loss': 0.37586341897646586} | train loss {'Reaction outcome loss': 0.2333127377692748, 'Total loss': 0.2333127377692748}
2022-12-31 11:25:26,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:26,201 INFO:     Epoch: 66
2022-12-31 11:25:27,795 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3609595331052939, 'Total loss': 0.3609595331052939} | train loss {'Reaction outcome loss': 0.23595283432277264, 'Total loss': 0.23595283432277264}
2022-12-31 11:25:27,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:27,795 INFO:     Epoch: 67
2022-12-31 11:25:29,379 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3875274707873662, 'Total loss': 0.3875274707873662} | train loss {'Reaction outcome loss': 0.22897152144599844, 'Total loss': 0.22897152144599844}
2022-12-31 11:25:29,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:29,379 INFO:     Epoch: 68
2022-12-31 11:25:30,967 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44123005668322246, 'Total loss': 0.44123005668322246} | train loss {'Reaction outcome loss': 0.22683456082724862, 'Total loss': 0.22683456082724862}
2022-12-31 11:25:30,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:30,968 INFO:     Epoch: 69
2022-12-31 11:25:32,558 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.35329125126202904, 'Total loss': 0.35329125126202904} | train loss {'Reaction outcome loss': 0.22663057419574922, 'Total loss': 0.22663057419574922}
2022-12-31 11:25:32,558 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:32,558 INFO:     Epoch: 70
2022-12-31 11:25:33,824 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4038509209950765, 'Total loss': 0.4038509209950765} | train loss {'Reaction outcome loss': 0.21617955076335757, 'Total loss': 0.21617955076335757}
2022-12-31 11:25:33,824 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:33,824 INFO:     Epoch: 71
2022-12-31 11:25:34,864 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3556500439842542, 'Total loss': 0.3556500439842542} | train loss {'Reaction outcome loss': 0.21997141133717918, 'Total loss': 0.21997141133717918}
2022-12-31 11:25:34,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:34,864 INFO:     Epoch: 72
2022-12-31 11:25:35,898 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.35909389158089955, 'Total loss': 0.35909389158089955} | train loss {'Reaction outcome loss': 0.21563007711536356, 'Total loss': 0.21563007711536356}
2022-12-31 11:25:35,898 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:35,898 INFO:     Epoch: 73
2022-12-31 11:25:36,936 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4388834019502004, 'Total loss': 0.4388834019502004} | train loss {'Reaction outcome loss': 0.22027691533375118, 'Total loss': 0.22027691533375118}
2022-12-31 11:25:36,936 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:36,936 INFO:     Epoch: 74
2022-12-31 11:25:38,089 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4128358781337738, 'Total loss': 0.4128358781337738} | train loss {'Reaction outcome loss': 0.22304295874028293, 'Total loss': 0.22304295874028293}
2022-12-31 11:25:38,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:38,090 INFO:     Epoch: 75
2022-12-31 11:25:39,718 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3545361469189326, 'Total loss': 0.3545361469189326} | train loss {'Reaction outcome loss': 0.2121593926895272, 'Total loss': 0.2121593926895272}
2022-12-31 11:25:39,718 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:39,719 INFO:     Epoch: 76
2022-12-31 11:25:41,312 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.348718623816967, 'Total loss': 0.348718623816967} | train loss {'Reaction outcome loss': 0.21467803242029967, 'Total loss': 0.21467803242029967}
2022-12-31 11:25:41,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:41,312 INFO:     Epoch: 77
2022-12-31 11:25:42,904 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3515694335103035, 'Total loss': 0.3515694335103035} | train loss {'Reaction outcome loss': 0.21270527156345823, 'Total loss': 0.21270527156345823}
2022-12-31 11:25:42,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:42,904 INFO:     Epoch: 78
2022-12-31 11:25:44,483 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.36466579188903175, 'Total loss': 0.36466579188903175} | train loss {'Reaction outcome loss': 0.21169605123362056, 'Total loss': 0.21169605123362056}
2022-12-31 11:25:44,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:44,484 INFO:     Epoch: 79
2022-12-31 11:25:46,062 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.34947791149218876, 'Total loss': 0.34947791149218876} | train loss {'Reaction outcome loss': 0.21103538389283197, 'Total loss': 0.21103538389283197}
2022-12-31 11:25:46,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:46,063 INFO:     Epoch: 80
2022-12-31 11:25:47,620 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44091001749038694, 'Total loss': 0.44091001749038694} | train loss {'Reaction outcome loss': 0.20776520651523714, 'Total loss': 0.20776520651523714}
2022-12-31 11:25:47,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:47,620 INFO:     Epoch: 81
2022-12-31 11:25:49,210 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3904000774025917, 'Total loss': 0.3904000774025917} | train loss {'Reaction outcome loss': 0.2112503912023924, 'Total loss': 0.2112503912023924}
2022-12-31 11:25:49,211 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:49,211 INFO:     Epoch: 82
2022-12-31 11:25:50,766 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.36553983290990194, 'Total loss': 0.36553983290990194} | train loss {'Reaction outcome loss': 0.20579095187562482, 'Total loss': 0.20579095187562482}
2022-12-31 11:25:50,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:50,766 INFO:     Epoch: 83
2022-12-31 11:25:52,373 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.39130797882874807, 'Total loss': 0.39130797882874807} | train loss {'Reaction outcome loss': 0.2064519360937454, 'Total loss': 0.2064519360937454}
2022-12-31 11:25:52,373 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:52,373 INFO:     Epoch: 84
2022-12-31 11:25:53,967 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.36713058104117713, 'Total loss': 0.36713058104117713} | train loss {'Reaction outcome loss': 0.2022308200183842, 'Total loss': 0.2022308200183842}
2022-12-31 11:25:53,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:53,967 INFO:     Epoch: 85
2022-12-31 11:25:55,545 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.38360219697157544, 'Total loss': 0.38360219697157544} | train loss {'Reaction outcome loss': 0.20791792141066656, 'Total loss': 0.20791792141066656}
2022-12-31 11:25:55,546 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:55,546 INFO:     Epoch: 86
2022-12-31 11:25:57,110 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3420034664217383, 'Total loss': 0.3420034664217383} | train loss {'Reaction outcome loss': 0.2012803693957351, 'Total loss': 0.2012803693957351}
2022-12-31 11:25:57,110 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:57,110 INFO:     Epoch: 87
2022-12-31 11:25:58,680 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3804745554924011, 'Total loss': 0.3804745554924011} | train loss {'Reaction outcome loss': 0.20240614864699266, 'Total loss': 0.20240614864699266}
2022-12-31 11:25:58,680 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:25:58,680 INFO:     Epoch: 88
2022-12-31 11:26:00,260 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3391351374487082, 'Total loss': 0.3391351374487082} | train loss {'Reaction outcome loss': 0.2012756441650843, 'Total loss': 0.2012756441650843}
2022-12-31 11:26:00,261 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:00,261 INFO:     Epoch: 89
2022-12-31 11:26:01,841 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3576339092105627, 'Total loss': 0.3576339092105627} | train loss {'Reaction outcome loss': 0.20248067548705473, 'Total loss': 0.20248067548705473}
2022-12-31 11:26:01,842 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:01,842 INFO:     Epoch: 90
2022-12-31 11:26:03,423 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.32812111179033915, 'Total loss': 0.32812111179033915} | train loss {'Reaction outcome loss': 0.20491053776608573, 'Total loss': 0.20491053776608573}
2022-12-31 11:26:03,423 INFO:     Found new best model at epoch 90
2022-12-31 11:26:03,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:03,424 INFO:     Epoch: 91
2022-12-31 11:26:04,993 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3886565685272217, 'Total loss': 0.3886565685272217} | train loss {'Reaction outcome loss': 0.20343425210427354, 'Total loss': 0.20343425210427354}
2022-12-31 11:26:04,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:04,993 INFO:     Epoch: 92
2022-12-31 11:26:06,556 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3505357796947161, 'Total loss': 0.3505357796947161} | train loss {'Reaction outcome loss': 0.19732207364264737, 'Total loss': 0.19732207364264737}
2022-12-31 11:26:06,556 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:06,556 INFO:     Epoch: 93
2022-12-31 11:26:08,131 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.38523227671782173, 'Total loss': 0.38523227671782173} | train loss {'Reaction outcome loss': 0.20037439741470195, 'Total loss': 0.20037439741470195}
2022-12-31 11:26:08,132 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:08,132 INFO:     Epoch: 94
2022-12-31 11:26:09,708 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.340097708053266, 'Total loss': 0.340097708053266} | train loss {'Reaction outcome loss': 0.1999484907646008, 'Total loss': 0.1999484907646008}
2022-12-31 11:26:09,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:09,708 INFO:     Epoch: 95
2022-12-31 11:26:11,283 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3926421449830135, 'Total loss': 0.3926421449830135} | train loss {'Reaction outcome loss': 0.195687611375211, 'Total loss': 0.195687611375211}
2022-12-31 11:26:11,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:11,284 INFO:     Epoch: 96
2022-12-31 11:26:12,860 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4149508262674014, 'Total loss': 0.4149508262674014} | train loss {'Reaction outcome loss': 0.19965510376970524, 'Total loss': 0.19965510376970524}
2022-12-31 11:26:12,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:12,860 INFO:     Epoch: 97
2022-12-31 11:26:14,426 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.36468529154857, 'Total loss': 0.36468529154857} | train loss {'Reaction outcome loss': 0.19344599153846503, 'Total loss': 0.19344599153846503}
2022-12-31 11:26:14,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:14,427 INFO:     Epoch: 98
2022-12-31 11:26:16,015 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.34855377407123644, 'Total loss': 0.34855377407123644} | train loss {'Reaction outcome loss': 0.19795509297745648, 'Total loss': 0.19795509297745648}
2022-12-31 11:26:16,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:16,015 INFO:     Epoch: 99
2022-12-31 11:26:17,574 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.33933328092098236, 'Total loss': 0.33933328092098236} | train loss {'Reaction outcome loss': 0.1976685421127412, 'Total loss': 0.1976685421127412}
2022-12-31 11:26:17,574 INFO:     Best model found after epoch 91 of 100.
2022-12-31 11:26:17,574 INFO:   Done with stage: TRAINING
2022-12-31 11:26:17,574 INFO:   Starting stage: EVALUATION
2022-12-31 11:26:17,725 INFO:   Done with stage: EVALUATION
2022-12-31 11:26:17,726 INFO:   Leaving out SEQ value Fold_3
2022-12-31 11:26:17,738 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2022-12-31 11:26:17,738 INFO:   Starting stage: FEATURE SCALING
2022-12-31 11:26:18,379 INFO:   Done with stage: FEATURE SCALING
2022-12-31 11:26:18,379 INFO:   Starting stage: SCALING TARGETS
2022-12-31 11:26:18,448 INFO:   Done with stage: SCALING TARGETS
2022-12-31 11:26:18,448 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:26:18,448 INFO:     No hyperparam tuning for this model
2022-12-31 11:26:18,448 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:26:18,448 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 11:26:18,449 INFO:     None feature selector for col prot
2022-12-31 11:26:18,449 INFO:     None feature selector for col prot
2022-12-31 11:26:18,449 INFO:     None feature selector for col prot
2022-12-31 11:26:18,449 INFO:     None feature selector for col chem
2022-12-31 11:26:18,450 INFO:     None feature selector for col chem
2022-12-31 11:26:18,450 INFO:     None feature selector for col chem
2022-12-31 11:26:18,450 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 11:26:18,450 INFO:   Starting stage: BUILD MODEL
2022-12-31 11:26:18,452 INFO:     Number of params in model 223921
2022-12-31 11:26:18,455 INFO:   Done with stage: BUILD MODEL
2022-12-31 11:26:18,455 INFO:   Starting stage: TRAINING
2022-12-31 11:26:18,499 INFO:     Val loss before train {'Reaction outcome loss': 1.0236910422643026, 'Total loss': 1.0236910422643026}
2022-12-31 11:26:18,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:18,499 INFO:     Epoch: 0
2022-12-31 11:26:20,089 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6742664575576782, 'Total loss': 0.6742664575576782} | train loss {'Reaction outcome loss': 0.8067787689167064, 'Total loss': 0.8067787689167064}
2022-12-31 11:26:20,089 INFO:     Found new best model at epoch 0
2022-12-31 11:26:20,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:20,090 INFO:     Epoch: 1
2022-12-31 11:26:21,683 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5755479613939921, 'Total loss': 0.5755479613939921} | train loss {'Reaction outcome loss': 0.596122336092886, 'Total loss': 0.596122336092886}
2022-12-31 11:26:21,683 INFO:     Found new best model at epoch 1
2022-12-31 11:26:21,684 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:21,684 INFO:     Epoch: 2
2022-12-31 11:26:23,262 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5071912229061126, 'Total loss': 0.5071912229061126} | train loss {'Reaction outcome loss': 0.5360909614698354, 'Total loss': 0.5360909614698354}
2022-12-31 11:26:23,262 INFO:     Found new best model at epoch 2
2022-12-31 11:26:23,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:23,263 INFO:     Epoch: 3
2022-12-31 11:26:24,892 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5253341674804688, 'Total loss': 0.5253341674804688} | train loss {'Reaction outcome loss': 0.506778882154615, 'Total loss': 0.506778882154615}
2022-12-31 11:26:24,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:24,893 INFO:     Epoch: 4
2022-12-31 11:26:26,480 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5049027929703395, 'Total loss': 0.5049027929703395} | train loss {'Reaction outcome loss': 0.4978941019092287, 'Total loss': 0.4978941019092287}
2022-12-31 11:26:26,481 INFO:     Found new best model at epoch 4
2022-12-31 11:26:26,482 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:26,482 INFO:     Epoch: 5
2022-12-31 11:26:28,073 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45926933325827124, 'Total loss': 0.45926933325827124} | train loss {'Reaction outcome loss': 0.48519823042464344, 'Total loss': 0.48519823042464344}
2022-12-31 11:26:28,074 INFO:     Found new best model at epoch 5
2022-12-31 11:26:28,074 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:28,075 INFO:     Epoch: 6
2022-12-31 11:26:29,669 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5004639526208242, 'Total loss': 0.5004639526208242} | train loss {'Reaction outcome loss': 0.4789324901697837, 'Total loss': 0.4789324901697837}
2022-12-31 11:26:29,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:29,670 INFO:     Epoch: 7
2022-12-31 11:26:31,262 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4857029139995575, 'Total loss': 0.4857029139995575} | train loss {'Reaction outcome loss': 0.46976718060917905, 'Total loss': 0.46976718060917905}
2022-12-31 11:26:31,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:31,263 INFO:     Epoch: 8
2022-12-31 11:26:32,834 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.46264474987983706, 'Total loss': 0.46264474987983706} | train loss {'Reaction outcome loss': 0.4551758107357409, 'Total loss': 0.4551758107357409}
2022-12-31 11:26:32,835 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:32,835 INFO:     Epoch: 9
2022-12-31 11:26:34,424 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4739995022614797, 'Total loss': 0.4739995022614797} | train loss {'Reaction outcome loss': 0.45227125524492057, 'Total loss': 0.45227125524492057}
2022-12-31 11:26:34,424 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:34,424 INFO:     Epoch: 10
2022-12-31 11:26:36,014 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4969312995672226, 'Total loss': 0.4969312995672226} | train loss {'Reaction outcome loss': 0.44044765497083627, 'Total loss': 0.44044765497083627}
2022-12-31 11:26:36,014 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:36,014 INFO:     Epoch: 11
2022-12-31 11:26:37,605 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45184556518991786, 'Total loss': 0.45184556518991786} | train loss {'Reaction outcome loss': 0.4358663818229249, 'Total loss': 0.4358663818229249}
2022-12-31 11:26:37,605 INFO:     Found new best model at epoch 11
2022-12-31 11:26:37,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:37,606 INFO:     Epoch: 12
2022-12-31 11:26:39,200 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4693746864795685, 'Total loss': 0.4693746864795685} | train loss {'Reaction outcome loss': 0.4303362711226984, 'Total loss': 0.4303362711226984}
2022-12-31 11:26:39,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:39,200 INFO:     Epoch: 13
2022-12-31 11:26:40,825 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5006628612677256, 'Total loss': 0.5006628612677256} | train loss {'Reaction outcome loss': 0.4257100720108647, 'Total loss': 0.4257100720108647}
2022-12-31 11:26:40,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:40,825 INFO:     Epoch: 14
2022-12-31 11:26:42,427 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46949400305747985, 'Total loss': 0.46949400305747985} | train loss {'Reaction outcome loss': 0.42232058947776263, 'Total loss': 0.42232058947776263}
2022-12-31 11:26:42,427 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:42,427 INFO:     Epoch: 15
2022-12-31 11:26:44,027 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4363640248775482, 'Total loss': 0.4363640248775482} | train loss {'Reaction outcome loss': 0.41555173796066, 'Total loss': 0.41555173796066}
2022-12-31 11:26:44,027 INFO:     Found new best model at epoch 15
2022-12-31 11:26:44,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:44,028 INFO:     Epoch: 16
2022-12-31 11:26:45,654 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4392432530721029, 'Total loss': 0.4392432530721029} | train loss {'Reaction outcome loss': 0.40708465090928936, 'Total loss': 0.40708465090928936}
2022-12-31 11:26:45,654 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:45,655 INFO:     Epoch: 17
2022-12-31 11:26:47,278 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46195857524871825, 'Total loss': 0.46195857524871825} | train loss {'Reaction outcome loss': 0.4024825080983586, 'Total loss': 0.4024825080983586}
2022-12-31 11:26:47,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:47,278 INFO:     Epoch: 18
2022-12-31 11:26:48,903 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4279386659463247, 'Total loss': 0.4279386659463247} | train loss {'Reaction outcome loss': 0.39042318705128226, 'Total loss': 0.39042318705128226}
2022-12-31 11:26:48,903 INFO:     Found new best model at epoch 18
2022-12-31 11:26:48,904 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:48,904 INFO:     Epoch: 19
2022-12-31 11:26:50,505 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45132819016774495, 'Total loss': 0.45132819016774495} | train loss {'Reaction outcome loss': 0.387418164349683, 'Total loss': 0.387418164349683}
2022-12-31 11:26:50,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:50,505 INFO:     Epoch: 20
2022-12-31 11:26:52,116 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.478323370218277, 'Total loss': 0.478323370218277} | train loss {'Reaction outcome loss': 0.3844958292695629, 'Total loss': 0.3844958292695629}
2022-12-31 11:26:52,116 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:52,116 INFO:     Epoch: 21
2022-12-31 11:26:53,722 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.49845942060152687, 'Total loss': 0.49845942060152687} | train loss {'Reaction outcome loss': 0.38298018516856674, 'Total loss': 0.38298018516856674}
2022-12-31 11:26:53,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:53,722 INFO:     Epoch: 22
2022-12-31 11:26:55,341 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5083771189053853, 'Total loss': 0.5083771189053853} | train loss {'Reaction outcome loss': 0.3733221540302584, 'Total loss': 0.3733221540302584}
2022-12-31 11:26:55,342 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:55,342 INFO:     Epoch: 23
2022-12-31 11:26:56,967 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43524072766304017, 'Total loss': 0.43524072766304017} | train loss {'Reaction outcome loss': 0.3696971004862925, 'Total loss': 0.3696971004862925}
2022-12-31 11:26:56,968 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:56,968 INFO:     Epoch: 24
2022-12-31 11:26:58,590 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4366413573424021, 'Total loss': 0.4366413573424021} | train loss {'Reaction outcome loss': 0.36524845081152935, 'Total loss': 0.36524845081152935}
2022-12-31 11:26:58,590 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:26:58,590 INFO:     Epoch: 25
2022-12-31 11:27:00,185 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4637382427851359, 'Total loss': 0.4637382427851359} | train loss {'Reaction outcome loss': 0.365832688976011, 'Total loss': 0.365832688976011}
2022-12-31 11:27:00,185 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:00,185 INFO:     Epoch: 26
2022-12-31 11:27:01,811 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42059036791324617, 'Total loss': 0.42059036791324617} | train loss {'Reaction outcome loss': 0.3531332391522306, 'Total loss': 0.3531332391522306}
2022-12-31 11:27:01,812 INFO:     Found new best model at epoch 26
2022-12-31 11:27:01,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:01,812 INFO:     Epoch: 27
2022-12-31 11:27:03,411 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.44357582926750183, 'Total loss': 0.44357582926750183} | train loss {'Reaction outcome loss': 0.3443405167523758, 'Total loss': 0.3443405167523758}
2022-12-31 11:27:03,411 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:03,411 INFO:     Epoch: 28
2022-12-31 11:27:05,033 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41932224730650586, 'Total loss': 0.41932224730650586} | train loss {'Reaction outcome loss': 0.34773897851779784, 'Total loss': 0.34773897851779784}
2022-12-31 11:27:05,033 INFO:     Found new best model at epoch 28
2022-12-31 11:27:05,034 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:05,034 INFO:     Epoch: 29
2022-12-31 11:27:06,673 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.43556320865948994, 'Total loss': 0.43556320865948994} | train loss {'Reaction outcome loss': 0.3431447165789622, 'Total loss': 0.3431447165789622}
2022-12-31 11:27:06,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:06,674 INFO:     Epoch: 30
2022-12-31 11:27:08,300 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.448456468184789, 'Total loss': 0.448456468184789} | train loss {'Reaction outcome loss': 0.33273622671981434, 'Total loss': 0.33273622671981434}
2022-12-31 11:27:08,300 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:08,301 INFO:     Epoch: 31
2022-12-31 11:27:09,897 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4428343027830124, 'Total loss': 0.4428343027830124} | train loss {'Reaction outcome loss': 0.3314744830677361, 'Total loss': 0.3314744830677361}
2022-12-31 11:27:09,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:09,897 INFO:     Epoch: 32
2022-12-31 11:27:11,468 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.38911127547423047, 'Total loss': 0.38911127547423047} | train loss {'Reaction outcome loss': 0.3260299557676682, 'Total loss': 0.3260299557676682}
2022-12-31 11:27:11,468 INFO:     Found new best model at epoch 32
2022-12-31 11:27:11,469 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:11,469 INFO:     Epoch: 33
2022-12-31 11:27:13,112 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41384954849878947, 'Total loss': 0.41384954849878947} | train loss {'Reaction outcome loss': 0.315694527338931, 'Total loss': 0.315694527338931}
2022-12-31 11:27:13,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:13,113 INFO:     Epoch: 34
2022-12-31 11:27:14,703 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4249157220125198, 'Total loss': 0.4249157220125198} | train loss {'Reaction outcome loss': 0.3198402325312297, 'Total loss': 0.3198402325312297}
2022-12-31 11:27:14,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:14,704 INFO:     Epoch: 35
2022-12-31 11:27:16,291 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41062199473381045, 'Total loss': 0.41062199473381045} | train loss {'Reaction outcome loss': 0.3107810083763067, 'Total loss': 0.3107810083763067}
2022-12-31 11:27:16,292 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:16,292 INFO:     Epoch: 36
2022-12-31 11:27:17,865 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40304917891820274, 'Total loss': 0.40304917891820274} | train loss {'Reaction outcome loss': 0.31184824270916073, 'Total loss': 0.31184824270916073}
2022-12-31 11:27:17,866 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:17,866 INFO:     Epoch: 37
2022-12-31 11:27:19,452 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41227230727672576, 'Total loss': 0.41227230727672576} | train loss {'Reaction outcome loss': 0.3063189858509289, 'Total loss': 0.3063189858509289}
2022-12-31 11:27:19,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:19,453 INFO:     Epoch: 38
2022-12-31 11:27:21,032 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3870274563630422, 'Total loss': 0.3870274563630422} | train loss {'Reaction outcome loss': 0.3016279953712727, 'Total loss': 0.3016279953712727}
2022-12-31 11:27:21,032 INFO:     Found new best model at epoch 38
2022-12-31 11:27:21,033 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:21,033 INFO:     Epoch: 39
2022-12-31 11:27:22,620 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.394928706685702, 'Total loss': 0.394928706685702} | train loss {'Reaction outcome loss': 0.29670754974305413, 'Total loss': 0.29670754974305413}
2022-12-31 11:27:22,620 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:22,620 INFO:     Epoch: 40
2022-12-31 11:27:24,207 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4277458777030309, 'Total loss': 0.4277458777030309} | train loss {'Reaction outcome loss': 0.2975353524498232, 'Total loss': 0.2975353524498232}
2022-12-31 11:27:24,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:24,207 INFO:     Epoch: 41
2022-12-31 11:27:25,795 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4010732779900233, 'Total loss': 0.4010732779900233} | train loss {'Reaction outcome loss': 0.29718900540154497, 'Total loss': 0.29718900540154497}
2022-12-31 11:27:25,795 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:25,796 INFO:     Epoch: 42
2022-12-31 11:27:27,371 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3959601491689682, 'Total loss': 0.3959601491689682} | train loss {'Reaction outcome loss': 0.29124082960597764, 'Total loss': 0.29124082960597764}
2022-12-31 11:27:27,371 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:27,371 INFO:     Epoch: 43
2022-12-31 11:27:28,959 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40387556155522664, 'Total loss': 0.40387556155522664} | train loss {'Reaction outcome loss': 0.2891536185265461, 'Total loss': 0.2891536185265461}
2022-12-31 11:27:28,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:28,959 INFO:     Epoch: 44
2022-12-31 11:27:30,538 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43905187050501504, 'Total loss': 0.43905187050501504} | train loss {'Reaction outcome loss': 0.2911706378908603, 'Total loss': 0.2911706378908603}
2022-12-31 11:27:30,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:30,539 INFO:     Epoch: 45
2022-12-31 11:27:32,128 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4729308903217316, 'Total loss': 0.4729308903217316} | train loss {'Reaction outcome loss': 0.2800127215403722, 'Total loss': 0.2800127215403722}
2022-12-31 11:27:32,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:32,128 INFO:     Epoch: 46
2022-12-31 11:27:33,714 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4179779539505641, 'Total loss': 0.4179779539505641} | train loss {'Reaction outcome loss': 0.27710035512899306, 'Total loss': 0.27710035512899306}
2022-12-31 11:27:33,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:33,715 INFO:     Epoch: 47
2022-12-31 11:27:35,297 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3820609147349993, 'Total loss': 0.3820609147349993} | train loss {'Reaction outcome loss': 0.27575423298301277, 'Total loss': 0.27575423298301277}
2022-12-31 11:27:35,297 INFO:     Found new best model at epoch 47
2022-12-31 11:27:35,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:35,298 INFO:     Epoch: 48
2022-12-31 11:27:36,899 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4354835162560145, 'Total loss': 0.4354835162560145} | train loss {'Reaction outcome loss': 0.2724203461501406, 'Total loss': 0.2724203461501406}
2022-12-31 11:27:36,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:36,900 INFO:     Epoch: 49
2022-12-31 11:27:38,489 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4492509086926778, 'Total loss': 0.4492509086926778} | train loss {'Reaction outcome loss': 0.277929448130312, 'Total loss': 0.277929448130312}
2022-12-31 11:27:38,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:38,489 INFO:     Epoch: 50
2022-12-31 11:27:40,135 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41515061457951863, 'Total loss': 0.41515061457951863} | train loss {'Reaction outcome loss': 0.2733858463801307, 'Total loss': 0.2733858463801307}
2022-12-31 11:27:40,135 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:40,136 INFO:     Epoch: 51
2022-12-31 11:27:41,752 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3959151924898227, 'Total loss': 0.3959151924898227} | train loss {'Reaction outcome loss': 0.26321747431006187, 'Total loss': 0.26321747431006187}
2022-12-31 11:27:41,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:41,752 INFO:     Epoch: 52
2022-12-31 11:27:43,339 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.393059362967809, 'Total loss': 0.393059362967809} | train loss {'Reaction outcome loss': 0.2645798857859421, 'Total loss': 0.2645798857859421}
2022-12-31 11:27:43,339 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:43,339 INFO:     Epoch: 53
2022-12-31 11:27:44,921 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3938280979792277, 'Total loss': 0.3938280979792277} | train loss {'Reaction outcome loss': 0.2612279053818394, 'Total loss': 0.2612279053818394}
2022-12-31 11:27:44,921 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:44,921 INFO:     Epoch: 54
2022-12-31 11:27:46,538 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45609366993109385, 'Total loss': 0.45609366993109385} | train loss {'Reaction outcome loss': 0.2607966678510437, 'Total loss': 0.2607966678510437}
2022-12-31 11:27:46,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:46,538 INFO:     Epoch: 55
2022-12-31 11:27:48,137 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42756454745928446, 'Total loss': 0.42756454745928446} | train loss {'Reaction outcome loss': 0.26065141321483987, 'Total loss': 0.26065141321483987}
2022-12-31 11:27:48,137 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:48,137 INFO:     Epoch: 56
2022-12-31 11:27:49,767 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3929014205932617, 'Total loss': 0.3929014205932617} | train loss {'Reaction outcome loss': 0.25889157270500945, 'Total loss': 0.25889157270500945}
2022-12-31 11:27:49,767 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:49,768 INFO:     Epoch: 57
2022-12-31 11:27:51,399 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42667640646298727, 'Total loss': 0.42667640646298727} | train loss {'Reaction outcome loss': 0.2534889440314892, 'Total loss': 0.2534889440314892}
2022-12-31 11:27:51,399 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:51,399 INFO:     Epoch: 58
2022-12-31 11:27:53,028 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4268174474438032, 'Total loss': 0.4268174474438032} | train loss {'Reaction outcome loss': 0.25502738873764275, 'Total loss': 0.25502738873764275}
2022-12-31 11:27:53,029 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:53,029 INFO:     Epoch: 59
2022-12-31 11:27:54,629 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4398151606321335, 'Total loss': 0.4398151606321335} | train loss {'Reaction outcome loss': 0.24847202778080882, 'Total loss': 0.24847202778080882}
2022-12-31 11:27:54,629 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:54,629 INFO:     Epoch: 60
2022-12-31 11:27:56,222 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3937388569116592, 'Total loss': 0.3937388569116592} | train loss {'Reaction outcome loss': 0.2449708811311058, 'Total loss': 0.2449708811311058}
2022-12-31 11:27:56,222 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:56,223 INFO:     Epoch: 61
2022-12-31 11:27:57,809 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4081780950228373, 'Total loss': 0.4081780950228373} | train loss {'Reaction outcome loss': 0.25434053718579774, 'Total loss': 0.25434053718579774}
2022-12-31 11:27:57,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:57,809 INFO:     Epoch: 62
2022-12-31 11:27:59,395 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42205782532691954, 'Total loss': 0.42205782532691954} | train loss {'Reaction outcome loss': 0.2401582322803227, 'Total loss': 0.2401582322803227}
2022-12-31 11:27:59,395 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:27:59,395 INFO:     Epoch: 63
2022-12-31 11:28:00,981 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40628642241160073, 'Total loss': 0.40628642241160073} | train loss {'Reaction outcome loss': 0.24306914998361698, 'Total loss': 0.24306914998361698}
2022-12-31 11:28:00,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:00,981 INFO:     Epoch: 64
2022-12-31 11:28:02,560 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41551519334316256, 'Total loss': 0.41551519334316256} | train loss {'Reaction outcome loss': 0.23925696307922895, 'Total loss': 0.23925696307922895}
2022-12-31 11:28:02,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:02,560 INFO:     Epoch: 65
2022-12-31 11:28:04,138 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4188943386077881, 'Total loss': 0.4188943386077881} | train loss {'Reaction outcome loss': 0.24191571860113642, 'Total loss': 0.24191571860113642}
2022-12-31 11:28:04,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:04,138 INFO:     Epoch: 66
2022-12-31 11:28:05,708 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4482318421204885, 'Total loss': 0.4482318421204885} | train loss {'Reaction outcome loss': 0.243128172261811, 'Total loss': 0.243128172261811}
2022-12-31 11:28:05,708 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:05,708 INFO:     Epoch: 67
2022-12-31 11:28:07,294 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42212486068407695, 'Total loss': 0.42212486068407695} | train loss {'Reaction outcome loss': 0.23829951992892956, 'Total loss': 0.23829951992892956}
2022-12-31 11:28:07,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:07,294 INFO:     Epoch: 68
2022-12-31 11:28:08,879 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4247084220250448, 'Total loss': 0.4247084220250448} | train loss {'Reaction outcome loss': 0.24549761709958423, 'Total loss': 0.24549761709958423}
2022-12-31 11:28:08,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:08,880 INFO:     Epoch: 69
2022-12-31 11:28:10,465 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.41105314195156095, 'Total loss': 0.41105314195156095} | train loss {'Reaction outcome loss': 0.24087532305400886, 'Total loss': 0.24087532305400886}
2022-12-31 11:28:10,465 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:10,465 INFO:     Epoch: 70
2022-12-31 11:28:12,040 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42222245236237843, 'Total loss': 0.42222245236237843} | train loss {'Reaction outcome loss': 0.23118771077730718, 'Total loss': 0.23118771077730718}
2022-12-31 11:28:12,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:12,040 INFO:     Epoch: 71
2022-12-31 11:28:13,624 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41083548267682396, 'Total loss': 0.41083548267682396} | train loss {'Reaction outcome loss': 0.236076888324686, 'Total loss': 0.236076888324686}
2022-12-31 11:28:13,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:13,624 INFO:     Epoch: 72
2022-12-31 11:28:15,207 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41644572019577025, 'Total loss': 0.41644572019577025} | train loss {'Reaction outcome loss': 0.22668330303151094, 'Total loss': 0.22668330303151094}
2022-12-31 11:28:15,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:15,208 INFO:     Epoch: 73
2022-12-31 11:28:16,807 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42923691670099895, 'Total loss': 0.42923691670099895} | train loss {'Reaction outcome loss': 0.2316881977635753, 'Total loss': 0.2316881977635753}
2022-12-31 11:28:16,807 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:16,807 INFO:     Epoch: 74
2022-12-31 11:28:18,438 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4177354395389557, 'Total loss': 0.4177354395389557} | train loss {'Reaction outcome loss': 0.23056364295946183, 'Total loss': 0.23056364295946183}
2022-12-31 11:28:18,438 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:18,438 INFO:     Epoch: 75
2022-12-31 11:28:20,061 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4134739364186923, 'Total loss': 0.4134739364186923} | train loss {'Reaction outcome loss': 0.22691906740268072, 'Total loss': 0.22691906740268072}
2022-12-31 11:28:20,061 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:20,061 INFO:     Epoch: 76
2022-12-31 11:28:21,650 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41978966295719145, 'Total loss': 0.41978966295719145} | train loss {'Reaction outcome loss': 0.2470175461526346, 'Total loss': 0.2470175461526346}
2022-12-31 11:28:21,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:21,650 INFO:     Epoch: 77
2022-12-31 11:28:23,243 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.44462889631589253, 'Total loss': 0.44462889631589253} | train loss {'Reaction outcome loss': 0.23302865530545022, 'Total loss': 0.23302865530545022}
2022-12-31 11:28:23,243 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:23,243 INFO:     Epoch: 78
2022-12-31 11:28:24,839 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41389682491620383, 'Total loss': 0.41389682491620383} | train loss {'Reaction outcome loss': 0.22711998390438096, 'Total loss': 0.22711998390438096}
2022-12-31 11:28:24,840 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:24,840 INFO:     Epoch: 79
2022-12-31 11:28:26,474 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4331600785255432, 'Total loss': 0.4331600785255432} | train loss {'Reaction outcome loss': 0.22534947411836068, 'Total loss': 0.22534947411836068}
2022-12-31 11:28:26,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:26,474 INFO:     Epoch: 80
2022-12-31 11:28:28,106 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4088488457724452, 'Total loss': 0.4088488457724452} | train loss {'Reaction outcome loss': 0.22829165130567092, 'Total loss': 0.22829165130567092}
2022-12-31 11:28:28,106 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:28,107 INFO:     Epoch: 81
2022-12-31 11:28:29,728 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4685940474271774, 'Total loss': 0.4685940474271774} | train loss {'Reaction outcome loss': 0.22137104121169873, 'Total loss': 0.22137104121169873}
2022-12-31 11:28:29,729 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:29,729 INFO:     Epoch: 82
2022-12-31 11:28:31,318 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4024948348601659, 'Total loss': 0.4024948348601659} | train loss {'Reaction outcome loss': 0.21997636341022483, 'Total loss': 0.21997636341022483}
2022-12-31 11:28:31,318 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:31,318 INFO:     Epoch: 83
2022-12-31 11:28:32,894 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.39502714276313783, 'Total loss': 0.39502714276313783} | train loss {'Reaction outcome loss': 0.22615810283101523, 'Total loss': 0.22615810283101523}
2022-12-31 11:28:32,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:32,894 INFO:     Epoch: 84
2022-12-31 11:28:34,532 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4105156635244687, 'Total loss': 0.4105156635244687} | train loss {'Reaction outcome loss': 0.22167012444782608, 'Total loss': 0.22167012444782608}
2022-12-31 11:28:34,532 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:34,533 INFO:     Epoch: 85
2022-12-31 11:28:36,168 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4187494993209839, 'Total loss': 0.4187494993209839} | train loss {'Reaction outcome loss': 0.22632457060746222, 'Total loss': 0.22632457060746222}
2022-12-31 11:28:36,168 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:36,168 INFO:     Epoch: 86
2022-12-31 11:28:37,766 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42340401113033294, 'Total loss': 0.42340401113033294} | train loss {'Reaction outcome loss': 0.22821760832096685, 'Total loss': 0.22821760832096685}
2022-12-31 11:28:37,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:37,766 INFO:     Epoch: 87
2022-12-31 11:28:39,354 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41298081576824186, 'Total loss': 0.41298081576824186} | train loss {'Reaction outcome loss': 0.2151326702723464, 'Total loss': 0.2151326702723464}
2022-12-31 11:28:39,355 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:39,355 INFO:     Epoch: 88
2022-12-31 11:28:40,946 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.390638264020284, 'Total loss': 0.390638264020284} | train loss {'Reaction outcome loss': 0.22241543437569186, 'Total loss': 0.22241543437569186}
2022-12-31 11:28:40,946 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:40,946 INFO:     Epoch: 89
2022-12-31 11:28:42,524 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4244687626759211, 'Total loss': 0.4244687626759211} | train loss {'Reaction outcome loss': 0.21708138411243758, 'Total loss': 0.21708138411243758}
2022-12-31 11:28:42,525 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:42,525 INFO:     Epoch: 90
2022-12-31 11:28:44,126 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.442692173520724, 'Total loss': 0.442692173520724} | train loss {'Reaction outcome loss': 0.22514287930923504, 'Total loss': 0.22514287930923504}
2022-12-31 11:28:44,127 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:44,127 INFO:     Epoch: 91
2022-12-31 11:28:45,730 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3904071057836215, 'Total loss': 0.3904071057836215} | train loss {'Reaction outcome loss': 0.21311880939472944, 'Total loss': 0.21311880939472944}
2022-12-31 11:28:45,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:45,731 INFO:     Epoch: 92
2022-12-31 11:28:47,327 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4567403415838877, 'Total loss': 0.4567403415838877} | train loss {'Reaction outcome loss': 0.21153181030896012, 'Total loss': 0.21153181030896012}
2022-12-31 11:28:47,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:47,327 INFO:     Epoch: 93
2022-12-31 11:28:48,905 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4036897470553716, 'Total loss': 0.4036897470553716} | train loss {'Reaction outcome loss': 0.2120780851316703, 'Total loss': 0.2120780851316703}
2022-12-31 11:28:48,905 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:48,905 INFO:     Epoch: 94
2022-12-31 11:28:50,498 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41395679066578545, 'Total loss': 0.41395679066578545} | train loss {'Reaction outcome loss': 0.21103114379235569, 'Total loss': 0.21103114379235569}
2022-12-31 11:28:50,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:50,498 INFO:     Epoch: 95
2022-12-31 11:28:52,111 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.406365168094635, 'Total loss': 0.406365168094635} | train loss {'Reaction outcome loss': 0.2066372530125491, 'Total loss': 0.2066372530125491}
2022-12-31 11:28:52,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:52,112 INFO:     Epoch: 96
2022-12-31 11:28:53,735 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4589546432097753, 'Total loss': 0.4589546432097753} | train loss {'Reaction outcome loss': 0.21215409403769198, 'Total loss': 0.21215409403769198}
2022-12-31 11:28:53,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:53,736 INFO:     Epoch: 97
2022-12-31 11:28:55,359 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43271236220995585, 'Total loss': 0.43271236220995585} | train loss {'Reaction outcome loss': 0.20169294225017884, 'Total loss': 0.20169294225017884}
2022-12-31 11:28:55,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:55,359 INFO:     Epoch: 98
2022-12-31 11:28:56,938 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4446475863456726, 'Total loss': 0.4446475863456726} | train loss {'Reaction outcome loss': 0.21212429060999835, 'Total loss': 0.21212429060999835}
2022-12-31 11:28:56,938 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:56,938 INFO:     Epoch: 99
2022-12-31 11:28:58,526 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4026004562775294, 'Total loss': 0.4026004562775294} | train loss {'Reaction outcome loss': 0.20850947733982142, 'Total loss': 0.20850947733982142}
2022-12-31 11:28:58,527 INFO:     Best model found after epoch 48 of 100.
2022-12-31 11:28:58,527 INFO:   Done with stage: TRAINING
2022-12-31 11:28:58,527 INFO:   Starting stage: EVALUATION
2022-12-31 11:28:58,666 INFO:   Done with stage: EVALUATION
2022-12-31 11:28:58,667 INFO:   Leaving out SEQ value Fold_4
2022-12-31 11:28:58,679 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 11:28:58,679 INFO:   Starting stage: FEATURE SCALING
2022-12-31 11:28:59,328 INFO:   Done with stage: FEATURE SCALING
2022-12-31 11:28:59,328 INFO:   Starting stage: SCALING TARGETS
2022-12-31 11:28:59,398 INFO:   Done with stage: SCALING TARGETS
2022-12-31 11:28:59,398 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:28:59,398 INFO:     No hyperparam tuning for this model
2022-12-31 11:28:59,398 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:28:59,398 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 11:28:59,399 INFO:     None feature selector for col prot
2022-12-31 11:28:59,399 INFO:     None feature selector for col prot
2022-12-31 11:28:59,399 INFO:     None feature selector for col prot
2022-12-31 11:28:59,400 INFO:     None feature selector for col chem
2022-12-31 11:28:59,400 INFO:     None feature selector for col chem
2022-12-31 11:28:59,400 INFO:     None feature selector for col chem
2022-12-31 11:28:59,400 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 11:28:59,400 INFO:   Starting stage: BUILD MODEL
2022-12-31 11:28:59,402 INFO:     Number of params in model 223921
2022-12-31 11:28:59,405 INFO:   Done with stage: BUILD MODEL
2022-12-31 11:28:59,405 INFO:   Starting stage: TRAINING
2022-12-31 11:28:59,449 INFO:     Val loss before train {'Reaction outcome loss': 0.9778466860453288, 'Total loss': 0.9778466860453288}
2022-12-31 11:28:59,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:28:59,449 INFO:     Epoch: 0
2022-12-31 11:29:01,048 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6905486365159352, 'Total loss': 0.6905486365159352} | train loss {'Reaction outcome loss': 0.8152886949499826, 'Total loss': 0.8152886949499826}
2022-12-31 11:29:01,048 INFO:     Found new best model at epoch 0
2022-12-31 11:29:01,049 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:01,049 INFO:     Epoch: 1
2022-12-31 11:29:02,658 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5493493348360061, 'Total loss': 0.5493493348360061} | train loss {'Reaction outcome loss': 0.6194178582965464, 'Total loss': 0.6194178582965464}
2022-12-31 11:29:02,658 INFO:     Found new best model at epoch 1
2022-12-31 11:29:02,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:02,659 INFO:     Epoch: 2
2022-12-31 11:29:04,269 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5134282827377319, 'Total loss': 0.5134282827377319} | train loss {'Reaction outcome loss': 0.5368948498929756, 'Total loss': 0.5368948498929756}
2022-12-31 11:29:04,269 INFO:     Found new best model at epoch 2
2022-12-31 11:29:04,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:04,270 INFO:     Epoch: 3
2022-12-31 11:29:05,859 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4908248245716095, 'Total loss': 0.4908248245716095} | train loss {'Reaction outcome loss': 0.5313886142052386, 'Total loss': 0.5313886142052386}
2022-12-31 11:29:05,860 INFO:     Found new best model at epoch 3
2022-12-31 11:29:05,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:05,861 INFO:     Epoch: 4
2022-12-31 11:29:07,494 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5186423261960348, 'Total loss': 0.5186423261960348} | train loss {'Reaction outcome loss': 0.4861589772761732, 'Total loss': 0.4861589772761732}
2022-12-31 11:29:07,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:07,495 INFO:     Epoch: 5
2022-12-31 11:29:09,091 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4887660135825475, 'Total loss': 0.4887660135825475} | train loss {'Reaction outcome loss': 0.4804146109837229, 'Total loss': 0.4804146109837229}
2022-12-31 11:29:09,091 INFO:     Found new best model at epoch 5
2022-12-31 11:29:09,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:09,092 INFO:     Epoch: 6
2022-12-31 11:29:10,711 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4505861947933833, 'Total loss': 0.4505861947933833} | train loss {'Reaction outcome loss': 0.4611787008287375, 'Total loss': 0.4611787008287375}
2022-12-31 11:29:10,712 INFO:     Found new best model at epoch 6
2022-12-31 11:29:10,713 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:10,713 INFO:     Epoch: 7
2022-12-31 11:29:12,324 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4671883632739385, 'Total loss': 0.4671883632739385} | train loss {'Reaction outcome loss': 0.4559043121011253, 'Total loss': 0.4559043121011253}
2022-12-31 11:29:12,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:12,325 INFO:     Epoch: 8
2022-12-31 11:29:13,980 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45631458759307864, 'Total loss': 0.45631458759307864} | train loss {'Reaction outcome loss': 0.4573268552405247, 'Total loss': 0.4573268552405247}
2022-12-31 11:29:13,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:13,981 INFO:     Epoch: 9
2022-12-31 11:29:15,602 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4425564448038737, 'Total loss': 0.4425564448038737} | train loss {'Reaction outcome loss': 0.45039383722937404, 'Total loss': 0.45039383722937404}
2022-12-31 11:29:15,602 INFO:     Found new best model at epoch 9
2022-12-31 11:29:15,603 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:15,603 INFO:     Epoch: 10
2022-12-31 11:29:17,254 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4520959715048472, 'Total loss': 0.4520959715048472} | train loss {'Reaction outcome loss': 0.4355459593411913, 'Total loss': 0.4355459593411913}
2022-12-31 11:29:17,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:17,255 INFO:     Epoch: 11
2022-12-31 11:29:18,849 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4879863391319911, 'Total loss': 0.4879863391319911} | train loss {'Reaction outcome loss': 0.44727072300578374, 'Total loss': 0.44727072300578374}
2022-12-31 11:29:18,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:18,849 INFO:     Epoch: 12
2022-12-31 11:29:20,451 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4537607173124949, 'Total loss': 0.4537607173124949} | train loss {'Reaction outcome loss': 0.47188206686489825, 'Total loss': 0.47188206686489825}
2022-12-31 11:29:20,451 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:20,451 INFO:     Epoch: 13
2022-12-31 11:29:22,084 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4220625768105189, 'Total loss': 0.4220625768105189} | train loss {'Reaction outcome loss': 0.43139365987609263, 'Total loss': 0.43139365987609263}
2022-12-31 11:29:22,084 INFO:     Found new best model at epoch 13
2022-12-31 11:29:22,085 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:22,085 INFO:     Epoch: 14
2022-12-31 11:29:23,738 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.450415043036143, 'Total loss': 0.450415043036143} | train loss {'Reaction outcome loss': 0.42540458638382994, 'Total loss': 0.42540458638382994}
2022-12-31 11:29:23,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:23,738 INFO:     Epoch: 15
2022-12-31 11:29:25,332 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44694376985232037, 'Total loss': 0.44694376985232037} | train loss {'Reaction outcome loss': 0.43922167595313943, 'Total loss': 0.43922167595313943}
2022-12-31 11:29:25,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:25,332 INFO:     Epoch: 16
2022-12-31 11:29:26,926 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44992550313472746, 'Total loss': 0.44992550313472746} | train loss {'Reaction outcome loss': 0.4133070477491592, 'Total loss': 0.4133070477491592}
2022-12-31 11:29:26,926 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:26,926 INFO:     Epoch: 17
2022-12-31 11:29:28,524 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42947925130526227, 'Total loss': 0.42947925130526227} | train loss {'Reaction outcome loss': 0.4027422300296957, 'Total loss': 0.4027422300296957}
2022-12-31 11:29:28,524 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:28,524 INFO:     Epoch: 18
2022-12-31 11:29:30,127 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4563910484313965, 'Total loss': 0.4563910484313965} | train loss {'Reaction outcome loss': 0.4001772830505734, 'Total loss': 0.4001772830505734}
2022-12-31 11:29:30,128 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:30,128 INFO:     Epoch: 19
2022-12-31 11:29:31,733 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.42984607120354973, 'Total loss': 0.42984607120354973} | train loss {'Reaction outcome loss': 0.42212748516728915, 'Total loss': 0.42212748516728915}
2022-12-31 11:29:31,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:31,733 INFO:     Epoch: 20
2022-12-31 11:29:33,329 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.42225989898045857, 'Total loss': 0.42225989898045857} | train loss {'Reaction outcome loss': 0.40186066121078917, 'Total loss': 0.40186066121078917}
2022-12-31 11:29:33,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:33,330 INFO:     Epoch: 21
2022-12-31 11:29:34,932 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40772687196731566, 'Total loss': 0.40772687196731566} | train loss {'Reaction outcome loss': 0.3880979217235332, 'Total loss': 0.3880979217235332}
2022-12-31 11:29:34,932 INFO:     Found new best model at epoch 21
2022-12-31 11:29:34,933 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:34,933 INFO:     Epoch: 22
2022-12-31 11:29:36,525 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.420468141635259, 'Total loss': 0.420468141635259} | train loss {'Reaction outcome loss': 0.3771057727527754, 'Total loss': 0.3771057727527754}
2022-12-31 11:29:36,526 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:36,526 INFO:     Epoch: 23
2022-12-31 11:29:38,148 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4358991285165151, 'Total loss': 0.4358991285165151} | train loss {'Reaction outcome loss': 0.3904658639938503, 'Total loss': 0.3904658639938503}
2022-12-31 11:29:38,148 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:38,148 INFO:     Epoch: 24
2022-12-31 11:29:39,757 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.448067565759023, 'Total loss': 0.448067565759023} | train loss {'Reaction outcome loss': 0.4050607752097953, 'Total loss': 0.4050607752097953}
2022-12-31 11:29:39,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:39,757 INFO:     Epoch: 25
2022-12-31 11:29:41,366 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5044356604417165, 'Total loss': 0.5044356604417165} | train loss {'Reaction outcome loss': 0.3798766599941081, 'Total loss': 0.3798766599941081}
2022-12-31 11:29:41,367 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:41,368 INFO:     Epoch: 26
2022-12-31 11:29:42,970 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44278907775878906, 'Total loss': 0.44278907775878906} | train loss {'Reaction outcome loss': 0.4044910090826992, 'Total loss': 0.4044910090826992}
2022-12-31 11:29:42,970 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:42,970 INFO:     Epoch: 27
2022-12-31 11:29:44,579 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4070515046517054, 'Total loss': 0.4070515046517054} | train loss {'Reaction outcome loss': 0.37039203057065606, 'Total loss': 0.37039203057065606}
2022-12-31 11:29:44,579 INFO:     Found new best model at epoch 27
2022-12-31 11:29:44,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:44,580 INFO:     Epoch: 28
2022-12-31 11:29:46,170 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.39459116756916046, 'Total loss': 0.39459116756916046} | train loss {'Reaction outcome loss': 0.3626076965963981, 'Total loss': 0.3626076965963981}
2022-12-31 11:29:46,170 INFO:     Found new best model at epoch 28
2022-12-31 11:29:46,171 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:46,171 INFO:     Epoch: 29
2022-12-31 11:29:47,779 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3930545101563136, 'Total loss': 0.3930545101563136} | train loss {'Reaction outcome loss': 0.3529228060607515, 'Total loss': 0.3529228060607515}
2022-12-31 11:29:47,780 INFO:     Found new best model at epoch 29
2022-12-31 11:29:47,781 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:47,781 INFO:     Epoch: 30
2022-12-31 11:29:49,388 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4263204832871755, 'Total loss': 0.4263204832871755} | train loss {'Reaction outcome loss': 0.3538262111445268, 'Total loss': 0.3538262111445268}
2022-12-31 11:29:49,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:49,388 INFO:     Epoch: 31
2022-12-31 11:29:50,985 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43200347224871316, 'Total loss': 0.43200347224871316} | train loss {'Reaction outcome loss': 0.35014802503629006, 'Total loss': 0.35014802503629006}
2022-12-31 11:29:50,985 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:50,985 INFO:     Epoch: 32
2022-12-31 11:29:52,597 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42115165293216705, 'Total loss': 0.42115165293216705} | train loss {'Reaction outcome loss': 0.34113754500994337, 'Total loss': 0.34113754500994337}
2022-12-31 11:29:52,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:52,597 INFO:     Epoch: 33
2022-12-31 11:29:54,186 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3836501434445381, 'Total loss': 0.3836501434445381} | train loss {'Reaction outcome loss': 0.34046761392222624, 'Total loss': 0.34046761392222624}
2022-12-31 11:29:54,186 INFO:     Found new best model at epoch 33
2022-12-31 11:29:54,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:54,187 INFO:     Epoch: 34
2022-12-31 11:29:55,817 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4463939319054286, 'Total loss': 0.4463939319054286} | train loss {'Reaction outcome loss': 0.34362178273579996, 'Total loss': 0.34362178273579996}
2022-12-31 11:29:55,817 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:55,817 INFO:     Epoch: 35
2022-12-31 11:29:57,455 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.40906113187472026, 'Total loss': 0.40906113187472026} | train loss {'Reaction outcome loss': 0.33343891924707114, 'Total loss': 0.33343891924707114}
2022-12-31 11:29:57,455 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:57,455 INFO:     Epoch: 36
2022-12-31 11:29:59,064 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4377848337093989, 'Total loss': 0.4377848337093989} | train loss {'Reaction outcome loss': 0.3328858686314113, 'Total loss': 0.3328858686314113}
2022-12-31 11:29:59,064 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:29:59,064 INFO:     Epoch: 37
2022-12-31 11:30:00,673 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42554788092772167, 'Total loss': 0.42554788092772167} | train loss {'Reaction outcome loss': 0.3398432943538047, 'Total loss': 0.3398432943538047}
2022-12-31 11:30:00,673 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:00,673 INFO:     Epoch: 38
2022-12-31 11:30:02,311 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41174076199531556, 'Total loss': 0.41174076199531556} | train loss {'Reaction outcome loss': 0.33632278146504413, 'Total loss': 0.33632278146504413}
2022-12-31 11:30:02,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:02,311 INFO:     Epoch: 39
2022-12-31 11:30:03,919 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40903478463490806, 'Total loss': 0.40903478463490806} | train loss {'Reaction outcome loss': 0.3261993876827098, 'Total loss': 0.3261993876827098}
2022-12-31 11:30:03,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:03,919 INFO:     Epoch: 40
2022-12-31 11:30:05,554 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.39783245921134947, 'Total loss': 0.39783245921134947} | train loss {'Reaction outcome loss': 0.3190556901867819, 'Total loss': 0.3190556901867819}
2022-12-31 11:30:05,554 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:05,555 INFO:     Epoch: 41
2022-12-31 11:30:07,191 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3909304032723109, 'Total loss': 0.3909304032723109} | train loss {'Reaction outcome loss': 0.3158528163381245, 'Total loss': 0.3158528163381245}
2022-12-31 11:30:07,191 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:07,191 INFO:     Epoch: 42
2022-12-31 11:30:08,827 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3926390841603279, 'Total loss': 0.3926390841603279} | train loss {'Reaction outcome loss': 0.3080827264571596, 'Total loss': 0.3080827264571596}
2022-12-31 11:30:08,827 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:08,827 INFO:     Epoch: 43
2022-12-31 11:30:10,444 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3812985897064209, 'Total loss': 0.3812985897064209} | train loss {'Reaction outcome loss': 0.3038266653269259, 'Total loss': 0.3038266653269259}
2022-12-31 11:30:10,444 INFO:     Found new best model at epoch 43
2022-12-31 11:30:10,445 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:10,445 INFO:     Epoch: 44
2022-12-31 11:30:12,075 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3945519874493281, 'Total loss': 0.3945519874493281} | train loss {'Reaction outcome loss': 0.3096438518748956, 'Total loss': 0.3096438518748956}
2022-12-31 11:30:12,076 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:12,076 INFO:     Epoch: 45
2022-12-31 11:30:13,670 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3910477449496587, 'Total loss': 0.3910477449496587} | train loss {'Reaction outcome loss': 0.29764244629009423, 'Total loss': 0.29764244629009423}
2022-12-31 11:30:13,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:13,670 INFO:     Epoch: 46
2022-12-31 11:30:15,274 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4198642293612162, 'Total loss': 0.4198642293612162} | train loss {'Reaction outcome loss': 0.31850644430496555, 'Total loss': 0.31850644430496555}
2022-12-31 11:30:15,275 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:15,275 INFO:     Epoch: 47
2022-12-31 11:30:16,887 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41241385142008463, 'Total loss': 0.41241385142008463} | train loss {'Reaction outcome loss': 0.30101205061689235, 'Total loss': 0.30101205061689235}
2022-12-31 11:30:16,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:16,887 INFO:     Epoch: 48
2022-12-31 11:30:18,486 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40740014612674713, 'Total loss': 0.40740014612674713} | train loss {'Reaction outcome loss': 0.29287110894585855, 'Total loss': 0.29287110894585855}
2022-12-31 11:30:18,487 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:18,487 INFO:     Epoch: 49
2022-12-31 11:30:20,090 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3982654501994451, 'Total loss': 0.3982654501994451} | train loss {'Reaction outcome loss': 0.2890884790846241, 'Total loss': 0.2890884790846241}
2022-12-31 11:30:20,090 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:20,090 INFO:     Epoch: 50
2022-12-31 11:30:21,680 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3704407562812169, 'Total loss': 0.3704407562812169} | train loss {'Reaction outcome loss': 0.2818674939968016, 'Total loss': 0.2818674939968016}
2022-12-31 11:30:21,680 INFO:     Found new best model at epoch 50
2022-12-31 11:30:21,681 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:21,681 INFO:     Epoch: 51
2022-12-31 11:30:23,284 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3957415749629339, 'Total loss': 0.3957415749629339} | train loss {'Reaction outcome loss': 0.2840923269741588, 'Total loss': 0.2840923269741588}
2022-12-31 11:30:23,284 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:23,285 INFO:     Epoch: 52
2022-12-31 11:30:24,889 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4197884996732076, 'Total loss': 0.4197884996732076} | train loss {'Reaction outcome loss': 0.28293704567487654, 'Total loss': 0.28293704567487654}
2022-12-31 11:30:24,889 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:24,889 INFO:     Epoch: 53
2022-12-31 11:30:26,498 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.37930946151415507, 'Total loss': 0.37930946151415507} | train loss {'Reaction outcome loss': 0.27492217940828373, 'Total loss': 0.27492217940828373}
2022-12-31 11:30:26,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:26,499 INFO:     Epoch: 54
2022-12-31 11:30:28,091 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.42079842487970986, 'Total loss': 0.42079842487970986} | train loss {'Reaction outcome loss': 0.28123113551534346, 'Total loss': 0.28123113551534346}
2022-12-31 11:30:28,091 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:28,092 INFO:     Epoch: 55
2022-12-31 11:30:29,697 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3821271965901057, 'Total loss': 0.3821271965901057} | train loss {'Reaction outcome loss': 0.27429490613022883, 'Total loss': 0.27429490613022883}
2022-12-31 11:30:29,697 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:29,697 INFO:     Epoch: 56
2022-12-31 11:30:31,294 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.36878000299135844, 'Total loss': 0.36878000299135844} | train loss {'Reaction outcome loss': 0.2713350818125089, 'Total loss': 0.2713350818125089}
2022-12-31 11:30:31,294 INFO:     Found new best model at epoch 56
2022-12-31 11:30:31,295 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:31,295 INFO:     Epoch: 57
2022-12-31 11:30:32,900 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4031043415268262, 'Total loss': 0.4031043415268262} | train loss {'Reaction outcome loss': 0.2662746075395684, 'Total loss': 0.2662746075395684}
2022-12-31 11:30:32,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:32,900 INFO:     Epoch: 58
2022-12-31 11:30:34,552 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4070634921391805, 'Total loss': 0.4070634921391805} | train loss {'Reaction outcome loss': 0.2667884846045838, 'Total loss': 0.2667884846045838}
2022-12-31 11:30:34,552 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:34,552 INFO:     Epoch: 59
2022-12-31 11:30:36,174 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3914569546778997, 'Total loss': 0.3914569546778997} | train loss {'Reaction outcome loss': 0.2648149639290236, 'Total loss': 0.2648149639290236}
2022-12-31 11:30:36,174 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:36,174 INFO:     Epoch: 60
2022-12-31 11:30:37,812 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4014565388361613, 'Total loss': 0.4014565388361613} | train loss {'Reaction outcome loss': 0.2580078522661242, 'Total loss': 0.2580078522661242}
2022-12-31 11:30:37,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:37,813 INFO:     Epoch: 61
2022-12-31 11:30:39,426 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.37406002630790075, 'Total loss': 0.37406002630790075} | train loss {'Reaction outcome loss': 0.2606144592628234, 'Total loss': 0.2606144592628234}
2022-12-31 11:30:39,426 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:39,426 INFO:     Epoch: 62
2022-12-31 11:30:41,039 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43203749855359397, 'Total loss': 0.43203749855359397} | train loss {'Reaction outcome loss': 0.2524429827471318, 'Total loss': 0.2524429827471318}
2022-12-31 11:30:41,039 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:41,039 INFO:     Epoch: 63
2022-12-31 11:30:42,640 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3848284016052882, 'Total loss': 0.3848284016052882} | train loss {'Reaction outcome loss': 0.2559707548168882, 'Total loss': 0.2559707548168882}
2022-12-31 11:30:42,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:42,641 INFO:     Epoch: 64
2022-12-31 11:30:44,271 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3911147991816203, 'Total loss': 0.3911147991816203} | train loss {'Reaction outcome loss': 0.2556865312539942, 'Total loss': 0.2556865312539942}
2022-12-31 11:30:44,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:44,271 INFO:     Epoch: 65
2022-12-31 11:30:45,891 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.36212467551231386, 'Total loss': 0.36212467551231386} | train loss {'Reaction outcome loss': 0.2498891306712049, 'Total loss': 0.2498891306712049}
2022-12-31 11:30:45,891 INFO:     Found new best model at epoch 65
2022-12-31 11:30:45,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:45,892 INFO:     Epoch: 66
2022-12-31 11:30:47,508 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3913169672091802, 'Total loss': 0.3913169672091802} | train loss {'Reaction outcome loss': 0.255117844088354, 'Total loss': 0.255117844088354}
2022-12-31 11:30:47,508 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:47,509 INFO:     Epoch: 67
2022-12-31 11:30:49,096 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38130829532941185, 'Total loss': 0.38130829532941185} | train loss {'Reaction outcome loss': 0.29078994371187605, 'Total loss': 0.29078994371187605}
2022-12-31 11:30:49,097 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:49,097 INFO:     Epoch: 68
2022-12-31 11:30:50,701 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.36972684661547345, 'Total loss': 0.36972684661547345} | train loss {'Reaction outcome loss': 0.24888429438452359, 'Total loss': 0.24888429438452359}
2022-12-31 11:30:50,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:50,701 INFO:     Epoch: 69
2022-12-31 11:30:52,307 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3851417372624079, 'Total loss': 0.3851417372624079} | train loss {'Reaction outcome loss': 0.24035571216676466, 'Total loss': 0.24035571216676466}
2022-12-31 11:30:52,307 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:52,307 INFO:     Epoch: 70
2022-12-31 11:30:53,911 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.391240257024765, 'Total loss': 0.391240257024765} | train loss {'Reaction outcome loss': 0.24238416486785855, 'Total loss': 0.24238416486785855}
2022-12-31 11:30:53,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:53,911 INFO:     Epoch: 71
2022-12-31 11:30:55,499 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.37117456446091335, 'Total loss': 0.37117456446091335} | train loss {'Reaction outcome loss': 0.23947940714846272, 'Total loss': 0.23947940714846272}
2022-12-31 11:30:55,499 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:55,499 INFO:     Epoch: 72
2022-12-31 11:30:57,102 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3660246069232623, 'Total loss': 0.3660246069232623} | train loss {'Reaction outcome loss': 0.2377706714230927, 'Total loss': 0.2377706714230927}
2022-12-31 11:30:57,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:57,102 INFO:     Epoch: 73
2022-12-31 11:30:58,691 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3945709285636743, 'Total loss': 0.3945709285636743} | train loss {'Reaction outcome loss': 0.2417974435308903, 'Total loss': 0.2417974435308903}
2022-12-31 11:30:58,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:30:58,692 INFO:     Epoch: 74
2022-12-31 11:31:00,323 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39307777682940165, 'Total loss': 0.39307777682940165} | train loss {'Reaction outcome loss': 0.2348137924083225, 'Total loss': 0.2348137924083225}
2022-12-31 11:31:00,323 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:00,323 INFO:     Epoch: 75
2022-12-31 11:31:01,954 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40505462338527043, 'Total loss': 0.40505462338527043} | train loss {'Reaction outcome loss': 0.2474809384877807, 'Total loss': 0.2474809384877807}
2022-12-31 11:31:01,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:01,955 INFO:     Epoch: 76
2022-12-31 11:31:03,567 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43709087868531543, 'Total loss': 0.43709087868531543} | train loss {'Reaction outcome loss': 0.26997438316702493, 'Total loss': 0.26997438316702493}
2022-12-31 11:31:03,567 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:03,568 INFO:     Epoch: 77
2022-12-31 11:31:05,199 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.36246395309766133, 'Total loss': 0.36246395309766133} | train loss {'Reaction outcome loss': 0.24267111004453487, 'Total loss': 0.24267111004453487}
2022-12-31 11:31:05,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:05,199 INFO:     Epoch: 78
2022-12-31 11:31:06,792 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40031746625900266, 'Total loss': 0.40031746625900266} | train loss {'Reaction outcome loss': 0.24387855209035636, 'Total loss': 0.24387855209035636}
2022-12-31 11:31:06,792 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:06,792 INFO:     Epoch: 79
2022-12-31 11:31:08,397 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3543435682853063, 'Total loss': 0.3543435682853063} | train loss {'Reaction outcome loss': 0.23803047102241628, 'Total loss': 0.23803047102241628}
2022-12-31 11:31:08,397 INFO:     Found new best model at epoch 79
2022-12-31 11:31:08,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:08,398 INFO:     Epoch: 80
2022-12-31 11:31:10,000 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4320037523905436, 'Total loss': 0.4320037523905436} | train loss {'Reaction outcome loss': 0.2331214796083615, 'Total loss': 0.2331214796083615}
2022-12-31 11:31:10,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:10,000 INFO:     Epoch: 81
2022-12-31 11:31:11,617 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.37961903115113577, 'Total loss': 0.37961903115113577} | train loss {'Reaction outcome loss': 0.22858942543034969, 'Total loss': 0.22858942543034969}
2022-12-31 11:31:11,617 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:11,617 INFO:     Epoch: 82
2022-12-31 11:31:13,217 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.419866673151652, 'Total loss': 0.419866673151652} | train loss {'Reaction outcome loss': 0.2298620683588155, 'Total loss': 0.2298620683588155}
2022-12-31 11:31:13,218 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:13,218 INFO:     Epoch: 83
2022-12-31 11:31:14,848 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4028110762437185, 'Total loss': 0.4028110762437185} | train loss {'Reaction outcome loss': 0.2290272118936654, 'Total loss': 0.2290272118936654}
2022-12-31 11:31:14,848 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:14,848 INFO:     Epoch: 84
2022-12-31 11:31:16,453 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3664942026138306, 'Total loss': 0.3664942026138306} | train loss {'Reaction outcome loss': 0.2273799093959826, 'Total loss': 0.2273799093959826}
2022-12-31 11:31:16,453 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:16,453 INFO:     Epoch: 85
2022-12-31 11:31:18,088 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40587317049503324, 'Total loss': 0.40587317049503324} | train loss {'Reaction outcome loss': 0.22375437210607546, 'Total loss': 0.22375437210607546}
2022-12-31 11:31:18,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:18,088 INFO:     Epoch: 86
2022-12-31 11:31:19,729 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38444264431794484, 'Total loss': 0.38444264431794484} | train loss {'Reaction outcome loss': 0.22308094080358717, 'Total loss': 0.22308094080358717}
2022-12-31 11:31:19,730 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:19,730 INFO:     Epoch: 87
2022-12-31 11:31:21,310 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3963490515947342, 'Total loss': 0.3963490515947342} | train loss {'Reaction outcome loss': 0.22190061438764594, 'Total loss': 0.22190061438764594}
2022-12-31 11:31:21,311 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:21,311 INFO:     Epoch: 88
2022-12-31 11:31:22,956 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.38453983267148334, 'Total loss': 0.38453983267148334} | train loss {'Reaction outcome loss': 0.23469825092035826, 'Total loss': 0.23469825092035826}
2022-12-31 11:31:22,956 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:22,956 INFO:     Epoch: 89
2022-12-31 11:31:24,550 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3859357794125875, 'Total loss': 0.3859357794125875} | train loss {'Reaction outcome loss': 0.24736772074053684, 'Total loss': 0.24736772074053684}
2022-12-31 11:31:24,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:24,551 INFO:     Epoch: 90
2022-12-31 11:31:26,267 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3968428949515025, 'Total loss': 0.3968428949515025} | train loss {'Reaction outcome loss': 0.22467341760267923, 'Total loss': 0.22467341760267923}
2022-12-31 11:31:26,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:26,267 INFO:     Epoch: 91
2022-12-31 11:31:27,972 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.38516286611557005, 'Total loss': 0.38516286611557005} | train loss {'Reaction outcome loss': 0.22352290073046088, 'Total loss': 0.22352290073046088}
2022-12-31 11:31:27,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:27,972 INFO:     Epoch: 92
2022-12-31 11:31:29,608 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.38906657993793486, 'Total loss': 0.38906657993793486} | train loss {'Reaction outcome loss': 0.2233026651530594, 'Total loss': 0.2233026651530594}
2022-12-31 11:31:29,608 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:29,608 INFO:     Epoch: 93
2022-12-31 11:31:31,227 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.37777361075083415, 'Total loss': 0.37777361075083415} | train loss {'Reaction outcome loss': 0.21821766441596835, 'Total loss': 0.21821766441596835}
2022-12-31 11:31:31,228 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:31,228 INFO:     Epoch: 94
2022-12-31 11:31:32,851 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.3969485849142075, 'Total loss': 0.3969485849142075} | train loss {'Reaction outcome loss': 0.21883573905443368, 'Total loss': 0.21883573905443368}
2022-12-31 11:31:32,852 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:32,852 INFO:     Epoch: 95
2022-12-31 11:31:34,434 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3877023408810298, 'Total loss': 0.3877023408810298} | train loss {'Reaction outcome loss': 0.21578956889583345, 'Total loss': 0.21578956889583345}
2022-12-31 11:31:34,434 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:34,434 INFO:     Epoch: 96
2022-12-31 11:31:36,050 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3568268001079559, 'Total loss': 0.3568268001079559} | train loss {'Reaction outcome loss': 0.2229692958505399, 'Total loss': 0.2229692958505399}
2022-12-31 11:31:36,050 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:36,050 INFO:     Epoch: 97
2022-12-31 11:31:37,696 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3876405914624532, 'Total loss': 0.3876405914624532} | train loss {'Reaction outcome loss': 0.21623258542377446, 'Total loss': 0.21623258542377446}
2022-12-31 11:31:37,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:37,696 INFO:     Epoch: 98
2022-12-31 11:31:39,308 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3753941516081492, 'Total loss': 0.3753941516081492} | train loss {'Reaction outcome loss': 0.21811489941445988, 'Total loss': 0.21811489941445988}
2022-12-31 11:31:39,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:39,309 INFO:     Epoch: 99
2022-12-31 11:31:40,922 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3803446759780248, 'Total loss': 0.3803446759780248} | train loss {'Reaction outcome loss': 0.21053736287159036, 'Total loss': 0.21053736287159036}
2022-12-31 11:31:40,922 INFO:     Best model found after epoch 80 of 100.
2022-12-31 11:31:40,922 INFO:   Done with stage: TRAINING
2022-12-31 11:31:40,922 INFO:   Starting stage: EVALUATION
2022-12-31 11:31:41,051 INFO:   Done with stage: EVALUATION
2022-12-31 11:31:41,052 INFO:   Leaving out SEQ value Fold_5
2022-12-31 11:31:41,064 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 11:31:41,064 INFO:   Starting stage: FEATURE SCALING
2022-12-31 11:31:41,707 INFO:   Done with stage: FEATURE SCALING
2022-12-31 11:31:41,707 INFO:   Starting stage: SCALING TARGETS
2022-12-31 11:31:41,777 INFO:   Done with stage: SCALING TARGETS
2022-12-31 11:31:41,777 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:31:41,777 INFO:     No hyperparam tuning for this model
2022-12-31 11:31:41,777 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:31:41,777 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 11:31:41,778 INFO:     None feature selector for col prot
2022-12-31 11:31:41,778 INFO:     None feature selector for col prot
2022-12-31 11:31:41,778 INFO:     None feature selector for col prot
2022-12-31 11:31:41,779 INFO:     None feature selector for col chem
2022-12-31 11:31:41,779 INFO:     None feature selector for col chem
2022-12-31 11:31:41,779 INFO:     None feature selector for col chem
2022-12-31 11:31:41,779 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 11:31:41,779 INFO:   Starting stage: BUILD MODEL
2022-12-31 11:31:41,781 INFO:     Number of params in model 223921
2022-12-31 11:31:41,784 INFO:   Done with stage: BUILD MODEL
2022-12-31 11:31:41,784 INFO:   Starting stage: TRAINING
2022-12-31 11:31:41,828 INFO:     Val loss before train {'Reaction outcome loss': 0.97778506676356, 'Total loss': 0.97778506676356}
2022-12-31 11:31:41,828 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:41,828 INFO:     Epoch: 0
2022-12-31 11:31:43,436 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7249852081139883, 'Total loss': 0.7249852081139883} | train loss {'Reaction outcome loss': 0.8240138960975236, 'Total loss': 0.8240138960975236}
2022-12-31 11:31:43,436 INFO:     Found new best model at epoch 0
2022-12-31 11:31:43,437 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:43,437 INFO:     Epoch: 1
2022-12-31 11:31:45,064 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5453046421209972, 'Total loss': 0.5453046421209972} | train loss {'Reaction outcome loss': 0.6054931309452092, 'Total loss': 0.6054931309452092}
2022-12-31 11:31:45,065 INFO:     Found new best model at epoch 1
2022-12-31 11:31:45,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:45,066 INFO:     Epoch: 2
2022-12-31 11:31:46,675 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5443214178085327, 'Total loss': 0.5443214178085327} | train loss {'Reaction outcome loss': 0.5350194069138472, 'Total loss': 0.5350194069138472}
2022-12-31 11:31:46,675 INFO:     Found new best model at epoch 2
2022-12-31 11:31:46,676 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:46,676 INFO:     Epoch: 3
2022-12-31 11:31:48,270 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5091830094655355, 'Total loss': 0.5091830094655355} | train loss {'Reaction outcome loss': 0.5091749661622326, 'Total loss': 0.5091749661622326}
2022-12-31 11:31:48,270 INFO:     Found new best model at epoch 3
2022-12-31 11:31:48,271 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:48,271 INFO:     Epoch: 4
2022-12-31 11:31:49,897 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5252161224683126, 'Total loss': 0.5252161224683126} | train loss {'Reaction outcome loss': 0.49203330797372735, 'Total loss': 0.49203330797372735}
2022-12-31 11:31:49,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:49,897 INFO:     Epoch: 5
2022-12-31 11:31:51,494 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5147866139809291, 'Total loss': 0.5147866139809291} | train loss {'Reaction outcome loss': 0.4858881397361773, 'Total loss': 0.4858881397361773}
2022-12-31 11:31:51,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:51,495 INFO:     Epoch: 6
2022-12-31 11:31:53,107 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4819025109211604, 'Total loss': 0.4819025109211604} | train loss {'Reaction outcome loss': 0.47363835746722727, 'Total loss': 0.47363835746722727}
2022-12-31 11:31:53,108 INFO:     Found new best model at epoch 6
2022-12-31 11:31:53,108 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:53,108 INFO:     Epoch: 7
2022-12-31 11:31:54,738 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47159923911094664, 'Total loss': 0.47159923911094664} | train loss {'Reaction outcome loss': 0.46195806847865006, 'Total loss': 0.46195806847865006}
2022-12-31 11:31:54,739 INFO:     Found new best model at epoch 7
2022-12-31 11:31:54,739 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:54,740 INFO:     Epoch: 8
2022-12-31 11:31:56,376 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5250779648621877, 'Total loss': 0.5250779648621877} | train loss {'Reaction outcome loss': 0.45895720369088044, 'Total loss': 0.45895720369088044}
2022-12-31 11:31:56,376 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:56,376 INFO:     Epoch: 9
2022-12-31 11:31:58,007 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5209073821703593, 'Total loss': 0.5209073821703593} | train loss {'Reaction outcome loss': 0.4476660991364253, 'Total loss': 0.4476660991364253}
2022-12-31 11:31:58,007 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:58,007 INFO:     Epoch: 10
2022-12-31 11:31:59,653 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46753103186686834, 'Total loss': 0.46753103186686834} | train loss {'Reaction outcome loss': 0.44897749921074137, 'Total loss': 0.44897749921074137}
2022-12-31 11:31:59,653 INFO:     Found new best model at epoch 10
2022-12-31 11:31:59,654 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:31:59,654 INFO:     Epoch: 11
2022-12-31 11:32:01,257 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.505495497584343, 'Total loss': 0.505495497584343} | train loss {'Reaction outcome loss': 0.43992415465091006, 'Total loss': 0.43992415465091006}
2022-12-31 11:32:01,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:01,257 INFO:     Epoch: 12
2022-12-31 11:32:02,896 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4940807471672694, 'Total loss': 0.4940807471672694} | train loss {'Reaction outcome loss': 0.43627121850200323, 'Total loss': 0.43627121850200323}
2022-12-31 11:32:02,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:02,896 INFO:     Epoch: 13
2022-12-31 11:32:04,528 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45955858925978343, 'Total loss': 0.45955858925978343} | train loss {'Reaction outcome loss': 0.46276461584088596, 'Total loss': 0.46276461584088596}
2022-12-31 11:32:04,529 INFO:     Found new best model at epoch 13
2022-12-31 11:32:04,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:04,530 INFO:     Epoch: 14
2022-12-31 11:32:06,181 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4865690330664317, 'Total loss': 0.4865690330664317} | train loss {'Reaction outcome loss': 0.43737868235810945, 'Total loss': 0.43737868235810945}
2022-12-31 11:32:06,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:06,181 INFO:     Epoch: 15
2022-12-31 11:32:07,778 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.49152395327885945, 'Total loss': 0.49152395327885945} | train loss {'Reaction outcome loss': 0.4513833688587316, 'Total loss': 0.4513833688587316}
2022-12-31 11:32:07,778 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:07,778 INFO:     Epoch: 16
2022-12-31 11:32:09,388 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.455513659119606, 'Total loss': 0.455513659119606} | train loss {'Reaction outcome loss': 0.4271543891965479, 'Total loss': 0.4271543891965479}
2022-12-31 11:32:09,388 INFO:     Found new best model at epoch 16
2022-12-31 11:32:09,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:09,389 INFO:     Epoch: 17
2022-12-31 11:32:10,976 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4786101996898651, 'Total loss': 0.4786101996898651} | train loss {'Reaction outcome loss': 0.4274855009862222, 'Total loss': 0.4274855009862222}
2022-12-31 11:32:10,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:10,976 INFO:     Epoch: 18
2022-12-31 11:32:12,587 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47749220331509906, 'Total loss': 0.47749220331509906} | train loss {'Reaction outcome loss': 0.40661774644547183, 'Total loss': 0.40661774644547183}
2022-12-31 11:32:12,587 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:12,587 INFO:     Epoch: 19
2022-12-31 11:32:14,198 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44180249571800234, 'Total loss': 0.44180249571800234} | train loss {'Reaction outcome loss': 0.398070022170414, 'Total loss': 0.398070022170414}
2022-12-31 11:32:14,199 INFO:     Found new best model at epoch 19
2022-12-31 11:32:14,200 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:14,200 INFO:     Epoch: 20
2022-12-31 11:32:15,810 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44425595700740816, 'Total loss': 0.44425595700740816} | train loss {'Reaction outcome loss': 0.3972086736905402, 'Total loss': 0.3972086736905402}
2022-12-31 11:32:15,810 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:15,810 INFO:     Epoch: 21
2022-12-31 11:32:17,421 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4539489150047302, 'Total loss': 0.4539489150047302} | train loss {'Reaction outcome loss': 0.38936975787299266, 'Total loss': 0.38936975787299266}
2022-12-31 11:32:17,421 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:17,421 INFO:     Epoch: 22
2022-12-31 11:32:19,009 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4407999853293101, 'Total loss': 0.4407999853293101} | train loss {'Reaction outcome loss': 0.3928310237419994, 'Total loss': 0.3928310237419994}
2022-12-31 11:32:19,009 INFO:     Found new best model at epoch 22
2022-12-31 11:32:19,010 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:19,010 INFO:     Epoch: 23
2022-12-31 11:32:20,645 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4360964645942052, 'Total loss': 0.4360964645942052} | train loss {'Reaction outcome loss': 0.3866713749703722, 'Total loss': 0.3866713749703722}
2022-12-31 11:32:20,645 INFO:     Found new best model at epoch 23
2022-12-31 11:32:20,646 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:20,646 INFO:     Epoch: 24
2022-12-31 11:32:22,280 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4707368900378545, 'Total loss': 0.4707368900378545} | train loss {'Reaction outcome loss': 0.3901213239743442, 'Total loss': 0.3901213239743442}
2022-12-31 11:32:22,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:22,280 INFO:     Epoch: 25
2022-12-31 11:32:23,920 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42240563531716663, 'Total loss': 0.42240563531716663} | train loss {'Reaction outcome loss': 0.3962198225342655, 'Total loss': 0.3962198225342655}
2022-12-31 11:32:23,920 INFO:     Found new best model at epoch 25
2022-12-31 11:32:23,920 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:23,921 INFO:     Epoch: 26
2022-12-31 11:32:25,513 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44068818787733716, 'Total loss': 0.44068818787733716} | train loss {'Reaction outcome loss': 0.3698958378391462, 'Total loss': 0.3698958378391462}
2022-12-31 11:32:25,513 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:25,513 INFO:     Epoch: 27
2022-12-31 11:32:27,121 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46750802795092267, 'Total loss': 0.46750802795092267} | train loss {'Reaction outcome loss': 0.3666119019946326, 'Total loss': 0.3666119019946326}
2022-12-31 11:32:27,121 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:27,121 INFO:     Epoch: 28
2022-12-31 11:32:28,710 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42372549722592034, 'Total loss': 0.42372549722592034} | train loss {'Reaction outcome loss': 0.36021203001070284, 'Total loss': 0.36021203001070284}
2022-12-31 11:32:28,710 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:28,710 INFO:     Epoch: 29
2022-12-31 11:32:30,318 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.41640787074963254, 'Total loss': 0.41640787074963254} | train loss {'Reaction outcome loss': 0.3532034151553028, 'Total loss': 0.3532034151553028}
2022-12-31 11:32:30,318 INFO:     Found new best model at epoch 29
2022-12-31 11:32:30,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:30,319 INFO:     Epoch: 30
2022-12-31 11:32:31,927 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4087065915266673, 'Total loss': 0.4087065915266673} | train loss {'Reaction outcome loss': 0.3518334197942222, 'Total loss': 0.3518334197942222}
2022-12-31 11:32:31,927 INFO:     Found new best model at epoch 30
2022-12-31 11:32:31,928 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:31,928 INFO:     Epoch: 31
2022-12-31 11:32:33,521 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42741578817367554, 'Total loss': 0.42741578817367554} | train loss {'Reaction outcome loss': 0.3427039770425493, 'Total loss': 0.3427039770425493}
2022-12-31 11:32:33,522 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:33,522 INFO:     Epoch: 32
2022-12-31 11:32:35,129 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4371500233809153, 'Total loss': 0.4371500233809153} | train loss {'Reaction outcome loss': 0.35365336148095305, 'Total loss': 0.35365336148095305}
2022-12-31 11:32:35,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:35,130 INFO:     Epoch: 33
2022-12-31 11:32:36,737 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40667564074198403, 'Total loss': 0.40667564074198403} | train loss {'Reaction outcome loss': 0.3678446567846813, 'Total loss': 0.3678446567846813}
2022-12-31 11:32:36,737 INFO:     Found new best model at epoch 33
2022-12-31 11:32:36,738 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:36,738 INFO:     Epoch: 34
2022-12-31 11:32:38,325 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4252857228120168, 'Total loss': 0.4252857228120168} | train loss {'Reaction outcome loss': 0.3527593977506394, 'Total loss': 0.3527593977506394}
2022-12-31 11:32:38,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:38,325 INFO:     Epoch: 35
2022-12-31 11:32:39,933 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3964580833911896, 'Total loss': 0.3964580833911896} | train loss {'Reaction outcome loss': 0.33626887163677316, 'Total loss': 0.33626887163677316}
2022-12-31 11:32:39,933 INFO:     Found new best model at epoch 35
2022-12-31 11:32:39,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:39,934 INFO:     Epoch: 36
2022-12-31 11:32:41,539 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5070280075073242, 'Total loss': 0.5070280075073242} | train loss {'Reaction outcome loss': 0.3328355482812765, 'Total loss': 0.3328355482812765}
2022-12-31 11:32:41,539 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:41,539 INFO:     Epoch: 37
2022-12-31 11:32:43,130 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41633693923552834, 'Total loss': 0.41633693923552834} | train loss {'Reaction outcome loss': 0.3274298660588734, 'Total loss': 0.3274298660588734}
2022-12-31 11:32:43,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:43,130 INFO:     Epoch: 38
2022-12-31 11:32:44,735 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41815705796082814, 'Total loss': 0.41815705796082814} | train loss {'Reaction outcome loss': 0.317351374073305, 'Total loss': 0.317351374073305}
2022-12-31 11:32:44,735 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:44,735 INFO:     Epoch: 39
2022-12-31 11:32:46,330 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4187958061695099, 'Total loss': 0.4187958061695099} | train loss {'Reaction outcome loss': 0.31718752425355057, 'Total loss': 0.31718752425355057}
2022-12-31 11:32:46,330 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:46,330 INFO:     Epoch: 40
2022-12-31 11:32:47,966 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4556632459163666, 'Total loss': 0.4556632459163666} | train loss {'Reaction outcome loss': 0.3161308900505875, 'Total loss': 0.3161308900505875}
2022-12-31 11:32:47,966 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:47,966 INFO:     Epoch: 41
2022-12-31 11:32:49,583 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4070263832807541, 'Total loss': 0.4070263832807541} | train loss {'Reaction outcome loss': 0.30991987284758815, 'Total loss': 0.30991987284758815}
2022-12-31 11:32:49,583 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:49,583 INFO:     Epoch: 42
2022-12-31 11:32:51,191 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5113995522260666, 'Total loss': 0.5113995522260666} | train loss {'Reaction outcome loss': 0.30002672256280977, 'Total loss': 0.30002672256280977}
2022-12-31 11:32:51,192 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:51,192 INFO:     Epoch: 43
2022-12-31 11:32:52,788 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4348177800575892, 'Total loss': 0.4348177800575892} | train loss {'Reaction outcome loss': 0.31060348475432914, 'Total loss': 0.31060348475432914}
2022-12-31 11:32:52,789 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:52,789 INFO:     Epoch: 44
2022-12-31 11:32:54,400 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4597454418738683, 'Total loss': 0.4597454418738683} | train loss {'Reaction outcome loss': 0.3305251982044707, 'Total loss': 0.3305251982044707}
2022-12-31 11:32:54,400 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:54,400 INFO:     Epoch: 45
2022-12-31 11:32:55,984 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4243370900551478, 'Total loss': 0.4243370900551478} | train loss {'Reaction outcome loss': 0.300794607433288, 'Total loss': 0.300794607433288}
2022-12-31 11:32:55,984 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:55,984 INFO:     Epoch: 46
2022-12-31 11:32:57,591 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4034081041812897, 'Total loss': 0.4034081041812897} | train loss {'Reaction outcome loss': 0.3054461889078611, 'Total loss': 0.3054461889078611}
2022-12-31 11:32:57,592 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:57,592 INFO:     Epoch: 47
2022-12-31 11:32:59,199 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41415377259254454, 'Total loss': 0.41415377259254454} | train loss {'Reaction outcome loss': 0.2961189226412714, 'Total loss': 0.2961189226412714}
2022-12-31 11:32:59,199 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:32:59,199 INFO:     Epoch: 48
2022-12-31 11:33:00,787 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4282437036434809, 'Total loss': 0.4282437036434809} | train loss {'Reaction outcome loss': 0.28866566026007984, 'Total loss': 0.28866566026007984}
2022-12-31 11:33:00,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:00,787 INFO:     Epoch: 49
2022-12-31 11:33:02,396 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39310293197631835, 'Total loss': 0.39310293197631835} | train loss {'Reaction outcome loss': 0.288358628183799, 'Total loss': 0.288358628183799}
2022-12-31 11:33:02,396 INFO:     Found new best model at epoch 49
2022-12-31 11:33:02,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:02,397 INFO:     Epoch: 50
2022-12-31 11:33:04,005 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4228048195441564, 'Total loss': 0.4228048195441564} | train loss {'Reaction outcome loss': 0.2761789782603771, 'Total loss': 0.2761789782603771}
2022-12-31 11:33:04,005 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:04,005 INFO:     Epoch: 51
2022-12-31 11:33:05,606 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40160585443178815, 'Total loss': 0.40160585443178815} | train loss {'Reaction outcome loss': 0.28406477204618463, 'Total loss': 0.28406477204618463}
2022-12-31 11:33:05,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:05,606 INFO:     Epoch: 52
2022-12-31 11:33:07,212 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.43007223109404247, 'Total loss': 0.43007223109404247} | train loss {'Reaction outcome loss': 0.27629464416522126, 'Total loss': 0.27629464416522126}
2022-12-31 11:33:07,212 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:07,212 INFO:     Epoch: 53
2022-12-31 11:33:08,851 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4297720362742742, 'Total loss': 0.4297720362742742} | train loss {'Reaction outcome loss': 0.2704774307802428, 'Total loss': 0.2704774307802428}
2022-12-31 11:33:08,851 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:08,851 INFO:     Epoch: 54
2022-12-31 11:33:10,443 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.45529324014981587, 'Total loss': 0.45529324014981587} | train loss {'Reaction outcome loss': 0.27417159983483347, 'Total loss': 0.27417159983483347}
2022-12-31 11:33:10,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:10,444 INFO:     Epoch: 55
2022-12-31 11:33:12,051 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44494587580362954, 'Total loss': 0.44494587580362954} | train loss {'Reaction outcome loss': 0.27045396083722945, 'Total loss': 0.27045396083722945}
2022-12-31 11:33:12,051 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:12,051 INFO:     Epoch: 56
2022-12-31 11:33:13,670 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44626841843128207, 'Total loss': 0.44626841843128207} | train loss {'Reaction outcome loss': 0.2655854248348961, 'Total loss': 0.2655854248348961}
2022-12-31 11:33:13,670 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:13,670 INFO:     Epoch: 57
2022-12-31 11:33:15,304 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4223678211371104, 'Total loss': 0.4223678211371104} | train loss {'Reaction outcome loss': 0.2690669554920506, 'Total loss': 0.2690669554920506}
2022-12-31 11:33:15,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:15,304 INFO:     Epoch: 58
2022-12-31 11:33:16,957 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3895672778288523, 'Total loss': 0.3895672778288523} | train loss {'Reaction outcome loss': 0.2648374213297401, 'Total loss': 0.2648374213297401}
2022-12-31 11:33:16,957 INFO:     Found new best model at epoch 58
2022-12-31 11:33:16,958 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:16,958 INFO:     Epoch: 59
2022-12-31 11:33:18,549 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3872744103272756, 'Total loss': 0.3872744103272756} | train loss {'Reaction outcome loss': 0.25792390063567006, 'Total loss': 0.25792390063567006}
2022-12-31 11:33:18,549 INFO:     Found new best model at epoch 59
2022-12-31 11:33:18,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:18,550 INFO:     Epoch: 60
2022-12-31 11:33:20,148 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40816846092542014, 'Total loss': 0.40816846092542014} | train loss {'Reaction outcome loss': 0.2576248635524425, 'Total loss': 0.2576248635524425}
2022-12-31 11:33:20,149 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:20,149 INFO:     Epoch: 61
2022-12-31 11:33:21,750 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.39628955026467644, 'Total loss': 0.39628955026467644} | train loss {'Reaction outcome loss': 0.25480948422320077, 'Total loss': 0.25480948422320077}
2022-12-31 11:33:21,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:21,750 INFO:     Epoch: 62
2022-12-31 11:33:23,380 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40661288499832154, 'Total loss': 0.40661288499832154} | train loss {'Reaction outcome loss': 0.27613402943572274, 'Total loss': 0.27613402943572274}
2022-12-31 11:33:23,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:23,380 INFO:     Epoch: 63
2022-12-31 11:33:25,028 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4385419753690561, 'Total loss': 0.4385419753690561} | train loss {'Reaction outcome loss': 0.2761198921155259, 'Total loss': 0.2761198921155259}
2022-12-31 11:33:25,028 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:25,028 INFO:     Epoch: 64
2022-12-31 11:33:26,677 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4087895373503367, 'Total loss': 0.4087895373503367} | train loss {'Reaction outcome loss': 0.26474848201209883, 'Total loss': 0.26474848201209883}
2022-12-31 11:33:26,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:26,679 INFO:     Epoch: 65
2022-12-31 11:33:28,293 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42189237624406817, 'Total loss': 0.42189237624406817} | train loss {'Reaction outcome loss': 0.2609303759653931, 'Total loss': 0.2609303759653931}
2022-12-31 11:33:28,294 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:28,294 INFO:     Epoch: 66
2022-12-31 11:33:29,918 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4466759900252024, 'Total loss': 0.4466759900252024} | train loss {'Reaction outcome loss': 0.2501573889268279, 'Total loss': 0.2501573889268279}
2022-12-31 11:33:29,918 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:29,918 INFO:     Epoch: 67
2022-12-31 11:33:31,500 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.45138293504714966, 'Total loss': 0.45138293504714966} | train loss {'Reaction outcome loss': 0.2526072145049946, 'Total loss': 0.2526072145049946}
2022-12-31 11:33:31,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:31,500 INFO:     Epoch: 68
2022-12-31 11:33:33,149 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41015911996364596, 'Total loss': 0.41015911996364596} | train loss {'Reaction outcome loss': 0.2481748829968242, 'Total loss': 0.2481748829968242}
2022-12-31 11:33:33,150 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:33,150 INFO:     Epoch: 69
2022-12-31 11:33:34,764 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45397597054640454, 'Total loss': 0.45397597054640454} | train loss {'Reaction outcome loss': 0.24686490973850805, 'Total loss': 0.24686490973850805}
2022-12-31 11:33:34,764 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:34,764 INFO:     Epoch: 70
2022-12-31 11:33:36,393 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4631920576095581, 'Total loss': 0.4631920576095581} | train loss {'Reaction outcome loss': 0.24654958906335261, 'Total loss': 0.24654958906335261}
2022-12-31 11:33:36,393 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:36,393 INFO:     Epoch: 71
2022-12-31 11:33:38,011 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4349904755751292, 'Total loss': 0.4349904755751292} | train loss {'Reaction outcome loss': 0.24418099203572585, 'Total loss': 0.24418099203572585}
2022-12-31 11:33:38,011 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:38,011 INFO:     Epoch: 72
2022-12-31 11:33:39,609 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.41383755107720693, 'Total loss': 0.41383755107720693} | train loss {'Reaction outcome loss': 0.23919223482548463, 'Total loss': 0.23919223482548463}
2022-12-31 11:33:39,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:39,609 INFO:     Epoch: 73
2022-12-31 11:33:41,217 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4283162166674932, 'Total loss': 0.4283162166674932} | train loss {'Reaction outcome loss': 0.24499206162148227, 'Total loss': 0.24499206162148227}
2022-12-31 11:33:41,217 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:41,217 INFO:     Epoch: 74
2022-12-31 11:33:42,843 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41278944661219913, 'Total loss': 0.41278944661219913} | train loss {'Reaction outcome loss': 0.2386909117044854, 'Total loss': 0.2386909117044854}
2022-12-31 11:33:42,844 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:42,844 INFO:     Epoch: 75
2022-12-31 11:33:44,463 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4374057749907176, 'Total loss': 0.4374057749907176} | train loss {'Reaction outcome loss': 0.2471047326841432, 'Total loss': 0.2471047326841432}
2022-12-31 11:33:44,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:44,463 INFO:     Epoch: 76
2022-12-31 11:33:46,063 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43665000398953757, 'Total loss': 0.43665000398953757} | train loss {'Reaction outcome loss': 0.26793208777003136, 'Total loss': 0.26793208777003136}
2022-12-31 11:33:46,063 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:46,064 INFO:     Epoch: 77
2022-12-31 11:33:47,696 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4295578946669896, 'Total loss': 0.4295578946669896} | train loss {'Reaction outcome loss': 0.24566982936260773, 'Total loss': 0.24566982936260773}
2022-12-31 11:33:47,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:47,696 INFO:     Epoch: 78
2022-12-31 11:33:49,290 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4133074181775252, 'Total loss': 0.4133074181775252} | train loss {'Reaction outcome loss': 0.23683444927935826, 'Total loss': 0.23683444927935826}
2022-12-31 11:33:49,291 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:49,291 INFO:     Epoch: 79
2022-12-31 11:33:50,894 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4357755482196808, 'Total loss': 0.4357755482196808} | train loss {'Reaction outcome loss': 0.23548741427341313, 'Total loss': 0.23548741427341313}
2022-12-31 11:33:50,894 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:50,894 INFO:     Epoch: 80
2022-12-31 11:33:52,505 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42770884235699974, 'Total loss': 0.42770884235699974} | train loss {'Reaction outcome loss': 0.22974247410699414, 'Total loss': 0.22974247410699414}
2022-12-31 11:33:52,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:52,505 INFO:     Epoch: 81
2022-12-31 11:33:54,118 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4178639143705368, 'Total loss': 0.4178639143705368} | train loss {'Reaction outcome loss': 0.2318801642867966, 'Total loss': 0.2318801642867966}
2022-12-31 11:33:54,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:54,118 INFO:     Epoch: 82
2022-12-31 11:33:55,733 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4258944343775511, 'Total loss': 0.4258944343775511} | train loss {'Reaction outcome loss': 0.23024480342384934, 'Total loss': 0.23024480342384934}
2022-12-31 11:33:55,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:55,733 INFO:     Epoch: 83
2022-12-31 11:33:57,396 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4305405497550964, 'Total loss': 0.4305405497550964} | train loss {'Reaction outcome loss': 0.23172505668101265, 'Total loss': 0.23172505668101265}
2022-12-31 11:33:57,397 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:57,397 INFO:     Epoch: 84
2022-12-31 11:33:59,015 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44072431822617847, 'Total loss': 0.44072431822617847} | train loss {'Reaction outcome loss': 0.23153437929146964, 'Total loss': 0.23153437929146964}
2022-12-31 11:33:59,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:33:59,015 INFO:     Epoch: 85
2022-12-31 11:34:00,650 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43035354812939963, 'Total loss': 0.43035354812939963} | train loss {'Reaction outcome loss': 0.22502873410079358, 'Total loss': 0.22502873410079358}
2022-12-31 11:34:00,650 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:00,650 INFO:     Epoch: 86
2022-12-31 11:34:02,259 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3757291823625565, 'Total loss': 0.3757291823625565} | train loss {'Reaction outcome loss': 0.2264593045830765, 'Total loss': 0.2264593045830765}
2022-12-31 11:34:02,259 INFO:     Found new best model at epoch 86
2022-12-31 11:34:02,260 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:02,260 INFO:     Epoch: 87
2022-12-31 11:34:03,848 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.47547072966893517, 'Total loss': 0.47547072966893517} | train loss {'Reaction outcome loss': 0.2263945246560742, 'Total loss': 0.2263945246560742}
2022-12-31 11:34:03,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:03,849 INFO:     Epoch: 88
2022-12-31 11:34:05,458 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40686470170815786, 'Total loss': 0.40686470170815786} | train loss {'Reaction outcome loss': 0.24167477341509674, 'Total loss': 0.24167477341509674}
2022-12-31 11:34:05,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:05,458 INFO:     Epoch: 89
2022-12-31 11:34:07,069 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40033617814381917, 'Total loss': 0.40033617814381917} | train loss {'Reaction outcome loss': 0.22343240798100072, 'Total loss': 0.22343240798100072}
2022-12-31 11:34:07,070 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:07,070 INFO:     Epoch: 90
2022-12-31 11:34:08,657 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41827973574399946, 'Total loss': 0.41827973574399946} | train loss {'Reaction outcome loss': 0.23367648990149947, 'Total loss': 0.23367648990149947}
2022-12-31 11:34:08,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:08,657 INFO:     Epoch: 91
2022-12-31 11:34:10,277 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4001980851093928, 'Total loss': 0.4001980851093928} | train loss {'Reaction outcome loss': 0.23600330786860507, 'Total loss': 0.23600330786860507}
2022-12-31 11:34:10,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:10,277 INFO:     Epoch: 92
2022-12-31 11:34:11,908 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.44322369992733, 'Total loss': 0.44322369992733} | train loss {'Reaction outcome loss': 0.22357541258532074, 'Total loss': 0.22357541258532074}
2022-12-31 11:34:11,908 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:11,908 INFO:     Epoch: 93
2022-12-31 11:34:13,513 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4424105823040009, 'Total loss': 0.4424105823040009} | train loss {'Reaction outcome loss': 0.21732210164908253, 'Total loss': 0.21732210164908253}
2022-12-31 11:34:13,514 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:13,514 INFO:     Epoch: 94
2022-12-31 11:34:15,147 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42344608207543694, 'Total loss': 0.42344608207543694} | train loss {'Reaction outcome loss': 0.2183030192829682, 'Total loss': 0.2183030192829682}
2022-12-31 11:34:15,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:15,147 INFO:     Epoch: 95
2022-12-31 11:34:16,742 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4037356674671173, 'Total loss': 0.4037356674671173} | train loss {'Reaction outcome loss': 0.2208814470521748, 'Total loss': 0.2208814470521748}
2022-12-31 11:34:16,742 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:16,742 INFO:     Epoch: 96
2022-12-31 11:34:18,352 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4316931446393331, 'Total loss': 0.4316931446393331} | train loss {'Reaction outcome loss': 0.21776439501829464, 'Total loss': 0.21776439501829464}
2022-12-31 11:34:18,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:18,353 INFO:     Epoch: 97
2022-12-31 11:34:19,976 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4657564659913381, 'Total loss': 0.4657564659913381} | train loss {'Reaction outcome loss': 0.23108360368380512, 'Total loss': 0.23108360368380512}
2022-12-31 11:34:19,976 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:19,976 INFO:     Epoch: 98
2022-12-31 11:34:21,585 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4055421054363251, 'Total loss': 0.4055421054363251} | train loss {'Reaction outcome loss': 0.2670087660055446, 'Total loss': 0.2670087660055446}
2022-12-31 11:34:21,585 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:21,585 INFO:     Epoch: 99
2022-12-31 11:34:23,186 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41422275453805923, 'Total loss': 0.41422275453805923} | train loss {'Reaction outcome loss': 0.24019619074322796, 'Total loss': 0.24019619074322796}
2022-12-31 11:34:23,186 INFO:     Best model found after epoch 87 of 100.
2022-12-31 11:34:23,186 INFO:   Done with stage: TRAINING
2022-12-31 11:34:23,186 INFO:   Starting stage: EVALUATION
2022-12-31 11:34:23,313 INFO:   Done with stage: EVALUATION
2022-12-31 11:34:23,313 INFO:   Leaving out SEQ value Fold_6
2022-12-31 11:34:23,326 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 11:34:23,326 INFO:   Starting stage: FEATURE SCALING
2022-12-31 11:34:23,966 INFO:   Done with stage: FEATURE SCALING
2022-12-31 11:34:23,967 INFO:   Starting stage: SCALING TARGETS
2022-12-31 11:34:24,036 INFO:   Done with stage: SCALING TARGETS
2022-12-31 11:34:24,036 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:34:24,037 INFO:     No hyperparam tuning for this model
2022-12-31 11:34:24,037 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:34:24,037 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 11:34:24,037 INFO:     None feature selector for col prot
2022-12-31 11:34:24,037 INFO:     None feature selector for col prot
2022-12-31 11:34:24,038 INFO:     None feature selector for col prot
2022-12-31 11:34:24,038 INFO:     None feature selector for col chem
2022-12-31 11:34:24,038 INFO:     None feature selector for col chem
2022-12-31 11:34:24,038 INFO:     None feature selector for col chem
2022-12-31 11:34:24,038 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 11:34:24,038 INFO:   Starting stage: BUILD MODEL
2022-12-31 11:34:24,040 INFO:     Number of params in model 223921
2022-12-31 11:34:24,043 INFO:   Done with stage: BUILD MODEL
2022-12-31 11:34:24,043 INFO:   Starting stage: TRAINING
2022-12-31 11:34:24,088 INFO:     Val loss before train {'Reaction outcome loss': 1.0075806458791097, 'Total loss': 1.0075806458791097}
2022-12-31 11:34:24,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:24,088 INFO:     Epoch: 0
2022-12-31 11:34:25,681 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6737561007340749, 'Total loss': 0.6737561007340749} | train loss {'Reaction outcome loss': 0.8085077966671383, 'Total loss': 0.8085077966671383}
2022-12-31 11:34:25,682 INFO:     Found new best model at epoch 0
2022-12-31 11:34:25,682 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:25,683 INFO:     Epoch: 1
2022-12-31 11:34:27,322 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5351016004880269, 'Total loss': 0.5351016004880269} | train loss {'Reaction outcome loss': 0.5944920026872685, 'Total loss': 0.5944920026872685}
2022-12-31 11:34:27,324 INFO:     Found new best model at epoch 1
2022-12-31 11:34:27,324 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:27,325 INFO:     Epoch: 2
2022-12-31 11:34:28,968 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5077490389347077, 'Total loss': 0.5077490389347077} | train loss {'Reaction outcome loss': 0.530243611171381, 'Total loss': 0.530243611171381}
2022-12-31 11:34:28,968 INFO:     Found new best model at epoch 2
2022-12-31 11:34:28,969 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:28,969 INFO:     Epoch: 3
2022-12-31 11:34:30,626 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4890663782755534, 'Total loss': 0.4890663782755534} | train loss {'Reaction outcome loss': 0.5024441406333252, 'Total loss': 0.5024441406333252}
2022-12-31 11:34:30,626 INFO:     Found new best model at epoch 3
2022-12-31 11:34:30,627 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:30,627 INFO:     Epoch: 4
2022-12-31 11:34:32,236 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4866724928220113, 'Total loss': 0.4866724928220113} | train loss {'Reaction outcome loss': 0.48969362158685975, 'Total loss': 0.48969362158685975}
2022-12-31 11:34:32,236 INFO:     Found new best model at epoch 4
2022-12-31 11:34:32,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:32,237 INFO:     Epoch: 5
2022-12-31 11:34:33,848 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.46753690838813783, 'Total loss': 0.46753690838813783} | train loss {'Reaction outcome loss': 0.47431044795371563, 'Total loss': 0.47431044795371563}
2022-12-31 11:34:33,849 INFO:     Found new best model at epoch 5
2022-12-31 11:34:33,849 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:33,850 INFO:     Epoch: 6
2022-12-31 11:34:35,441 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4204761783281962, 'Total loss': 0.4204761783281962} | train loss {'Reaction outcome loss': 0.4629982785155381, 'Total loss': 0.4629982785155381}
2022-12-31 11:34:35,441 INFO:     Found new best model at epoch 6
2022-12-31 11:34:35,442 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:35,442 INFO:     Epoch: 7
2022-12-31 11:34:37,053 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43973327378431953, 'Total loss': 0.43973327378431953} | train loss {'Reaction outcome loss': 0.4590724304291433, 'Total loss': 0.4590724304291433}
2022-12-31 11:34:37,053 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:37,053 INFO:     Epoch: 8
2022-12-31 11:34:38,666 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4377053121725718, 'Total loss': 0.4377053121725718} | train loss {'Reaction outcome loss': 0.4565845648206617, 'Total loss': 0.4565845648206617}
2022-12-31 11:34:38,666 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:38,666 INFO:     Epoch: 9
2022-12-31 11:34:40,263 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44602685372034706, 'Total loss': 0.44602685372034706} | train loss {'Reaction outcome loss': 0.4449643359892408, 'Total loss': 0.4449643359892408}
2022-12-31 11:34:40,263 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:40,263 INFO:     Epoch: 10
2022-12-31 11:34:41,875 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41632867405811946, 'Total loss': 0.41632867405811946} | train loss {'Reaction outcome loss': 0.443367732985728, 'Total loss': 0.443367732985728}
2022-12-31 11:34:41,875 INFO:     Found new best model at epoch 10
2022-12-31 11:34:41,876 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:41,876 INFO:     Epoch: 11
2022-12-31 11:34:43,476 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41461288630962373, 'Total loss': 0.41461288630962373} | train loss {'Reaction outcome loss': 0.4334155491053842, 'Total loss': 0.4334155491053842}
2022-12-31 11:34:43,476 INFO:     Found new best model at epoch 11
2022-12-31 11:34:43,477 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:43,477 INFO:     Epoch: 12
2022-12-31 11:34:45,089 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41803484559059145, 'Total loss': 0.41803484559059145} | train loss {'Reaction outcome loss': 0.42697407022047706, 'Total loss': 0.42697407022047706}
2022-12-31 11:34:45,089 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:45,089 INFO:     Epoch: 13
2022-12-31 11:34:46,701 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4110290318727493, 'Total loss': 0.4110290318727493} | train loss {'Reaction outcome loss': 0.4222621792198523, 'Total loss': 0.4222621792198523}
2022-12-31 11:34:46,702 INFO:     Found new best model at epoch 13
2022-12-31 11:34:46,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:46,703 INFO:     Epoch: 14
2022-12-31 11:34:48,343 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4114567319552104, 'Total loss': 0.4114567319552104} | train loss {'Reaction outcome loss': 0.4197974614706228, 'Total loss': 0.4197974614706228}
2022-12-31 11:34:48,344 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:48,344 INFO:     Epoch: 15
2022-12-31 11:34:49,961 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42233239610989887, 'Total loss': 0.42233239610989887} | train loss {'Reaction outcome loss': 0.41279978896288766, 'Total loss': 0.41279978896288766}
2022-12-31 11:34:49,961 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:49,961 INFO:     Epoch: 16
2022-12-31 11:34:51,580 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.41232818067073823, 'Total loss': 0.41232818067073823} | train loss {'Reaction outcome loss': 0.40491258801160296, 'Total loss': 0.40491258801160296}
2022-12-31 11:34:51,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:51,580 INFO:     Epoch: 17
2022-12-31 11:34:53,194 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39739129443963367, 'Total loss': 0.39739129443963367} | train loss {'Reaction outcome loss': 0.39875686253451376, 'Total loss': 0.39875686253451376}
2022-12-31 11:34:53,195 INFO:     Found new best model at epoch 17
2022-12-31 11:34:53,195 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:53,196 INFO:     Epoch: 18
2022-12-31 11:34:54,795 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.38783054749170937, 'Total loss': 0.38783054749170937} | train loss {'Reaction outcome loss': 0.3945457191000679, 'Total loss': 0.3945457191000679}
2022-12-31 11:34:54,795 INFO:     Found new best model at epoch 18
2022-12-31 11:34:54,796 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:54,796 INFO:     Epoch: 19
2022-12-31 11:34:56,422 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3857713252305984, 'Total loss': 0.3857713252305984} | train loss {'Reaction outcome loss': 0.389975055655721, 'Total loss': 0.389975055655721}
2022-12-31 11:34:56,422 INFO:     Found new best model at epoch 19
2022-12-31 11:34:56,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:56,423 INFO:     Epoch: 20
2022-12-31 11:34:58,016 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.39388032754262287, 'Total loss': 0.39388032754262287} | train loss {'Reaction outcome loss': 0.38285784535379946, 'Total loss': 0.38285784535379946}
2022-12-31 11:34:58,016 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:58,016 INFO:     Epoch: 21
2022-12-31 11:34:59,624 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4083819667498271, 'Total loss': 0.4083819667498271} | train loss {'Reaction outcome loss': 0.37862852854026563, 'Total loss': 0.37862852854026563}
2022-12-31 11:34:59,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:34:59,624 INFO:     Epoch: 22
2022-12-31 11:35:01,228 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38554561535517373, 'Total loss': 0.38554561535517373} | train loss {'Reaction outcome loss': 0.3744994591479949, 'Total loss': 0.3744994591479949}
2022-12-31 11:35:01,229 INFO:     Found new best model at epoch 22
2022-12-31 11:35:01,229 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:01,230 INFO:     Epoch: 23
2022-12-31 11:35:02,817 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.38167448341846466, 'Total loss': 0.38167448341846466} | train loss {'Reaction outcome loss': 0.36729087590246295, 'Total loss': 0.36729087590246295}
2022-12-31 11:35:02,818 INFO:     Found new best model at epoch 23
2022-12-31 11:35:02,818 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:02,819 INFO:     Epoch: 24
2022-12-31 11:35:04,414 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4212278922398885, 'Total loss': 0.4212278922398885} | train loss {'Reaction outcome loss': 0.3628101925723309, 'Total loss': 0.3628101925723309}
2022-12-31 11:35:04,416 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:04,416 INFO:     Epoch: 25
2022-12-31 11:35:06,015 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46412609579662484, 'Total loss': 0.46412609579662484} | train loss {'Reaction outcome loss': 0.3617583568059448, 'Total loss': 0.3617583568059448}
2022-12-31 11:35:06,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:06,015 INFO:     Epoch: 26
2022-12-31 11:35:07,623 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3841107984383901, 'Total loss': 0.3841107984383901} | train loss {'Reaction outcome loss': 0.4369976993623203, 'Total loss': 0.4369976993623203}
2022-12-31 11:35:07,623 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:07,624 INFO:     Epoch: 27
2022-12-31 11:35:09,226 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4396788994471232, 'Total loss': 0.4396788994471232} | train loss {'Reaction outcome loss': 0.3686297200350226, 'Total loss': 0.3686297200350226}
2022-12-31 11:35:09,226 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:09,226 INFO:     Epoch: 28
2022-12-31 11:35:10,807 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3764486307899157, 'Total loss': 0.3764486307899157} | train loss {'Reaction outcome loss': 0.3599475764260759, 'Total loss': 0.3599475764260759}
2022-12-31 11:35:10,808 INFO:     Found new best model at epoch 28
2022-12-31 11:35:10,809 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:10,809 INFO:     Epoch: 29
2022-12-31 11:35:12,419 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.35986709396044414, 'Total loss': 0.35986709396044414} | train loss {'Reaction outcome loss': 0.34361113208359567, 'Total loss': 0.34361113208359567}
2022-12-31 11:35:12,419 INFO:     Found new best model at epoch 29
2022-12-31 11:35:12,420 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:12,420 INFO:     Epoch: 30
2022-12-31 11:35:14,021 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41006638407707213, 'Total loss': 0.41006638407707213} | train loss {'Reaction outcome loss': 0.3513903869990853, 'Total loss': 0.3513903869990853}
2022-12-31 11:35:14,021 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:14,021 INFO:     Epoch: 31
2022-12-31 11:35:15,622 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.38565946916739147, 'Total loss': 0.38565946916739147} | train loss {'Reaction outcome loss': 0.3648982964172635, 'Total loss': 0.3648982964172635}
2022-12-31 11:35:15,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:15,622 INFO:     Epoch: 32
2022-12-31 11:35:17,210 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.36470099687576296, 'Total loss': 0.36470099687576296} | train loss {'Reaction outcome loss': 0.3344020407188562, 'Total loss': 0.3344020407188562}
2022-12-31 11:35:17,210 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:17,210 INFO:     Epoch: 33
2022-12-31 11:35:18,812 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.37676038096348446, 'Total loss': 0.37676038096348446} | train loss {'Reaction outcome loss': 0.3263872834730242, 'Total loss': 0.3263872834730242}
2022-12-31 11:35:18,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:18,812 INFO:     Epoch: 34
2022-12-31 11:35:20,415 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38719797680775325, 'Total loss': 0.38719797680775325} | train loss {'Reaction outcome loss': 0.322517799407976, 'Total loss': 0.322517799407976}
2022-12-31 11:35:20,415 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:20,415 INFO:     Epoch: 35
2022-12-31 11:35:22,065 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.35314109871784843, 'Total loss': 0.35314109871784843} | train loss {'Reaction outcome loss': 0.31379766432919365, 'Total loss': 0.31379766432919365}
2022-12-31 11:35:22,065 INFO:     Found new best model at epoch 35
2022-12-31 11:35:22,066 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:22,066 INFO:     Epoch: 36
2022-12-31 11:35:23,677 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3856009383996328, 'Total loss': 0.3856009383996328} | train loss {'Reaction outcome loss': 0.32212432433405647, 'Total loss': 0.32212432433405647}
2022-12-31 11:35:23,678 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:23,678 INFO:     Epoch: 37
2022-12-31 11:35:25,265 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3611449273924033, 'Total loss': 0.3611449273924033} | train loss {'Reaction outcome loss': 0.313629577973979, 'Total loss': 0.313629577973979}
2022-12-31 11:35:25,265 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:25,266 INFO:     Epoch: 38
2022-12-31 11:35:26,919 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4033761858940125, 'Total loss': 0.4033761858940125} | train loss {'Reaction outcome loss': 0.31217404546729033, 'Total loss': 0.31217404546729033}
2022-12-31 11:35:26,919 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:26,919 INFO:     Epoch: 39
2022-12-31 11:35:28,528 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.35512291491031645, 'Total loss': 0.35512291491031645} | train loss {'Reaction outcome loss': 0.3011159285811448, 'Total loss': 0.3011159285811448}
2022-12-31 11:35:28,528 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:28,528 INFO:     Epoch: 40
2022-12-31 11:35:30,112 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3824470301469167, 'Total loss': 0.3824470301469167} | train loss {'Reaction outcome loss': 0.29574596481857507, 'Total loss': 0.29574596481857507}
2022-12-31 11:35:30,112 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:30,112 INFO:     Epoch: 41
2022-12-31 11:35:31,712 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.37565769056479137, 'Total loss': 0.37565769056479137} | train loss {'Reaction outcome loss': 0.29273611667525506, 'Total loss': 0.29273611667525506}
2022-12-31 11:35:31,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:31,712 INFO:     Epoch: 42
2022-12-31 11:35:33,312 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3966032028198242, 'Total loss': 0.3966032028198242} | train loss {'Reaction outcome loss': 0.29515406070066197, 'Total loss': 0.29515406070066197}
2022-12-31 11:35:33,312 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:33,312 INFO:     Epoch: 43
2022-12-31 11:35:34,907 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3811046818892161, 'Total loss': 0.3811046818892161} | train loss {'Reaction outcome loss': 0.29786491410239885, 'Total loss': 0.29786491410239885}
2022-12-31 11:35:34,907 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:34,907 INFO:     Epoch: 44
2022-12-31 11:35:36,509 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.39223973552385966, 'Total loss': 0.39223973552385966} | train loss {'Reaction outcome loss': 0.3064258121581667, 'Total loss': 0.3064258121581667}
2022-12-31 11:35:36,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:36,510 INFO:     Epoch: 45
2022-12-31 11:35:38,092 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3864799072345098, 'Total loss': 0.3864799072345098} | train loss {'Reaction outcome loss': 0.2920208930517074, 'Total loss': 0.2920208930517074}
2022-12-31 11:35:38,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:38,093 INFO:     Epoch: 46
2022-12-31 11:35:39,695 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3696238249540329, 'Total loss': 0.3696238249540329} | train loss {'Reaction outcome loss': 0.28372350673906616, 'Total loss': 0.28372350673906616}
2022-12-31 11:35:39,696 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:39,697 INFO:     Epoch: 47
2022-12-31 11:35:41,298 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.37699236869812014, 'Total loss': 0.37699236869812014} | train loss {'Reaction outcome loss': 0.276586636809201, 'Total loss': 0.276586636809201}
2022-12-31 11:35:41,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:41,299 INFO:     Epoch: 48
2022-12-31 11:35:42,887 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.37762883802254993, 'Total loss': 0.37762883802254993} | train loss {'Reaction outcome loss': 0.2714155860569166, 'Total loss': 0.2714155860569166}
2022-12-31 11:35:42,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:42,887 INFO:     Epoch: 49
2022-12-31 11:35:44,499 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3472917282332977, 'Total loss': 0.3472917282332977} | train loss {'Reaction outcome loss': 0.2707667760761873, 'Total loss': 0.2707667760761873}
2022-12-31 11:35:44,499 INFO:     Found new best model at epoch 49
2022-12-31 11:35:44,500 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:44,500 INFO:     Epoch: 50
2022-12-31 11:35:46,101 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40016288061936695, 'Total loss': 0.40016288061936695} | train loss {'Reaction outcome loss': 0.26635436122212897, 'Total loss': 0.26635436122212897}
2022-12-31 11:35:46,102 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:46,102 INFO:     Epoch: 51
2022-12-31 11:35:47,686 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40345122118790944, 'Total loss': 0.40345122118790944} | train loss {'Reaction outcome loss': 0.273227641183505, 'Total loss': 0.273227641183505}
2022-12-31 11:35:47,686 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:47,686 INFO:     Epoch: 52
2022-12-31 11:35:49,287 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.37722505927085875, 'Total loss': 0.37722505927085875} | train loss {'Reaction outcome loss': 0.30581821744546184, 'Total loss': 0.30581821744546184}
2022-12-31 11:35:49,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:49,287 INFO:     Epoch: 53
2022-12-31 11:35:50,888 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3993748754262924, 'Total loss': 0.3993748754262924} | train loss {'Reaction outcome loss': 0.26994654888867575, 'Total loss': 0.26994654888867575}
2022-12-31 11:35:50,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:50,889 INFO:     Epoch: 54
2022-12-31 11:35:52,495 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.38241345485051476, 'Total loss': 0.38241345485051476} | train loss {'Reaction outcome loss': 0.2665415792642676, 'Total loss': 0.2665415792642676}
2022-12-31 11:35:52,495 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:52,496 INFO:     Epoch: 55
2022-12-31 11:35:54,097 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3893657853205999, 'Total loss': 0.3893657853205999} | train loss {'Reaction outcome loss': 0.25766325932994916, 'Total loss': 0.25766325932994916}
2022-12-31 11:35:54,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:54,098 INFO:     Epoch: 56
2022-12-31 11:35:55,704 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.355922336379687, 'Total loss': 0.355922336379687} | train loss {'Reaction outcome loss': 0.25635378166733036, 'Total loss': 0.25635378166733036}
2022-12-31 11:35:55,704 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:55,704 INFO:     Epoch: 57
2022-12-31 11:35:56,793 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3805025358994802, 'Total loss': 0.3805025358994802} | train loss {'Reaction outcome loss': 0.252819897629324, 'Total loss': 0.252819897629324}
2022-12-31 11:35:56,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:56,793 INFO:     Epoch: 58
2022-12-31 11:35:57,874 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.37086230516433716, 'Total loss': 0.37086230516433716} | train loss {'Reaction outcome loss': 0.2528062517707493, 'Total loss': 0.2528062517707493}
2022-12-31 11:35:57,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:57,874 INFO:     Epoch: 59
2022-12-31 11:35:58,956 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.380725958943367, 'Total loss': 0.380725958943367} | train loss {'Reaction outcome loss': 0.2500077479874275, 'Total loss': 0.2500077479874275}
2022-12-31 11:35:58,957 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:35:58,957 INFO:     Epoch: 60
2022-12-31 11:36:00,045 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3617562492688497, 'Total loss': 0.3617562492688497} | train loss {'Reaction outcome loss': 0.25116481299282634, 'Total loss': 0.25116481299282634}
2022-12-31 11:36:00,045 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:00,045 INFO:     Epoch: 61
2022-12-31 11:36:01,622 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3948117166757584, 'Total loss': 0.3948117166757584} | train loss {'Reaction outcome loss': 0.24723505480991056, 'Total loss': 0.24723505480991056}
2022-12-31 11:36:01,622 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:01,622 INFO:     Epoch: 62
2022-12-31 11:36:03,231 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3945946718255679, 'Total loss': 0.3945946718255679} | train loss {'Reaction outcome loss': 0.24667313470559168, 'Total loss': 0.24667313470559168}
2022-12-31 11:36:03,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:03,231 INFO:     Epoch: 63
2022-12-31 11:36:04,839 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3600071549415588, 'Total loss': 0.3600071549415588} | train loss {'Reaction outcome loss': 0.24291485141831168, 'Total loss': 0.24291485141831168}
2022-12-31 11:36:04,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:04,839 INFO:     Epoch: 64
2022-12-31 11:36:06,448 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.372322686513265, 'Total loss': 0.372322686513265} | train loss {'Reaction outcome loss': 0.2457308906832359, 'Total loss': 0.2457308906832359}
2022-12-31 11:36:06,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:06,448 INFO:     Epoch: 65
2022-12-31 11:36:08,040 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.37751697401205697, 'Total loss': 0.37751697401205697} | train loss {'Reaction outcome loss': 0.2515633825239712, 'Total loss': 0.2515633825239712}
2022-12-31 11:36:08,040 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:08,040 INFO:     Epoch: 66
2022-12-31 11:36:09,637 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3901939272880554, 'Total loss': 0.3901939272880554} | train loss {'Reaction outcome loss': 0.35349266565796256, 'Total loss': 0.35349266565796256}
2022-12-31 11:36:09,638 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:09,638 INFO:     Epoch: 67
2022-12-31 11:36:11,254 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3802312324444453, 'Total loss': 0.3802312324444453} | train loss {'Reaction outcome loss': 0.27214059455582174, 'Total loss': 0.27214059455582174}
2022-12-31 11:36:11,255 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:11,255 INFO:     Epoch: 68
2022-12-31 11:36:12,864 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.33122464617093406, 'Total loss': 0.33122464617093406} | train loss {'Reaction outcome loss': 0.240922748806306, 'Total loss': 0.240922748806306}
2022-12-31 11:36:12,864 INFO:     Found new best model at epoch 68
2022-12-31 11:36:12,865 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:12,865 INFO:     Epoch: 69
2022-12-31 11:36:14,474 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.37791579763094585, 'Total loss': 0.37791579763094585} | train loss {'Reaction outcome loss': 0.2422682395123917, 'Total loss': 0.2422682395123917}
2022-12-31 11:36:14,474 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:14,474 INFO:     Epoch: 70
2022-12-31 11:36:16,084 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3591034859418869, 'Total loss': 0.3591034859418869} | train loss {'Reaction outcome loss': 0.24996946149073757, 'Total loss': 0.24996946149073757}
2022-12-31 11:36:16,084 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:16,084 INFO:     Epoch: 71
2022-12-31 11:36:17,682 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.37692955185969673, 'Total loss': 0.37692955185969673} | train loss {'Reaction outcome loss': 0.23615584745509652, 'Total loss': 0.23615584745509652}
2022-12-31 11:36:17,683 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:17,683 INFO:     Epoch: 72
2022-12-31 11:36:19,282 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3800018606086572, 'Total loss': 0.3800018606086572} | train loss {'Reaction outcome loss': 0.23084629762329775, 'Total loss': 0.23084629762329775}
2022-12-31 11:36:19,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:19,282 INFO:     Epoch: 73
2022-12-31 11:36:20,895 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.38461018800735475, 'Total loss': 0.38461018800735475} | train loss {'Reaction outcome loss': 0.23074396840040234, 'Total loss': 0.23074396840040234}
2022-12-31 11:36:20,896 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:20,896 INFO:     Epoch: 74
2022-12-31 11:36:22,510 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3826670326292515, 'Total loss': 0.3826670326292515} | train loss {'Reaction outcome loss': 0.22939766662708228, 'Total loss': 0.22939766662708228}
2022-12-31 11:36:22,510 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:22,510 INFO:     Epoch: 75
2022-12-31 11:36:24,124 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3859571119149526, 'Total loss': 0.3859571119149526} | train loss {'Reaction outcome loss': 0.22900931057050833, 'Total loss': 0.22900931057050833}
2022-12-31 11:36:24,124 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:24,124 INFO:     Epoch: 76
2022-12-31 11:36:25,716 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3846103092034658, 'Total loss': 0.3846103092034658} | train loss {'Reaction outcome loss': 0.22387291573260512, 'Total loss': 0.22387291573260512}
2022-12-31 11:36:25,716 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:25,716 INFO:     Epoch: 77
2022-12-31 11:36:27,310 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.36679044862588245, 'Total loss': 0.36679044862588245} | train loss {'Reaction outcome loss': 0.22577400390036928, 'Total loss': 0.22577400390036928}
2022-12-31 11:36:27,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:27,310 INFO:     Epoch: 78
2022-12-31 11:36:28,924 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3730593780676524, 'Total loss': 0.3730593780676524} | train loss {'Reaction outcome loss': 0.22246272326109634, 'Total loss': 0.22246272326109634}
2022-12-31 11:36:28,924 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:28,924 INFO:     Epoch: 79
2022-12-31 11:36:30,534 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3623722493648529, 'Total loss': 0.3623722493648529} | train loss {'Reaction outcome loss': 0.21959338937976744, 'Total loss': 0.21959338937976744}
2022-12-31 11:36:30,535 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:30,535 INFO:     Epoch: 80
2022-12-31 11:36:32,143 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3540295382340749, 'Total loss': 0.3540295382340749} | train loss {'Reaction outcome loss': 0.22743332891832982, 'Total loss': 0.22743332891832982}
2022-12-31 11:36:32,143 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:32,143 INFO:     Epoch: 81
2022-12-31 11:36:33,751 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3768417716026306, 'Total loss': 0.3768417716026306} | train loss {'Reaction outcome loss': 0.21444163195775362, 'Total loss': 0.21444163195775362}
2022-12-31 11:36:33,752 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:33,752 INFO:     Epoch: 82
2022-12-31 11:36:35,332 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.39491928815841676, 'Total loss': 0.39491928815841676} | train loss {'Reaction outcome loss': 0.22256545964763433, 'Total loss': 0.22256545964763433}
2022-12-31 11:36:35,332 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:35,332 INFO:     Epoch: 83
2022-12-31 11:36:36,951 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3467638780673345, 'Total loss': 0.3467638780673345} | train loss {'Reaction outcome loss': 0.22027263432012303, 'Total loss': 0.22027263432012303}
2022-12-31 11:36:36,952 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:36,952 INFO:     Epoch: 84
2022-12-31 11:36:38,605 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3561105628808339, 'Total loss': 0.3561105628808339} | train loss {'Reaction outcome loss': 0.22014721451441932, 'Total loss': 0.22014721451441932}
2022-12-31 11:36:38,605 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:38,605 INFO:     Epoch: 85
2022-12-31 11:36:40,236 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.362152436375618, 'Total loss': 0.362152436375618} | train loss {'Reaction outcome loss': 0.2137288282443162, 'Total loss': 0.2137288282443162}
2022-12-31 11:36:40,237 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:40,237 INFO:     Epoch: 86
2022-12-31 11:36:41,846 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3646101097265879, 'Total loss': 0.3646101097265879} | train loss {'Reaction outcome loss': 0.2103589725827434, 'Total loss': 0.2103589725827434}
2022-12-31 11:36:41,846 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:41,847 INFO:     Epoch: 87
2022-12-31 11:36:43,447 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.390876030921936, 'Total loss': 0.390876030921936} | train loss {'Reaction outcome loss': 0.21039526645251064, 'Total loss': 0.21039526645251064}
2022-12-31 11:36:43,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:43,448 INFO:     Epoch: 88
2022-12-31 11:36:45,046 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.39480165044466653, 'Total loss': 0.39480165044466653} | train loss {'Reaction outcome loss': 0.2226141299141328, 'Total loss': 0.2226141299141328}
2022-12-31 11:36:45,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:45,046 INFO:     Epoch: 89
2022-12-31 11:36:46,641 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.35973622898260754, 'Total loss': 0.35973622898260754} | train loss {'Reaction outcome loss': 0.2783249373711389, 'Total loss': 0.2783249373711389}
2022-12-31 11:36:46,642 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:46,642 INFO:     Epoch: 90
2022-12-31 11:36:48,250 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3616785407066345, 'Total loss': 0.3616785407066345} | train loss {'Reaction outcome loss': 0.2302293377727477, 'Total loss': 0.2302293377727477}
2022-12-31 11:36:48,251 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:48,251 INFO:     Epoch: 91
2022-12-31 11:36:49,860 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3726677060127258, 'Total loss': 0.3726677060127258} | train loss {'Reaction outcome loss': 0.22142574158024744, 'Total loss': 0.22142574158024744}
2022-12-31 11:36:49,860 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:49,861 INFO:     Epoch: 92
2022-12-31 11:36:51,472 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.37084382586181164, 'Total loss': 0.37084382586181164} | train loss {'Reaction outcome loss': 0.22005103158902045, 'Total loss': 0.22005103158902045}
2022-12-31 11:36:51,472 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:51,472 INFO:     Epoch: 93
2022-12-31 11:36:53,071 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.35296621918678284, 'Total loss': 0.35296621918678284} | train loss {'Reaction outcome loss': 0.2134370702922857, 'Total loss': 0.2134370702922857}
2022-12-31 11:36:53,071 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:53,072 INFO:     Epoch: 94
2022-12-31 11:36:54,667 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.34905915558338163, 'Total loss': 0.34905915558338163} | train loss {'Reaction outcome loss': 0.20891321124424617, 'Total loss': 0.20891321124424617}
2022-12-31 11:36:54,667 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:54,667 INFO:     Epoch: 95
2022-12-31 11:36:56,277 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3721049855152766, 'Total loss': 0.3721049855152766} | train loss {'Reaction outcome loss': 0.21207883627410384, 'Total loss': 0.21207883627410384}
2022-12-31 11:36:56,277 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:56,277 INFO:     Epoch: 96
2022-12-31 11:36:57,880 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.35845829447110494, 'Total loss': 0.35845829447110494} | train loss {'Reaction outcome loss': 0.2575465989783339, 'Total loss': 0.2575465989783339}
2022-12-31 11:36:57,880 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:57,880 INFO:     Epoch: 97
2022-12-31 11:36:59,484 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3859045038620631, 'Total loss': 0.3859045038620631} | train loss {'Reaction outcome loss': 0.22854592478361682, 'Total loss': 0.22854592478361682}
2022-12-31 11:36:59,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:36:59,484 INFO:     Epoch: 98
2022-12-31 11:37:01,088 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3838963687419891, 'Total loss': 0.3838963687419891} | train loss {'Reaction outcome loss': 0.22029651427452546, 'Total loss': 0.22029651427452546}
2022-12-31 11:37:01,088 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:01,088 INFO:     Epoch: 99
2022-12-31 11:37:02,673 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41013176341851554, 'Total loss': 0.41013176341851554} | train loss {'Reaction outcome loss': 0.2775915739973467, 'Total loss': 0.2775915739973467}
2022-12-31 11:37:02,674 INFO:     Best model found after epoch 69 of 100.
2022-12-31 11:37:02,674 INFO:   Done with stage: TRAINING
2022-12-31 11:37:02,674 INFO:   Starting stage: EVALUATION
2022-12-31 11:37:02,800 INFO:   Done with stage: EVALUATION
2022-12-31 11:37:02,801 INFO:   Leaving out SEQ value Fold_7
2022-12-31 11:37:02,813 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 11:37:02,813 INFO:   Starting stage: FEATURE SCALING
2022-12-31 11:37:03,464 INFO:   Done with stage: FEATURE SCALING
2022-12-31 11:37:03,464 INFO:   Starting stage: SCALING TARGETS
2022-12-31 11:37:03,535 INFO:   Done with stage: SCALING TARGETS
2022-12-31 11:37:03,535 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:37:03,535 INFO:     No hyperparam tuning for this model
2022-12-31 11:37:03,535 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:37:03,535 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 11:37:03,536 INFO:     None feature selector for col prot
2022-12-31 11:37:03,536 INFO:     None feature selector for col prot
2022-12-31 11:37:03,536 INFO:     None feature selector for col prot
2022-12-31 11:37:03,537 INFO:     None feature selector for col chem
2022-12-31 11:37:03,537 INFO:     None feature selector for col chem
2022-12-31 11:37:03,537 INFO:     None feature selector for col chem
2022-12-31 11:37:03,537 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 11:37:03,537 INFO:   Starting stage: BUILD MODEL
2022-12-31 11:37:03,539 INFO:     Number of params in model 223921
2022-12-31 11:37:03,542 INFO:   Done with stage: BUILD MODEL
2022-12-31 11:37:03,542 INFO:   Starting stage: TRAINING
2022-12-31 11:37:03,588 INFO:     Val loss before train {'Reaction outcome loss': 0.9460912624994914, 'Total loss': 0.9460912624994914}
2022-12-31 11:37:03,588 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:03,588 INFO:     Epoch: 0
2022-12-31 11:37:05,235 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6545550902684529, 'Total loss': 0.6545550902684529} | train loss {'Reaction outcome loss': 0.8059375384008841, 'Total loss': 0.8059375384008841}
2022-12-31 11:37:05,236 INFO:     Found new best model at epoch 0
2022-12-31 11:37:05,236 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:05,237 INFO:     Epoch: 1
2022-12-31 11:37:06,857 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.4971632460753123, 'Total loss': 0.4971632460753123} | train loss {'Reaction outcome loss': 0.5790553798206446, 'Total loss': 0.5790553798206446}
2022-12-31 11:37:06,858 INFO:     Found new best model at epoch 1
2022-12-31 11:37:06,858 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:06,859 INFO:     Epoch: 2
2022-12-31 11:37:08,504 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48750624656677244, 'Total loss': 0.48750624656677244} | train loss {'Reaction outcome loss': 0.5197674596029929, 'Total loss': 0.5197674596029929}
2022-12-31 11:37:08,504 INFO:     Found new best model at epoch 2
2022-12-31 11:37:08,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:08,505 INFO:     Epoch: 3
2022-12-31 11:37:10,117 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4761391659577688, 'Total loss': 0.4761391659577688} | train loss {'Reaction outcome loss': 0.4975399102760136, 'Total loss': 0.4975399102760136}
2022-12-31 11:37:10,118 INFO:     Found new best model at epoch 3
2022-12-31 11:37:10,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:10,119 INFO:     Epoch: 4
2022-12-31 11:37:11,715 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5170888384183248, 'Total loss': 0.5170888384183248} | train loss {'Reaction outcome loss': 0.48359473630624555, 'Total loss': 0.48359473630624555}
2022-12-31 11:37:11,715 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:11,716 INFO:     Epoch: 5
2022-12-31 11:37:13,308 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4867961972951889, 'Total loss': 0.4867961972951889} | train loss {'Reaction outcome loss': 0.4696842568122953, 'Total loss': 0.4696842568122953}
2022-12-31 11:37:13,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:13,308 INFO:     Epoch: 6
2022-12-31 11:37:14,913 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.456626262764136, 'Total loss': 0.456626262764136} | train loss {'Reaction outcome loss': 0.45507425833695203, 'Total loss': 0.45507425833695203}
2022-12-31 11:37:14,913 INFO:     Found new best model at epoch 6
2022-12-31 11:37:14,914 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:14,914 INFO:     Epoch: 7
2022-12-31 11:37:16,518 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46150422692298887, 'Total loss': 0.46150422692298887} | train loss {'Reaction outcome loss': 0.45090289306339376, 'Total loss': 0.45090289306339376}
2022-12-31 11:37:16,518 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:16,518 INFO:     Epoch: 8
2022-12-31 11:37:18,122 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4451885680357615, 'Total loss': 0.4451885680357615} | train loss {'Reaction outcome loss': 0.44523817228173523, 'Total loss': 0.44523817228173523}
2022-12-31 11:37:18,123 INFO:     Found new best model at epoch 8
2022-12-31 11:37:18,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:18,124 INFO:     Epoch: 9
2022-12-31 11:37:19,721 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4890160580476125, 'Total loss': 0.4890160580476125} | train loss {'Reaction outcome loss': 0.44059543575190463, 'Total loss': 0.44059543575190463}
2022-12-31 11:37:19,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:19,721 INFO:     Epoch: 10
2022-12-31 11:37:21,348 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45231601893901824, 'Total loss': 0.45231601893901824} | train loss {'Reaction outcome loss': 0.42725836208581064, 'Total loss': 0.42725836208581064}
2022-12-31 11:37:21,348 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:21,348 INFO:     Epoch: 11
2022-12-31 11:37:22,953 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45790964166323345, 'Total loss': 0.45790964166323345} | train loss {'Reaction outcome loss': 0.4287165050472163, 'Total loss': 0.4287165050472163}
2022-12-31 11:37:22,954 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:22,954 INFO:     Epoch: 12
2022-12-31 11:37:24,557 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4771275798479716, 'Total loss': 0.4771275798479716} | train loss {'Reaction outcome loss': 0.41640011748359523, 'Total loss': 0.41640011748359523}
2022-12-31 11:37:24,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:24,557 INFO:     Epoch: 13
2022-12-31 11:37:26,160 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45839135547478993, 'Total loss': 0.45839135547478993} | train loss {'Reaction outcome loss': 0.41271247112256093, 'Total loss': 0.41271247112256093}
2022-12-31 11:37:26,160 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:26,160 INFO:     Epoch: 14
2022-12-31 11:37:27,765 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4330510139465332, 'Total loss': 0.4330510139465332} | train loss {'Reaction outcome loss': 0.41164317990683474, 'Total loss': 0.41164317990683474}
2022-12-31 11:37:27,766 INFO:     Found new best model at epoch 14
2022-12-31 11:37:27,766 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:27,767 INFO:     Epoch: 15
2022-12-31 11:37:29,381 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.467364501953125, 'Total loss': 0.467364501953125} | train loss {'Reaction outcome loss': 0.40401051357549883, 'Total loss': 0.40401051357549883}
2022-12-31 11:37:29,381 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:29,381 INFO:     Epoch: 16
2022-12-31 11:37:30,988 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44056829710801443, 'Total loss': 0.44056829710801443} | train loss {'Reaction outcome loss': 0.39816875059144163, 'Total loss': 0.39816875059144163}
2022-12-31 11:37:30,988 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:30,988 INFO:     Epoch: 17
2022-12-31 11:37:32,596 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4699303408463796, 'Total loss': 0.4699303408463796} | train loss {'Reaction outcome loss': 0.39150247857351167, 'Total loss': 0.39150247857351167}
2022-12-31 11:37:32,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:32,596 INFO:     Epoch: 18
2022-12-31 11:37:34,202 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4781244119008382, 'Total loss': 0.4781244119008382} | train loss {'Reaction outcome loss': 0.38682638576745126, 'Total loss': 0.38682638576745126}
2022-12-31 11:37:34,202 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:34,202 INFO:     Epoch: 19
2022-12-31 11:37:35,808 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43818641106287637, 'Total loss': 0.43818641106287637} | train loss {'Reaction outcome loss': 0.38593080021198906, 'Total loss': 0.38593080021198906}
2022-12-31 11:37:35,808 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:35,808 INFO:     Epoch: 20
2022-12-31 11:37:37,401 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44133650958538057, 'Total loss': 0.44133650958538057} | train loss {'Reaction outcome loss': 0.38292110622574704, 'Total loss': 0.38292110622574704}
2022-12-31 11:37:37,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:37,401 INFO:     Epoch: 21
2022-12-31 11:37:38,995 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47845710317293805, 'Total loss': 0.47845710317293805} | train loss {'Reaction outcome loss': 0.3681545044406442, 'Total loss': 0.3681545044406442}
2022-12-31 11:37:38,996 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:38,996 INFO:     Epoch: 22
2022-12-31 11:37:40,636 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4613205432891846, 'Total loss': 0.4613205432891846} | train loss {'Reaction outcome loss': 0.36068688249652564, 'Total loss': 0.36068688249652564}
2022-12-31 11:37:40,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:40,636 INFO:     Epoch: 23
2022-12-31 11:37:42,286 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46090602775414785, 'Total loss': 0.46090602775414785} | train loss {'Reaction outcome loss': 0.3639242171380494, 'Total loss': 0.3639242171380494}
2022-12-31 11:37:42,287 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:42,287 INFO:     Epoch: 24
2022-12-31 11:37:43,921 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4133252521355947, 'Total loss': 0.4133252521355947} | train loss {'Reaction outcome loss': 0.35827589962994577, 'Total loss': 0.35827589962994577}
2022-12-31 11:37:43,921 INFO:     Found new best model at epoch 24
2022-12-31 11:37:43,922 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:43,922 INFO:     Epoch: 25
2022-12-31 11:37:45,529 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4333628435929616, 'Total loss': 0.4333628435929616} | train loss {'Reaction outcome loss': 0.34699045936661077, 'Total loss': 0.34699045936661077}
2022-12-31 11:37:45,529 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:45,529 INFO:     Epoch: 26
2022-12-31 11:37:47,130 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.460591126481692, 'Total loss': 0.460591126481692} | train loss {'Reaction outcome loss': 0.3449093086194476, 'Total loss': 0.3449093086194476}
2022-12-31 11:37:47,130 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:47,130 INFO:     Epoch: 27
2022-12-31 11:37:48,735 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4438392301400503, 'Total loss': 0.4438392301400503} | train loss {'Reaction outcome loss': 0.34255871959434087, 'Total loss': 0.34255871959434087}
2022-12-31 11:37:48,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:48,736 INFO:     Epoch: 28
2022-12-31 11:37:50,388 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.474779079357783, 'Total loss': 0.474779079357783} | train loss {'Reaction outcome loss': 0.3342695296725211, 'Total loss': 0.3342695296725211}
2022-12-31 11:37:50,388 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:50,388 INFO:     Epoch: 29
2022-12-31 11:37:52,047 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46093030174573263, 'Total loss': 0.46093030174573263} | train loss {'Reaction outcome loss': 0.33344687524147415, 'Total loss': 0.33344687524147415}
2022-12-31 11:37:52,047 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:52,047 INFO:     Epoch: 30
2022-12-31 11:37:53,703 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42910970548788707, 'Total loss': 0.42910970548788707} | train loss {'Reaction outcome loss': 0.3268332048874039, 'Total loss': 0.3268332048874039}
2022-12-31 11:37:53,703 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:53,704 INFO:     Epoch: 31
2022-12-31 11:37:55,303 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41609107901652653, 'Total loss': 0.41609107901652653} | train loss {'Reaction outcome loss': 0.3223357588886569, 'Total loss': 0.3223357588886569}
2022-12-31 11:37:55,303 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:55,303 INFO:     Epoch: 32
2022-12-31 11:37:56,906 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4521556571125984, 'Total loss': 0.4521556571125984} | train loss {'Reaction outcome loss': 0.3208283324346, 'Total loss': 0.3208283324346}
2022-12-31 11:37:56,906 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:56,906 INFO:     Epoch: 33
2022-12-31 11:37:58,504 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.48958790898323057, 'Total loss': 0.48958790898323057} | train loss {'Reaction outcome loss': 0.3139296618932421, 'Total loss': 0.3139296618932421}
2022-12-31 11:37:58,505 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:37:58,505 INFO:     Epoch: 34
2022-12-31 11:38:00,113 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44141795933246614, 'Total loss': 0.44141795933246614} | train loss {'Reaction outcome loss': 0.316632301005323, 'Total loss': 0.316632301005323}
2022-12-31 11:38:00,113 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:00,113 INFO:     Epoch: 35
2022-12-31 11:38:01,722 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42790331939856213, 'Total loss': 0.42790331939856213} | train loss {'Reaction outcome loss': 0.3075138622296416, 'Total loss': 0.3075138622296416}
2022-12-31 11:38:01,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:01,722 INFO:     Epoch: 36
2022-12-31 11:38:03,330 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44686885674794513, 'Total loss': 0.44686885674794513} | train loss {'Reaction outcome loss': 0.3033273964851341, 'Total loss': 0.3033273964851341}
2022-12-31 11:38:03,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:03,331 INFO:     Epoch: 37
2022-12-31 11:38:04,933 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4440485825141271, 'Total loss': 0.4440485825141271} | train loss {'Reaction outcome loss': 0.3039702722661547, 'Total loss': 0.3039702722661547}
2022-12-31 11:38:04,934 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:04,934 INFO:     Epoch: 38
2022-12-31 11:38:06,559 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4354053854942322, 'Total loss': 0.4354053854942322} | train loss {'Reaction outcome loss': 0.29660384814231405, 'Total loss': 0.29660384814231405}
2022-12-31 11:38:06,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:06,560 INFO:     Epoch: 39
2022-12-31 11:38:08,180 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45262070298194884, 'Total loss': 0.45262070298194884} | train loss {'Reaction outcome loss': 0.2963202096898418, 'Total loss': 0.2963202096898418}
2022-12-31 11:38:08,181 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:08,181 INFO:     Epoch: 40
2022-12-31 11:38:09,821 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.48245426813761394, 'Total loss': 0.48245426813761394} | train loss {'Reaction outcome loss': 0.2873847504761675, 'Total loss': 0.2873847504761675}
2022-12-31 11:38:09,821 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:09,821 INFO:     Epoch: 41
2022-12-31 11:38:11,432 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40528687040011085, 'Total loss': 0.40528687040011085} | train loss {'Reaction outcome loss': 0.2913451140161456, 'Total loss': 0.2913451140161456}
2022-12-31 11:38:11,432 INFO:     Found new best model at epoch 41
2022-12-31 11:38:11,433 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:11,433 INFO:     Epoch: 42
2022-12-31 11:38:13,093 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4600791911284129, 'Total loss': 0.4600791911284129} | train loss {'Reaction outcome loss': 0.29199489054105343, 'Total loss': 0.29199489054105343}
2022-12-31 11:38:13,093 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:13,093 INFO:     Epoch: 43
2022-12-31 11:38:14,674 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42433632810910543, 'Total loss': 0.42433632810910543} | train loss {'Reaction outcome loss': 0.2869132499240796, 'Total loss': 0.2869132499240796}
2022-12-31 11:38:14,674 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:14,674 INFO:     Epoch: 44
2022-12-31 11:38:16,298 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4688281774520874, 'Total loss': 0.4688281774520874} | train loss {'Reaction outcome loss': 0.2934195522743442, 'Total loss': 0.2934195522743442}
2022-12-31 11:38:16,298 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:16,298 INFO:     Epoch: 45
2022-12-31 11:38:17,966 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.45654416680335996, 'Total loss': 0.45654416680335996} | train loss {'Reaction outcome loss': 0.2785151033436994, 'Total loss': 0.2785151033436994}
2022-12-31 11:38:17,967 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:17,967 INFO:     Epoch: 46
2022-12-31 11:38:19,596 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44027468959490457, 'Total loss': 0.44027468959490457} | train loss {'Reaction outcome loss': 0.2803546667825229, 'Total loss': 0.2803546667825229}
2022-12-31 11:38:19,596 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:19,597 INFO:     Epoch: 47
2022-12-31 11:38:21,248 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4318318486213684, 'Total loss': 0.4318318486213684} | train loss {'Reaction outcome loss': 0.2727860670792282, 'Total loss': 0.2727860670792282}
2022-12-31 11:38:21,248 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:21,248 INFO:     Epoch: 48
2022-12-31 11:38:22,867 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.49223973552385963, 'Total loss': 0.49223973552385963} | train loss {'Reaction outcome loss': 0.2671599363242461, 'Total loss': 0.2671599363242461}
2022-12-31 11:38:22,867 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:22,867 INFO:     Epoch: 49
2022-12-31 11:38:24,463 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4162425716718038, 'Total loss': 0.4162425716718038} | train loss {'Reaction outcome loss': 0.2721907643177664, 'Total loss': 0.2721907643177664}
2022-12-31 11:38:24,463 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:24,463 INFO:     Epoch: 50
2022-12-31 11:38:26,125 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4472214192152023, 'Total loss': 0.4472214192152023} | train loss {'Reaction outcome loss': 0.2686637297326477, 'Total loss': 0.2686637297326477}
2022-12-31 11:38:26,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:26,125 INFO:     Epoch: 51
2022-12-31 11:38:27,787 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.46738893588383995, 'Total loss': 0.46738893588383995} | train loss {'Reaction outcome loss': 0.2608872119350769, 'Total loss': 0.2608872119350769}
2022-12-31 11:38:27,787 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:27,787 INFO:     Epoch: 52
2022-12-31 11:38:29,430 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4441579937934875, 'Total loss': 0.4441579937934875} | train loss {'Reaction outcome loss': 0.2636895159844457, 'Total loss': 0.2636895159844457}
2022-12-31 11:38:29,430 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:29,430 INFO:     Epoch: 53
2022-12-31 11:38:31,043 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.44282328089078266, 'Total loss': 0.44282328089078266} | train loss {'Reaction outcome loss': 0.26586823804230036, 'Total loss': 0.26586823804230036}
2022-12-31 11:38:31,043 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:31,043 INFO:     Epoch: 54
2022-12-31 11:38:32,660 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4509224275747935, 'Total loss': 0.4509224275747935} | train loss {'Reaction outcome loss': 0.25974811904051676, 'Total loss': 0.25974811904051676}
2022-12-31 11:38:32,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:32,660 INFO:     Epoch: 55
2022-12-31 11:38:34,288 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4463517745335897, 'Total loss': 0.4463517745335897} | train loss {'Reaction outcome loss': 0.26443001215046924, 'Total loss': 0.26443001215046924}
2022-12-31 11:38:34,290 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:34,290 INFO:     Epoch: 56
2022-12-31 11:38:35,900 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4194624125957489, 'Total loss': 0.4194624125957489} | train loss {'Reaction outcome loss': 0.2513400023056712, 'Total loss': 0.2513400023056712}
2022-12-31 11:38:35,900 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:35,900 INFO:     Epoch: 57
2022-12-31 11:38:37,556 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3961998502413432, 'Total loss': 0.3961998502413432} | train loss {'Reaction outcome loss': 0.25538895117784666, 'Total loss': 0.25538895117784666}
2022-12-31 11:38:37,556 INFO:     Found new best model at epoch 57
2022-12-31 11:38:37,557 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:37,557 INFO:     Epoch: 58
2022-12-31 11:38:39,170 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4374727338552475, 'Total loss': 0.4374727338552475} | train loss {'Reaction outcome loss': 0.24779587237682152, 'Total loss': 0.24779587237682152}
2022-12-31 11:38:39,170 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:39,170 INFO:     Epoch: 59
2022-12-31 11:38:40,771 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42844613591829933, 'Total loss': 0.42844613591829933} | train loss {'Reaction outcome loss': 0.2508987879064539, 'Total loss': 0.2508987879064539}
2022-12-31 11:38:40,772 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:40,772 INFO:     Epoch: 60
2022-12-31 11:38:42,407 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4376194116969903, 'Total loss': 0.4376194116969903} | train loss {'Reaction outcome loss': 0.2439284730057101, 'Total loss': 0.2439284730057101}
2022-12-31 11:38:42,407 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:42,407 INFO:     Epoch: 61
2022-12-31 11:38:44,013 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4490506152311961, 'Total loss': 0.4490506152311961} | train loss {'Reaction outcome loss': 0.24192183152755675, 'Total loss': 0.24192183152755675}
2022-12-31 11:38:44,013 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:44,013 INFO:     Epoch: 62
2022-12-31 11:38:45,630 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4275144318739573, 'Total loss': 0.4275144318739573} | train loss {'Reaction outcome loss': 0.23951138001917072, 'Total loss': 0.23951138001917072}
2022-12-31 11:38:45,630 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:45,631 INFO:     Epoch: 63
2022-12-31 11:38:47,246 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5065326338013013, 'Total loss': 0.5065326338013013} | train loss {'Reaction outcome loss': 0.23814909798950495, 'Total loss': 0.23814909798950495}
2022-12-31 11:38:47,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:47,247 INFO:     Epoch: 64
2022-12-31 11:38:48,863 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41203842759132386, 'Total loss': 0.41203842759132386} | train loss {'Reaction outcome loss': 0.23920361436096554, 'Total loss': 0.23920361436096554}
2022-12-31 11:38:48,863 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:48,863 INFO:     Epoch: 65
2022-12-31 11:38:50,473 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4688124438126882, 'Total loss': 0.4688124438126882} | train loss {'Reaction outcome loss': 0.24196797154763114, 'Total loss': 0.24196797154763114}
2022-12-31 11:38:50,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:50,473 INFO:     Epoch: 66
2022-12-31 11:38:52,082 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4611764043569565, 'Total loss': 0.4611764043569565} | train loss {'Reaction outcome loss': 0.2287266373244326, 'Total loss': 0.2287266373244326}
2022-12-31 11:38:52,082 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:52,083 INFO:     Epoch: 67
2022-12-31 11:38:53,694 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4397083471218745, 'Total loss': 0.4397083471218745} | train loss {'Reaction outcome loss': 0.23940979889745317, 'Total loss': 0.23940979889745317}
2022-12-31 11:38:53,694 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:53,695 INFO:     Epoch: 68
2022-12-31 11:38:55,304 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4589494456847509, 'Total loss': 0.4589494456847509} | train loss {'Reaction outcome loss': 0.22860624766252963, 'Total loss': 0.22860624766252963}
2022-12-31 11:38:55,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:55,305 INFO:     Epoch: 69
2022-12-31 11:38:56,930 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46755046844482423, 'Total loss': 0.46755046844482423} | train loss {'Reaction outcome loss': 0.22993449609565283, 'Total loss': 0.22993449609565283}
2022-12-31 11:38:56,930 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:56,930 INFO:     Epoch: 70
2022-12-31 11:38:58,531 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45197960337003074, 'Total loss': 0.45197960337003074} | train loss {'Reaction outcome loss': 0.23272160811867523, 'Total loss': 0.23272160811867523}
2022-12-31 11:38:58,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:38:58,531 INFO:     Epoch: 71
2022-12-31 11:39:00,145 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42482629815737405, 'Total loss': 0.42482629815737405} | train loss {'Reaction outcome loss': 0.2306994375460092, 'Total loss': 0.2306994375460092}
2022-12-31 11:39:00,145 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:00,146 INFO:     Epoch: 72
2022-12-31 11:39:01,757 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4447264105081558, 'Total loss': 0.4447264105081558} | train loss {'Reaction outcome loss': 0.23012137923403123, 'Total loss': 0.23012137923403123}
2022-12-31 11:39:01,757 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:01,757 INFO:     Epoch: 73
2022-12-31 11:39:03,369 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44073864420255027, 'Total loss': 0.44073864420255027} | train loss {'Reaction outcome loss': 0.23350881734553602, 'Total loss': 0.23350881734553602}
2022-12-31 11:39:03,369 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:03,369 INFO:     Epoch: 74
2022-12-31 11:39:04,980 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.43007551729679105, 'Total loss': 0.43007551729679105} | train loss {'Reaction outcome loss': 0.22683875582143934, 'Total loss': 0.22683875582143934}
2022-12-31 11:39:04,980 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:04,980 INFO:     Epoch: 75
2022-12-31 11:39:06,597 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.426171088218689, 'Total loss': 0.426171088218689} | train loss {'Reaction outcome loss': 0.2207811372052031, 'Total loss': 0.2207811372052031}
2022-12-31 11:39:06,597 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:06,597 INFO:     Epoch: 76
2022-12-31 11:39:08,203 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42470220327377317, 'Total loss': 0.42470220327377317} | train loss {'Reaction outcome loss': 0.2325718992857081, 'Total loss': 0.2325718992857081}
2022-12-31 11:39:08,203 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:08,203 INFO:     Epoch: 77
2022-12-31 11:39:09,792 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4090104838212331, 'Total loss': 0.4090104838212331} | train loss {'Reaction outcome loss': 0.22436429991551576, 'Total loss': 0.22436429991551576}
2022-12-31 11:39:09,793 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:09,793 INFO:     Epoch: 78
2022-12-31 11:39:11,389 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4455903093020121, 'Total loss': 0.4455903093020121} | train loss {'Reaction outcome loss': 0.22700393988014558, 'Total loss': 0.22700393988014558}
2022-12-31 11:39:11,389 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:11,389 INFO:     Epoch: 79
2022-12-31 11:39:13,025 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4247378428777059, 'Total loss': 0.4247378428777059} | train loss {'Reaction outcome loss': 0.21856290202870265, 'Total loss': 0.21856290202870265}
2022-12-31 11:39:13,025 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:13,025 INFO:     Epoch: 80
2022-12-31 11:39:14,641 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4039371838172277, 'Total loss': 0.4039371838172277} | train loss {'Reaction outcome loss': 0.22146845997617132, 'Total loss': 0.22146845997617132}
2022-12-31 11:39:14,641 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:14,641 INFO:     Epoch: 81
2022-12-31 11:39:16,257 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4544033149878184, 'Total loss': 0.4544033149878184} | train loss {'Reaction outcome loss': 0.22006206861310487, 'Total loss': 0.22006206861310487}
2022-12-31 11:39:16,257 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:16,257 INFO:     Epoch: 82
2022-12-31 11:39:17,858 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41805118024349214, 'Total loss': 0.41805118024349214} | train loss {'Reaction outcome loss': 0.2136834186101702, 'Total loss': 0.2136834186101702}
2022-12-31 11:39:17,859 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:17,859 INFO:     Epoch: 83
2022-12-31 11:39:19,481 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4820532351732254, 'Total loss': 0.4820532351732254} | train loss {'Reaction outcome loss': 0.22041361347271216, 'Total loss': 0.22041361347271216}
2022-12-31 11:39:19,481 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:19,481 INFO:     Epoch: 84
2022-12-31 11:39:21,147 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40695398471628624, 'Total loss': 0.40695398471628624} | train loss {'Reaction outcome loss': 0.22521612562561938, 'Total loss': 0.22521612562561938}
2022-12-31 11:39:21,147 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:21,147 INFO:     Epoch: 85
2022-12-31 11:39:22,804 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4271323397755623, 'Total loss': 0.4271323397755623} | train loss {'Reaction outcome loss': 0.2188608882215802, 'Total loss': 0.2188608882215802}
2022-12-31 11:39:22,804 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:22,804 INFO:     Epoch: 86
2022-12-31 11:39:24,464 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4708463728427887, 'Total loss': 0.4708463728427887} | train loss {'Reaction outcome loss': 0.2099709173476169, 'Total loss': 0.2099709173476169}
2022-12-31 11:39:24,464 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:24,465 INFO:     Epoch: 87
2022-12-31 11:39:26,098 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4080497185389201, 'Total loss': 0.4080497185389201} | train loss {'Reaction outcome loss': 0.21121346870175015, 'Total loss': 0.21121346870175015}
2022-12-31 11:39:26,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:26,098 INFO:     Epoch: 88
2022-12-31 11:39:27,750 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45642022490501405, 'Total loss': 0.45642022490501405} | train loss {'Reaction outcome loss': 0.20987467075755234, 'Total loss': 0.20987467075755234}
2022-12-31 11:39:27,750 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:27,750 INFO:     Epoch: 89
2022-12-31 11:39:29,350 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43718636135260264, 'Total loss': 0.43718636135260264} | train loss {'Reaction outcome loss': 0.21174215528414675, 'Total loss': 0.21174215528414675}
2022-12-31 11:39:29,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:29,350 INFO:     Epoch: 90
2022-12-31 11:39:30,964 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43950884640216825, 'Total loss': 0.43950884640216825} | train loss {'Reaction outcome loss': 0.20885406663163905, 'Total loss': 0.20885406663163905}
2022-12-31 11:39:30,964 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:30,964 INFO:     Epoch: 91
2022-12-31 11:39:32,579 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4219618725279967, 'Total loss': 0.4219618725279967} | train loss {'Reaction outcome loss': 0.20833824429028946, 'Total loss': 0.20833824429028946}
2022-12-31 11:39:32,579 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:32,580 INFO:     Epoch: 92
2022-12-31 11:39:34,194 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.455056760708491, 'Total loss': 0.455056760708491} | train loss {'Reaction outcome loss': 0.20663848109812297, 'Total loss': 0.20663848109812297}
2022-12-31 11:39:34,194 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:34,194 INFO:     Epoch: 93
2022-12-31 11:39:35,798 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48662146826585134, 'Total loss': 0.48662146826585134} | train loss {'Reaction outcome loss': 0.19990894447891075, 'Total loss': 0.19990894447891075}
2022-12-31 11:39:35,798 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:35,798 INFO:     Epoch: 94
2022-12-31 11:39:37,398 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48017159203688303, 'Total loss': 0.48017159203688303} | train loss {'Reaction outcome loss': 0.2052340013872738, 'Total loss': 0.2052340013872738}
2022-12-31 11:39:37,398 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:37,398 INFO:     Epoch: 95
2022-12-31 11:39:39,014 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45870821475982665, 'Total loss': 0.45870821475982665} | train loss {'Reaction outcome loss': 0.20466523681555468, 'Total loss': 0.20466523681555468}
2022-12-31 11:39:39,015 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:39,015 INFO:     Epoch: 96
2022-12-31 11:39:40,631 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4722709834575653, 'Total loss': 0.4722709834575653} | train loss {'Reaction outcome loss': 0.2144476451410068, 'Total loss': 0.2144476451410068}
2022-12-31 11:39:40,632 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:40,633 INFO:     Epoch: 97
2022-12-31 11:39:42,247 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4614233603080114, 'Total loss': 0.4614233603080114} | train loss {'Reaction outcome loss': 0.20853675598621585, 'Total loss': 0.20853675598621585}
2022-12-31 11:39:42,247 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:42,247 INFO:     Epoch: 98
2022-12-31 11:39:43,850 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.40600935618082684, 'Total loss': 0.40600935618082684} | train loss {'Reaction outcome loss': 0.21080815941364325, 'Total loss': 0.21080815941364325}
2022-12-31 11:39:43,850 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:43,850 INFO:     Epoch: 99
2022-12-31 11:39:45,467 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4641397714614868, 'Total loss': 0.4641397714614868} | train loss {'Reaction outcome loss': 0.21002592336695763, 'Total loss': 0.21002592336695763}
2022-12-31 11:39:45,467 INFO:     Best model found after epoch 58 of 100.
2022-12-31 11:39:45,467 INFO:   Done with stage: TRAINING
2022-12-31 11:39:45,467 INFO:   Starting stage: EVALUATION
2022-12-31 11:39:45,588 INFO:   Done with stage: EVALUATION
2022-12-31 11:39:45,588 INFO:   Leaving out SEQ value Fold_8
2022-12-31 11:39:45,600 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2022-12-31 11:39:45,600 INFO:   Starting stage: FEATURE SCALING
2022-12-31 11:39:46,246 INFO:   Done with stage: FEATURE SCALING
2022-12-31 11:39:46,247 INFO:   Starting stage: SCALING TARGETS
2022-12-31 11:39:46,317 INFO:   Done with stage: SCALING TARGETS
2022-12-31 11:39:46,317 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:39:46,317 INFO:     No hyperparam tuning for this model
2022-12-31 11:39:46,317 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:39:46,317 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 11:39:46,318 INFO:     None feature selector for col prot
2022-12-31 11:39:46,318 INFO:     None feature selector for col prot
2022-12-31 11:39:46,318 INFO:     None feature selector for col prot
2022-12-31 11:39:46,318 INFO:     None feature selector for col chem
2022-12-31 11:39:46,319 INFO:     None feature selector for col chem
2022-12-31 11:39:46,319 INFO:     None feature selector for col chem
2022-12-31 11:39:46,319 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 11:39:46,319 INFO:   Starting stage: BUILD MODEL
2022-12-31 11:39:46,320 INFO:     Number of params in model 223921
2022-12-31 11:39:46,324 INFO:   Done with stage: BUILD MODEL
2022-12-31 11:39:46,324 INFO:   Starting stage: TRAINING
2022-12-31 11:39:46,368 INFO:     Val loss before train {'Reaction outcome loss': 0.9342566053072612, 'Total loss': 0.9342566053072612}
2022-12-31 11:39:46,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:46,368 INFO:     Epoch: 0
2022-12-31 11:39:48,007 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.663305115699768, 'Total loss': 0.663305115699768} | train loss {'Reaction outcome loss': 0.833193051255567, 'Total loss': 0.833193051255567}
2022-12-31 11:39:48,008 INFO:     Found new best model at epoch 0
2022-12-31 11:39:48,009 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:48,009 INFO:     Epoch: 1
2022-12-31 11:39:49,656 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5535301585992177, 'Total loss': 0.5535301585992177} | train loss {'Reaction outcome loss': 0.6084296563472128, 'Total loss': 0.6084296563472128}
2022-12-31 11:39:49,657 INFO:     Found new best model at epoch 1
2022-12-31 11:39:49,657 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:49,658 INFO:     Epoch: 2
2022-12-31 11:39:51,335 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.48763890465100607, 'Total loss': 0.48763890465100607} | train loss {'Reaction outcome loss': 0.5319352618516137, 'Total loss': 0.5319352618516137}
2022-12-31 11:39:51,335 INFO:     Found new best model at epoch 2
2022-12-31 11:39:51,336 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:51,336 INFO:     Epoch: 3
2022-12-31 11:39:52,960 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4749610463778178, 'Total loss': 0.4749610463778178} | train loss {'Reaction outcome loss': 0.5043985278812987, 'Total loss': 0.5043985278812987}
2022-12-31 11:39:52,960 INFO:     Found new best model at epoch 3
2022-12-31 11:39:52,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:52,961 INFO:     Epoch: 4
2022-12-31 11:39:54,606 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49311439593633016, 'Total loss': 0.49311439593633016} | train loss {'Reaction outcome loss': 0.4931743542263654, 'Total loss': 0.4931743542263654}
2022-12-31 11:39:54,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:54,606 INFO:     Epoch: 5
2022-12-31 11:39:56,206 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4731824358304342, 'Total loss': 0.4731824358304342} | train loss {'Reaction outcome loss': 0.4840922798921055, 'Total loss': 0.4840922798921055}
2022-12-31 11:39:56,207 INFO:     Found new best model at epoch 5
2022-12-31 11:39:56,207 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:56,208 INFO:     Epoch: 6
2022-12-31 11:39:57,822 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48669893145561216, 'Total loss': 0.48669893145561216} | train loss {'Reaction outcome loss': 0.47202678734860265, 'Total loss': 0.47202678734860265}
2022-12-31 11:39:57,822 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:57,822 INFO:     Epoch: 7
2022-12-31 11:39:59,439 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4748927116394043, 'Total loss': 0.4748927116394043} | train loss {'Reaction outcome loss': 0.4648537327021038, 'Total loss': 0.4648537327021038}
2022-12-31 11:39:59,439 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:39:59,439 INFO:     Epoch: 8
2022-12-31 11:40:01,055 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4563117206096649, 'Total loss': 0.4563117206096649} | train loss {'Reaction outcome loss': 0.45458410075102473, 'Total loss': 0.45458410075102473}
2022-12-31 11:40:01,056 INFO:     Found new best model at epoch 8
2022-12-31 11:40:01,057 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:01,057 INFO:     Epoch: 9
2022-12-31 11:40:02,674 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4364054868618647, 'Total loss': 0.4364054868618647} | train loss {'Reaction outcome loss': 0.4496862482185398, 'Total loss': 0.4496862482185398}
2022-12-31 11:40:02,674 INFO:     Found new best model at epoch 9
2022-12-31 11:40:02,675 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:02,675 INFO:     Epoch: 10
2022-12-31 11:40:04,276 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.44425339897473654, 'Total loss': 0.44425339897473654} | train loss {'Reaction outcome loss': 0.43876970422181844, 'Total loss': 0.43876970422181844}
2022-12-31 11:40:04,276 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:04,276 INFO:     Epoch: 11
2022-12-31 11:40:05,891 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4508957117795944, 'Total loss': 0.4508957117795944} | train loss {'Reaction outcome loss': 0.43336085577088573, 'Total loss': 0.43336085577088573}
2022-12-31 11:40:05,892 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:05,892 INFO:     Epoch: 12
2022-12-31 11:40:07,505 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4215510874986649, 'Total loss': 0.4215510874986649} | train loss {'Reaction outcome loss': 0.42372503297047065, 'Total loss': 0.42372503297047065}
2022-12-31 11:40:07,505 INFO:     Found new best model at epoch 12
2022-12-31 11:40:07,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:07,506 INFO:     Epoch: 13
2022-12-31 11:40:09,120 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.479127562046051, 'Total loss': 0.479127562046051} | train loss {'Reaction outcome loss': 0.4226304888187333, 'Total loss': 0.4226304888187333}
2022-12-31 11:40:09,120 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:09,120 INFO:     Epoch: 14
2022-12-31 11:40:10,721 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43270522157351177, 'Total loss': 0.43270522157351177} | train loss {'Reaction outcome loss': 0.42597398465828773, 'Total loss': 0.42597398465828773}
2022-12-31 11:40:10,722 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:10,722 INFO:     Epoch: 15
2022-12-31 11:40:12,360 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.42320184806982675, 'Total loss': 0.42320184806982675} | train loss {'Reaction outcome loss': 0.413503503379839, 'Total loss': 0.413503503379839}
2022-12-31 11:40:12,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:12,360 INFO:     Epoch: 16
2022-12-31 11:40:13,989 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.46988735993703207, 'Total loss': 0.46988735993703207} | train loss {'Reaction outcome loss': 0.4015334344835488, 'Total loss': 0.4015334344835488}
2022-12-31 11:40:13,989 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:13,989 INFO:     Epoch: 17
2022-12-31 11:40:15,651 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40820862352848053, 'Total loss': 0.40820862352848053} | train loss {'Reaction outcome loss': 0.4031890825997191, 'Total loss': 0.4031890825997191}
2022-12-31 11:40:15,652 INFO:     Found new best model at epoch 17
2022-12-31 11:40:15,653 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:15,653 INFO:     Epoch: 18
2022-12-31 11:40:17,324 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.38330237070719403, 'Total loss': 0.38330237070719403} | train loss {'Reaction outcome loss': 0.39614205247981454, 'Total loss': 0.39614205247981454}
2022-12-31 11:40:17,324 INFO:     Found new best model at epoch 18
2022-12-31 11:40:17,325 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:17,325 INFO:     Epoch: 19
2022-12-31 11:40:18,960 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.405265544851621, 'Total loss': 0.405265544851621} | train loss {'Reaction outcome loss': 0.38434977869802434, 'Total loss': 0.38434977869802434}
2022-12-31 11:40:18,960 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:18,961 INFO:     Epoch: 20
2022-12-31 11:40:20,583 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.38634162247180937, 'Total loss': 0.38634162247180937} | train loss {'Reaction outcome loss': 0.3828537233093155, 'Total loss': 0.3828537233093155}
2022-12-31 11:40:20,584 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:20,584 INFO:     Epoch: 21
2022-12-31 11:40:22,180 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3900222112735113, 'Total loss': 0.3900222112735113} | train loss {'Reaction outcome loss': 0.37764730568074145, 'Total loss': 0.37764730568074145}
2022-12-31 11:40:22,180 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:22,180 INFO:     Epoch: 22
2022-12-31 11:40:23,812 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.41924013396104176, 'Total loss': 0.41924013396104176} | train loss {'Reaction outcome loss': 0.36684114163210246, 'Total loss': 0.36684114163210246}
2022-12-31 11:40:23,812 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:23,812 INFO:     Epoch: 23
2022-12-31 11:40:25,427 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3791952093442281, 'Total loss': 0.3791952093442281} | train loss {'Reaction outcome loss': 0.3647923311117754, 'Total loss': 0.3647923311117754}
2022-12-31 11:40:25,427 INFO:     Found new best model at epoch 23
2022-12-31 11:40:25,428 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:25,428 INFO:     Epoch: 24
2022-12-31 11:40:27,041 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4195165028174718, 'Total loss': 0.4195165028174718} | train loss {'Reaction outcome loss': 0.359315799569395, 'Total loss': 0.359315799569395}
2022-12-31 11:40:27,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:27,041 INFO:     Epoch: 25
2022-12-31 11:40:28,655 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.35051878641049067, 'Total loss': 0.35051878641049067} | train loss {'Reaction outcome loss': 0.35071521733857236, 'Total loss': 0.35071521733857236}
2022-12-31 11:40:28,655 INFO:     Found new best model at epoch 25
2022-12-31 11:40:28,656 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:28,656 INFO:     Epoch: 26
2022-12-31 11:40:30,259 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.38047557274500526, 'Total loss': 0.38047557274500526} | train loss {'Reaction outcome loss': 0.3511639233100285, 'Total loss': 0.3511639233100285}
2022-12-31 11:40:30,259 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:30,259 INFO:     Epoch: 27
2022-12-31 11:40:31,863 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.37257794936498007, 'Total loss': 0.37257794936498007} | train loss {'Reaction outcome loss': 0.34620306037016724, 'Total loss': 0.34620306037016724}
2022-12-31 11:40:31,864 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:31,864 INFO:     Epoch: 28
2022-12-31 11:40:33,479 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4031503503521284, 'Total loss': 0.4031503503521284} | train loss {'Reaction outcome loss': 0.3394778393989005, 'Total loss': 0.3394778393989005}
2022-12-31 11:40:33,479 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:33,479 INFO:     Epoch: 29
2022-12-31 11:40:35,094 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3709407369295756, 'Total loss': 0.3709407369295756} | train loss {'Reaction outcome loss': 0.33480063158790124, 'Total loss': 0.33480063158790124}
2022-12-31 11:40:35,095 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:35,095 INFO:     Epoch: 30
2022-12-31 11:40:36,708 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3471743851900101, 'Total loss': 0.3471743851900101} | train loss {'Reaction outcome loss': 0.3320859222528306, 'Total loss': 0.3320859222528306}
2022-12-31 11:40:36,709 INFO:     Found new best model at epoch 30
2022-12-31 11:40:36,709 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:36,710 INFO:     Epoch: 31
2022-12-31 11:40:38,167 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.35960446993509926, 'Total loss': 0.35960446993509926} | train loss {'Reaction outcome loss': 0.3217895192628733, 'Total loss': 0.3217895192628733}
2022-12-31 11:40:38,167 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:38,167 INFO:     Epoch: 32
2022-12-31 11:40:39,249 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3824040204286575, 'Total loss': 0.3824040204286575} | train loss {'Reaction outcome loss': 0.3202451483921454, 'Total loss': 0.3202451483921454}
2022-12-31 11:40:39,250 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:39,250 INFO:     Epoch: 33
2022-12-31 11:40:40,327 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.36411485572655994, 'Total loss': 0.36411485572655994} | train loss {'Reaction outcome loss': 0.31669089699749053, 'Total loss': 0.31669089699749053}
2022-12-31 11:40:40,327 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:40,327 INFO:     Epoch: 34
2022-12-31 11:40:41,400 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3622578352689743, 'Total loss': 0.3622578352689743} | train loss {'Reaction outcome loss': 0.3103668820314674, 'Total loss': 0.3103668820314674}
2022-12-31 11:40:41,401 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:41,401 INFO:     Epoch: 35
2022-12-31 11:40:42,531 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3646601667006811, 'Total loss': 0.3646601667006811} | train loss {'Reaction outcome loss': 0.30724044637048503, 'Total loss': 0.30724044637048503}
2022-12-31 11:40:42,531 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:42,531 INFO:     Epoch: 36
2022-12-31 11:40:44,142 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.36502165148655574, 'Total loss': 0.36502165148655574} | train loss {'Reaction outcome loss': 0.29925668376097825, 'Total loss': 0.29925668376097825}
2022-12-31 11:40:44,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:44,142 INFO:     Epoch: 37
2022-12-31 11:40:45,759 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.34182879676421485, 'Total loss': 0.34182879676421485} | train loss {'Reaction outcome loss': 0.2963727375606768, 'Total loss': 0.2963727375606768}
2022-12-31 11:40:45,759 INFO:     Found new best model at epoch 37
2022-12-31 11:40:45,760 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:45,760 INFO:     Epoch: 38
2022-12-31 11:40:47,368 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4376508891582489, 'Total loss': 0.4376508891582489} | train loss {'Reaction outcome loss': 0.2939091241424264, 'Total loss': 0.2939091241424264}
2022-12-31 11:40:47,368 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:47,368 INFO:     Epoch: 39
2022-12-31 11:40:49,001 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.34048300286134087, 'Total loss': 0.34048300286134087} | train loss {'Reaction outcome loss': 0.3008887671499046, 'Total loss': 0.3008887671499046}
2022-12-31 11:40:49,001 INFO:     Found new best model at epoch 39
2022-12-31 11:40:49,002 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:49,002 INFO:     Epoch: 40
2022-12-31 11:40:50,618 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3695515632629395, 'Total loss': 0.3695515632629395} | train loss {'Reaction outcome loss': 0.2833936308856906, 'Total loss': 0.2833936308856906}
2022-12-31 11:40:50,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:50,618 INFO:     Epoch: 41
2022-12-31 11:40:52,215 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3433321843544642, 'Total loss': 0.3433321843544642} | train loss {'Reaction outcome loss': 0.28322313400489757, 'Total loss': 0.28322313400489757}
2022-12-31 11:40:52,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:52,217 INFO:     Epoch: 42
2022-12-31 11:40:53,832 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3447928378979365, 'Total loss': 0.3447928378979365} | train loss {'Reaction outcome loss': 0.28070424150151035, 'Total loss': 0.28070424150151035}
2022-12-31 11:40:53,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:53,832 INFO:     Epoch: 43
2022-12-31 11:40:55,448 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3396581053733826, 'Total loss': 0.3396581053733826} | train loss {'Reaction outcome loss': 0.2756775567839292, 'Total loss': 0.2756775567839292}
2022-12-31 11:40:55,448 INFO:     Found new best model at epoch 43
2022-12-31 11:40:55,449 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:55,449 INFO:     Epoch: 44
2022-12-31 11:40:57,041 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.333357631166776, 'Total loss': 0.333357631166776} | train loss {'Reaction outcome loss': 0.27790408832986, 'Total loss': 0.27790408832986}
2022-12-31 11:40:57,041 INFO:     Found new best model at epoch 44
2022-12-31 11:40:57,041 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:57,042 INFO:     Epoch: 45
2022-12-31 11:40:58,656 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.33659324248631795, 'Total loss': 0.33659324248631795} | train loss {'Reaction outcome loss': 0.2760359826985249, 'Total loss': 0.2760359826985249}
2022-12-31 11:40:58,656 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:40:58,657 INFO:     Epoch: 46
2022-12-31 11:41:00,269 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.35845274329185484, 'Total loss': 0.35845274329185484} | train loss {'Reaction outcome loss': 0.2718147328426046, 'Total loss': 0.2718147328426046}
2022-12-31 11:41:00,270 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:00,270 INFO:     Epoch: 47
2022-12-31 11:41:01,911 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.34851132531960805, 'Total loss': 0.34851132531960805} | train loss {'Reaction outcome loss': 0.2690294661125444, 'Total loss': 0.2690294661125444}
2022-12-31 11:41:01,911 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:01,911 INFO:     Epoch: 48
2022-12-31 11:41:03,542 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3516386439402898, 'Total loss': 0.3516386439402898} | train loss {'Reaction outcome loss': 0.2675149024191854, 'Total loss': 0.2675149024191854}
2022-12-31 11:41:03,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:03,542 INFO:     Epoch: 49
2022-12-31 11:41:05,138 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3639269083738327, 'Total loss': 0.3639269083738327} | train loss {'Reaction outcome loss': 0.26411245893754254, 'Total loss': 0.26411245893754254}
2022-12-31 11:41:05,138 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:05,138 INFO:     Epoch: 50
2022-12-31 11:41:06,756 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.36011149833599726, 'Total loss': 0.36011149833599726} | train loss {'Reaction outcome loss': 0.2588292696523322, 'Total loss': 0.2588292696523322}
2022-12-31 11:41:06,756 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:06,756 INFO:     Epoch: 51
2022-12-31 11:41:08,374 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.33800288240114845, 'Total loss': 0.33800288240114845} | train loss {'Reaction outcome loss': 0.2610128061973661, 'Total loss': 0.2610128061973661}
2022-12-31 11:41:08,374 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:08,374 INFO:     Epoch: 52
2022-12-31 11:41:09,975 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.37326933244864147, 'Total loss': 0.37326933244864147} | train loss {'Reaction outcome loss': 0.2589478674025312, 'Total loss': 0.2589478674025312}
2022-12-31 11:41:09,975 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:09,976 INFO:     Epoch: 53
2022-12-31 11:41:11,608 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.32700137197971346, 'Total loss': 0.32700137197971346} | train loss {'Reaction outcome loss': 0.25226797047155214, 'Total loss': 0.25226797047155214}
2022-12-31 11:41:11,608 INFO:     Found new best model at epoch 53
2022-12-31 11:41:11,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:11,609 INFO:     Epoch: 54
2022-12-31 11:41:13,243 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3706640015045802, 'Total loss': 0.3706640015045802} | train loss {'Reaction outcome loss': 0.26083813190782973, 'Total loss': 0.26083813190782973}
2022-12-31 11:41:13,244 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:13,244 INFO:     Epoch: 55
2022-12-31 11:41:14,878 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3370920191208521, 'Total loss': 0.3370920191208521} | train loss {'Reaction outcome loss': 0.2535316774500568, 'Total loss': 0.2535316774500568}
2022-12-31 11:41:14,878 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:14,878 INFO:     Epoch: 56
2022-12-31 11:41:16,549 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.35410592903693516, 'Total loss': 0.35410592903693516} | train loss {'Reaction outcome loss': 0.24891906527513202, 'Total loss': 0.24891906527513202}
2022-12-31 11:41:16,549 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:16,549 INFO:     Epoch: 57
2022-12-31 11:41:18,187 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3275648166735967, 'Total loss': 0.3275648166735967} | train loss {'Reaction outcome loss': 0.2516479030897041, 'Total loss': 0.2516479030897041}
2022-12-31 11:41:18,187 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:18,188 INFO:     Epoch: 58
2022-12-31 11:41:19,820 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3742656459410985, 'Total loss': 0.3742656459410985} | train loss {'Reaction outcome loss': 0.24813200062685495, 'Total loss': 0.24813200062685495}
2022-12-31 11:41:19,820 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:19,820 INFO:     Epoch: 59
2022-12-31 11:41:21,491 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3591185142596563, 'Total loss': 0.3591185142596563} | train loss {'Reaction outcome loss': 0.24209251556047895, 'Total loss': 0.24209251556047895}
2022-12-31 11:41:21,491 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:21,491 INFO:     Epoch: 60
2022-12-31 11:41:23,141 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.34216733773549396, 'Total loss': 0.34216733773549396} | train loss {'Reaction outcome loss': 0.24821769123365733, 'Total loss': 0.24821769123365733}
2022-12-31 11:41:23,142 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:23,142 INFO:     Epoch: 61
2022-12-31 11:41:24,755 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.33971970081329345, 'Total loss': 0.33971970081329345} | train loss {'Reaction outcome loss': 0.24120254330471536, 'Total loss': 0.24120254330471536}
2022-12-31 11:41:24,755 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:24,755 INFO:     Epoch: 62
2022-12-31 11:41:26,379 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.34198826005061467, 'Total loss': 0.34198826005061467} | train loss {'Reaction outcome loss': 0.2358860440135325, 'Total loss': 0.2358860440135325}
2022-12-31 11:41:26,379 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:26,379 INFO:     Epoch: 63
2022-12-31 11:41:27,986 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.34579778810342154, 'Total loss': 0.34579778810342154} | train loss {'Reaction outcome loss': 0.23617872202412532, 'Total loss': 0.23617872202412532}
2022-12-31 11:41:27,986 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:27,986 INFO:     Epoch: 64
2022-12-31 11:41:29,652 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3464288145303726, 'Total loss': 0.3464288145303726} | train loss {'Reaction outcome loss': 0.23533633489847613, 'Total loss': 0.23533633489847613}
2022-12-31 11:41:29,652 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:29,653 INFO:     Epoch: 65
2022-12-31 11:41:31,274 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.347632293899854, 'Total loss': 0.347632293899854} | train loss {'Reaction outcome loss': 0.2395837824616837, 'Total loss': 0.2395837824616837}
2022-12-31 11:41:31,274 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:31,274 INFO:     Epoch: 66
2022-12-31 11:41:32,888 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.37132694820563, 'Total loss': 0.37132694820563} | train loss {'Reaction outcome loss': 0.23394868321488158, 'Total loss': 0.23394868321488158}
2022-12-31 11:41:32,888 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:32,888 INFO:     Epoch: 67
2022-12-31 11:41:34,505 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3226565649112066, 'Total loss': 0.3226565649112066} | train loss {'Reaction outcome loss': 0.23304337986647436, 'Total loss': 0.23304337986647436}
2022-12-31 11:41:34,505 INFO:     Found new best model at epoch 67
2022-12-31 11:41:34,506 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:34,506 INFO:     Epoch: 68
2022-12-31 11:41:36,182 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.33239090541998545, 'Total loss': 0.33239090541998545} | train loss {'Reaction outcome loss': 0.2382568968560829, 'Total loss': 0.2382568968560829}
2022-12-31 11:41:36,182 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:36,182 INFO:     Epoch: 69
2022-12-31 11:41:37,790 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.34283296366532645, 'Total loss': 0.34283296366532645} | train loss {'Reaction outcome loss': 0.2308323448960962, 'Total loss': 0.2308323448960962}
2022-12-31 11:41:37,790 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:37,790 INFO:     Epoch: 70
2022-12-31 11:41:39,411 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.37457178235054017, 'Total loss': 0.37457178235054017} | train loss {'Reaction outcome loss': 0.22713940799074914, 'Total loss': 0.22713940799074914}
2022-12-31 11:41:39,412 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:39,412 INFO:     Epoch: 71
2022-12-31 11:41:41,056 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.34636257390181224, 'Total loss': 0.34636257390181224} | train loss {'Reaction outcome loss': 0.23516895654964318, 'Total loss': 0.23516895654964318}
2022-12-31 11:41:41,057 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:41,057 INFO:     Epoch: 72
2022-12-31 11:41:42,658 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3650334085027377, 'Total loss': 0.3650334085027377} | train loss {'Reaction outcome loss': 0.2265704485692003, 'Total loss': 0.2265704485692003}
2022-12-31 11:41:42,659 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:42,659 INFO:     Epoch: 73
2022-12-31 11:41:44,279 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.30732357800006865, 'Total loss': 0.30732357800006865} | train loss {'Reaction outcome loss': 0.2236969764226718, 'Total loss': 0.2236969764226718}
2022-12-31 11:41:44,279 INFO:     Found new best model at epoch 73
2022-12-31 11:41:44,280 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:44,280 INFO:     Epoch: 74
2022-12-31 11:41:45,897 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3257917158305645, 'Total loss': 0.3257917158305645} | train loss {'Reaction outcome loss': 0.22053586526198937, 'Total loss': 0.22053586526198937}
2022-12-31 11:41:45,897 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:45,897 INFO:     Epoch: 75
2022-12-31 11:41:47,503 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.36707113981246947, 'Total loss': 0.36707113981246947} | train loss {'Reaction outcome loss': 0.21720005590670374, 'Total loss': 0.21720005590670374}
2022-12-31 11:41:47,504 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:47,504 INFO:     Epoch: 76
2022-12-31 11:41:49,125 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3169641410311063, 'Total loss': 0.3169641410311063} | train loss {'Reaction outcome loss': 0.2210505066257952, 'Total loss': 0.2210505066257952}
2022-12-31 11:41:49,125 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:49,125 INFO:     Epoch: 77
2022-12-31 11:41:50,727 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.32647348841031393, 'Total loss': 0.32647348841031393} | train loss {'Reaction outcome loss': 0.2179487313241412, 'Total loss': 0.2179487313241412}
2022-12-31 11:41:50,727 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:50,727 INFO:     Epoch: 78
2022-12-31 11:41:52,360 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3331277668476105, 'Total loss': 0.3331277668476105} | train loss {'Reaction outcome loss': 0.22570531289446225, 'Total loss': 0.22570531289446225}
2022-12-31 11:41:52,360 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:52,360 INFO:     Epoch: 79
2022-12-31 11:41:53,981 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.34917551577091216, 'Total loss': 0.34917551577091216} | train loss {'Reaction outcome loss': 0.21209567956734005, 'Total loss': 0.21209567956734005}
2022-12-31 11:41:53,981 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:53,981 INFO:     Epoch: 80
2022-12-31 11:41:55,594 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.36449718475341797, 'Total loss': 0.36449718475341797} | train loss {'Reaction outcome loss': 0.22286711927731975, 'Total loss': 0.22286711927731975}
2022-12-31 11:41:55,595 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:55,595 INFO:     Epoch: 81
2022-12-31 11:41:57,216 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.33177940050760907, 'Total loss': 0.33177940050760907} | train loss {'Reaction outcome loss': 0.21489617676349754, 'Total loss': 0.21489617676349754}
2022-12-31 11:41:57,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:57,217 INFO:     Epoch: 82
2022-12-31 11:41:58,838 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.34022003213564556, 'Total loss': 0.34022003213564556} | train loss {'Reaction outcome loss': 0.22169567622405742, 'Total loss': 0.22169567622405742}
2022-12-31 11:41:58,839 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:41:58,839 INFO:     Epoch: 83
2022-12-31 11:42:00,458 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.31574330031871795, 'Total loss': 0.31574330031871795} | train loss {'Reaction outcome loss': 0.21067280530768182, 'Total loss': 0.21067280530768182}
2022-12-31 11:42:00,458 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:00,458 INFO:     Epoch: 84
2022-12-31 11:42:02,078 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.326020273566246, 'Total loss': 0.326020273566246} | train loss {'Reaction outcome loss': 0.21450264400900057, 'Total loss': 0.21450264400900057}
2022-12-31 11:42:02,079 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:02,079 INFO:     Epoch: 85
2022-12-31 11:42:03,702 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3256016214688619, 'Total loss': 0.3256016214688619} | train loss {'Reaction outcome loss': 0.21249703601648232, 'Total loss': 0.21249703601648232}
2022-12-31 11:42:03,702 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:03,702 INFO:     Epoch: 86
2022-12-31 11:42:05,308 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3298269311587016, 'Total loss': 0.3298269311587016} | train loss {'Reaction outcome loss': 0.21086047924651566, 'Total loss': 0.21086047924651566}
2022-12-31 11:42:05,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:05,308 INFO:     Epoch: 87
2022-12-31 11:42:06,933 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3557400683561961, 'Total loss': 0.3557400683561961} | train loss {'Reaction outcome loss': 0.20856716180058862, 'Total loss': 0.20856716180058862}
2022-12-31 11:42:06,933 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:06,933 INFO:     Epoch: 88
2022-12-31 11:42:08,541 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3290263553460439, 'Total loss': 0.3290263553460439} | train loss {'Reaction outcome loss': 0.2097767969788412, 'Total loss': 0.2097767969788412}
2022-12-31 11:42:08,542 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:08,542 INFO:     Epoch: 89
2022-12-31 11:42:10,208 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.352758984764417, 'Total loss': 0.352758984764417} | train loss {'Reaction outcome loss': 0.21100748573776187, 'Total loss': 0.21100748573776187}
2022-12-31 11:42:10,208 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:10,208 INFO:     Epoch: 90
2022-12-31 11:42:11,825 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.33294897178808847, 'Total loss': 0.33294897178808847} | train loss {'Reaction outcome loss': 0.21156277923780872, 'Total loss': 0.21156277923780872}
2022-12-31 11:42:11,825 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:11,825 INFO:     Epoch: 91
2022-12-31 11:42:13,423 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3250396688779195, 'Total loss': 0.3250396688779195} | train loss {'Reaction outcome loss': 0.203551893616734, 'Total loss': 0.203551893616734}
2022-12-31 11:42:13,423 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:13,423 INFO:     Epoch: 92
2022-12-31 11:42:15,046 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3623229920864105, 'Total loss': 0.3623229920864105} | train loss {'Reaction outcome loss': 0.20830290120377437, 'Total loss': 0.20830290120377437}
2022-12-31 11:42:15,046 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:15,046 INFO:     Epoch: 93
2022-12-31 11:42:16,721 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3525148411591848, 'Total loss': 0.3525148411591848} | train loss {'Reaction outcome loss': 0.20318200734413702, 'Total loss': 0.20318200734413702}
2022-12-31 11:42:16,721 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:16,721 INFO:     Epoch: 94
2022-12-31 11:42:18,349 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.34253155315915745, 'Total loss': 0.34253155315915745} | train loss {'Reaction outcome loss': 0.20848149496268495, 'Total loss': 0.20848149496268495}
2022-12-31 11:42:18,350 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:18,350 INFO:     Epoch: 95
2022-12-31 11:42:20,022 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3137625570098559, 'Total loss': 0.3137625570098559} | train loss {'Reaction outcome loss': 0.20515925977177354, 'Total loss': 0.20515925977177354}
2022-12-31 11:42:20,022 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:20,022 INFO:     Epoch: 96
2022-12-31 11:42:21,660 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.33997671405474345, 'Total loss': 0.33997671405474345} | train loss {'Reaction outcome loss': 0.2058567431509925, 'Total loss': 0.2058567431509925}
2022-12-31 11:42:21,660 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:21,660 INFO:     Epoch: 97
2022-12-31 11:42:23,281 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3410202627380689, 'Total loss': 0.3410202627380689} | train loss {'Reaction outcome loss': 0.20432853314097607, 'Total loss': 0.20432853314097607}
2022-12-31 11:42:23,282 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:23,282 INFO:     Epoch: 98
2022-12-31 11:42:24,950 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3280429194370906, 'Total loss': 0.3280429194370906} | train loss {'Reaction outcome loss': 0.1985667650167585, 'Total loss': 0.1985667650167585}
2022-12-31 11:42:24,951 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:24,951 INFO:     Epoch: 99
2022-12-31 11:42:26,572 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.36334175591667495, 'Total loss': 0.36334175591667495} | train loss {'Reaction outcome loss': 0.20261984392462654, 'Total loss': 0.20261984392462654}
2022-12-31 11:42:26,573 INFO:     Best model found after epoch 74 of 100.
2022-12-31 11:42:26,573 INFO:   Done with stage: TRAINING
2022-12-31 11:42:26,573 INFO:   Starting stage: EVALUATION
2022-12-31 11:42:26,694 INFO:   Done with stage: EVALUATION
2022-12-31 11:42:26,695 INFO:   Leaving out SEQ value Fold_9
2022-12-31 11:42:26,707 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2022-12-31 11:42:26,707 INFO:   Starting stage: FEATURE SCALING
2022-12-31 11:42:27,352 INFO:   Done with stage: FEATURE SCALING
2022-12-31 11:42:27,352 INFO:   Starting stage: SCALING TARGETS
2022-12-31 11:42:27,421 INFO:   Done with stage: SCALING TARGETS
2022-12-31 11:42:27,421 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:42:27,421 INFO:     No hyperparam tuning for this model
2022-12-31 11:42:27,421 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2022-12-31 11:42:27,422 INFO:   Starting stage: FEATURE SELECTION
2022-12-31 11:42:27,422 INFO:     None feature selector for col prot
2022-12-31 11:42:27,422 INFO:     None feature selector for col prot
2022-12-31 11:42:27,423 INFO:     None feature selector for col prot
2022-12-31 11:42:27,423 INFO:     None feature selector for col chem
2022-12-31 11:42:27,423 INFO:     None feature selector for col chem
2022-12-31 11:42:27,423 INFO:     None feature selector for col chem
2022-12-31 11:42:27,423 INFO:   Done with stage: FEATURE SELECTION
2022-12-31 11:42:27,424 INFO:   Starting stage: BUILD MODEL
2022-12-31 11:42:27,425 INFO:     Number of params in model 223921
2022-12-31 11:42:27,428 INFO:   Done with stage: BUILD MODEL
2022-12-31 11:42:27,429 INFO:   Starting stage: TRAINING
2022-12-31 11:42:27,473 INFO:     Val loss before train {'Reaction outcome loss': 0.9663393219312032, 'Total loss': 0.9663393219312032}
2022-12-31 11:42:27,473 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:27,473 INFO:     Epoch: 0
2022-12-31 11:42:29,125 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.6266415218512217, 'Total loss': 0.6266415218512217} | train loss {'Reaction outcome loss': 0.837350391742328, 'Total loss': 0.837350391742328}
2022-12-31 11:42:29,125 INFO:     Found new best model at epoch 0
2022-12-31 11:42:29,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:29,126 INFO:     Epoch: 1
2022-12-31 11:42:30,776 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.48179468711217244, 'Total loss': 0.48179468711217244} | train loss {'Reaction outcome loss': 0.6231174078108608, 'Total loss': 0.6231174078108608}
2022-12-31 11:42:30,776 INFO:     Found new best model at epoch 1
2022-12-31 11:42:30,777 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:30,777 INFO:     Epoch: 2
2022-12-31 11:42:32,379 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.46152366598447164, 'Total loss': 0.46152366598447164} | train loss {'Reaction outcome loss': 0.549374416794466, 'Total loss': 0.549374416794466}
2022-12-31 11:42:32,379 INFO:     Found new best model at epoch 2
2022-12-31 11:42:32,380 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:32,380 INFO:     Epoch: 3
2022-12-31 11:42:33,991 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4301956474781036, 'Total loss': 0.4301956474781036} | train loss {'Reaction outcome loss': 0.5323903988608145, 'Total loss': 0.5323903988608145}
2022-12-31 11:42:33,992 INFO:     Found new best model at epoch 3
2022-12-31 11:42:33,993 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:33,993 INFO:     Epoch: 4
2022-12-31 11:42:35,640 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4564314991235733, 'Total loss': 0.4564314991235733} | train loss {'Reaction outcome loss': 0.5060565020666337, 'Total loss': 0.5060565020666337}
2022-12-31 11:42:35,640 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:35,640 INFO:     Epoch: 5
2022-12-31 11:42:37,246 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4399680395921071, 'Total loss': 0.4399680395921071} | train loss {'Reaction outcome loss': 0.49455735827053804, 'Total loss': 0.49455735827053804}
2022-12-31 11:42:37,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:37,247 INFO:     Epoch: 6
2022-12-31 11:42:38,892 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4161804477373759, 'Total loss': 0.4161804477373759} | train loss {'Reaction outcome loss': 0.4873372866621113, 'Total loss': 0.4873372866621113}
2022-12-31 11:42:38,892 INFO:     Found new best model at epoch 6
2022-12-31 11:42:38,893 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:38,893 INFO:     Epoch: 7
2022-12-31 11:42:40,518 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.41435570816198986, 'Total loss': 0.41435570816198986} | train loss {'Reaction outcome loss': 0.4808140667265052, 'Total loss': 0.4808140667265052}
2022-12-31 11:42:40,519 INFO:     Found new best model at epoch 7
2022-12-31 11:42:40,520 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:40,520 INFO:     Epoch: 8
2022-12-31 11:42:42,125 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4130292862653732, 'Total loss': 0.4130292862653732} | train loss {'Reaction outcome loss': 0.4667887785311694, 'Total loss': 0.4667887785311694}
2022-12-31 11:42:42,125 INFO:     Found new best model at epoch 8
2022-12-31 11:42:42,126 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:42,126 INFO:     Epoch: 9
2022-12-31 11:42:43,737 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.42885360717773435, 'Total loss': 0.42885360717773435} | train loss {'Reaction outcome loss': 0.45544639418232324, 'Total loss': 0.45544639418232324}
2022-12-31 11:42:43,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:43,737 INFO:     Epoch: 10
2022-12-31 11:42:45,339 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.3749753112594287, 'Total loss': 0.3749753112594287} | train loss {'Reaction outcome loss': 0.45573875938704156, 'Total loss': 0.45573875938704156}
2022-12-31 11:42:45,339 INFO:     Found new best model at epoch 10
2022-12-31 11:42:45,340 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:45,340 INFO:     Epoch: 11
2022-12-31 11:42:46,971 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.37006622441112996, 'Total loss': 0.37006622441112996} | train loss {'Reaction outcome loss': 0.4512350895185617, 'Total loss': 0.4512350895185617}
2022-12-31 11:42:46,971 INFO:     Found new best model at epoch 11
2022-12-31 11:42:46,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:46,972 INFO:     Epoch: 12
2022-12-31 11:42:48,609 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.3886854569117228, 'Total loss': 0.3886854569117228} | train loss {'Reaction outcome loss': 0.44121859325905854, 'Total loss': 0.44121859325905854}
2022-12-31 11:42:48,609 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:48,610 INFO:     Epoch: 13
2022-12-31 11:42:50,246 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.40328361888726555, 'Total loss': 0.40328361888726555} | train loss {'Reaction outcome loss': 0.4361846253539071, 'Total loss': 0.4361846253539071}
2022-12-31 11:42:50,246 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:50,246 INFO:     Epoch: 14
2022-12-31 11:42:51,874 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.37758877674738567, 'Total loss': 0.37758877674738567} | train loss {'Reaction outcome loss': 0.4305857966883459, 'Total loss': 0.4305857966883459}
2022-12-31 11:42:51,874 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:51,874 INFO:     Epoch: 15
2022-12-31 11:42:53,483 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.39913914700349173, 'Total loss': 0.39913914700349173} | train loss {'Reaction outcome loss': 0.4382819835960433, 'Total loss': 0.4382819835960433}
2022-12-31 11:42:53,484 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:53,484 INFO:     Epoch: 16
2022-12-31 11:42:55,077 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.40709569056828815, 'Total loss': 0.40709569056828815} | train loss {'Reaction outcome loss': 0.42129913086603704, 'Total loss': 0.42129913086603704}
2022-12-31 11:42:55,077 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:55,077 INFO:     Epoch: 17
2022-12-31 11:42:56,691 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.3593936413526535, 'Total loss': 0.3593936413526535} | train loss {'Reaction outcome loss': 0.41445807730918244, 'Total loss': 0.41445807730918244}
2022-12-31 11:42:56,691 INFO:     Found new best model at epoch 17
2022-12-31 11:42:56,691 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:56,692 INFO:     Epoch: 18
2022-12-31 11:42:58,302 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3604166954755783, 'Total loss': 0.3604166954755783} | train loss {'Reaction outcome loss': 0.40547495729465416, 'Total loss': 0.40547495729465416}
2022-12-31 11:42:58,302 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:58,302 INFO:     Epoch: 19
2022-12-31 11:42:59,908 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.3571508824825287, 'Total loss': 0.3571508824825287} | train loss {'Reaction outcome loss': 0.40637732876637306, 'Total loss': 0.40637732876637306}
2022-12-31 11:42:59,909 INFO:     Found new best model at epoch 19
2022-12-31 11:42:59,909 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:42:59,910 INFO:     Epoch: 20
2022-12-31 11:43:01,538 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3882405266165733, 'Total loss': 0.3882405266165733} | train loss {'Reaction outcome loss': 0.404070022151522, 'Total loss': 0.404070022151522}
2022-12-31 11:43:01,538 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:01,538 INFO:     Epoch: 21
2022-12-31 11:43:03,121 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3717379709084829, 'Total loss': 0.3717379709084829} | train loss {'Reaction outcome loss': 0.43770949398859177, 'Total loss': 0.43770949398859177}
2022-12-31 11:43:03,122 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:03,122 INFO:     Epoch: 22
2022-12-31 11:43:04,729 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.40596052606900535, 'Total loss': 0.40596052606900535} | train loss {'Reaction outcome loss': 0.39592112237722543, 'Total loss': 0.39592112237722543}
2022-12-31 11:43:04,731 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:04,731 INFO:     Epoch: 23
2022-12-31 11:43:06,344 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3554358909527461, 'Total loss': 0.3554358909527461} | train loss {'Reaction outcome loss': 0.3922667813392869, 'Total loss': 0.3922667813392869}
2022-12-31 11:43:06,344 INFO:     Found new best model at epoch 23
2022-12-31 11:43:06,345 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:06,345 INFO:     Epoch: 24
2022-12-31 11:43:07,944 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.35604764918486276, 'Total loss': 0.35604764918486276} | train loss {'Reaction outcome loss': 0.3841084922458032, 'Total loss': 0.3841084922458032}
2022-12-31 11:43:07,944 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:07,944 INFO:     Epoch: 25
2022-12-31 11:43:09,559 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3537505676349004, 'Total loss': 0.3537505676349004} | train loss {'Reaction outcome loss': 0.380938947416734, 'Total loss': 0.380938947416734}
2022-12-31 11:43:09,559 INFO:     Found new best model at epoch 25
2022-12-31 11:43:09,560 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:09,560 INFO:     Epoch: 26
2022-12-31 11:43:11,168 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3349011311928431, 'Total loss': 0.3349011311928431} | train loss {'Reaction outcome loss': 0.3700021964808305, 'Total loss': 0.3700021964808305}
2022-12-31 11:43:11,168 INFO:     Found new best model at epoch 26
2022-12-31 11:43:11,169 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:11,169 INFO:     Epoch: 27
2022-12-31 11:43:12,784 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.34671937028566996, 'Total loss': 0.34671937028566996} | train loss {'Reaction outcome loss': 0.3748469914620121, 'Total loss': 0.3748469914620121}
2022-12-31 11:43:12,784 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:12,784 INFO:     Epoch: 28
2022-12-31 11:43:14,447 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3491175244251887, 'Total loss': 0.3491175244251887} | train loss {'Reaction outcome loss': 0.3605019394383197, 'Total loss': 0.3605019394383197}
2022-12-31 11:43:14,447 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:14,447 INFO:     Epoch: 29
2022-12-31 11:43:16,086 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3213275800148646, 'Total loss': 0.3213275800148646} | train loss {'Reaction outcome loss': 0.37210475634513557, 'Total loss': 0.37210475634513557}
2022-12-31 11:43:16,086 INFO:     Found new best model at epoch 29
2022-12-31 11:43:16,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:16,087 INFO:     Epoch: 30
2022-12-31 11:43:17,700 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.34559752941131594, 'Total loss': 0.34559752941131594} | train loss {'Reaction outcome loss': 0.39503838964130567, 'Total loss': 0.39503838964130567}
2022-12-31 11:43:17,701 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:17,701 INFO:     Epoch: 31
2022-12-31 11:43:19,359 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3439443796873093, 'Total loss': 0.3439443796873093} | train loss {'Reaction outcome loss': 0.4075358621776104, 'Total loss': 0.4075358621776104}
2022-12-31 11:43:19,359 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:19,359 INFO:     Epoch: 32
2022-12-31 11:43:20,971 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.33760060171286266, 'Total loss': 0.33760060171286266} | train loss {'Reaction outcome loss': 0.3648678502603603, 'Total loss': 0.3648678502603603}
2022-12-31 11:43:20,972 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:20,972 INFO:     Epoch: 33
2022-12-31 11:43:22,606 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.33782450755437216, 'Total loss': 0.33782450755437216} | train loss {'Reaction outcome loss': 0.34781112034292216, 'Total loss': 0.34781112034292216}
2022-12-31 11:43:22,606 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:22,607 INFO:     Epoch: 34
2022-12-31 11:43:24,218 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3536762098471324, 'Total loss': 0.3536762098471324} | train loss {'Reaction outcome loss': 0.34629275548555283, 'Total loss': 0.34629275548555283}
2022-12-31 11:43:24,219 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:24,219 INFO:     Epoch: 35
2022-12-31 11:43:25,811 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.35792397360006967, 'Total loss': 0.35792397360006967} | train loss {'Reaction outcome loss': 0.342958174119501, 'Total loss': 0.342958174119501}
2022-12-31 11:43:25,811 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:25,812 INFO:     Epoch: 36
2022-12-31 11:43:27,425 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3323397477467855, 'Total loss': 0.3323397477467855} | train loss {'Reaction outcome loss': 0.3334820499231168, 'Total loss': 0.3334820499231168}
2022-12-31 11:43:27,425 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:27,425 INFO:     Epoch: 37
2022-12-31 11:43:29,035 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.33662858853737515, 'Total loss': 0.33662858853737515} | train loss {'Reaction outcome loss': 0.33321722232647294, 'Total loss': 0.33321722232647294}
2022-12-31 11:43:29,035 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:29,036 INFO:     Epoch: 38
2022-12-31 11:43:30,668 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.352435427904129, 'Total loss': 0.352435427904129} | train loss {'Reaction outcome loss': 0.33166131697784085, 'Total loss': 0.33166131697784085}
2022-12-31 11:43:30,668 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:30,668 INFO:     Epoch: 39
2022-12-31 11:43:32,307 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3847655196984609, 'Total loss': 0.3847655196984609} | train loss {'Reaction outcome loss': 0.31741813472404645, 'Total loss': 0.31741813472404645}
2022-12-31 11:43:32,308 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:32,308 INFO:     Epoch: 40
2022-12-31 11:43:34,000 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.32449888239304225, 'Total loss': 0.32449888239304225} | train loss {'Reaction outcome loss': 0.32432029363025466, 'Total loss': 0.32432029363025466}
2022-12-31 11:43:34,000 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:34,000 INFO:     Epoch: 41
2022-12-31 11:43:35,616 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.30935246745745343, 'Total loss': 0.30935246745745343} | train loss {'Reaction outcome loss': 0.3197141427789693, 'Total loss': 0.3197141427789693}
2022-12-31 11:43:35,617 INFO:     Found new best model at epoch 41
2022-12-31 11:43:35,618 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:35,618 INFO:     Epoch: 42
2022-12-31 11:43:37,266 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.33426158626874286, 'Total loss': 0.33426158626874286} | train loss {'Reaction outcome loss': 0.3219153510703557, 'Total loss': 0.3219153510703557}
2022-12-31 11:43:37,267 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:37,267 INFO:     Epoch: 43
2022-12-31 11:43:38,911 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3265046924352646, 'Total loss': 0.3265046924352646} | train loss {'Reaction outcome loss': 0.33126834035341535, 'Total loss': 0.33126834035341535}
2022-12-31 11:43:38,912 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:38,912 INFO:     Epoch: 44
2022-12-31 11:43:40,579 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3551216055949529, 'Total loss': 0.3551216055949529} | train loss {'Reaction outcome loss': 0.30884747184303496, 'Total loss': 0.30884747184303496}
2022-12-31 11:43:40,580 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:40,580 INFO:     Epoch: 45
2022-12-31 11:43:42,230 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3577444404363632, 'Total loss': 0.3577444404363632} | train loss {'Reaction outcome loss': 0.2987990211661689, 'Total loss': 0.2987990211661689}
2022-12-31 11:43:42,231 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:42,231 INFO:     Epoch: 46
2022-12-31 11:43:43,873 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3340486298004786, 'Total loss': 0.3340486298004786} | train loss {'Reaction outcome loss': 0.29807492030406557, 'Total loss': 0.29807492030406557}
2022-12-31 11:43:43,873 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:43,873 INFO:     Epoch: 47
2022-12-31 11:43:45,489 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.35384533057610196, 'Total loss': 0.35384533057610196} | train loss {'Reaction outcome loss': 0.2972171706568377, 'Total loss': 0.2972171706568377}
2022-12-31 11:43:45,489 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:45,489 INFO:     Epoch: 48
2022-12-31 11:43:47,133 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.35418844521045684, 'Total loss': 0.35418844521045684} | train loss {'Reaction outcome loss': 0.3055805359845576, 'Total loss': 0.3055805359845576}
2022-12-31 11:43:47,133 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:47,134 INFO:     Epoch: 49
2022-12-31 11:43:48,774 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3096289664506912, 'Total loss': 0.3096289664506912} | train loss {'Reaction outcome loss': 0.36399007082049584, 'Total loss': 0.36399007082049584}
2022-12-31 11:43:48,774 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:48,774 INFO:     Epoch: 50
2022-12-31 11:43:50,448 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3383688966433207, 'Total loss': 0.3383688966433207} | train loss {'Reaction outcome loss': 0.291814453319471, 'Total loss': 0.291814453319471}
2022-12-31 11:43:50,448 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:50,448 INFO:     Epoch: 51
2022-12-31 11:43:52,118 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3293952763080597, 'Total loss': 0.3293952763080597} | train loss {'Reaction outcome loss': 0.2862596403591443, 'Total loss': 0.2862596403591443}
2022-12-31 11:43:52,118 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:52,119 INFO:     Epoch: 52
2022-12-31 11:43:53,737 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.33036873638629916, 'Total loss': 0.33036873638629916} | train loss {'Reaction outcome loss': 0.28526362148535345, 'Total loss': 0.28526362148535345}
2022-12-31 11:43:53,737 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:53,737 INFO:     Epoch: 53
2022-12-31 11:43:55,386 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3276125073432922, 'Total loss': 0.3276125073432922} | train loss {'Reaction outcome loss': 0.28115094539479935, 'Total loss': 0.28115094539479935}
2022-12-31 11:43:55,387 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:55,387 INFO:     Epoch: 54
2022-12-31 11:43:57,036 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3347967724005381, 'Total loss': 0.3347967724005381} | train loss {'Reaction outcome loss': 0.29542787111215835, 'Total loss': 0.29542787111215835}
2022-12-31 11:43:57,036 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:57,036 INFO:     Epoch: 55
2022-12-31 11:43:58,672 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.33058899343013765, 'Total loss': 0.33058899343013765} | train loss {'Reaction outcome loss': 0.3294173843839773, 'Total loss': 0.3294173843839773}
2022-12-31 11:43:58,672 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:43:58,672 INFO:     Epoch: 56
2022-12-31 11:44:00,310 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.35764308969179787, 'Total loss': 0.35764308969179787} | train loss {'Reaction outcome loss': 0.3102097542875487, 'Total loss': 0.3102097542875487}
2022-12-31 11:44:00,310 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:00,310 INFO:     Epoch: 57
2022-12-31 11:44:02,003 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.31760961214701333, 'Total loss': 0.31760961214701333} | train loss {'Reaction outcome loss': 0.3411950853870898, 'Total loss': 0.3411950853870898}
2022-12-31 11:44:02,004 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:02,004 INFO:     Epoch: 58
2022-12-31 11:44:03,636 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3098554089665413, 'Total loss': 0.3098554089665413} | train loss {'Reaction outcome loss': 0.2848975238444257, 'Total loss': 0.2848975238444257}
2022-12-31 11:44:03,636 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:03,636 INFO:     Epoch: 59
2022-12-31 11:44:05,278 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3523256669441859, 'Total loss': 0.3523256669441859} | train loss {'Reaction outcome loss': 0.2719870306402985, 'Total loss': 0.2719870306402985}
2022-12-31 11:44:05,278 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:05,278 INFO:     Epoch: 60
2022-12-31 11:44:06,886 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.358111760020256, 'Total loss': 0.358111760020256} | train loss {'Reaction outcome loss': 0.2667482565730756, 'Total loss': 0.2667482565730756}
2022-12-31 11:44:06,887 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:06,888 INFO:     Epoch: 61
2022-12-31 11:44:08,478 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3105584998925527, 'Total loss': 0.3105584998925527} | train loss {'Reaction outcome loss': 0.26244897792871663, 'Total loss': 0.26244897792871663}
2022-12-31 11:44:08,478 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:08,478 INFO:     Epoch: 62
2022-12-31 11:44:10,087 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3245832512776057, 'Total loss': 0.3245832512776057} | train loss {'Reaction outcome loss': 0.26422863093414006, 'Total loss': 0.26422863093414006}
2022-12-31 11:44:10,087 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:10,087 INFO:     Epoch: 63
2022-12-31 11:44:11,733 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3728798786799113, 'Total loss': 0.3728798786799113} | train loss {'Reaction outcome loss': 0.2615031681598866, 'Total loss': 0.2615031681598866}
2022-12-31 11:44:11,733 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:11,734 INFO:     Epoch: 64
2022-12-31 11:44:13,352 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.34365558822949727, 'Total loss': 0.34365558822949727} | train loss {'Reaction outcome loss': 0.25579410843362194, 'Total loss': 0.25579410843362194}
2022-12-31 11:44:13,352 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:13,353 INFO:     Epoch: 65
2022-12-31 11:44:14,962 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3624932664136092, 'Total loss': 0.3624932664136092} | train loss {'Reaction outcome loss': 0.2544558074838225, 'Total loss': 0.2544558074838225}
2022-12-31 11:44:14,962 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:14,962 INFO:     Epoch: 66
2022-12-31 11:44:16,550 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3162085205316544, 'Total loss': 0.3162085205316544} | train loss {'Reaction outcome loss': 0.27088481430352357, 'Total loss': 0.27088481430352357}
2022-12-31 11:44:16,550 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:16,550 INFO:     Epoch: 67
2022-12-31 11:44:18,201 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3330554127693176, 'Total loss': 0.3330554127693176} | train loss {'Reaction outcome loss': 0.24538872673081746, 'Total loss': 0.24538872673081746}
2022-12-31 11:44:18,201 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:18,201 INFO:     Epoch: 68
2022-12-31 11:44:19,838 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.34522552192211153, 'Total loss': 0.34522552192211153} | train loss {'Reaction outcome loss': 0.24538209184454213, 'Total loss': 0.24538209184454213}
2022-12-31 11:44:19,838 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:19,838 INFO:     Epoch: 69
2022-12-31 11:44:21,444 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.32651929954687753, 'Total loss': 0.32651929954687753} | train loss {'Reaction outcome loss': 0.250874725146813, 'Total loss': 0.250874725146813}
2022-12-31 11:44:21,444 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:21,445 INFO:     Epoch: 70
2022-12-31 11:44:23,092 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3476208726565043, 'Total loss': 0.3476208726565043} | train loss {'Reaction outcome loss': 0.24649960176506336, 'Total loss': 0.24649960176506336}
2022-12-31 11:44:23,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:23,092 INFO:     Epoch: 71
2022-12-31 11:44:24,736 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.31794314781824745, 'Total loss': 0.31794314781824745} | train loss {'Reaction outcome loss': 0.24355778616070206, 'Total loss': 0.24355778616070206}
2022-12-31 11:44:24,736 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:24,736 INFO:     Epoch: 72
2022-12-31 11:44:26,329 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.30587180455525714, 'Total loss': 0.30587180455525714} | train loss {'Reaction outcome loss': 0.24229190395588218, 'Total loss': 0.24229190395588218}
2022-12-31 11:44:26,330 INFO:     Found new best model at epoch 72
2022-12-31 11:44:26,331 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:26,331 INFO:     Epoch: 73
2022-12-31 11:44:27,974 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.31400758524735767, 'Total loss': 0.31400758524735767} | train loss {'Reaction outcome loss': 0.2363589691484104, 'Total loss': 0.2363589691484104}
2022-12-31 11:44:27,974 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:27,974 INFO:     Epoch: 74
2022-12-31 11:44:29,624 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.36237779607375464, 'Total loss': 0.36237779607375464} | train loss {'Reaction outcome loss': 0.24861566357962464, 'Total loss': 0.24861566357962464}
2022-12-31 11:44:29,624 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:29,624 INFO:     Epoch: 75
2022-12-31 11:44:31,216 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3287212202946345, 'Total loss': 0.3287212202946345} | train loss {'Reaction outcome loss': 0.24409216871604061, 'Total loss': 0.24409216871604061}
2022-12-31 11:44:31,216 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:31,217 INFO:     Epoch: 76
2022-12-31 11:44:32,832 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.31686363071203233, 'Total loss': 0.31686363071203233} | train loss {'Reaction outcome loss': 0.22632504409082924, 'Total loss': 0.22632504409082924}
2022-12-31 11:44:32,832 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:32,832 INFO:     Epoch: 77
2022-12-31 11:44:34,430 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.30536943425734836, 'Total loss': 0.30536943425734836} | train loss {'Reaction outcome loss': 0.2452096570903687, 'Total loss': 0.2452096570903687}
2022-12-31 11:44:34,431 INFO:     Found new best model at epoch 77
2022-12-31 11:44:34,431 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:34,432 INFO:     Epoch: 78
2022-12-31 11:44:36,092 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3442797586321831, 'Total loss': 0.3442797586321831} | train loss {'Reaction outcome loss': 0.22905386788346915, 'Total loss': 0.22905386788346915}
2022-12-31 11:44:36,092 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:36,092 INFO:     Epoch: 79
2022-12-31 11:44:37,712 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.34636446833610535, 'Total loss': 0.34636446833610535} | train loss {'Reaction outcome loss': 0.23597777025956337, 'Total loss': 0.23597777025956337}
2022-12-31 11:44:37,712 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:37,713 INFO:     Epoch: 80
2022-12-31 11:44:39,304 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.30787131587664285, 'Total loss': 0.30787131587664285} | train loss {'Reaction outcome loss': 0.23043746065598275, 'Total loss': 0.23043746065598275}
2022-12-31 11:44:39,304 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:39,304 INFO:     Epoch: 81
2022-12-31 11:44:40,917 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.34434592400987946, 'Total loss': 0.34434592400987946} | train loss {'Reaction outcome loss': 0.22027318581830765, 'Total loss': 0.22027318581830765}
2022-12-31 11:44:40,917 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:40,917 INFO:     Epoch: 82
2022-12-31 11:44:42,529 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3127289243042469, 'Total loss': 0.3127289243042469} | train loss {'Reaction outcome loss': 0.23055864121715128, 'Total loss': 0.23055864121715128}
2022-12-31 11:44:42,530 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:42,530 INFO:     Epoch: 83
2022-12-31 11:44:44,123 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3263453523317973, 'Total loss': 0.3263453523317973} | train loss {'Reaction outcome loss': 0.22381915749355213, 'Total loss': 0.22381915749355213}
2022-12-31 11:44:44,123 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:44,123 INFO:     Epoch: 84
2022-12-31 11:44:45,739 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.32394767900307975, 'Total loss': 0.32394767900307975} | train loss {'Reaction outcome loss': 0.2253920200843519, 'Total loss': 0.2253920200843519}
2022-12-31 11:44:45,740 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:45,740 INFO:     Epoch: 85
2022-12-31 11:44:47,356 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3175296420852343, 'Total loss': 0.3175296420852343} | train loss {'Reaction outcome loss': 0.2210939190606924, 'Total loss': 0.2210939190606924}
2022-12-31 11:44:47,356 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:47,356 INFO:     Epoch: 86
2022-12-31 11:44:48,958 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3691406180461248, 'Total loss': 0.3691406180461248} | train loss {'Reaction outcome loss': 0.2370057617165688, 'Total loss': 0.2370057617165688}
2022-12-31 11:44:48,959 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:48,959 INFO:     Epoch: 87
2022-12-31 11:44:50,572 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.28103448301553724, 'Total loss': 0.28103448301553724} | train loss {'Reaction outcome loss': 0.27127559786554173, 'Total loss': 0.27127559786554173}
2022-12-31 11:44:50,572 INFO:     Found new best model at epoch 87
2022-12-31 11:44:50,573 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:50,573 INFO:     Epoch: 88
2022-12-31 11:44:52,235 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.32499205668767295, 'Total loss': 0.32499205668767295} | train loss {'Reaction outcome loss': 0.2208437152625318, 'Total loss': 0.2208437152625318}
2022-12-31 11:44:52,235 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:52,236 INFO:     Epoch: 89
2022-12-31 11:44:53,869 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3094284199178219, 'Total loss': 0.3094284199178219} | train loss {'Reaction outcome loss': 0.2233242287799932, 'Total loss': 0.2233242287799932}
2022-12-31 11:44:53,869 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:53,869 INFO:     Epoch: 90
2022-12-31 11:44:55,498 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3430552805463473, 'Total loss': 0.3430552805463473} | train loss {'Reaction outcome loss': 0.2712260132007625, 'Total loss': 0.2712260132007625}
2022-12-31 11:44:55,498 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:55,498 INFO:     Epoch: 91
2022-12-31 11:44:57,098 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.33172495861848195, 'Total loss': 0.33172495861848195} | train loss {'Reaction outcome loss': 0.22996807586552703, 'Total loss': 0.22996807586552703}
2022-12-31 11:44:57,098 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:57,099 INFO:     Epoch: 92
2022-12-31 11:44:58,705 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3096599449714025, 'Total loss': 0.3096599449714025} | train loss {'Reaction outcome loss': 0.2175659831237068, 'Total loss': 0.2175659831237068}
2022-12-31 11:44:58,705 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:44:58,705 INFO:     Epoch: 93
2022-12-31 11:45:00,318 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3112985670566559, 'Total loss': 0.3112985670566559} | train loss {'Reaction outcome loss': 0.2145937831321161, 'Total loss': 0.2145937831321161}
2022-12-31 11:45:00,319 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:45:00,319 INFO:     Epoch: 94
2022-12-31 11:45:01,944 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.32019416987895966, 'Total loss': 0.32019416987895966} | train loss {'Reaction outcome loss': 0.21697980097994424, 'Total loss': 0.21697980097994424}
2022-12-31 11:45:01,945 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:45:01,945 INFO:     Epoch: 95
2022-12-31 11:45:03,563 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3080294082562129, 'Total loss': 0.3080294082562129} | train loss {'Reaction outcome loss': 0.21129876550664936, 'Total loss': 0.21129876550664936}
2022-12-31 11:45:03,563 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:45:03,564 INFO:     Epoch: 96
2022-12-31 11:45:05,176 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3225908656915029, 'Total loss': 0.3225908656915029} | train loss {'Reaction outcome loss': 0.2125730421596571, 'Total loss': 0.2125730421596571}
2022-12-31 11:45:05,176 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:45:05,176 INFO:     Epoch: 97
2022-12-31 11:45:06,773 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.317860413591067, 'Total loss': 0.317860413591067} | train loss {'Reaction outcome loss': 0.21855562110094057, 'Total loss': 0.21855562110094057}
2022-12-31 11:45:06,773 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:45:06,773 INFO:     Epoch: 98
2022-12-31 11:45:08,386 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3160459756851196, 'Total loss': 0.3160459756851196} | train loss {'Reaction outcome loss': 0.21416683897099364, 'Total loss': 0.21416683897099364}
2022-12-31 11:45:08,386 INFO:     Current learning rate [0.00015553873022161447]
2022-12-31 11:45:08,386 INFO:     Epoch: 99
2022-12-31 11:45:09,998 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3179747258623441, 'Total loss': 0.3179747258623441} | train loss {'Reaction outcome loss': 0.20777864474971927, 'Total loss': 0.20777864474971927}
2022-12-31 11:45:09,998 INFO:     Best model found after epoch 88 of 100.
2022-12-31 11:45:09,998 INFO:   Done with stage: TRAINING
2022-12-31 11:45:09,998 INFO:   Starting stage: EVALUATION
2022-12-31 11:45:10,125 INFO:   Done with stage: EVALUATION
2022-12-31 11:45:10,125 INFO: Done with stage: RUNNING SPLITS
2022-12-31 11:45:10,125 INFO: Starting stage: COMPUTE METRICS
2022-12-31 11:45:11,289 INFO: Done with stage: COMPUTE METRICS
2022-12-31 11:45:11,289 INFO: Starting stage: EXPORT RESULTS
2022-12-31 11:45:11,306 INFO:   Final results averaged over 50 folds: 
2022-12-31 11:45:11,310 INFO:   
                     mae  neg-spearman      rmse  spearman
dataset_split                                            
test           0.186167           NaN  0.341959       NaN
2022-12-31 11:45:12,936 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2022-12-31 11:45:12,942 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2022-12-31 11:45:12,944 DEBUG:   interactive is False
2022-12-31 11:45:12,944 DEBUG:   platform is linux
2022-12-31 11:45:12,944 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.sql.naming', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2022-12-31 11:45:13,115 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2022-12-31 11:45:13,117 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2022-12-31 11:45:13,547 DEBUG:   Loaded backend agg version unknown.
2022-12-31 11:45:13,549 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-12-31 11:45:13,549 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 11:45:13,549 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,549 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,549 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 11:45:13,549 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 11:45:13,549 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 11:45:13,549 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 11:45:13,550 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 11:45:13,550 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,550 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,550 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 11:45:13,550 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 11:45:13,550 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,550 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,550 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,550 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 11:45:13,550 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,550 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 11:45:13,550 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,550 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,550 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-12-31 11:45:13,550 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 11:45:13,550 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 11:45:13,551 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,551 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,551 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,551 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 11:45:13,551 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,551 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 11:45:13,551 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 11:45:13,551 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,551 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 11:45:13,551 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-12-31 11:45:13,551 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,551 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,551 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 11:45:13,551 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,551 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 11:45:13,551 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 11:45:13,551 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,552 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 11:45:13,552 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,552 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 11:45:13,552 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 11:45:13,552 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-12-31 11:45:13,588 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2022-12-31 11:45:13,588 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 11:45:13,589 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,589 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,589 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 11:45:13,589 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 11:45:13,589 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 11:45:13,589 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 11:45:13,589 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 11:45:13,589 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,589 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,589 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 11:45:13,589 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 11:45:13,589 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,589 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,589 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,589 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 11:45:13,589 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,590 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 11:45:13,590 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,590 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,590 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-12-31 11:45:13,590 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 11:45:13,590 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 11:45:13,590 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,590 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,590 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,590 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 11:45:13,590 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,590 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 11:45:13,590 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 11:45:13,590 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,590 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 11:45:13,590 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-12-31 11:45:13,591 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,591 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,591 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 11:45:13,591 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,591 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 11:45:13,591 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 11:45:13,591 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,591 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 11:45:13,591 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,591 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 11:45:13,591 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 11:45:13,591 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-12-31 11:45:13,599 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2022-12-31 11:45:13,600 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 11:45:13,600 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,600 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,600 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 11:45:13,600 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 11:45:13,600 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 11:45:13,600 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 11:45:13,600 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 11:45:13,600 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,600 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,600 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 11:45:13,600 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 11:45:13,600 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,601 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,601 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,601 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 11:45:13,601 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,601 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 11:45:13,601 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,601 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,601 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2022-12-31 11:45:13,601 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 11:45:13,601 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2022-12-31 11:45:13,601 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,601 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,601 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,601 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 11:45:13,601 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,601 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 11:45:13,601 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 11:45:13,602 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,602 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 11:45:13,602 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2022-12-31 11:45:13,602 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,602 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,602 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 11:45:13,602 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,602 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2022-12-31 11:45:13,602 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2022-12-31 11:45:13,602 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,602 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 11:45:13,602 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2022-12-31 11:45:13,602 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2022-12-31 11:45:13,602 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2022-12-31 11:45:13,602 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2022-12-31 11:45:13,885 INFO: Done with stage: EXPORT RESULTS
2022-12-31 11:45:13,885 INFO: Starting stage: SAVE MODEL
2022-12-31 11:45:13,935 INFO: Done with stage: SAVE MODEL
2022-12-31 11:45:13,935 INFO: Wall time for program:  8068.05 seconds
