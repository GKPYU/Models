2023-01-05 07:05:00,298 INFO: Parsed args: {
  "out": "results/dense/2021_05_27_psar_with_multi/Final_Lipo_GOE_Substrate/ffn/9b52f48c712e4c9cfbfc342f165d61dd/2023_01_04-214452",
  "seed": 1,
  "dataset_type": "HTSLoader",
  "chem_featurizer": "morgan1024",
  "prot_featurizer": "esm",
  "debug_mode": false,
  "export_predictions": false,
  "gpu": true,
  "regression": true,
  "model_params_file": "results/dense/2021_05_25_pqsar_olea_hyperopt_seed_1/olea_binary/ffndot/952cbf3d9c8ab59fe9c0531715302502/2021_05_26-165106_optuna_params.json",
  "save_outputs": false,
  "run_optuna": false,
  "optuna_trials": 10,
  "hts_csv_file": "data/processed/Final_Lipo_GOE_Substrate.csv",
  "ssa_ref_file": null,
  "substrate_cats_file": "data/processed/substrate_categories/Final_sub_cats.p",
  "substrate_cat": null,
  "debug_sample": 0.01,
  "n_bits": 1024,
  "ngram_min": 2,
  "ngram_max": 3,
  "unnormalized": false,
  "pool_prot_strategy": "mean",
  "pool_num": 5,
  "embed_batch_size": 4,
  "cache_dir": "data/program_cache",
  "chem_fp_file": null,
  "prot_feat_file": null,
  "evotuned_dir": null,
  "n_bits_prot": 100,
  "seq_msa": "data/processed/alignments/Final_alignment.fasta",
  "jt_vae_loc": "data/processed/precomputed_features/",
  "num_k_best": 30,
  "n_components": 10,
  "prot_selector": null,
  "chem_selector": null,
  "var_select_threshold": 0.05,
  "splitter_name": "kfold-seq",
  "eval_grouping": "SUBSTRATES",
  "scale_prot": true,
  "scale_chem": false,
  "model": "ffn",
  "ignore_train": true,
  "pivot_task": null,
  "frac_train_mask": 0.0,
  "optuna_folds": 5,
  "optuna_grid_sample": false,
  "optuna_global": true,
  "train_size": 0.95,
  "val_size": 0.05,
  "test_size": 0.0,
  "count_positives": false,
  "num_folds": 10,
  "num_kfold_trials": 5,
  "split_groups_file": null,
  "max_imbalance": 0.9,
  "no_loo_pool": false,
  "sub_split_type": "loo",
  "batch_size": 64,
  "knn_uniform": false,
  "epochs": 100,
  "learning_rate": 0.00015553873022161447,
  "gp_implementation": "sklearn",
  "deep_ensemble_num": 1,
  "seq_dist_type": null,
  "sub_dist_type": null,
  "concat_val": true,
  "layers": 5,
  "hidden_size": 30,
  "model_dropout": 0.04479215158380028,
  "use_scheduler": false,
  "warmup_epochs": 1,
  "kernel_size": 5,
  "avg_pool_conv": false,
  "num_conv_layers": 3,
  "batches_per_eval": null,
  "weight_decay": 0.0016309161239175475,
  "max_depth": 8,
  "n_estimators": 100,
  "n_neighbors": 5,
  "solver": "lbfgs",
  "alpha": 1,
  "no_class_weight": false,
  "align_dist": null
}
2023-01-05 07:05:00,307 INFO: Starting stage: BUILD FEATURIZERS
2023-01-05 07:05:00,309 INFO:   Creating esm representation model
2023-01-05 07:05:00,309 INFO:   Done esm representation model
2023-01-05 07:05:00,309 INFO: Done with stage: BUILD FEATURIZERS
2023-01-05 07:05:00,309 INFO: Starting stage: BUILDING DATASET
2023-01-05 07:05:00,365 INFO: Done with stage: BUILDING DATASET
2023-01-05 07:05:00,365 INFO: Starting stage: FEATURIZING DATA
2023-01-05 07:05:00,365 INFO:   Featurizing proteins
2023-01-05 07:05:00,366 INFO:   Loading cache file data/program_cache/ecc734a18b148b2da7b1456501f003c4
2023-01-05 07:05:00,371 INFO:   Loaded feature cache of size 489
2023-01-05 07:05:00,372 INFO:   Starting to pool ESM Embeddings
2023-01-05 07:05:00,495 INFO:   Featurizing molecules
2023-01-05 07:05:00,497 INFO:   Loading cache file data/program_cache/739a0d20a6c75d701bd3663cec254635
2023-01-05 07:05:00,499 INFO:   Loaded feature cache of size 498
2023-01-05 07:05:01,855 INFO: Done with stage: FEATURIZING DATA
2023-01-05 07:05:01,855 INFO: Starting stage: RUNNING SPLITS
2023-01-05 07:05:01,865 INFO:   Leaving out SEQ value Fold_0
2023-01-05 07:05:01,879 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 07:05:01,879 INFO:   Starting stage: FEATURE SCALING
2023-01-05 07:05:02,552 INFO:   Done with stage: FEATURE SCALING
2023-01-05 07:05:02,552 INFO:   Starting stage: SCALING TARGETS
2023-01-05 07:05:02,619 INFO:   Done with stage: SCALING TARGETS
2023-01-05 07:05:02,620 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:05:02,620 INFO:     No hyperparam tuning for this model
2023-01-05 07:05:02,620 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:05:02,620 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 07:05:02,621 INFO:     None feature selector for col prot
2023-01-05 07:05:02,621 INFO:     None feature selector for col prot
2023-01-05 07:05:02,621 INFO:     None feature selector for col prot
2023-01-05 07:05:02,621 INFO:     None feature selector for col chem
2023-01-05 07:05:02,621 INFO:     None feature selector for col chem
2023-01-05 07:05:02,621 INFO:     None feature selector for col chem
2023-01-05 07:05:02,622 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 07:05:02,622 INFO:   Starting stage: BUILD MODEL
2023-01-05 07:05:02,623 INFO:     Number of params in model 72901
2023-01-05 07:05:02,623 INFO:   Done with stage: BUILD MODEL
2023-01-05 07:05:02,623 INFO:   Starting stage: TRAINING
2023-01-05 07:05:04,312 INFO:     Val loss before train {'Reaction outcome loss': 0.8786911189556121, 'Total loss': 0.8786911189556121}
2023-01-05 07:05:04,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:05:04,313 INFO:     Epoch: 0
2023-01-05 07:05:06,425 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7299046615759531, 'Total loss': 0.7299046615759531} | train loss {'Reaction outcome loss': 0.9359629610519269, 'Total loss': 0.9359629610519269}
2023-01-05 07:05:06,425 INFO:     Found new best model at epoch 0
2023-01-05 07:05:06,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:05:06,426 INFO:     Epoch: 1
2023-01-05 07:05:08,551 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6046062866846721, 'Total loss': 0.6046062866846721} | train loss {'Reaction outcome loss': 0.7546125872012897, 'Total loss': 0.7546125872012897}
2023-01-05 07:05:08,552 INFO:     Found new best model at epoch 1
2023-01-05 07:05:08,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:05:08,553 INFO:     Epoch: 2
2023-01-05 07:05:10,691 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5159732302029928, 'Total loss': 0.5159732302029928} | train loss {'Reaction outcome loss': 0.586456727031823, 'Total loss': 0.586456727031823}
2023-01-05 07:05:10,691 INFO:     Found new best model at epoch 2
2023-01-05 07:05:10,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:05:10,693 INFO:     Epoch: 3
2023-01-05 07:05:12,818 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5164923548698426, 'Total loss': 0.5164923548698426} | train loss {'Reaction outcome loss': 0.540900605502146, 'Total loss': 0.540900605502146}
2023-01-05 07:05:12,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:05:12,819 INFO:     Epoch: 4
2023-01-05 07:05:14,942 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5101708749930064, 'Total loss': 0.5101708749930064} | train loss {'Reaction outcome loss': 0.5140616996384366, 'Total loss': 0.5140616996384366}
2023-01-05 07:05:14,943 INFO:     Found new best model at epoch 4
2023-01-05 07:05:14,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:05:14,944 INFO:     Epoch: 5
2023-01-05 07:05:17,051 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4824430853128433, 'Total loss': 0.4824430853128433} | train loss {'Reaction outcome loss': 0.5013465486712508, 'Total loss': 0.5013465486712508}
2023-01-05 07:05:17,051 INFO:     Found new best model at epoch 5
2023-01-05 07:05:17,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:05:17,052 INFO:     Epoch: 6
2023-01-05 07:05:19,167 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5202636241912841, 'Total loss': 0.5202636241912841} | train loss {'Reaction outcome loss': 0.48787593039182514, 'Total loss': 0.48787593039182514}
2023-01-05 07:05:19,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:05:19,167 INFO:     Epoch: 7
2023-01-05 07:05:21,280 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5083694597085316, 'Total loss': 0.5083694597085316} | train loss {'Reaction outcome loss': 0.48830356850073886, 'Total loss': 0.48830356850073886}
2023-01-05 07:05:21,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:05:21,281 INFO:     Epoch: 8
2023-01-05 07:05:23,423 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4659944514433543, 'Total loss': 0.4659944514433543} | train loss {'Reaction outcome loss': 0.4769315812941436, 'Total loss': 0.4769315812941436}
2023-01-05 07:05:23,424 INFO:     Found new best model at epoch 8
2023-01-05 07:05:23,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:05:23,425 INFO:     Epoch: 9
2023-01-05 07:05:25,556 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.48408480882644656, 'Total loss': 0.48408480882644656} | train loss {'Reaction outcome loss': 0.4697511838032649, 'Total loss': 0.4697511838032649}
2023-01-05 07:05:25,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:05:25,556 INFO:     Epoch: 10
2023-01-05 07:05:27,681 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4835579494635264, 'Total loss': 0.4835579494635264} | train loss {'Reaction outcome loss': 0.46304917390093264, 'Total loss': 0.46304917390093264}
2023-01-05 07:05:27,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:05:27,681 INFO:     Epoch: 11
2023-01-05 07:05:29,812 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4530505354205767, 'Total loss': 0.4530505354205767} | train loss {'Reaction outcome loss': 0.4627657346018068, 'Total loss': 0.4627657346018068}
2023-01-05 07:05:29,812 INFO:     Found new best model at epoch 11
2023-01-05 07:05:29,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:05:29,814 INFO:     Epoch: 12
2023-01-05 07:05:31,948 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45185102224349977, 'Total loss': 0.45185102224349977} | train loss {'Reaction outcome loss': 0.4582592920833455, 'Total loss': 0.4582592920833455}
2023-01-05 07:05:31,948 INFO:     Found new best model at epoch 12
2023-01-05 07:05:31,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:05:31,949 INFO:     Epoch: 13
2023-01-05 07:05:34,087 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4581664433081945, 'Total loss': 0.4581664433081945} | train loss {'Reaction outcome loss': 0.45061069410362525, 'Total loss': 0.45061069410362525}
2023-01-05 07:05:34,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:05:34,087 INFO:     Epoch: 14
2023-01-05 07:05:36,219 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.44212363213300704, 'Total loss': 0.44212363213300704} | train loss {'Reaction outcome loss': 0.45271156076000724, 'Total loss': 0.45271156076000724}
2023-01-05 07:05:36,220 INFO:     Found new best model at epoch 14
2023-01-05 07:05:36,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:05:36,222 INFO:     Epoch: 15
2023-01-05 07:05:38,355 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4384707063436508, 'Total loss': 0.4384707063436508} | train loss {'Reaction outcome loss': 0.44253692292905117, 'Total loss': 0.44253692292905117}
2023-01-05 07:05:38,355 INFO:     Found new best model at epoch 15
2023-01-05 07:05:38,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:05:38,357 INFO:     Epoch: 16
2023-01-05 07:05:40,503 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4312242741386096, 'Total loss': 0.4312242741386096} | train loss {'Reaction outcome loss': 0.44345941970418223, 'Total loss': 0.44345941970418223}
2023-01-05 07:05:40,503 INFO:     Found new best model at epoch 16
2023-01-05 07:05:40,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:05:40,504 INFO:     Epoch: 17
2023-01-05 07:05:42,634 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.457041068871816, 'Total loss': 0.457041068871816} | train loss {'Reaction outcome loss': 0.44156253371974485, 'Total loss': 0.44156253371974485}
2023-01-05 07:05:42,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:05:42,635 INFO:     Epoch: 18
2023-01-05 07:05:44,775 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45572516123453777, 'Total loss': 0.45572516123453777} | train loss {'Reaction outcome loss': 0.4352641142768301, 'Total loss': 0.4352641142768301}
2023-01-05 07:05:44,775 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:05:44,775 INFO:     Epoch: 19
2023-01-05 07:05:46,909 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46130094726880394, 'Total loss': 0.46130094726880394} | train loss {'Reaction outcome loss': 0.43314589439949275, 'Total loss': 0.43314589439949275}
2023-01-05 07:05:46,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:05:46,909 INFO:     Epoch: 20
2023-01-05 07:05:49,047 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4411052346229553, 'Total loss': 0.4411052346229553} | train loss {'Reaction outcome loss': 0.42990710851037023, 'Total loss': 0.42990710851037023}
2023-01-05 07:05:49,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:05:49,048 INFO:     Epoch: 21
2023-01-05 07:05:51,229 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4679127146800359, 'Total loss': 0.4679127146800359} | train loss {'Reaction outcome loss': 0.4270291409213028, 'Total loss': 0.4270291409213028}
2023-01-05 07:05:51,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:05:51,230 INFO:     Epoch: 22
2023-01-05 07:05:53,364 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4282644281784693, 'Total loss': 0.4282644281784693} | train loss {'Reaction outcome loss': 0.4152792582472602, 'Total loss': 0.4152792582472602}
2023-01-05 07:05:53,364 INFO:     Found new best model at epoch 22
2023-01-05 07:05:53,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:05:53,365 INFO:     Epoch: 23
2023-01-05 07:05:55,491 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45219908058643343, 'Total loss': 0.45219908058643343} | train loss {'Reaction outcome loss': 0.41781724307126616, 'Total loss': 0.41781724307126616}
2023-01-05 07:05:55,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:05:55,492 INFO:     Epoch: 24
2023-01-05 07:05:57,605 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4358722378810247, 'Total loss': 0.4358722378810247} | train loss {'Reaction outcome loss': 0.41365129194962674, 'Total loss': 0.41365129194962674}
2023-01-05 07:05:57,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:05:57,606 INFO:     Epoch: 25
2023-01-05 07:05:59,723 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45312751332918805, 'Total loss': 0.45312751332918805} | train loss {'Reaction outcome loss': 0.4078706403624526, 'Total loss': 0.4078706403624526}
2023-01-05 07:05:59,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:05:59,723 INFO:     Epoch: 26
2023-01-05 07:06:01,847 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4520201285680135, 'Total loss': 0.4520201285680135} | train loss {'Reaction outcome loss': 0.410258361298741, 'Total loss': 0.410258361298741}
2023-01-05 07:06:01,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:06:01,847 INFO:     Epoch: 27
2023-01-05 07:06:03,984 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45481283267339073, 'Total loss': 0.45481283267339073} | train loss {'Reaction outcome loss': 0.4036149154434274, 'Total loss': 0.4036149154434274}
2023-01-05 07:06:03,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:06:03,984 INFO:     Epoch: 28
2023-01-05 07:06:06,103 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41740189492702484, 'Total loss': 0.41740189492702484} | train loss {'Reaction outcome loss': 0.3964376674739869, 'Total loss': 0.3964376674739869}
2023-01-05 07:06:06,103 INFO:     Found new best model at epoch 28
2023-01-05 07:06:06,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:06:06,105 INFO:     Epoch: 29
2023-01-05 07:06:08,231 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4290161540110906, 'Total loss': 0.4290161540110906} | train loss {'Reaction outcome loss': 0.3958873851668267, 'Total loss': 0.3958873851668267}
2023-01-05 07:06:08,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:06:08,231 INFO:     Epoch: 30
2023-01-05 07:06:10,366 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4061269616087278, 'Total loss': 0.4061269616087278} | train loss {'Reaction outcome loss': 0.3893009678020582, 'Total loss': 0.3893009678020582}
2023-01-05 07:06:10,366 INFO:     Found new best model at epoch 30
2023-01-05 07:06:10,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:06:10,367 INFO:     Epoch: 31
2023-01-05 07:06:12,507 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43136523564656576, 'Total loss': 0.43136523564656576} | train loss {'Reaction outcome loss': 0.39134127837725174, 'Total loss': 0.39134127837725174}
2023-01-05 07:06:12,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:06:12,509 INFO:     Epoch: 32
2023-01-05 07:06:14,609 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.45116785963376366, 'Total loss': 0.45116785963376366} | train loss {'Reaction outcome loss': 0.3893048121378972, 'Total loss': 0.3893048121378972}
2023-01-05 07:06:14,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:06:14,609 INFO:     Epoch: 33
2023-01-05 07:06:16,723 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4586593230565389, 'Total loss': 0.4586593230565389} | train loss {'Reaction outcome loss': 0.38449623611765904, 'Total loss': 0.38449623611765904}
2023-01-05 07:06:16,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:06:16,723 INFO:     Epoch: 34
2023-01-05 07:06:18,867 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4208949387073517, 'Total loss': 0.4208949387073517} | train loss {'Reaction outcome loss': 0.37933135472047025, 'Total loss': 0.37933135472047025}
2023-01-05 07:06:18,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:06:18,867 INFO:     Epoch: 35
2023-01-05 07:06:21,017 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4340357999006907, 'Total loss': 0.4340357999006907} | train loss {'Reaction outcome loss': 0.38091912663681604, 'Total loss': 0.38091912663681604}
2023-01-05 07:06:21,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:06:21,017 INFO:     Epoch: 36
2023-01-05 07:06:23,147 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.462616511185964, 'Total loss': 0.462616511185964} | train loss {'Reaction outcome loss': 0.37862213875675377, 'Total loss': 0.37862213875675377}
2023-01-05 07:06:23,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:06:23,147 INFO:     Epoch: 37
2023-01-05 07:06:25,256 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43052642047405243, 'Total loss': 0.43052642047405243} | train loss {'Reaction outcome loss': 0.3733602952444073, 'Total loss': 0.3733602952444073}
2023-01-05 07:06:25,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:06:25,257 INFO:     Epoch: 38
2023-01-05 07:06:27,427 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39569268276294073, 'Total loss': 0.39569268276294073} | train loss {'Reaction outcome loss': 0.36491111911587665, 'Total loss': 0.36491111911587665}
2023-01-05 07:06:27,427 INFO:     Found new best model at epoch 38
2023-01-05 07:06:27,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:06:27,429 INFO:     Epoch: 39
2023-01-05 07:06:29,632 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42141398787498474, 'Total loss': 0.42141398787498474} | train loss {'Reaction outcome loss': 0.36214764484446565, 'Total loss': 0.36214764484446565}
2023-01-05 07:06:29,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:06:29,633 INFO:     Epoch: 40
2023-01-05 07:06:31,755 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4196966826915741, 'Total loss': 0.4196966826915741} | train loss {'Reaction outcome loss': 0.3628085260535335, 'Total loss': 0.3628085260535335}
2023-01-05 07:06:31,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:06:31,755 INFO:     Epoch: 41
2023-01-05 07:06:33,881 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.41126363078753153, 'Total loss': 0.41126363078753153} | train loss {'Reaction outcome loss': 0.35752487147138234, 'Total loss': 0.35752487147138234}
2023-01-05 07:06:33,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:06:33,882 INFO:     Epoch: 42
2023-01-05 07:06:36,022 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.413399883111318, 'Total loss': 0.413399883111318} | train loss {'Reaction outcome loss': 0.3584353279581655, 'Total loss': 0.3584353279581655}
2023-01-05 07:06:36,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:06:36,022 INFO:     Epoch: 43
2023-01-05 07:06:38,131 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4186953047911326, 'Total loss': 0.4186953047911326} | train loss {'Reaction outcome loss': 0.3545726657923543, 'Total loss': 0.3545726657923543}
2023-01-05 07:06:38,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:06:38,132 INFO:     Epoch: 44
2023-01-05 07:06:40,273 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.35841388007005054, 'Total loss': 0.35841388007005054} | train loss {'Reaction outcome loss': 0.34654430980920353, 'Total loss': 0.34654430980920353}
2023-01-05 07:06:40,273 INFO:     Found new best model at epoch 44
2023-01-05 07:06:40,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:06:40,275 INFO:     Epoch: 45
2023-01-05 07:06:42,429 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3885811964670817, 'Total loss': 0.3885811964670817} | train loss {'Reaction outcome loss': 0.34382668005527706, 'Total loss': 0.34382668005527706}
2023-01-05 07:06:42,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:06:42,429 INFO:     Epoch: 46
2023-01-05 07:06:44,555 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.38607702453931175, 'Total loss': 0.38607702453931175} | train loss {'Reaction outcome loss': 0.33533458474464034, 'Total loss': 0.33533458474464034}
2023-01-05 07:06:44,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:06:44,555 INFO:     Epoch: 47
2023-01-05 07:06:46,697 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.38631230741739275, 'Total loss': 0.38631230741739275} | train loss {'Reaction outcome loss': 0.34653636032626745, 'Total loss': 0.34653636032626745}
2023-01-05 07:06:46,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:06:46,697 INFO:     Epoch: 48
2023-01-05 07:06:48,821 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39537739555040996, 'Total loss': 0.39537739555040996} | train loss {'Reaction outcome loss': 0.34083618336926885, 'Total loss': 0.34083618336926885}
2023-01-05 07:06:48,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:06:48,822 INFO:     Epoch: 49
2023-01-05 07:06:50,957 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4155574947595596, 'Total loss': 0.4155574947595596} | train loss {'Reaction outcome loss': 0.3350970810995652, 'Total loss': 0.3350970810995652}
2023-01-05 07:06:50,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:06:50,957 INFO:     Epoch: 50
2023-01-05 07:06:53,087 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41898241142431897, 'Total loss': 0.41898241142431897} | train loss {'Reaction outcome loss': 0.33073419762345463, 'Total loss': 0.33073419762345463}
2023-01-05 07:06:53,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:06:53,087 INFO:     Epoch: 51
2023-01-05 07:06:55,213 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4190648039182027, 'Total loss': 0.4190648039182027} | train loss {'Reaction outcome loss': 0.33154245498743684, 'Total loss': 0.33154245498743684}
2023-01-05 07:06:55,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:06:55,214 INFO:     Epoch: 52
2023-01-05 07:06:57,340 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39252335429191587, 'Total loss': 0.39252335429191587} | train loss {'Reaction outcome loss': 0.32401296055633505, 'Total loss': 0.32401296055633505}
2023-01-05 07:06:57,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:06:57,341 INFO:     Epoch: 53
2023-01-05 07:06:59,511 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3794635732968648, 'Total loss': 0.3794635732968648} | train loss {'Reaction outcome loss': 0.3174135247416003, 'Total loss': 0.3174135247416003}
2023-01-05 07:06:59,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:06:59,512 INFO:     Epoch: 54
2023-01-05 07:07:01,676 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.38302852312723795, 'Total loss': 0.38302852312723795} | train loss {'Reaction outcome loss': 0.31858786985605625, 'Total loss': 0.31858786985605625}
2023-01-05 07:07:01,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:07:01,677 INFO:     Epoch: 55
2023-01-05 07:07:03,824 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3884318689505259, 'Total loss': 0.3884318689505259} | train loss {'Reaction outcome loss': 0.31243068384366524, 'Total loss': 0.31243068384366524}
2023-01-05 07:07:03,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:07:03,824 INFO:     Epoch: 56
2023-01-05 07:07:05,959 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42194747030735014, 'Total loss': 0.42194747030735014} | train loss {'Reaction outcome loss': 0.31920730376500134, 'Total loss': 0.31920730376500134}
2023-01-05 07:07:05,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:07:05,959 INFO:     Epoch: 57
2023-01-05 07:07:08,090 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3936959207057953, 'Total loss': 0.3936959207057953} | train loss {'Reaction outcome loss': 0.30899324794828675, 'Total loss': 0.30899324794828675}
2023-01-05 07:07:08,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:07:08,091 INFO:     Epoch: 58
2023-01-05 07:07:10,217 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4144188662370046, 'Total loss': 0.4144188662370046} | train loss {'Reaction outcome loss': 0.30893484500301627, 'Total loss': 0.30893484500301627}
2023-01-05 07:07:10,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:07:10,217 INFO:     Epoch: 59
2023-01-05 07:07:12,346 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3678327535589536, 'Total loss': 0.3678327535589536} | train loss {'Reaction outcome loss': 0.31772825989749404, 'Total loss': 0.31772825989749404}
2023-01-05 07:07:12,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:07:12,346 INFO:     Epoch: 60
2023-01-05 07:07:14,469 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44643528362115226, 'Total loss': 0.44643528362115226} | train loss {'Reaction outcome loss': 0.3132686763183101, 'Total loss': 0.3132686763183101}
2023-01-05 07:07:14,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:07:14,469 INFO:     Epoch: 61
2023-01-05 07:07:16,618 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4099182446797689, 'Total loss': 0.4099182446797689} | train loss {'Reaction outcome loss': 0.31251253515154453, 'Total loss': 0.31251253515154453}
2023-01-05 07:07:16,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:07:16,619 INFO:     Epoch: 62
2023-01-05 07:07:18,762 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43940432866414386, 'Total loss': 0.43940432866414386} | train loss {'Reaction outcome loss': 0.3039226456112041, 'Total loss': 0.3039226456112041}
2023-01-05 07:07:18,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:07:18,763 INFO:     Epoch: 63
2023-01-05 07:07:20,890 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4029536247253418, 'Total loss': 0.4029536247253418} | train loss {'Reaction outcome loss': 0.3027767017995427, 'Total loss': 0.3027767017995427}
2023-01-05 07:07:20,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:07:20,890 INFO:     Epoch: 64
2023-01-05 07:07:23,007 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3932571843266487, 'Total loss': 0.3932571843266487} | train loss {'Reaction outcome loss': 0.2974928034616177, 'Total loss': 0.2974928034616177}
2023-01-05 07:07:23,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:07:23,007 INFO:     Epoch: 65
2023-01-05 07:07:25,123 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.407875561217467, 'Total loss': 0.407875561217467} | train loss {'Reaction outcome loss': 0.2970615999957362, 'Total loss': 0.2970615999957362}
2023-01-05 07:07:25,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:07:25,124 INFO:     Epoch: 66
2023-01-05 07:07:27,244 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4222982630133629, 'Total loss': 0.4222982630133629} | train loss {'Reaction outcome loss': 0.2916268073431738, 'Total loss': 0.2916268073431738}
2023-01-05 07:07:27,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:07:27,245 INFO:     Epoch: 67
2023-01-05 07:07:29,354 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38985287547111513, 'Total loss': 0.38985287547111513} | train loss {'Reaction outcome loss': 0.29557571408676575, 'Total loss': 0.29557571408676575}
2023-01-05 07:07:29,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:07:29,355 INFO:     Epoch: 68
2023-01-05 07:07:31,480 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39841996630032855, 'Total loss': 0.39841996630032855} | train loss {'Reaction outcome loss': 0.28660073767214905, 'Total loss': 0.28660073767214905}
2023-01-05 07:07:31,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:07:31,480 INFO:     Epoch: 69
2023-01-05 07:07:33,601 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.38059644599755604, 'Total loss': 0.38059644599755604} | train loss {'Reaction outcome loss': 0.29086567445456873, 'Total loss': 0.29086567445456873}
2023-01-05 07:07:33,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:07:33,601 INFO:     Epoch: 70
2023-01-05 07:07:35,724 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40854475597540535, 'Total loss': 0.40854475597540535} | train loss {'Reaction outcome loss': 0.2937210320525772, 'Total loss': 0.2937210320525772}
2023-01-05 07:07:35,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:07:35,725 INFO:     Epoch: 71
2023-01-05 07:07:37,822 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3915459851423899, 'Total loss': 0.3915459851423899} | train loss {'Reaction outcome loss': 0.29160697528949153, 'Total loss': 0.29160697528949153}
2023-01-05 07:07:37,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:07:37,822 INFO:     Epoch: 72
2023-01-05 07:07:39,941 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3832943469285965, 'Total loss': 0.3832943469285965} | train loss {'Reaction outcome loss': 0.2913305567024828, 'Total loss': 0.2913305567024828}
2023-01-05 07:07:39,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:07:39,941 INFO:     Epoch: 73
2023-01-05 07:07:42,071 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3949059893687566, 'Total loss': 0.3949059893687566} | train loss {'Reaction outcome loss': 0.2834703563524908, 'Total loss': 0.2834703563524908}
2023-01-05 07:07:42,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:07:42,071 INFO:     Epoch: 74
2023-01-05 07:07:44,210 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.36466888102392353, 'Total loss': 0.36466888102392353} | train loss {'Reaction outcome loss': 0.2862214370197429, 'Total loss': 0.2862214370197429}
2023-01-05 07:07:44,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:07:44,210 INFO:     Epoch: 75
2023-01-05 07:07:46,336 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.40950331489245095, 'Total loss': 0.40950331489245095} | train loss {'Reaction outcome loss': 0.2858995561225292, 'Total loss': 0.2858995561225292}
2023-01-05 07:07:46,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:07:46,336 INFO:     Epoch: 76
2023-01-05 07:07:48,249 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.40204419791698454, 'Total loss': 0.40204419791698454} | train loss {'Reaction outcome loss': 0.27709697557429036, 'Total loss': 0.27709697557429036}
2023-01-05 07:07:48,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:07:48,249 INFO:     Epoch: 77
2023-01-05 07:07:50,140 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39233917395273843, 'Total loss': 0.39233917395273843} | train loss {'Reaction outcome loss': 0.27690112499363256, 'Total loss': 0.27690112499363256}
2023-01-05 07:07:50,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:07:50,140 INFO:     Epoch: 78
2023-01-05 07:07:51,879 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4220749229192734, 'Total loss': 0.4220749229192734} | train loss {'Reaction outcome loss': 0.2757513835436013, 'Total loss': 0.2757513835436013}
2023-01-05 07:07:51,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:07:51,880 INFO:     Epoch: 79
2023-01-05 07:07:53,689 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40813605884710946, 'Total loss': 0.40813605884710946} | train loss {'Reaction outcome loss': 0.27770668955949634, 'Total loss': 0.27770668955949634}
2023-01-05 07:07:53,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:07:53,689 INFO:     Epoch: 80
2023-01-05 07:07:55,837 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.35994345247745513, 'Total loss': 0.35994345247745513} | train loss {'Reaction outcome loss': 0.2892881069919129, 'Total loss': 0.2892881069919129}
2023-01-05 07:07:55,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:07:55,839 INFO:     Epoch: 81
2023-01-05 07:07:57,965 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3877711951732635, 'Total loss': 0.3877711951732635} | train loss {'Reaction outcome loss': 0.27942318182725173, 'Total loss': 0.27942318182725173}
2023-01-05 07:07:57,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:07:57,965 INFO:     Epoch: 82
2023-01-05 07:08:00,070 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.37224122087160744, 'Total loss': 0.37224122087160744} | train loss {'Reaction outcome loss': 0.2640249956835866, 'Total loss': 0.2640249956835866}
2023-01-05 07:08:00,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:08:00,071 INFO:     Epoch: 83
2023-01-05 07:08:02,190 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4124729037284851, 'Total loss': 0.4124729037284851} | train loss {'Reaction outcome loss': 0.26921451298840643, 'Total loss': 0.26921451298840643}
2023-01-05 07:08:02,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:08:02,191 INFO:     Epoch: 84
2023-01-05 07:08:04,309 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.378936671713988, 'Total loss': 0.378936671713988} | train loss {'Reaction outcome loss': 0.270516018905155, 'Total loss': 0.270516018905155}
2023-01-05 07:08:04,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:08:04,309 INFO:     Epoch: 85
2023-01-05 07:08:06,429 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3904185732205709, 'Total loss': 0.3904185732205709} | train loss {'Reaction outcome loss': 0.2615632576963458, 'Total loss': 0.2615632576963458}
2023-01-05 07:08:06,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:08:06,430 INFO:     Epoch: 86
2023-01-05 07:08:08,566 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.43381006121635435, 'Total loss': 0.43381006121635435} | train loss {'Reaction outcome loss': 0.26544515837679855, 'Total loss': 0.26544515837679855}
2023-01-05 07:08:08,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:08:08,566 INFO:     Epoch: 87
2023-01-05 07:08:10,693 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3991350700457891, 'Total loss': 0.3991350700457891} | train loss {'Reaction outcome loss': 0.26822631945321845, 'Total loss': 0.26822631945321845}
2023-01-05 07:08:10,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:08:10,693 INFO:     Epoch: 88
2023-01-05 07:08:12,815 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.394324499865373, 'Total loss': 0.394324499865373} | train loss {'Reaction outcome loss': 0.2592605256745012, 'Total loss': 0.2592605256745012}
2023-01-05 07:08:12,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:08:12,815 INFO:     Epoch: 89
2023-01-05 07:08:14,943 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3927490423123042, 'Total loss': 0.3927490423123042} | train loss {'Reaction outcome loss': 0.26395885692738785, 'Total loss': 0.26395885692738785}
2023-01-05 07:08:14,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:08:14,944 INFO:     Epoch: 90
2023-01-05 07:08:17,050 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41327587366104124, 'Total loss': 0.41327587366104124} | train loss {'Reaction outcome loss': 0.2706109141596617, 'Total loss': 0.2706109141596617}
2023-01-05 07:08:17,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:08:17,050 INFO:     Epoch: 91
2023-01-05 07:08:19,197 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.40406209031740825, 'Total loss': 0.40406209031740825} | train loss {'Reaction outcome loss': 0.25818760562244625, 'Total loss': 0.25818760562244625}
2023-01-05 07:08:19,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:08:19,197 INFO:     Epoch: 92
2023-01-05 07:08:21,322 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.362261201441288, 'Total loss': 0.362261201441288} | train loss {'Reaction outcome loss': 0.2619128903994958, 'Total loss': 0.2619128903994958}
2023-01-05 07:08:21,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:08:21,322 INFO:     Epoch: 93
2023-01-05 07:08:23,436 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.42039736012617746, 'Total loss': 0.42039736012617746} | train loss {'Reaction outcome loss': 0.26402866699129013, 'Total loss': 0.26402866699129013}
2023-01-05 07:08:23,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:08:23,436 INFO:     Epoch: 94
2023-01-05 07:08:25,575 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.393766975402832, 'Total loss': 0.393766975402832} | train loss {'Reaction outcome loss': 0.25797328384654533, 'Total loss': 0.25797328384654533}
2023-01-05 07:08:25,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:08:25,575 INFO:     Epoch: 95
2023-01-05 07:08:27,717 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3955451379219691, 'Total loss': 0.3955451379219691} | train loss {'Reaction outcome loss': 0.25912975216277573, 'Total loss': 0.25912975216277573}
2023-01-05 07:08:27,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:08:27,718 INFO:     Epoch: 96
2023-01-05 07:08:29,828 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3795093516508738, 'Total loss': 0.3795093516508738} | train loss {'Reaction outcome loss': 0.258004506729243, 'Total loss': 0.258004506729243}
2023-01-05 07:08:29,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:08:29,829 INFO:     Epoch: 97
2023-01-05 07:08:31,971 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.36614609832564987, 'Total loss': 0.36614609832564987} | train loss {'Reaction outcome loss': 0.24495850395643232, 'Total loss': 0.24495850395643232}
2023-01-05 07:08:31,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:08:31,971 INFO:     Epoch: 98
2023-01-05 07:08:34,080 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.40551806514461836, 'Total loss': 0.40551806514461836} | train loss {'Reaction outcome loss': 0.251611842402008, 'Total loss': 0.251611842402008}
2023-01-05 07:08:34,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:08:34,081 INFO:     Epoch: 99
2023-01-05 07:08:36,210 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4372863739728928, 'Total loss': 0.4372863739728928} | train loss {'Reaction outcome loss': 0.24741998388544545, 'Total loss': 0.24741998388544545}
2023-01-05 07:08:36,211 INFO:     Best model found after epoch 45 of 100.
2023-01-05 07:08:36,211 INFO:   Done with stage: TRAINING
2023-01-05 07:08:36,211 INFO:   Starting stage: EVALUATION
2023-01-05 07:08:36,355 INFO:   Done with stage: EVALUATION
2023-01-05 07:08:36,355 INFO:   Leaving out SEQ value Fold_1
2023-01-05 07:08:36,368 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 07:08:36,368 INFO:   Starting stage: FEATURE SCALING
2023-01-05 07:08:37,031 INFO:   Done with stage: FEATURE SCALING
2023-01-05 07:08:37,032 INFO:   Starting stage: SCALING TARGETS
2023-01-05 07:08:37,101 INFO:   Done with stage: SCALING TARGETS
2023-01-05 07:08:37,102 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:08:37,102 INFO:     No hyperparam tuning for this model
2023-01-05 07:08:37,102 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:08:37,102 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 07:08:37,103 INFO:     None feature selector for col prot
2023-01-05 07:08:37,103 INFO:     None feature selector for col prot
2023-01-05 07:08:37,103 INFO:     None feature selector for col prot
2023-01-05 07:08:37,103 INFO:     None feature selector for col chem
2023-01-05 07:08:37,103 INFO:     None feature selector for col chem
2023-01-05 07:08:37,103 INFO:     None feature selector for col chem
2023-01-05 07:08:37,104 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 07:08:37,104 INFO:   Starting stage: BUILD MODEL
2023-01-05 07:08:37,105 INFO:     Number of params in model 72901
2023-01-05 07:08:37,108 INFO:   Done with stage: BUILD MODEL
2023-01-05 07:08:37,108 INFO:   Starting stage: TRAINING
2023-01-05 07:08:37,168 INFO:     Val loss before train {'Reaction outcome loss': 1.003683908780416, 'Total loss': 1.003683908780416}
2023-01-05 07:08:37,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:08:37,168 INFO:     Epoch: 0
2023-01-05 07:08:39,318 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8515881141026814, 'Total loss': 0.8515881141026814} | train loss {'Reaction outcome loss': 0.9191112853586674, 'Total loss': 0.9191112853586674}
2023-01-05 07:08:39,318 INFO:     Found new best model at epoch 0
2023-01-05 07:08:39,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:08:39,319 INFO:     Epoch: 1
2023-01-05 07:08:41,464 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.706553602218628, 'Total loss': 0.706553602218628} | train loss {'Reaction outcome loss': 0.737437808683709, 'Total loss': 0.737437808683709}
2023-01-05 07:08:41,464 INFO:     Found new best model at epoch 1
2023-01-05 07:08:41,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:08:41,465 INFO:     Epoch: 2
2023-01-05 07:08:43,626 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5976189245780309, 'Total loss': 0.5976189245780309} | train loss {'Reaction outcome loss': 0.588708962381318, 'Total loss': 0.588708962381318}
2023-01-05 07:08:43,626 INFO:     Found new best model at epoch 2
2023-01-05 07:08:43,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:08:43,628 INFO:     Epoch: 3
2023-01-05 07:08:45,755 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6205342054367066, 'Total loss': 0.6205342054367066} | train loss {'Reaction outcome loss': 0.5486518960392129, 'Total loss': 0.5486518960392129}
2023-01-05 07:08:45,756 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:08:45,756 INFO:     Epoch: 4
2023-01-05 07:08:47,928 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.6285974860191346, 'Total loss': 0.6285974860191346} | train loss {'Reaction outcome loss': 0.531026338827307, 'Total loss': 0.531026338827307}
2023-01-05 07:08:47,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:08:47,928 INFO:     Epoch: 5
2023-01-05 07:08:50,121 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.6275871872901917, 'Total loss': 0.6275871872901917} | train loss {'Reaction outcome loss': 0.4997569042446929, 'Total loss': 0.4997569042446929}
2023-01-05 07:08:50,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:08:50,122 INFO:     Epoch: 6
2023-01-05 07:08:52,286 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.6014902333418528, 'Total loss': 0.6014902333418528} | train loss {'Reaction outcome loss': 0.5136322442820107, 'Total loss': 0.5136322442820107}
2023-01-05 07:08:52,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:08:52,286 INFO:     Epoch: 7
2023-01-05 07:08:54,469 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.6273009002208709, 'Total loss': 0.6273009002208709} | train loss {'Reaction outcome loss': 0.48064114320753276, 'Total loss': 0.48064114320753276}
2023-01-05 07:08:54,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:08:54,469 INFO:     Epoch: 8
2023-01-05 07:08:56,611 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5930156230926513, 'Total loss': 0.5930156230926513} | train loss {'Reaction outcome loss': 0.4738561873736731, 'Total loss': 0.4738561873736731}
2023-01-05 07:08:56,611 INFO:     Found new best model at epoch 8
2023-01-05 07:08:56,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:08:56,613 INFO:     Epoch: 9
2023-01-05 07:08:58,761 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5842238545417786, 'Total loss': 0.5842238545417786} | train loss {'Reaction outcome loss': 0.4735928365987712, 'Total loss': 0.4735928365987712}
2023-01-05 07:08:58,762 INFO:     Found new best model at epoch 9
2023-01-05 07:08:58,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:08:58,763 INFO:     Epoch: 10
2023-01-05 07:09:00,921 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.6251665969689687, 'Total loss': 0.6251665969689687} | train loss {'Reaction outcome loss': 0.46783722575375997, 'Total loss': 0.46783722575375997}
2023-01-05 07:09:00,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:09:00,921 INFO:     Epoch: 11
2023-01-05 07:09:03,069 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.6078180690606435, 'Total loss': 0.6078180690606435} | train loss {'Reaction outcome loss': 0.47312582397590514, 'Total loss': 0.47312582397590514}
2023-01-05 07:09:03,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:09:03,069 INFO:     Epoch: 12
2023-01-05 07:09:05,207 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5894364138444265, 'Total loss': 0.5894364138444265} | train loss {'Reaction outcome loss': 0.49300860624804255, 'Total loss': 0.49300860624804255}
2023-01-05 07:09:05,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:09:05,207 INFO:     Epoch: 13
2023-01-05 07:09:07,353 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5753122339646022, 'Total loss': 0.5753122339646022} | train loss {'Reaction outcome loss': 0.4578523386971674, 'Total loss': 0.4578523386971674}
2023-01-05 07:09:07,354 INFO:     Found new best model at epoch 13
2023-01-05 07:09:07,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:09:07,355 INFO:     Epoch: 14
2023-01-05 07:09:09,483 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5873861511548361, 'Total loss': 0.5873861511548361} | train loss {'Reaction outcome loss': 0.45390635146280317, 'Total loss': 0.45390635146280317}
2023-01-05 07:09:09,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:09:09,484 INFO:     Epoch: 15
2023-01-05 07:09:11,624 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.6076120277245839, 'Total loss': 0.6076120277245839} | train loss {'Reaction outcome loss': 0.44363214636383497, 'Total loss': 0.44363214636383497}
2023-01-05 07:09:11,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:09:11,625 INFO:     Epoch: 16
2023-01-05 07:09:13,777 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.601861642797788, 'Total loss': 0.601861642797788} | train loss {'Reaction outcome loss': 0.439509610836658, 'Total loss': 0.439509610836658}
2023-01-05 07:09:13,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:09:13,778 INFO:     Epoch: 17
2023-01-05 07:09:15,927 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5879833817481994, 'Total loss': 0.5879833817481994} | train loss {'Reaction outcome loss': 0.43701180513354315, 'Total loss': 0.43701180513354315}
2023-01-05 07:09:15,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:09:15,928 INFO:     Epoch: 18
2023-01-05 07:09:18,075 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.579882429043452, 'Total loss': 0.579882429043452} | train loss {'Reaction outcome loss': 0.43022537363012286, 'Total loss': 0.43022537363012286}
2023-01-05 07:09:18,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:09:18,075 INFO:     Epoch: 19
2023-01-05 07:09:20,202 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5807599147160848, 'Total loss': 0.5807599147160848} | train loss {'Reaction outcome loss': 0.43058357416969334, 'Total loss': 0.43058357416969334}
2023-01-05 07:09:20,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:09:20,202 INFO:     Epoch: 20
2023-01-05 07:09:22,342 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5552469422419866, 'Total loss': 0.5552469422419866} | train loss {'Reaction outcome loss': 0.4232791045311994, 'Total loss': 0.4232791045311994}
2023-01-05 07:09:22,343 INFO:     Found new best model at epoch 20
2023-01-05 07:09:22,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:09:22,344 INFO:     Epoch: 21
2023-01-05 07:09:24,499 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.54112229347229, 'Total loss': 0.54112229347229} | train loss {'Reaction outcome loss': 0.4245192547577313, 'Total loss': 0.4245192547577313}
2023-01-05 07:09:24,499 INFO:     Found new best model at epoch 21
2023-01-05 07:09:24,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:09:24,501 INFO:     Epoch: 22
2023-01-05 07:09:26,659 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5785546898841858, 'Total loss': 0.5785546898841858} | train loss {'Reaction outcome loss': 0.4236649200860141, 'Total loss': 0.4236649200860141}
2023-01-05 07:09:26,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:09:26,660 INFO:     Epoch: 23
2023-01-05 07:09:28,802 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5444014668464661, 'Total loss': 0.5444014668464661} | train loss {'Reaction outcome loss': 0.419841867205147, 'Total loss': 0.419841867205147}
2023-01-05 07:09:28,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:09:28,803 INFO:     Epoch: 24
2023-01-05 07:09:30,955 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5574912309646607, 'Total loss': 0.5574912309646607} | train loss {'Reaction outcome loss': 0.4110963924558482, 'Total loss': 0.4110963924558482}
2023-01-05 07:09:30,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:09:30,955 INFO:     Epoch: 25
2023-01-05 07:09:33,100 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5690142333507537, 'Total loss': 0.5690142333507537} | train loss {'Reaction outcome loss': 0.4101982139796693, 'Total loss': 0.4101982139796693}
2023-01-05 07:09:33,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:09:33,100 INFO:     Epoch: 26
2023-01-05 07:09:35,255 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5521738588809967, 'Total loss': 0.5521738588809967} | train loss {'Reaction outcome loss': 0.41519315859329875, 'Total loss': 0.41519315859329875}
2023-01-05 07:09:35,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:09:35,256 INFO:     Epoch: 27
2023-01-05 07:09:37,409 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5518812278906504, 'Total loss': 0.5518812278906504} | train loss {'Reaction outcome loss': 0.4082764683264321, 'Total loss': 0.4082764683264321}
2023-01-05 07:09:37,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:09:37,411 INFO:     Epoch: 28
2023-01-05 07:09:39,557 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5273295640945435, 'Total loss': 0.5273295640945435} | train loss {'Reaction outcome loss': 0.40129424271868047, 'Total loss': 0.40129424271868047}
2023-01-05 07:09:39,557 INFO:     Found new best model at epoch 28
2023-01-05 07:09:39,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:09:39,558 INFO:     Epoch: 29
2023-01-05 07:09:41,720 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5594336668650309, 'Total loss': 0.5594336668650309} | train loss {'Reaction outcome loss': 0.3977463986923702, 'Total loss': 0.3977463986923702}
2023-01-05 07:09:41,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:09:41,720 INFO:     Epoch: 30
2023-01-05 07:09:43,860 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5661862393220266, 'Total loss': 0.5661862393220266} | train loss {'Reaction outcome loss': 0.3909015376120806, 'Total loss': 0.3909015376120806}
2023-01-05 07:09:43,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:09:43,861 INFO:     Epoch: 31
2023-01-05 07:09:46,015 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5484855115413666, 'Total loss': 0.5484855115413666} | train loss {'Reaction outcome loss': 0.4000175900865292, 'Total loss': 0.4000175900865292}
2023-01-05 07:09:46,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:09:46,015 INFO:     Epoch: 32
2023-01-05 07:09:48,166 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5609538008769354, 'Total loss': 0.5609538008769354} | train loss {'Reaction outcome loss': 0.43444072754810686, 'Total loss': 0.43444072754810686}
2023-01-05 07:09:48,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:09:48,166 INFO:     Epoch: 33
2023-01-05 07:09:50,320 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5439969917138417, 'Total loss': 0.5439969917138417} | train loss {'Reaction outcome loss': 0.40452439794856787, 'Total loss': 0.40452439794856787}
2023-01-05 07:09:50,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:09:50,320 INFO:     Epoch: 34
2023-01-05 07:09:52,483 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5675298829873403, 'Total loss': 0.5675298829873403} | train loss {'Reaction outcome loss': 0.38251684774793143, 'Total loss': 0.38251684774793143}
2023-01-05 07:09:52,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:09:52,483 INFO:     Epoch: 35
2023-01-05 07:09:54,635 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5578917364279429, 'Total loss': 0.5578917364279429} | train loss {'Reaction outcome loss': 0.3848459745446841, 'Total loss': 0.3848459745446841}
2023-01-05 07:09:54,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:09:54,635 INFO:     Epoch: 36
2023-01-05 07:09:56,787 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5344831963380178, 'Total loss': 0.5344831963380178} | train loss {'Reaction outcome loss': 0.38743991032242775, 'Total loss': 0.38743991032242775}
2023-01-05 07:09:56,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:09:56,788 INFO:     Epoch: 37
2023-01-05 07:09:58,948 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.566381690899531, 'Total loss': 0.566381690899531} | train loss {'Reaction outcome loss': 0.38104480967951426, 'Total loss': 0.38104480967951426}
2023-01-05 07:09:58,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:09:58,948 INFO:     Epoch: 38
2023-01-05 07:10:01,107 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5350144555171331, 'Total loss': 0.5350144555171331} | train loss {'Reaction outcome loss': 0.37308567358126893, 'Total loss': 0.37308567358126893}
2023-01-05 07:10:01,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:10:01,108 INFO:     Epoch: 39
2023-01-05 07:10:03,252 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5467546880245209, 'Total loss': 0.5467546880245209} | train loss {'Reaction outcome loss': 0.37487665150800475, 'Total loss': 0.37487665150800475}
2023-01-05 07:10:03,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:10:03,252 INFO:     Epoch: 40
2023-01-05 07:10:05,415 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5786295890808105, 'Total loss': 0.5786295890808105} | train loss {'Reaction outcome loss': 0.4960583298318628, 'Total loss': 0.4960583298318628}
2023-01-05 07:10:05,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:10:05,416 INFO:     Epoch: 41
2023-01-05 07:10:07,560 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.51710551182429, 'Total loss': 0.51710551182429} | train loss {'Reaction outcome loss': 0.39452924055681715, 'Total loss': 0.39452924055681715}
2023-01-05 07:10:07,560 INFO:     Found new best model at epoch 41
2023-01-05 07:10:07,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:10:07,562 INFO:     Epoch: 42
2023-01-05 07:10:09,728 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5316914161046346, 'Total loss': 0.5316914161046346} | train loss {'Reaction outcome loss': 0.3751725165942765, 'Total loss': 0.3751725165942765}
2023-01-05 07:10:09,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:10:09,728 INFO:     Epoch: 43
2023-01-05 07:10:11,892 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5255233451724053, 'Total loss': 0.5255233451724053} | train loss {'Reaction outcome loss': 0.37638785074586456, 'Total loss': 0.37638785074586456}
2023-01-05 07:10:11,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:10:11,893 INFO:     Epoch: 44
2023-01-05 07:10:14,044 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5116987486680349, 'Total loss': 0.5116987486680349} | train loss {'Reaction outcome loss': 0.3821988010684541, 'Total loss': 0.3821988010684541}
2023-01-05 07:10:14,045 INFO:     Found new best model at epoch 44
2023-01-05 07:10:14,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:10:14,046 INFO:     Epoch: 45
2023-01-05 07:10:16,212 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4962255110343297, 'Total loss': 0.4962255110343297} | train loss {'Reaction outcome loss': 0.3612120340078853, 'Total loss': 0.3612120340078853}
2023-01-05 07:10:16,212 INFO:     Found new best model at epoch 45
2023-01-05 07:10:16,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:10:16,213 INFO:     Epoch: 46
2023-01-05 07:10:18,376 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5196710348129272, 'Total loss': 0.5196710348129272} | train loss {'Reaction outcome loss': 0.4377562603871068, 'Total loss': 0.4377562603871068}
2023-01-05 07:10:18,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:10:18,377 INFO:     Epoch: 47
2023-01-05 07:10:20,545 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5523823002974192, 'Total loss': 0.5523823002974192} | train loss {'Reaction outcome loss': 0.35404354666167387, 'Total loss': 0.35404354666167387}
2023-01-05 07:10:20,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:10:20,546 INFO:     Epoch: 48
2023-01-05 07:10:22,725 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5097372968991597, 'Total loss': 0.5097372968991597} | train loss {'Reaction outcome loss': 0.3481601353622587, 'Total loss': 0.3481601353622587}
2023-01-05 07:10:22,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:10:22,726 INFO:     Epoch: 49
2023-01-05 07:10:24,878 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5206744392712911, 'Total loss': 0.5206744392712911} | train loss {'Reaction outcome loss': 0.34384077840853855, 'Total loss': 0.34384077840853855}
2023-01-05 07:10:24,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:10:24,878 INFO:     Epoch: 50
2023-01-05 07:10:27,037 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5164518306652705, 'Total loss': 0.5164518306652705} | train loss {'Reaction outcome loss': 0.3443715653476724, 'Total loss': 0.3443715653476724}
2023-01-05 07:10:27,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:10:27,038 INFO:     Epoch: 51
2023-01-05 07:10:29,197 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5333001534144084, 'Total loss': 0.5333001534144084} | train loss {'Reaction outcome loss': 0.3368107310312368, 'Total loss': 0.3368107310312368}
2023-01-05 07:10:29,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:10:29,197 INFO:     Epoch: 52
2023-01-05 07:10:31,334 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5160000483194987, 'Total loss': 0.5160000483194987} | train loss {'Reaction outcome loss': 0.3359994681187622, 'Total loss': 0.3359994681187622}
2023-01-05 07:10:31,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:10:31,335 INFO:     Epoch: 53
2023-01-05 07:10:33,505 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5254931896924973, 'Total loss': 0.5254931896924973} | train loss {'Reaction outcome loss': 0.32509389756908774, 'Total loss': 0.32509389756908774}
2023-01-05 07:10:33,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:10:33,506 INFO:     Epoch: 54
2023-01-05 07:10:35,659 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5023466547330221, 'Total loss': 0.5023466547330221} | train loss {'Reaction outcome loss': 0.3337845313649598, 'Total loss': 0.3337845313649598}
2023-01-05 07:10:35,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:10:35,659 INFO:     Epoch: 55
2023-01-05 07:10:37,819 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4958688159783681, 'Total loss': 0.4958688159783681} | train loss {'Reaction outcome loss': 0.32348237384154555, 'Total loss': 0.32348237384154555}
2023-01-05 07:10:37,819 INFO:     Found new best model at epoch 55
2023-01-05 07:10:37,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:10:37,821 INFO:     Epoch: 56
2023-01-05 07:10:39,983 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5210080782572428, 'Total loss': 0.5210080782572428} | train loss {'Reaction outcome loss': 0.32146491856479587, 'Total loss': 0.32146491856479587}
2023-01-05 07:10:39,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:10:39,983 INFO:     Epoch: 57
2023-01-05 07:10:42,144 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.48731199006239573, 'Total loss': 0.48731199006239573} | train loss {'Reaction outcome loss': 0.3218114614721634, 'Total loss': 0.3218114614721634}
2023-01-05 07:10:42,144 INFO:     Found new best model at epoch 57
2023-01-05 07:10:42,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:10:42,145 INFO:     Epoch: 58
2023-01-05 07:10:44,302 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4860858385761579, 'Total loss': 0.4860858385761579} | train loss {'Reaction outcome loss': 0.3171425569108163, 'Total loss': 0.3171425569108163}
2023-01-05 07:10:44,303 INFO:     Found new best model at epoch 58
2023-01-05 07:10:44,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:10:44,304 INFO:     Epoch: 59
2023-01-05 07:10:46,464 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5214256763458252, 'Total loss': 0.5214256763458252} | train loss {'Reaction outcome loss': 0.31295741157246876, 'Total loss': 0.31295741157246876}
2023-01-05 07:10:46,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:10:46,464 INFO:     Epoch: 60
2023-01-05 07:10:48,613 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.49438637097676597, 'Total loss': 0.49438637097676597} | train loss {'Reaction outcome loss': 0.31579798762349115, 'Total loss': 0.31579798762349115}
2023-01-05 07:10:48,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:10:48,613 INFO:     Epoch: 61
2023-01-05 07:10:50,777 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5000839660565058, 'Total loss': 0.5000839660565058} | train loss {'Reaction outcome loss': 0.31492208656635595, 'Total loss': 0.31492208656635595}
2023-01-05 07:10:50,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:10:50,778 INFO:     Epoch: 62
2023-01-05 07:10:52,931 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5104990243911743, 'Total loss': 0.5104990243911743} | train loss {'Reaction outcome loss': 0.30908637259668414, 'Total loss': 0.30908637259668414}
2023-01-05 07:10:52,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:10:52,931 INFO:     Epoch: 63
2023-01-05 07:10:55,081 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.5100102643171947, 'Total loss': 0.5100102643171947} | train loss {'Reaction outcome loss': 0.3029094625908065, 'Total loss': 0.3029094625908065}
2023-01-05 07:10:55,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:10:55,081 INFO:     Epoch: 64
2023-01-05 07:10:57,251 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.489607048034668, 'Total loss': 0.489607048034668} | train loss {'Reaction outcome loss': 0.3042304837128039, 'Total loss': 0.3042304837128039}
2023-01-05 07:10:57,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:10:57,251 INFO:     Epoch: 65
2023-01-05 07:10:59,411 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.48060183227062225, 'Total loss': 0.48060183227062225} | train loss {'Reaction outcome loss': 0.3031151663424258, 'Total loss': 0.3031151663424258}
2023-01-05 07:10:59,411 INFO:     Found new best model at epoch 65
2023-01-05 07:10:59,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:10:59,412 INFO:     Epoch: 66
2023-01-05 07:11:01,582 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5151463488737742, 'Total loss': 0.5151463488737742} | train loss {'Reaction outcome loss': 0.3002750939298151, 'Total loss': 0.3002750939298151}
2023-01-05 07:11:01,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:11:01,582 INFO:     Epoch: 67
2023-01-05 07:11:03,751 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4791389375925064, 'Total loss': 0.4791389375925064} | train loss {'Reaction outcome loss': 0.3056471313258057, 'Total loss': 0.3056471313258057}
2023-01-05 07:11:03,751 INFO:     Found new best model at epoch 67
2023-01-05 07:11:03,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:11:03,753 INFO:     Epoch: 68
2023-01-05 07:11:05,899 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49379631678263347, 'Total loss': 0.49379631678263347} | train loss {'Reaction outcome loss': 0.29460080542971345, 'Total loss': 0.29460080542971345}
2023-01-05 07:11:05,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:11:05,900 INFO:     Epoch: 69
2023-01-05 07:11:08,050 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.5195010284582774, 'Total loss': 0.5195010284582774} | train loss {'Reaction outcome loss': 0.29049923058799165, 'Total loss': 0.29049923058799165}
2023-01-05 07:11:08,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:11:08,050 INFO:     Epoch: 70
2023-01-05 07:11:10,228 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4894042481978734, 'Total loss': 0.4894042481978734} | train loss {'Reaction outcome loss': 0.31826743275682995, 'Total loss': 0.31826743275682995}
2023-01-05 07:11:10,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:11:10,229 INFO:     Epoch: 71
2023-01-05 07:11:12,391 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46913905839125314, 'Total loss': 0.46913905839125314} | train loss {'Reaction outcome loss': 0.29118220267760014, 'Total loss': 0.29118220267760014}
2023-01-05 07:11:12,391 INFO:     Found new best model at epoch 71
2023-01-05 07:11:12,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:11:12,392 INFO:     Epoch: 72
2023-01-05 07:11:14,558 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.48736351331075034, 'Total loss': 0.48736351331075034} | train loss {'Reaction outcome loss': 0.2928405247486966, 'Total loss': 0.2928405247486966}
2023-01-05 07:11:14,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:11:14,559 INFO:     Epoch: 73
2023-01-05 07:11:16,729 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47604321042696635, 'Total loss': 0.47604321042696635} | train loss {'Reaction outcome loss': 0.28937883749334276, 'Total loss': 0.28937883749334276}
2023-01-05 07:11:16,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:11:16,729 INFO:     Epoch: 74
2023-01-05 07:11:18,878 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47896636128425596, 'Total loss': 0.47896636128425596} | train loss {'Reaction outcome loss': 0.2787977788091862, 'Total loss': 0.2787977788091862}
2023-01-05 07:11:18,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:11:18,878 INFO:     Epoch: 75
2023-01-05 07:11:21,046 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4854477564493815, 'Total loss': 0.4854477564493815} | train loss {'Reaction outcome loss': 0.27848458524280484, 'Total loss': 0.27848458524280484}
2023-01-05 07:11:21,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:11:21,047 INFO:     Epoch: 76
2023-01-05 07:11:23,202 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4691250860691071, 'Total loss': 0.4691250860691071} | train loss {'Reaction outcome loss': 0.28005968839483947, 'Total loss': 0.28005968839483947}
2023-01-05 07:11:23,202 INFO:     Found new best model at epoch 76
2023-01-05 07:11:23,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:11:23,203 INFO:     Epoch: 77
2023-01-05 07:11:25,369 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5136160085598628, 'Total loss': 0.5136160085598628} | train loss {'Reaction outcome loss': 0.2822577989570783, 'Total loss': 0.2822577989570783}
2023-01-05 07:11:25,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:11:25,369 INFO:     Epoch: 78
2023-01-05 07:11:27,529 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4609917402267456, 'Total loss': 0.4609917402267456} | train loss {'Reaction outcome loss': 0.2774721445643134, 'Total loss': 0.2774721445643134}
2023-01-05 07:11:27,529 INFO:     Found new best model at epoch 78
2023-01-05 07:11:27,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:11:27,530 INFO:     Epoch: 79
2023-01-05 07:11:29,682 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.46287611027558645, 'Total loss': 0.46287611027558645} | train loss {'Reaction outcome loss': 0.27795798522656434, 'Total loss': 0.27795798522656434}
2023-01-05 07:11:29,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:11:29,682 INFO:     Epoch: 80
2023-01-05 07:11:31,847 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5208578571677208, 'Total loss': 0.5208578571677208} | train loss {'Reaction outcome loss': 0.2741223392089444, 'Total loss': 0.2741223392089444}
2023-01-05 07:11:31,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:11:31,847 INFO:     Epoch: 81
2023-01-05 07:11:34,000 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4584654986858368, 'Total loss': 0.4584654986858368} | train loss {'Reaction outcome loss': 0.2731101065300459, 'Total loss': 0.2731101065300459}
2023-01-05 07:11:34,001 INFO:     Found new best model at epoch 81
2023-01-05 07:11:34,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:11:34,002 INFO:     Epoch: 82
2023-01-05 07:11:36,159 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4858437975247701, 'Total loss': 0.4858437975247701} | train loss {'Reaction outcome loss': 0.2741300159781847, 'Total loss': 0.2741300159781847}
2023-01-05 07:11:36,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:11:36,160 INFO:     Epoch: 83
2023-01-05 07:11:38,317 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46621079643567404, 'Total loss': 0.46621079643567404} | train loss {'Reaction outcome loss': 0.27271111080746935, 'Total loss': 0.27271111080746935}
2023-01-05 07:11:38,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:11:38,317 INFO:     Epoch: 84
2023-01-05 07:11:40,482 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4636433372894923, 'Total loss': 0.4636433372894923} | train loss {'Reaction outcome loss': 0.2852203188787984, 'Total loss': 0.2852203188787984}
2023-01-05 07:11:40,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:11:40,482 INFO:     Epoch: 85
2023-01-05 07:11:42,633 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.471718959013621, 'Total loss': 0.471718959013621} | train loss {'Reaction outcome loss': 0.2835039551799233, 'Total loss': 0.2835039551799233}
2023-01-05 07:11:42,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:11:42,634 INFO:     Epoch: 86
2023-01-05 07:11:44,800 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45870909839868546, 'Total loss': 0.45870909839868546} | train loss {'Reaction outcome loss': 0.2683613898006497, 'Total loss': 0.2683613898006497}
2023-01-05 07:11:44,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:11:44,801 INFO:     Epoch: 87
2023-01-05 07:11:46,953 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5030151416858037, 'Total loss': 0.5030151416858037} | train loss {'Reaction outcome loss': 0.26335393906101934, 'Total loss': 0.26335393906101934}
2023-01-05 07:11:46,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:11:46,953 INFO:     Epoch: 88
2023-01-05 07:11:49,119 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45415348609288536, 'Total loss': 0.45415348609288536} | train loss {'Reaction outcome loss': 0.2632706428648553, 'Total loss': 0.2632706428648553}
2023-01-05 07:11:49,119 INFO:     Found new best model at epoch 88
2023-01-05 07:11:49,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:11:49,121 INFO:     Epoch: 89
2023-01-05 07:11:51,286 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47210510571797687, 'Total loss': 0.47210510571797687} | train loss {'Reaction outcome loss': 0.25940046619380946, 'Total loss': 0.25940046619380946}
2023-01-05 07:11:51,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:11:51,287 INFO:     Epoch: 90
2023-01-05 07:11:53,226 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.45114736755688983, 'Total loss': 0.45114736755688983} | train loss {'Reaction outcome loss': 0.26516147569982684, 'Total loss': 0.26516147569982684}
2023-01-05 07:11:53,226 INFO:     Found new best model at epoch 90
2023-01-05 07:11:53,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:11:53,228 INFO:     Epoch: 91
2023-01-05 07:11:55,366 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5140825668970744, 'Total loss': 0.5140825668970744} | train loss {'Reaction outcome loss': 0.3356669877015836, 'Total loss': 0.3356669877015836}
2023-01-05 07:11:55,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:11:55,367 INFO:     Epoch: 92
2023-01-05 07:11:57,524 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4879903316497803, 'Total loss': 0.4879903316497803} | train loss {'Reaction outcome loss': 0.2713798908415534, 'Total loss': 0.2713798908415534}
2023-01-05 07:11:57,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:11:57,525 INFO:     Epoch: 93
2023-01-05 07:11:59,688 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5233876029650371, 'Total loss': 0.5233876029650371} | train loss {'Reaction outcome loss': 0.26517541529628086, 'Total loss': 0.26517541529628086}
2023-01-05 07:11:59,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:11:59,688 INFO:     Epoch: 94
2023-01-05 07:12:01,858 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4740798542896906, 'Total loss': 0.4740798542896906} | train loss {'Reaction outcome loss': 0.2588624412150028, 'Total loss': 0.2588624412150028}
2023-01-05 07:12:01,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:12:01,859 INFO:     Epoch: 95
2023-01-05 07:12:04,013 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.46545453866322833, 'Total loss': 0.46545453866322833} | train loss {'Reaction outcome loss': 0.2559845817032392, 'Total loss': 0.2559845817032392}
2023-01-05 07:12:04,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:12:04,014 INFO:     Epoch: 96
2023-01-05 07:12:06,168 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4855554888645808, 'Total loss': 0.4855554888645808} | train loss {'Reaction outcome loss': 0.2619255877297806, 'Total loss': 0.2619255877297806}
2023-01-05 07:12:06,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:12:06,168 INFO:     Epoch: 97
2023-01-05 07:12:08,308 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.48384297589461006, 'Total loss': 0.48384297589461006} | train loss {'Reaction outcome loss': 0.2588160045752506, 'Total loss': 0.2588160045752506}
2023-01-05 07:12:08,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:12:08,309 INFO:     Epoch: 98
2023-01-05 07:12:10,460 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4582960809270541, 'Total loss': 0.4582960809270541} | train loss {'Reaction outcome loss': 0.2553349765096926, 'Total loss': 0.2553349765096926}
2023-01-05 07:12:10,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:12:10,461 INFO:     Epoch: 99
2023-01-05 07:12:12,633 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5049219767252604, 'Total loss': 0.5049219767252604} | train loss {'Reaction outcome loss': 0.2576350424054038, 'Total loss': 0.2576350424054038}
2023-01-05 07:12:12,633 INFO:     Best model found after epoch 91 of 100.
2023-01-05 07:12:12,633 INFO:   Done with stage: TRAINING
2023-01-05 07:12:12,633 INFO:   Starting stage: EVALUATION
2023-01-05 07:12:12,765 INFO:   Done with stage: EVALUATION
2023-01-05 07:12:12,765 INFO:   Leaving out SEQ value Fold_2
2023-01-05 07:12:12,778 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 07:12:12,778 INFO:   Starting stage: FEATURE SCALING
2023-01-05 07:12:13,447 INFO:   Done with stage: FEATURE SCALING
2023-01-05 07:12:13,447 INFO:   Starting stage: SCALING TARGETS
2023-01-05 07:12:13,517 INFO:   Done with stage: SCALING TARGETS
2023-01-05 07:12:13,517 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:12:13,517 INFO:     No hyperparam tuning for this model
2023-01-05 07:12:13,517 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:12:13,517 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 07:12:13,518 INFO:     None feature selector for col prot
2023-01-05 07:12:13,518 INFO:     None feature selector for col prot
2023-01-05 07:12:13,518 INFO:     None feature selector for col prot
2023-01-05 07:12:13,519 INFO:     None feature selector for col chem
2023-01-05 07:12:13,519 INFO:     None feature selector for col chem
2023-01-05 07:12:13,519 INFO:     None feature selector for col chem
2023-01-05 07:12:13,519 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 07:12:13,519 INFO:   Starting stage: BUILD MODEL
2023-01-05 07:12:13,520 INFO:     Number of params in model 72901
2023-01-05 07:12:13,523 INFO:   Done with stage: BUILD MODEL
2023-01-05 07:12:13,523 INFO:   Starting stage: TRAINING
2023-01-05 07:12:13,584 INFO:     Val loss before train {'Reaction outcome loss': 0.9598373293876648, 'Total loss': 0.9598373293876648}
2023-01-05 07:12:13,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:12:13,584 INFO:     Epoch: 0
2023-01-05 07:12:15,724 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7712147851785024, 'Total loss': 0.7712147851785024} | train loss {'Reaction outcome loss': 0.9542557945216659, 'Total loss': 0.9542557945216659}
2023-01-05 07:12:15,724 INFO:     Found new best model at epoch 0
2023-01-05 07:12:15,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:12:15,725 INFO:     Epoch: 1
2023-01-05 07:12:17,871 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.621058835585912, 'Total loss': 0.621058835585912} | train loss {'Reaction outcome loss': 0.7809740632337375, 'Total loss': 0.7809740632337375}
2023-01-05 07:12:17,871 INFO:     Found new best model at epoch 1
2023-01-05 07:12:17,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:12:17,873 INFO:     Epoch: 2
2023-01-05 07:12:20,020 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4785154938697815, 'Total loss': 0.4785154938697815} | train loss {'Reaction outcome loss': 0.6120804446565844, 'Total loss': 0.6120804446565844}
2023-01-05 07:12:20,020 INFO:     Found new best model at epoch 2
2023-01-05 07:12:20,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:12:20,021 INFO:     Epoch: 3
2023-01-05 07:12:22,160 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48867090344429015, 'Total loss': 0.48867090344429015} | train loss {'Reaction outcome loss': 0.540998826388025, 'Total loss': 0.540998826388025}
2023-01-05 07:12:22,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:12:22,161 INFO:     Epoch: 4
2023-01-05 07:12:24,304 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.43888195157051085, 'Total loss': 0.43888195157051085} | train loss {'Reaction outcome loss': 0.515098232096129, 'Total loss': 0.515098232096129}
2023-01-05 07:12:24,304 INFO:     Found new best model at epoch 4
2023-01-05 07:12:24,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:12:24,306 INFO:     Epoch: 5
2023-01-05 07:12:26,462 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.41314815133810046, 'Total loss': 0.41314815133810046} | train loss {'Reaction outcome loss': 0.5000618066992203, 'Total loss': 0.5000618066992203}
2023-01-05 07:12:26,462 INFO:     Found new best model at epoch 5
2023-01-05 07:12:26,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:12:26,463 INFO:     Epoch: 6
2023-01-05 07:12:28,598 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4791688323020935, 'Total loss': 0.4791688323020935} | train loss {'Reaction outcome loss': 0.4885912860886459, 'Total loss': 0.4885912860886459}
2023-01-05 07:12:28,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:12:28,599 INFO:     Epoch: 7
2023-01-05 07:12:30,748 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.42022106250127156, 'Total loss': 0.42022106250127156} | train loss {'Reaction outcome loss': 0.4839540069011876, 'Total loss': 0.4839540069011876}
2023-01-05 07:12:30,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:12:30,749 INFO:     Epoch: 8
2023-01-05 07:12:32,882 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.40029167334238686, 'Total loss': 0.40029167334238686} | train loss {'Reaction outcome loss': 0.478793212260208, 'Total loss': 0.478793212260208}
2023-01-05 07:12:32,882 INFO:     Found new best model at epoch 8
2023-01-05 07:12:32,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:12:32,884 INFO:     Epoch: 9
2023-01-05 07:12:35,023 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.3990883260965347, 'Total loss': 0.3990883260965347} | train loss {'Reaction outcome loss': 0.4738739972023198, 'Total loss': 0.4738739972023198}
2023-01-05 07:12:35,023 INFO:     Found new best model at epoch 9
2023-01-05 07:12:35,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:12:35,025 INFO:     Epoch: 10
2023-01-05 07:12:37,181 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.400335160891215, 'Total loss': 0.400335160891215} | train loss {'Reaction outcome loss': 0.46180646143255444, 'Total loss': 0.46180646143255444}
2023-01-05 07:12:37,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:12:37,181 INFO:     Epoch: 11
2023-01-05 07:12:39,301 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4069499373435974, 'Total loss': 0.4069499373435974} | train loss {'Reaction outcome loss': 0.4628444015979767, 'Total loss': 0.4628444015979767}
2023-01-05 07:12:39,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:12:39,301 INFO:     Epoch: 12
2023-01-05 07:12:41,451 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.40849426090717317, 'Total loss': 0.40849426090717317} | train loss {'Reaction outcome loss': 0.4563383249579555, 'Total loss': 0.4563383249579555}
2023-01-05 07:12:41,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:12:41,452 INFO:     Epoch: 13
2023-01-05 07:12:43,591 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.41848241289456684, 'Total loss': 0.41848241289456684} | train loss {'Reaction outcome loss': 0.45285437984840715, 'Total loss': 0.45285437984840715}
2023-01-05 07:12:43,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:12:43,591 INFO:     Epoch: 14
2023-01-05 07:12:45,736 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.40807582835356393, 'Total loss': 0.40807582835356393} | train loss {'Reaction outcome loss': 0.4444825439883845, 'Total loss': 0.4444825439883845}
2023-01-05 07:12:45,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:12:45,736 INFO:     Epoch: 15
2023-01-05 07:12:47,886 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43942973514397937, 'Total loss': 0.43942973514397937} | train loss {'Reaction outcome loss': 0.44341302325908283, 'Total loss': 0.44341302325908283}
2023-01-05 07:12:47,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:12:47,887 INFO:     Epoch: 16
2023-01-05 07:12:50,034 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3707178781429927, 'Total loss': 0.3707178781429927} | train loss {'Reaction outcome loss': 0.4441996798408728, 'Total loss': 0.4441996798408728}
2023-01-05 07:12:50,034 INFO:     Found new best model at epoch 16
2023-01-05 07:12:50,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:12:50,036 INFO:     Epoch: 17
2023-01-05 07:12:52,173 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40692355036735534, 'Total loss': 0.40692355036735534} | train loss {'Reaction outcome loss': 0.4374588187919916, 'Total loss': 0.4374588187919916}
2023-01-05 07:12:52,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:12:52,175 INFO:     Epoch: 18
2023-01-05 07:12:54,329 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3757329334815343, 'Total loss': 0.3757329334815343} | train loss {'Reaction outcome loss': 0.4402690566804287, 'Total loss': 0.4402690566804287}
2023-01-05 07:12:54,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:12:54,329 INFO:     Epoch: 19
2023-01-05 07:12:56,478 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.39281903505325316, 'Total loss': 0.39281903505325316} | train loss {'Reaction outcome loss': 0.42824676551305463, 'Total loss': 0.42824676551305463}
2023-01-05 07:12:56,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:12:56,478 INFO:     Epoch: 20
2023-01-05 07:12:58,648 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3954297343889872, 'Total loss': 0.3954297343889872} | train loss {'Reaction outcome loss': 0.43102464620975683, 'Total loss': 0.43102464620975683}
2023-01-05 07:12:58,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:12:58,649 INFO:     Epoch: 21
2023-01-05 07:13:00,807 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3750601241985957, 'Total loss': 0.3750601241985957} | train loss {'Reaction outcome loss': 0.4263654814856331, 'Total loss': 0.4263654814856331}
2023-01-05 07:13:00,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:13:00,808 INFO:     Epoch: 22
2023-01-05 07:13:02,944 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4086919883886973, 'Total loss': 0.4086919883886973} | train loss {'Reaction outcome loss': 0.4236727631005057, 'Total loss': 0.4236727631005057}
2023-01-05 07:13:02,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:13:02,944 INFO:     Epoch: 23
2023-01-05 07:13:05,085 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4026218016942342, 'Total loss': 0.4026218016942342} | train loss {'Reaction outcome loss': 0.4191164982906223, 'Total loss': 0.4191164982906223}
2023-01-05 07:13:05,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:13:05,085 INFO:     Epoch: 24
2023-01-05 07:13:07,198 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3823201576868693, 'Total loss': 0.3823201576868693} | train loss {'Reaction outcome loss': 0.41283435755184966, 'Total loss': 0.41283435755184966}
2023-01-05 07:13:07,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:13:07,199 INFO:     Epoch: 25
2023-01-05 07:13:09,351 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3834797223409017, 'Total loss': 0.3834797223409017} | train loss {'Reaction outcome loss': 0.4087548317917942, 'Total loss': 0.4087548317917942}
2023-01-05 07:13:09,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:13:09,351 INFO:     Epoch: 26
2023-01-05 07:13:11,497 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3871808111667633, 'Total loss': 0.3871808111667633} | train loss {'Reaction outcome loss': 0.4090351130079179, 'Total loss': 0.4090351130079179}
2023-01-05 07:13:11,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:13:11,498 INFO:     Epoch: 27
2023-01-05 07:13:13,638 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3899816711743673, 'Total loss': 0.3899816711743673} | train loss {'Reaction outcome loss': 0.400806508061007, 'Total loss': 0.400806508061007}
2023-01-05 07:13:13,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:13:13,639 INFO:     Epoch: 28
2023-01-05 07:13:15,782 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.38038182457288106, 'Total loss': 0.38038182457288106} | train loss {'Reaction outcome loss': 0.3970426396623145, 'Total loss': 0.3970426396623145}
2023-01-05 07:13:15,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:13:15,782 INFO:     Epoch: 29
2023-01-05 07:13:17,993 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3871142536401749, 'Total loss': 0.3871142536401749} | train loss {'Reaction outcome loss': 0.3952351492850015, 'Total loss': 0.3952351492850015}
2023-01-05 07:13:17,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:13:17,993 INFO:     Epoch: 30
2023-01-05 07:13:20,183 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.37886808514595033, 'Total loss': 0.37886808514595033} | train loss {'Reaction outcome loss': 0.3908738575902951, 'Total loss': 0.3908738575902951}
2023-01-05 07:13:20,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:13:20,183 INFO:     Epoch: 31
2023-01-05 07:13:22,325 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.37734747727712, 'Total loss': 0.37734747727712} | train loss {'Reaction outcome loss': 0.39280057627789294, 'Total loss': 0.39280057627789294}
2023-01-05 07:13:22,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:13:22,325 INFO:     Epoch: 32
2023-01-05 07:13:24,468 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.37766709327697756, 'Total loss': 0.37766709327697756} | train loss {'Reaction outcome loss': 0.3853355136013379, 'Total loss': 0.3853355136013379}
2023-01-05 07:13:24,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:13:24,469 INFO:     Epoch: 33
2023-01-05 07:13:26,585 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3480943863590558, 'Total loss': 0.3480943863590558} | train loss {'Reaction outcome loss': 0.39045628750302497, 'Total loss': 0.39045628750302497}
2023-01-05 07:13:26,585 INFO:     Found new best model at epoch 33
2023-01-05 07:13:26,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:13:26,587 INFO:     Epoch: 34
2023-01-05 07:13:28,728 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.40454513728618624, 'Total loss': 0.40454513728618624} | train loss {'Reaction outcome loss': 0.38054269255839124, 'Total loss': 0.38054269255839124}
2023-01-05 07:13:28,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:13:28,729 INFO:     Epoch: 35
2023-01-05 07:13:30,884 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.354180050889651, 'Total loss': 0.354180050889651} | train loss {'Reaction outcome loss': 0.3840185304981296, 'Total loss': 0.3840185304981296}
2023-01-05 07:13:30,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:13:30,884 INFO:     Epoch: 36
2023-01-05 07:13:33,039 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3630566994349162, 'Total loss': 0.3630566994349162} | train loss {'Reaction outcome loss': 0.3750249611037056, 'Total loss': 0.3750249611037056}
2023-01-05 07:13:33,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:13:33,040 INFO:     Epoch: 37
2023-01-05 07:13:35,179 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.34887879391511284, 'Total loss': 0.34887879391511284} | train loss {'Reaction outcome loss': 0.37317582981212294, 'Total loss': 0.37317582981212294}
2023-01-05 07:13:35,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:13:35,180 INFO:     Epoch: 38
2023-01-05 07:13:37,336 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3716125736633937, 'Total loss': 0.3716125736633937} | train loss {'Reaction outcome loss': 0.3659811620022694, 'Total loss': 0.3659811620022694}
2023-01-05 07:13:37,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:13:37,337 INFO:     Epoch: 39
2023-01-05 07:13:39,466 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.377877351641655, 'Total loss': 0.377877351641655} | train loss {'Reaction outcome loss': 0.36585529129544314, 'Total loss': 0.36585529129544314}
2023-01-05 07:13:39,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:13:39,466 INFO:     Epoch: 40
2023-01-05 07:13:41,613 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.34753771622975665, 'Total loss': 0.34753771622975665} | train loss {'Reaction outcome loss': 0.361098278368259, 'Total loss': 0.361098278368259}
2023-01-05 07:13:41,613 INFO:     Found new best model at epoch 40
2023-01-05 07:13:41,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:13:41,614 INFO:     Epoch: 41
2023-01-05 07:13:43,777 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3422361820936203, 'Total loss': 0.3422361820936203} | train loss {'Reaction outcome loss': 0.3570046417659869, 'Total loss': 0.3570046417659869}
2023-01-05 07:13:43,777 INFO:     Found new best model at epoch 41
2023-01-05 07:13:43,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:13:43,779 INFO:     Epoch: 42
2023-01-05 07:13:45,961 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38650919099648795, 'Total loss': 0.38650919099648795} | train loss {'Reaction outcome loss': 0.35558166743738806, 'Total loss': 0.35558166743738806}
2023-01-05 07:13:45,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:13:45,961 INFO:     Epoch: 43
2023-01-05 07:13:48,157 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3436737229426702, 'Total loss': 0.3436737229426702} | train loss {'Reaction outcome loss': 0.35555301345612883, 'Total loss': 0.35555301345612883}
2023-01-05 07:13:48,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:13:48,158 INFO:     Epoch: 44
2023-01-05 07:13:50,318 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3762208729982376, 'Total loss': 0.3762208729982376} | train loss {'Reaction outcome loss': 0.36028441789485244, 'Total loss': 0.36028441789485244}
2023-01-05 07:13:50,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:13:50,319 INFO:     Epoch: 45
2023-01-05 07:13:52,468 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.35466783319910367, 'Total loss': 0.35466783319910367} | train loss {'Reaction outcome loss': 0.34768573219214916, 'Total loss': 0.34768573219214916}
2023-01-05 07:13:52,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:13:52,468 INFO:     Epoch: 46
2023-01-05 07:13:54,623 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3292455087105433, 'Total loss': 0.3292455087105433} | train loss {'Reaction outcome loss': 0.3445882524234535, 'Total loss': 0.3445882524234535}
2023-01-05 07:13:54,623 INFO:     Found new best model at epoch 46
2023-01-05 07:13:54,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:13:54,625 INFO:     Epoch: 47
2023-01-05 07:13:56,808 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3501251737276713, 'Total loss': 0.3501251737276713} | train loss {'Reaction outcome loss': 0.343436779848633, 'Total loss': 0.343436779848633}
2023-01-05 07:13:56,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:13:56,809 INFO:     Epoch: 48
2023-01-05 07:13:59,006 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.358932093779246, 'Total loss': 0.358932093779246} | train loss {'Reaction outcome loss': 0.33711477271179213, 'Total loss': 0.33711477271179213}
2023-01-05 07:13:59,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:13:59,006 INFO:     Epoch: 49
2023-01-05 07:14:01,185 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.36411676605542503, 'Total loss': 0.36411676605542503} | train loss {'Reaction outcome loss': 0.33004380632055935, 'Total loss': 0.33004380632055935}
2023-01-05 07:14:01,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:14:01,185 INFO:     Epoch: 50
2023-01-05 07:14:03,310 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.33260908325513205, 'Total loss': 0.33260908325513205} | train loss {'Reaction outcome loss': 0.33108431571265207, 'Total loss': 0.33108431571265207}
2023-01-05 07:14:03,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:14:03,312 INFO:     Epoch: 51
2023-01-05 07:14:05,462 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.33524940808614095, 'Total loss': 0.33524940808614095} | train loss {'Reaction outcome loss': 0.3289633235846558, 'Total loss': 0.3289633235846558}
2023-01-05 07:14:05,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:14:05,462 INFO:     Epoch: 52
2023-01-05 07:14:07,620 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.37523110459248227, 'Total loss': 0.37523110459248227} | train loss {'Reaction outcome loss': 0.3239318886567859, 'Total loss': 0.3239318886567859}
2023-01-05 07:14:07,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:14:07,621 INFO:     Epoch: 53
2023-01-05 07:14:09,769 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.35565438667933147, 'Total loss': 0.35565438667933147} | train loss {'Reaction outcome loss': 0.3258052934369032, 'Total loss': 0.3258052934369032}
2023-01-05 07:14:09,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:14:09,770 INFO:     Epoch: 54
2023-01-05 07:14:11,921 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3316351721684138, 'Total loss': 0.3316351721684138} | train loss {'Reaction outcome loss': 0.3252655770765604, 'Total loss': 0.3252655770765604}
2023-01-05 07:14:11,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:14:11,921 INFO:     Epoch: 55
2023-01-05 07:14:14,054 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3185168720781803, 'Total loss': 0.3185168720781803} | train loss {'Reaction outcome loss': 0.3204815578612968, 'Total loss': 0.3204815578612968}
2023-01-05 07:14:14,054 INFO:     Found new best model at epoch 55
2023-01-05 07:14:14,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:14:14,055 INFO:     Epoch: 56
2023-01-05 07:14:16,208 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.34962641398111977, 'Total loss': 0.34962641398111977} | train loss {'Reaction outcome loss': 0.31347212551610315, 'Total loss': 0.31347212551610315}
2023-01-05 07:14:16,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:14:16,208 INFO:     Epoch: 57
2023-01-05 07:14:18,357 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3763357371091843, 'Total loss': 0.3763357371091843} | train loss {'Reaction outcome loss': 0.31595328128658723, 'Total loss': 0.31595328128658723}
2023-01-05 07:14:18,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:14:18,358 INFO:     Epoch: 58
2023-01-05 07:14:20,506 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3432204067707062, 'Total loss': 0.3432204067707062} | train loss {'Reaction outcome loss': 0.3095571673917074, 'Total loss': 0.3095571673917074}
2023-01-05 07:14:20,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:14:20,507 INFO:     Epoch: 59
2023-01-05 07:14:22,668 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.33696918686230976, 'Total loss': 0.33696918686230976} | train loss {'Reaction outcome loss': 0.3097157197168274, 'Total loss': 0.3097157197168274}
2023-01-05 07:14:22,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:14:22,668 INFO:     Epoch: 60
2023-01-05 07:14:24,809 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3427650113900503, 'Total loss': 0.3427650113900503} | train loss {'Reaction outcome loss': 0.30222618044184074, 'Total loss': 0.30222618044184074}
2023-01-05 07:14:24,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:14:24,810 INFO:     Epoch: 61
2023-01-05 07:14:26,967 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3777265101671219, 'Total loss': 0.3777265101671219} | train loss {'Reaction outcome loss': 0.30718505779539584, 'Total loss': 0.30718505779539584}
2023-01-05 07:14:26,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:14:26,967 INFO:     Epoch: 62
2023-01-05 07:14:29,109 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3919222886363665, 'Total loss': 0.3919222886363665} | train loss {'Reaction outcome loss': 0.3014570390329744, 'Total loss': 0.3014570390329744}
2023-01-05 07:14:29,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:14:29,109 INFO:     Epoch: 63
2023-01-05 07:14:31,264 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3733047197262446, 'Total loss': 0.3733047197262446} | train loss {'Reaction outcome loss': 0.2972635161811418, 'Total loss': 0.2972635161811418}
2023-01-05 07:14:31,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:14:31,264 INFO:     Epoch: 64
2023-01-05 07:14:33,420 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.397572868069013, 'Total loss': 0.397572868069013} | train loss {'Reaction outcome loss': 0.3000505451575248, 'Total loss': 0.3000505451575248}
2023-01-05 07:14:33,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:14:33,420 INFO:     Epoch: 65
2023-01-05 07:14:35,582 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.34620393017927803, 'Total loss': 0.34620393017927803} | train loss {'Reaction outcome loss': 0.3025671098326897, 'Total loss': 0.3025671098326897}
2023-01-05 07:14:35,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:14:35,582 INFO:     Epoch: 66
2023-01-05 07:14:37,710 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.37233608961105347, 'Total loss': 0.37233608961105347} | train loss {'Reaction outcome loss': 0.28906881149831043, 'Total loss': 0.28906881149831043}
2023-01-05 07:14:37,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:14:37,710 INFO:     Epoch: 67
2023-01-05 07:14:39,858 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.32082847952842714, 'Total loss': 0.32082847952842714} | train loss {'Reaction outcome loss': 0.2948296966751779, 'Total loss': 0.2948296966751779}
2023-01-05 07:14:39,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:14:39,859 INFO:     Epoch: 68
2023-01-05 07:14:42,008 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.35562421679496764, 'Total loss': 0.35562421679496764} | train loss {'Reaction outcome loss': 0.29245696310633723, 'Total loss': 0.29245696310633723}
2023-01-05 07:14:42,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:14:42,008 INFO:     Epoch: 69
2023-01-05 07:14:44,164 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3762449473142624, 'Total loss': 0.3762449473142624} | train loss {'Reaction outcome loss': 0.28943381862320605, 'Total loss': 0.28943381862320605}
2023-01-05 07:14:44,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:14:44,164 INFO:     Epoch: 70
2023-01-05 07:14:46,317 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3703463276227315, 'Total loss': 0.3703463276227315} | train loss {'Reaction outcome loss': 0.2939962217733808, 'Total loss': 0.2939962217733808}
2023-01-05 07:14:46,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:14:46,318 INFO:     Epoch: 71
2023-01-05 07:14:48,460 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.37115958631038665, 'Total loss': 0.37115958631038665} | train loss {'Reaction outcome loss': 0.29545509720044416, 'Total loss': 0.29545509720044416}
2023-01-05 07:14:48,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:14:48,460 INFO:     Epoch: 72
2023-01-05 07:14:50,616 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.35524792969226837, 'Total loss': 0.35524792969226837} | train loss {'Reaction outcome loss': 0.2870353641138025, 'Total loss': 0.2870353641138025}
2023-01-05 07:14:50,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:14:50,616 INFO:     Epoch: 73
2023-01-05 07:14:52,753 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.36212535202503204, 'Total loss': 0.36212535202503204} | train loss {'Reaction outcome loss': 0.2820954797449556, 'Total loss': 0.2820954797449556}
2023-01-05 07:14:52,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:14:52,753 INFO:     Epoch: 74
2023-01-05 07:14:54,905 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.33771003236373265, 'Total loss': 0.33771003236373265} | train loss {'Reaction outcome loss': 0.2828409267575854, 'Total loss': 0.2828409267575854}
2023-01-05 07:14:54,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:14:54,906 INFO:     Epoch: 75
2023-01-05 07:14:57,065 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3367460230986277, 'Total loss': 0.3367460230986277} | train loss {'Reaction outcome loss': 0.277402975467326, 'Total loss': 0.277402975467326}
2023-01-05 07:14:57,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:14:57,066 INFO:     Epoch: 76
2023-01-05 07:14:59,227 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.36160076161225635, 'Total loss': 0.36160076161225635} | train loss {'Reaction outcome loss': 0.2770331941653777, 'Total loss': 0.2770331941653777}
2023-01-05 07:14:59,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:14:59,228 INFO:     Epoch: 77
2023-01-05 07:15:01,360 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.35683874487876893, 'Total loss': 0.35683874487876893} | train loss {'Reaction outcome loss': 0.2757473132865381, 'Total loss': 0.2757473132865381}
2023-01-05 07:15:01,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:15:01,361 INFO:     Epoch: 78
2023-01-05 07:15:03,492 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3546008785565694, 'Total loss': 0.3546008785565694} | train loss {'Reaction outcome loss': 0.2743457520829283, 'Total loss': 0.2743457520829283}
2023-01-05 07:15:03,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:15:03,492 INFO:     Epoch: 79
2023-01-05 07:15:05,620 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3531233976284663, 'Total loss': 0.3531233976284663} | train loss {'Reaction outcome loss': 0.2754435965614597, 'Total loss': 0.2754435965614597}
2023-01-05 07:15:05,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:15:05,621 INFO:     Epoch: 80
2023-01-05 07:15:07,766 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3622857887297869, 'Total loss': 0.3622857887297869} | train loss {'Reaction outcome loss': 0.2722694648049065, 'Total loss': 0.2722694648049065}
2023-01-05 07:15:07,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:15:07,767 INFO:     Epoch: 81
2023-01-05 07:15:09,923 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.35493297427892684, 'Total loss': 0.35493297427892684} | train loss {'Reaction outcome loss': 0.2708011185274507, 'Total loss': 0.2708011185274507}
2023-01-05 07:15:09,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:15:09,924 INFO:     Epoch: 82
2023-01-05 07:15:12,064 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3412357618411382, 'Total loss': 0.3412357618411382} | train loss {'Reaction outcome loss': 0.2646234236576044, 'Total loss': 0.2646234236576044}
2023-01-05 07:15:12,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:15:12,065 INFO:     Epoch: 83
2023-01-05 07:15:14,220 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4032374620437622, 'Total loss': 0.4032374620437622} | train loss {'Reaction outcome loss': 0.2792469883867859, 'Total loss': 0.2792469883867859}
2023-01-05 07:15:14,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:15:14,220 INFO:     Epoch: 84
2023-01-05 07:15:16,370 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3487426201502482, 'Total loss': 0.3487426201502482} | train loss {'Reaction outcome loss': 0.2631976646813054, 'Total loss': 0.2631976646813054}
2023-01-05 07:15:16,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:15:16,371 INFO:     Epoch: 85
2023-01-05 07:15:18,519 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3457046769559383, 'Total loss': 0.3457046769559383} | train loss {'Reaction outcome loss': 0.2681350933292704, 'Total loss': 0.2681350933292704}
2023-01-05 07:15:18,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:15:18,519 INFO:     Epoch: 86
2023-01-05 07:15:20,674 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.37230342427889507, 'Total loss': 0.37230342427889507} | train loss {'Reaction outcome loss': 0.26033812857838007, 'Total loss': 0.26033812857838007}
2023-01-05 07:15:20,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:15:20,674 INFO:     Epoch: 87
2023-01-05 07:15:22,831 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3479079633951187, 'Total loss': 0.3479079633951187} | train loss {'Reaction outcome loss': 0.2627694803514402, 'Total loss': 0.2627694803514402}
2023-01-05 07:15:22,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:15:22,832 INFO:     Epoch: 88
2023-01-05 07:15:24,962 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3449192653099696, 'Total loss': 0.3449192653099696} | train loss {'Reaction outcome loss': 0.2609452968123403, 'Total loss': 0.2609452968123403}
2023-01-05 07:15:24,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:15:24,962 INFO:     Epoch: 89
2023-01-05 07:15:27,114 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3319576196372509, 'Total loss': 0.3319576196372509} | train loss {'Reaction outcome loss': 0.26526450506499866, 'Total loss': 0.26526450506499866}
2023-01-05 07:15:27,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:15:27,115 INFO:     Epoch: 90
2023-01-05 07:15:29,270 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.32813736200332644, 'Total loss': 0.32813736200332644} | train loss {'Reaction outcome loss': 0.2541694154378271, 'Total loss': 0.2541694154378271}
2023-01-05 07:15:29,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:15:29,271 INFO:     Epoch: 91
2023-01-05 07:15:31,423 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3648936164875825, 'Total loss': 0.3648936164875825} | train loss {'Reaction outcome loss': 0.253453374874309, 'Total loss': 0.253453374874309}
2023-01-05 07:15:31,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:15:31,423 INFO:     Epoch: 92
2023-01-05 07:15:33,578 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3498326336344083, 'Total loss': 0.3498326336344083} | train loss {'Reaction outcome loss': 0.2558095882014528, 'Total loss': 0.2558095882014528}
2023-01-05 07:15:33,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:15:33,579 INFO:     Epoch: 93
2023-01-05 07:15:35,728 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3758021871248881, 'Total loss': 0.3758021871248881} | train loss {'Reaction outcome loss': 0.2505347501404964, 'Total loss': 0.2505347501404964}
2023-01-05 07:15:35,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:15:35,728 INFO:     Epoch: 94
2023-01-05 07:15:37,882 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.35135130683581034, 'Total loss': 0.35135130683581034} | train loss {'Reaction outcome loss': 0.2528767837313459, 'Total loss': 0.2528767837313459}
2023-01-05 07:15:37,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:15:37,882 INFO:     Epoch: 95
2023-01-05 07:15:40,029 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3395436326662699, 'Total loss': 0.3395436326662699} | train loss {'Reaction outcome loss': 0.25135690020057405, 'Total loss': 0.25135690020057405}
2023-01-05 07:15:40,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:15:40,029 INFO:     Epoch: 96
2023-01-05 07:15:42,148 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.38531146148840584, 'Total loss': 0.38531146148840584} | train loss {'Reaction outcome loss': 0.2511134073138237, 'Total loss': 0.2511134073138237}
2023-01-05 07:15:42,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:15:42,149 INFO:     Epoch: 97
2023-01-05 07:15:44,298 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3519624565728009, 'Total loss': 0.3519624565728009} | train loss {'Reaction outcome loss': 0.24935923437214028, 'Total loss': 0.24935923437214028}
2023-01-05 07:15:44,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:15:44,298 INFO:     Epoch: 98
2023-01-05 07:15:46,455 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.35594038665294647, 'Total loss': 0.35594038665294647} | train loss {'Reaction outcome loss': 0.24697399900777497, 'Total loss': 0.24697399900777497}
2023-01-05 07:15:46,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:15:46,456 INFO:     Epoch: 99
2023-01-05 07:15:48,591 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3634018858273824, 'Total loss': 0.3634018858273824} | train loss {'Reaction outcome loss': 0.250105926665022, 'Total loss': 0.250105926665022}
2023-01-05 07:15:48,591 INFO:     Best model found after epoch 56 of 100.
2023-01-05 07:15:48,591 INFO:   Done with stage: TRAINING
2023-01-05 07:15:48,592 INFO:   Starting stage: EVALUATION
2023-01-05 07:15:48,730 INFO:   Done with stage: EVALUATION
2023-01-05 07:15:48,731 INFO:   Leaving out SEQ value Fold_3
2023-01-05 07:15:48,744 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 07:15:48,744 INFO:   Starting stage: FEATURE SCALING
2023-01-05 07:15:49,405 INFO:   Done with stage: FEATURE SCALING
2023-01-05 07:15:49,406 INFO:   Starting stage: SCALING TARGETS
2023-01-05 07:15:49,476 INFO:   Done with stage: SCALING TARGETS
2023-01-05 07:15:49,476 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:15:49,476 INFO:     No hyperparam tuning for this model
2023-01-05 07:15:49,477 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:15:49,477 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 07:15:49,477 INFO:     None feature selector for col prot
2023-01-05 07:15:49,478 INFO:     None feature selector for col prot
2023-01-05 07:15:49,478 INFO:     None feature selector for col prot
2023-01-05 07:15:49,478 INFO:     None feature selector for col chem
2023-01-05 07:15:49,478 INFO:     None feature selector for col chem
2023-01-05 07:15:49,478 INFO:     None feature selector for col chem
2023-01-05 07:15:49,478 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 07:15:49,478 INFO:   Starting stage: BUILD MODEL
2023-01-05 07:15:49,480 INFO:     Number of params in model 72901
2023-01-05 07:15:49,483 INFO:   Done with stage: BUILD MODEL
2023-01-05 07:15:49,483 INFO:   Starting stage: TRAINING
2023-01-05 07:15:49,545 INFO:     Val loss before train {'Reaction outcome loss': 1.0147745927174887, 'Total loss': 1.0147745927174887}
2023-01-05 07:15:49,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:15:49,545 INFO:     Epoch: 0
2023-01-05 07:15:51,725 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8074456612269084, 'Total loss': 0.8074456612269084} | train loss {'Reaction outcome loss': 0.9297756280777228, 'Total loss': 0.9297756280777228}
2023-01-05 07:15:51,725 INFO:     Found new best model at epoch 0
2023-01-05 07:15:51,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:15:51,726 INFO:     Epoch: 1
2023-01-05 07:15:53,932 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5555520077546438, 'Total loss': 0.5555520077546438} | train loss {'Reaction outcome loss': 0.7214491163944676, 'Total loss': 0.7214491163944676}
2023-01-05 07:15:53,933 INFO:     Found new best model at epoch 1
2023-01-05 07:15:53,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:15:53,935 INFO:     Epoch: 2
2023-01-05 07:15:56,063 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5419926444689432, 'Total loss': 0.5419926444689432} | train loss {'Reaction outcome loss': 0.5805393883781712, 'Total loss': 0.5805393883781712}
2023-01-05 07:15:56,063 INFO:     Found new best model at epoch 2
2023-01-05 07:15:56,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:15:56,065 INFO:     Epoch: 3
2023-01-05 07:15:58,206 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.517348955074946, 'Total loss': 0.517348955074946} | train loss {'Reaction outcome loss': 0.5421480256928145, 'Total loss': 0.5421480256928145}
2023-01-05 07:15:58,206 INFO:     Found new best model at epoch 3
2023-01-05 07:15:58,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:15:58,208 INFO:     Epoch: 4
2023-01-05 07:16:00,275 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48809866507848104, 'Total loss': 0.48809866507848104} | train loss {'Reaction outcome loss': 0.5131652938188428, 'Total loss': 0.5131652938188428}
2023-01-05 07:16:00,276 INFO:     Found new best model at epoch 4
2023-01-05 07:16:00,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:16:00,277 INFO:     Epoch: 5
2023-01-05 07:16:02,263 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47579947113990784, 'Total loss': 0.47579947113990784} | train loss {'Reaction outcome loss': 0.5049840179238007, 'Total loss': 0.5049840179238007}
2023-01-05 07:16:02,263 INFO:     Found new best model at epoch 5
2023-01-05 07:16:02,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:16:02,264 INFO:     Epoch: 6
2023-01-05 07:16:04,401 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.44382362961769106, 'Total loss': 0.44382362961769106} | train loss {'Reaction outcome loss': 0.4925971333562893, 'Total loss': 0.4925971333562893}
2023-01-05 07:16:04,402 INFO:     Found new best model at epoch 6
2023-01-05 07:16:04,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:16:04,403 INFO:     Epoch: 7
2023-01-05 07:16:06,532 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4464798818031947, 'Total loss': 0.4464798818031947} | train loss {'Reaction outcome loss': 0.48769402395199685, 'Total loss': 0.48769402395199685}
2023-01-05 07:16:06,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:16:06,533 INFO:     Epoch: 8
2023-01-05 07:16:08,660 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45533576905727385, 'Total loss': 0.45533576905727385} | train loss {'Reaction outcome loss': 0.48169909420348433, 'Total loss': 0.48169909420348433}
2023-01-05 07:16:08,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:16:08,660 INFO:     Epoch: 9
2023-01-05 07:16:10,808 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43915600776672364, 'Total loss': 0.43915600776672364} | train loss {'Reaction outcome loss': 0.4729815362578761, 'Total loss': 0.4729815362578761}
2023-01-05 07:16:10,808 INFO:     Found new best model at epoch 9
2023-01-05 07:16:10,810 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:16:10,810 INFO:     Epoch: 10
2023-01-05 07:16:12,989 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45060365994771323, 'Total loss': 0.45060365994771323} | train loss {'Reaction outcome loss': 0.4686821506623804, 'Total loss': 0.4686821506623804}
2023-01-05 07:16:12,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:16:12,989 INFO:     Epoch: 11
2023-01-05 07:16:15,144 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4673557142416636, 'Total loss': 0.4673557142416636} | train loss {'Reaction outcome loss': 0.46054623224330643, 'Total loss': 0.46054623224330643}
2023-01-05 07:16:15,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:16:15,144 INFO:     Epoch: 12
2023-01-05 07:16:17,288 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4481156309445699, 'Total loss': 0.4481156309445699} | train loss {'Reaction outcome loss': 0.45688870179392127, 'Total loss': 0.45688870179392127}
2023-01-05 07:16:17,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:16:17,290 INFO:     Epoch: 13
2023-01-05 07:16:19,431 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.43672690391540525, 'Total loss': 0.43672690391540525} | train loss {'Reaction outcome loss': 0.455704014177305, 'Total loss': 0.455704014177305}
2023-01-05 07:16:19,431 INFO:     Found new best model at epoch 13
2023-01-05 07:16:19,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:16:19,432 INFO:     Epoch: 14
2023-01-05 07:16:21,570 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42705600361029306, 'Total loss': 0.42705600361029306} | train loss {'Reaction outcome loss': 0.4468107133233634, 'Total loss': 0.4468107133233634}
2023-01-05 07:16:21,570 INFO:     Found new best model at epoch 14
2023-01-05 07:16:21,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:16:21,571 INFO:     Epoch: 15
2023-01-05 07:16:23,703 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43590036034584045, 'Total loss': 0.43590036034584045} | train loss {'Reaction outcome loss': 0.44323734993482156, 'Total loss': 0.44323734993482156}
2023-01-05 07:16:23,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:16:23,704 INFO:     Epoch: 16
2023-01-05 07:16:25,824 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.45060003101825713, 'Total loss': 0.45060003101825713} | train loss {'Reaction outcome loss': 0.44392457533709323, 'Total loss': 0.44392457533709323}
2023-01-05 07:16:25,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:16:25,825 INFO:     Epoch: 17
2023-01-05 07:16:27,977 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42664812902609506, 'Total loss': 0.42664812902609506} | train loss {'Reaction outcome loss': 0.43495434280620876, 'Total loss': 0.43495434280620876}
2023-01-05 07:16:27,977 INFO:     Found new best model at epoch 17
2023-01-05 07:16:27,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:16:27,979 INFO:     Epoch: 18
2023-01-05 07:16:30,120 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4329883943001429, 'Total loss': 0.4329883943001429} | train loss {'Reaction outcome loss': 0.4279734005566931, 'Total loss': 0.4279734005566931}
2023-01-05 07:16:30,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:16:30,120 INFO:     Epoch: 19
2023-01-05 07:16:32,260 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4560891052087148, 'Total loss': 0.4560891052087148} | train loss {'Reaction outcome loss': 0.4242230137252677, 'Total loss': 0.4242230137252677}
2023-01-05 07:16:32,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:16:32,260 INFO:     Epoch: 20
2023-01-05 07:16:34,399 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43656278649965924, 'Total loss': 0.43656278649965924} | train loss {'Reaction outcome loss': 0.42404237465701833, 'Total loss': 0.42404237465701833}
2023-01-05 07:16:34,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:16:34,400 INFO:     Epoch: 21
2023-01-05 07:16:36,537 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40602155327796935, 'Total loss': 0.40602155327796935} | train loss {'Reaction outcome loss': 0.4173361019224581, 'Total loss': 0.4173361019224581}
2023-01-05 07:16:36,537 INFO:     Found new best model at epoch 21
2023-01-05 07:16:36,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:16:36,539 INFO:     Epoch: 22
2023-01-05 07:16:38,718 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4412916998068492, 'Total loss': 0.4412916998068492} | train loss {'Reaction outcome loss': 0.41036925687842124, 'Total loss': 0.41036925687842124}
2023-01-05 07:16:38,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:16:38,718 INFO:     Epoch: 23
2023-01-05 07:16:40,905 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.43263595501581825, 'Total loss': 0.43263595501581825} | train loss {'Reaction outcome loss': 0.40810538134979507, 'Total loss': 0.40810538134979507}
2023-01-05 07:16:40,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:16:40,905 INFO:     Epoch: 24
2023-01-05 07:16:43,097 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43501200477282204, 'Total loss': 0.43501200477282204} | train loss {'Reaction outcome loss': 0.41315632392346424, 'Total loss': 0.41315632392346424}
2023-01-05 07:16:43,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:16:43,097 INFO:     Epoch: 25
2023-01-05 07:16:45,257 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4226727604866028, 'Total loss': 0.4226727604866028} | train loss {'Reaction outcome loss': 0.4031769245808577, 'Total loss': 0.4031769245808577}
2023-01-05 07:16:45,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:16:45,258 INFO:     Epoch: 26
2023-01-05 07:16:47,402 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3988675038019816, 'Total loss': 0.3988675038019816} | train loss {'Reaction outcome loss': 0.4000052274034841, 'Total loss': 0.4000052274034841}
2023-01-05 07:16:47,403 INFO:     Found new best model at epoch 26
2023-01-05 07:16:47,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:16:47,405 INFO:     Epoch: 27
2023-01-05 07:16:49,547 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.41414761195580163, 'Total loss': 0.41414761195580163} | train loss {'Reaction outcome loss': 0.39244981137287877, 'Total loss': 0.39244981137287877}
2023-01-05 07:16:49,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:16:49,548 INFO:     Epoch: 28
2023-01-05 07:16:51,706 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4111847092707952, 'Total loss': 0.4111847092707952} | train loss {'Reaction outcome loss': 0.39395551494982123, 'Total loss': 0.39395551494982123}
2023-01-05 07:16:51,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:16:51,706 INFO:     Epoch: 29
2023-01-05 07:16:53,860 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40404809812704723, 'Total loss': 0.40404809812704723} | train loss {'Reaction outcome loss': 0.38567767517953894, 'Total loss': 0.38567767517953894}
2023-01-05 07:16:53,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:16:53,861 INFO:     Epoch: 30
2023-01-05 07:16:56,000 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.39258033931255343, 'Total loss': 0.39258033931255343} | train loss {'Reaction outcome loss': 0.3894280920716098, 'Total loss': 0.3894280920716098}
2023-01-05 07:16:56,000 INFO:     Found new best model at epoch 30
2023-01-05 07:16:56,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:16:56,001 INFO:     Epoch: 31
2023-01-05 07:16:58,129 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3877981811761856, 'Total loss': 0.3877981811761856} | train loss {'Reaction outcome loss': 0.385163704789903, 'Total loss': 0.385163704789903}
2023-01-05 07:16:58,129 INFO:     Found new best model at epoch 31
2023-01-05 07:16:58,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:16:58,130 INFO:     Epoch: 32
2023-01-05 07:17:00,261 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3934643765290578, 'Total loss': 0.3934643765290578} | train loss {'Reaction outcome loss': 0.3780324336984297, 'Total loss': 0.3780324336984297}
2023-01-05 07:17:00,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:17:00,262 INFO:     Epoch: 33
2023-01-05 07:17:02,421 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4031401058038076, 'Total loss': 0.4031401058038076} | train loss {'Reaction outcome loss': 0.3796412070846035, 'Total loss': 0.3796412070846035}
2023-01-05 07:17:02,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:17:02,421 INFO:     Epoch: 34
2023-01-05 07:17:04,565 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.419989017645518, 'Total loss': 0.419989017645518} | train loss {'Reaction outcome loss': 0.36869402607753327, 'Total loss': 0.36869402607753327}
2023-01-05 07:17:04,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:17:04,565 INFO:     Epoch: 35
2023-01-05 07:17:06,705 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.38802074690659843, 'Total loss': 0.38802074690659843} | train loss {'Reaction outcome loss': 0.3704668947624682, 'Total loss': 0.3704668947624682}
2023-01-05 07:17:06,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:17:06,706 INFO:     Epoch: 36
2023-01-05 07:17:08,855 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38255989948908486, 'Total loss': 0.38255989948908486} | train loss {'Reaction outcome loss': 0.36336319812022855, 'Total loss': 0.36336319812022855}
2023-01-05 07:17:08,855 INFO:     Found new best model at epoch 36
2023-01-05 07:17:08,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:17:08,856 INFO:     Epoch: 37
2023-01-05 07:17:11,001 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3933573375145594, 'Total loss': 0.3933573375145594} | train loss {'Reaction outcome loss': 0.3624410298075119, 'Total loss': 0.3624410298075119}
2023-01-05 07:17:11,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:17:11,001 INFO:     Epoch: 38
2023-01-05 07:17:13,144 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41332783301671344, 'Total loss': 0.41332783301671344} | train loss {'Reaction outcome loss': 0.35740178930879074, 'Total loss': 0.35740178930879074}
2023-01-05 07:17:13,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:17:13,144 INFO:     Epoch: 39
2023-01-05 07:17:15,308 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3806072920560837, 'Total loss': 0.3806072920560837} | train loss {'Reaction outcome loss': 0.3543527321550098, 'Total loss': 0.3543527321550098}
2023-01-05 07:17:15,308 INFO:     Found new best model at epoch 39
2023-01-05 07:17:15,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:17:15,309 INFO:     Epoch: 40
2023-01-05 07:17:17,465 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4185957709948222, 'Total loss': 0.4185957709948222} | train loss {'Reaction outcome loss': 0.35155704138922866, 'Total loss': 0.35155704138922866}
2023-01-05 07:17:17,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:17:17,465 INFO:     Epoch: 41
2023-01-05 07:17:19,633 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40425447523593905, 'Total loss': 0.40425447523593905} | train loss {'Reaction outcome loss': 0.34394855449234485, 'Total loss': 0.34394855449234485}
2023-01-05 07:17:19,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:17:19,633 INFO:     Epoch: 42
2023-01-05 07:17:21,761 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40750199953715005, 'Total loss': 0.40750199953715005} | train loss {'Reaction outcome loss': 0.34357219473560796, 'Total loss': 0.34357219473560796}
2023-01-05 07:17:21,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:17:21,762 INFO:     Epoch: 43
2023-01-05 07:17:23,912 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4246381004651388, 'Total loss': 0.4246381004651388} | train loss {'Reaction outcome loss': 0.343229819714588, 'Total loss': 0.343229819714588}
2023-01-05 07:17:23,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:17:23,913 INFO:     Epoch: 44
2023-01-05 07:17:26,055 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4490194708108902, 'Total loss': 0.4490194708108902} | train loss {'Reaction outcome loss': 0.3361681033279339, 'Total loss': 0.3361681033279339}
2023-01-05 07:17:26,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:17:26,055 INFO:     Epoch: 45
2023-01-05 07:17:28,228 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3951760540405909, 'Total loss': 0.3951760540405909} | train loss {'Reaction outcome loss': 0.34014234931147014, 'Total loss': 0.34014234931147014}
2023-01-05 07:17:28,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:17:28,228 INFO:     Epoch: 46
2023-01-05 07:17:30,393 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.39680868685245513, 'Total loss': 0.39680868685245513} | train loss {'Reaction outcome loss': 0.32521093068440465, 'Total loss': 0.32521093068440465}
2023-01-05 07:17:30,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:17:30,394 INFO:     Epoch: 47
2023-01-05 07:17:32,532 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.421737427636981, 'Total loss': 0.421737427636981} | train loss {'Reaction outcome loss': 0.3252359700192065, 'Total loss': 0.3252359700192065}
2023-01-05 07:17:32,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:17:32,532 INFO:     Epoch: 48
2023-01-05 07:17:34,665 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4122592608133952, 'Total loss': 0.4122592608133952} | train loss {'Reaction outcome loss': 0.3231993875173974, 'Total loss': 0.3231993875173974}
2023-01-05 07:17:34,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:17:34,665 INFO:     Epoch: 49
2023-01-05 07:17:36,811 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3955095961689949, 'Total loss': 0.3955095961689949} | train loss {'Reaction outcome loss': 0.32263580323570834, 'Total loss': 0.32263580323570834}
2023-01-05 07:17:36,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:17:36,812 INFO:     Epoch: 50
2023-01-05 07:17:38,959 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3805080314477285, 'Total loss': 0.3805080314477285} | train loss {'Reaction outcome loss': 0.31732269323492135, 'Total loss': 0.31732269323492135}
2023-01-05 07:17:38,959 INFO:     Found new best model at epoch 50
2023-01-05 07:17:38,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:17:38,961 INFO:     Epoch: 51
2023-01-05 07:17:41,107 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4640164027611415, 'Total loss': 0.4640164027611415} | train loss {'Reaction outcome loss': 0.3138099930718215, 'Total loss': 0.3138099930718215}
2023-01-05 07:17:41,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:17:41,108 INFO:     Epoch: 52
2023-01-05 07:17:43,248 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4105399509270986, 'Total loss': 0.4105399509270986} | train loss {'Reaction outcome loss': 0.30977410774161346, 'Total loss': 0.30977410774161346}
2023-01-05 07:17:43,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:17:43,249 INFO:     Epoch: 53
2023-01-05 07:17:45,395 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39478187064329784, 'Total loss': 0.39478187064329784} | train loss {'Reaction outcome loss': 0.31001826729217585, 'Total loss': 0.31001826729217585}
2023-01-05 07:17:45,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:17:45,396 INFO:     Epoch: 54
2023-01-05 07:17:47,523 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3649196664492289, 'Total loss': 0.3649196664492289} | train loss {'Reaction outcome loss': 0.3100582297456308, 'Total loss': 0.3100582297456308}
2023-01-05 07:17:47,523 INFO:     Found new best model at epoch 54
2023-01-05 07:17:47,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:17:47,524 INFO:     Epoch: 55
2023-01-05 07:17:49,657 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4224267979462942, 'Total loss': 0.4224267979462942} | train loss {'Reaction outcome loss': 0.30750698548653266, 'Total loss': 0.30750698548653266}
2023-01-05 07:17:49,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:17:49,657 INFO:     Epoch: 56
2023-01-05 07:17:51,807 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3716141402721405, 'Total loss': 0.3716141402721405} | train loss {'Reaction outcome loss': 0.3014423913138844, 'Total loss': 0.3014423913138844}
2023-01-05 07:17:51,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:17:51,807 INFO:     Epoch: 57
2023-01-05 07:17:53,949 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3535671869913737, 'Total loss': 0.3535671869913737} | train loss {'Reaction outcome loss': 0.2965816433752214, 'Total loss': 0.2965816433752214}
2023-01-05 07:17:53,950 INFO:     Found new best model at epoch 57
2023-01-05 07:17:53,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:17:53,951 INFO:     Epoch: 58
2023-01-05 07:17:56,089 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4121088072657585, 'Total loss': 0.4121088072657585} | train loss {'Reaction outcome loss': 0.2843500912107908, 'Total loss': 0.2843500912107908}
2023-01-05 07:17:56,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:17:56,090 INFO:     Epoch: 59
2023-01-05 07:17:58,239 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4027474770943324, 'Total loss': 0.4027474770943324} | train loss {'Reaction outcome loss': 0.2956745336851934, 'Total loss': 0.2956745336851934}
2023-01-05 07:17:58,239 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:17:58,239 INFO:     Epoch: 60
2023-01-05 07:18:00,405 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4106875697771708, 'Total loss': 0.4106875697771708} | train loss {'Reaction outcome loss': 0.29663862177871003, 'Total loss': 0.29663862177871003}
2023-01-05 07:18:00,405 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:18:00,405 INFO:     Epoch: 61
2023-01-05 07:18:02,557 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38108278115590416, 'Total loss': 0.38108278115590416} | train loss {'Reaction outcome loss': 0.29083327179516316, 'Total loss': 0.29083327179516316}
2023-01-05 07:18:02,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:18:02,557 INFO:     Epoch: 62
2023-01-05 07:18:04,715 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4014804830153783, 'Total loss': 0.4014804830153783} | train loss {'Reaction outcome loss': 0.2906072469849656, 'Total loss': 0.2906072469849656}
2023-01-05 07:18:04,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:18:04,715 INFO:     Epoch: 63
2023-01-05 07:18:06,858 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42238607406616213, 'Total loss': 0.42238607406616213} | train loss {'Reaction outcome loss': 0.2895592487260808, 'Total loss': 0.2895592487260808}
2023-01-05 07:18:06,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:18:06,858 INFO:     Epoch: 64
2023-01-05 07:18:08,992 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43573040068149566, 'Total loss': 0.43573040068149566} | train loss {'Reaction outcome loss': 0.28360778860149594, 'Total loss': 0.28360778860149594}
2023-01-05 07:18:08,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:18:08,992 INFO:     Epoch: 65
2023-01-05 07:18:11,131 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4223977789282799, 'Total loss': 0.4223977789282799} | train loss {'Reaction outcome loss': 0.28352943334701286, 'Total loss': 0.28352943334701286}
2023-01-05 07:18:11,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:18:11,132 INFO:     Epoch: 66
2023-01-05 07:18:13,284 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43757809003194176, 'Total loss': 0.43757809003194176} | train loss {'Reaction outcome loss': 0.2848036841482577, 'Total loss': 0.2848036841482577}
2023-01-05 07:18:13,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:18:13,285 INFO:     Epoch: 67
2023-01-05 07:18:15,437 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40586711664994557, 'Total loss': 0.40586711664994557} | train loss {'Reaction outcome loss': 0.28167844092622946, 'Total loss': 0.28167844092622946}
2023-01-05 07:18:15,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:18:15,437 INFO:     Epoch: 68
2023-01-05 07:18:17,598 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.37885208080212274, 'Total loss': 0.37885208080212274} | train loss {'Reaction outcome loss': 0.2780535838763862, 'Total loss': 0.2780535838763862}
2023-01-05 07:18:17,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:18:17,599 INFO:     Epoch: 69
2023-01-05 07:18:19,726 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3599006106456121, 'Total loss': 0.3599006106456121} | train loss {'Reaction outcome loss': 0.27365666415787093, 'Total loss': 0.27365666415787093}
2023-01-05 07:18:19,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:18:19,727 INFO:     Epoch: 70
2023-01-05 07:18:21,858 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44461086491743723, 'Total loss': 0.44461086491743723} | train loss {'Reaction outcome loss': 0.2740547206647096, 'Total loss': 0.2740547206647096}
2023-01-05 07:18:21,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:18:21,859 INFO:     Epoch: 71
2023-01-05 07:18:24,018 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3447038193543752, 'Total loss': 0.3447038193543752} | train loss {'Reaction outcome loss': 0.27012942518603844, 'Total loss': 0.27012942518603844}
2023-01-05 07:18:24,018 INFO:     Found new best model at epoch 71
2023-01-05 07:18:24,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:18:24,020 INFO:     Epoch: 72
2023-01-05 07:18:26,167 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40495312760273616, 'Total loss': 0.40495312760273616} | train loss {'Reaction outcome loss': 0.2746990768334074, 'Total loss': 0.2746990768334074}
2023-01-05 07:18:26,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:18:26,167 INFO:     Epoch: 73
2023-01-05 07:18:28,325 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41409250497817995, 'Total loss': 0.41409250497817995} | train loss {'Reaction outcome loss': 0.26692836186474694, 'Total loss': 0.26692836186474694}
2023-01-05 07:18:28,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:18:28,326 INFO:     Epoch: 74
2023-01-05 07:18:30,474 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.37971817553043363, 'Total loss': 0.37971817553043363} | train loss {'Reaction outcome loss': 0.26986267140651815, 'Total loss': 0.26986267140651815}
2023-01-05 07:18:30,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:18:30,476 INFO:     Epoch: 75
2023-01-05 07:18:32,592 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3715773115555445, 'Total loss': 0.3715773115555445} | train loss {'Reaction outcome loss': 0.2669886692909755, 'Total loss': 0.2669886692909755}
2023-01-05 07:18:32,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:18:32,592 INFO:     Epoch: 76
2023-01-05 07:18:34,729 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43237329898402094, 'Total loss': 0.43237329898402094} | train loss {'Reaction outcome loss': 0.27312696817582544, 'Total loss': 0.27312696817582544}
2023-01-05 07:18:34,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:18:34,729 INFO:     Epoch: 77
2023-01-05 07:18:36,877 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.36351218819618225, 'Total loss': 0.36351218819618225} | train loss {'Reaction outcome loss': 0.27172936175535195, 'Total loss': 0.27172936175535195}
2023-01-05 07:18:36,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:18:36,878 INFO:     Epoch: 78
2023-01-05 07:18:39,019 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.38102161437273024, 'Total loss': 0.38102161437273024} | train loss {'Reaction outcome loss': 0.26858163237517335, 'Total loss': 0.26858163237517335}
2023-01-05 07:18:39,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:18:39,019 INFO:     Epoch: 79
2023-01-05 07:18:41,158 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3613428721825282, 'Total loss': 0.3613428721825282} | train loss {'Reaction outcome loss': 0.25888549575894854, 'Total loss': 0.25888549575894854}
2023-01-05 07:18:41,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:18:41,158 INFO:     Epoch: 80
2023-01-05 07:18:43,290 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4267642617225647, 'Total loss': 0.4267642617225647} | train loss {'Reaction outcome loss': 0.2614944488299589, 'Total loss': 0.2614944488299589}
2023-01-05 07:18:43,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:18:43,290 INFO:     Epoch: 81
2023-01-05 07:18:45,425 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3988978609442711, 'Total loss': 0.3988978609442711} | train loss {'Reaction outcome loss': 0.2555745407925361, 'Total loss': 0.2555745407925361}
2023-01-05 07:18:45,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:18:45,426 INFO:     Epoch: 82
2023-01-05 07:18:47,578 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.37027388711770376, 'Total loss': 0.37027388711770376} | train loss {'Reaction outcome loss': 0.25710724142590796, 'Total loss': 0.25710724142590796}
2023-01-05 07:18:47,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:18:47,578 INFO:     Epoch: 83
2023-01-05 07:18:49,731 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.36711066563924155, 'Total loss': 0.36711066563924155} | train loss {'Reaction outcome loss': 0.2581955103516361, 'Total loss': 0.2581955103516361}
2023-01-05 07:18:49,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:18:49,732 INFO:     Epoch: 84
2023-01-05 07:18:51,880 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.35969438205162685, 'Total loss': 0.35969438205162685} | train loss {'Reaction outcome loss': 0.25058363365811587, 'Total loss': 0.25058363365811587}
2023-01-05 07:18:51,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:18:51,880 INFO:     Epoch: 85
2023-01-05 07:18:54,016 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4251292313138644, 'Total loss': 0.4251292313138644} | train loss {'Reaction outcome loss': 0.24892786264854627, 'Total loss': 0.24892786264854627}
2023-01-05 07:18:54,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:18:54,016 INFO:     Epoch: 86
2023-01-05 07:18:56,133 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3690674101312955, 'Total loss': 0.3690674101312955} | train loss {'Reaction outcome loss': 0.2583190562597809, 'Total loss': 0.2583190562597809}
2023-01-05 07:18:56,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:18:56,134 INFO:     Epoch: 87
2023-01-05 07:18:58,267 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.36333515817920364, 'Total loss': 0.36333515817920364} | train loss {'Reaction outcome loss': 0.255333184883216, 'Total loss': 0.255333184883216}
2023-01-05 07:18:58,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:18:58,268 INFO:     Epoch: 88
2023-01-05 07:19:00,417 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4063477878769239, 'Total loss': 0.4063477878769239} | train loss {'Reaction outcome loss': 0.25530731316356764, 'Total loss': 0.25530731316356764}
2023-01-05 07:19:00,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:19:00,418 INFO:     Epoch: 89
2023-01-05 07:19:02,560 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38882690370082856, 'Total loss': 0.38882690370082856} | train loss {'Reaction outcome loss': 0.25385107103069005, 'Total loss': 0.25385107103069005}
2023-01-05 07:19:02,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:19:02,560 INFO:     Epoch: 90
2023-01-05 07:19:04,697 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.38932625353336336, 'Total loss': 0.38932625353336336} | train loss {'Reaction outcome loss': 0.25110585918908357, 'Total loss': 0.25110585918908357}
2023-01-05 07:19:04,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:19:04,697 INFO:     Epoch: 91
2023-01-05 07:19:06,824 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4391471187273661, 'Total loss': 0.4391471187273661} | train loss {'Reaction outcome loss': 0.2465617379282404, 'Total loss': 0.2465617379282404}
2023-01-05 07:19:06,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:19:06,825 INFO:     Epoch: 92
2023-01-05 07:19:08,945 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3841890235741933, 'Total loss': 0.3841890235741933} | train loss {'Reaction outcome loss': 0.24777878238309692, 'Total loss': 0.24777878238309692}
2023-01-05 07:19:08,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:19:08,945 INFO:     Epoch: 93
2023-01-05 07:19:11,081 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3482404520114263, 'Total loss': 0.3482404520114263} | train loss {'Reaction outcome loss': 0.24910167554379814, 'Total loss': 0.24910167554379814}
2023-01-05 07:19:11,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:19:11,081 INFO:     Epoch: 94
2023-01-05 07:19:13,225 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.35921726922194164, 'Total loss': 0.35921726922194164} | train loss {'Reaction outcome loss': 0.24185089955283126, 'Total loss': 0.24185089955283126}
2023-01-05 07:19:13,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:19:13,226 INFO:     Epoch: 95
2023-01-05 07:19:15,364 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3965572570761045, 'Total loss': 0.3965572570761045} | train loss {'Reaction outcome loss': 0.24913636266668565, 'Total loss': 0.24913636266668565}
2023-01-05 07:19:15,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:19:15,364 INFO:     Epoch: 96
2023-01-05 07:19:17,485 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.41390818953514097, 'Total loss': 0.41390818953514097} | train loss {'Reaction outcome loss': 0.2469436526536452, 'Total loss': 0.2469436526536452}
2023-01-05 07:19:17,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:19:17,485 INFO:     Epoch: 97
2023-01-05 07:19:19,619 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3815236061811447, 'Total loss': 0.3815236061811447} | train loss {'Reaction outcome loss': 0.24466677163693593, 'Total loss': 0.24466677163693593}
2023-01-05 07:19:19,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:19:19,620 INFO:     Epoch: 98
2023-01-05 07:19:21,760 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.34081339140733086, 'Total loss': 0.34081339140733086} | train loss {'Reaction outcome loss': 0.24306869287941144, 'Total loss': 0.24306869287941144}
2023-01-05 07:19:21,760 INFO:     Found new best model at epoch 98
2023-01-05 07:19:21,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:19:21,761 INFO:     Epoch: 99
2023-01-05 07:19:23,904 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.35556575407584506, 'Total loss': 0.35556575407584506} | train loss {'Reaction outcome loss': 0.2439318548371322, 'Total loss': 0.2439318548371322}
2023-01-05 07:19:23,904 INFO:     Best model found after epoch 99 of 100.
2023-01-05 07:19:23,904 INFO:   Done with stage: TRAINING
2023-01-05 07:19:23,904 INFO:   Starting stage: EVALUATION
2023-01-05 07:19:24,043 INFO:   Done with stage: EVALUATION
2023-01-05 07:19:24,043 INFO:   Leaving out SEQ value Fold_4
2023-01-05 07:19:24,056 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 07:19:24,056 INFO:   Starting stage: FEATURE SCALING
2023-01-05 07:19:24,718 INFO:   Done with stage: FEATURE SCALING
2023-01-05 07:19:24,718 INFO:   Starting stage: SCALING TARGETS
2023-01-05 07:19:24,787 INFO:   Done with stage: SCALING TARGETS
2023-01-05 07:19:24,787 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:19:24,787 INFO:     No hyperparam tuning for this model
2023-01-05 07:19:24,787 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:19:24,787 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 07:19:24,788 INFO:     None feature selector for col prot
2023-01-05 07:19:24,788 INFO:     None feature selector for col prot
2023-01-05 07:19:24,788 INFO:     None feature selector for col prot
2023-01-05 07:19:24,789 INFO:     None feature selector for col chem
2023-01-05 07:19:24,789 INFO:     None feature selector for col chem
2023-01-05 07:19:24,789 INFO:     None feature selector for col chem
2023-01-05 07:19:24,789 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 07:19:24,789 INFO:   Starting stage: BUILD MODEL
2023-01-05 07:19:24,791 INFO:     Number of params in model 72901
2023-01-05 07:19:24,794 INFO:   Done with stage: BUILD MODEL
2023-01-05 07:19:24,794 INFO:   Starting stage: TRAINING
2023-01-05 07:19:24,854 INFO:     Val loss before train {'Reaction outcome loss': 1.0361891071001688, 'Total loss': 1.0361891071001688}
2023-01-05 07:19:24,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:19:24,854 INFO:     Epoch: 0
2023-01-05 07:19:26,981 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.746589082479477, 'Total loss': 0.746589082479477} | train loss {'Reaction outcome loss': 0.9223059387537684, 'Total loss': 0.9223059387537684}
2023-01-05 07:19:26,982 INFO:     Found new best model at epoch 0
2023-01-05 07:19:26,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:19:26,983 INFO:     Epoch: 1
2023-01-05 07:19:29,127 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6209386765956879, 'Total loss': 0.6209386765956879} | train loss {'Reaction outcome loss': 0.7458923673325212, 'Total loss': 0.7458923673325212}
2023-01-05 07:19:29,127 INFO:     Found new best model at epoch 1
2023-01-05 07:19:29,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:19:29,129 INFO:     Epoch: 2
2023-01-05 07:19:31,254 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5506312747796377, 'Total loss': 0.5506312747796377} | train loss {'Reaction outcome loss': 0.5975236933488045, 'Total loss': 0.5975236933488045}
2023-01-05 07:19:31,254 INFO:     Found new best model at epoch 2
2023-01-05 07:19:31,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:19:31,255 INFO:     Epoch: 3
2023-01-05 07:19:33,388 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5147626121838887, 'Total loss': 0.5147626121838887} | train loss {'Reaction outcome loss': 0.5336082041481115, 'Total loss': 0.5336082041481115}
2023-01-05 07:19:33,388 INFO:     Found new best model at epoch 3
2023-01-05 07:19:33,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:19:33,389 INFO:     Epoch: 4
2023-01-05 07:19:35,531 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4877543886502584, 'Total loss': 0.4877543886502584} | train loss {'Reaction outcome loss': 0.5056518749979726, 'Total loss': 0.5056518749979726}
2023-01-05 07:19:35,532 INFO:     Found new best model at epoch 4
2023-01-05 07:19:35,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:19:35,534 INFO:     Epoch: 5
2023-01-05 07:19:37,673 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4913461983203888, 'Total loss': 0.4913461983203888} | train loss {'Reaction outcome loss': 0.48884087300648654, 'Total loss': 0.48884087300648654}
2023-01-05 07:19:37,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:19:37,673 INFO:     Epoch: 6
2023-01-05 07:19:39,812 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4799645185470581, 'Total loss': 0.4799645185470581} | train loss {'Reaction outcome loss': 0.47774707351940393, 'Total loss': 0.47774707351940393}
2023-01-05 07:19:39,812 INFO:     Found new best model at epoch 6
2023-01-05 07:19:39,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:19:39,814 INFO:     Epoch: 7
2023-01-05 07:19:41,935 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.510868634780248, 'Total loss': 0.510868634780248} | train loss {'Reaction outcome loss': 0.4707423594311206, 'Total loss': 0.4707423594311206}
2023-01-05 07:19:41,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:19:41,936 INFO:     Epoch: 8
2023-01-05 07:19:44,067 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4641610066095988, 'Total loss': 0.4641610066095988} | train loss {'Reaction outcome loss': 0.46214272734457557, 'Total loss': 0.46214272734457557}
2023-01-05 07:19:44,067 INFO:     Found new best model at epoch 8
2023-01-05 07:19:44,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:19:44,068 INFO:     Epoch: 9
2023-01-05 07:19:46,204 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4644396185874939, 'Total loss': 0.4644396185874939} | train loss {'Reaction outcome loss': 0.45269545608193335, 'Total loss': 0.45269545608193335}
2023-01-05 07:19:46,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:19:46,204 INFO:     Epoch: 10
2023-01-05 07:19:48,348 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4965512732664744, 'Total loss': 0.4965512732664744} | train loss {'Reaction outcome loss': 0.44921436106419044, 'Total loss': 0.44921436106419044}
2023-01-05 07:19:48,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:19:48,348 INFO:     Epoch: 11
2023-01-05 07:19:50,491 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45117565194765724, 'Total loss': 0.45117565194765724} | train loss {'Reaction outcome loss': 0.4480147806614855, 'Total loss': 0.4480147806614855}
2023-01-05 07:19:50,492 INFO:     Found new best model at epoch 11
2023-01-05 07:19:50,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:19:50,493 INFO:     Epoch: 12
2023-01-05 07:19:52,632 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4459524427851041, 'Total loss': 0.4459524427851041} | train loss {'Reaction outcome loss': 0.436672082456359, 'Total loss': 0.436672082456359}
2023-01-05 07:19:52,633 INFO:     Found new best model at epoch 12
2023-01-05 07:19:52,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:19:52,634 INFO:     Epoch: 13
2023-01-05 07:19:54,781 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4239111358920733, 'Total loss': 0.4239111358920733} | train loss {'Reaction outcome loss': 0.4323657630351338, 'Total loss': 0.4323657630351338}
2023-01-05 07:19:54,782 INFO:     Found new best model at epoch 13
2023-01-05 07:19:54,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:19:54,784 INFO:     Epoch: 14
2023-01-05 07:19:56,942 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43192259867986044, 'Total loss': 0.43192259867986044} | train loss {'Reaction outcome loss': 0.4284248777332097, 'Total loss': 0.4284248777332097}
2023-01-05 07:19:56,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:19:56,942 INFO:     Epoch: 15
2023-01-05 07:19:59,097 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4243681619564692, 'Total loss': 0.4243681619564692} | train loss {'Reaction outcome loss': 0.42523014877181853, 'Total loss': 0.42523014877181853}
2023-01-05 07:19:59,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:19:59,097 INFO:     Epoch: 16
2023-01-05 07:20:01,229 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4503496468067169, 'Total loss': 0.4503496468067169} | train loss {'Reaction outcome loss': 0.4169875938635673, 'Total loss': 0.4169875938635673}
2023-01-05 07:20:01,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:20:01,229 INFO:     Epoch: 17
2023-01-05 07:20:03,374 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4316680510838827, 'Total loss': 0.4316680510838827} | train loss {'Reaction outcome loss': 0.4142453424686933, 'Total loss': 0.4142453424686933}
2023-01-05 07:20:03,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:20:03,374 INFO:     Epoch: 18
2023-01-05 07:20:05,494 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43536490698655445, 'Total loss': 0.43536490698655445} | train loss {'Reaction outcome loss': 0.4098370231851174, 'Total loss': 0.4098370231851174}
2023-01-05 07:20:05,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:20:05,495 INFO:     Epoch: 19
2023-01-05 07:20:07,425 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.43177917699019114, 'Total loss': 0.43177917699019114} | train loss {'Reaction outcome loss': 0.4073028212046101, 'Total loss': 0.4073028212046101}
2023-01-05 07:20:07,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:20:07,426 INFO:     Epoch: 20
2023-01-05 07:20:09,561 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4447372297445933, 'Total loss': 0.4447372297445933} | train loss {'Reaction outcome loss': 0.4021996785036839, 'Total loss': 0.4021996785036839}
2023-01-05 07:20:09,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:20:09,562 INFO:     Epoch: 21
2023-01-05 07:20:11,750 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.463564270734787, 'Total loss': 0.463564270734787} | train loss {'Reaction outcome loss': 0.39910262643638317, 'Total loss': 0.39910262643638317}
2023-01-05 07:20:11,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:20:11,751 INFO:     Epoch: 22
2023-01-05 07:20:13,959 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.406825328618288, 'Total loss': 0.406825328618288} | train loss {'Reaction outcome loss': 0.39939725040084256, 'Total loss': 0.39939725040084256}
2023-01-05 07:20:13,959 INFO:     Found new best model at epoch 22
2023-01-05 07:20:13,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:20:13,961 INFO:     Epoch: 23
2023-01-05 07:20:16,099 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.44679682652155556, 'Total loss': 0.44679682652155556} | train loss {'Reaction outcome loss': 0.39884032746844916, 'Total loss': 0.39884032746844916}
2023-01-05 07:20:16,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:20:16,099 INFO:     Epoch: 24
2023-01-05 07:20:18,236 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.43601846595605215, 'Total loss': 0.43601846595605215} | train loss {'Reaction outcome loss': 0.39579643597350506, 'Total loss': 0.39579643597350506}
2023-01-05 07:20:18,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:20:18,237 INFO:     Epoch: 25
2023-01-05 07:20:20,377 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4410274128119151, 'Total loss': 0.4410274128119151} | train loss {'Reaction outcome loss': 0.3858123904053312, 'Total loss': 0.3858123904053312}
2023-01-05 07:20:20,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:20:20,377 INFO:     Epoch: 26
2023-01-05 07:20:22,535 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44729137420654297, 'Total loss': 0.44729137420654297} | train loss {'Reaction outcome loss': 0.38895447995432103, 'Total loss': 0.38895447995432103}
2023-01-05 07:20:22,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:20:22,535 INFO:     Epoch: 27
2023-01-05 07:20:24,685 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4261325359344482, 'Total loss': 0.4261325359344482} | train loss {'Reaction outcome loss': 0.3851969889263167, 'Total loss': 0.3851969889263167}
2023-01-05 07:20:24,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:20:24,686 INFO:     Epoch: 28
2023-01-05 07:20:26,829 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4518449013431867, 'Total loss': 0.4518449013431867} | train loss {'Reaction outcome loss': 0.3747858248759795, 'Total loss': 0.3747858248759795}
2023-01-05 07:20:26,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:20:26,829 INFO:     Epoch: 29
2023-01-05 07:20:28,946 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.40750177105267843, 'Total loss': 0.40750177105267843} | train loss {'Reaction outcome loss': 0.3745571733962228, 'Total loss': 0.3745571733962228}
2023-01-05 07:20:28,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:20:28,947 INFO:     Epoch: 30
2023-01-05 07:20:31,092 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4225985825061798, 'Total loss': 0.4225985825061798} | train loss {'Reaction outcome loss': 0.3701941731800563, 'Total loss': 0.3701941731800563}
2023-01-05 07:20:31,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:20:31,093 INFO:     Epoch: 31
2023-01-05 07:20:33,248 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4391367018222809, 'Total loss': 0.4391367018222809} | train loss {'Reaction outcome loss': 0.36640261668358404, 'Total loss': 0.36640261668358404}
2023-01-05 07:20:33,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:20:33,248 INFO:     Epoch: 32
2023-01-05 07:20:35,403 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42492340207099916, 'Total loss': 0.42492340207099916} | train loss {'Reaction outcome loss': 0.3677492467346635, 'Total loss': 0.3677492467346635}
2023-01-05 07:20:35,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:20:35,403 INFO:     Epoch: 33
2023-01-05 07:20:37,560 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.39723464945952097, 'Total loss': 0.39723464945952097} | train loss {'Reaction outcome loss': 0.3645873588176757, 'Total loss': 0.3645873588176757}
2023-01-05 07:20:37,560 INFO:     Found new best model at epoch 33
2023-01-05 07:20:37,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:20:37,561 INFO:     Epoch: 34
2023-01-05 07:20:39,728 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4177565375963847, 'Total loss': 0.4177565375963847} | train loss {'Reaction outcome loss': 0.36076251028554285, 'Total loss': 0.36076251028554285}
2023-01-05 07:20:39,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:20:39,729 INFO:     Epoch: 35
2023-01-05 07:20:41,897 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4112210104862849, 'Total loss': 0.4112210104862849} | train loss {'Reaction outcome loss': 0.35679329591837244, 'Total loss': 0.35679329591837244}
2023-01-05 07:20:41,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:20:41,897 INFO:     Epoch: 36
2023-01-05 07:20:44,051 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4120803773403168, 'Total loss': 0.4120803773403168} | train loss {'Reaction outcome loss': 0.3509277284390082, 'Total loss': 0.3509277284390082}
2023-01-05 07:20:44,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:20:44,052 INFO:     Epoch: 37
2023-01-05 07:20:46,203 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3866300731897354, 'Total loss': 0.3866300731897354} | train loss {'Reaction outcome loss': 0.351877348211995, 'Total loss': 0.351877348211995}
2023-01-05 07:20:46,203 INFO:     Found new best model at epoch 37
2023-01-05 07:20:46,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:20:46,205 INFO:     Epoch: 38
2023-01-05 07:20:48,349 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41687170465787254, 'Total loss': 0.41687170465787254} | train loss {'Reaction outcome loss': 0.34387420041717753, 'Total loss': 0.34387420041717753}
2023-01-05 07:20:48,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:20:48,350 INFO:     Epoch: 39
2023-01-05 07:20:50,508 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4291251460711161, 'Total loss': 0.4291251460711161} | train loss {'Reaction outcome loss': 0.3408346255003971, 'Total loss': 0.3408346255003971}
2023-01-05 07:20:50,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:20:50,509 INFO:     Epoch: 40
2023-01-05 07:20:52,643 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4084693998098373, 'Total loss': 0.4084693998098373} | train loss {'Reaction outcome loss': 0.34277059192204995, 'Total loss': 0.34277059192204995}
2023-01-05 07:20:52,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:20:52,643 INFO:     Epoch: 41
2023-01-05 07:20:54,802 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39340687493483223, 'Total loss': 0.39340687493483223} | train loss {'Reaction outcome loss': 0.33403519916273383, 'Total loss': 0.33403519916273383}
2023-01-05 07:20:54,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:20:54,803 INFO:     Epoch: 42
2023-01-05 07:20:56,952 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4006643096605937, 'Total loss': 0.4006643096605937} | train loss {'Reaction outcome loss': 0.3359076127980965, 'Total loss': 0.3359076127980965}
2023-01-05 07:20:56,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:20:56,952 INFO:     Epoch: 43
2023-01-05 07:20:59,094 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41407493551572166, 'Total loss': 0.41407493551572166} | train loss {'Reaction outcome loss': 0.32895507634936894, 'Total loss': 0.32895507634936894}
2023-01-05 07:20:59,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:20:59,095 INFO:     Epoch: 44
2023-01-05 07:21:01,259 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40049614707628883, 'Total loss': 0.40049614707628883} | train loss {'Reaction outcome loss': 0.3303929328048316, 'Total loss': 0.3303929328048316}
2023-01-05 07:21:01,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:21:01,259 INFO:     Epoch: 45
2023-01-05 07:21:03,379 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4040317585070928, 'Total loss': 0.4040317585070928} | train loss {'Reaction outcome loss': 0.32206499973570346, 'Total loss': 0.32206499973570346}
2023-01-05 07:21:03,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:21:03,379 INFO:     Epoch: 46
2023-01-05 07:21:05,520 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42601425051689146, 'Total loss': 0.42601425051689146} | train loss {'Reaction outcome loss': 0.31991029247967867, 'Total loss': 0.31991029247967867}
2023-01-05 07:21:05,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:21:05,521 INFO:     Epoch: 47
2023-01-05 07:21:07,650 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.36432093878587085, 'Total loss': 0.36432093878587085} | train loss {'Reaction outcome loss': 0.31752699129555345, 'Total loss': 0.31752699129555345}
2023-01-05 07:21:07,650 INFO:     Found new best model at epoch 47
2023-01-05 07:21:07,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:21:07,651 INFO:     Epoch: 48
2023-01-05 07:21:09,794 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.440885462363561, 'Total loss': 0.440885462363561} | train loss {'Reaction outcome loss': 0.3154394151982817, 'Total loss': 0.3154394151982817}
2023-01-05 07:21:09,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:21:09,794 INFO:     Epoch: 49
2023-01-05 07:21:11,948 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4041195789972941, 'Total loss': 0.4041195789972941} | train loss {'Reaction outcome loss': 0.3188156855639315, 'Total loss': 0.3188156855639315}
2023-01-05 07:21:11,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:21:11,948 INFO:     Epoch: 50
2023-01-05 07:21:14,111 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4092369149128596, 'Total loss': 0.4092369149128596} | train loss {'Reaction outcome loss': 0.31206590120755406, 'Total loss': 0.31206590120755406}
2023-01-05 07:21:14,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:21:14,111 INFO:     Epoch: 51
2023-01-05 07:21:16,249 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39749887386957805, 'Total loss': 0.39749887386957805} | train loss {'Reaction outcome loss': 0.31363868310938786, 'Total loss': 0.31363868310938786}
2023-01-05 07:21:16,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:21:16,249 INFO:     Epoch: 52
2023-01-05 07:21:18,400 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4125830471515656, 'Total loss': 0.4125830471515656} | train loss {'Reaction outcome loss': 0.3053773037654205, 'Total loss': 0.3053773037654205}
2023-01-05 07:21:18,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:21:18,401 INFO:     Epoch: 53
2023-01-05 07:21:20,549 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3908552701274554, 'Total loss': 0.3908552701274554} | train loss {'Reaction outcome loss': 0.30980286593582945, 'Total loss': 0.30980286593582945}
2023-01-05 07:21:20,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:21:20,549 INFO:     Epoch: 54
2023-01-05 07:21:22,704 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4140239030122757, 'Total loss': 0.4140239030122757} | train loss {'Reaction outcome loss': 0.3042037341927253, 'Total loss': 0.3042037341927253}
2023-01-05 07:21:22,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:21:22,704 INFO:     Epoch: 55
2023-01-05 07:21:24,867 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.42736570835113524, 'Total loss': 0.42736570835113524} | train loss {'Reaction outcome loss': 0.30707400274483393, 'Total loss': 0.30707400274483393}
2023-01-05 07:21:24,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:21:24,868 INFO:     Epoch: 56
2023-01-05 07:21:26,984 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.41465818223853906, 'Total loss': 0.41465818223853906} | train loss {'Reaction outcome loss': 0.29837559604079184, 'Total loss': 0.29837559604079184}
2023-01-05 07:21:26,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:21:26,984 INFO:     Epoch: 57
2023-01-05 07:21:29,137 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.38788367907206217, 'Total loss': 0.38788367907206217} | train loss {'Reaction outcome loss': 0.2971197515862049, 'Total loss': 0.2971197515862049}
2023-01-05 07:21:29,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:21:29,137 INFO:     Epoch: 58
2023-01-05 07:21:31,282 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3977671543757121, 'Total loss': 0.3977671543757121} | train loss {'Reaction outcome loss': 0.29274181121566, 'Total loss': 0.29274181121566}
2023-01-05 07:21:31,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:21:31,283 INFO:     Epoch: 59
2023-01-05 07:21:33,429 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.39002732237180077, 'Total loss': 0.39002732237180077} | train loss {'Reaction outcome loss': 0.29462294734633754, 'Total loss': 0.29462294734633754}
2023-01-05 07:21:33,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:21:33,429 INFO:     Epoch: 60
2023-01-05 07:21:35,586 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.37526409526666005, 'Total loss': 0.37526409526666005} | train loss {'Reaction outcome loss': 0.28862417625249737, 'Total loss': 0.28862417625249737}
2023-01-05 07:21:35,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:21:35,586 INFO:     Epoch: 61
2023-01-05 07:21:37,739 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3999199360609055, 'Total loss': 0.3999199360609055} | train loss {'Reaction outcome loss': 0.2822706691485687, 'Total loss': 0.2822706691485687}
2023-01-05 07:21:37,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:21:37,739 INFO:     Epoch: 62
2023-01-05 07:21:39,853 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.38635937329381703, 'Total loss': 0.38635937329381703} | train loss {'Reaction outcome loss': 0.289074571572081, 'Total loss': 0.289074571572081}
2023-01-05 07:21:39,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:21:39,853 INFO:     Epoch: 63
2023-01-05 07:21:42,055 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.38325845698515576, 'Total loss': 0.38325845698515576} | train loss {'Reaction outcome loss': 0.28405190452280704, 'Total loss': 0.28405190452280704}
2023-01-05 07:21:42,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:21:42,055 INFO:     Epoch: 64
2023-01-05 07:21:44,307 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4056632399559021, 'Total loss': 0.4056632399559021} | train loss {'Reaction outcome loss': 0.2762777508936659, 'Total loss': 0.2762777508936659}
2023-01-05 07:21:44,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:21:44,308 INFO:     Epoch: 65
2023-01-05 07:21:46,470 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4083931485811869, 'Total loss': 0.4083931485811869} | train loss {'Reaction outcome loss': 0.2855122350292267, 'Total loss': 0.2855122350292267}
2023-01-05 07:21:46,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:21:46,471 INFO:     Epoch: 66
2023-01-05 07:21:48,615 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40325232843557995, 'Total loss': 0.40325232843557995} | train loss {'Reaction outcome loss': 0.2780945663591915, 'Total loss': 0.2780945663591915}
2023-01-05 07:21:48,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:21:48,615 INFO:     Epoch: 67
2023-01-05 07:21:50,749 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39132450918356576, 'Total loss': 0.39132450918356576} | train loss {'Reaction outcome loss': 0.2680869889411613, 'Total loss': 0.2680869889411613}
2023-01-05 07:21:50,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:21:50,750 INFO:     Epoch: 68
2023-01-05 07:21:52,918 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39826252857844036, 'Total loss': 0.39826252857844036} | train loss {'Reaction outcome loss': 0.2750158428221288, 'Total loss': 0.2750158428221288}
2023-01-05 07:21:52,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:21:52,919 INFO:     Epoch: 69
2023-01-05 07:21:55,075 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3669269879659017, 'Total loss': 0.3669269879659017} | train loss {'Reaction outcome loss': 0.2769930833393205, 'Total loss': 0.2769930833393205}
2023-01-05 07:21:55,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:21:55,076 INFO:     Epoch: 70
2023-01-05 07:21:57,240 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.37212553024291994, 'Total loss': 0.37212553024291994} | train loss {'Reaction outcome loss': 0.2656912966393424, 'Total loss': 0.2656912966393424}
2023-01-05 07:21:57,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:21:57,241 INFO:     Epoch: 71
2023-01-05 07:21:59,408 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.415925998489062, 'Total loss': 0.415925998489062} | train loss {'Reaction outcome loss': 0.27480598994578326, 'Total loss': 0.27480598994578326}
2023-01-05 07:21:59,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:21:59,408 INFO:     Epoch: 72
2023-01-05 07:22:01,569 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4239480217297872, 'Total loss': 0.4239480217297872} | train loss {'Reaction outcome loss': 0.2670689477809589, 'Total loss': 0.2670689477809589}
2023-01-05 07:22:01,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:22:01,570 INFO:     Epoch: 73
2023-01-05 07:22:03,725 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3921766996383667, 'Total loss': 0.3921766996383667} | train loss {'Reaction outcome loss': 0.26688019560826737, 'Total loss': 0.26688019560826737}
2023-01-05 07:22:03,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:22:03,726 INFO:     Epoch: 74
2023-01-05 07:22:05,874 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.35603553454081216, 'Total loss': 0.35603553454081216} | train loss {'Reaction outcome loss': 0.26445740747544233, 'Total loss': 0.26445740747544233}
2023-01-05 07:22:05,874 INFO:     Found new best model at epoch 74
2023-01-05 07:22:05,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:22:05,875 INFO:     Epoch: 75
2023-01-05 07:22:08,018 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44420021076997124, 'Total loss': 0.44420021076997124} | train loss {'Reaction outcome loss': 0.26469856453039786, 'Total loss': 0.26469856453039786}
2023-01-05 07:22:08,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:22:08,018 INFO:     Epoch: 76
2023-01-05 07:22:10,169 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.40984029372533165, 'Total loss': 0.40984029372533165} | train loss {'Reaction outcome loss': 0.2612319846372426, 'Total loss': 0.2612319846372426}
2023-01-05 07:22:10,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:22:10,169 INFO:     Epoch: 77
2023-01-05 07:22:12,317 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.37174413800239564, 'Total loss': 0.37174413800239564} | train loss {'Reaction outcome loss': 0.26239759884230845, 'Total loss': 0.26239759884230845}
2023-01-05 07:22:12,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:22:12,318 INFO:     Epoch: 78
2023-01-05 07:22:14,425 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4345822110772133, 'Total loss': 0.4345822110772133} | train loss {'Reaction outcome loss': 0.2554692807437403, 'Total loss': 0.2554692807437403}
2023-01-05 07:22:14,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:22:14,426 INFO:     Epoch: 79
2023-01-05 07:22:16,597 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3587671369314194, 'Total loss': 0.3587671369314194} | train loss {'Reaction outcome loss': 0.2581698542501587, 'Total loss': 0.2581698542501587}
2023-01-05 07:22:16,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:22:16,597 INFO:     Epoch: 80
2023-01-05 07:22:18,746 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41469131807486215, 'Total loss': 0.41469131807486215} | train loss {'Reaction outcome loss': 0.2608579607938763, 'Total loss': 0.2608579607938763}
2023-01-05 07:22:18,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:22:18,746 INFO:     Epoch: 81
2023-01-05 07:22:20,902 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4350134253501892, 'Total loss': 0.4350134253501892} | train loss {'Reaction outcome loss': 0.2564067366621355, 'Total loss': 0.2564067366621355}
2023-01-05 07:22:20,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:22:20,902 INFO:     Epoch: 82
2023-01-05 07:22:23,055 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.37750360717376075, 'Total loss': 0.37750360717376075} | train loss {'Reaction outcome loss': 0.25584664644442334, 'Total loss': 0.25584664644442334}
2023-01-05 07:22:23,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:22:23,055 INFO:     Epoch: 83
2023-01-05 07:22:25,185 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.36677230981489023, 'Total loss': 0.36677230981489023} | train loss {'Reaction outcome loss': 0.2518427109984803, 'Total loss': 0.2518427109984803}
2023-01-05 07:22:25,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:22:25,187 INFO:     Epoch: 84
2023-01-05 07:22:27,335 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3435444379846255, 'Total loss': 0.3435444379846255} | train loss {'Reaction outcome loss': 0.25409678906800537, 'Total loss': 0.25409678906800537}
2023-01-05 07:22:27,335 INFO:     Found new best model at epoch 84
2023-01-05 07:22:27,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:22:27,336 INFO:     Epoch: 85
2023-01-05 07:22:29,495 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43730465869108837, 'Total loss': 0.43730465869108837} | train loss {'Reaction outcome loss': 0.25491014094411457, 'Total loss': 0.25491014094411457}
2023-01-05 07:22:29,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:22:29,495 INFO:     Epoch: 86
2023-01-05 07:22:31,646 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38837863206863404, 'Total loss': 0.38837863206863404} | train loss {'Reaction outcome loss': 0.25110828266717006, 'Total loss': 0.25110828266717006}
2023-01-05 07:22:31,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:22:31,647 INFO:     Epoch: 87
2023-01-05 07:22:33,804 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39934933334589007, 'Total loss': 0.39934933334589007} | train loss {'Reaction outcome loss': 0.24831278138134602, 'Total loss': 0.24831278138134602}
2023-01-05 07:22:33,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:22:33,804 INFO:     Epoch: 88
2023-01-05 07:22:35,960 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.33513119965791704, 'Total loss': 0.33513119965791704} | train loss {'Reaction outcome loss': 0.24615717048070182, 'Total loss': 0.24615717048070182}
2023-01-05 07:22:35,960 INFO:     Found new best model at epoch 88
2023-01-05 07:22:35,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:22:35,962 INFO:     Epoch: 89
2023-01-05 07:22:38,094 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3884594937165578, 'Total loss': 0.3884594937165578} | train loss {'Reaction outcome loss': 0.2522661546313197, 'Total loss': 0.2522661546313197}
2023-01-05 07:22:38,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:22:38,094 INFO:     Epoch: 90
2023-01-05 07:22:40,244 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.372912539045016, 'Total loss': 0.372912539045016} | train loss {'Reaction outcome loss': 0.24285183218137843, 'Total loss': 0.24285183218137843}
2023-01-05 07:22:40,245 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:22:40,245 INFO:     Epoch: 91
2023-01-05 07:22:42,396 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4054285248120626, 'Total loss': 0.4054285248120626} | train loss {'Reaction outcome loss': 0.2491446714304442, 'Total loss': 0.2491446714304442}
2023-01-05 07:22:42,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:22:42,396 INFO:     Epoch: 92
2023-01-05 07:22:44,541 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39388214498758317, 'Total loss': 0.39388214498758317} | train loss {'Reaction outcome loss': 0.2482146883424181, 'Total loss': 0.2482146883424181}
2023-01-05 07:22:44,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:22:44,542 INFO:     Epoch: 93
2023-01-05 07:22:46,687 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3704812544087569, 'Total loss': 0.3704812544087569} | train loss {'Reaction outcome loss': 0.2495935360601947, 'Total loss': 0.2495935360601947}
2023-01-05 07:22:46,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:22:46,687 INFO:     Epoch: 94
2023-01-05 07:22:48,817 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.36586290995279946, 'Total loss': 0.36586290995279946} | train loss {'Reaction outcome loss': 0.2488673493728368, 'Total loss': 0.2488673493728368}
2023-01-05 07:22:48,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:22:48,817 INFO:     Epoch: 95
2023-01-05 07:22:50,974 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.35646011245747405, 'Total loss': 0.35646011245747405} | train loss {'Reaction outcome loss': 0.2378907851181435, 'Total loss': 0.2378907851181435}
2023-01-05 07:22:50,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:22:50,974 INFO:     Epoch: 96
2023-01-05 07:22:53,133 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40288821458816526, 'Total loss': 0.40288821458816526} | train loss {'Reaction outcome loss': 0.23638086511760298, 'Total loss': 0.23638086511760298}
2023-01-05 07:22:53,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:22:53,134 INFO:     Epoch: 97
2023-01-05 07:22:55,299 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3688834965229034, 'Total loss': 0.3688834965229034} | train loss {'Reaction outcome loss': 0.23869259456974745, 'Total loss': 0.23869259456974745}
2023-01-05 07:22:55,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:22:55,299 INFO:     Epoch: 98
2023-01-05 07:22:57,469 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3662725418806076, 'Total loss': 0.3662725418806076} | train loss {'Reaction outcome loss': 0.2369074525148438, 'Total loss': 0.2369074525148438}
2023-01-05 07:22:57,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:22:57,469 INFO:     Epoch: 99
2023-01-05 07:22:59,635 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4024740951756636, 'Total loss': 0.4024740951756636} | train loss {'Reaction outcome loss': 0.23103193556685953, 'Total loss': 0.23103193556685953}
2023-01-05 07:22:59,635 INFO:     Best model found after epoch 89 of 100.
2023-01-05 07:22:59,635 INFO:   Done with stage: TRAINING
2023-01-05 07:22:59,635 INFO:   Starting stage: EVALUATION
2023-01-05 07:22:59,774 INFO:   Done with stage: EVALUATION
2023-01-05 07:22:59,774 INFO:   Leaving out SEQ value Fold_5
2023-01-05 07:22:59,787 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 07:22:59,787 INFO:   Starting stage: FEATURE SCALING
2023-01-05 07:23:00,450 INFO:   Done with stage: FEATURE SCALING
2023-01-05 07:23:00,451 INFO:   Starting stage: SCALING TARGETS
2023-01-05 07:23:00,523 INFO:   Done with stage: SCALING TARGETS
2023-01-05 07:23:00,523 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:23:00,523 INFO:     No hyperparam tuning for this model
2023-01-05 07:23:00,523 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:23:00,523 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 07:23:00,524 INFO:     None feature selector for col prot
2023-01-05 07:23:00,524 INFO:     None feature selector for col prot
2023-01-05 07:23:00,524 INFO:     None feature selector for col prot
2023-01-05 07:23:00,525 INFO:     None feature selector for col chem
2023-01-05 07:23:00,525 INFO:     None feature selector for col chem
2023-01-05 07:23:00,525 INFO:     None feature selector for col chem
2023-01-05 07:23:00,525 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 07:23:00,525 INFO:   Starting stage: BUILD MODEL
2023-01-05 07:23:00,527 INFO:     Number of params in model 72901
2023-01-05 07:23:00,530 INFO:   Done with stage: BUILD MODEL
2023-01-05 07:23:00,530 INFO:   Starting stage: TRAINING
2023-01-05 07:23:00,592 INFO:     Val loss before train {'Reaction outcome loss': 1.0632389187812805, 'Total loss': 1.0632389187812805}
2023-01-05 07:23:00,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:23:00,592 INFO:     Epoch: 0
2023-01-05 07:23:02,767 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.861379599571228, 'Total loss': 0.861379599571228} | train loss {'Reaction outcome loss': 0.9219888750288626, 'Total loss': 0.9219888750288626}
2023-01-05 07:23:02,767 INFO:     Found new best model at epoch 0
2023-01-05 07:23:02,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:23:02,769 INFO:     Epoch: 1
2023-01-05 07:23:04,933 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6008164425690968, 'Total loss': 0.6008164425690968} | train loss {'Reaction outcome loss': 0.724295160072633, 'Total loss': 0.724295160072633}
2023-01-05 07:23:04,933 INFO:     Found new best model at epoch 1
2023-01-05 07:23:04,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:23:04,935 INFO:     Epoch: 2
2023-01-05 07:23:07,105 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.533611927429835, 'Total loss': 0.533611927429835} | train loss {'Reaction outcome loss': 0.5654975458012853, 'Total loss': 0.5654975458012853}
2023-01-05 07:23:07,106 INFO:     Found new best model at epoch 2
2023-01-05 07:23:07,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:23:07,107 INFO:     Epoch: 3
2023-01-05 07:23:09,274 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5093874553839366, 'Total loss': 0.5093874553839366} | train loss {'Reaction outcome loss': 0.5274460984771883, 'Total loss': 0.5274460984771883}
2023-01-05 07:23:09,274 INFO:     Found new best model at epoch 3
2023-01-05 07:23:09,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:23:09,276 INFO:     Epoch: 4
2023-01-05 07:23:11,424 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49944612284501394, 'Total loss': 0.49944612284501394} | train loss {'Reaction outcome loss': 0.5052397771695446, 'Total loss': 0.5052397771695446}
2023-01-05 07:23:11,424 INFO:     Found new best model at epoch 4
2023-01-05 07:23:11,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:23:11,426 INFO:     Epoch: 5
2023-01-05 07:23:13,573 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.504950467745463, 'Total loss': 0.504950467745463} | train loss {'Reaction outcome loss': 0.48977755460204, 'Total loss': 0.48977755460204}
2023-01-05 07:23:13,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:23:13,573 INFO:     Epoch: 6
2023-01-05 07:23:15,744 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5118794282277425, 'Total loss': 0.5118794282277425} | train loss {'Reaction outcome loss': 0.4852643883584634, 'Total loss': 0.4852643883584634}
2023-01-05 07:23:15,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:23:15,745 INFO:     Epoch: 7
2023-01-05 07:23:17,918 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5022132436434428, 'Total loss': 0.5022132436434428} | train loss {'Reaction outcome loss': 0.4762909871305042, 'Total loss': 0.4762909871305042}
2023-01-05 07:23:17,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:23:17,918 INFO:     Epoch: 8
2023-01-05 07:23:20,065 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4798157533009847, 'Total loss': 0.4798157533009847} | train loss {'Reaction outcome loss': 0.4802250727687193, 'Total loss': 0.4802250727687193}
2023-01-05 07:23:20,066 INFO:     Found new best model at epoch 8
2023-01-05 07:23:20,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:23:20,067 INFO:     Epoch: 9
2023-01-05 07:23:22,241 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4601148277521133, 'Total loss': 0.4601148277521133} | train loss {'Reaction outcome loss': 0.48229020504758396, 'Total loss': 0.48229020504758396}
2023-01-05 07:23:22,241 INFO:     Found new best model at epoch 9
2023-01-05 07:23:22,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:23:22,242 INFO:     Epoch: 10
2023-01-05 07:23:24,393 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.48029070695241294, 'Total loss': 0.48029070695241294} | train loss {'Reaction outcome loss': 0.4615967233422334, 'Total loss': 0.4615967233422334}
2023-01-05 07:23:24,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:23:24,393 INFO:     Epoch: 11
2023-01-05 07:23:26,549 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4523600975672404, 'Total loss': 0.4523600975672404} | train loss {'Reaction outcome loss': 0.45178429316729307, 'Total loss': 0.45178429316729307}
2023-01-05 07:23:26,549 INFO:     Found new best model at epoch 11
2023-01-05 07:23:26,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:23:26,551 INFO:     Epoch: 12
2023-01-05 07:23:28,720 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4841876089572906, 'Total loss': 0.4841876089572906} | train loss {'Reaction outcome loss': 0.44798220926937915, 'Total loss': 0.44798220926937915}
2023-01-05 07:23:28,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:23:28,720 INFO:     Epoch: 13
2023-01-05 07:23:30,896 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4750640372435252, 'Total loss': 0.4750640372435252} | train loss {'Reaction outcome loss': 0.4385243896462455, 'Total loss': 0.4385243896462455}
2023-01-05 07:23:30,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:23:30,897 INFO:     Epoch: 14
2023-01-05 07:23:33,058 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4585998316605886, 'Total loss': 0.4585998316605886} | train loss {'Reaction outcome loss': 0.4371800697003694, 'Total loss': 0.4371800697003694}
2023-01-05 07:23:33,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:23:33,059 INFO:     Epoch: 15
2023-01-05 07:23:35,218 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4626646260420481, 'Total loss': 0.4626646260420481} | train loss {'Reaction outcome loss': 0.43267651198381657, 'Total loss': 0.43267651198381657}
2023-01-05 07:23:35,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:23:35,218 INFO:     Epoch: 16
2023-01-05 07:23:37,378 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4387469172477722, 'Total loss': 0.4387469172477722} | train loss {'Reaction outcome loss': 0.42996365722754726, 'Total loss': 0.42996365722754726}
2023-01-05 07:23:37,378 INFO:     Found new best model at epoch 16
2023-01-05 07:23:37,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:23:37,379 INFO:     Epoch: 17
2023-01-05 07:23:39,546 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.42928230464458467, 'Total loss': 0.42928230464458467} | train loss {'Reaction outcome loss': 0.42895284298877423, 'Total loss': 0.42895284298877423}
2023-01-05 07:23:39,546 INFO:     Found new best model at epoch 17
2023-01-05 07:23:39,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:23:39,548 INFO:     Epoch: 18
2023-01-05 07:23:41,717 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4341775665680567, 'Total loss': 0.4341775665680567} | train loss {'Reaction outcome loss': 0.4265187828121112, 'Total loss': 0.4265187828121112}
2023-01-05 07:23:41,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:23:41,718 INFO:     Epoch: 19
2023-01-05 07:23:43,876 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4527977337439855, 'Total loss': 0.4527977337439855} | train loss {'Reaction outcome loss': 0.4197793679608815, 'Total loss': 0.4197793679608815}
2023-01-05 07:23:43,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:23:43,876 INFO:     Epoch: 20
2023-01-05 07:23:46,026 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43790772557258606, 'Total loss': 0.43790772557258606} | train loss {'Reaction outcome loss': 0.4176719777836073, 'Total loss': 0.4176719777836073}
2023-01-05 07:23:46,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:23:46,027 INFO:     Epoch: 21
2023-01-05 07:23:48,174 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44833796719710034, 'Total loss': 0.44833796719710034} | train loss {'Reaction outcome loss': 0.40849509003464185, 'Total loss': 0.40849509003464185}
2023-01-05 07:23:48,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:23:48,174 INFO:     Epoch: 22
2023-01-05 07:23:50,342 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4836052099863688, 'Total loss': 0.4836052099863688} | train loss {'Reaction outcome loss': 0.4073549617297839, 'Total loss': 0.4073549617297839}
2023-01-05 07:23:50,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:23:50,342 INFO:     Epoch: 23
2023-01-05 07:23:52,501 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.46506983041763306, 'Total loss': 0.46506983041763306} | train loss {'Reaction outcome loss': 0.41453656405750394, 'Total loss': 0.41453656405750394}
2023-01-05 07:23:52,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:23:52,502 INFO:     Epoch: 24
2023-01-05 07:23:54,665 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4249211221933365, 'Total loss': 0.4249211221933365} | train loss {'Reaction outcome loss': 0.4411213635355217, 'Total loss': 0.4411213635355217}
2023-01-05 07:23:54,665 INFO:     Found new best model at epoch 24
2023-01-05 07:23:54,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:23:54,666 INFO:     Epoch: 25
2023-01-05 07:23:56,836 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45949145356814064, 'Total loss': 0.45949145356814064} | train loss {'Reaction outcome loss': 0.3975203449144433, 'Total loss': 0.3975203449144433}
2023-01-05 07:23:56,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:23:56,836 INFO:     Epoch: 26
2023-01-05 07:23:58,985 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4817634334166845, 'Total loss': 0.4817634334166845} | train loss {'Reaction outcome loss': 0.4004643411794003, 'Total loss': 0.4004643411794003}
2023-01-05 07:23:58,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:23:58,985 INFO:     Epoch: 27
2023-01-05 07:24:01,166 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.451318001250426, 'Total loss': 0.451318001250426} | train loss {'Reaction outcome loss': 0.4327353187041624, 'Total loss': 0.4327353187041624}
2023-01-05 07:24:01,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:24:01,166 INFO:     Epoch: 28
2023-01-05 07:24:03,337 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4134888490041097, 'Total loss': 0.4134888490041097} | train loss {'Reaction outcome loss': 0.3866936425691929, 'Total loss': 0.3866936425691929}
2023-01-05 07:24:03,337 INFO:     Found new best model at epoch 28
2023-01-05 07:24:03,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:24:03,338 INFO:     Epoch: 29
2023-01-05 07:24:05,501 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4370788643757502, 'Total loss': 0.4370788643757502} | train loss {'Reaction outcome loss': 0.38276107909357804, 'Total loss': 0.38276107909357804}
2023-01-05 07:24:05,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:24:05,502 INFO:     Epoch: 30
2023-01-05 07:24:07,660 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45309528708457947, 'Total loss': 0.45309528708457947} | train loss {'Reaction outcome loss': 0.37727460881064145, 'Total loss': 0.37727460881064145}
2023-01-05 07:24:07,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:24:07,662 INFO:     Epoch: 31
2023-01-05 07:24:09,811 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42725477516651156, 'Total loss': 0.42725477516651156} | train loss {'Reaction outcome loss': 0.3776431027627832, 'Total loss': 0.3776431027627832}
2023-01-05 07:24:09,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:24:09,811 INFO:     Epoch: 32
2023-01-05 07:24:11,884 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43959709207216896, 'Total loss': 0.43959709207216896} | train loss {'Reaction outcome loss': 0.3757309765112924, 'Total loss': 0.3757309765112924}
2023-01-05 07:24:11,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:24:11,885 INFO:     Epoch: 33
2023-01-05 07:24:13,946 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4798352658748627, 'Total loss': 0.4798352658748627} | train loss {'Reaction outcome loss': 0.3749636854045093, 'Total loss': 0.3749636854045093}
2023-01-05 07:24:13,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:24:13,947 INFO:     Epoch: 34
2023-01-05 07:24:16,129 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4042436401049296, 'Total loss': 0.4042436401049296} | train loss {'Reaction outcome loss': 0.3710683239079262, 'Total loss': 0.3710683239079262}
2023-01-05 07:24:16,129 INFO:     Found new best model at epoch 34
2023-01-05 07:24:16,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:24:16,131 INFO:     Epoch: 35
2023-01-05 07:24:18,323 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4052579571803411, 'Total loss': 0.4052579571803411} | train loss {'Reaction outcome loss': 0.3685972660234151, 'Total loss': 0.3685972660234151}
2023-01-05 07:24:18,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:24:18,323 INFO:     Epoch: 36
2023-01-05 07:24:20,469 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4275377114613851, 'Total loss': 0.4275377114613851} | train loss {'Reaction outcome loss': 0.3647741637655797, 'Total loss': 0.3647741637655797}
2023-01-05 07:24:20,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:24:20,469 INFO:     Epoch: 37
2023-01-05 07:24:22,576 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4209820528825124, 'Total loss': 0.4209820528825124} | train loss {'Reaction outcome loss': 0.36132736103786883, 'Total loss': 0.36132736103786883}
2023-01-05 07:24:22,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:24:22,576 INFO:     Epoch: 38
2023-01-05 07:24:24,733 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4431930065155029, 'Total loss': 0.4431930065155029} | train loss {'Reaction outcome loss': 0.3586227673741118, 'Total loss': 0.3586227673741118}
2023-01-05 07:24:24,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:24:24,734 INFO:     Epoch: 39
2023-01-05 07:24:26,908 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4107686847448349, 'Total loss': 0.4107686847448349} | train loss {'Reaction outcome loss': 0.3593720990786518, 'Total loss': 0.3593720990786518}
2023-01-05 07:24:26,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:24:26,909 INFO:     Epoch: 40
2023-01-05 07:24:29,078 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42556132276852926, 'Total loss': 0.42556132276852926} | train loss {'Reaction outcome loss': 0.357729627850832, 'Total loss': 0.357729627850832}
2023-01-05 07:24:29,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:24:29,079 INFO:     Epoch: 41
2023-01-05 07:24:31,235 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39703990121682486, 'Total loss': 0.39703990121682486} | train loss {'Reaction outcome loss': 0.3497556379095287, 'Total loss': 0.3497556379095287}
2023-01-05 07:24:31,235 INFO:     Found new best model at epoch 41
2023-01-05 07:24:31,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:24:31,236 INFO:     Epoch: 42
2023-01-05 07:24:33,382 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3886365662018458, 'Total loss': 0.3886365662018458} | train loss {'Reaction outcome loss': 0.3444438598294189, 'Total loss': 0.3444438598294189}
2023-01-05 07:24:33,382 INFO:     Found new best model at epoch 42
2023-01-05 07:24:33,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:24:33,383 INFO:     Epoch: 43
2023-01-05 07:24:35,256 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4003342469533285, 'Total loss': 0.4003342469533285} | train loss {'Reaction outcome loss': 0.37025363054936344, 'Total loss': 0.37025363054936344}
2023-01-05 07:24:35,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:24:35,256 INFO:     Epoch: 44
2023-01-05 07:24:37,012 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43422616918881735, 'Total loss': 0.43422616918881735} | train loss {'Reaction outcome loss': 0.34635425911076617, 'Total loss': 0.34635425911076617}
2023-01-05 07:24:37,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:24:37,013 INFO:     Epoch: 45
2023-01-05 07:24:38,893 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4393986533085505, 'Total loss': 0.4393986533085505} | train loss {'Reaction outcome loss': 0.3353918068671086, 'Total loss': 0.3353918068671086}
2023-01-05 07:24:38,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:24:38,893 INFO:     Epoch: 46
2023-01-05 07:24:41,066 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41406562527020774, 'Total loss': 0.41406562527020774} | train loss {'Reaction outcome loss': 0.33381504378537985, 'Total loss': 0.33381504378537985}
2023-01-05 07:24:41,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:24:41,066 INFO:     Epoch: 47
2023-01-05 07:24:43,222 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4079081396261851, 'Total loss': 0.4079081396261851} | train loss {'Reaction outcome loss': 0.3291711697331292, 'Total loss': 0.3291711697331292}
2023-01-05 07:24:43,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:24:43,224 INFO:     Epoch: 48
2023-01-05 07:24:45,407 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40802345077196756, 'Total loss': 0.40802345077196756} | train loss {'Reaction outcome loss': 0.33261721551526285, 'Total loss': 0.33261721551526285}
2023-01-05 07:24:45,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:24:45,407 INFO:     Epoch: 49
2023-01-05 07:24:47,565 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4347087691227595, 'Total loss': 0.4347087691227595} | train loss {'Reaction outcome loss': 0.327820138203105, 'Total loss': 0.327820138203105}
2023-01-05 07:24:47,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:24:47,565 INFO:     Epoch: 50
2023-01-05 07:24:49,732 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4172905306021372, 'Total loss': 0.4172905306021372} | train loss {'Reaction outcome loss': 0.3258415619798209, 'Total loss': 0.3258415619798209}
2023-01-05 07:24:49,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:24:49,733 INFO:     Epoch: 51
2023-01-05 07:24:51,882 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39986293713251747, 'Total loss': 0.39986293713251747} | train loss {'Reaction outcome loss': 0.33229372088891873, 'Total loss': 0.33229372088891873}
2023-01-05 07:24:51,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:24:51,882 INFO:     Epoch: 52
2023-01-05 07:24:54,037 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4155797297755877, 'Total loss': 0.4155797297755877} | train loss {'Reaction outcome loss': 0.3403570176291185, 'Total loss': 0.3403570176291185}
2023-01-05 07:24:54,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:24:54,037 INFO:     Epoch: 53
2023-01-05 07:24:56,184 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4034440437952677, 'Total loss': 0.4034440437952677} | train loss {'Reaction outcome loss': 0.3251683452774435, 'Total loss': 0.3251683452774435}
2023-01-05 07:24:56,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:24:56,184 INFO:     Epoch: 54
2023-01-05 07:24:58,353 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4006468633810679, 'Total loss': 0.4006468633810679} | train loss {'Reaction outcome loss': 0.3234241968155771, 'Total loss': 0.3234241968155771}
2023-01-05 07:24:58,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:24:58,353 INFO:     Epoch: 55
2023-01-05 07:25:00,520 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43629229863484703, 'Total loss': 0.43629229863484703} | train loss {'Reaction outcome loss': 0.3270062193583673, 'Total loss': 0.3270062193583673}
2023-01-05 07:25:00,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:25:00,521 INFO:     Epoch: 56
2023-01-05 07:25:02,659 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42599572936693825, 'Total loss': 0.42599572936693825} | train loss {'Reaction outcome loss': 0.3219066640628718, 'Total loss': 0.3219066640628718}
2023-01-05 07:25:02,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:25:02,660 INFO:     Epoch: 57
2023-01-05 07:25:04,825 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.400854804366827, 'Total loss': 0.400854804366827} | train loss {'Reaction outcome loss': 0.31292880722954264, 'Total loss': 0.31292880722954264}
2023-01-05 07:25:04,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:25:04,826 INFO:     Epoch: 58
2023-01-05 07:25:06,975 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38819428781668347, 'Total loss': 0.38819428781668347} | train loss {'Reaction outcome loss': 0.3105672421068817, 'Total loss': 0.3105672421068817}
2023-01-05 07:25:06,975 INFO:     Found new best model at epoch 58
2023-01-05 07:25:06,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:25:06,977 INFO:     Epoch: 59
2023-01-05 07:25:09,136 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40018753012021385, 'Total loss': 0.40018753012021385} | train loss {'Reaction outcome loss': 0.3073862866884261, 'Total loss': 0.3073862866884261}
2023-01-05 07:25:09,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:25:09,137 INFO:     Epoch: 60
2023-01-05 07:25:11,297 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4036591957012812, 'Total loss': 0.4036591957012812} | train loss {'Reaction outcome loss': 0.3041807225284477, 'Total loss': 0.3041807225284477}
2023-01-05 07:25:11,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:25:11,297 INFO:     Epoch: 61
2023-01-05 07:25:13,451 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3782244970401128, 'Total loss': 0.3782244970401128} | train loss {'Reaction outcome loss': 0.30092330980182125, 'Total loss': 0.30092330980182125}
2023-01-05 07:25:13,451 INFO:     Found new best model at epoch 61
2023-01-05 07:25:13,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:25:13,453 INFO:     Epoch: 62
2023-01-05 07:25:15,594 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39884007374445596, 'Total loss': 0.39884007374445596} | train loss {'Reaction outcome loss': 0.3165004740442163, 'Total loss': 0.3165004740442163}
2023-01-05 07:25:15,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:25:15,594 INFO:     Epoch: 63
2023-01-05 07:25:17,745 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3972750912110011, 'Total loss': 0.3972750912110011} | train loss {'Reaction outcome loss': 0.3010332291834883, 'Total loss': 0.3010332291834883}
2023-01-05 07:25:17,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:25:17,746 INFO:     Epoch: 64
2023-01-05 07:25:19,901 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4000733097394307, 'Total loss': 0.4000733097394307} | train loss {'Reaction outcome loss': 0.3004025808309118, 'Total loss': 0.3004025808309118}
2023-01-05 07:25:19,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:25:19,902 INFO:     Epoch: 65
2023-01-05 07:25:22,061 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3966945360104243, 'Total loss': 0.3966945360104243} | train loss {'Reaction outcome loss': 0.3039404388223572, 'Total loss': 0.3039404388223572}
2023-01-05 07:25:22,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:25:22,061 INFO:     Epoch: 66
2023-01-05 07:25:24,215 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4449693481127421, 'Total loss': 0.4449693481127421} | train loss {'Reaction outcome loss': 0.2954650965984911, 'Total loss': 0.2954650965984911}
2023-01-05 07:25:24,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:25:24,215 INFO:     Epoch: 67
2023-01-05 07:25:26,352 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38289494315783185, 'Total loss': 0.38289494315783185} | train loss {'Reaction outcome loss': 0.2954518373066937, 'Total loss': 0.2954518373066937}
2023-01-05 07:25:26,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:25:26,353 INFO:     Epoch: 68
2023-01-05 07:25:28,532 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4434304376443227, 'Total loss': 0.4434304376443227} | train loss {'Reaction outcome loss': 0.29247383732244076, 'Total loss': 0.29247383732244076}
2023-01-05 07:25:28,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:25:28,532 INFO:     Epoch: 69
2023-01-05 07:25:30,707 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3907266398270925, 'Total loss': 0.3907266398270925} | train loss {'Reaction outcome loss': 0.3148167638135129, 'Total loss': 0.3148167638135129}
2023-01-05 07:25:30,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:25:30,708 INFO:     Epoch: 70
2023-01-05 07:25:32,900 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38589702248573304, 'Total loss': 0.38589702248573304} | train loss {'Reaction outcome loss': 0.2881535765773151, 'Total loss': 0.2881535765773151}
2023-01-05 07:25:32,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:25:32,900 INFO:     Epoch: 71
2023-01-05 07:25:35,088 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.38024740914503735, 'Total loss': 0.38024740914503735} | train loss {'Reaction outcome loss': 0.2906886986186863, 'Total loss': 0.2906886986186863}
2023-01-05 07:25:35,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:25:35,088 INFO:     Epoch: 72
2023-01-05 07:25:37,242 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.38453379372755686, 'Total loss': 0.38453379372755686} | train loss {'Reaction outcome loss': 0.3502789462382561, 'Total loss': 0.3502789462382561}
2023-01-05 07:25:37,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:25:37,242 INFO:     Epoch: 73
2023-01-05 07:25:39,415 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.38165183216333387, 'Total loss': 0.38165183216333387} | train loss {'Reaction outcome loss': 0.28716786045149184, 'Total loss': 0.28716786045149184}
2023-01-05 07:25:39,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:25:39,416 INFO:     Epoch: 74
2023-01-05 07:25:41,607 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39367129703362785, 'Total loss': 0.39367129703362785} | train loss {'Reaction outcome loss': 0.28337029478364234, 'Total loss': 0.28337029478364234}
2023-01-05 07:25:41,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:25:41,607 INFO:     Epoch: 75
2023-01-05 07:25:43,761 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3754373033841451, 'Total loss': 0.3754373033841451} | train loss {'Reaction outcome loss': 0.2782626799873759, 'Total loss': 0.2782626799873759}
2023-01-05 07:25:43,761 INFO:     Found new best model at epoch 75
2023-01-05 07:25:43,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:25:43,762 INFO:     Epoch: 76
2023-01-05 07:25:45,920 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39250442932049434, 'Total loss': 0.39250442932049434} | train loss {'Reaction outcome loss': 0.2799139640064559, 'Total loss': 0.2799139640064559}
2023-01-05 07:25:45,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:25:45,920 INFO:     Epoch: 77
2023-01-05 07:25:48,077 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3879535029331843, 'Total loss': 0.3879535029331843} | train loss {'Reaction outcome loss': 0.30147734700585715, 'Total loss': 0.30147734700585715}
2023-01-05 07:25:48,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:25:48,078 INFO:     Epoch: 78
2023-01-05 07:25:50,232 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.36390939553578694, 'Total loss': 0.36390939553578694} | train loss {'Reaction outcome loss': 0.27301740813408804, 'Total loss': 0.27301740813408804}
2023-01-05 07:25:50,233 INFO:     Found new best model at epoch 78
2023-01-05 07:25:50,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:25:50,235 INFO:     Epoch: 79
2023-01-05 07:25:52,398 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3926070995007952, 'Total loss': 0.3926070995007952} | train loss {'Reaction outcome loss': 0.2731065206243184, 'Total loss': 0.2731065206243184}
2023-01-05 07:25:52,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:25:52,398 INFO:     Epoch: 80
2023-01-05 07:25:54,580 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41501052379608155, 'Total loss': 0.41501052379608155} | train loss {'Reaction outcome loss': 0.2712654611384386, 'Total loss': 0.2712654611384386}
2023-01-05 07:25:54,580 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:25:54,580 INFO:     Epoch: 81
2023-01-05 07:25:56,787 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4307810058196386, 'Total loss': 0.4307810058196386} | train loss {'Reaction outcome loss': 0.27118113498621876, 'Total loss': 0.27118113498621876}
2023-01-05 07:25:56,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:25:56,788 INFO:     Epoch: 82
2023-01-05 07:25:58,951 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3611923158168793, 'Total loss': 0.3611923158168793} | train loss {'Reaction outcome loss': 0.2684658200773613, 'Total loss': 0.2684658200773613}
2023-01-05 07:25:58,951 INFO:     Found new best model at epoch 82
2023-01-05 07:25:58,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:25:58,953 INFO:     Epoch: 83
2023-01-05 07:26:01,104 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3860393434762955, 'Total loss': 0.3860393434762955} | train loss {'Reaction outcome loss': 0.2842251990678842, 'Total loss': 0.2842251990678842}
2023-01-05 07:26:01,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:26:01,104 INFO:     Epoch: 84
2023-01-05 07:26:03,270 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.37655548254648846, 'Total loss': 0.37655548254648846} | train loss {'Reaction outcome loss': 0.3170134571205447, 'Total loss': 0.3170134571205447}
2023-01-05 07:26:03,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:26:03,270 INFO:     Epoch: 85
2023-01-05 07:26:05,425 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.38292913138866425, 'Total loss': 0.38292913138866425} | train loss {'Reaction outcome loss': 0.2755737934561878, 'Total loss': 0.2755737934561878}
2023-01-05 07:26:05,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:26:05,425 INFO:     Epoch: 86
2023-01-05 07:26:07,587 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.36778014004230497, 'Total loss': 0.36778014004230497} | train loss {'Reaction outcome loss': 0.2620424727891446, 'Total loss': 0.2620424727891446}
2023-01-05 07:26:07,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:26:07,588 INFO:     Epoch: 87
2023-01-05 07:26:09,745 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.36805753003184993, 'Total loss': 0.36805753003184993} | train loss {'Reaction outcome loss': 0.26196381281972764, 'Total loss': 0.26196381281972764}
2023-01-05 07:26:09,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:26:09,746 INFO:     Epoch: 88
2023-01-05 07:26:11,913 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3759394576152166, 'Total loss': 0.3759394576152166} | train loss {'Reaction outcome loss': 0.2649918197286383, 'Total loss': 0.2649918197286383}
2023-01-05 07:26:11,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:26:11,914 INFO:     Epoch: 89
2023-01-05 07:26:14,074 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3907895008722941, 'Total loss': 0.3907895008722941} | train loss {'Reaction outcome loss': 0.26070964708882116, 'Total loss': 0.26070964708882116}
2023-01-05 07:26:14,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:26:14,075 INFO:     Epoch: 90
2023-01-05 07:26:16,220 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.39288546244303385, 'Total loss': 0.39288546244303385} | train loss {'Reaction outcome loss': 0.25809572675000486, 'Total loss': 0.25809572675000486}
2023-01-05 07:26:16,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:26:16,220 INFO:     Epoch: 91
2023-01-05 07:26:18,358 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.35835194488366445, 'Total loss': 0.35835194488366445} | train loss {'Reaction outcome loss': 0.25242513011925033, 'Total loss': 0.25242513011925033}
2023-01-05 07:26:18,358 INFO:     Found new best model at epoch 91
2023-01-05 07:26:18,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:26:18,360 INFO:     Epoch: 92
2023-01-05 07:26:20,507 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3544435759385427, 'Total loss': 0.3544435759385427} | train loss {'Reaction outcome loss': 0.2631340545068151, 'Total loss': 0.2631340545068151}
2023-01-05 07:26:20,507 INFO:     Found new best model at epoch 92
2023-01-05 07:26:20,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:26:20,508 INFO:     Epoch: 93
2023-01-05 07:26:22,654 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3672224188844363, 'Total loss': 0.3672224188844363} | train loss {'Reaction outcome loss': 0.25796474013085297, 'Total loss': 0.25796474013085297}
2023-01-05 07:26:22,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:26:22,654 INFO:     Epoch: 94
2023-01-05 07:26:24,807 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.36825371384620664, 'Total loss': 0.36825371384620664} | train loss {'Reaction outcome loss': 0.2606356844198013, 'Total loss': 0.2606356844198013}
2023-01-05 07:26:24,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:26:24,808 INFO:     Epoch: 95
2023-01-05 07:26:26,962 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4250303571422895, 'Total loss': 0.4250303571422895} | train loss {'Reaction outcome loss': 0.2705155451397371, 'Total loss': 0.2705155451397371}
2023-01-05 07:26:26,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:26:26,963 INFO:     Epoch: 96
2023-01-05 07:26:29,103 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.35540477707982066, 'Total loss': 0.35540477707982066} | train loss {'Reaction outcome loss': 0.26427662075308245, 'Total loss': 0.26427662075308245}
2023-01-05 07:26:29,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:26:29,104 INFO:     Epoch: 97
2023-01-05 07:26:31,280 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.38413380533456803, 'Total loss': 0.38413380533456803} | train loss {'Reaction outcome loss': 0.2489318765996807, 'Total loss': 0.2489318765996807}
2023-01-05 07:26:31,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:26:31,280 INFO:     Epoch: 98
2023-01-05 07:26:33,433 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3769243131081263, 'Total loss': 0.3769243131081263} | train loss {'Reaction outcome loss': 0.2509454119584837, 'Total loss': 0.2509454119584837}
2023-01-05 07:26:33,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:26:33,434 INFO:     Epoch: 99
2023-01-05 07:26:35,583 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3667069147030512, 'Total loss': 0.3667069147030512} | train loss {'Reaction outcome loss': 0.2581345649970596, 'Total loss': 0.2581345649970596}
2023-01-05 07:26:35,583 INFO:     Best model found after epoch 93 of 100.
2023-01-05 07:26:35,583 INFO:   Done with stage: TRAINING
2023-01-05 07:26:35,583 INFO:   Starting stage: EVALUATION
2023-01-05 07:26:35,716 INFO:   Done with stage: EVALUATION
2023-01-05 07:26:35,716 INFO:   Leaving out SEQ value Fold_6
2023-01-05 07:26:35,728 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 07:26:35,729 INFO:   Starting stage: FEATURE SCALING
2023-01-05 07:26:36,386 INFO:   Done with stage: FEATURE SCALING
2023-01-05 07:26:36,386 INFO:   Starting stage: SCALING TARGETS
2023-01-05 07:26:36,457 INFO:   Done with stage: SCALING TARGETS
2023-01-05 07:26:36,457 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:26:36,457 INFO:     No hyperparam tuning for this model
2023-01-05 07:26:36,457 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:26:36,457 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 07:26:36,458 INFO:     None feature selector for col prot
2023-01-05 07:26:36,458 INFO:     None feature selector for col prot
2023-01-05 07:26:36,458 INFO:     None feature selector for col prot
2023-01-05 07:26:36,459 INFO:     None feature selector for col chem
2023-01-05 07:26:36,459 INFO:     None feature selector for col chem
2023-01-05 07:26:36,459 INFO:     None feature selector for col chem
2023-01-05 07:26:36,459 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 07:26:36,459 INFO:   Starting stage: BUILD MODEL
2023-01-05 07:26:36,460 INFO:     Number of params in model 72901
2023-01-05 07:26:36,463 INFO:   Done with stage: BUILD MODEL
2023-01-05 07:26:36,463 INFO:   Starting stage: TRAINING
2023-01-05 07:26:36,520 INFO:     Val loss before train {'Reaction outcome loss': 1.0169129888216655, 'Total loss': 1.0169129888216655}
2023-01-05 07:26:36,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:26:36,521 INFO:     Epoch: 0
2023-01-05 07:26:38,667 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8269309123357137, 'Total loss': 0.8269309123357137} | train loss {'Reaction outcome loss': 0.9207033464409384, 'Total loss': 0.9207033464409384}
2023-01-05 07:26:38,668 INFO:     Found new best model at epoch 0
2023-01-05 07:26:38,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:26:38,669 INFO:     Epoch: 1
2023-01-05 07:26:40,812 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.624068953593572, 'Total loss': 0.624068953593572} | train loss {'Reaction outcome loss': 0.7368861570254991, 'Total loss': 0.7368861570254991}
2023-01-05 07:26:40,812 INFO:     Found new best model at epoch 1
2023-01-05 07:26:40,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:26:40,813 INFO:     Epoch: 2
2023-01-05 07:26:42,968 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5108818570772807, 'Total loss': 0.5108818570772807} | train loss {'Reaction outcome loss': 0.5887902851354344, 'Total loss': 0.5887902851354344}
2023-01-05 07:26:42,968 INFO:     Found new best model at epoch 2
2023-01-05 07:26:42,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:26:42,969 INFO:     Epoch: 3
2023-01-05 07:26:45,121 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.495717978477478, 'Total loss': 0.495717978477478} | train loss {'Reaction outcome loss': 0.5356489253173236, 'Total loss': 0.5356489253173236}
2023-01-05 07:26:45,121 INFO:     Found new best model at epoch 3
2023-01-05 07:26:45,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:26:45,123 INFO:     Epoch: 4
2023-01-05 07:26:47,273 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49639932513237, 'Total loss': 0.49639932513237} | train loss {'Reaction outcome loss': 0.5172669619644592, 'Total loss': 0.5172669619644592}
2023-01-05 07:26:47,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:26:47,273 INFO:     Epoch: 5
2023-01-05 07:26:49,416 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.509333602587382, 'Total loss': 0.509333602587382} | train loss {'Reaction outcome loss': 0.5019664971514299, 'Total loss': 0.5019664971514299}
2023-01-05 07:26:49,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:26:49,416 INFO:     Epoch: 6
2023-01-05 07:26:51,556 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47854992349942527, 'Total loss': 0.47854992349942527} | train loss {'Reaction outcome loss': 0.4918301518105428, 'Total loss': 0.4918301518105428}
2023-01-05 07:26:51,556 INFO:     Found new best model at epoch 6
2023-01-05 07:26:51,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:26:51,557 INFO:     Epoch: 7
2023-01-05 07:26:53,712 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46158359249432884, 'Total loss': 0.46158359249432884} | train loss {'Reaction outcome loss': 0.48615192708018024, 'Total loss': 0.48615192708018024}
2023-01-05 07:26:53,713 INFO:     Found new best model at epoch 7
2023-01-05 07:26:53,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:26:53,714 INFO:     Epoch: 8
2023-01-05 07:26:55,856 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48184603254000347, 'Total loss': 0.48184603254000347} | train loss {'Reaction outcome loss': 0.4791029898806169, 'Total loss': 0.4791029898806169}
2023-01-05 07:26:55,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:26:55,858 INFO:     Epoch: 9
2023-01-05 07:26:58,012 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4945744236310323, 'Total loss': 0.4945744236310323} | train loss {'Reaction outcome loss': 0.4736228183396026, 'Total loss': 0.4736228183396026}
2023-01-05 07:26:58,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:26:58,013 INFO:     Epoch: 10
2023-01-05 07:27:00,182 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4825824946165085, 'Total loss': 0.4825824946165085} | train loss {'Reaction outcome loss': 0.4744987994002091, 'Total loss': 0.4744987994002091}
2023-01-05 07:27:00,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:27:00,183 INFO:     Epoch: 11
2023-01-05 07:27:02,369 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48489800492922464, 'Total loss': 0.48489800492922464} | train loss {'Reaction outcome loss': 0.4593906081970848, 'Total loss': 0.4593906081970848}
2023-01-05 07:27:02,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:27:02,370 INFO:     Epoch: 12
2023-01-05 07:27:04,538 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46144946813583376, 'Total loss': 0.46144946813583376} | train loss {'Reaction outcome loss': 0.45715032980545334, 'Total loss': 0.45715032980545334}
2023-01-05 07:27:04,538 INFO:     Found new best model at epoch 12
2023-01-05 07:27:04,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:27:04,539 INFO:     Epoch: 13
2023-01-05 07:27:06,699 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.46494426131248473, 'Total loss': 0.46494426131248473} | train loss {'Reaction outcome loss': 0.45573981412911674, 'Total loss': 0.45573981412911674}
2023-01-05 07:27:06,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:27:06,699 INFO:     Epoch: 14
2023-01-05 07:27:08,860 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4415374765793482, 'Total loss': 0.4415374765793482} | train loss {'Reaction outcome loss': 0.44983111009916243, 'Total loss': 0.44983111009916243}
2023-01-05 07:27:08,860 INFO:     Found new best model at epoch 14
2023-01-05 07:27:08,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:27:08,861 INFO:     Epoch: 15
2023-01-05 07:27:11,024 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.44862792020042735, 'Total loss': 0.44862792020042735} | train loss {'Reaction outcome loss': 0.4497889251001045, 'Total loss': 0.4497889251001045}
2023-01-05 07:27:11,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:27:11,025 INFO:     Epoch: 16
2023-01-05 07:27:13,200 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.47284022172292073, 'Total loss': 0.47284022172292073} | train loss {'Reaction outcome loss': 0.4409367233945144, 'Total loss': 0.4409367233945144}
2023-01-05 07:27:13,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:27:13,200 INFO:     Epoch: 17
2023-01-05 07:27:15,233 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4568321079015732, 'Total loss': 0.4568321079015732} | train loss {'Reaction outcome loss': 0.4422876342646912, 'Total loss': 0.4422876342646912}
2023-01-05 07:27:15,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:27:15,234 INFO:     Epoch: 18
2023-01-05 07:27:17,004 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4557715803384781, 'Total loss': 0.4557715803384781} | train loss {'Reaction outcome loss': 0.4324181631261261, 'Total loss': 0.4324181631261261}
2023-01-05 07:27:17,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:27:17,004 INFO:     Epoch: 19
2023-01-05 07:27:18,768 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4541588385899862, 'Total loss': 0.4541588385899862} | train loss {'Reaction outcome loss': 0.43154259165917064, 'Total loss': 0.43154259165917064}
2023-01-05 07:27:18,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:27:18,769 INFO:     Epoch: 20
2023-01-05 07:27:20,875 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4257417241732279, 'Total loss': 0.4257417241732279} | train loss {'Reaction outcome loss': 0.42427061188845, 'Total loss': 0.42427061188845}
2023-01-05 07:27:20,875 INFO:     Found new best model at epoch 20
2023-01-05 07:27:20,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:27:20,877 INFO:     Epoch: 21
2023-01-05 07:27:23,044 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46004714369773864, 'Total loss': 0.46004714369773864} | train loss {'Reaction outcome loss': 0.4235049060643365, 'Total loss': 0.4235049060643365}
2023-01-05 07:27:23,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:27:23,044 INFO:     Epoch: 22
2023-01-05 07:27:25,241 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44678656856218973, 'Total loss': 0.44678656856218973} | train loss {'Reaction outcome loss': 0.41772011562590133, 'Total loss': 0.41772011562590133}
2023-01-05 07:27:25,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:27:25,241 INFO:     Epoch: 23
2023-01-05 07:27:27,419 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4535211592912674, 'Total loss': 0.4535211592912674} | train loss {'Reaction outcome loss': 0.4106919060491483, 'Total loss': 0.4106919060491483}
2023-01-05 07:27:27,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:27:27,419 INFO:     Epoch: 24
2023-01-05 07:27:29,626 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4478807210922241, 'Total loss': 0.4478807210922241} | train loss {'Reaction outcome loss': 0.4115695581916007, 'Total loss': 0.4115695581916007}
2023-01-05 07:27:29,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:27:29,626 INFO:     Epoch: 25
2023-01-05 07:27:31,795 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4291614969571432, 'Total loss': 0.4291614969571432} | train loss {'Reaction outcome loss': 0.4067851299628454, 'Total loss': 0.4067851299628454}
2023-01-05 07:27:31,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:27:31,796 INFO:     Epoch: 26
2023-01-05 07:27:33,967 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4412383367617925, 'Total loss': 0.4412383367617925} | train loss {'Reaction outcome loss': 0.40155892364600076, 'Total loss': 0.40155892364600076}
2023-01-05 07:27:33,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:27:33,967 INFO:     Epoch: 27
2023-01-05 07:27:36,134 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.413590939839681, 'Total loss': 0.413590939839681} | train loss {'Reaction outcome loss': 0.39744855093665504, 'Total loss': 0.39744855093665504}
2023-01-05 07:27:36,134 INFO:     Found new best model at epoch 27
2023-01-05 07:27:36,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:27:36,135 INFO:     Epoch: 28
2023-01-05 07:27:38,302 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43098962505658467, 'Total loss': 0.43098962505658467} | train loss {'Reaction outcome loss': 0.3939039339496341, 'Total loss': 0.3939039339496341}
2023-01-05 07:27:38,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:27:38,303 INFO:     Epoch: 29
2023-01-05 07:27:40,480 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42098921636740366, 'Total loss': 0.42098921636740366} | train loss {'Reaction outcome loss': 0.3928528423774113, 'Total loss': 0.3928528423774113}
2023-01-05 07:27:40,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:27:40,480 INFO:     Epoch: 30
2023-01-05 07:27:42,638 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43297438422838846, 'Total loss': 0.43297438422838846} | train loss {'Reaction outcome loss': 0.38808109369196186, 'Total loss': 0.38808109369196186}
2023-01-05 07:27:42,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:27:42,639 INFO:     Epoch: 31
2023-01-05 07:27:44,812 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4374879906574885, 'Total loss': 0.4374879906574885} | train loss {'Reaction outcome loss': 0.38931102429378767, 'Total loss': 0.38931102429378767}
2023-01-05 07:27:44,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:27:44,813 INFO:     Epoch: 32
2023-01-05 07:27:46,976 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4381583909193675, 'Total loss': 0.4381583909193675} | train loss {'Reaction outcome loss': 0.3852483048658509, 'Total loss': 0.3852483048658509}
2023-01-05 07:27:46,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:27:46,976 INFO:     Epoch: 33
2023-01-05 07:27:49,131 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4140204191207886, 'Total loss': 0.4140204191207886} | train loss {'Reaction outcome loss': 0.38195674153656733, 'Total loss': 0.38195674153656733}
2023-01-05 07:27:49,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:27:49,131 INFO:     Epoch: 34
2023-01-05 07:27:51,306 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4128013630708059, 'Total loss': 0.4128013630708059} | train loss {'Reaction outcome loss': 0.3757436491199349, 'Total loss': 0.3757436491199349}
2023-01-05 07:27:51,306 INFO:     Found new best model at epoch 34
2023-01-05 07:27:51,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:27:51,308 INFO:     Epoch: 35
2023-01-05 07:27:53,479 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44107329150040947, 'Total loss': 0.44107329150040947} | train loss {'Reaction outcome loss': 0.374199729372448, 'Total loss': 0.374199729372448}
2023-01-05 07:27:53,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:27:53,479 INFO:     Epoch: 36
2023-01-05 07:27:55,650 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44795320679744083, 'Total loss': 0.44795320679744083} | train loss {'Reaction outcome loss': 0.3692537955805283, 'Total loss': 0.3692537955805283}
2023-01-05 07:27:55,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:27:55,650 INFO:     Epoch: 37
2023-01-05 07:27:57,817 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4147587786118189, 'Total loss': 0.4147587786118189} | train loss {'Reaction outcome loss': 0.3669619754440948, 'Total loss': 0.3669619754440948}
2023-01-05 07:27:57,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:27:57,818 INFO:     Epoch: 38
2023-01-05 07:27:59,996 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.41849660873413086, 'Total loss': 0.41849660873413086} | train loss {'Reaction outcome loss': 0.36724330490246576, 'Total loss': 0.36724330490246576}
2023-01-05 07:27:59,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:27:59,996 INFO:     Epoch: 39
2023-01-05 07:28:02,182 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3975440889596939, 'Total loss': 0.3975440889596939} | train loss {'Reaction outcome loss': 0.3655216655952836, 'Total loss': 0.3655216655952836}
2023-01-05 07:28:02,182 INFO:     Found new best model at epoch 39
2023-01-05 07:28:02,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:28:02,184 INFO:     Epoch: 40
2023-01-05 07:28:04,364 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4272666906317075, 'Total loss': 0.4272666906317075} | train loss {'Reaction outcome loss': 0.3557617451578701, 'Total loss': 0.3557617451578701}
2023-01-05 07:28:04,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:28:04,364 INFO:     Epoch: 41
2023-01-05 07:28:06,517 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.40352625052134194, 'Total loss': 0.40352625052134194} | train loss {'Reaction outcome loss': 0.35840587300460264, 'Total loss': 0.35840587300460264}
2023-01-05 07:28:06,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:28:06,518 INFO:     Epoch: 42
2023-01-05 07:28:08,682 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4086500763893127, 'Total loss': 0.4086500763893127} | train loss {'Reaction outcome loss': 0.3513827362914808, 'Total loss': 0.3513827362914808}
2023-01-05 07:28:08,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:28:08,683 INFO:     Epoch: 43
2023-01-05 07:28:10,854 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4284153600533803, 'Total loss': 0.4284153600533803} | train loss {'Reaction outcome loss': 0.34582788489140326, 'Total loss': 0.34582788489140326}
2023-01-05 07:28:10,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:28:10,854 INFO:     Epoch: 44
2023-01-05 07:28:13,006 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4104148119688034, 'Total loss': 0.4104148119688034} | train loss {'Reaction outcome loss': 0.34257524018091845, 'Total loss': 0.34257524018091845}
2023-01-05 07:28:13,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:28:13,006 INFO:     Epoch: 45
2023-01-05 07:28:14,985 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3836954226096471, 'Total loss': 0.3836954226096471} | train loss {'Reaction outcome loss': 0.34358553478111, 'Total loss': 0.34358553478111}
2023-01-05 07:28:14,985 INFO:     Found new best model at epoch 45
2023-01-05 07:28:14,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:28:14,987 INFO:     Epoch: 46
2023-01-05 07:28:17,168 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40410938014586767, 'Total loss': 0.40410938014586767} | train loss {'Reaction outcome loss': 0.3466617419293641, 'Total loss': 0.3466617419293641}
2023-01-05 07:28:17,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:28:17,168 INFO:     Epoch: 47
2023-01-05 07:28:19,322 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.37332266171773276, 'Total loss': 0.37332266171773276} | train loss {'Reaction outcome loss': 0.3424415269375708, 'Total loss': 0.3424415269375708}
2023-01-05 07:28:19,322 INFO:     Found new best model at epoch 47
2023-01-05 07:28:19,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:28:19,324 INFO:     Epoch: 48
2023-01-05 07:28:21,479 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40926806529362997, 'Total loss': 0.40926806529362997} | train loss {'Reaction outcome loss': 0.33785123375348663, 'Total loss': 0.33785123375348663}
2023-01-05 07:28:21,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:28:21,479 INFO:     Epoch: 49
2023-01-05 07:28:23,638 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42605085770289103, 'Total loss': 0.42605085770289103} | train loss {'Reaction outcome loss': 0.32871607829571203, 'Total loss': 0.32871607829571203}
2023-01-05 07:28:23,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:28:23,638 INFO:     Epoch: 50
2023-01-05 07:28:25,810 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.38424426714579263, 'Total loss': 0.38424426714579263} | train loss {'Reaction outcome loss': 0.33664540471744453, 'Total loss': 0.33664540471744453}
2023-01-05 07:28:25,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:28:25,811 INFO:     Epoch: 51
2023-01-05 07:28:27,966 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3826618472735087, 'Total loss': 0.3826618472735087} | train loss {'Reaction outcome loss': 0.32882248072310044, 'Total loss': 0.32882248072310044}
2023-01-05 07:28:27,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:28:27,967 INFO:     Epoch: 52
2023-01-05 07:28:30,109 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.37513870298862456, 'Total loss': 0.37513870298862456} | train loss {'Reaction outcome loss': 0.33021902957332694, 'Total loss': 0.33021902957332694}
2023-01-05 07:28:30,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:28:30,110 INFO:     Epoch: 53
2023-01-05 07:28:32,260 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3886463105678558, 'Total loss': 0.3886463105678558} | train loss {'Reaction outcome loss': 0.32424227773659064, 'Total loss': 0.32424227773659064}
2023-01-05 07:28:32,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:28:32,260 INFO:     Epoch: 54
2023-01-05 07:28:34,409 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.38816847999890647, 'Total loss': 0.38816847999890647} | train loss {'Reaction outcome loss': 0.3212784895343901, 'Total loss': 0.3212784895343901}
2023-01-05 07:28:34,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:28:34,409 INFO:     Epoch: 55
2023-01-05 07:28:36,577 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3986704895893733, 'Total loss': 0.3986704895893733} | train loss {'Reaction outcome loss': 0.31895809305919204, 'Total loss': 0.31895809305919204}
2023-01-05 07:28:36,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:28:36,577 INFO:     Epoch: 56
2023-01-05 07:28:38,733 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3593865320086479, 'Total loss': 0.3593865320086479} | train loss {'Reaction outcome loss': 0.3182906996095654, 'Total loss': 0.3182906996095654}
2023-01-05 07:28:38,733 INFO:     Found new best model at epoch 56
2023-01-05 07:28:38,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:28:38,735 INFO:     Epoch: 57
2023-01-05 07:28:40,876 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3804823398590088, 'Total loss': 0.3804823398590088} | train loss {'Reaction outcome loss': 0.3154664152580908, 'Total loss': 0.3154664152580908}
2023-01-05 07:28:40,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:28:40,877 INFO:     Epoch: 58
2023-01-05 07:28:43,057 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4071941077709198, 'Total loss': 0.4071941077709198} | train loss {'Reaction outcome loss': 0.3139221229008819, 'Total loss': 0.3139221229008819}
2023-01-05 07:28:43,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:28:43,057 INFO:     Epoch: 59
2023-01-05 07:28:45,221 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3913255070646604, 'Total loss': 0.3913255070646604} | train loss {'Reaction outcome loss': 0.3115195472210323, 'Total loss': 0.3115195472210323}
2023-01-05 07:28:45,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:28:45,222 INFO:     Epoch: 60
2023-01-05 07:28:47,391 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4043509443600973, 'Total loss': 0.4043509443600973} | train loss {'Reaction outcome loss': 0.30475672193221237, 'Total loss': 0.30475672193221237}
2023-01-05 07:28:47,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:28:47,391 INFO:     Epoch: 61
2023-01-05 07:28:49,560 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3874019871155421, 'Total loss': 0.3874019871155421} | train loss {'Reaction outcome loss': 0.30584687058433946, 'Total loss': 0.30584687058433946}
2023-01-05 07:28:49,560 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:28:49,560 INFO:     Epoch: 62
2023-01-05 07:28:51,725 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3915721873442332, 'Total loss': 0.3915721873442332} | train loss {'Reaction outcome loss': 0.30969741005141166, 'Total loss': 0.30969741005141166}
2023-01-05 07:28:51,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:28:51,726 INFO:     Epoch: 63
2023-01-05 07:28:53,897 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3620521475871404, 'Total loss': 0.3620521475871404} | train loss {'Reaction outcome loss': 0.3032878764404071, 'Total loss': 0.3032878764404071}
2023-01-05 07:28:53,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:28:53,897 INFO:     Epoch: 64
2023-01-05 07:28:56,069 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4072977582613627, 'Total loss': 0.4072977582613627} | train loss {'Reaction outcome loss': 0.3017423544953231, 'Total loss': 0.3017423544953231}
2023-01-05 07:28:56,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:28:56,069 INFO:     Epoch: 65
2023-01-05 07:28:58,236 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.36900801261266075, 'Total loss': 0.36900801261266075} | train loss {'Reaction outcome loss': 0.2965694494975818, 'Total loss': 0.2965694494975818}
2023-01-05 07:28:58,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:28:58,237 INFO:     Epoch: 66
2023-01-05 07:29:00,412 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4080199748277664, 'Total loss': 0.4080199748277664} | train loss {'Reaction outcome loss': 0.2980412523588334, 'Total loss': 0.2980412523588334}
2023-01-05 07:29:00,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:29:00,412 INFO:     Epoch: 67
2023-01-05 07:29:02,589 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.36270970727006596, 'Total loss': 0.36270970727006596} | train loss {'Reaction outcome loss': 0.29381968910782347, 'Total loss': 0.29381968910782347}
2023-01-05 07:29:02,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:29:02,589 INFO:     Epoch: 68
2023-01-05 07:29:04,762 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.35144110570351283, 'Total loss': 0.35144110570351283} | train loss {'Reaction outcome loss': 0.30071214043168815, 'Total loss': 0.30071214043168815}
2023-01-05 07:29:04,763 INFO:     Found new best model at epoch 68
2023-01-05 07:29:04,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:29:04,764 INFO:     Epoch: 69
2023-01-05 07:29:06,925 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.37873684664567314, 'Total loss': 0.37873684664567314} | train loss {'Reaction outcome loss': 0.28383607575367287, 'Total loss': 0.28383607575367287}
2023-01-05 07:29:06,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:29:06,925 INFO:     Epoch: 70
2023-01-05 07:29:09,088 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3442217936118444, 'Total loss': 0.3442217936118444} | train loss {'Reaction outcome loss': 0.2897062610754145, 'Total loss': 0.2897062610754145}
2023-01-05 07:29:09,088 INFO:     Found new best model at epoch 70
2023-01-05 07:29:09,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:29:09,090 INFO:     Epoch: 71
2023-01-05 07:29:11,249 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3556730398287376, 'Total loss': 0.3556730398287376} | train loss {'Reaction outcome loss': 0.29898827198879385, 'Total loss': 0.29898827198879385}
2023-01-05 07:29:11,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:29:11,250 INFO:     Epoch: 72
2023-01-05 07:29:13,417 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.35526973058780037, 'Total loss': 0.35526973058780037} | train loss {'Reaction outcome loss': 0.2972497246513943, 'Total loss': 0.2972497246513943}
2023-01-05 07:29:13,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:29:13,417 INFO:     Epoch: 73
2023-01-05 07:29:15,576 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3671415761113167, 'Total loss': 0.3671415761113167} | train loss {'Reaction outcome loss': 0.28934238361537673, 'Total loss': 0.28934238361537673}
2023-01-05 07:29:15,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:29:15,578 INFO:     Epoch: 74
2023-01-05 07:29:17,747 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.36533219714959464, 'Total loss': 0.36533219714959464} | train loss {'Reaction outcome loss': 0.288346024277193, 'Total loss': 0.288346024277193}
2023-01-05 07:29:17,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:29:17,747 INFO:     Epoch: 75
2023-01-05 07:29:19,910 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3886757969856262, 'Total loss': 0.3886757969856262} | train loss {'Reaction outcome loss': 0.2786647328898472, 'Total loss': 0.2786647328898472}
2023-01-05 07:29:19,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:29:19,910 INFO:     Epoch: 76
2023-01-05 07:29:22,069 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3626029377182325, 'Total loss': 0.3626029377182325} | train loss {'Reaction outcome loss': 0.282383825293732, 'Total loss': 0.282383825293732}
2023-01-05 07:29:22,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:29:22,070 INFO:     Epoch: 77
2023-01-05 07:29:24,224 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3770918260018031, 'Total loss': 0.3770918260018031} | train loss {'Reaction outcome loss': 0.2733221296960696, 'Total loss': 0.2733221296960696}
2023-01-05 07:29:24,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:29:24,224 INFO:     Epoch: 78
2023-01-05 07:29:26,377 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3809026345610619, 'Total loss': 0.3809026345610619} | train loss {'Reaction outcome loss': 0.268125300756269, 'Total loss': 0.268125300756269}
2023-01-05 07:29:26,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:29:26,377 INFO:     Epoch: 79
2023-01-05 07:29:28,533 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.381398809949557, 'Total loss': 0.381398809949557} | train loss {'Reaction outcome loss': 0.2803811745092757, 'Total loss': 0.2803811745092757}
2023-01-05 07:29:28,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:29:28,533 INFO:     Epoch: 80
2023-01-05 07:29:30,697 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3796013613541921, 'Total loss': 0.3796013613541921} | train loss {'Reaction outcome loss': 0.2750247583627055, 'Total loss': 0.2750247583627055}
2023-01-05 07:29:30,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:29:30,698 INFO:     Epoch: 81
2023-01-05 07:29:32,840 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.38672392318646115, 'Total loss': 0.38672392318646115} | train loss {'Reaction outcome loss': 0.2710575812667716, 'Total loss': 0.2710575812667716}
2023-01-05 07:29:32,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:29:32,840 INFO:     Epoch: 82
2023-01-05 07:29:35,011 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3756141404310862, 'Total loss': 0.3756141404310862} | train loss {'Reaction outcome loss': 0.27046630206090877, 'Total loss': 0.27046630206090877}
2023-01-05 07:29:35,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:29:35,012 INFO:     Epoch: 83
2023-01-05 07:29:37,172 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.35010691583156583, 'Total loss': 0.35010691583156583} | train loss {'Reaction outcome loss': 0.2720409734208231, 'Total loss': 0.2720409734208231}
2023-01-05 07:29:37,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:29:37,173 INFO:     Epoch: 84
2023-01-05 07:29:39,297 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3729273994763692, 'Total loss': 0.3729273994763692} | train loss {'Reaction outcome loss': 0.2664564122455968, 'Total loss': 0.2664564122455968}
2023-01-05 07:29:39,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:29:39,298 INFO:     Epoch: 85
2023-01-05 07:29:41,461 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.37388868431250255, 'Total loss': 0.37388868431250255} | train loss {'Reaction outcome loss': 0.26950191372891197, 'Total loss': 0.26950191372891197}
2023-01-05 07:29:41,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:29:41,461 INFO:     Epoch: 86
2023-01-05 07:29:43,606 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3426762307683627, 'Total loss': 0.3426762307683627} | train loss {'Reaction outcome loss': 0.2700575102550996, 'Total loss': 0.2700575102550996}
2023-01-05 07:29:43,606 INFO:     Found new best model at epoch 86
2023-01-05 07:29:43,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:29:43,607 INFO:     Epoch: 87
2023-01-05 07:29:45,768 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.34204722438007595, 'Total loss': 0.34204722438007595} | train loss {'Reaction outcome loss': 0.2688411806612561, 'Total loss': 0.2688411806612561}
2023-01-05 07:29:45,769 INFO:     Found new best model at epoch 87
2023-01-05 07:29:45,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:29:45,771 INFO:     Epoch: 88
2023-01-05 07:29:47,943 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.35528892278671265, 'Total loss': 0.35528892278671265} | train loss {'Reaction outcome loss': 0.2670117586528351, 'Total loss': 0.2670117586528351}
2023-01-05 07:29:47,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:29:47,944 INFO:     Epoch: 89
2023-01-05 07:29:50,127 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3933430939912796, 'Total loss': 0.3933430939912796} | train loss {'Reaction outcome loss': 0.2604070721792615, 'Total loss': 0.2604070721792615}
2023-01-05 07:29:50,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:29:50,128 INFO:     Epoch: 90
2023-01-05 07:29:52,277 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.37824649127821125, 'Total loss': 0.37824649127821125} | train loss {'Reaction outcome loss': 0.2609146636598054, 'Total loss': 0.2609146636598054}
2023-01-05 07:29:52,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:29:52,278 INFO:     Epoch: 91
2023-01-05 07:29:54,470 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39322375853856406, 'Total loss': 0.39322375853856406} | train loss {'Reaction outcome loss': 0.2593633357758234, 'Total loss': 0.2593633357758234}
2023-01-05 07:29:54,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:29:54,471 INFO:     Epoch: 92
2023-01-05 07:29:56,651 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3886128728588422, 'Total loss': 0.3886128728588422} | train loss {'Reaction outcome loss': 0.25478245275572536, 'Total loss': 0.25478245275572536}
2023-01-05 07:29:56,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:29:56,651 INFO:     Epoch: 93
2023-01-05 07:29:58,854 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.35621061623096467, 'Total loss': 0.35621061623096467} | train loss {'Reaction outcome loss': 0.2556384230093082, 'Total loss': 0.2556384230093082}
2023-01-05 07:29:58,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:29:58,854 INFO:     Epoch: 94
2023-01-05 07:30:01,070 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38740087623397507, 'Total loss': 0.38740087623397507} | train loss {'Reaction outcome loss': 0.2595459919133718, 'Total loss': 0.2595459919133718}
2023-01-05 07:30:01,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:30:01,071 INFO:     Epoch: 95
2023-01-05 07:30:03,224 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4019405295451482, 'Total loss': 0.4019405295451482} | train loss {'Reaction outcome loss': 0.25554992292842926, 'Total loss': 0.25554992292842926}
2023-01-05 07:30:03,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:30:03,225 INFO:     Epoch: 96
2023-01-05 07:30:05,378 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3622030953566233, 'Total loss': 0.3622030953566233} | train loss {'Reaction outcome loss': 0.2595718325744467, 'Total loss': 0.2595718325744467}
2023-01-05 07:30:05,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:30:05,379 INFO:     Epoch: 97
2023-01-05 07:30:07,524 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3805466115474701, 'Total loss': 0.3805466115474701} | train loss {'Reaction outcome loss': 0.25505467439709156, 'Total loss': 0.25505467439709156}
2023-01-05 07:30:07,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:30:07,524 INFO:     Epoch: 98
2023-01-05 07:30:09,690 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3420065740744273, 'Total loss': 0.3420065740744273} | train loss {'Reaction outcome loss': 0.255107973013006, 'Total loss': 0.255107973013006}
2023-01-05 07:30:09,690 INFO:     Found new best model at epoch 98
2023-01-05 07:30:09,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:30:09,691 INFO:     Epoch: 99
2023-01-05 07:30:11,856 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.35969622830549874, 'Total loss': 0.35969622830549874} | train loss {'Reaction outcome loss': 0.2503621292835108, 'Total loss': 0.2503621292835108}
2023-01-05 07:30:11,857 INFO:     Best model found after epoch 99 of 100.
2023-01-05 07:30:11,857 INFO:   Done with stage: TRAINING
2023-01-05 07:30:11,857 INFO:   Starting stage: EVALUATION
2023-01-05 07:30:11,982 INFO:   Done with stage: EVALUATION
2023-01-05 07:30:11,982 INFO:   Leaving out SEQ value Fold_7
2023-01-05 07:30:11,995 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 07:30:11,995 INFO:   Starting stage: FEATURE SCALING
2023-01-05 07:30:12,652 INFO:   Done with stage: FEATURE SCALING
2023-01-05 07:30:12,652 INFO:   Starting stage: SCALING TARGETS
2023-01-05 07:30:12,722 INFO:   Done with stage: SCALING TARGETS
2023-01-05 07:30:12,722 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:30:12,722 INFO:     No hyperparam tuning for this model
2023-01-05 07:30:12,722 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:30:12,722 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 07:30:12,723 INFO:     None feature selector for col prot
2023-01-05 07:30:12,723 INFO:     None feature selector for col prot
2023-01-05 07:30:12,723 INFO:     None feature selector for col prot
2023-01-05 07:30:12,723 INFO:     None feature selector for col chem
2023-01-05 07:30:12,724 INFO:     None feature selector for col chem
2023-01-05 07:30:12,724 INFO:     None feature selector for col chem
2023-01-05 07:30:12,724 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 07:30:12,724 INFO:   Starting stage: BUILD MODEL
2023-01-05 07:30:12,725 INFO:     Number of params in model 72901
2023-01-05 07:30:12,728 INFO:   Done with stage: BUILD MODEL
2023-01-05 07:30:12,728 INFO:   Starting stage: TRAINING
2023-01-05 07:30:12,788 INFO:     Val loss before train {'Reaction outcome loss': 0.9603254040082295, 'Total loss': 0.9603254040082295}
2023-01-05 07:30:12,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:30:12,789 INFO:     Epoch: 0
2023-01-05 07:30:14,935 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7440650423367818, 'Total loss': 0.7440650423367818} | train loss {'Reaction outcome loss': 0.9025568372529486, 'Total loss': 0.9025568372529486}
2023-01-05 07:30:14,935 INFO:     Found new best model at epoch 0
2023-01-05 07:30:14,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:30:14,937 INFO:     Epoch: 1
2023-01-05 07:30:17,092 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6033498167991638, 'Total loss': 0.6033498167991638} | train loss {'Reaction outcome loss': 0.719287104544439, 'Total loss': 0.719287104544439}
2023-01-05 07:30:17,092 INFO:     Found new best model at epoch 1
2023-01-05 07:30:17,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:30:17,094 INFO:     Epoch: 2
2023-01-05 07:30:19,229 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5634557137886683, 'Total loss': 0.5634557137886683} | train loss {'Reaction outcome loss': 0.5678555151528638, 'Total loss': 0.5678555151528638}
2023-01-05 07:30:19,229 INFO:     Found new best model at epoch 2
2023-01-05 07:30:19,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:30:19,231 INFO:     Epoch: 3
2023-01-05 07:30:21,392 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5417453567186992, 'Total loss': 0.5417453567186992} | train loss {'Reaction outcome loss': 0.5264068704260432, 'Total loss': 0.5264068704260432}
2023-01-05 07:30:21,393 INFO:     Found new best model at epoch 3
2023-01-05 07:30:21,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:30:21,395 INFO:     Epoch: 4
2023-01-05 07:30:23,564 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5318597555160522, 'Total loss': 0.5318597555160522} | train loss {'Reaction outcome loss': 0.5080488485004078, 'Total loss': 0.5080488485004078}
2023-01-05 07:30:23,564 INFO:     Found new best model at epoch 4
2023-01-05 07:30:23,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:30:23,566 INFO:     Epoch: 5
2023-01-05 07:30:25,708 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5199227074782053, 'Total loss': 0.5199227074782053} | train loss {'Reaction outcome loss': 0.491177943343338, 'Total loss': 0.491177943343338}
2023-01-05 07:30:25,708 INFO:     Found new best model at epoch 5
2023-01-05 07:30:25,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:30:25,709 INFO:     Epoch: 6
2023-01-05 07:30:27,881 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5142013450463613, 'Total loss': 0.5142013450463613} | train loss {'Reaction outcome loss': 0.4906189857528248, 'Total loss': 0.4906189857528248}
2023-01-05 07:30:27,881 INFO:     Found new best model at epoch 6
2023-01-05 07:30:27,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:30:27,883 INFO:     Epoch: 7
2023-01-05 07:30:30,031 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5529415349165598, 'Total loss': 0.5529415349165598} | train loss {'Reaction outcome loss': 0.47589882530029054, 'Total loss': 0.47589882530029054}
2023-01-05 07:30:30,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:30:30,031 INFO:     Epoch: 8
2023-01-05 07:30:32,179 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4961601068576177, 'Total loss': 0.4961601068576177} | train loss {'Reaction outcome loss': 0.4715438225392037, 'Total loss': 0.4715438225392037}
2023-01-05 07:30:32,179 INFO:     Found new best model at epoch 8
2023-01-05 07:30:32,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:30:32,181 INFO:     Epoch: 9
2023-01-05 07:30:34,324 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4898166666428248, 'Total loss': 0.4898166666428248} | train loss {'Reaction outcome loss': 0.4662574140525396, 'Total loss': 0.4662574140525396}
2023-01-05 07:30:34,324 INFO:     Found new best model at epoch 9
2023-01-05 07:30:34,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:30:34,325 INFO:     Epoch: 10
2023-01-05 07:30:36,469 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5293689141670863, 'Total loss': 0.5293689141670863} | train loss {'Reaction outcome loss': 0.47068260269968404, 'Total loss': 0.47068260269968404}
2023-01-05 07:30:36,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:30:36,469 INFO:     Epoch: 11
2023-01-05 07:30:38,618 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5417438864707946, 'Total loss': 0.5417438864707946} | train loss {'Reaction outcome loss': 0.4652588192265535, 'Total loss': 0.4652588192265535}
2023-01-05 07:30:38,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:30:38,618 INFO:     Epoch: 12
2023-01-05 07:30:40,779 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5188478648662567, 'Total loss': 0.5188478648662567} | train loss {'Reaction outcome loss': 0.4699830888417057, 'Total loss': 0.4699830888417057}
2023-01-05 07:30:40,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:30:40,780 INFO:     Epoch: 13
2023-01-05 07:30:42,923 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5237081289291382, 'Total loss': 0.5237081289291382} | train loss {'Reaction outcome loss': 0.4458046373828952, 'Total loss': 0.4458046373828952}
2023-01-05 07:30:42,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:30:42,923 INFO:     Epoch: 14
2023-01-05 07:30:45,083 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5240143696467082, 'Total loss': 0.5240143696467082} | train loss {'Reaction outcome loss': 0.4438295567381209, 'Total loss': 0.4438295567381209}
2023-01-05 07:30:45,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:30:45,083 INFO:     Epoch: 15
2023-01-05 07:30:47,258 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.538383009036382, 'Total loss': 0.538383009036382} | train loss {'Reaction outcome loss': 0.4602273210235264, 'Total loss': 0.4602273210235264}
2023-01-05 07:30:47,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:30:47,259 INFO:     Epoch: 16
2023-01-05 07:30:49,402 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5151721556981405, 'Total loss': 0.5151721556981405} | train loss {'Reaction outcome loss': 0.4742316471621988, 'Total loss': 0.4742316471621988}
2023-01-05 07:30:49,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:30:49,402 INFO:     Epoch: 17
2023-01-05 07:30:51,554 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5125444054603576, 'Total loss': 0.5125444054603576} | train loss {'Reaction outcome loss': 0.438969263102173, 'Total loss': 0.438969263102173}
2023-01-05 07:30:51,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:30:51,554 INFO:     Epoch: 18
2023-01-05 07:30:53,702 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4987392216920853, 'Total loss': 0.4987392216920853} | train loss {'Reaction outcome loss': 0.4328136840865583, 'Total loss': 0.4328136840865583}
2023-01-05 07:30:53,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:30:53,702 INFO:     Epoch: 19
2023-01-05 07:30:55,857 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5036249895890553, 'Total loss': 0.5036249895890553} | train loss {'Reaction outcome loss': 0.43701413176629855, 'Total loss': 0.43701413176629855}
2023-01-05 07:30:55,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:30:55,858 INFO:     Epoch: 20
2023-01-05 07:30:58,022 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4835175573825836, 'Total loss': 0.4835175573825836} | train loss {'Reaction outcome loss': 0.4282364625284664, 'Total loss': 0.4282364625284664}
2023-01-05 07:30:58,023 INFO:     Found new best model at epoch 20
2023-01-05 07:30:58,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:30:58,025 INFO:     Epoch: 21
2023-01-05 07:31:00,173 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.493065466483434, 'Total loss': 0.493065466483434} | train loss {'Reaction outcome loss': 0.4286986847553213, 'Total loss': 0.4286986847553213}
2023-01-05 07:31:00,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:31:00,173 INFO:     Epoch: 22
2023-01-05 07:31:02,329 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4921254277229309, 'Total loss': 0.4921254277229309} | train loss {'Reaction outcome loss': 0.42206692510702903, 'Total loss': 0.42206692510702903}
2023-01-05 07:31:02,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:31:02,329 INFO:     Epoch: 23
2023-01-05 07:31:04,475 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5002826988697052, 'Total loss': 0.5002826988697052} | train loss {'Reaction outcome loss': 0.4301370971336745, 'Total loss': 0.4301370971336745}
2023-01-05 07:31:04,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:31:04,475 INFO:     Epoch: 24
2023-01-05 07:31:06,627 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4880607465902964, 'Total loss': 0.4880607465902964} | train loss {'Reaction outcome loss': 0.43978181438169617, 'Total loss': 0.43978181438169617}
2023-01-05 07:31:06,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:31:06,627 INFO:     Epoch: 25
2023-01-05 07:31:08,822 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5071349233388901, 'Total loss': 0.5071349233388901} | train loss {'Reaction outcome loss': 0.45084473498476046, 'Total loss': 0.45084473498476046}
2023-01-05 07:31:08,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:31:08,823 INFO:     Epoch: 26
2023-01-05 07:31:10,980 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4874858776728312, 'Total loss': 0.4874858776728312} | train loss {'Reaction outcome loss': 0.41091062414626073, 'Total loss': 0.41091062414626073}
2023-01-05 07:31:10,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:31:10,981 INFO:     Epoch: 27
2023-01-05 07:31:13,128 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.49365585843722026, 'Total loss': 0.49365585843722026} | train loss {'Reaction outcome loss': 0.4124219198913678, 'Total loss': 0.4124219198913678}
2023-01-05 07:31:13,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:31:13,128 INFO:     Epoch: 28
2023-01-05 07:31:15,317 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5216127137343088, 'Total loss': 0.5216127137343088} | train loss {'Reaction outcome loss': 0.41568934080820275, 'Total loss': 0.41568934080820275}
2023-01-05 07:31:15,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:31:15,318 INFO:     Epoch: 29
2023-01-05 07:31:17,473 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4893928349018097, 'Total loss': 0.4893928349018097} | train loss {'Reaction outcome loss': 0.3964690943012365, 'Total loss': 0.3964690943012365}
2023-01-05 07:31:17,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:31:17,473 INFO:     Epoch: 30
2023-01-05 07:31:19,660 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4802374720573425, 'Total loss': 0.4802374720573425} | train loss {'Reaction outcome loss': 0.3933482963981552, 'Total loss': 0.3933482963981552}
2023-01-05 07:31:19,660 INFO:     Found new best model at epoch 30
2023-01-05 07:31:19,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:31:19,661 INFO:     Epoch: 31
2023-01-05 07:31:21,840 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5006870438655218, 'Total loss': 0.5006870438655218} | train loss {'Reaction outcome loss': 0.39693810277368763, 'Total loss': 0.39693810277368763}
2023-01-05 07:31:21,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:31:21,840 INFO:     Epoch: 32
2023-01-05 07:31:23,992 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4756250500679016, 'Total loss': 0.4756250500679016} | train loss {'Reaction outcome loss': 0.38693352121998137, 'Total loss': 0.38693352121998137}
2023-01-05 07:31:23,992 INFO:     Found new best model at epoch 32
2023-01-05 07:31:23,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:31:23,994 INFO:     Epoch: 33
2023-01-05 07:31:26,186 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.465866756439209, 'Total loss': 0.465866756439209} | train loss {'Reaction outcome loss': 0.39201457027102943, 'Total loss': 0.39201457027102943}
2023-01-05 07:31:26,186 INFO:     Found new best model at epoch 33
2023-01-05 07:31:26,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:31:26,187 INFO:     Epoch: 34
2023-01-05 07:31:28,356 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.49656162758668265, 'Total loss': 0.49656162758668265} | train loss {'Reaction outcome loss': 0.38046854261082824, 'Total loss': 0.38046854261082824}
2023-01-05 07:31:28,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:31:28,358 INFO:     Epoch: 35
2023-01-05 07:31:30,512 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.48760535617669426, 'Total loss': 0.48760535617669426} | train loss {'Reaction outcome loss': 0.3779089022664002, 'Total loss': 0.3779089022664002}
2023-01-05 07:31:30,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:31:30,512 INFO:     Epoch: 36
2023-01-05 07:31:32,696 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4658817191918691, 'Total loss': 0.4658817191918691} | train loss {'Reaction outcome loss': 0.3797302057235198, 'Total loss': 0.3797302057235198}
2023-01-05 07:31:32,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:31:32,697 INFO:     Epoch: 37
2023-01-05 07:31:34,855 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.48111714522043864, 'Total loss': 0.48111714522043864} | train loss {'Reaction outcome loss': 0.3732933699544789, 'Total loss': 0.3732933699544789}
2023-01-05 07:31:34,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:31:34,856 INFO:     Epoch: 38
2023-01-05 07:31:37,028 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.493434731165568, 'Total loss': 0.493434731165568} | train loss {'Reaction outcome loss': 0.38618323431296303, 'Total loss': 0.38618323431296303}
2023-01-05 07:31:37,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:31:37,028 INFO:     Epoch: 39
2023-01-05 07:31:39,202 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4610124091307322, 'Total loss': 0.4610124091307322} | train loss {'Reaction outcome loss': 0.36129703018409404, 'Total loss': 0.36129703018409404}
2023-01-05 07:31:39,202 INFO:     Found new best model at epoch 39
2023-01-05 07:31:39,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:31:39,204 INFO:     Epoch: 40
2023-01-05 07:31:41,369 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46943823496500653, 'Total loss': 0.46943823496500653} | train loss {'Reaction outcome loss': 0.36043167469240184, 'Total loss': 0.36043167469240184}
2023-01-05 07:31:41,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:31:41,369 INFO:     Epoch: 41
2023-01-05 07:31:43,556 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4885951280593872, 'Total loss': 0.4885951280593872} | train loss {'Reaction outcome loss': 0.3599225937893304, 'Total loss': 0.3599225937893304}
2023-01-05 07:31:43,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:31:43,556 INFO:     Epoch: 42
2023-01-05 07:31:45,726 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5444365541140238, 'Total loss': 0.5444365541140238} | train loss {'Reaction outcome loss': 0.3679623083494928, 'Total loss': 0.3679623083494928}
2023-01-05 07:31:45,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:31:45,726 INFO:     Epoch: 43
2023-01-05 07:31:47,875 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4821139444907506, 'Total loss': 0.4821139444907506} | train loss {'Reaction outcome loss': 0.3998986152201078, 'Total loss': 0.3998986152201078}
2023-01-05 07:31:47,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:31:47,876 INFO:     Epoch: 44
2023-01-05 07:31:50,066 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5120913823445638, 'Total loss': 0.5120913823445638} | train loss {'Reaction outcome loss': 0.35979975892257865, 'Total loss': 0.35979975892257865}
2023-01-05 07:31:50,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:31:50,066 INFO:     Epoch: 45
2023-01-05 07:31:52,288 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4661393309632937, 'Total loss': 0.4661393309632937} | train loss {'Reaction outcome loss': 0.36226396416010254, 'Total loss': 0.36226396416010254}
2023-01-05 07:31:52,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:31:52,289 INFO:     Epoch: 46
2023-01-05 07:31:54,459 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4958810160557429, 'Total loss': 0.4958810160557429} | train loss {'Reaction outcome loss': 0.34884583275171294, 'Total loss': 0.34884583275171294}
2023-01-05 07:31:54,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:31:54,459 INFO:     Epoch: 47
2023-01-05 07:31:56,624 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4688639958699544, 'Total loss': 0.4688639958699544} | train loss {'Reaction outcome loss': 0.35116269296597, 'Total loss': 0.35116269296597}
2023-01-05 07:31:56,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:31:56,624 INFO:     Epoch: 48
2023-01-05 07:31:58,772 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.5013583789269129, 'Total loss': 0.5013583789269129} | train loss {'Reaction outcome loss': 0.34026780702971743, 'Total loss': 0.34026780702971743}
2023-01-05 07:31:58,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:31:58,772 INFO:     Epoch: 49
2023-01-05 07:32:00,931 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4488971511522929, 'Total loss': 0.4488971511522929} | train loss {'Reaction outcome loss': 0.3405094451314864, 'Total loss': 0.3405094451314864}
2023-01-05 07:32:00,931 INFO:     Found new best model at epoch 49
2023-01-05 07:32:00,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:32:00,933 INFO:     Epoch: 50
2023-01-05 07:32:03,118 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5010094871123631, 'Total loss': 0.5010094871123631} | train loss {'Reaction outcome loss': 0.3346590788198122, 'Total loss': 0.3346590788198122}
2023-01-05 07:32:03,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:32:03,119 INFO:     Epoch: 51
2023-01-05 07:32:05,303 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.477668442328771, 'Total loss': 0.477668442328771} | train loss {'Reaction outcome loss': 0.33702462336615374, 'Total loss': 0.33702462336615374}
2023-01-05 07:32:05,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:32:05,304 INFO:     Epoch: 52
2023-01-05 07:32:07,506 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.49058824578921, 'Total loss': 0.49058824578921} | train loss {'Reaction outcome loss': 0.3460091735983767, 'Total loss': 0.3460091735983767}
2023-01-05 07:32:07,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:32:07,507 INFO:     Epoch: 53
2023-01-05 07:32:09,684 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42837339341640474, 'Total loss': 0.42837339341640474} | train loss {'Reaction outcome loss': 0.3318463649817547, 'Total loss': 0.3318463649817547}
2023-01-05 07:32:09,685 INFO:     Found new best model at epoch 53
2023-01-05 07:32:09,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:32:09,686 INFO:     Epoch: 54
2023-01-05 07:32:11,869 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4605132669210434, 'Total loss': 0.4605132669210434} | train loss {'Reaction outcome loss': 0.31879502088335904, 'Total loss': 0.31879502088335904}
2023-01-05 07:32:11,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:32:11,869 INFO:     Epoch: 55
2023-01-05 07:32:14,062 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.49560940464337666, 'Total loss': 0.49560940464337666} | train loss {'Reaction outcome loss': 0.31999358851089216, 'Total loss': 0.31999358851089216}
2023-01-05 07:32:14,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:32:14,063 INFO:     Epoch: 56
2023-01-05 07:32:16,231 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5205311755339305, 'Total loss': 0.5205311755339305} | train loss {'Reaction outcome loss': 0.31803057282704156, 'Total loss': 0.31803057282704156}
2023-01-05 07:32:16,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:32:16,232 INFO:     Epoch: 57
2023-01-05 07:32:18,395 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4770709604024887, 'Total loss': 0.4770709604024887} | train loss {'Reaction outcome loss': 0.31465156176262465, 'Total loss': 0.31465156176262465}
2023-01-05 07:32:18,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:32:18,395 INFO:     Epoch: 58
2023-01-05 07:32:20,345 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47778917451699576, 'Total loss': 0.47778917451699576} | train loss {'Reaction outcome loss': 0.32080319267360197, 'Total loss': 0.32080319267360197}
2023-01-05 07:32:20,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:32:20,345 INFO:     Epoch: 59
2023-01-05 07:32:22,501 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5135244568188985, 'Total loss': 0.5135244568188985} | train loss {'Reaction outcome loss': 0.3218826605344488, 'Total loss': 0.3218826605344488}
2023-01-05 07:32:22,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:32:22,502 INFO:     Epoch: 60
2023-01-05 07:32:24,658 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.49462268749872845, 'Total loss': 0.49462268749872845} | train loss {'Reaction outcome loss': 0.3091061291178567, 'Total loss': 0.3091061291178567}
2023-01-05 07:32:24,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:32:24,658 INFO:     Epoch: 61
2023-01-05 07:32:26,817 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.46723816990852357, 'Total loss': 0.46723816990852357} | train loss {'Reaction outcome loss': 0.30656498483837813, 'Total loss': 0.30656498483837813}
2023-01-05 07:32:26,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:32:26,817 INFO:     Epoch: 62
2023-01-05 07:32:28,973 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4553797423839569, 'Total loss': 0.4553797423839569} | train loss {'Reaction outcome loss': 0.2984822886091802, 'Total loss': 0.2984822886091802}
2023-01-05 07:32:28,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:32:28,974 INFO:     Epoch: 63
2023-01-05 07:32:31,126 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4820639024178187, 'Total loss': 0.4820639024178187} | train loss {'Reaction outcome loss': 0.3050545355847293, 'Total loss': 0.3050545355847293}
2023-01-05 07:32:31,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:32:31,126 INFO:     Epoch: 64
2023-01-05 07:32:33,274 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4337405999501546, 'Total loss': 0.4337405999501546} | train loss {'Reaction outcome loss': 0.3051735772768144, 'Total loss': 0.3051735772768144}
2023-01-05 07:32:33,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:32:33,275 INFO:     Epoch: 65
2023-01-05 07:32:35,432 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45396374464035033, 'Total loss': 0.45396374464035033} | train loss {'Reaction outcome loss': 0.30209827329963446, 'Total loss': 0.30209827329963446}
2023-01-05 07:32:35,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:32:35,433 INFO:     Epoch: 66
2023-01-05 07:32:37,576 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48500303328037264, 'Total loss': 0.48500303328037264} | train loss {'Reaction outcome loss': 0.3040632242166306, 'Total loss': 0.3040632242166306}
2023-01-05 07:32:37,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:32:37,576 INFO:     Epoch: 67
2023-01-05 07:32:39,714 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4393648167451223, 'Total loss': 0.4393648167451223} | train loss {'Reaction outcome loss': 0.2986639453692065, 'Total loss': 0.2986639453692065}
2023-01-05 07:32:39,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:32:39,715 INFO:     Epoch: 68
2023-01-05 07:32:41,874 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.43121669391791023, 'Total loss': 0.43121669391791023} | train loss {'Reaction outcome loss': 0.2927908148967486, 'Total loss': 0.2927908148967486}
2023-01-05 07:32:41,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:32:41,874 INFO:     Epoch: 69
2023-01-05 07:32:44,013 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4709810276826223, 'Total loss': 0.4709810276826223} | train loss {'Reaction outcome loss': 0.2898472021852409, 'Total loss': 0.2898472021852409}
2023-01-05 07:32:44,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:32:44,014 INFO:     Epoch: 70
2023-01-05 07:32:46,169 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4709971447785695, 'Total loss': 0.4709971447785695} | train loss {'Reaction outcome loss': 0.2968855601783208, 'Total loss': 0.2968855601783208}
2023-01-05 07:32:46,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:32:46,170 INFO:     Epoch: 71
2023-01-05 07:32:48,326 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.48351228137811025, 'Total loss': 0.48351228137811025} | train loss {'Reaction outcome loss': 0.289763613867209, 'Total loss': 0.289763613867209}
2023-01-05 07:32:48,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:32:48,326 INFO:     Epoch: 72
2023-01-05 07:32:50,476 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45968757569789886, 'Total loss': 0.45968757569789886} | train loss {'Reaction outcome loss': 0.2911626787584585, 'Total loss': 0.2911626787584585}
2023-01-05 07:32:50,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:32:50,476 INFO:     Epoch: 73
2023-01-05 07:32:52,635 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4842530846595764, 'Total loss': 0.4842530846595764} | train loss {'Reaction outcome loss': 0.278127870215373, 'Total loss': 0.278127870215373}
2023-01-05 07:32:52,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:32:52,635 INFO:     Epoch: 74
2023-01-05 07:32:54,802 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.45759938259919486, 'Total loss': 0.45759938259919486} | train loss {'Reaction outcome loss': 0.28249934516750963, 'Total loss': 0.28249934516750963}
2023-01-05 07:32:54,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:32:54,802 INFO:     Epoch: 75
2023-01-05 07:32:56,962 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.5217503686745961, 'Total loss': 0.5217503686745961} | train loss {'Reaction outcome loss': 0.2844822958138758, 'Total loss': 0.2844822958138758}
2023-01-05 07:32:56,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:32:56,962 INFO:     Epoch: 76
2023-01-05 07:32:59,133 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4567939430475235, 'Total loss': 0.4567939430475235} | train loss {'Reaction outcome loss': 0.29385656924516323, 'Total loss': 0.29385656924516323}
2023-01-05 07:32:59,133 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:32:59,133 INFO:     Epoch: 77
2023-01-05 07:33:01,292 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5368227005004883, 'Total loss': 0.5368227005004883} | train loss {'Reaction outcome loss': 0.274340354619093, 'Total loss': 0.274340354619093}
2023-01-05 07:33:01,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:33:01,293 INFO:     Epoch: 78
2023-01-05 07:33:03,414 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4677666569749514, 'Total loss': 0.4677666569749514} | train loss {'Reaction outcome loss': 0.27841552773379197, 'Total loss': 0.27841552773379197}
2023-01-05 07:33:03,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:33:03,414 INFO:     Epoch: 79
2023-01-05 07:33:05,566 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5139171014229457, 'Total loss': 0.5139171014229457} | train loss {'Reaction outcome loss': 0.2783936942671088, 'Total loss': 0.2783936942671088}
2023-01-05 07:33:05,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:33:05,566 INFO:     Epoch: 80
2023-01-05 07:33:07,709 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4759434441725413, 'Total loss': 0.4759434441725413} | train loss {'Reaction outcome loss': 0.2790775752716623, 'Total loss': 0.2790775752716623}
2023-01-05 07:33:07,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:33:07,709 INFO:     Epoch: 81
2023-01-05 07:33:09,870 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42829218208789827, 'Total loss': 0.42829218208789827} | train loss {'Reaction outcome loss': 0.2601096144787954, 'Total loss': 0.2601096144787954}
2023-01-05 07:33:09,871 INFO:     Found new best model at epoch 81
2023-01-05 07:33:09,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:33:09,872 INFO:     Epoch: 82
2023-01-05 07:33:12,033 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44495909561713537, 'Total loss': 0.44495909561713537} | train loss {'Reaction outcome loss': 0.27042417517066863, 'Total loss': 0.27042417517066863}
2023-01-05 07:33:12,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:33:12,033 INFO:     Epoch: 83
2023-01-05 07:33:14,193 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4637822846571604, 'Total loss': 0.4637822846571604} | train loss {'Reaction outcome loss': 0.27035231947935984, 'Total loss': 0.27035231947935984}
2023-01-05 07:33:14,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:33:14,194 INFO:     Epoch: 84
2023-01-05 07:33:16,350 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.44778501192728676, 'Total loss': 0.44778501192728676} | train loss {'Reaction outcome loss': 0.2701763442712853, 'Total loss': 0.2701763442712853}
2023-01-05 07:33:16,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:33:16,352 INFO:     Epoch: 85
2023-01-05 07:33:18,518 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4517914185921351, 'Total loss': 0.4517914185921351} | train loss {'Reaction outcome loss': 0.26478168131797103, 'Total loss': 0.26478168131797103}
2023-01-05 07:33:18,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:33:18,519 INFO:     Epoch: 86
2023-01-05 07:33:20,671 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3911509573459625, 'Total loss': 0.3911509573459625} | train loss {'Reaction outcome loss': 0.2619097955554508, 'Total loss': 0.2619097955554508}
2023-01-05 07:33:20,671 INFO:     Found new best model at epoch 86
2023-01-05 07:33:20,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:33:20,673 INFO:     Epoch: 87
2023-01-05 07:33:22,842 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4641217619180679, 'Total loss': 0.4641217619180679} | train loss {'Reaction outcome loss': 0.2598949406028096, 'Total loss': 0.2598949406028096}
2023-01-05 07:33:22,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:33:22,843 INFO:     Epoch: 88
2023-01-05 07:33:24,993 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42880464692910514, 'Total loss': 0.42880464692910514} | train loss {'Reaction outcome loss': 0.2576522686764635, 'Total loss': 0.2576522686764635}
2023-01-05 07:33:24,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:33:24,993 INFO:     Epoch: 89
2023-01-05 07:33:27,152 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4624473065137863, 'Total loss': 0.4624473065137863} | train loss {'Reaction outcome loss': 0.2571945001347584, 'Total loss': 0.2571945001347584}
2023-01-05 07:33:27,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:33:27,152 INFO:     Epoch: 90
2023-01-05 07:33:29,312 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4818867782751719, 'Total loss': 0.4818867782751719} | train loss {'Reaction outcome loss': 0.26825600722129794, 'Total loss': 0.26825600722129794}
2023-01-05 07:33:29,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:33:29,313 INFO:     Epoch: 91
2023-01-05 07:33:31,453 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44204682211081187, 'Total loss': 0.44204682211081187} | train loss {'Reaction outcome loss': 0.28614228429522476, 'Total loss': 0.28614228429522476}
2023-01-05 07:33:31,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:33:31,453 INFO:     Epoch: 92
2023-01-05 07:33:33,619 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4705822745958964, 'Total loss': 0.4705822745958964} | train loss {'Reaction outcome loss': 0.26305921270808985, 'Total loss': 0.26305921270808985}
2023-01-05 07:33:33,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:33:33,619 INFO:     Epoch: 93
2023-01-05 07:33:35,808 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4560800164937973, 'Total loss': 0.4560800164937973} | train loss {'Reaction outcome loss': 0.262568440245704, 'Total loss': 0.262568440245704}
2023-01-05 07:33:35,809 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:33:35,809 INFO:     Epoch: 94
2023-01-05 07:33:37,988 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4582600196202596, 'Total loss': 0.4582600196202596} | train loss {'Reaction outcome loss': 0.25190585263097065, 'Total loss': 0.25190585263097065}
2023-01-05 07:33:37,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:33:37,988 INFO:     Epoch: 95
2023-01-05 07:33:40,162 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.43996756076812743, 'Total loss': 0.43996756076812743} | train loss {'Reaction outcome loss': 0.24858139684268585, 'Total loss': 0.24858139684268585}
2023-01-05 07:33:40,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:33:40,162 INFO:     Epoch: 96
2023-01-05 07:33:42,318 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42967420915762583, 'Total loss': 0.42967420915762583} | train loss {'Reaction outcome loss': 0.2501967925275929, 'Total loss': 0.2501967925275929}
2023-01-05 07:33:42,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:33:42,319 INFO:     Epoch: 97
2023-01-05 07:33:44,456 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4714601457118988, 'Total loss': 0.4714601457118988} | train loss {'Reaction outcome loss': 0.24151500343831014, 'Total loss': 0.24151500343831014}
2023-01-05 07:33:44,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:33:44,456 INFO:     Epoch: 98
2023-01-05 07:33:46,585 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5077610542376836, 'Total loss': 0.5077610542376836} | train loss {'Reaction outcome loss': 0.2535199106711408, 'Total loss': 0.2535199106711408}
2023-01-05 07:33:46,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:33:46,587 INFO:     Epoch: 99
2023-01-05 07:33:48,739 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4232689494887988, 'Total loss': 0.4232689494887988} | train loss {'Reaction outcome loss': 0.2490679054664751, 'Total loss': 0.2490679054664751}
2023-01-05 07:33:48,739 INFO:     Best model found after epoch 87 of 100.
2023-01-05 07:33:48,739 INFO:   Done with stage: TRAINING
2023-01-05 07:33:48,739 INFO:   Starting stage: EVALUATION
2023-01-05 07:33:48,872 INFO:   Done with stage: EVALUATION
2023-01-05 07:33:48,872 INFO:   Leaving out SEQ value Fold_8
2023-01-05 07:33:48,885 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 07:33:48,885 INFO:   Starting stage: FEATURE SCALING
2023-01-05 07:33:49,545 INFO:   Done with stage: FEATURE SCALING
2023-01-05 07:33:49,545 INFO:   Starting stage: SCALING TARGETS
2023-01-05 07:33:49,614 INFO:   Done with stage: SCALING TARGETS
2023-01-05 07:33:49,614 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:33:49,614 INFO:     No hyperparam tuning for this model
2023-01-05 07:33:49,614 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:33:49,615 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 07:33:49,615 INFO:     None feature selector for col prot
2023-01-05 07:33:49,615 INFO:     None feature selector for col prot
2023-01-05 07:33:49,616 INFO:     None feature selector for col prot
2023-01-05 07:33:49,616 INFO:     None feature selector for col chem
2023-01-05 07:33:49,616 INFO:     None feature selector for col chem
2023-01-05 07:33:49,616 INFO:     None feature selector for col chem
2023-01-05 07:33:49,616 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 07:33:49,616 INFO:   Starting stage: BUILD MODEL
2023-01-05 07:33:49,618 INFO:     Number of params in model 72901
2023-01-05 07:33:49,621 INFO:   Done with stage: BUILD MODEL
2023-01-05 07:33:49,621 INFO:   Starting stage: TRAINING
2023-01-05 07:33:49,677 INFO:     Val loss before train {'Reaction outcome loss': 0.9311400453249613, 'Total loss': 0.9311400453249613}
2023-01-05 07:33:49,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:33:49,678 INFO:     Epoch: 0
2023-01-05 07:33:51,819 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7918657481670379, 'Total loss': 0.7918657481670379} | train loss {'Reaction outcome loss': 0.9303012108025344, 'Total loss': 0.9303012108025344}
2023-01-05 07:33:51,819 INFO:     Found new best model at epoch 0
2023-01-05 07:33:51,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:33:51,821 INFO:     Epoch: 1
2023-01-05 07:33:53,969 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5617059449354808, 'Total loss': 0.5617059449354808} | train loss {'Reaction outcome loss': 0.7452345420336486, 'Total loss': 0.7452345420336486}
2023-01-05 07:33:53,970 INFO:     Found new best model at epoch 1
2023-01-05 07:33:53,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:33:53,971 INFO:     Epoch: 2
2023-01-05 07:33:56,117 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5179790516694387, 'Total loss': 0.5179790516694387} | train loss {'Reaction outcome loss': 0.5901648156434312, 'Total loss': 0.5901648156434312}
2023-01-05 07:33:56,117 INFO:     Found new best model at epoch 2
2023-01-05 07:33:56,118 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:33:56,118 INFO:     Epoch: 3
2023-01-05 07:33:58,270 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5003371854623159, 'Total loss': 0.5003371854623159} | train loss {'Reaction outcome loss': 0.5406057778425326, 'Total loss': 0.5406057778425326}
2023-01-05 07:33:58,270 INFO:     Found new best model at epoch 3
2023-01-05 07:33:58,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:33:58,272 INFO:     Epoch: 4
2023-01-05 07:34:00,429 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5040470043818156, 'Total loss': 0.5040470043818156} | train loss {'Reaction outcome loss': 0.5206962014114612, 'Total loss': 0.5206962014114612}
2023-01-05 07:34:00,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:34:00,430 INFO:     Epoch: 5
2023-01-05 07:34:02,568 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5039689640204111, 'Total loss': 0.5039689640204111} | train loss {'Reaction outcome loss': 0.5130185384414685, 'Total loss': 0.5130185384414685}
2023-01-05 07:34:02,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:34:02,568 INFO:     Epoch: 6
2023-01-05 07:34:04,754 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.47409091095129646, 'Total loss': 0.47409091095129646} | train loss {'Reaction outcome loss': 0.4994202069514279, 'Total loss': 0.4994202069514279}
2023-01-05 07:34:04,754 INFO:     Found new best model at epoch 6
2023-01-05 07:34:04,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:34:04,756 INFO:     Epoch: 7
2023-01-05 07:34:06,906 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4728798071543376, 'Total loss': 0.4728798071543376} | train loss {'Reaction outcome loss': 0.4912937244845797, 'Total loss': 0.4912937244845797}
2023-01-05 07:34:06,907 INFO:     Found new best model at epoch 7
2023-01-05 07:34:06,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:34:06,908 INFO:     Epoch: 8
2023-01-05 07:34:09,053 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4585156559944153, 'Total loss': 0.4585156559944153} | train loss {'Reaction outcome loss': 0.48676944988361304, 'Total loss': 0.48676944988361304}
2023-01-05 07:34:09,054 INFO:     Found new best model at epoch 8
2023-01-05 07:34:09,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:34:09,055 INFO:     Epoch: 9
2023-01-05 07:34:11,216 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4862213412920634, 'Total loss': 0.4862213412920634} | train loss {'Reaction outcome loss': 0.4963670791560393, 'Total loss': 0.4963670791560393}
2023-01-05 07:34:11,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:34:11,216 INFO:     Epoch: 10
2023-01-05 07:34:13,355 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.500846932331721, 'Total loss': 0.500846932331721} | train loss {'Reaction outcome loss': 0.4728653218219246, 'Total loss': 0.4728653218219246}
2023-01-05 07:34:13,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:34:13,356 INFO:     Epoch: 11
2023-01-05 07:34:15,510 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.46772425770759585, 'Total loss': 0.46772425770759585} | train loss {'Reaction outcome loss': 0.4717250044433994, 'Total loss': 0.4717250044433994}
2023-01-05 07:34:15,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:34:15,510 INFO:     Epoch: 12
2023-01-05 07:34:17,662 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46712769865989684, 'Total loss': 0.46712769865989684} | train loss {'Reaction outcome loss': 0.4651732252975268, 'Total loss': 0.4651732252975268}
2023-01-05 07:34:17,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:34:17,663 INFO:     Epoch: 13
2023-01-05 07:34:19,833 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4406059056520462, 'Total loss': 0.4406059056520462} | train loss {'Reaction outcome loss': 0.4631789010288059, 'Total loss': 0.4631789010288059}
2023-01-05 07:34:19,833 INFO:     Found new best model at epoch 13
2023-01-05 07:34:19,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:34:19,834 INFO:     Epoch: 14
2023-01-05 07:34:21,979 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.514384001493454, 'Total loss': 0.514384001493454} | train loss {'Reaction outcome loss': 0.4635031623765826, 'Total loss': 0.4635031623765826}
2023-01-05 07:34:21,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:34:21,980 INFO:     Epoch: 15
2023-01-05 07:34:24,120 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.46592134833335874, 'Total loss': 0.46592134833335874} | train loss {'Reaction outcome loss': 0.4465408600315087, 'Total loss': 0.4465408600315087}
2023-01-05 07:34:24,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:34:24,121 INFO:     Epoch: 16
2023-01-05 07:34:26,274 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44806660413742067, 'Total loss': 0.44806660413742067} | train loss {'Reaction outcome loss': 0.4478949251469981, 'Total loss': 0.4478949251469981}
2023-01-05 07:34:26,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:34:26,274 INFO:     Epoch: 17
2023-01-05 07:34:28,428 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4746507426102956, 'Total loss': 0.4746507426102956} | train loss {'Reaction outcome loss': 0.44101816527477966, 'Total loss': 0.44101816527477966}
2023-01-05 07:34:28,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:34:28,428 INFO:     Epoch: 18
2023-01-05 07:34:30,561 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4556107044219971, 'Total loss': 0.4556107044219971} | train loss {'Reaction outcome loss': 0.43931911216418484, 'Total loss': 0.43931911216418484}
2023-01-05 07:34:30,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:34:30,562 INFO:     Epoch: 19
2023-01-05 07:34:32,718 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44550219575564065, 'Total loss': 0.44550219575564065} | train loss {'Reaction outcome loss': 0.4324574323142862, 'Total loss': 0.4324574323142862}
2023-01-05 07:34:32,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:34:32,718 INFO:     Epoch: 20
2023-01-05 07:34:34,880 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.46476165652275087, 'Total loss': 0.46476165652275087} | train loss {'Reaction outcome loss': 0.42991250714260165, 'Total loss': 0.42991250714260165}
2023-01-05 07:34:34,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:34:34,880 INFO:     Epoch: 21
2023-01-05 07:34:37,034 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47073253194491066, 'Total loss': 0.47073253194491066} | train loss {'Reaction outcome loss': 0.42877044377551565, 'Total loss': 0.42877044377551565}
2023-01-05 07:34:37,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:34:37,035 INFO:     Epoch: 22
2023-01-05 07:34:39,185 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44331961969534556, 'Total loss': 0.44331961969534556} | train loss {'Reaction outcome loss': 0.4253388946214556, 'Total loss': 0.4253388946214556}
2023-01-05 07:34:39,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:34:39,186 INFO:     Epoch: 23
2023-01-05 07:34:41,337 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.47325834035873415, 'Total loss': 0.47325834035873415} | train loss {'Reaction outcome loss': 0.4197708323624903, 'Total loss': 0.4197708323624903}
2023-01-05 07:34:41,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:34:41,337 INFO:     Epoch: 24
2023-01-05 07:34:43,535 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4599123805761337, 'Total loss': 0.4599123805761337} | train loss {'Reaction outcome loss': 0.41622944757261354, 'Total loss': 0.41622944757261354}
2023-01-05 07:34:43,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:34:43,535 INFO:     Epoch: 25
2023-01-05 07:34:45,687 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44526549776395163, 'Total loss': 0.44526549776395163} | train loss {'Reaction outcome loss': 0.4137617415289624, 'Total loss': 0.4137617415289624}
2023-01-05 07:34:45,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:34:45,688 INFO:     Epoch: 26
2023-01-05 07:34:47,840 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.43697288632392883, 'Total loss': 0.43697288632392883} | train loss {'Reaction outcome loss': 0.4048518809461224, 'Total loss': 0.4048518809461224}
2023-01-05 07:34:47,841 INFO:     Found new best model at epoch 26
2023-01-05 07:34:47,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:34:47,842 INFO:     Epoch: 27
2023-01-05 07:34:49,988 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.48794788916905724, 'Total loss': 0.48794788916905724} | train loss {'Reaction outcome loss': 0.4085896315889946, 'Total loss': 0.4085896315889946}
2023-01-05 07:34:49,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:34:49,988 INFO:     Epoch: 28
2023-01-05 07:34:52,138 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46113859713077543, 'Total loss': 0.46113859713077543} | train loss {'Reaction outcome loss': 0.4137689103172504, 'Total loss': 0.4137689103172504}
2023-01-05 07:34:52,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:34:52,139 INFO:     Epoch: 29
2023-01-05 07:34:54,281 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.42453085680802666, 'Total loss': 0.42453085680802666} | train loss {'Reaction outcome loss': 0.3952599348689335, 'Total loss': 0.3952599348689335}
2023-01-05 07:34:54,282 INFO:     Found new best model at epoch 29
2023-01-05 07:34:54,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:34:54,283 INFO:     Epoch: 30
2023-01-05 07:34:56,430 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43773815731207527, 'Total loss': 0.43773815731207527} | train loss {'Reaction outcome loss': 0.404707101052222, 'Total loss': 0.404707101052222}
2023-01-05 07:34:56,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:34:56,430 INFO:     Epoch: 31
2023-01-05 07:34:58,574 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4247385491927465, 'Total loss': 0.4247385491927465} | train loss {'Reaction outcome loss': 0.4169382797107033, 'Total loss': 0.4169382797107033}
2023-01-05 07:34:58,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:34:58,574 INFO:     Epoch: 32
2023-01-05 07:35:00,730 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4195960909128189, 'Total loss': 0.4195960909128189} | train loss {'Reaction outcome loss': 0.3835427741945276, 'Total loss': 0.3835427741945276}
2023-01-05 07:35:00,730 INFO:     Found new best model at epoch 32
2023-01-05 07:35:00,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:35:00,732 INFO:     Epoch: 33
2023-01-05 07:35:02,876 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4433194359143575, 'Total loss': 0.4433194359143575} | train loss {'Reaction outcome loss': 0.3779937231396932, 'Total loss': 0.3779937231396932}
2023-01-05 07:35:02,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:35:02,877 INFO:     Epoch: 34
2023-01-05 07:35:05,022 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4229067107041677, 'Total loss': 0.4229067107041677} | train loss {'Reaction outcome loss': 0.3748310968913374, 'Total loss': 0.3748310968913374}
2023-01-05 07:35:05,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:35:05,023 INFO:     Epoch: 35
2023-01-05 07:35:07,203 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.43324891328811643, 'Total loss': 0.43324891328811643} | train loss {'Reaction outcome loss': 0.3764277898261081, 'Total loss': 0.3764277898261081}
2023-01-05 07:35:07,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:35:07,204 INFO:     Epoch: 36
2023-01-05 07:35:09,353 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42463784391681353, 'Total loss': 0.42463784391681353} | train loss {'Reaction outcome loss': 0.3727186163853638, 'Total loss': 0.3727186163853638}
2023-01-05 07:35:09,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:35:09,353 INFO:     Epoch: 37
2023-01-05 07:35:11,497 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4441785395145416, 'Total loss': 0.4441785395145416} | train loss {'Reaction outcome loss': 0.36483477182902285, 'Total loss': 0.36483477182902285}
2023-01-05 07:35:11,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:35:11,497 INFO:     Epoch: 38
2023-01-05 07:35:13,652 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4043658185750246, 'Total loss': 0.4043658185750246} | train loss {'Reaction outcome loss': 0.35778158112684055, 'Total loss': 0.35778158112684055}
2023-01-05 07:35:13,652 INFO:     Found new best model at epoch 38
2023-01-05 07:35:13,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:35:13,653 INFO:     Epoch: 39
2023-01-05 07:35:15,792 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42320029536883036, 'Total loss': 0.42320029536883036} | train loss {'Reaction outcome loss': 0.3566798926318449, 'Total loss': 0.3566798926318449}
2023-01-05 07:35:15,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:35:15,793 INFO:     Epoch: 40
2023-01-05 07:35:17,963 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4044552942117055, 'Total loss': 0.4044552942117055} | train loss {'Reaction outcome loss': 0.3602047477295433, 'Total loss': 0.3602047477295433}
2023-01-05 07:35:17,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:35:17,963 INFO:     Epoch: 41
2023-01-05 07:35:20,126 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3972351372241974, 'Total loss': 0.3972351372241974} | train loss {'Reaction outcome loss': 0.3613439871258089, 'Total loss': 0.3613439871258089}
2023-01-05 07:35:20,126 INFO:     Found new best model at epoch 41
2023-01-05 07:35:20,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:35:20,128 INFO:     Epoch: 42
2023-01-05 07:35:22,299 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.453955007592837, 'Total loss': 0.453955007592837} | train loss {'Reaction outcome loss': 0.3431980032343046, 'Total loss': 0.3431980032343046}
2023-01-05 07:35:22,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:35:22,299 INFO:     Epoch: 43
2023-01-05 07:35:24,446 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.38340001155932746, 'Total loss': 0.38340001155932746} | train loss {'Reaction outcome loss': 0.3417741438391639, 'Total loss': 0.3417741438391639}
2023-01-05 07:35:24,447 INFO:     Found new best model at epoch 43
2023-01-05 07:35:24,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:35:24,448 INFO:     Epoch: 44
2023-01-05 07:35:26,628 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4587490032116572, 'Total loss': 0.4587490032116572} | train loss {'Reaction outcome loss': 0.3522236814749414, 'Total loss': 0.3522236814749414}
2023-01-05 07:35:26,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:35:26,628 INFO:     Epoch: 45
2023-01-05 07:35:28,781 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46182407637437184, 'Total loss': 0.46182407637437184} | train loss {'Reaction outcome loss': 0.4074580781701682, 'Total loss': 0.4074580781701682}
2023-01-05 07:35:28,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:35:28,781 INFO:     Epoch: 46
2023-01-05 07:35:30,953 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.40540865858395897, 'Total loss': 0.40540865858395897} | train loss {'Reaction outcome loss': 0.3776513977650936, 'Total loss': 0.3776513977650936}
2023-01-05 07:35:30,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:35:30,954 INFO:     Epoch: 47
2023-01-05 07:35:33,128 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39908241033554076, 'Total loss': 0.39908241033554076} | train loss {'Reaction outcome loss': 0.3409173064392762, 'Total loss': 0.3409173064392762}
2023-01-05 07:35:33,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:35:33,128 INFO:     Epoch: 48
2023-01-05 07:35:35,292 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40015840033690137, 'Total loss': 0.40015840033690137} | train loss {'Reaction outcome loss': 0.3277216258465542, 'Total loss': 0.3277216258465542}
2023-01-05 07:35:35,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:35:35,292 INFO:     Epoch: 49
2023-01-05 07:35:37,501 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.40631825228532154, 'Total loss': 0.40631825228532154} | train loss {'Reaction outcome loss': 0.33092068391599005, 'Total loss': 0.33092068391599005}
2023-01-05 07:35:37,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:35:37,501 INFO:     Epoch: 50
2023-01-05 07:35:39,686 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4005660672982534, 'Total loss': 0.4005660672982534} | train loss {'Reaction outcome loss': 0.3215882030403723, 'Total loss': 0.3215882030403723}
2023-01-05 07:35:39,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:35:39,686 INFO:     Epoch: 51
2023-01-05 07:35:41,861 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.42291839023431144, 'Total loss': 0.42291839023431144} | train loss {'Reaction outcome loss': 0.3133368605445814, 'Total loss': 0.3133368605445814}
2023-01-05 07:35:41,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:35:41,862 INFO:     Epoch: 52
2023-01-05 07:35:44,030 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4051966061194738, 'Total loss': 0.4051966061194738} | train loss {'Reaction outcome loss': 0.31940134636301926, 'Total loss': 0.31940134636301926}
2023-01-05 07:35:44,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:35:44,031 INFO:     Epoch: 53
2023-01-05 07:35:46,198 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39392697215080263, 'Total loss': 0.39392697215080263} | train loss {'Reaction outcome loss': 0.33890185302756387, 'Total loss': 0.33890185302756387}
2023-01-05 07:35:46,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:35:46,199 INFO:     Epoch: 54
2023-01-05 07:35:48,354 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.38724021514256796, 'Total loss': 0.38724021514256796} | train loss {'Reaction outcome loss': 0.3276474301406331, 'Total loss': 0.3276474301406331}
2023-01-05 07:35:48,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:35:48,354 INFO:     Epoch: 55
2023-01-05 07:35:50,508 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.38900853792826334, 'Total loss': 0.38900853792826334} | train loss {'Reaction outcome loss': 0.31999864083026414, 'Total loss': 0.31999864083026414}
2023-01-05 07:35:50,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:35:50,509 INFO:     Epoch: 56
2023-01-05 07:35:52,723 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43348204493522646, 'Total loss': 0.43348204493522646} | train loss {'Reaction outcome loss': 0.3088785815660072, 'Total loss': 0.3088785815660072}
2023-01-05 07:35:52,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:35:52,723 INFO:     Epoch: 57
2023-01-05 07:35:54,949 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.42109387516975405, 'Total loss': 0.42109387516975405} | train loss {'Reaction outcome loss': 0.3313105439402811, 'Total loss': 0.3313105439402811}
2023-01-05 07:35:54,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:35:54,951 INFO:     Epoch: 58
2023-01-05 07:35:57,163 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.37440351049105325, 'Total loss': 0.37440351049105325} | train loss {'Reaction outcome loss': 0.3123014809798274, 'Total loss': 0.3123014809798274}
2023-01-05 07:35:57,163 INFO:     Found new best model at epoch 58
2023-01-05 07:35:57,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:35:57,165 INFO:     Epoch: 59
2023-01-05 07:35:59,370 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.40337915619214376, 'Total loss': 0.40337915619214376} | train loss {'Reaction outcome loss': 0.305994758490419, 'Total loss': 0.305994758490419}
2023-01-05 07:35:59,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:35:59,370 INFO:     Epoch: 60
2023-01-05 07:36:01,526 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40694979031880696, 'Total loss': 0.40694979031880696} | train loss {'Reaction outcome loss': 0.30433308002471493, 'Total loss': 0.30433308002471493}
2023-01-05 07:36:01,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:36:01,527 INFO:     Epoch: 61
2023-01-05 07:36:03,659 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.39528459707895913, 'Total loss': 0.39528459707895913} | train loss {'Reaction outcome loss': 0.3050081878360631, 'Total loss': 0.3050081878360631}
2023-01-05 07:36:03,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:36:03,659 INFO:     Epoch: 62
2023-01-05 07:36:05,828 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.398513662815094, 'Total loss': 0.398513662815094} | train loss {'Reaction outcome loss': 0.2980533062034975, 'Total loss': 0.2980533062034975}
2023-01-05 07:36:05,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:36:05,829 INFO:     Epoch: 63
2023-01-05 07:36:08,007 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4045478830734889, 'Total loss': 0.4045478830734889} | train loss {'Reaction outcome loss': 0.2944032146419952, 'Total loss': 0.2944032146419952}
2023-01-05 07:36:08,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:36:08,007 INFO:     Epoch: 64
2023-01-05 07:36:10,174 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.379764154056708, 'Total loss': 0.379764154056708} | train loss {'Reaction outcome loss': 0.296971842978973, 'Total loss': 0.296971842978973}
2023-01-05 07:36:10,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:36:10,174 INFO:     Epoch: 65
2023-01-05 07:36:12,340 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3870731075604757, 'Total loss': 0.3870731075604757} | train loss {'Reaction outcome loss': 0.28819236033266044, 'Total loss': 0.28819236033266044}
2023-01-05 07:36:12,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:36:12,341 INFO:     Epoch: 66
2023-01-05 07:36:14,502 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.364262913664182, 'Total loss': 0.364262913664182} | train loss {'Reaction outcome loss': 0.29087790793256724, 'Total loss': 0.29087790793256724}
2023-01-05 07:36:14,503 INFO:     Found new best model at epoch 66
2023-01-05 07:36:14,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:36:14,504 INFO:     Epoch: 67
2023-01-05 07:36:16,676 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3707326506574949, 'Total loss': 0.3707326506574949} | train loss {'Reaction outcome loss': 0.2886079122089659, 'Total loss': 0.2886079122089659}
2023-01-05 07:36:16,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:36:16,677 INFO:     Epoch: 68
2023-01-05 07:36:18,859 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40369562307993573, 'Total loss': 0.40369562307993573} | train loss {'Reaction outcome loss': 0.29867833399254345, 'Total loss': 0.29867833399254345}
2023-01-05 07:36:18,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:36:18,859 INFO:     Epoch: 69
2023-01-05 07:36:21,027 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.39726505676905316, 'Total loss': 0.39726505676905316} | train loss {'Reaction outcome loss': 0.2937535705594042, 'Total loss': 0.2937535705594042}
2023-01-05 07:36:21,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:36:21,030 INFO:     Epoch: 70
2023-01-05 07:36:23,203 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.38140554825464884, 'Total loss': 0.38140554825464884} | train loss {'Reaction outcome loss': 0.28414885786469973, 'Total loss': 0.28414885786469973}
2023-01-05 07:36:23,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:36:23,203 INFO:     Epoch: 71
2023-01-05 07:36:25,164 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4147737006346385, 'Total loss': 0.4147737006346385} | train loss {'Reaction outcome loss': 0.28780607725291146, 'Total loss': 0.28780607725291146}
2023-01-05 07:36:25,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:36:25,165 INFO:     Epoch: 72
2023-01-05 07:36:27,347 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.38995610425869626, 'Total loss': 0.38995610425869626} | train loss {'Reaction outcome loss': 0.27677485248537065, 'Total loss': 0.27677485248537065}
2023-01-05 07:36:27,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:36:27,347 INFO:     Epoch: 73
2023-01-05 07:36:29,526 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39744253555933634, 'Total loss': 0.39744253555933634} | train loss {'Reaction outcome loss': 0.28313709446503205, 'Total loss': 0.28313709446503205}
2023-01-05 07:36:29,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:36:29,526 INFO:     Epoch: 74
2023-01-05 07:36:31,714 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4648226271073023, 'Total loss': 0.4648226271073023} | train loss {'Reaction outcome loss': 0.29097501465213904, 'Total loss': 0.29097501465213904}
2023-01-05 07:36:31,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:36:31,715 INFO:     Epoch: 75
2023-01-05 07:36:33,891 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.38648609519004823, 'Total loss': 0.38648609519004823} | train loss {'Reaction outcome loss': 0.36085073336004786, 'Total loss': 0.36085073336004786}
2023-01-05 07:36:33,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:36:33,891 INFO:     Epoch: 76
2023-01-05 07:36:36,053 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.36860673129558563, 'Total loss': 0.36860673129558563} | train loss {'Reaction outcome loss': 0.2743799573458407, 'Total loss': 0.2743799573458407}
2023-01-05 07:36:36,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:36:36,053 INFO:     Epoch: 77
2023-01-05 07:36:38,194 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.377631651610136, 'Total loss': 0.377631651610136} | train loss {'Reaction outcome loss': 0.27213121153687575, 'Total loss': 0.27213121153687575}
2023-01-05 07:36:38,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:36:38,194 INFO:     Epoch: 78
2023-01-05 07:36:40,379 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40509479741255444, 'Total loss': 0.40509479741255444} | train loss {'Reaction outcome loss': 0.26469320119244716, 'Total loss': 0.26469320119244716}
2023-01-05 07:36:40,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:36:40,379 INFO:     Epoch: 79
2023-01-05 07:36:42,553 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3767438977956772, 'Total loss': 0.3767438977956772} | train loss {'Reaction outcome loss': 0.28222079793741234, 'Total loss': 0.28222079793741234}
2023-01-05 07:36:42,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:36:42,554 INFO:     Epoch: 80
2023-01-05 07:36:44,733 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3870976731181145, 'Total loss': 0.3870976731181145} | train loss {'Reaction outcome loss': 0.2657395588013468, 'Total loss': 0.2657395588013468}
2023-01-05 07:36:44,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:36:44,734 INFO:     Epoch: 81
2023-01-05 07:36:46,900 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4327543169260025, 'Total loss': 0.4327543169260025} | train loss {'Reaction outcome loss': 0.2598343912977725, 'Total loss': 0.2598343912977725}
2023-01-05 07:36:46,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:36:46,900 INFO:     Epoch: 82
2023-01-05 07:36:49,071 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.37921499013900756, 'Total loss': 0.37921499013900756} | train loss {'Reaction outcome loss': 0.26563332426746417, 'Total loss': 0.26563332426746417}
2023-01-05 07:36:49,071 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:36:49,071 INFO:     Epoch: 83
2023-01-05 07:36:51,263 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.38437001009782157, 'Total loss': 0.38437001009782157} | train loss {'Reaction outcome loss': 0.2661190673142024, 'Total loss': 0.2661190673142024}
2023-01-05 07:36:51,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:36:51,263 INFO:     Epoch: 84
2023-01-05 07:36:53,454 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.45356714228789013, 'Total loss': 0.45356714228789013} | train loss {'Reaction outcome loss': 0.2572699937820975, 'Total loss': 0.2572699937820975}
2023-01-05 07:36:53,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:36:53,454 INFO:     Epoch: 85
2023-01-05 07:36:55,632 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46459079086780547, 'Total loss': 0.46459079086780547} | train loss {'Reaction outcome loss': 0.2816662525064832, 'Total loss': 0.2816662525064832}
2023-01-05 07:36:55,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:36:55,633 INFO:     Epoch: 86
2023-01-05 07:36:57,784 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.39463139573733014, 'Total loss': 0.39463139573733014} | train loss {'Reaction outcome loss': 0.2606701672050184, 'Total loss': 0.2606701672050184}
2023-01-05 07:36:57,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:36:57,784 INFO:     Epoch: 87
2023-01-05 07:36:59,952 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41834700604279834, 'Total loss': 0.41834700604279834} | train loss {'Reaction outcome loss': 0.25571735344693886, 'Total loss': 0.25571735344693886}
2023-01-05 07:36:59,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:36:59,952 INFO:     Epoch: 88
2023-01-05 07:37:02,110 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.37850780685742696, 'Total loss': 0.37850780685742696} | train loss {'Reaction outcome loss': 0.2520827730033383, 'Total loss': 0.2520827730033383}
2023-01-05 07:37:02,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:37:02,111 INFO:     Epoch: 89
2023-01-05 07:37:04,290 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39523620704809825, 'Total loss': 0.39523620704809825} | train loss {'Reaction outcome loss': 0.2608868069870843, 'Total loss': 0.2608868069870843}
2023-01-05 07:37:04,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:37:04,290 INFO:     Epoch: 90
2023-01-05 07:37:06,481 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41824780603249867, 'Total loss': 0.41824780603249867} | train loss {'Reaction outcome loss': 0.25112304803147656, 'Total loss': 0.25112304803147656}
2023-01-05 07:37:06,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:37:06,481 INFO:     Epoch: 91
2023-01-05 07:37:08,660 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41521440744400023, 'Total loss': 0.41521440744400023} | train loss {'Reaction outcome loss': 0.2542244921602052, 'Total loss': 0.2542244921602052}
2023-01-05 07:37:08,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:37:08,660 INFO:     Epoch: 92
2023-01-05 07:37:10,822 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4199919005235036, 'Total loss': 0.4199919005235036} | train loss {'Reaction outcome loss': 0.2558393241749887, 'Total loss': 0.2558393241749887}
2023-01-05 07:37:10,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:37:10,822 INFO:     Epoch: 93
2023-01-05 07:37:12,985 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39801936149597167, 'Total loss': 0.39801936149597167} | train loss {'Reaction outcome loss': 0.28598507319617533, 'Total loss': 0.28598507319617533}
2023-01-05 07:37:12,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:37:12,986 INFO:     Epoch: 94
2023-01-05 07:37:15,166 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4196754107872645, 'Total loss': 0.4196754107872645} | train loss {'Reaction outcome loss': 0.2920177616297092, 'Total loss': 0.2920177616297092}
2023-01-05 07:37:15,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:37:15,167 INFO:     Epoch: 95
2023-01-05 07:37:17,353 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.39701879819234215, 'Total loss': 0.39701879819234215} | train loss {'Reaction outcome loss': 0.2632236894037899, 'Total loss': 0.2632236894037899}
2023-01-05 07:37:17,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:37:17,353 INFO:     Epoch: 96
2023-01-05 07:37:19,527 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4209115063150724, 'Total loss': 0.4209115063150724} | train loss {'Reaction outcome loss': 0.25049309296519967, 'Total loss': 0.25049309296519967}
2023-01-05 07:37:19,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:37:19,527 INFO:     Epoch: 97
2023-01-05 07:37:21,685 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41502256095409396, 'Total loss': 0.41502256095409396} | train loss {'Reaction outcome loss': 0.2511250631296602, 'Total loss': 0.2511250631296602}
2023-01-05 07:37:21,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:37:21,685 INFO:     Epoch: 98
2023-01-05 07:37:23,850 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4017930060625076, 'Total loss': 0.4017930060625076} | train loss {'Reaction outcome loss': 0.2579895142816763, 'Total loss': 0.2579895142816763}
2023-01-05 07:37:23,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:37:23,850 INFO:     Epoch: 99
2023-01-05 07:37:26,002 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4249906981984774, 'Total loss': 0.4249906981984774} | train loss {'Reaction outcome loss': 0.28517941857917584, 'Total loss': 0.28517941857917584}
2023-01-05 07:37:26,002 INFO:     Best model found after epoch 67 of 100.
2023-01-05 07:37:26,002 INFO:   Done with stage: TRAINING
2023-01-05 07:37:26,002 INFO:   Starting stage: EVALUATION
2023-01-05 07:37:26,133 INFO:   Done with stage: EVALUATION
2023-01-05 07:37:26,133 INFO:   Leaving out SEQ value Fold_9
2023-01-05 07:37:26,146 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 07:37:26,146 INFO:   Starting stage: FEATURE SCALING
2023-01-05 07:37:26,805 INFO:   Done with stage: FEATURE SCALING
2023-01-05 07:37:26,805 INFO:   Starting stage: SCALING TARGETS
2023-01-05 07:37:26,875 INFO:   Done with stage: SCALING TARGETS
2023-01-05 07:37:26,875 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:37:26,875 INFO:     No hyperparam tuning for this model
2023-01-05 07:37:26,875 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:37:26,875 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 07:37:26,876 INFO:     None feature selector for col prot
2023-01-05 07:37:26,876 INFO:     None feature selector for col prot
2023-01-05 07:37:26,876 INFO:     None feature selector for col prot
2023-01-05 07:37:26,877 INFO:     None feature selector for col chem
2023-01-05 07:37:26,877 INFO:     None feature selector for col chem
2023-01-05 07:37:26,877 INFO:     None feature selector for col chem
2023-01-05 07:37:26,877 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 07:37:26,877 INFO:   Starting stage: BUILD MODEL
2023-01-05 07:37:26,878 INFO:     Number of params in model 72901
2023-01-05 07:37:26,882 INFO:   Done with stage: BUILD MODEL
2023-01-05 07:37:26,882 INFO:   Starting stage: TRAINING
2023-01-05 07:37:26,940 INFO:     Val loss before train {'Reaction outcome loss': 1.0499772667884826, 'Total loss': 1.0499772667884826}
2023-01-05 07:37:26,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:37:26,941 INFO:     Epoch: 0
2023-01-05 07:37:29,112 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8685179591178894, 'Total loss': 0.8685179591178894} | train loss {'Reaction outcome loss': 0.9379917266576187, 'Total loss': 0.9379917266576187}
2023-01-05 07:37:29,112 INFO:     Found new best model at epoch 0
2023-01-05 07:37:29,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:37:29,113 INFO:     Epoch: 1
2023-01-05 07:37:31,297 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.674298220872879, 'Total loss': 0.674298220872879} | train loss {'Reaction outcome loss': 0.7767621298199114, 'Total loss': 0.7767621298199114}
2023-01-05 07:37:31,298 INFO:     Found new best model at epoch 1
2023-01-05 07:37:31,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:37:31,299 INFO:     Epoch: 2
2023-01-05 07:37:33,466 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.571075979868571, 'Total loss': 0.571075979868571} | train loss {'Reaction outcome loss': 0.6139118690651072, 'Total loss': 0.6139118690651072}
2023-01-05 07:37:33,467 INFO:     Found new best model at epoch 2
2023-01-05 07:37:33,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:37:33,468 INFO:     Epoch: 3
2023-01-05 07:37:35,623 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5364458978176116, 'Total loss': 0.5364458978176116} | train loss {'Reaction outcome loss': 0.5515405802845793, 'Total loss': 0.5515405802845793}
2023-01-05 07:37:35,624 INFO:     Found new best model at epoch 3
2023-01-05 07:37:35,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:37:35,625 INFO:     Epoch: 4
2023-01-05 07:37:37,828 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5519447068373362, 'Total loss': 0.5519447068373362} | train loss {'Reaction outcome loss': 0.5213057517202274, 'Total loss': 0.5213057517202274}
2023-01-05 07:37:37,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:37:37,829 INFO:     Epoch: 5
2023-01-05 07:37:39,986 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5550187249978383, 'Total loss': 0.5550187249978383} | train loss {'Reaction outcome loss': 0.52770511560358, 'Total loss': 0.52770511560358}
2023-01-05 07:37:39,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:37:39,986 INFO:     Epoch: 6
2023-01-05 07:37:42,163 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5040345191955566, 'Total loss': 0.5040345191955566} | train loss {'Reaction outcome loss': 0.49292154718136444, 'Total loss': 0.49292154718136444}
2023-01-05 07:37:42,164 INFO:     Found new best model at epoch 6
2023-01-05 07:37:42,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:37:42,165 INFO:     Epoch: 7
2023-01-05 07:37:44,323 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.518417086203893, 'Total loss': 0.518417086203893} | train loss {'Reaction outcome loss': 0.48434112242598465, 'Total loss': 0.48434112242598465}
2023-01-05 07:37:44,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:37:44,323 INFO:     Epoch: 8
2023-01-05 07:37:46,466 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5247478206952413, 'Total loss': 0.5247478206952413} | train loss {'Reaction outcome loss': 0.4806465202169763, 'Total loss': 0.4806465202169763}
2023-01-05 07:37:46,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:37:46,466 INFO:     Epoch: 9
2023-01-05 07:37:48,632 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5023452232281367, 'Total loss': 0.5023452232281367} | train loss {'Reaction outcome loss': 0.47486620018447656, 'Total loss': 0.47486620018447656}
2023-01-05 07:37:48,632 INFO:     Found new best model at epoch 9
2023-01-05 07:37:48,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:37:48,633 INFO:     Epoch: 10
2023-01-05 07:37:50,789 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5064246972401937, 'Total loss': 0.5064246972401937} | train loss {'Reaction outcome loss': 0.4900076103437206, 'Total loss': 0.4900076103437206}
2023-01-05 07:37:50,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:37:50,790 INFO:     Epoch: 11
2023-01-05 07:37:52,951 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4981480280558268, 'Total loss': 0.4981480280558268} | train loss {'Reaction outcome loss': 0.4647653717412681, 'Total loss': 0.4647653717412681}
2023-01-05 07:37:52,951 INFO:     Found new best model at epoch 11
2023-01-05 07:37:52,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:37:52,952 INFO:     Epoch: 12
2023-01-05 07:37:55,186 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5155759374300639, 'Total loss': 0.5155759374300639} | train loss {'Reaction outcome loss': 0.4561975097319152, 'Total loss': 0.4561975097319152}
2023-01-05 07:37:55,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:37:55,186 INFO:     Epoch: 13
2023-01-05 07:37:57,391 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4935744971036911, 'Total loss': 0.4935744971036911} | train loss {'Reaction outcome loss': 0.4518225254099546, 'Total loss': 0.4518225254099546}
2023-01-05 07:37:57,391 INFO:     Found new best model at epoch 13
2023-01-05 07:37:57,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:37:57,393 INFO:     Epoch: 14
2023-01-05 07:37:59,547 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5150158047676087, 'Total loss': 0.5150158047676087} | train loss {'Reaction outcome loss': 0.45175341279178427, 'Total loss': 0.45175341279178427}
2023-01-05 07:37:59,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:37:59,548 INFO:     Epoch: 15
2023-01-05 07:38:01,714 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4955465137958527, 'Total loss': 0.4955465137958527} | train loss {'Reaction outcome loss': 0.461396057094174, 'Total loss': 0.461396057094174}
2023-01-05 07:38:01,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:38:01,714 INFO:     Epoch: 16
2023-01-05 07:38:03,888 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48636051813761394, 'Total loss': 0.48636051813761394} | train loss {'Reaction outcome loss': 0.44234545850127505, 'Total loss': 0.44234545850127505}
2023-01-05 07:38:03,888 INFO:     Found new best model at epoch 16
2023-01-05 07:38:03,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:38:03,890 INFO:     Epoch: 17
2023-01-05 07:38:06,072 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5046227663755417, 'Total loss': 0.5046227663755417} | train loss {'Reaction outcome loss': 0.43677592608213855, 'Total loss': 0.43677592608213855}
2023-01-05 07:38:06,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:38:06,072 INFO:     Epoch: 18
2023-01-05 07:38:08,234 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5401759684085846, 'Total loss': 0.5401759684085846} | train loss {'Reaction outcome loss': 0.42798081280636613, 'Total loss': 0.42798081280636613}
2023-01-05 07:38:08,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:38:08,235 INFO:     Epoch: 19
2023-01-05 07:38:10,395 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5010376632213592, 'Total loss': 0.5010376632213592} | train loss {'Reaction outcome loss': 0.4264339209885161, 'Total loss': 0.4264339209885161}
2023-01-05 07:38:10,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:38:10,395 INFO:     Epoch: 20
2023-01-05 07:38:12,574 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.49461177984873456, 'Total loss': 0.49461177984873456} | train loss {'Reaction outcome loss': 0.4222651916299609, 'Total loss': 0.4222651916299609}
2023-01-05 07:38:12,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:38:12,574 INFO:     Epoch: 21
2023-01-05 07:38:14,750 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.49165934522946675, 'Total loss': 0.49165934522946675} | train loss {'Reaction outcome loss': 0.417455964775729, 'Total loss': 0.417455964775729}
2023-01-05 07:38:14,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:38:14,750 INFO:     Epoch: 22
2023-01-05 07:38:16,928 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.49061193068822223, 'Total loss': 0.49061193068822223} | train loss {'Reaction outcome loss': 0.4168345123745393, 'Total loss': 0.4168345123745393}
2023-01-05 07:38:16,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:38:16,929 INFO:     Epoch: 23
2023-01-05 07:38:19,103 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5162436445554097, 'Total loss': 0.5162436445554097} | train loss {'Reaction outcome loss': 0.4220863307245832, 'Total loss': 0.4220863307245832}
2023-01-05 07:38:19,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:38:19,103 INFO:     Epoch: 24
2023-01-05 07:38:21,247 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46490141650040945, 'Total loss': 0.46490141650040945} | train loss {'Reaction outcome loss': 0.4414799147406998, 'Total loss': 0.4414799147406998}
2023-01-05 07:38:21,247 INFO:     Found new best model at epoch 24
2023-01-05 07:38:21,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:38:21,248 INFO:     Epoch: 25
2023-01-05 07:38:23,441 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5287531872590383, 'Total loss': 0.5287531872590383} | train loss {'Reaction outcome loss': 0.4106550536219046, 'Total loss': 0.4106550536219046}
2023-01-05 07:38:23,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:38:23,442 INFO:     Epoch: 26
2023-01-05 07:38:25,605 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4974938631057739, 'Total loss': 0.4974938631057739} | train loss {'Reaction outcome loss': 0.39898833162463404, 'Total loss': 0.39898833162463404}
2023-01-05 07:38:25,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:38:25,605 INFO:     Epoch: 27
2023-01-05 07:38:27,775 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4778549551963806, 'Total loss': 0.4778549551963806} | train loss {'Reaction outcome loss': 0.39979652718107717, 'Total loss': 0.39979652718107717}
2023-01-05 07:38:27,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:38:27,776 INFO:     Epoch: 28
2023-01-05 07:38:29,944 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4898315370082855, 'Total loss': 0.4898315370082855} | train loss {'Reaction outcome loss': 0.39578662338275195, 'Total loss': 0.39578662338275195}
2023-01-05 07:38:29,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:38:29,945 INFO:     Epoch: 29
2023-01-05 07:38:32,105 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46257264812787374, 'Total loss': 0.46257264812787374} | train loss {'Reaction outcome loss': 0.3905701806788343, 'Total loss': 0.3905701806788343}
2023-01-05 07:38:32,105 INFO:     Found new best model at epoch 29
2023-01-05 07:38:32,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:38:32,107 INFO:     Epoch: 30
2023-01-05 07:38:34,275 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4802158196767171, 'Total loss': 0.4802158196767171} | train loss {'Reaction outcome loss': 0.3882775587699143, 'Total loss': 0.3882775587699143}
2023-01-05 07:38:34,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:38:34,275 INFO:     Epoch: 31
2023-01-05 07:38:36,454 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.48242674668629965, 'Total loss': 0.48242674668629965} | train loss {'Reaction outcome loss': 0.38517980788415973, 'Total loss': 0.38517980788415973}
2023-01-05 07:38:36,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:38:36,454 INFO:     Epoch: 32
2023-01-05 07:38:38,620 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46475165088971454, 'Total loss': 0.46475165088971454} | train loss {'Reaction outcome loss': 0.3857022327526162, 'Total loss': 0.3857022327526162}
2023-01-05 07:38:38,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:38:38,621 INFO:     Epoch: 33
2023-01-05 07:38:40,798 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4980970730384191, 'Total loss': 0.4980970730384191} | train loss {'Reaction outcome loss': 0.38193901184190443, 'Total loss': 0.38193901184190443}
2023-01-05 07:38:40,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:38:40,798 INFO:     Epoch: 34
2023-01-05 07:38:42,963 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4922583490610123, 'Total loss': 0.4922583490610123} | train loss {'Reaction outcome loss': 0.38762964734780614, 'Total loss': 0.38762964734780614}
2023-01-05 07:38:42,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:38:42,963 INFO:     Epoch: 35
2023-01-05 07:38:45,125 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4736836353937785, 'Total loss': 0.4736836353937785} | train loss {'Reaction outcome loss': 0.37104549912560353, 'Total loss': 0.37104549912560353}
2023-01-05 07:38:45,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:38:45,126 INFO:     Epoch: 36
2023-01-05 07:38:47,351 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.48362075686454775, 'Total loss': 0.48362075686454775} | train loss {'Reaction outcome loss': 0.3717502316551121, 'Total loss': 0.3717502316551121}
2023-01-05 07:38:47,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:38:47,352 INFO:     Epoch: 37
2023-01-05 07:38:49,550 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5010790427525839, 'Total loss': 0.5010790427525839} | train loss {'Reaction outcome loss': 0.36831362069874624, 'Total loss': 0.36831362069874624}
2023-01-05 07:38:49,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:38:49,551 INFO:     Epoch: 38
2023-01-05 07:38:51,715 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.47840402722358705, 'Total loss': 0.47840402722358705} | train loss {'Reaction outcome loss': 0.3639953589974565, 'Total loss': 0.3639953589974565}
2023-01-05 07:38:51,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:38:51,715 INFO:     Epoch: 39
2023-01-05 07:38:53,884 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4821429173151652, 'Total loss': 0.4821429173151652} | train loss {'Reaction outcome loss': 0.3604003031758349, 'Total loss': 0.3604003031758349}
2023-01-05 07:38:53,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:38:53,884 INFO:     Epoch: 40
2023-01-05 07:38:56,027 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4575095772743225, 'Total loss': 0.4575095772743225} | train loss {'Reaction outcome loss': 0.3600157719861338, 'Total loss': 0.3600157719861338}
2023-01-05 07:38:56,027 INFO:     Found new best model at epoch 40
2023-01-05 07:38:56,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:38:56,029 INFO:     Epoch: 41
2023-01-05 07:38:58,197 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4703954835732778, 'Total loss': 0.4703954835732778} | train loss {'Reaction outcome loss': 0.3563104454435128, 'Total loss': 0.3563104454435128}
2023-01-05 07:38:58,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:38:58,198 INFO:     Epoch: 42
2023-01-05 07:39:00,361 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4949199100335439, 'Total loss': 0.4949199100335439} | train loss {'Reaction outcome loss': 0.35073544047232985, 'Total loss': 0.35073544047232985}
2023-01-05 07:39:00,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:39:00,361 INFO:     Epoch: 43
2023-01-05 07:39:02,522 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5037451763947804, 'Total loss': 0.5037451763947804} | train loss {'Reaction outcome loss': 0.3534725166020402, 'Total loss': 0.3534725166020402}
2023-01-05 07:39:02,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:39:02,522 INFO:     Epoch: 44
2023-01-05 07:39:04,687 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5218421181042989, 'Total loss': 0.5218421181042989} | train loss {'Reaction outcome loss': 0.34386960441327613, 'Total loss': 0.34386960441327613}
2023-01-05 07:39:04,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:39:04,688 INFO:     Epoch: 45
2023-01-05 07:39:06,819 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.472241340080897, 'Total loss': 0.472241340080897} | train loss {'Reaction outcome loss': 0.3497774113658006, 'Total loss': 0.3497774113658006}
2023-01-05 07:39:06,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:39:06,819 INFO:     Epoch: 46
2023-01-05 07:39:08,967 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.48414102097352346, 'Total loss': 0.48414102097352346} | train loss {'Reaction outcome loss': 0.3453531890594657, 'Total loss': 0.3453531890594657}
2023-01-05 07:39:08,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:39:08,969 INFO:     Epoch: 47
2023-01-05 07:39:11,138 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.516091376543045, 'Total loss': 0.516091376543045} | train loss {'Reaction outcome loss': 0.33254516013901436, 'Total loss': 0.33254516013901436}
2023-01-05 07:39:11,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:39:11,138 INFO:     Epoch: 48
2023-01-05 07:39:13,297 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47937419811884563, 'Total loss': 0.47937419811884563} | train loss {'Reaction outcome loss': 0.34011487005467433, 'Total loss': 0.34011487005467433}
2023-01-05 07:39:13,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:39:13,297 INFO:     Epoch: 49
2023-01-05 07:39:15,471 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47358063658078514, 'Total loss': 0.47358063658078514} | train loss {'Reaction outcome loss': 0.33155840491594246, 'Total loss': 0.33155840491594246}
2023-01-05 07:39:15,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:39:15,472 INFO:     Epoch: 50
2023-01-05 07:39:17,630 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.49181911249955496, 'Total loss': 0.49181911249955496} | train loss {'Reaction outcome loss': 0.330591215460816, 'Total loss': 0.330591215460816}
2023-01-05 07:39:17,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:39:17,630 INFO:     Epoch: 51
2023-01-05 07:39:19,758 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48132161696751913, 'Total loss': 0.48132161696751913} | train loss {'Reaction outcome loss': 0.34749315731713304, 'Total loss': 0.34749315731713304}
2023-01-05 07:39:19,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:39:19,758 INFO:     Epoch: 52
2023-01-05 07:39:21,919 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4597875376542409, 'Total loss': 0.4597875376542409} | train loss {'Reaction outcome loss': 0.34599710334146366, 'Total loss': 0.34599710334146366}
2023-01-05 07:39:21,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:39:21,919 INFO:     Epoch: 53
2023-01-05 07:39:24,090 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4393110752105713, 'Total loss': 0.4393110752105713} | train loss {'Reaction outcome loss': 0.3212975450804916, 'Total loss': 0.3212975450804916}
2023-01-05 07:39:24,090 INFO:     Found new best model at epoch 53
2023-01-05 07:39:24,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:39:24,091 INFO:     Epoch: 54
2023-01-05 07:39:26,273 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4872227301200231, 'Total loss': 0.4872227301200231} | train loss {'Reaction outcome loss': 0.3216939544158843, 'Total loss': 0.3216939544158843}
2023-01-05 07:39:26,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:39:26,273 INFO:     Epoch: 55
2023-01-05 07:39:28,438 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.49058351119359334, 'Total loss': 0.49058351119359334} | train loss {'Reaction outcome loss': 0.32382949236510455, 'Total loss': 0.32382949236510455}
2023-01-05 07:39:28,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:39:28,438 INFO:     Epoch: 56
2023-01-05 07:39:30,595 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5083594302336375, 'Total loss': 0.5083594302336375} | train loss {'Reaction outcome loss': 0.3218807879391639, 'Total loss': 0.3218807879391639}
2023-01-05 07:39:30,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:39:30,596 INFO:     Epoch: 57
2023-01-05 07:39:32,748 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4824986050526301, 'Total loss': 0.4824986050526301} | train loss {'Reaction outcome loss': 0.3105277106820933, 'Total loss': 0.3105277106820933}
2023-01-05 07:39:32,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:39:32,748 INFO:     Epoch: 58
2023-01-05 07:39:34,901 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.49123200376828513, 'Total loss': 0.49123200376828513} | train loss {'Reaction outcome loss': 0.31361587008206593, 'Total loss': 0.31361587008206593}
2023-01-05 07:39:34,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:39:34,901 INFO:     Epoch: 59
2023-01-05 07:39:37,070 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45768646001815794, 'Total loss': 0.45768646001815794} | train loss {'Reaction outcome loss': 0.31848593747945153, 'Total loss': 0.31848593747945153}
2023-01-05 07:39:37,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:39:37,070 INFO:     Epoch: 60
2023-01-05 07:39:39,242 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47332309583822885, 'Total loss': 0.47332309583822885} | train loss {'Reaction outcome loss': 0.312494385228481, 'Total loss': 0.312494385228481}
2023-01-05 07:39:39,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:39:39,243 INFO:     Epoch: 61
2023-01-05 07:39:41,410 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4809632817904154, 'Total loss': 0.4809632817904154} | train loss {'Reaction outcome loss': 0.3089183087533878, 'Total loss': 0.3089183087533878}
2023-01-05 07:39:41,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:39:41,410 INFO:     Epoch: 62
2023-01-05 07:39:43,554 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4617662340402603, 'Total loss': 0.4617662340402603} | train loss {'Reaction outcome loss': 0.30416675503078877, 'Total loss': 0.30416675503078877}
2023-01-05 07:39:43,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:39:43,555 INFO:     Epoch: 63
2023-01-05 07:39:45,728 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4838810622692108, 'Total loss': 0.4838810622692108} | train loss {'Reaction outcome loss': 0.30634294843817456, 'Total loss': 0.30634294843817456}
2023-01-05 07:39:45,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:39:45,729 INFO:     Epoch: 64
2023-01-05 07:39:47,915 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4724910179773966, 'Total loss': 0.4724910179773966} | train loss {'Reaction outcome loss': 0.3017728363216072, 'Total loss': 0.3017728363216072}
2023-01-05 07:39:47,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:39:47,916 INFO:     Epoch: 65
2023-01-05 07:39:50,088 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4941329518953959, 'Total loss': 0.4941329518953959} | train loss {'Reaction outcome loss': 0.295000278500113, 'Total loss': 0.295000278500113}
2023-01-05 07:39:50,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:39:50,088 INFO:     Epoch: 66
2023-01-05 07:39:52,270 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4491360823313395, 'Total loss': 0.4491360823313395} | train loss {'Reaction outcome loss': 0.2934804723597114, 'Total loss': 0.2934804723597114}
2023-01-05 07:39:52,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:39:52,271 INFO:     Epoch: 67
2023-01-05 07:39:54,417 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.48946267167727153, 'Total loss': 0.48946267167727153} | train loss {'Reaction outcome loss': 0.2973421509175197, 'Total loss': 0.2973421509175197}
2023-01-05 07:39:54,417 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:39:54,417 INFO:     Epoch: 68
2023-01-05 07:39:56,592 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5267069091399511, 'Total loss': 0.5267069091399511} | train loss {'Reaction outcome loss': 0.2928013091998013, 'Total loss': 0.2928013091998013}
2023-01-05 07:39:56,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:39:56,592 INFO:     Epoch: 69
2023-01-05 07:39:58,770 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4836371660232544, 'Total loss': 0.4836371660232544} | train loss {'Reaction outcome loss': 0.28593406761470047, 'Total loss': 0.28593406761470047}
2023-01-05 07:39:58,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:39:58,771 INFO:     Epoch: 70
2023-01-05 07:40:00,946 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.46710682809352877, 'Total loss': 0.46710682809352877} | train loss {'Reaction outcome loss': 0.2965698530580493, 'Total loss': 0.2965698530580493}
2023-01-05 07:40:00,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:40:00,946 INFO:     Epoch: 71
2023-01-05 07:40:03,116 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.48280470569928485, 'Total loss': 0.48280470569928485} | train loss {'Reaction outcome loss': 0.2833163487843906, 'Total loss': 0.2833163487843906}
2023-01-05 07:40:03,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:40:03,116 INFO:     Epoch: 72
2023-01-05 07:40:05,276 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4606434653202693, 'Total loss': 0.4606434653202693} | train loss {'Reaction outcome loss': 0.29001386606714863, 'Total loss': 0.29001386606714863}
2023-01-05 07:40:05,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:40:05,277 INFO:     Epoch: 73
2023-01-05 07:40:07,426 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.48084091444810234, 'Total loss': 0.48084091444810234} | train loss {'Reaction outcome loss': 0.2832462552367993, 'Total loss': 0.2832462552367993}
2023-01-05 07:40:07,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:40:07,426 INFO:     Epoch: 74
2023-01-05 07:40:09,608 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4518028974533081, 'Total loss': 0.4518028974533081} | train loss {'Reaction outcome loss': 0.2845043380402258, 'Total loss': 0.2845043380402258}
2023-01-05 07:40:09,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:40:09,608 INFO:     Epoch: 75
2023-01-05 07:40:11,803 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43430881202220917, 'Total loss': 0.43430881202220917} | train loss {'Reaction outcome loss': 0.28103503022018983, 'Total loss': 0.28103503022018983}
2023-01-05 07:40:11,804 INFO:     Found new best model at epoch 75
2023-01-05 07:40:11,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:40:11,805 INFO:     Epoch: 76
2023-01-05 07:40:13,979 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46657679478327435, 'Total loss': 0.46657679478327435} | train loss {'Reaction outcome loss': 0.27592136951790197, 'Total loss': 0.27592136951790197}
2023-01-05 07:40:13,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:40:13,979 INFO:     Epoch: 77
2023-01-05 07:40:16,139 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.454490652680397, 'Total loss': 0.454490652680397} | train loss {'Reaction outcome loss': 0.2746223052761153, 'Total loss': 0.2746223052761153}
2023-01-05 07:40:16,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:40:16,140 INFO:     Epoch: 78
2023-01-05 07:40:18,251 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46982688705126446, 'Total loss': 0.46982688705126446} | train loss {'Reaction outcome loss': 0.2723323779688487, 'Total loss': 0.2723323779688487}
2023-01-05 07:40:18,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:40:18,251 INFO:     Epoch: 79
2023-01-05 07:40:20,421 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5050686399141947, 'Total loss': 0.5050686399141947} | train loss {'Reaction outcome loss': 0.2744146223101753, 'Total loss': 0.2744146223101753}
2023-01-05 07:40:20,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:40:20,421 INFO:     Epoch: 80
2023-01-05 07:40:22,590 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46887753903865814, 'Total loss': 0.46887753903865814} | train loss {'Reaction outcome loss': 0.27995945973004605, 'Total loss': 0.27995945973004605}
2023-01-05 07:40:22,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:40:22,591 INFO:     Epoch: 81
2023-01-05 07:40:24,746 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4663600564002991, 'Total loss': 0.4663600564002991} | train loss {'Reaction outcome loss': 0.27148397619147663, 'Total loss': 0.27148397619147663}
2023-01-05 07:40:24,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:40:24,746 INFO:     Epoch: 82
2023-01-05 07:40:26,912 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45483499268690747, 'Total loss': 0.45483499268690747} | train loss {'Reaction outcome loss': 0.28632022559084336, 'Total loss': 0.28632022559084336}
2023-01-05 07:40:26,912 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:40:26,912 INFO:     Epoch: 83
2023-01-05 07:40:29,064 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46709813475608825, 'Total loss': 0.46709813475608825} | train loss {'Reaction outcome loss': 0.272180398256329, 'Total loss': 0.272180398256329}
2023-01-05 07:40:29,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:40:29,064 INFO:     Epoch: 84
2023-01-05 07:40:31,007 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4598977496226629, 'Total loss': 0.4598977496226629} | train loss {'Reaction outcome loss': 0.2721704978958123, 'Total loss': 0.2721704978958123}
2023-01-05 07:40:31,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:40:31,008 INFO:     Epoch: 85
2023-01-05 07:40:33,158 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.44409440557161967, 'Total loss': 0.44409440557161967} | train loss {'Reaction outcome loss': 0.27088967617379717, 'Total loss': 0.27088967617379717}
2023-01-05 07:40:33,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:40:33,159 INFO:     Epoch: 86
2023-01-05 07:40:35,318 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4515881101290385, 'Total loss': 0.4515881101290385} | train loss {'Reaction outcome loss': 0.264415364941933, 'Total loss': 0.264415364941933}
2023-01-05 07:40:35,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:40:35,319 INFO:     Epoch: 87
2023-01-05 07:40:37,479 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44867175817489624, 'Total loss': 0.44867175817489624} | train loss {'Reaction outcome loss': 0.2673585977881094, 'Total loss': 0.2673585977881094}
2023-01-05 07:40:37,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:40:37,479 INFO:     Epoch: 88
2023-01-05 07:40:39,656 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4860156575838725, 'Total loss': 0.4860156575838725} | train loss {'Reaction outcome loss': 0.26534791481073783, 'Total loss': 0.26534791481073783}
2023-01-05 07:40:39,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:40:39,656 INFO:     Epoch: 89
2023-01-05 07:40:41,802 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43036088943481443, 'Total loss': 0.43036088943481443} | train loss {'Reaction outcome loss': 0.2638036903487734, 'Total loss': 0.2638036903487734}
2023-01-05 07:40:41,802 INFO:     Found new best model at epoch 89
2023-01-05 07:40:41,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:40:41,803 INFO:     Epoch: 90
2023-01-05 07:40:43,969 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40870777865250907, 'Total loss': 0.40870777865250907} | train loss {'Reaction outcome loss': 0.2595046768592379, 'Total loss': 0.2595046768592379}
2023-01-05 07:40:43,970 INFO:     Found new best model at epoch 90
2023-01-05 07:40:43,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:40:43,971 INFO:     Epoch: 91
2023-01-05 07:40:46,135 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46378025809923806, 'Total loss': 0.46378025809923806} | train loss {'Reaction outcome loss': 0.26425680065986473, 'Total loss': 0.26425680065986473}
2023-01-05 07:40:46,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:40:46,136 INFO:     Epoch: 92
2023-01-05 07:40:48,302 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43386101027329765, 'Total loss': 0.43386101027329765} | train loss {'Reaction outcome loss': 0.26364894144395634, 'Total loss': 0.26364894144395634}
2023-01-05 07:40:48,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:40:48,303 INFO:     Epoch: 93
2023-01-05 07:40:50,494 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4440504391988119, 'Total loss': 0.4440504391988119} | train loss {'Reaction outcome loss': 0.2537917686369864, 'Total loss': 0.2537917686369864}
2023-01-05 07:40:50,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:40:50,495 INFO:     Epoch: 94
2023-01-05 07:40:52,645 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4510969857374827, 'Total loss': 0.4510969857374827} | train loss {'Reaction outcome loss': 0.25867141519447084, 'Total loss': 0.25867141519447084}
2023-01-05 07:40:52,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:40:52,646 INFO:     Epoch: 95
2023-01-05 07:40:54,854 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.45240060488382977, 'Total loss': 0.45240060488382977} | train loss {'Reaction outcome loss': 0.252928764478344, 'Total loss': 0.252928764478344}
2023-01-05 07:40:54,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:40:54,854 INFO:     Epoch: 96
2023-01-05 07:40:57,125 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.45310607651869456, 'Total loss': 0.45310607651869456} | train loss {'Reaction outcome loss': 0.25499056983592355, 'Total loss': 0.25499056983592355}
2023-01-05 07:40:57,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:40:57,125 INFO:     Epoch: 97
2023-01-05 07:40:59,399 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4615185817082723, 'Total loss': 0.4615185817082723} | train loss {'Reaction outcome loss': 0.2572718073826526, 'Total loss': 0.2572718073826526}
2023-01-05 07:40:59,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:40:59,399 INFO:     Epoch: 98
2023-01-05 07:41:01,671 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4354899272322655, 'Total loss': 0.4354899272322655} | train loss {'Reaction outcome loss': 0.2558354617165447, 'Total loss': 0.2558354617165447}
2023-01-05 07:41:01,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:41:01,671 INFO:     Epoch: 99
2023-01-05 07:41:03,817 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48040342380603157, 'Total loss': 0.48040342380603157} | train loss {'Reaction outcome loss': 0.25257504291258176, 'Total loss': 0.25257504291258176}
2023-01-05 07:41:03,817 INFO:     Best model found after epoch 91 of 100.
2023-01-05 07:41:03,818 INFO:   Done with stage: TRAINING
2023-01-05 07:41:03,818 INFO:   Starting stage: EVALUATION
2023-01-05 07:41:03,950 INFO:   Done with stage: EVALUATION
2023-01-05 07:41:03,959 INFO:   Leaving out SEQ value Fold_0
2023-01-05 07:41:03,972 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-05 07:41:03,972 INFO:   Starting stage: FEATURE SCALING
2023-01-05 07:41:04,624 INFO:   Done with stage: FEATURE SCALING
2023-01-05 07:41:04,624 INFO:   Starting stage: SCALING TARGETS
2023-01-05 07:41:04,693 INFO:   Done with stage: SCALING TARGETS
2023-01-05 07:41:04,694 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:41:04,694 INFO:     No hyperparam tuning for this model
2023-01-05 07:41:04,694 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:41:04,694 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 07:41:04,695 INFO:     None feature selector for col prot
2023-01-05 07:41:04,695 INFO:     None feature selector for col prot
2023-01-05 07:41:04,695 INFO:     None feature selector for col prot
2023-01-05 07:41:04,695 INFO:     None feature selector for col chem
2023-01-05 07:41:04,696 INFO:     None feature selector for col chem
2023-01-05 07:41:04,696 INFO:     None feature selector for col chem
2023-01-05 07:41:04,696 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 07:41:04,696 INFO:   Starting stage: BUILD MODEL
2023-01-05 07:41:04,697 INFO:     Number of params in model 72901
2023-01-05 07:41:04,700 INFO:   Done with stage: BUILD MODEL
2023-01-05 07:41:04,700 INFO:   Starting stage: TRAINING
2023-01-05 07:41:04,760 INFO:     Val loss before train {'Reaction outcome loss': 0.9809326688448589, 'Total loss': 0.9809326688448589}
2023-01-05 07:41:04,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:41:04,760 INFO:     Epoch: 0
2023-01-05 07:41:06,868 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7578660269578298, 'Total loss': 0.7578660269578298} | train loss {'Reaction outcome loss': 0.9051203495681945, 'Total loss': 0.9051203495681945}
2023-01-05 07:41:06,868 INFO:     Found new best model at epoch 0
2023-01-05 07:41:06,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:41:06,870 INFO:     Epoch: 1
2023-01-05 07:41:08,998 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5581245710452397, 'Total loss': 0.5581245710452397} | train loss {'Reaction outcome loss': 0.7024264894288405, 'Total loss': 0.7024264894288405}
2023-01-05 07:41:08,998 INFO:     Found new best model at epoch 1
2023-01-05 07:41:08,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:41:09,000 INFO:     Epoch: 2
2023-01-05 07:41:11,118 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5531771143277486, 'Total loss': 0.5531771143277486} | train loss {'Reaction outcome loss': 0.5631356186532447, 'Total loss': 0.5631356186532447}
2023-01-05 07:41:11,119 INFO:     Found new best model at epoch 2
2023-01-05 07:41:11,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:41:11,120 INFO:     Epoch: 3
2023-01-05 07:41:13,236 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4909516235192617, 'Total loss': 0.4909516235192617} | train loss {'Reaction outcome loss': 0.5225023810384019, 'Total loss': 0.5225023810384019}
2023-01-05 07:41:13,236 INFO:     Found new best model at epoch 3
2023-01-05 07:41:13,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:41:13,237 INFO:     Epoch: 4
2023-01-05 07:41:15,337 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5060114552577336, 'Total loss': 0.5060114552577336} | train loss {'Reaction outcome loss': 0.5024501820441981, 'Total loss': 0.5024501820441981}
2023-01-05 07:41:15,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:41:15,337 INFO:     Epoch: 5
2023-01-05 07:41:17,453 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5103896101315816, 'Total loss': 0.5103896101315816} | train loss {'Reaction outcome loss': 0.4924959328671663, 'Total loss': 0.4924959328671663}
2023-01-05 07:41:17,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:41:17,453 INFO:     Epoch: 6
2023-01-05 07:41:19,586 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46895332435766857, 'Total loss': 0.46895332435766857} | train loss {'Reaction outcome loss': 0.48118671384464773, 'Total loss': 0.48118671384464773}
2023-01-05 07:41:19,586 INFO:     Found new best model at epoch 6
2023-01-05 07:41:19,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:41:19,588 INFO:     Epoch: 7
2023-01-05 07:41:21,693 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5154918253421783, 'Total loss': 0.5154918253421783} | train loss {'Reaction outcome loss': 0.4706683666943624, 'Total loss': 0.4706683666943624}
2023-01-05 07:41:21,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:41:21,694 INFO:     Epoch: 8
2023-01-05 07:41:23,831 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4649586021900177, 'Total loss': 0.4649586021900177} | train loss {'Reaction outcome loss': 0.4680429545825698, 'Total loss': 0.4680429545825698}
2023-01-05 07:41:23,831 INFO:     Found new best model at epoch 8
2023-01-05 07:41:23,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:41:23,832 INFO:     Epoch: 9
2023-01-05 07:41:25,954 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4840283582607905, 'Total loss': 0.4840283582607905} | train loss {'Reaction outcome loss': 0.4566917063675244, 'Total loss': 0.4566917063675244}
2023-01-05 07:41:25,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:41:25,955 INFO:     Epoch: 10
2023-01-05 07:41:28,061 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47993034521738687, 'Total loss': 0.47993034521738687} | train loss {'Reaction outcome loss': 0.45389504901157535, 'Total loss': 0.45389504901157535}
2023-01-05 07:41:28,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:41:28,061 INFO:     Epoch: 11
2023-01-05 07:41:30,199 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45799461503823596, 'Total loss': 0.45799461503823596} | train loss {'Reaction outcome loss': 0.4509268625745914, 'Total loss': 0.4509268625745914}
2023-01-05 07:41:30,199 INFO:     Found new best model at epoch 11
2023-01-05 07:41:30,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:41:30,200 INFO:     Epoch: 12
2023-01-05 07:41:32,340 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44428635239601133, 'Total loss': 0.44428635239601133} | train loss {'Reaction outcome loss': 0.44696342818631457, 'Total loss': 0.44696342818631457}
2023-01-05 07:41:32,340 INFO:     Found new best model at epoch 12
2023-01-05 07:41:32,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:41:32,341 INFO:     Epoch: 13
2023-01-05 07:41:34,475 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.464419279495875, 'Total loss': 0.464419279495875} | train loss {'Reaction outcome loss': 0.44525755570713443, 'Total loss': 0.44525755570713443}
2023-01-05 07:41:34,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:41:34,475 INFO:     Epoch: 14
2023-01-05 07:41:36,624 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4657857378323873, 'Total loss': 0.4657857378323873} | train loss {'Reaction outcome loss': 0.4419045501089624, 'Total loss': 0.4419045501089624}
2023-01-05 07:41:36,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:41:36,624 INFO:     Epoch: 15
2023-01-05 07:41:38,722 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4905778626600901, 'Total loss': 0.4905778626600901} | train loss {'Reaction outcome loss': 0.429506104920623, 'Total loss': 0.429506104920623}
2023-01-05 07:41:38,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:41:38,722 INFO:     Epoch: 16
2023-01-05 07:41:40,854 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48570693731307985, 'Total loss': 0.48570693731307985} | train loss {'Reaction outcome loss': 0.425787159767538, 'Total loss': 0.425787159767538}
2023-01-05 07:41:40,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:41:40,855 INFO:     Epoch: 17
2023-01-05 07:41:42,979 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.45954371988773346, 'Total loss': 0.45954371988773346} | train loss {'Reaction outcome loss': 0.4269662252541398, 'Total loss': 0.4269662252541398}
2023-01-05 07:41:42,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:41:42,979 INFO:     Epoch: 18
2023-01-05 07:41:45,113 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.43167701264222463, 'Total loss': 0.43167701264222463} | train loss {'Reaction outcome loss': 0.41765939623007475, 'Total loss': 0.41765939623007475}
2023-01-05 07:41:45,114 INFO:     Found new best model at epoch 18
2023-01-05 07:41:45,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:41:45,115 INFO:     Epoch: 19
2023-01-05 07:41:47,253 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4256029357512792, 'Total loss': 0.4256029357512792} | train loss {'Reaction outcome loss': 0.4141446232685744, 'Total loss': 0.4141446232685744}
2023-01-05 07:41:47,253 INFO:     Found new best model at epoch 19
2023-01-05 07:41:47,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:41:47,254 INFO:     Epoch: 20
2023-01-05 07:41:49,385 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4788189917802811, 'Total loss': 0.4788189917802811} | train loss {'Reaction outcome loss': 0.4019778494300438, 'Total loss': 0.4019778494300438}
2023-01-05 07:41:49,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:41:49,385 INFO:     Epoch: 21
2023-01-05 07:41:51,460 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.470938104391098, 'Total loss': 0.470938104391098} | train loss {'Reaction outcome loss': 0.4063784699213461, 'Total loss': 0.4063784699213461}
2023-01-05 07:41:51,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:41:51,461 INFO:     Epoch: 22
2023-01-05 07:41:53,574 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.482395335038503, 'Total loss': 0.482395335038503} | train loss {'Reaction outcome loss': 0.40535386071653823, 'Total loss': 0.40535386071653823}
2023-01-05 07:41:53,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:41:53,575 INFO:     Epoch: 23
2023-01-05 07:41:55,703 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.487809444963932, 'Total loss': 0.487809444963932} | train loss {'Reaction outcome loss': 0.3983832785784098, 'Total loss': 0.3983832785784098}
2023-01-05 07:41:55,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:41:55,703 INFO:     Epoch: 24
2023-01-05 07:41:57,827 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46964342296123507, 'Total loss': 0.46964342296123507} | train loss {'Reaction outcome loss': 0.3913685304432338, 'Total loss': 0.3913685304432338}
2023-01-05 07:41:57,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:41:57,828 INFO:     Epoch: 25
2023-01-05 07:41:59,963 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4614660531282425, 'Total loss': 0.4614660531282425} | train loss {'Reaction outcome loss': 0.3884477248600928, 'Total loss': 0.3884477248600928}
2023-01-05 07:41:59,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:41:59,963 INFO:     Epoch: 26
2023-01-05 07:42:02,072 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.438521677814424, 'Total loss': 0.438521677814424} | train loss {'Reaction outcome loss': 0.3792189570535593, 'Total loss': 0.3792189570535593}
2023-01-05 07:42:02,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:42:02,072 INFO:     Epoch: 27
2023-01-05 07:42:04,192 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4411635448535283, 'Total loss': 0.4411635448535283} | train loss {'Reaction outcome loss': 0.38018694825168026, 'Total loss': 0.38018694825168026}
2023-01-05 07:42:04,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:42:04,193 INFO:     Epoch: 28
2023-01-05 07:42:06,320 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43742141326268513, 'Total loss': 0.43742141326268513} | train loss {'Reaction outcome loss': 0.38126496984399993, 'Total loss': 0.38126496984399993}
2023-01-05 07:42:06,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:42:06,320 INFO:     Epoch: 29
2023-01-05 07:42:08,444 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4376087665557861, 'Total loss': 0.4376087665557861} | train loss {'Reaction outcome loss': 0.3729059999719317, 'Total loss': 0.3729059999719317}
2023-01-05 07:42:08,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:42:08,444 INFO:     Epoch: 30
2023-01-05 07:42:10,565 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41637784155706564, 'Total loss': 0.41637784155706564} | train loss {'Reaction outcome loss': 0.37440273330660323, 'Total loss': 0.37440273330660323}
2023-01-05 07:42:10,565 INFO:     Found new best model at epoch 30
2023-01-05 07:42:10,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:42:10,566 INFO:     Epoch: 31
2023-01-05 07:42:12,693 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4478358507156372, 'Total loss': 0.4478358507156372} | train loss {'Reaction outcome loss': 0.3650476366446467, 'Total loss': 0.3650476366446467}
2023-01-05 07:42:12,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:42:12,693 INFO:     Epoch: 32
2023-01-05 07:42:14,796 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4498817652463913, 'Total loss': 0.4498817652463913} | train loss {'Reaction outcome loss': 0.36684759706258774, 'Total loss': 0.36684759706258774}
2023-01-05 07:42:14,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:42:14,796 INFO:     Epoch: 33
2023-01-05 07:42:16,935 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.43769300580024717, 'Total loss': 0.43769300580024717} | train loss {'Reaction outcome loss': 0.36188270234093894, 'Total loss': 0.36188270234093894}
2023-01-05 07:42:16,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:42:16,936 INFO:     Epoch: 34
2023-01-05 07:42:19,045 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4493906517823537, 'Total loss': 0.4493906517823537} | train loss {'Reaction outcome loss': 0.35330124614533465, 'Total loss': 0.35330124614533465}
2023-01-05 07:42:19,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:42:19,045 INFO:     Epoch: 35
2023-01-05 07:42:21,169 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4117234041293462, 'Total loss': 0.4117234041293462} | train loss {'Reaction outcome loss': 0.3498967214594028, 'Total loss': 0.3498967214594028}
2023-01-05 07:42:21,170 INFO:     Found new best model at epoch 35
2023-01-05 07:42:21,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:42:21,171 INFO:     Epoch: 36
2023-01-05 07:42:23,308 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.443933176000913, 'Total loss': 0.443933176000913} | train loss {'Reaction outcome loss': 0.3477415014127084, 'Total loss': 0.3477415014127084}
2023-01-05 07:42:23,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:42:23,309 INFO:     Epoch: 37
2023-01-05 07:42:25,418 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4168864299853643, 'Total loss': 0.4168864299853643} | train loss {'Reaction outcome loss': 0.3471730222231348, 'Total loss': 0.3471730222231348}
2023-01-05 07:42:25,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:42:25,418 INFO:     Epoch: 38
2023-01-05 07:42:27,540 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4216253995895386, 'Total loss': 0.4216253995895386} | train loss {'Reaction outcome loss': 0.34055265410359936, 'Total loss': 0.34055265410359936}
2023-01-05 07:42:27,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:42:27,540 INFO:     Epoch: 39
2023-01-05 07:42:29,656 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39916816155115764, 'Total loss': 0.39916816155115764} | train loss {'Reaction outcome loss': 0.34020053336871064, 'Total loss': 0.34020053336871064}
2023-01-05 07:42:29,656 INFO:     Found new best model at epoch 39
2023-01-05 07:42:29,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:42:29,657 INFO:     Epoch: 40
2023-01-05 07:42:31,802 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4174133842190107, 'Total loss': 0.4174133842190107} | train loss {'Reaction outcome loss': 0.33973644288923466, 'Total loss': 0.33973644288923466}
2023-01-05 07:42:31,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:42:31,802 INFO:     Epoch: 41
2023-01-05 07:42:33,926 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4549405723810196, 'Total loss': 0.4549405723810196} | train loss {'Reaction outcome loss': 0.33434969038321083, 'Total loss': 0.33434969038321083}
2023-01-05 07:42:33,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:42:33,927 INFO:     Epoch: 42
2023-01-05 07:42:36,052 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40789834757645926, 'Total loss': 0.40789834757645926} | train loss {'Reaction outcome loss': 0.3287225776657847, 'Total loss': 0.3287225776657847}
2023-01-05 07:42:36,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:42:36,052 INFO:     Epoch: 43
2023-01-05 07:42:38,152 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3792607009410858, 'Total loss': 0.3792607009410858} | train loss {'Reaction outcome loss': 0.3312885702838537, 'Total loss': 0.3312885702838537}
2023-01-05 07:42:38,152 INFO:     Found new best model at epoch 43
2023-01-05 07:42:38,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:42:38,154 INFO:     Epoch: 44
2023-01-05 07:42:40,293 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4041363686323166, 'Total loss': 0.4041363686323166} | train loss {'Reaction outcome loss': 0.3240515034082191, 'Total loss': 0.3240515034082191}
2023-01-05 07:42:40,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:42:40,294 INFO:     Epoch: 45
2023-01-05 07:42:42,423 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3966211040814718, 'Total loss': 0.3966211040814718} | train loss {'Reaction outcome loss': 0.3183802097238518, 'Total loss': 0.3183802097238518}
2023-01-05 07:42:42,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:42:42,423 INFO:     Epoch: 46
2023-01-05 07:42:44,553 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.38272390762964886, 'Total loss': 0.38272390762964886} | train loss {'Reaction outcome loss': 0.32127096352761964, 'Total loss': 0.32127096352761964}
2023-01-05 07:42:44,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:42:44,553 INFO:     Epoch: 47
2023-01-05 07:42:46,799 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.41449578404426574, 'Total loss': 0.41449578404426574} | train loss {'Reaction outcome loss': 0.32209854520774855, 'Total loss': 0.32209854520774855}
2023-01-05 07:42:46,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:42:46,800 INFO:     Epoch: 48
2023-01-05 07:42:48,916 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40993720591068267, 'Total loss': 0.40993720591068267} | train loss {'Reaction outcome loss': 0.31362185327549263, 'Total loss': 0.31362185327549263}
2023-01-05 07:42:48,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:42:48,916 INFO:     Epoch: 49
2023-01-05 07:42:51,041 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4052487850189209, 'Total loss': 0.4052487850189209} | train loss {'Reaction outcome loss': 0.30737203554803594, 'Total loss': 0.30737203554803594}
2023-01-05 07:42:51,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:42:51,041 INFO:     Epoch: 50
2023-01-05 07:42:53,165 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4010213017463684, 'Total loss': 0.4010213017463684} | train loss {'Reaction outcome loss': 0.3152170326299553, 'Total loss': 0.3152170326299553}
2023-01-05 07:42:53,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:42:53,166 INFO:     Epoch: 51
2023-01-05 07:42:55,277 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39861628313859304, 'Total loss': 0.39861628313859304} | train loss {'Reaction outcome loss': 0.318675065791145, 'Total loss': 0.318675065791145}
2023-01-05 07:42:55,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:42:55,277 INFO:     Epoch: 52
2023-01-05 07:42:57,407 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42648211419582366, 'Total loss': 0.42648211419582366} | train loss {'Reaction outcome loss': 0.30650128862679665, 'Total loss': 0.30650128862679665}
2023-01-05 07:42:57,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:42:57,407 INFO:     Epoch: 53
2023-01-05 07:42:59,539 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3718875686327616, 'Total loss': 0.3718875686327616} | train loss {'Reaction outcome loss': 0.3031670685816295, 'Total loss': 0.3031670685816295}
2023-01-05 07:42:59,540 INFO:     Found new best model at epoch 53
2023-01-05 07:42:59,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:42:59,541 INFO:     Epoch: 54
2023-01-05 07:43:01,650 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.435167728861173, 'Total loss': 0.435167728861173} | train loss {'Reaction outcome loss': 0.31001876455446453, 'Total loss': 0.31001876455446453}
2023-01-05 07:43:01,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:43:01,650 INFO:     Epoch: 55
2023-01-05 07:43:03,789 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43103575309117637, 'Total loss': 0.43103575309117637} | train loss {'Reaction outcome loss': 0.30091463228708265, 'Total loss': 0.30091463228708265}
2023-01-05 07:43:03,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:43:03,789 INFO:     Epoch: 56
2023-01-05 07:43:05,940 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3964530646800995, 'Total loss': 0.3964530646800995} | train loss {'Reaction outcome loss': 0.3036667360233425, 'Total loss': 0.3036667360233425}
2023-01-05 07:43:05,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:43:05,940 INFO:     Epoch: 57
2023-01-05 07:43:08,060 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.390921950340271, 'Total loss': 0.390921950340271} | train loss {'Reaction outcome loss': 0.29758721532306986, 'Total loss': 0.29758721532306986}
2023-01-05 07:43:08,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:43:08,060 INFO:     Epoch: 58
2023-01-05 07:43:10,192 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3787454138199488, 'Total loss': 0.3787454138199488} | train loss {'Reaction outcome loss': 0.29501256318522334, 'Total loss': 0.29501256318522334}
2023-01-05 07:43:10,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:43:10,193 INFO:     Epoch: 59
2023-01-05 07:43:12,306 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3794194410244624, 'Total loss': 0.3794194410244624} | train loss {'Reaction outcome loss': 0.2980990242281743, 'Total loss': 0.2980990242281743}
2023-01-05 07:43:12,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:43:12,306 INFO:     Epoch: 60
2023-01-05 07:43:14,417 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.37001900176207225, 'Total loss': 0.37001900176207225} | train loss {'Reaction outcome loss': 0.29229814233430196, 'Total loss': 0.29229814233430196}
2023-01-05 07:43:14,417 INFO:     Found new best model at epoch 60
2023-01-05 07:43:14,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:43:14,419 INFO:     Epoch: 61
2023-01-05 07:43:16,541 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4064335803190867, 'Total loss': 0.4064335803190867} | train loss {'Reaction outcome loss': 0.2906991719264826, 'Total loss': 0.2906991719264826}
2023-01-05 07:43:16,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:43:16,542 INFO:     Epoch: 62
2023-01-05 07:43:18,665 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4092665622631709, 'Total loss': 0.4092665622631709} | train loss {'Reaction outcome loss': 0.29110029979000673, 'Total loss': 0.29110029979000673}
2023-01-05 07:43:18,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:43:18,665 INFO:     Epoch: 63
2023-01-05 07:43:20,782 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4182481378316879, 'Total loss': 0.4182481378316879} | train loss {'Reaction outcome loss': 0.29020647764398383, 'Total loss': 0.29020647764398383}
2023-01-05 07:43:20,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:43:20,782 INFO:     Epoch: 64
2023-01-05 07:43:22,900 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3758955905834834, 'Total loss': 0.3758955905834834} | train loss {'Reaction outcome loss': 0.2864121983508232, 'Total loss': 0.2864121983508232}
2023-01-05 07:43:22,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:43:22,901 INFO:     Epoch: 65
2023-01-05 07:43:24,996 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42884867191314696, 'Total loss': 0.42884867191314696} | train loss {'Reaction outcome loss': 0.2795223824033768, 'Total loss': 0.2795223824033768}
2023-01-05 07:43:24,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:43:24,996 INFO:     Epoch: 66
2023-01-05 07:43:27,122 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3720879301428795, 'Total loss': 0.3720879301428795} | train loss {'Reaction outcome loss': 0.29122118919922857, 'Total loss': 0.29122118919922857}
2023-01-05 07:43:27,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:43:27,122 INFO:     Epoch: 67
2023-01-05 07:43:29,248 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3624703218539556, 'Total loss': 0.3624703218539556} | train loss {'Reaction outcome loss': 0.2778191917001981, 'Total loss': 0.2778191917001981}
2023-01-05 07:43:29,249 INFO:     Found new best model at epoch 67
2023-01-05 07:43:29,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:43:29,250 INFO:     Epoch: 68
2023-01-05 07:43:31,412 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3730425943930944, 'Total loss': 0.3730425943930944} | train loss {'Reaction outcome loss': 0.28646141312659007, 'Total loss': 0.28646141312659007}
2023-01-05 07:43:31,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:43:31,413 INFO:     Epoch: 69
2023-01-05 07:43:33,568 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.417959197362264, 'Total loss': 0.417959197362264} | train loss {'Reaction outcome loss': 0.27746612848061036, 'Total loss': 0.27746612848061036}
2023-01-05 07:43:33,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:43:33,569 INFO:     Epoch: 70
2023-01-05 07:43:35,730 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40949980914592743, 'Total loss': 0.40949980914592743} | train loss {'Reaction outcome loss': 0.2709261509916329, 'Total loss': 0.2709261509916329}
2023-01-05 07:43:35,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:43:35,730 INFO:     Epoch: 71
2023-01-05 07:43:37,889 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46075100898742677, 'Total loss': 0.46075100898742677} | train loss {'Reaction outcome loss': 0.27215663104479604, 'Total loss': 0.27215663104479604}
2023-01-05 07:43:37,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:43:37,889 INFO:     Epoch: 72
2023-01-05 07:43:40,046 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4203361764550209, 'Total loss': 0.4203361764550209} | train loss {'Reaction outcome loss': 0.2692640353392851, 'Total loss': 0.2692640353392851}
2023-01-05 07:43:40,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:43:40,047 INFO:     Epoch: 73
2023-01-05 07:43:42,192 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40992020765940346, 'Total loss': 0.40992020765940346} | train loss {'Reaction outcome loss': 0.27670825499615104, 'Total loss': 0.27670825499615104}
2023-01-05 07:43:42,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:43:42,192 INFO:     Epoch: 74
2023-01-05 07:43:44,369 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.38070099453131356, 'Total loss': 0.38070099453131356} | train loss {'Reaction outcome loss': 0.27309932543232873, 'Total loss': 0.27309932543232873}
2023-01-05 07:43:44,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:43:44,370 INFO:     Epoch: 75
2023-01-05 07:43:46,525 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.38147365120239557, 'Total loss': 0.38147365120239557} | train loss {'Reaction outcome loss': 0.2699506393121727, 'Total loss': 0.2699506393121727}
2023-01-05 07:43:46,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:43:46,526 INFO:     Epoch: 76
2023-01-05 07:43:48,665 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3982141027847926, 'Total loss': 0.3982141027847926} | train loss {'Reaction outcome loss': 0.2682529701352999, 'Total loss': 0.2682529701352999}
2023-01-05 07:43:48,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:43:48,665 INFO:     Epoch: 77
2023-01-05 07:43:50,815 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4096566766500473, 'Total loss': 0.4096566766500473} | train loss {'Reaction outcome loss': 0.2717909209526443, 'Total loss': 0.2717909209526443}
2023-01-05 07:43:50,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:43:50,815 INFO:     Epoch: 78
2023-01-05 07:43:52,944 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.379138774673144, 'Total loss': 0.379138774673144} | train loss {'Reaction outcome loss': 0.26332407548501263, 'Total loss': 0.26332407548501263}
2023-01-05 07:43:52,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:43:52,944 INFO:     Epoch: 79
2023-01-05 07:43:55,085 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4205721487601598, 'Total loss': 0.4205721487601598} | train loss {'Reaction outcome loss': 0.2598400370413747, 'Total loss': 0.2598400370413747}
2023-01-05 07:43:55,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:43:55,085 INFO:     Epoch: 80
2023-01-05 07:43:57,209 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.37444219291210173, 'Total loss': 0.37444219291210173} | train loss {'Reaction outcome loss': 0.2620590590284209, 'Total loss': 0.2620590590284209}
2023-01-05 07:43:57,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:43:57,209 INFO:     Epoch: 81
2023-01-05 07:43:59,313 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3991727123657862, 'Total loss': 0.3991727123657862} | train loss {'Reaction outcome loss': 0.26196835274598473, 'Total loss': 0.26196835274598473}
2023-01-05 07:43:59,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:43:59,314 INFO:     Epoch: 82
2023-01-05 07:44:01,445 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4338984986146291, 'Total loss': 0.4338984986146291} | train loss {'Reaction outcome loss': 0.265629132996516, 'Total loss': 0.265629132996516}
2023-01-05 07:44:01,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:44:01,445 INFO:     Epoch: 83
2023-01-05 07:44:03,574 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4201816976070404, 'Total loss': 0.4201816976070404} | train loss {'Reaction outcome loss': 0.2543737174207654, 'Total loss': 0.2543737174207654}
2023-01-05 07:44:03,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:44:03,574 INFO:     Epoch: 84
2023-01-05 07:44:05,677 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4329517314831416, 'Total loss': 0.4329517314831416} | train loss {'Reaction outcome loss': 0.2576920213968222, 'Total loss': 0.2576920213968222}
2023-01-05 07:44:05,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:44:05,678 INFO:     Epoch: 85
2023-01-05 07:44:07,820 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3988628993431727, 'Total loss': 0.3988628993431727} | train loss {'Reaction outcome loss': 0.2558068761540185, 'Total loss': 0.2558068761540185}
2023-01-05 07:44:07,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:44:07,820 INFO:     Epoch: 86
2023-01-05 07:44:09,953 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4383452096953988, 'Total loss': 0.4383452096953988} | train loss {'Reaction outcome loss': 0.26037929023915, 'Total loss': 0.26037929023915}
2023-01-05 07:44:09,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:44:09,953 INFO:     Epoch: 87
2023-01-05 07:44:12,033 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.35793296123544377, 'Total loss': 0.35793296123544377} | train loss {'Reaction outcome loss': 0.2518462639480719, 'Total loss': 0.2518462639480719}
2023-01-05 07:44:12,033 INFO:     Found new best model at epoch 87
2023-01-05 07:44:12,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:44:12,035 INFO:     Epoch: 88
2023-01-05 07:44:13,807 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.411196181178093, 'Total loss': 0.411196181178093} | train loss {'Reaction outcome loss': 0.2481458689123942, 'Total loss': 0.2481458689123942}
2023-01-05 07:44:13,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:44:13,808 INFO:     Epoch: 89
2023-01-05 07:44:15,565 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3850966493288676, 'Total loss': 0.3850966493288676} | train loss {'Reaction outcome loss': 0.26698376632869464, 'Total loss': 0.26698376632869464}
2023-01-05 07:44:15,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:44:15,567 INFO:     Epoch: 90
2023-01-05 07:44:17,611 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.36037451873222986, 'Total loss': 0.36037451873222986} | train loss {'Reaction outcome loss': 0.24630238984563693, 'Total loss': 0.24630238984563693}
2023-01-05 07:44:17,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:44:17,611 INFO:     Epoch: 91
2023-01-05 07:44:19,743 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.40075089161594707, 'Total loss': 0.40075089161594707} | train loss {'Reaction outcome loss': 0.24533023674563398, 'Total loss': 0.24533023674563398}
2023-01-05 07:44:19,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:44:19,744 INFO:     Epoch: 92
2023-01-05 07:44:21,838 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4068932796518008, 'Total loss': 0.4068932796518008} | train loss {'Reaction outcome loss': 0.24835115945399688, 'Total loss': 0.24835115945399688}
2023-01-05 07:44:21,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:44:21,839 INFO:     Epoch: 93
2023-01-05 07:44:23,968 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39731535216172537, 'Total loss': 0.39731535216172537} | train loss {'Reaction outcome loss': 0.24751179542296267, 'Total loss': 0.24751179542296267}
2023-01-05 07:44:23,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:44:23,969 INFO:     Epoch: 94
2023-01-05 07:44:26,095 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43937240342299144, 'Total loss': 0.43937240342299144} | train loss {'Reaction outcome loss': 0.24309425260802917, 'Total loss': 0.24309425260802917}
2023-01-05 07:44:26,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:44:26,095 INFO:     Epoch: 95
2023-01-05 07:44:28,214 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3897095744808515, 'Total loss': 0.3897095744808515} | train loss {'Reaction outcome loss': 0.25432520442920636, 'Total loss': 0.25432520442920636}
2023-01-05 07:44:28,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:44:28,214 INFO:     Epoch: 96
2023-01-05 07:44:30,347 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40397198299566905, 'Total loss': 0.40397198299566905} | train loss {'Reaction outcome loss': 0.24641098820250412, 'Total loss': 0.24641098820250412}
2023-01-05 07:44:30,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:44:30,347 INFO:     Epoch: 97
2023-01-05 07:44:32,464 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.397454509139061, 'Total loss': 0.397454509139061} | train loss {'Reaction outcome loss': 0.2491330696180518, 'Total loss': 0.2491330696180518}
2023-01-05 07:44:32,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:44:32,464 INFO:     Epoch: 98
2023-01-05 07:44:34,490 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42512373328208924, 'Total loss': 0.42512373328208924} | train loss {'Reaction outcome loss': 0.2540446190486535, 'Total loss': 0.2540446190486535}
2023-01-05 07:44:34,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:44:34,491 INFO:     Epoch: 99
2023-01-05 07:44:36,544 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.366152917748938, 'Total loss': 0.366152917748938} | train loss {'Reaction outcome loss': 0.23884302279413627, 'Total loss': 0.23884302279413627}
2023-01-05 07:44:36,544 INFO:     Best model found after epoch 88 of 100.
2023-01-05 07:44:36,545 INFO:   Done with stage: TRAINING
2023-01-05 07:44:36,545 INFO:   Starting stage: EVALUATION
2023-01-05 07:44:36,695 INFO:   Done with stage: EVALUATION
2023-01-05 07:44:36,695 INFO:   Leaving out SEQ value Fold_1
2023-01-05 07:44:36,708 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 07:44:36,708 INFO:   Starting stage: FEATURE SCALING
2023-01-05 07:44:37,370 INFO:   Done with stage: FEATURE SCALING
2023-01-05 07:44:37,370 INFO:   Starting stage: SCALING TARGETS
2023-01-05 07:44:37,440 INFO:   Done with stage: SCALING TARGETS
2023-01-05 07:44:37,440 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:44:37,440 INFO:     No hyperparam tuning for this model
2023-01-05 07:44:37,440 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:44:37,440 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 07:44:37,441 INFO:     None feature selector for col prot
2023-01-05 07:44:37,441 INFO:     None feature selector for col prot
2023-01-05 07:44:37,442 INFO:     None feature selector for col prot
2023-01-05 07:44:37,442 INFO:     None feature selector for col chem
2023-01-05 07:44:37,442 INFO:     None feature selector for col chem
2023-01-05 07:44:37,442 INFO:     None feature selector for col chem
2023-01-05 07:44:37,443 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 07:44:37,443 INFO:   Starting stage: BUILD MODEL
2023-01-05 07:44:37,444 INFO:     Number of params in model 72901
2023-01-05 07:44:37,447 INFO:   Done with stage: BUILD MODEL
2023-01-05 07:44:37,447 INFO:   Starting stage: TRAINING
2023-01-05 07:44:37,507 INFO:     Val loss before train {'Reaction outcome loss': 1.0821517030398051, 'Total loss': 1.0821517030398051}
2023-01-05 07:44:37,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:44:37,508 INFO:     Epoch: 0
2023-01-05 07:44:39,670 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8569504181543987, 'Total loss': 0.8569504181543987} | train loss {'Reaction outcome loss': 0.9198571477031362, 'Total loss': 0.9198571477031362}
2023-01-05 07:44:39,670 INFO:     Found new best model at epoch 0
2023-01-05 07:44:39,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:44:39,671 INFO:     Epoch: 1
2023-01-05 07:44:41,834 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6490552862485249, 'Total loss': 0.6490552862485249} | train loss {'Reaction outcome loss': 0.751048685706126, 'Total loss': 0.751048685706126}
2023-01-05 07:44:41,834 INFO:     Found new best model at epoch 1
2023-01-05 07:44:41,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:44:41,836 INFO:     Epoch: 2
2023-01-05 07:44:43,985 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5986069242159525, 'Total loss': 0.5986069242159525} | train loss {'Reaction outcome loss': 0.6142372994319253, 'Total loss': 0.6142372994319253}
2023-01-05 07:44:43,985 INFO:     Found new best model at epoch 2
2023-01-05 07:44:43,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:44:43,986 INFO:     Epoch: 3
2023-01-05 07:44:46,159 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5041770060857137, 'Total loss': 0.5041770060857137} | train loss {'Reaction outcome loss': 0.5531893235907984, 'Total loss': 0.5531893235907984}
2023-01-05 07:44:46,160 INFO:     Found new best model at epoch 3
2023-01-05 07:44:46,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:44:46,161 INFO:     Epoch: 4
2023-01-05 07:44:48,316 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5237189630667368, 'Total loss': 0.5237189630667368} | train loss {'Reaction outcome loss': 0.5265197828412056, 'Total loss': 0.5265197828412056}
2023-01-05 07:44:48,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:44:48,316 INFO:     Epoch: 5
2023-01-05 07:44:50,464 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.608816283941269, 'Total loss': 0.608816283941269} | train loss {'Reaction outcome loss': 0.5210826702523923, 'Total loss': 0.5210826702523923}
2023-01-05 07:44:50,464 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:44:50,464 INFO:     Epoch: 6
2023-01-05 07:44:52,613 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49088703791300453, 'Total loss': 0.49088703791300453} | train loss {'Reaction outcome loss': 0.5085922194192645, 'Total loss': 0.5085922194192645}
2023-01-05 07:44:52,614 INFO:     Found new best model at epoch 6
2023-01-05 07:44:52,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:44:52,615 INFO:     Epoch: 7
2023-01-05 07:44:54,763 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4792318999767303, 'Total loss': 0.4792318999767303} | train loss {'Reaction outcome loss': 0.49084677353950107, 'Total loss': 0.49084677353950107}
2023-01-05 07:44:54,763 INFO:     Found new best model at epoch 7
2023-01-05 07:44:54,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:44:54,765 INFO:     Epoch: 8
2023-01-05 07:44:56,931 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49097575147946676, 'Total loss': 0.49097575147946676} | train loss {'Reaction outcome loss': 0.4805571680279146, 'Total loss': 0.4805571680279146}
2023-01-05 07:44:56,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:44:56,931 INFO:     Epoch: 9
2023-01-05 07:44:59,141 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5062373260656993, 'Total loss': 0.5062373260656993} | train loss {'Reaction outcome loss': 0.47398102562980005, 'Total loss': 0.47398102562980005}
2023-01-05 07:44:59,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:44:59,141 INFO:     Epoch: 10
2023-01-05 07:45:01,348 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4890181303024292, 'Total loss': 0.4890181303024292} | train loss {'Reaction outcome loss': 0.4725217495073119, 'Total loss': 0.4725217495073119}
2023-01-05 07:45:01,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:45:01,348 INFO:     Epoch: 11
2023-01-05 07:45:03,539 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5313942203919093, 'Total loss': 0.5313942203919093} | train loss {'Reaction outcome loss': 0.47299442353887833, 'Total loss': 0.47299442353887833}
2023-01-05 07:45:03,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:45:03,540 INFO:     Epoch: 12
2023-01-05 07:45:05,745 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.46795675754547117, 'Total loss': 0.46795675754547117} | train loss {'Reaction outcome loss': 0.4741054342492767, 'Total loss': 0.4741054342492767}
2023-01-05 07:45:05,745 INFO:     Found new best model at epoch 12
2023-01-05 07:45:05,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:45:05,746 INFO:     Epoch: 13
2023-01-05 07:45:07,941 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4659785886605581, 'Total loss': 0.4659785886605581} | train loss {'Reaction outcome loss': 0.4619698936956516, 'Total loss': 0.4619698936956516}
2023-01-05 07:45:07,941 INFO:     Found new best model at epoch 13
2023-01-05 07:45:07,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:45:07,943 INFO:     Epoch: 14
2023-01-05 07:45:10,147 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4780973871548971, 'Total loss': 0.4780973871548971} | train loss {'Reaction outcome loss': 0.44993965629407245, 'Total loss': 0.44993965629407245}
2023-01-05 07:45:10,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:45:10,147 INFO:     Epoch: 15
2023-01-05 07:45:12,354 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48811765511830646, 'Total loss': 0.48811765511830646} | train loss {'Reaction outcome loss': 0.44798519068222115, 'Total loss': 0.44798519068222115}
2023-01-05 07:45:12,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:45:12,355 INFO:     Epoch: 16
2023-01-05 07:45:14,564 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49217215180397034, 'Total loss': 0.49217215180397034} | train loss {'Reaction outcome loss': 0.4486966414505319, 'Total loss': 0.4486966414505319}
2023-01-05 07:45:14,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:45:14,565 INFO:     Epoch: 17
2023-01-05 07:45:16,854 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4636711319287618, 'Total loss': 0.4636711319287618} | train loss {'Reaction outcome loss': 0.43972282847254607, 'Total loss': 0.43972282847254607}
2023-01-05 07:45:16,855 INFO:     Found new best model at epoch 17
2023-01-05 07:45:16,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:45:16,857 INFO:     Epoch: 18
2023-01-05 07:45:19,066 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47455649574597675, 'Total loss': 0.47455649574597675} | train loss {'Reaction outcome loss': 0.4376678572886664, 'Total loss': 0.4376678572886664}
2023-01-05 07:45:19,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:45:19,066 INFO:     Epoch: 19
2023-01-05 07:45:21,278 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.483232174317042, 'Total loss': 0.483232174317042} | train loss {'Reaction outcome loss': 0.43072961644898844, 'Total loss': 0.43072961644898844}
2023-01-05 07:45:21,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:45:21,278 INFO:     Epoch: 20
2023-01-05 07:45:23,502 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4459443251291911, 'Total loss': 0.4459443251291911} | train loss {'Reaction outcome loss': 0.43275820497649914, 'Total loss': 0.43275820497649914}
2023-01-05 07:45:23,503 INFO:     Found new best model at epoch 20
2023-01-05 07:45:23,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:45:23,504 INFO:     Epoch: 21
2023-01-05 07:45:25,724 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4901929954687754, 'Total loss': 0.4901929954687754} | train loss {'Reaction outcome loss': 0.4279768395581809, 'Total loss': 0.4279768395581809}
2023-01-05 07:45:25,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:45:25,725 INFO:     Epoch: 22
2023-01-05 07:45:27,908 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45853084822495777, 'Total loss': 0.45853084822495777} | train loss {'Reaction outcome loss': 0.42369417376609647, 'Total loss': 0.42369417376609647}
2023-01-05 07:45:27,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:45:27,909 INFO:     Epoch: 23
2023-01-05 07:45:30,097 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4588732649882635, 'Total loss': 0.4588732649882635} | train loss {'Reaction outcome loss': 0.41966991044877877, 'Total loss': 0.41966991044877877}
2023-01-05 07:45:30,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:45:30,098 INFO:     Epoch: 24
2023-01-05 07:45:32,287 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45687097708384194, 'Total loss': 0.45687097708384194} | train loss {'Reaction outcome loss': 0.4213686517061855, 'Total loss': 0.4213686517061855}
2023-01-05 07:45:32,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:45:32,287 INFO:     Epoch: 25
2023-01-05 07:45:34,495 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4586078405380249, 'Total loss': 0.4586078405380249} | train loss {'Reaction outcome loss': 0.41421997958810686, 'Total loss': 0.41421997958810686}
2023-01-05 07:45:34,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:45:34,495 INFO:     Epoch: 26
2023-01-05 07:45:36,702 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.479367862145106, 'Total loss': 0.479367862145106} | train loss {'Reaction outcome loss': 0.4120146050345679, 'Total loss': 0.4120146050345679}
2023-01-05 07:45:36,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:45:36,702 INFO:     Epoch: 27
2023-01-05 07:45:38,894 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4448690334955851, 'Total loss': 0.4448690334955851} | train loss {'Reaction outcome loss': 0.4057795267309184, 'Total loss': 0.4057795267309184}
2023-01-05 07:45:38,894 INFO:     Found new best model at epoch 27
2023-01-05 07:45:38,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:45:38,895 INFO:     Epoch: 28
2023-01-05 07:45:41,095 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46606669028600056, 'Total loss': 0.46606669028600056} | train loss {'Reaction outcome loss': 0.40398535257934226, 'Total loss': 0.40398535257934226}
2023-01-05 07:45:41,095 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:45:41,095 INFO:     Epoch: 29
2023-01-05 07:45:43,290 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4345318098862966, 'Total loss': 0.4345318098862966} | train loss {'Reaction outcome loss': 0.40638614962665376, 'Total loss': 0.40638614962665376}
2023-01-05 07:45:43,291 INFO:     Found new best model at epoch 29
2023-01-05 07:45:43,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:45:43,292 INFO:     Epoch: 30
2023-01-05 07:45:45,464 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4186177372932434, 'Total loss': 0.4186177372932434} | train loss {'Reaction outcome loss': 0.4042725872064179, 'Total loss': 0.4042725872064179}
2023-01-05 07:45:45,464 INFO:     Found new best model at epoch 30
2023-01-05 07:45:45,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:45:45,466 INFO:     Epoch: 31
2023-01-05 07:45:47,635 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.42015655686457953, 'Total loss': 0.42015655686457953} | train loss {'Reaction outcome loss': 0.40079270130482275, 'Total loss': 0.40079270130482275}
2023-01-05 07:45:47,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:45:47,635 INFO:     Epoch: 32
2023-01-05 07:45:49,789 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4627295106649399, 'Total loss': 0.4627295106649399} | train loss {'Reaction outcome loss': 0.42026361227935, 'Total loss': 0.42026361227935}
2023-01-05 07:45:49,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:45:49,789 INFO:     Epoch: 33
2023-01-05 07:45:51,959 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4466214964787165, 'Total loss': 0.4466214964787165} | train loss {'Reaction outcome loss': 0.39513736054346815, 'Total loss': 0.39513736054346815}
2023-01-05 07:45:51,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:45:51,959 INFO:     Epoch: 34
2023-01-05 07:45:54,129 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44295522272586824, 'Total loss': 0.44295522272586824} | train loss {'Reaction outcome loss': 0.39067638889495016, 'Total loss': 0.39067638889495016}
2023-01-05 07:45:54,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:45:54,130 INFO:     Epoch: 35
2023-01-05 07:45:56,322 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4314387897650401, 'Total loss': 0.4314387897650401} | train loss {'Reaction outcome loss': 0.4135159287029967, 'Total loss': 0.4135159287029967}
2023-01-05 07:45:56,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:45:56,322 INFO:     Epoch: 36
2023-01-05 07:45:58,496 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.40010697245597837, 'Total loss': 0.40010697245597837} | train loss {'Reaction outcome loss': 0.39022239954953175, 'Total loss': 0.39022239954953175}
2023-01-05 07:45:58,496 INFO:     Found new best model at epoch 36
2023-01-05 07:45:58,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:45:58,497 INFO:     Epoch: 37
2023-01-05 07:46:00,741 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4380699614683787, 'Total loss': 0.4380699614683787} | train loss {'Reaction outcome loss': 0.37612307024866587, 'Total loss': 0.37612307024866587}
2023-01-05 07:46:00,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:46:00,742 INFO:     Epoch: 38
2023-01-05 07:46:02,932 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4417428394158681, 'Total loss': 0.4417428394158681} | train loss {'Reaction outcome loss': 0.3748576301057229, 'Total loss': 0.3748576301057229}
2023-01-05 07:46:02,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:46:02,932 INFO:     Epoch: 39
2023-01-05 07:46:05,072 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42754639585812887, 'Total loss': 0.42754639585812887} | train loss {'Reaction outcome loss': 0.37573865366426035, 'Total loss': 0.37573865366426035}
2023-01-05 07:46:05,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:46:05,072 INFO:     Epoch: 40
2023-01-05 07:46:07,246 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.46778971155484517, 'Total loss': 0.46778971155484517} | train loss {'Reaction outcome loss': 0.36675050711863255, 'Total loss': 0.36675050711863255}
2023-01-05 07:46:07,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:46:07,246 INFO:     Epoch: 41
2023-01-05 07:46:09,399 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3913699179887772, 'Total loss': 0.3913699179887772} | train loss {'Reaction outcome loss': 0.36847476211108227, 'Total loss': 0.36847476211108227}
2023-01-05 07:46:09,400 INFO:     Found new best model at epoch 41
2023-01-05 07:46:09,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:46:09,401 INFO:     Epoch: 42
2023-01-05 07:46:11,552 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42278743982315065, 'Total loss': 0.42278743982315065} | train loss {'Reaction outcome loss': 0.3604125494687427, 'Total loss': 0.3604125494687427}
2023-01-05 07:46:11,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:46:11,553 INFO:     Epoch: 43
2023-01-05 07:46:13,696 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42337807913621267, 'Total loss': 0.42337807913621267} | train loss {'Reaction outcome loss': 0.35803689245485526, 'Total loss': 0.35803689245485526}
2023-01-05 07:46:13,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:46:13,697 INFO:     Epoch: 44
2023-01-05 07:46:15,860 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.41144132912158965, 'Total loss': 0.41144132912158965} | train loss {'Reaction outcome loss': 0.35462845917654573, 'Total loss': 0.35462845917654573}
2023-01-05 07:46:15,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:46:15,860 INFO:     Epoch: 45
2023-01-05 07:46:18,010 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4174003670612971, 'Total loss': 0.4174003670612971} | train loss {'Reaction outcome loss': 0.35932792038015643, 'Total loss': 0.35932792038015643}
2023-01-05 07:46:18,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:46:18,010 INFO:     Epoch: 46
2023-01-05 07:46:20,170 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44857075810432434, 'Total loss': 0.44857075810432434} | train loss {'Reaction outcome loss': 0.3554445159877988, 'Total loss': 0.3554445159877988}
2023-01-05 07:46:20,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:46:20,170 INFO:     Epoch: 47
2023-01-05 07:46:22,318 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42649755577246345, 'Total loss': 0.42649755577246345} | train loss {'Reaction outcome loss': 0.3568703093822452, 'Total loss': 0.3568703093822452}
2023-01-05 07:46:22,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:46:22,318 INFO:     Epoch: 48
2023-01-05 07:46:24,488 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43463321129481, 'Total loss': 0.43463321129481} | train loss {'Reaction outcome loss': 0.3432356941579517, 'Total loss': 0.3432356941579517}
2023-01-05 07:46:24,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:46:24,490 INFO:     Epoch: 49
2023-01-05 07:46:26,633 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4459170997142792, 'Total loss': 0.4459170997142792} | train loss {'Reaction outcome loss': 0.34103126353348023, 'Total loss': 0.34103126353348023}
2023-01-05 07:46:26,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:46:26,633 INFO:     Epoch: 50
2023-01-05 07:46:28,777 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43376823763052624, 'Total loss': 0.43376823763052624} | train loss {'Reaction outcome loss': 0.3466118138715409, 'Total loss': 0.3466118138715409}
2023-01-05 07:46:28,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:46:28,777 INFO:     Epoch: 51
2023-01-05 07:46:30,939 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.449148428440094, 'Total loss': 0.449148428440094} | train loss {'Reaction outcome loss': 0.3405742046180303, 'Total loss': 0.3405742046180303}
2023-01-05 07:46:30,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:46:30,940 INFO:     Epoch: 52
2023-01-05 07:46:33,100 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.42058461407820386, 'Total loss': 0.42058461407820386} | train loss {'Reaction outcome loss': 0.3354551771987209, 'Total loss': 0.3354551771987209}
2023-01-05 07:46:33,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:46:33,100 INFO:     Epoch: 53
2023-01-05 07:46:35,265 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43319418604175247, 'Total loss': 0.43319418604175247} | train loss {'Reaction outcome loss': 0.33419387960347574, 'Total loss': 0.33419387960347574}
2023-01-05 07:46:35,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:46:35,265 INFO:     Epoch: 54
2023-01-05 07:46:37,418 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4489842851956685, 'Total loss': 0.4489842851956685} | train loss {'Reaction outcome loss': 0.328712291184828, 'Total loss': 0.328712291184828}
2023-01-05 07:46:37,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:46:37,418 INFO:     Epoch: 55
2023-01-05 07:46:39,544 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43557567000389097, 'Total loss': 0.43557567000389097} | train loss {'Reaction outcome loss': 0.3250890038953925, 'Total loss': 0.3250890038953925}
2023-01-05 07:46:39,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:46:39,545 INFO:     Epoch: 56
2023-01-05 07:46:41,345 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4138563926021258, 'Total loss': 0.4138563926021258} | train loss {'Reaction outcome loss': 0.33461611628856347, 'Total loss': 0.33461611628856347}
2023-01-05 07:46:41,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:46:41,345 INFO:     Epoch: 57
2023-01-05 07:46:43,096 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40758746887246766, 'Total loss': 0.40758746887246766} | train loss {'Reaction outcome loss': 0.3406274563875859, 'Total loss': 0.3406274563875859}
2023-01-05 07:46:43,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:46:43,097 INFO:     Epoch: 58
2023-01-05 07:46:45,093 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.453843425710996, 'Total loss': 0.453843425710996} | train loss {'Reaction outcome loss': 0.3209261366185577, 'Total loss': 0.3209261366185577}
2023-01-05 07:46:45,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:46:45,093 INFO:     Epoch: 59
2023-01-05 07:46:47,246 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45553757548332213, 'Total loss': 0.45553757548332213} | train loss {'Reaction outcome loss': 0.3152188162683793, 'Total loss': 0.3152188162683793}
2023-01-05 07:46:47,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:46:47,246 INFO:     Epoch: 60
2023-01-05 07:46:49,396 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4267439117034276, 'Total loss': 0.4267439117034276} | train loss {'Reaction outcome loss': 0.33779437096276577, 'Total loss': 0.33779437096276577}
2023-01-05 07:46:49,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:46:49,397 INFO:     Epoch: 61
2023-01-05 07:46:51,556 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42090032796065013, 'Total loss': 0.42090032796065013} | train loss {'Reaction outcome loss': 0.3430784676709901, 'Total loss': 0.3430784676709901}
2023-01-05 07:46:51,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:46:51,557 INFO:     Epoch: 62
2023-01-05 07:46:53,710 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.44812221129735313, 'Total loss': 0.44812221129735313} | train loss {'Reaction outcome loss': 0.3367042648708288, 'Total loss': 0.3367042648708288}
2023-01-05 07:46:53,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:46:53,710 INFO:     Epoch: 63
2023-01-05 07:46:55,850 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4278229941924413, 'Total loss': 0.4278229941924413} | train loss {'Reaction outcome loss': 0.3072657827152938, 'Total loss': 0.3072657827152938}
2023-01-05 07:46:55,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:46:55,852 INFO:     Epoch: 64
2023-01-05 07:46:58,008 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43768873314062756, 'Total loss': 0.43768873314062756} | train loss {'Reaction outcome loss': 0.3058474390241115, 'Total loss': 0.3058474390241115}
2023-01-05 07:46:58,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:46:58,008 INFO:     Epoch: 65
2023-01-05 07:47:00,155 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41981471578280133, 'Total loss': 0.41981471578280133} | train loss {'Reaction outcome loss': 0.3053587526302326, 'Total loss': 0.3053587526302326}
2023-01-05 07:47:00,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:47:00,156 INFO:     Epoch: 66
2023-01-05 07:47:02,324 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4684249977270762, 'Total loss': 0.4684249977270762} | train loss {'Reaction outcome loss': 0.3074394064698962, 'Total loss': 0.3074394064698962}
2023-01-05 07:47:02,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:47:02,324 INFO:     Epoch: 67
2023-01-05 07:47:04,493 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3923646457493305, 'Total loss': 0.3923646457493305} | train loss {'Reaction outcome loss': 0.3116288452436203, 'Total loss': 0.3116288452436203}
2023-01-05 07:47:04,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:47:04,493 INFO:     Epoch: 68
2023-01-05 07:47:06,671 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.37788931131362913, 'Total loss': 0.37788931131362913} | train loss {'Reaction outcome loss': 0.29296831622132624, 'Total loss': 0.29296831622132624}
2023-01-05 07:47:06,671 INFO:     Found new best model at epoch 68
2023-01-05 07:47:06,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:47:06,672 INFO:     Epoch: 69
2023-01-05 07:47:08,838 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4337573111057281, 'Total loss': 0.4337573111057281} | train loss {'Reaction outcome loss': 0.29309214057782124, 'Total loss': 0.29309214057782124}
2023-01-05 07:47:08,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:47:08,839 INFO:     Epoch: 70
2023-01-05 07:47:10,998 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39315613607565564, 'Total loss': 0.39315613607565564} | train loss {'Reaction outcome loss': 0.2917521605563377, 'Total loss': 0.2917521605563377}
2023-01-05 07:47:10,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:47:10,998 INFO:     Epoch: 71
2023-01-05 07:47:13,175 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4603002488613129, 'Total loss': 0.4603002488613129} | train loss {'Reaction outcome loss': 0.29924683067002805, 'Total loss': 0.29924683067002805}
2023-01-05 07:47:13,175 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:47:13,175 INFO:     Epoch: 72
2023-01-05 07:47:15,346 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46792594293753303, 'Total loss': 0.46792594293753303} | train loss {'Reaction outcome loss': 0.35022235255498174, 'Total loss': 0.35022235255498174}
2023-01-05 07:47:15,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:47:15,347 INFO:     Epoch: 73
2023-01-05 07:47:17,516 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3978677133719126, 'Total loss': 0.3978677133719126} | train loss {'Reaction outcome loss': 0.3007598354146256, 'Total loss': 0.3007598354146256}
2023-01-05 07:47:17,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:47:17,516 INFO:     Epoch: 74
2023-01-05 07:47:19,668 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3693529158830643, 'Total loss': 0.3693529158830643} | train loss {'Reaction outcome loss': 0.29839153154044534, 'Total loss': 0.29839153154044534}
2023-01-05 07:47:19,668 INFO:     Found new best model at epoch 74
2023-01-05 07:47:19,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:47:19,670 INFO:     Epoch: 75
2023-01-05 07:47:21,836 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4094269622117281, 'Total loss': 0.4094269622117281} | train loss {'Reaction outcome loss': 0.28759048164795165, 'Total loss': 0.28759048164795165}
2023-01-05 07:47:21,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:47:21,837 INFO:     Epoch: 76
2023-01-05 07:47:23,993 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44394590655962624, 'Total loss': 0.44394590655962624} | train loss {'Reaction outcome loss': 0.28603217516124924, 'Total loss': 0.28603217516124924}
2023-01-05 07:47:23,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:47:23,993 INFO:     Epoch: 77
2023-01-05 07:47:26,159 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3732878799860676, 'Total loss': 0.3732878799860676} | train loss {'Reaction outcome loss': 0.28266400610943715, 'Total loss': 0.28266400610943715}
2023-01-05 07:47:26,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:47:26,159 INFO:     Epoch: 78
2023-01-05 07:47:28,339 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4157792657613754, 'Total loss': 0.4157792657613754} | train loss {'Reaction outcome loss': 0.2859917711142889, 'Total loss': 0.2859917711142889}
2023-01-05 07:47:28,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:47:28,339 INFO:     Epoch: 79
2023-01-05 07:47:30,503 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.37397466202576957, 'Total loss': 0.37397466202576957} | train loss {'Reaction outcome loss': 0.2791707972469537, 'Total loss': 0.2791707972469537}
2023-01-05 07:47:30,505 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:47:30,505 INFO:     Epoch: 80
2023-01-05 07:47:32,677 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4303897728522619, 'Total loss': 0.4303897728522619} | train loss {'Reaction outcome loss': 0.27392416575795336, 'Total loss': 0.27392416575795336}
2023-01-05 07:47:32,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:47:32,677 INFO:     Epoch: 81
2023-01-05 07:47:34,834 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3853394791483879, 'Total loss': 0.3853394791483879} | train loss {'Reaction outcome loss': 0.26993253478945733, 'Total loss': 0.26993253478945733}
2023-01-05 07:47:34,835 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:47:34,835 INFO:     Epoch: 82
2023-01-05 07:47:37,037 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.39982834955056507, 'Total loss': 0.39982834955056507} | train loss {'Reaction outcome loss': 0.27604963199195004, 'Total loss': 0.27604963199195004}
2023-01-05 07:47:37,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:47:37,038 INFO:     Epoch: 83
2023-01-05 07:47:39,199 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.409756064414978, 'Total loss': 0.409756064414978} | train loss {'Reaction outcome loss': 0.2785333332106255, 'Total loss': 0.2785333332106255}
2023-01-05 07:47:39,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:47:39,199 INFO:     Epoch: 84
2023-01-05 07:47:41,365 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42631460130214693, 'Total loss': 0.42631460130214693} | train loss {'Reaction outcome loss': 0.308363195248893, 'Total loss': 0.308363195248893}
2023-01-05 07:47:41,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:47:41,365 INFO:     Epoch: 85
2023-01-05 07:47:43,512 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42566289405028024, 'Total loss': 0.42566289405028024} | train loss {'Reaction outcome loss': 0.27585746367897274, 'Total loss': 0.27585746367897274}
2023-01-05 07:47:43,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:47:43,512 INFO:     Epoch: 86
2023-01-05 07:47:45,673 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4336233233412107, 'Total loss': 0.4336233233412107} | train loss {'Reaction outcome loss': 0.26901098597200884, 'Total loss': 0.26901098597200884}
2023-01-05 07:47:45,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:47:45,673 INFO:     Epoch: 87
2023-01-05 07:47:47,824 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42670753970742226, 'Total loss': 0.42670753970742226} | train loss {'Reaction outcome loss': 0.2712880773182985, 'Total loss': 0.2712880773182985}
2023-01-05 07:47:47,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:47:47,824 INFO:     Epoch: 88
2023-01-05 07:47:49,992 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41429271052281064, 'Total loss': 0.41429271052281064} | train loss {'Reaction outcome loss': 0.2673722995163242, 'Total loss': 0.2673722995163242}
2023-01-05 07:47:49,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:47:49,993 INFO:     Epoch: 89
2023-01-05 07:47:52,155 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4195865124464035, 'Total loss': 0.4195865124464035} | train loss {'Reaction outcome loss': 0.26352848881683516, 'Total loss': 0.26352848881683516}
2023-01-05 07:47:52,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:47:52,156 INFO:     Epoch: 90
2023-01-05 07:47:54,304 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44475811123847964, 'Total loss': 0.44475811123847964} | train loss {'Reaction outcome loss': 0.2737855360154872, 'Total loss': 0.2737855360154872}
2023-01-05 07:47:54,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:47:54,304 INFO:     Epoch: 91
2023-01-05 07:47:56,477 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41242220997810364, 'Total loss': 0.41242220997810364} | train loss {'Reaction outcome loss': 0.27965874926092615, 'Total loss': 0.27965874926092615}
2023-01-05 07:47:56,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:47:56,478 INFO:     Epoch: 92
2023-01-05 07:47:58,671 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4415270249048869, 'Total loss': 0.4415270249048869} | train loss {'Reaction outcome loss': 0.26559293006869045, 'Total loss': 0.26559293006869045}
2023-01-05 07:47:58,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:47:58,671 INFO:     Epoch: 93
2023-01-05 07:48:00,830 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4914406418800354, 'Total loss': 0.4914406418800354} | train loss {'Reaction outcome loss': 0.2645783300303383, 'Total loss': 0.2645783300303383}
2023-01-05 07:48:00,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:48:00,830 INFO:     Epoch: 94
2023-01-05 07:48:02,986 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4434454699357351, 'Total loss': 0.4434454699357351} | train loss {'Reaction outcome loss': 0.26905691565648804, 'Total loss': 0.26905691565648804}
2023-01-05 07:48:02,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:48:02,986 INFO:     Epoch: 95
2023-01-05 07:48:05,141 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4170383304357529, 'Total loss': 0.4170383304357529} | train loss {'Reaction outcome loss': 0.329983062886693, 'Total loss': 0.329983062886693}
2023-01-05 07:48:05,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:48:05,141 INFO:     Epoch: 96
2023-01-05 07:48:07,273 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4195862720410029, 'Total loss': 0.4195862720410029} | train loss {'Reaction outcome loss': 0.2686018785575668, 'Total loss': 0.2686018785575668}
2023-01-05 07:48:07,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:48:07,274 INFO:     Epoch: 97
2023-01-05 07:48:09,394 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41626106401284535, 'Total loss': 0.41626106401284535} | train loss {'Reaction outcome loss': 0.26170419458387606, 'Total loss': 0.26170419458387606}
2023-01-05 07:48:09,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:48:09,395 INFO:     Epoch: 98
2023-01-05 07:48:11,544 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4246764292319616, 'Total loss': 0.4246764292319616} | train loss {'Reaction outcome loss': 0.25428354959560395, 'Total loss': 0.25428354959560395}
2023-01-05 07:48:11,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:48:11,544 INFO:     Epoch: 99
2023-01-05 07:48:13,699 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43037099838256837, 'Total loss': 0.43037099838256837} | train loss {'Reaction outcome loss': 0.26880798504588305, 'Total loss': 0.26880798504588305}
2023-01-05 07:48:13,699 INFO:     Best model found after epoch 75 of 100.
2023-01-05 07:48:13,700 INFO:   Done with stage: TRAINING
2023-01-05 07:48:13,700 INFO:   Starting stage: EVALUATION
2023-01-05 07:48:13,832 INFO:   Done with stage: EVALUATION
2023-01-05 07:48:13,832 INFO:   Leaving out SEQ value Fold_2
2023-01-05 07:48:13,845 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 07:48:13,845 INFO:   Starting stage: FEATURE SCALING
2023-01-05 07:48:14,490 INFO:   Done with stage: FEATURE SCALING
2023-01-05 07:48:14,490 INFO:   Starting stage: SCALING TARGETS
2023-01-05 07:48:14,559 INFO:   Done with stage: SCALING TARGETS
2023-01-05 07:48:14,559 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:48:14,559 INFO:     No hyperparam tuning for this model
2023-01-05 07:48:14,559 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:48:14,559 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 07:48:14,560 INFO:     None feature selector for col prot
2023-01-05 07:48:14,560 INFO:     None feature selector for col prot
2023-01-05 07:48:14,560 INFO:     None feature selector for col prot
2023-01-05 07:48:14,560 INFO:     None feature selector for col chem
2023-01-05 07:48:14,560 INFO:     None feature selector for col chem
2023-01-05 07:48:14,560 INFO:     None feature selector for col chem
2023-01-05 07:48:14,560 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 07:48:14,561 INFO:   Starting stage: BUILD MODEL
2023-01-05 07:48:14,562 INFO:     Number of params in model 72901
2023-01-05 07:48:14,565 INFO:   Done with stage: BUILD MODEL
2023-01-05 07:48:14,565 INFO:   Starting stage: TRAINING
2023-01-05 07:48:14,626 INFO:     Val loss before train {'Reaction outcome loss': 1.1407243371009828, 'Total loss': 1.1407243371009828}
2023-01-05 07:48:14,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:48:14,627 INFO:     Epoch: 0
2023-01-05 07:48:16,760 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9347910841306051, 'Total loss': 0.9347910841306051} | train loss {'Reaction outcome loss': 0.9245303031736917, 'Total loss': 0.9245303031736917}
2023-01-05 07:48:16,760 INFO:     Found new best model at epoch 0
2023-01-05 07:48:16,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:48:16,761 INFO:     Epoch: 1
2023-01-05 07:48:18,905 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7337481220563252, 'Total loss': 0.7337481220563252} | train loss {'Reaction outcome loss': 0.7340802618839445, 'Total loss': 0.7340802618839445}
2023-01-05 07:48:18,905 INFO:     Found new best model at epoch 1
2023-01-05 07:48:18,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:48:18,907 INFO:     Epoch: 2
2023-01-05 07:48:21,020 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.616761040687561, 'Total loss': 0.616761040687561} | train loss {'Reaction outcome loss': 0.5665047708218985, 'Total loss': 0.5665047708218985}
2023-01-05 07:48:21,020 INFO:     Found new best model at epoch 2
2023-01-05 07:48:21,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:48:21,021 INFO:     Epoch: 3
2023-01-05 07:48:23,139 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5845995823542277, 'Total loss': 0.5845995823542277} | train loss {'Reaction outcome loss': 0.5294944680955288, 'Total loss': 0.5294944680955288}
2023-01-05 07:48:23,139 INFO:     Found new best model at epoch 3
2023-01-05 07:48:23,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:48:23,140 INFO:     Epoch: 4
2023-01-05 07:48:25,279 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5892423510551452, 'Total loss': 0.5892423510551452} | train loss {'Reaction outcome loss': 0.5097365066082808, 'Total loss': 0.5097365066082808}
2023-01-05 07:48:25,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:48:25,279 INFO:     Epoch: 5
2023-01-05 07:48:27,401 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5555523335933685, 'Total loss': 0.5555523335933685} | train loss {'Reaction outcome loss': 0.4985339542592529, 'Total loss': 0.4985339542592529}
2023-01-05 07:48:27,401 INFO:     Found new best model at epoch 5
2023-01-05 07:48:27,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:48:27,403 INFO:     Epoch: 6
2023-01-05 07:48:29,512 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5632372677326203, 'Total loss': 0.5632372677326203} | train loss {'Reaction outcome loss': 0.48599985742220914, 'Total loss': 0.48599985742220914}
2023-01-05 07:48:29,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:48:29,512 INFO:     Epoch: 7
2023-01-05 07:48:31,654 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5412572423617045, 'Total loss': 0.5412572423617045} | train loss {'Reaction outcome loss': 0.4806042772031178, 'Total loss': 0.4806042772031178}
2023-01-05 07:48:31,654 INFO:     Found new best model at epoch 7
2023-01-05 07:48:31,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:48:31,655 INFO:     Epoch: 8
2023-01-05 07:48:33,760 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5510210017363231, 'Total loss': 0.5510210017363231} | train loss {'Reaction outcome loss': 0.4753657923671451, 'Total loss': 0.4753657923671451}
2023-01-05 07:48:33,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:48:33,761 INFO:     Epoch: 9
2023-01-05 07:48:35,903 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5705738604068756, 'Total loss': 0.5705738604068756} | train loss {'Reaction outcome loss': 0.46853285919140725, 'Total loss': 0.46853285919140725}
2023-01-05 07:48:35,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:48:35,903 INFO:     Epoch: 10
2023-01-05 07:48:38,014 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5818851113319397, 'Total loss': 0.5818851113319397} | train loss {'Reaction outcome loss': 0.4658819918867445, 'Total loss': 0.4658819918867445}
2023-01-05 07:48:38,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:48:38,015 INFO:     Epoch: 11
2023-01-05 07:48:39,953 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5558954656124115, 'Total loss': 0.5558954656124115} | train loss {'Reaction outcome loss': 0.4627041305503706, 'Total loss': 0.4627041305503706}
2023-01-05 07:48:39,953 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:48:39,953 INFO:     Epoch: 12
2023-01-05 07:48:42,100 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5505223552385966, 'Total loss': 0.5505223552385966} | train loss {'Reaction outcome loss': 0.4558122347849999, 'Total loss': 0.4558122347849999}
2023-01-05 07:48:42,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:48:42,100 INFO:     Epoch: 13
2023-01-05 07:48:44,231 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5222129603226979, 'Total loss': 0.5222129603226979} | train loss {'Reaction outcome loss': 0.4485082073803366, 'Total loss': 0.4485082073803366}
2023-01-05 07:48:44,232 INFO:     Found new best model at epoch 13
2023-01-05 07:48:44,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:48:44,233 INFO:     Epoch: 14
2023-01-05 07:48:46,356 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5340394874413809, 'Total loss': 0.5340394874413809} | train loss {'Reaction outcome loss': 0.4437050566376343, 'Total loss': 0.4437050566376343}
2023-01-05 07:48:46,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:48:46,357 INFO:     Epoch: 15
2023-01-05 07:48:48,483 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5221477011839549, 'Total loss': 0.5221477011839549} | train loss {'Reaction outcome loss': 0.4413722773646786, 'Total loss': 0.4413722773646786}
2023-01-05 07:48:48,483 INFO:     Found new best model at epoch 15
2023-01-05 07:48:48,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:48:48,485 INFO:     Epoch: 16
2023-01-05 07:48:50,617 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5200579613447189, 'Total loss': 0.5200579613447189} | train loss {'Reaction outcome loss': 0.4411671490129763, 'Total loss': 0.4411671490129763}
2023-01-05 07:48:50,618 INFO:     Found new best model at epoch 16
2023-01-05 07:48:50,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:48:50,619 INFO:     Epoch: 17
2023-01-05 07:48:52,740 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5308327411611875, 'Total loss': 0.5308327411611875} | train loss {'Reaction outcome loss': 0.4284776945727585, 'Total loss': 0.4284776945727585}
2023-01-05 07:48:52,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:48:52,740 INFO:     Epoch: 18
2023-01-05 07:48:54,883 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5462145507335663, 'Total loss': 0.5462145507335663} | train loss {'Reaction outcome loss': 0.4316387967662002, 'Total loss': 0.4316387967662002}
2023-01-05 07:48:54,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:48:54,884 INFO:     Epoch: 19
2023-01-05 07:48:57,000 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5270511428515117, 'Total loss': 0.5270511428515117} | train loss {'Reaction outcome loss': 0.42855269059430073, 'Total loss': 0.42855269059430073}
2023-01-05 07:48:57,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:48:57,001 INFO:     Epoch: 20
2023-01-05 07:48:59,141 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5033297300338745, 'Total loss': 0.5033297300338745} | train loss {'Reaction outcome loss': 0.42317743080049536, 'Total loss': 0.42317743080049536}
2023-01-05 07:48:59,141 INFO:     Found new best model at epoch 20
2023-01-05 07:48:59,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:48:59,142 INFO:     Epoch: 21
2023-01-05 07:49:01,279 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5097850660483042, 'Total loss': 0.5097850660483042} | train loss {'Reaction outcome loss': 0.41630275112434023, 'Total loss': 0.41630275112434023}
2023-01-05 07:49:01,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:49:01,279 INFO:     Epoch: 22
2023-01-05 07:49:03,383 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5378858804702759, 'Total loss': 0.5378858804702759} | train loss {'Reaction outcome loss': 0.41338571242607425, 'Total loss': 0.41338571242607425}
2023-01-05 07:49:03,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:49:03,383 INFO:     Epoch: 23
2023-01-05 07:49:05,506 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5204513221979141, 'Total loss': 0.5204513221979141} | train loss {'Reaction outcome loss': 0.41315430016630755, 'Total loss': 0.41315430016630755}
2023-01-05 07:49:05,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:49:05,507 INFO:     Epoch: 24
2023-01-05 07:49:07,636 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.531702321767807, 'Total loss': 0.531702321767807} | train loss {'Reaction outcome loss': 0.4078725653353834, 'Total loss': 0.4078725653353834}
2023-01-05 07:49:07,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:49:07,637 INFO:     Epoch: 25
2023-01-05 07:49:09,762 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5388009150822958, 'Total loss': 0.5388009150822958} | train loss {'Reaction outcome loss': 0.4031573486154097, 'Total loss': 0.4031573486154097}
2023-01-05 07:49:09,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:49:09,762 INFO:     Epoch: 26
2023-01-05 07:49:11,903 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5448511908451716, 'Total loss': 0.5448511908451716} | train loss {'Reaction outcome loss': 0.40366701743681066, 'Total loss': 0.40366701743681066}
2023-01-05 07:49:11,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:49:11,903 INFO:     Epoch: 27
2023-01-05 07:49:14,064 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.49290662407875063, 'Total loss': 0.49290662407875063} | train loss {'Reaction outcome loss': 0.3982333292382477, 'Total loss': 0.3982333292382477}
2023-01-05 07:49:14,065 INFO:     Found new best model at epoch 27
2023-01-05 07:49:14,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:49:14,066 INFO:     Epoch: 28
2023-01-05 07:49:16,204 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5017879009246826, 'Total loss': 0.5017879009246826} | train loss {'Reaction outcome loss': 0.3892209783033298, 'Total loss': 0.3892209783033298}
2023-01-05 07:49:16,204 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:49:16,204 INFO:     Epoch: 29
2023-01-05 07:49:18,364 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5369980752468109, 'Total loss': 0.5369980752468109} | train loss {'Reaction outcome loss': 0.39198994932927356, 'Total loss': 0.39198994932927356}
2023-01-05 07:49:18,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:49:18,364 INFO:     Epoch: 30
2023-01-05 07:49:20,512 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5255310436089834, 'Total loss': 0.5255310436089834} | train loss {'Reaction outcome loss': 0.3860762056479924, 'Total loss': 0.3860762056479924}
2023-01-05 07:49:20,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:49:20,512 INFO:     Epoch: 31
2023-01-05 07:49:22,675 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5275723139444987, 'Total loss': 0.5275723139444987} | train loss {'Reaction outcome loss': 0.38166705176343013, 'Total loss': 0.38166705176343013}
2023-01-05 07:49:22,676 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:49:22,676 INFO:     Epoch: 32
2023-01-05 07:49:24,832 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5345309456189473, 'Total loss': 0.5345309456189473} | train loss {'Reaction outcome loss': 0.3716799465898615, 'Total loss': 0.3716799465898615}
2023-01-05 07:49:24,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:49:24,832 INFO:     Epoch: 33
2023-01-05 07:49:26,974 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5206480592489242, 'Total loss': 0.5206480592489242} | train loss {'Reaction outcome loss': 0.3713635659239588, 'Total loss': 0.3713635659239588}
2023-01-05 07:49:26,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:49:26,975 INFO:     Epoch: 34
2023-01-05 07:49:29,125 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5280361572901408, 'Total loss': 0.5280361572901408} | train loss {'Reaction outcome loss': 0.37295455382253134, 'Total loss': 0.37295455382253134}
2023-01-05 07:49:29,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:49:29,126 INFO:     Epoch: 35
2023-01-05 07:49:31,247 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5102317810058594, 'Total loss': 0.5102317810058594} | train loss {'Reaction outcome loss': 0.37029864478611596, 'Total loss': 0.37029864478611596}
2023-01-05 07:49:31,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:49:31,247 INFO:     Epoch: 36
2023-01-05 07:49:33,407 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.521464882294337, 'Total loss': 0.521464882294337} | train loss {'Reaction outcome loss': 0.36280153387219366, 'Total loss': 0.36280153387219366}
2023-01-05 07:49:33,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:49:33,408 INFO:     Epoch: 37
2023-01-05 07:49:35,556 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5062111218770345, 'Total loss': 0.5062111218770345} | train loss {'Reaction outcome loss': 0.36506075164588697, 'Total loss': 0.36506075164588697}
2023-01-05 07:49:35,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:49:35,556 INFO:     Epoch: 38
2023-01-05 07:49:37,693 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5071930517752965, 'Total loss': 0.5071930517752965} | train loss {'Reaction outcome loss': 0.36316583811366643, 'Total loss': 0.36316583811366643}
2023-01-05 07:49:37,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:49:37,694 INFO:     Epoch: 39
2023-01-05 07:49:39,840 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5058239678541819, 'Total loss': 0.5058239678541819} | train loss {'Reaction outcome loss': 0.3556146602397853, 'Total loss': 0.3556146602397853}
2023-01-05 07:49:39,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:49:39,840 INFO:     Epoch: 40
2023-01-05 07:49:41,988 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5152331839005152, 'Total loss': 0.5152331839005152} | train loss {'Reaction outcome loss': 0.3577260389434595, 'Total loss': 0.3577260389434595}
2023-01-05 07:49:41,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:49:41,989 INFO:     Epoch: 41
2023-01-05 07:49:44,138 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5331456462542216, 'Total loss': 0.5331456462542216} | train loss {'Reaction outcome loss': 0.34994275071216324, 'Total loss': 0.34994275071216324}
2023-01-05 07:49:44,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:49:44,139 INFO:     Epoch: 42
2023-01-05 07:49:46,295 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5224644372860591, 'Total loss': 0.5224644372860591} | train loss {'Reaction outcome loss': 0.35083694489890316, 'Total loss': 0.35083694489890316}
2023-01-05 07:49:46,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:49:46,295 INFO:     Epoch: 43
2023-01-05 07:49:48,441 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4816814283529917, 'Total loss': 0.4816814283529917} | train loss {'Reaction outcome loss': 0.3402261768678462, 'Total loss': 0.3402261768678462}
2023-01-05 07:49:48,442 INFO:     Found new best model at epoch 43
2023-01-05 07:49:48,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:49:48,443 INFO:     Epoch: 44
2023-01-05 07:49:50,562 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4874311337868373, 'Total loss': 0.4874311337868373} | train loss {'Reaction outcome loss': 0.3416850348920935, 'Total loss': 0.3416850348920935}
2023-01-05 07:49:50,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:49:50,563 INFO:     Epoch: 45
2023-01-05 07:49:52,710 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5166948358217875, 'Total loss': 0.5166948358217875} | train loss {'Reaction outcome loss': 0.33507303270871625, 'Total loss': 0.33507303270871625}
2023-01-05 07:49:52,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:49:52,710 INFO:     Epoch: 46
2023-01-05 07:49:54,860 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.49608636697133385, 'Total loss': 0.49608636697133385} | train loss {'Reaction outcome loss': 0.33752569091254775, 'Total loss': 0.33752569091254775}
2023-01-05 07:49:54,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:49:54,860 INFO:     Epoch: 47
2023-01-05 07:49:57,015 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5052640795707702, 'Total loss': 0.5052640795707702} | train loss {'Reaction outcome loss': 0.3351057112815171, 'Total loss': 0.3351057112815171}
2023-01-05 07:49:57,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:49:57,015 INFO:     Epoch: 48
2023-01-05 07:49:59,168 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.47607352236906686, 'Total loss': 0.47607352236906686} | train loss {'Reaction outcome loss': 0.33181650109969785, 'Total loss': 0.33181650109969785}
2023-01-05 07:49:59,168 INFO:     Found new best model at epoch 48
2023-01-05 07:49:59,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:49:59,169 INFO:     Epoch: 49
2023-01-05 07:50:01,317 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.513120194276174, 'Total loss': 0.513120194276174} | train loss {'Reaction outcome loss': 0.3310404518061746, 'Total loss': 0.3310404518061746}
2023-01-05 07:50:01,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:50:01,317 INFO:     Epoch: 50
2023-01-05 07:50:03,471 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4958217372496923, 'Total loss': 0.4958217372496923} | train loss {'Reaction outcome loss': 0.3263423261198684, 'Total loss': 0.3263423261198684}
2023-01-05 07:50:03,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:50:03,471 INFO:     Epoch: 51
2023-01-05 07:50:05,622 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5173739155133565, 'Total loss': 0.5173739155133565} | train loss {'Reaction outcome loss': 0.3168510605927801, 'Total loss': 0.3168510605927801}
2023-01-05 07:50:05,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:50:05,622 INFO:     Epoch: 52
2023-01-05 07:50:07,771 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4935360312461853, 'Total loss': 0.4935360312461853} | train loss {'Reaction outcome loss': 0.3137217973134596, 'Total loss': 0.3137217973134596}
2023-01-05 07:50:07,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:50:07,771 INFO:     Epoch: 53
2023-01-05 07:50:09,928 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5043548204004764, 'Total loss': 0.5043548204004764} | train loss {'Reaction outcome loss': 0.3210519874726769, 'Total loss': 0.3210519874726769}
2023-01-05 07:50:09,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:50:09,928 INFO:     Epoch: 54
2023-01-05 07:50:12,098 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5248109747966131, 'Total loss': 0.5248109747966131} | train loss {'Reaction outcome loss': 0.313385605200255, 'Total loss': 0.313385605200255}
2023-01-05 07:50:12,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:50:12,099 INFO:     Epoch: 55
2023-01-05 07:50:14,245 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.515245662132899, 'Total loss': 0.515245662132899} | train loss {'Reaction outcome loss': 0.3057639712100699, 'Total loss': 0.3057639712100699}
2023-01-05 07:50:14,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:50:14,246 INFO:     Epoch: 56
2023-01-05 07:50:16,385 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5232232888539632, 'Total loss': 0.5232232888539632} | train loss {'Reaction outcome loss': 0.30195380172209585, 'Total loss': 0.30195380172209585}
2023-01-05 07:50:16,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:50:16,386 INFO:     Epoch: 57
2023-01-05 07:50:18,514 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.5623725126187007, 'Total loss': 0.5623725126187007} | train loss {'Reaction outcome loss': 0.3064304271536152, 'Total loss': 0.3064304271536152}
2023-01-05 07:50:18,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:50:18,514 INFO:     Epoch: 58
2023-01-05 07:50:20,668 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47639597455660504, 'Total loss': 0.47639597455660504} | train loss {'Reaction outcome loss': 0.303514889597784, 'Total loss': 0.303514889597784}
2023-01-05 07:50:20,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:50:20,668 INFO:     Epoch: 59
2023-01-05 07:50:22,815 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5270114034414292, 'Total loss': 0.5270114034414292} | train loss {'Reaction outcome loss': 0.3027751511778601, 'Total loss': 0.3027751511778601}
2023-01-05 07:50:22,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:50:22,815 INFO:     Epoch: 60
2023-01-05 07:50:24,947 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5653980573018392, 'Total loss': 0.5653980573018392} | train loss {'Reaction outcome loss': 0.2940612195916202, 'Total loss': 0.2940612195916202}
2023-01-05 07:50:24,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:50:24,947 INFO:     Epoch: 61
2023-01-05 07:50:27,093 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4876427767177423, 'Total loss': 0.4876427767177423} | train loss {'Reaction outcome loss': 0.30005943612025604, 'Total loss': 0.30005943612025604}
2023-01-05 07:50:27,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:50:27,093 INFO:     Epoch: 62
2023-01-05 07:50:29,234 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4973423004150391, 'Total loss': 0.4973423004150391} | train loss {'Reaction outcome loss': 0.3031061618813198, 'Total loss': 0.3031061618813198}
2023-01-05 07:50:29,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:50:29,234 INFO:     Epoch: 63
2023-01-05 07:50:31,362 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.49302555819352467, 'Total loss': 0.49302555819352467} | train loss {'Reaction outcome loss': 0.2974267404417705, 'Total loss': 0.2974267404417705}
2023-01-05 07:50:31,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:50:31,362 INFO:     Epoch: 64
2023-01-05 07:50:33,494 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4702060177922249, 'Total loss': 0.4702060177922249} | train loss {'Reaction outcome loss': 0.2876716222627646, 'Total loss': 0.2876716222627646}
2023-01-05 07:50:33,495 INFO:     Found new best model at epoch 64
2023-01-05 07:50:33,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:50:33,496 INFO:     Epoch: 65
2023-01-05 07:50:35,630 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5077694197495778, 'Total loss': 0.5077694197495778} | train loss {'Reaction outcome loss': 0.2826692707306386, 'Total loss': 0.2826692707306386}
2023-01-05 07:50:35,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:50:35,630 INFO:     Epoch: 66
2023-01-05 07:50:37,764 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.491762504975001, 'Total loss': 0.491762504975001} | train loss {'Reaction outcome loss': 0.28876945611606114, 'Total loss': 0.28876945611606114}
2023-01-05 07:50:37,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:50:37,764 INFO:     Epoch: 67
2023-01-05 07:50:39,918 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49763648013273876, 'Total loss': 0.49763648013273876} | train loss {'Reaction outcome loss': 0.2883389856815882, 'Total loss': 0.2883389856815882}
2023-01-05 07:50:39,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:50:39,918 INFO:     Epoch: 68
2023-01-05 07:50:42,046 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46130574444929756, 'Total loss': 0.46130574444929756} | train loss {'Reaction outcome loss': 0.2889556802374168, 'Total loss': 0.2889556802374168}
2023-01-05 07:50:42,047 INFO:     Found new best model at epoch 68
2023-01-05 07:50:42,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:50:42,048 INFO:     Epoch: 69
2023-01-05 07:50:44,208 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.47997108300526936, 'Total loss': 0.47997108300526936} | train loss {'Reaction outcome loss': 0.28856022593422526, 'Total loss': 0.28856022593422526}
2023-01-05 07:50:44,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:50:44,208 INFO:     Epoch: 70
2023-01-05 07:50:46,368 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4790790279706319, 'Total loss': 0.4790790279706319} | train loss {'Reaction outcome loss': 0.27682359171283505, 'Total loss': 0.27682359171283505}
2023-01-05 07:50:46,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:50:46,368 INFO:     Epoch: 71
2023-01-05 07:50:48,508 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.49989250153303144, 'Total loss': 0.49989250153303144} | train loss {'Reaction outcome loss': 0.27889668507786997, 'Total loss': 0.27889668507786997}
2023-01-05 07:50:48,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:50:48,509 INFO:     Epoch: 72
2023-01-05 07:50:50,645 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5318211595217387, 'Total loss': 0.5318211595217387} | train loss {'Reaction outcome loss': 0.2732659039175967, 'Total loss': 0.2732659039175967}
2023-01-05 07:50:50,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:50:50,646 INFO:     Epoch: 73
2023-01-05 07:50:52,790 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45411966840426127, 'Total loss': 0.45411966840426127} | train loss {'Reaction outcome loss': 0.2724597531296041, 'Total loss': 0.2724597531296041}
2023-01-05 07:50:52,791 INFO:     Found new best model at epoch 73
2023-01-05 07:50:52,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:50:52,792 INFO:     Epoch: 74
2023-01-05 07:50:54,933 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5075903137524923, 'Total loss': 0.5075903137524923} | train loss {'Reaction outcome loss': 0.27382600110323324, 'Total loss': 0.27382600110323324}
2023-01-05 07:50:54,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:50:54,933 INFO:     Epoch: 75
2023-01-05 07:50:57,083 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48874483903249105, 'Total loss': 0.48874483903249105} | train loss {'Reaction outcome loss': 0.2662423532048281, 'Total loss': 0.2662423532048281}
2023-01-05 07:50:57,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:50:57,084 INFO:     Epoch: 76
2023-01-05 07:50:59,229 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4782854864994685, 'Total loss': 0.4782854864994685} | train loss {'Reaction outcome loss': 0.2714955842081648, 'Total loss': 0.2714955842081648}
2023-01-05 07:50:59,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:50:59,229 INFO:     Epoch: 77
2023-01-05 07:51:01,378 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47760998606681826, 'Total loss': 0.47760998606681826} | train loss {'Reaction outcome loss': 0.2696565403365088, 'Total loss': 0.2696565403365088}
2023-01-05 07:51:01,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:51:01,378 INFO:     Epoch: 78
2023-01-05 07:51:03,520 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.46325240433216097, 'Total loss': 0.46325240433216097} | train loss {'Reaction outcome loss': 0.26873783901143466, 'Total loss': 0.26873783901143466}
2023-01-05 07:51:03,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:51:03,520 INFO:     Epoch: 79
2023-01-05 07:51:05,647 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45990089972813925, 'Total loss': 0.45990089972813925} | train loss {'Reaction outcome loss': 0.2615191434802365, 'Total loss': 0.2615191434802365}
2023-01-05 07:51:05,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:51:05,647 INFO:     Epoch: 80
2023-01-05 07:51:07,796 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5225314646959305, 'Total loss': 0.5225314646959305} | train loss {'Reaction outcome loss': 0.2638178650344158, 'Total loss': 0.2638178650344158}
2023-01-05 07:51:07,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:51:07,796 INFO:     Epoch: 81
2023-01-05 07:51:09,936 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.49992862592140835, 'Total loss': 0.49992862592140835} | train loss {'Reaction outcome loss': 0.26455486302066894, 'Total loss': 0.26455486302066894}
2023-01-05 07:51:09,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:51:09,937 INFO:     Epoch: 82
2023-01-05 07:51:12,052 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4714718610048294, 'Total loss': 0.4714718610048294} | train loss {'Reaction outcome loss': 0.2574595682268595, 'Total loss': 0.2574595682268595}
2023-01-05 07:51:12,052 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:51:12,052 INFO:     Epoch: 83
2023-01-05 07:51:14,199 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.45384108026822406, 'Total loss': 0.45384108026822406} | train loss {'Reaction outcome loss': 0.2605275374830422, 'Total loss': 0.2605275374830422}
2023-01-05 07:51:14,200 INFO:     Found new best model at epoch 83
2023-01-05 07:51:14,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:51:14,201 INFO:     Epoch: 84
2023-01-05 07:51:16,347 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5033231255908807, 'Total loss': 0.5033231255908807} | train loss {'Reaction outcome loss': 0.26897795280835923, 'Total loss': 0.26897795280835923}
2023-01-05 07:51:16,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:51:16,348 INFO:     Epoch: 85
2023-01-05 07:51:18,476 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4578760117292404, 'Total loss': 0.4578760117292404} | train loss {'Reaction outcome loss': 0.25763180204089325, 'Total loss': 0.25763180204089325}
2023-01-05 07:51:18,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:51:18,477 INFO:     Epoch: 86
2023-01-05 07:51:20,626 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.538845936457316, 'Total loss': 0.538845936457316} | train loss {'Reaction outcome loss': 0.2519869685689681, 'Total loss': 0.2519869685689681}
2023-01-05 07:51:20,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:51:20,627 INFO:     Epoch: 87
2023-01-05 07:51:22,762 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46367454081773757, 'Total loss': 0.46367454081773757} | train loss {'Reaction outcome loss': 0.2553853024830566, 'Total loss': 0.2553853024830566}
2023-01-05 07:51:22,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:51:22,763 INFO:     Epoch: 88
2023-01-05 07:51:24,913 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.45918961316347123, 'Total loss': 0.45918961316347123} | train loss {'Reaction outcome loss': 0.26214874650005004, 'Total loss': 0.26214874650005004}
2023-01-05 07:51:24,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:51:24,913 INFO:     Epoch: 89
2023-01-05 07:51:27,057 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4753551185131073, 'Total loss': 0.4753551185131073} | train loss {'Reaction outcome loss': 0.25113561582907923, 'Total loss': 0.25113561582907923}
2023-01-05 07:51:27,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:51:27,058 INFO:     Epoch: 90
2023-01-05 07:51:29,187 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5392249325911204, 'Total loss': 0.5392249325911204} | train loss {'Reaction outcome loss': 0.24693789066624466, 'Total loss': 0.24693789066624466}
2023-01-05 07:51:29,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:51:29,187 INFO:     Epoch: 91
2023-01-05 07:51:31,335 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4769498964150747, 'Total loss': 0.4769498964150747} | train loss {'Reaction outcome loss': 0.25610689489837113, 'Total loss': 0.25610689489837113}
2023-01-05 07:51:31,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:51:31,335 INFO:     Epoch: 92
2023-01-05 07:51:33,473 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5011411845684052, 'Total loss': 0.5011411845684052} | train loss {'Reaction outcome loss': 0.24136316089000362, 'Total loss': 0.24136316089000362}
2023-01-05 07:51:33,473 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:51:33,473 INFO:     Epoch: 93
2023-01-05 07:51:35,589 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4603770951430003, 'Total loss': 0.4603770951430003} | train loss {'Reaction outcome loss': 0.24630073024245508, 'Total loss': 0.24630073024245508}
2023-01-05 07:51:35,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:51:35,590 INFO:     Epoch: 94
2023-01-05 07:51:37,740 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5002285758654277, 'Total loss': 0.5002285758654277} | train loss {'Reaction outcome loss': 0.2508153109097459, 'Total loss': 0.2508153109097459}
2023-01-05 07:51:37,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:51:37,740 INFO:     Epoch: 95
2023-01-05 07:51:39,894 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.515595476826032, 'Total loss': 0.515595476826032} | train loss {'Reaction outcome loss': 0.24466454018124917, 'Total loss': 0.24466454018124917}
2023-01-05 07:51:39,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:51:39,895 INFO:     Epoch: 96
2023-01-05 07:51:42,035 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5180607477823893, 'Total loss': 0.5180607477823893} | train loss {'Reaction outcome loss': 0.24392691953447612, 'Total loss': 0.24392691953447612}
2023-01-05 07:51:42,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:51:42,036 INFO:     Epoch: 97
2023-01-05 07:51:44,183 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.48493319700161613, 'Total loss': 0.48493319700161613} | train loss {'Reaction outcome loss': 0.23952697069268591, 'Total loss': 0.23952697069268591}
2023-01-05 07:51:44,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:51:44,184 INFO:     Epoch: 98
2023-01-05 07:51:46,310 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48431712786356607, 'Total loss': 0.48431712786356607} | train loss {'Reaction outcome loss': 0.23815581492100754, 'Total loss': 0.23815581492100754}
2023-01-05 07:51:46,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:51:46,310 INFO:     Epoch: 99
2023-01-05 07:51:48,453 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4770506312449773, 'Total loss': 0.4770506312449773} | train loss {'Reaction outcome loss': 0.24642042887743806, 'Total loss': 0.24642042887743806}
2023-01-05 07:51:48,453 INFO:     Best model found after epoch 84 of 100.
2023-01-05 07:51:48,453 INFO:   Done with stage: TRAINING
2023-01-05 07:51:48,453 INFO:   Starting stage: EVALUATION
2023-01-05 07:51:48,592 INFO:   Done with stage: EVALUATION
2023-01-05 07:51:48,592 INFO:   Leaving out SEQ value Fold_3
2023-01-05 07:51:48,605 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 07:51:48,605 INFO:   Starting stage: FEATURE SCALING
2023-01-05 07:51:49,258 INFO:   Done with stage: FEATURE SCALING
2023-01-05 07:51:49,259 INFO:   Starting stage: SCALING TARGETS
2023-01-05 07:51:49,327 INFO:   Done with stage: SCALING TARGETS
2023-01-05 07:51:49,328 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:51:49,328 INFO:     No hyperparam tuning for this model
2023-01-05 07:51:49,328 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:51:49,328 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 07:51:49,328 INFO:     None feature selector for col prot
2023-01-05 07:51:49,329 INFO:     None feature selector for col prot
2023-01-05 07:51:49,329 INFO:     None feature selector for col prot
2023-01-05 07:51:49,329 INFO:     None feature selector for col chem
2023-01-05 07:51:49,329 INFO:     None feature selector for col chem
2023-01-05 07:51:49,329 INFO:     None feature selector for col chem
2023-01-05 07:51:49,329 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 07:51:49,330 INFO:   Starting stage: BUILD MODEL
2023-01-05 07:51:49,331 INFO:     Number of params in model 72901
2023-01-05 07:51:49,334 INFO:   Done with stage: BUILD MODEL
2023-01-05 07:51:49,334 INFO:   Starting stage: TRAINING
2023-01-05 07:51:49,393 INFO:     Val loss before train {'Reaction outcome loss': 0.9455950488646825, 'Total loss': 0.9455950488646825}
2023-01-05 07:51:49,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:51:49,393 INFO:     Epoch: 0
2023-01-05 07:51:51,515 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8338825066884359, 'Total loss': 0.8338825066884359} | train loss {'Reaction outcome loss': 0.9312185057790288, 'Total loss': 0.9312185057790288}
2023-01-05 07:51:51,515 INFO:     Found new best model at epoch 0
2023-01-05 07:51:51,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:51:51,516 INFO:     Epoch: 1
2023-01-05 07:51:53,620 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5991823434829712, 'Total loss': 0.5991823434829712} | train loss {'Reaction outcome loss': 0.7108232184644148, 'Total loss': 0.7108232184644148}
2023-01-05 07:51:53,621 INFO:     Found new best model at epoch 1
2023-01-05 07:51:53,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:51:53,622 INFO:     Epoch: 2
2023-01-05 07:51:55,757 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5795585354169209, 'Total loss': 0.5795585354169209} | train loss {'Reaction outcome loss': 0.5692301154573322, 'Total loss': 0.5692301154573322}
2023-01-05 07:51:55,757 INFO:     Found new best model at epoch 2
2023-01-05 07:51:55,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:51:55,758 INFO:     Epoch: 3
2023-01-05 07:51:57,879 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5669664541880289, 'Total loss': 0.5669664541880289} | train loss {'Reaction outcome loss': 0.525644736958074, 'Total loss': 0.525644736958074}
2023-01-05 07:51:57,880 INFO:     Found new best model at epoch 3
2023-01-05 07:51:57,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:51:57,882 INFO:     Epoch: 4
2023-01-05 07:52:00,001 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5067102938890458, 'Total loss': 0.5067102938890458} | train loss {'Reaction outcome loss': 0.5061953686205022, 'Total loss': 0.5061953686205022}
2023-01-05 07:52:00,001 INFO:     Found new best model at epoch 4
2023-01-05 07:52:00,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:52:00,002 INFO:     Epoch: 5
2023-01-05 07:52:02,137 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5378658264875412, 'Total loss': 0.5378658264875412} | train loss {'Reaction outcome loss': 0.49634246397149434, 'Total loss': 0.49634246397149434}
2023-01-05 07:52:02,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:52:02,137 INFO:     Epoch: 6
2023-01-05 07:52:04,252 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49432163635889687, 'Total loss': 0.49432163635889687} | train loss {'Reaction outcome loss': 0.48215734008904343, 'Total loss': 0.48215734008904343}
2023-01-05 07:52:04,252 INFO:     Found new best model at epoch 6
2023-01-05 07:52:04,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:52:04,254 INFO:     Epoch: 7
2023-01-05 07:52:06,382 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5392668962478637, 'Total loss': 0.5392668962478637} | train loss {'Reaction outcome loss': 0.4783173938701441, 'Total loss': 0.4783173938701441}
2023-01-05 07:52:06,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:52:06,382 INFO:     Epoch: 8
2023-01-05 07:52:08,524 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5222205460071564, 'Total loss': 0.5222205460071564} | train loss {'Reaction outcome loss': 0.4711225526782619, 'Total loss': 0.4711225526782619}
2023-01-05 07:52:08,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:52:08,524 INFO:     Epoch: 9
2023-01-05 07:52:10,635 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5178079903125763, 'Total loss': 0.5178079903125763} | train loss {'Reaction outcome loss': 0.46112899564124726, 'Total loss': 0.46112899564124726}
2023-01-05 07:52:10,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:52:10,636 INFO:     Epoch: 10
2023-01-05 07:52:12,759 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5129811684290568, 'Total loss': 0.5129811684290568} | train loss {'Reaction outcome loss': 0.46157643351799404, 'Total loss': 0.46157643351799404}
2023-01-05 07:52:12,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:52:12,759 INFO:     Epoch: 11
2023-01-05 07:52:14,890 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5298229058583578, 'Total loss': 0.5298229058583578} | train loss {'Reaction outcome loss': 0.4572717078548648, 'Total loss': 0.4572717078548648}
2023-01-05 07:52:14,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:52:14,890 INFO:     Epoch: 12
2023-01-05 07:52:17,014 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5257814526557922, 'Total loss': 0.5257814526557922} | train loss {'Reaction outcome loss': 0.4494709433107586, 'Total loss': 0.4494709433107586}
2023-01-05 07:52:17,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:52:17,015 INFO:     Epoch: 13
2023-01-05 07:52:19,151 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49617802699406943, 'Total loss': 0.49617802699406943} | train loss {'Reaction outcome loss': 0.4421084534612249, 'Total loss': 0.4421084534612249}
2023-01-05 07:52:19,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:52:19,151 INFO:     Epoch: 14
2023-01-05 07:52:21,275 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5203681369622548, 'Total loss': 0.5203681369622548} | train loss {'Reaction outcome loss': 0.4422541971935894, 'Total loss': 0.4422541971935894}
2023-01-05 07:52:21,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:52:21,275 INFO:     Epoch: 15
2023-01-05 07:52:23,418 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5192526370286942, 'Total loss': 0.5192526370286942} | train loss {'Reaction outcome loss': 0.4389427594103656, 'Total loss': 0.4389427594103656}
2023-01-05 07:52:23,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:52:23,418 INFO:     Epoch: 16
2023-01-05 07:52:25,561 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5049167255560557, 'Total loss': 0.5049167255560557} | train loss {'Reaction outcome loss': 0.4335641615338378, 'Total loss': 0.4335641615338378}
2023-01-05 07:52:25,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:52:25,561 INFO:     Epoch: 17
2023-01-05 07:52:27,694 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5483915289243062, 'Total loss': 0.5483915289243062} | train loss {'Reaction outcome loss': 0.42798537998409064, 'Total loss': 0.42798537998409064}
2023-01-05 07:52:27,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:52:27,694 INFO:     Epoch: 18
2023-01-05 07:52:29,834 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5323499530553818, 'Total loss': 0.5323499530553818} | train loss {'Reaction outcome loss': 0.41987635793621503, 'Total loss': 0.41987635793621503}
2023-01-05 07:52:29,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:52:29,834 INFO:     Epoch: 19
2023-01-05 07:52:31,970 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5241526007652283, 'Total loss': 0.5241526007652283} | train loss {'Reaction outcome loss': 0.4179360914579678, 'Total loss': 0.4179360914579678}
2023-01-05 07:52:31,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:52:31,971 INFO:     Epoch: 20
2023-01-05 07:52:34,104 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5020987267295519, 'Total loss': 0.5020987267295519} | train loss {'Reaction outcome loss': 0.4144136701529716, 'Total loss': 0.4144136701529716}
2023-01-05 07:52:34,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:52:34,104 INFO:     Epoch: 21
2023-01-05 07:52:36,256 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.48153259058793385, 'Total loss': 0.48153259058793385} | train loss {'Reaction outcome loss': 0.4123012741154312, 'Total loss': 0.4123012741154312}
2023-01-05 07:52:36,256 INFO:     Found new best model at epoch 21
2023-01-05 07:52:36,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:52:36,257 INFO:     Epoch: 22
2023-01-05 07:52:38,399 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.48589152296384175, 'Total loss': 0.48589152296384175} | train loss {'Reaction outcome loss': 0.40446561340228976, 'Total loss': 0.40446561340228976}
2023-01-05 07:52:38,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:52:38,400 INFO:     Epoch: 23
2023-01-05 07:52:40,527 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5002622564633687, 'Total loss': 0.5002622564633687} | train loss {'Reaction outcome loss': 0.4051533960652002, 'Total loss': 0.4051533960652002}
2023-01-05 07:52:40,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:52:40,527 INFO:     Epoch: 24
2023-01-05 07:52:42,675 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4993514696756999, 'Total loss': 0.4993514696756999} | train loss {'Reaction outcome loss': 0.39464725944257917, 'Total loss': 0.39464725944257917}
2023-01-05 07:52:42,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:52:42,675 INFO:     Epoch: 25
2023-01-05 07:52:44,593 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5260399838288625, 'Total loss': 0.5260399838288625} | train loss {'Reaction outcome loss': 0.39551712984676324, 'Total loss': 0.39551712984676324}
2023-01-05 07:52:44,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:52:44,593 INFO:     Epoch: 26
2023-01-05 07:52:46,733 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5056126604477564, 'Total loss': 0.5056126604477564} | train loss {'Reaction outcome loss': 0.39322604964940977, 'Total loss': 0.39322604964940977}
2023-01-05 07:52:46,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:52:46,733 INFO:     Epoch: 27
2023-01-05 07:52:48,899 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5362681885560353, 'Total loss': 0.5362681885560353} | train loss {'Reaction outcome loss': 0.38651182089297736, 'Total loss': 0.38651182089297736}
2023-01-05 07:52:48,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:52:48,899 INFO:     Epoch: 28
2023-01-05 07:52:51,056 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5398765524228414, 'Total loss': 0.5398765524228414} | train loss {'Reaction outcome loss': 0.3845691593984763, 'Total loss': 0.3845691593984763}
2023-01-05 07:52:51,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:52:51,057 INFO:     Epoch: 29
2023-01-05 07:52:53,207 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.48389669756094617, 'Total loss': 0.48389669756094617} | train loss {'Reaction outcome loss': 0.3825792684168606, 'Total loss': 0.3825792684168606}
2023-01-05 07:52:53,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:52:53,208 INFO:     Epoch: 30
2023-01-05 07:52:55,323 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5755098213752111, 'Total loss': 0.5755098213752111} | train loss {'Reaction outcome loss': 0.3771923421285091, 'Total loss': 0.3771923421285091}
2023-01-05 07:52:55,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:52:55,324 INFO:     Epoch: 31
2023-01-05 07:52:57,458 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5544705887635549, 'Total loss': 0.5544705887635549} | train loss {'Reaction outcome loss': 0.37645826271765837, 'Total loss': 0.37645826271765837}
2023-01-05 07:52:57,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:52:57,459 INFO:     Epoch: 32
2023-01-05 07:52:59,611 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5374783287445705, 'Total loss': 0.5374783287445705} | train loss {'Reaction outcome loss': 0.373612255240098, 'Total loss': 0.373612255240098}
2023-01-05 07:52:59,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:52:59,611 INFO:     Epoch: 33
2023-01-05 07:53:01,741 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4975827932357788, 'Total loss': 0.4975827932357788} | train loss {'Reaction outcome loss': 0.3744159873315703, 'Total loss': 0.3744159873315703}
2023-01-05 07:53:01,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:53:01,741 INFO:     Epoch: 34
2023-01-05 07:53:03,891 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.46719815135002135, 'Total loss': 0.46719815135002135} | train loss {'Reaction outcome loss': 0.36231787521869707, 'Total loss': 0.36231787521869707}
2023-01-05 07:53:03,892 INFO:     Found new best model at epoch 34
2023-01-05 07:53:03,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:53:03,893 INFO:     Epoch: 35
2023-01-05 07:53:06,059 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5050425499677658, 'Total loss': 0.5050425499677658} | train loss {'Reaction outcome loss': 0.35921909613705383, 'Total loss': 0.35921909613705383}
2023-01-05 07:53:06,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:53:06,060 INFO:     Epoch: 36
2023-01-05 07:53:08,194 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46368290732304257, 'Total loss': 0.46368290732304257} | train loss {'Reaction outcome loss': 0.3618581016844773, 'Total loss': 0.3618581016844773}
2023-01-05 07:53:08,196 INFO:     Found new best model at epoch 36
2023-01-05 07:53:08,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:53:08,197 INFO:     Epoch: 37
2023-01-05 07:53:10,343 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.49798914392789206, 'Total loss': 0.49798914392789206} | train loss {'Reaction outcome loss': 0.355075193466721, 'Total loss': 0.355075193466721}
2023-01-05 07:53:10,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:53:10,344 INFO:     Epoch: 38
2023-01-05 07:53:12,494 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.48774138490358987, 'Total loss': 0.48774138490358987} | train loss {'Reaction outcome loss': 0.3475565906706174, 'Total loss': 0.3475565906706174}
2023-01-05 07:53:12,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:53:12,494 INFO:     Epoch: 39
2023-01-05 07:53:14,636 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5014983256657918, 'Total loss': 0.5014983256657918} | train loss {'Reaction outcome loss': 0.3455364261873258, 'Total loss': 0.3455364261873258}
2023-01-05 07:53:14,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:53:14,637 INFO:     Epoch: 40
2023-01-05 07:53:16,777 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5120916763941447, 'Total loss': 0.5120916763941447} | train loss {'Reaction outcome loss': 0.3394033074815631, 'Total loss': 0.3394033074815631}
2023-01-05 07:53:16,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:53:16,778 INFO:     Epoch: 41
2023-01-05 07:53:18,900 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4992768128712972, 'Total loss': 0.4992768128712972} | train loss {'Reaction outcome loss': 0.34315176275405257, 'Total loss': 0.34315176275405257}
2023-01-05 07:53:18,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:53:18,901 INFO:     Epoch: 42
2023-01-05 07:53:21,059 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4964374045530955, 'Total loss': 0.4964374045530955} | train loss {'Reaction outcome loss': 0.3360290905876911, 'Total loss': 0.3360290905876911}
2023-01-05 07:53:21,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:53:21,060 INFO:     Epoch: 43
2023-01-05 07:53:23,224 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4974877774715424, 'Total loss': 0.4974877774715424} | train loss {'Reaction outcome loss': 0.3364669041564831, 'Total loss': 0.3364669041564831}
2023-01-05 07:53:23,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:53:23,224 INFO:     Epoch: 44
2023-01-05 07:53:25,358 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.49245987832546234, 'Total loss': 0.49245987832546234} | train loss {'Reaction outcome loss': 0.32947982858607183, 'Total loss': 0.32947982858607183}
2023-01-05 07:53:25,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:53:25,358 INFO:     Epoch: 45
2023-01-05 07:53:27,487 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.49408198297023775, 'Total loss': 0.49408198297023775} | train loss {'Reaction outcome loss': 0.32614972484690363, 'Total loss': 0.32614972484690363}
2023-01-05 07:53:27,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:53:27,488 INFO:     Epoch: 46
2023-01-05 07:53:29,622 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5591723759969075, 'Total loss': 0.5591723759969075} | train loss {'Reaction outcome loss': 0.33077356045990636, 'Total loss': 0.33077356045990636}
2023-01-05 07:53:29,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:53:29,623 INFO:     Epoch: 47
2023-01-05 07:53:31,747 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4861015573143959, 'Total loss': 0.4861015573143959} | train loss {'Reaction outcome loss': 0.3203812894981095, 'Total loss': 0.3203812894981095}
2023-01-05 07:53:31,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:53:31,748 INFO:     Epoch: 48
2023-01-05 07:53:33,898 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.49076175192991894, 'Total loss': 0.49076175192991894} | train loss {'Reaction outcome loss': 0.3211506288021039, 'Total loss': 0.3211506288021039}
2023-01-05 07:53:33,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:53:33,899 INFO:     Epoch: 49
2023-01-05 07:53:36,081 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4883380144834518, 'Total loss': 0.4883380144834518} | train loss {'Reaction outcome loss': 0.3148070958344054, 'Total loss': 0.3148070958344054}
2023-01-05 07:53:36,081 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:53:36,081 INFO:     Epoch: 50
2023-01-05 07:53:38,219 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5178974469502767, 'Total loss': 0.5178974469502767} | train loss {'Reaction outcome loss': 0.313041376325237, 'Total loss': 0.313041376325237}
2023-01-05 07:53:38,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:53:38,219 INFO:     Epoch: 51
2023-01-05 07:53:40,377 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.47780854801336925, 'Total loss': 0.47780854801336925} | train loss {'Reaction outcome loss': 0.31888610752292607, 'Total loss': 0.31888610752292607}
2023-01-05 07:53:40,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:53:40,377 INFO:     Epoch: 52
2023-01-05 07:53:42,514 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48416369756062827, 'Total loss': 0.48416369756062827} | train loss {'Reaction outcome loss': 0.30947645310135113, 'Total loss': 0.30947645310135113}
2023-01-05 07:53:42,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:53:42,515 INFO:     Epoch: 53
2023-01-05 07:53:44,654 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47005793154239656, 'Total loss': 0.47005793154239656} | train loss {'Reaction outcome loss': 0.306888985287248, 'Total loss': 0.306888985287248}
2023-01-05 07:53:44,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:53:44,655 INFO:     Epoch: 54
2023-01-05 07:53:46,785 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.448280797402064, 'Total loss': 0.448280797402064} | train loss {'Reaction outcome loss': 0.30289619422821334, 'Total loss': 0.30289619422821334}
2023-01-05 07:53:46,785 INFO:     Found new best model at epoch 54
2023-01-05 07:53:46,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:53:46,786 INFO:     Epoch: 55
2023-01-05 07:53:48,900 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5065900593996048, 'Total loss': 0.5065900593996048} | train loss {'Reaction outcome loss': 0.31101033353543545, 'Total loss': 0.31101033353543545}
2023-01-05 07:53:48,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:53:48,900 INFO:     Epoch: 56
2023-01-05 07:53:51,032 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4483945886294047, 'Total loss': 0.4483945886294047} | train loss {'Reaction outcome loss': 0.309000099780577, 'Total loss': 0.309000099780577}
2023-01-05 07:53:51,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:53:51,033 INFO:     Epoch: 57
2023-01-05 07:53:53,155 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4859212835629781, 'Total loss': 0.4859212835629781} | train loss {'Reaction outcome loss': 0.3008616746099659, 'Total loss': 0.3008616746099659}
2023-01-05 07:53:53,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:53:53,155 INFO:     Epoch: 58
2023-01-05 07:53:55,272 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4777331362167994, 'Total loss': 0.4777331362167994} | train loss {'Reaction outcome loss': 0.2950404346152976, 'Total loss': 0.2950404346152976}
2023-01-05 07:53:55,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:53:55,273 INFO:     Epoch: 59
2023-01-05 07:53:57,416 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5012125353018443, 'Total loss': 0.5012125353018443} | train loss {'Reaction outcome loss': 0.2987993239756032, 'Total loss': 0.2987993239756032}
2023-01-05 07:53:57,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:53:57,416 INFO:     Epoch: 60
2023-01-05 07:53:59,555 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4703924616177877, 'Total loss': 0.4703924616177877} | train loss {'Reaction outcome loss': 0.3004156877679048, 'Total loss': 0.3004156877679048}
2023-01-05 07:53:59,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:53:59,556 INFO:     Epoch: 61
2023-01-05 07:54:01,680 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4653899669647217, 'Total loss': 0.4653899669647217} | train loss {'Reaction outcome loss': 0.29510862298391677, 'Total loss': 0.29510862298391677}
2023-01-05 07:54:01,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:54:01,680 INFO:     Epoch: 62
2023-01-05 07:54:03,819 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.49026668469111123, 'Total loss': 0.49026668469111123} | train loss {'Reaction outcome loss': 0.28786152327133024, 'Total loss': 0.28786152327133024}
2023-01-05 07:54:03,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:54:03,820 INFO:     Epoch: 63
2023-01-05 07:54:05,934 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.48452453017234803, 'Total loss': 0.48452453017234803} | train loss {'Reaction outcome loss': 0.2950939547898241, 'Total loss': 0.2950939547898241}
2023-01-05 07:54:05,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:54:05,935 INFO:     Epoch: 64
2023-01-05 07:54:08,092 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5229057788848877, 'Total loss': 0.5229057788848877} | train loss {'Reaction outcome loss': 0.2885998677967232, 'Total loss': 0.2885998677967232}
2023-01-05 07:54:08,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:54:08,093 INFO:     Epoch: 65
2023-01-05 07:54:10,240 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5137074748675029, 'Total loss': 0.5137074748675029} | train loss {'Reaction outcome loss': 0.29078467446805795, 'Total loss': 0.29078467446805795}
2023-01-05 07:54:10,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:54:10,240 INFO:     Epoch: 66
2023-01-05 07:54:12,356 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4760453542073568, 'Total loss': 0.4760453542073568} | train loss {'Reaction outcome loss': 0.28072741036832116, 'Total loss': 0.28072741036832116}
2023-01-05 07:54:12,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:54:12,356 INFO:     Epoch: 67
2023-01-05 07:54:14,483 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.5176607688268026, 'Total loss': 0.5176607688268026} | train loss {'Reaction outcome loss': 0.278507752412241, 'Total loss': 0.278507752412241}
2023-01-05 07:54:14,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:54:14,483 INFO:     Epoch: 68
2023-01-05 07:54:16,612 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4742861727873484, 'Total loss': 0.4742861727873484} | train loss {'Reaction outcome loss': 0.28076146609890157, 'Total loss': 0.28076146609890157}
2023-01-05 07:54:16,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:54:16,612 INFO:     Epoch: 69
2023-01-05 07:54:18,735 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4681942641735077, 'Total loss': 0.4681942641735077} | train loss {'Reaction outcome loss': 0.2844282175676945, 'Total loss': 0.2844282175676945}
2023-01-05 07:54:18,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:54:18,735 INFO:     Epoch: 70
2023-01-05 07:54:20,875 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5223379770914713, 'Total loss': 0.5223379770914713} | train loss {'Reaction outcome loss': 0.28327322657127957, 'Total loss': 0.28327322657127957}
2023-01-05 07:54:20,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:54:20,876 INFO:     Epoch: 71
2023-01-05 07:54:23,005 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46105432510375977, 'Total loss': 0.46105432510375977} | train loss {'Reaction outcome loss': 0.2793593052433524, 'Total loss': 0.2793593052433524}
2023-01-05 07:54:23,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:54:23,006 INFO:     Epoch: 72
2023-01-05 07:54:25,135 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4298467844724655, 'Total loss': 0.4298467844724655} | train loss {'Reaction outcome loss': 0.2860557847816647, 'Total loss': 0.2860557847816647}
2023-01-05 07:54:25,135 INFO:     Found new best model at epoch 72
2023-01-05 07:54:25,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:54:25,136 INFO:     Epoch: 73
2023-01-05 07:54:27,258 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5231953660647074, 'Total loss': 0.5231953660647074} | train loss {'Reaction outcome loss': 0.27341791997994586, 'Total loss': 0.27341791997994586}
2023-01-05 07:54:27,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:54:27,259 INFO:     Epoch: 74
2023-01-05 07:54:29,386 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5207223713397979, 'Total loss': 0.5207223713397979} | train loss {'Reaction outcome loss': 0.27302217967944703, 'Total loss': 0.27302217967944703}
2023-01-05 07:54:29,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:54:29,386 INFO:     Epoch: 75
2023-01-05 07:54:31,536 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4934556891520818, 'Total loss': 0.4934556891520818} | train loss {'Reaction outcome loss': 0.2798603835341695, 'Total loss': 0.2798603835341695}
2023-01-05 07:54:31,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:54:31,536 INFO:     Epoch: 76
2023-01-05 07:54:33,678 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4988951802253723, 'Total loss': 0.4988951802253723} | train loss {'Reaction outcome loss': 0.28815103617015775, 'Total loss': 0.28815103617015775}
2023-01-05 07:54:33,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:54:33,678 INFO:     Epoch: 77
2023-01-05 07:54:35,796 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4921770304441452, 'Total loss': 0.4921770304441452} | train loss {'Reaction outcome loss': 0.2705078610925229, 'Total loss': 0.2705078610925229}
2023-01-05 07:54:35,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:54:35,797 INFO:     Epoch: 78
2023-01-05 07:54:37,932 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43890709429979324, 'Total loss': 0.43890709429979324} | train loss {'Reaction outcome loss': 0.2653085896028922, 'Total loss': 0.2653085896028922}
2023-01-05 07:54:37,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:54:37,932 INFO:     Epoch: 79
2023-01-05 07:54:40,067 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.45254149436950686, 'Total loss': 0.45254149436950686} | train loss {'Reaction outcome loss': 0.2782304625371437, 'Total loss': 0.2782304625371437}
2023-01-05 07:54:40,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:54:40,068 INFO:     Epoch: 80
2023-01-05 07:54:42,209 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.49468597571055095, 'Total loss': 0.49468597571055095} | train loss {'Reaction outcome loss': 0.2780648187048488, 'Total loss': 0.2780648187048488}
2023-01-05 07:54:42,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:54:42,210 INFO:     Epoch: 81
2023-01-05 07:54:44,354 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.49939424693584444, 'Total loss': 0.49939424693584444} | train loss {'Reaction outcome loss': 0.2749695899476717, 'Total loss': 0.2749695899476717}
2023-01-05 07:54:44,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:54:44,355 INFO:     Epoch: 82
2023-01-05 07:54:46,505 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4441841294368108, 'Total loss': 0.4441841294368108} | train loss {'Reaction outcome loss': 0.258878036698961, 'Total loss': 0.258878036698961}
2023-01-05 07:54:46,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:54:46,506 INFO:     Epoch: 83
2023-01-05 07:54:48,658 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4764326959848404, 'Total loss': 0.4764326959848404} | train loss {'Reaction outcome loss': 0.26188400449169863, 'Total loss': 0.26188400449169863}
2023-01-05 07:54:48,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:54:48,659 INFO:     Epoch: 84
2023-01-05 07:54:50,795 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5131583988666535, 'Total loss': 0.5131583988666535} | train loss {'Reaction outcome loss': 0.26587785864351215, 'Total loss': 0.26587785864351215}
2023-01-05 07:54:50,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:54:50,796 INFO:     Epoch: 85
2023-01-05 07:54:52,907 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.45568404098351795, 'Total loss': 0.45568404098351795} | train loss {'Reaction outcome loss': 0.2611851529678801, 'Total loss': 0.2611851529678801}
2023-01-05 07:54:52,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:54:52,907 INFO:     Epoch: 86
2023-01-05 07:54:55,048 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5134188254674276, 'Total loss': 0.5134188254674276} | train loss {'Reaction outcome loss': 0.25763708005075925, 'Total loss': 0.25763708005075925}
2023-01-05 07:54:55,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:54:55,048 INFO:     Epoch: 87
2023-01-05 07:54:57,180 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4266118884086609, 'Total loss': 0.4266118884086609} | train loss {'Reaction outcome loss': 0.26049069439371425, 'Total loss': 0.26049069439371425}
2023-01-05 07:54:57,181 INFO:     Found new best model at epoch 87
2023-01-05 07:54:57,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:54:57,183 INFO:     Epoch: 88
2023-01-05 07:54:59,309 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4929527382055918, 'Total loss': 0.4929527382055918} | train loss {'Reaction outcome loss': 0.2548943549525095, 'Total loss': 0.2548943549525095}
2023-01-05 07:54:59,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:54:59,309 INFO:     Epoch: 89
2023-01-05 07:55:01,457 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.5287937651077906, 'Total loss': 0.5287937651077906} | train loss {'Reaction outcome loss': 0.2529751215600869, 'Total loss': 0.2529751215600869}
2023-01-05 07:55:01,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:55:01,457 INFO:     Epoch: 90
2023-01-05 07:55:03,570 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46187145411968233, 'Total loss': 0.46187145411968233} | train loss {'Reaction outcome loss': 0.2503356394177173, 'Total loss': 0.2503356394177173}
2023-01-05 07:55:03,570 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:55:03,570 INFO:     Epoch: 91
2023-01-05 07:55:05,699 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5109941601753235, 'Total loss': 0.5109941601753235} | train loss {'Reaction outcome loss': 0.25438696803224886, 'Total loss': 0.25438696803224886}
2023-01-05 07:55:05,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:55:05,699 INFO:     Epoch: 92
2023-01-05 07:55:07,834 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5214687262972196, 'Total loss': 0.5214687262972196} | train loss {'Reaction outcome loss': 0.2568068555232151, 'Total loss': 0.2568068555232151}
2023-01-05 07:55:07,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:55:07,834 INFO:     Epoch: 93
2023-01-05 07:55:09,975 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4845423916975657, 'Total loss': 0.4845423916975657} | train loss {'Reaction outcome loss': 0.2528781799237916, 'Total loss': 0.2528781799237916}
2023-01-05 07:55:09,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:55:09,976 INFO:     Epoch: 94
2023-01-05 07:55:12,089 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4972053204973539, 'Total loss': 0.4972053204973539} | train loss {'Reaction outcome loss': 0.25430498590808864, 'Total loss': 0.25430498590808864}
2023-01-05 07:55:12,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:55:12,089 INFO:     Epoch: 95
2023-01-05 07:55:14,218 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4882494380076726, 'Total loss': 0.4882494380076726} | train loss {'Reaction outcome loss': 0.25059193514130546, 'Total loss': 0.25059193514130546}
2023-01-05 07:55:14,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:55:14,218 INFO:     Epoch: 96
2023-01-05 07:55:16,344 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4649393578370412, 'Total loss': 0.4649393578370412} | train loss {'Reaction outcome loss': 0.24781138950706402, 'Total loss': 0.24781138950706402}
2023-01-05 07:55:16,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:55:16,344 INFO:     Epoch: 97
2023-01-05 07:55:18,487 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.47838141918182375, 'Total loss': 0.47838141918182375} | train loss {'Reaction outcome loss': 0.254732306432593, 'Total loss': 0.254732306432593}
2023-01-05 07:55:18,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:55:18,487 INFO:     Epoch: 98
2023-01-05 07:55:20,611 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44582903881867725, 'Total loss': 0.44582903881867725} | train loss {'Reaction outcome loss': 0.24888948685465714, 'Total loss': 0.24888948685465714}
2023-01-05 07:55:20,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:55:20,611 INFO:     Epoch: 99
2023-01-05 07:55:22,734 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4932013193766276, 'Total loss': 0.4932013193766276} | train loss {'Reaction outcome loss': 0.2473777200098767, 'Total loss': 0.2473777200098767}
2023-01-05 07:55:22,734 INFO:     Best model found after epoch 88 of 100.
2023-01-05 07:55:22,734 INFO:   Done with stage: TRAINING
2023-01-05 07:55:22,734 INFO:   Starting stage: EVALUATION
2023-01-05 07:55:22,878 INFO:   Done with stage: EVALUATION
2023-01-05 07:55:22,878 INFO:   Leaving out SEQ value Fold_4
2023-01-05 07:55:22,890 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 07:55:22,891 INFO:   Starting stage: FEATURE SCALING
2023-01-05 07:55:23,539 INFO:   Done with stage: FEATURE SCALING
2023-01-05 07:55:23,539 INFO:   Starting stage: SCALING TARGETS
2023-01-05 07:55:23,608 INFO:   Done with stage: SCALING TARGETS
2023-01-05 07:55:23,608 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:55:23,608 INFO:     No hyperparam tuning for this model
2023-01-05 07:55:23,608 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:55:23,608 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 07:55:23,609 INFO:     None feature selector for col prot
2023-01-05 07:55:23,609 INFO:     None feature selector for col prot
2023-01-05 07:55:23,609 INFO:     None feature selector for col prot
2023-01-05 07:55:23,610 INFO:     None feature selector for col chem
2023-01-05 07:55:23,610 INFO:     None feature selector for col chem
2023-01-05 07:55:23,610 INFO:     None feature selector for col chem
2023-01-05 07:55:23,610 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 07:55:23,610 INFO:   Starting stage: BUILD MODEL
2023-01-05 07:55:23,612 INFO:     Number of params in model 72901
2023-01-05 07:55:23,615 INFO:   Done with stage: BUILD MODEL
2023-01-05 07:55:23,615 INFO:   Starting stage: TRAINING
2023-01-05 07:55:23,672 INFO:     Val loss before train {'Reaction outcome loss': 1.013378663857778, 'Total loss': 1.013378663857778}
2023-01-05 07:55:23,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:55:23,672 INFO:     Epoch: 0
2023-01-05 07:55:25,837 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8506949067115783, 'Total loss': 0.8506949067115783} | train loss {'Reaction outcome loss': 0.9371553979215831, 'Total loss': 0.9371553979215831}
2023-01-05 07:55:25,838 INFO:     Found new best model at epoch 0
2023-01-05 07:55:25,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:55:25,840 INFO:     Epoch: 1
2023-01-05 07:55:27,965 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6703556080659231, 'Total loss': 0.6703556080659231} | train loss {'Reaction outcome loss': 0.7596485324367119, 'Total loss': 0.7596485324367119}
2023-01-05 07:55:27,965 INFO:     Found new best model at epoch 1
2023-01-05 07:55:27,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:55:27,967 INFO:     Epoch: 2
2023-01-05 07:55:30,105 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5705634295940399, 'Total loss': 0.5705634295940399} | train loss {'Reaction outcome loss': 0.596687885749079, 'Total loss': 0.596687885749079}
2023-01-05 07:55:30,105 INFO:     Found new best model at epoch 2
2023-01-05 07:55:30,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:55:30,107 INFO:     Epoch: 3
2023-01-05 07:55:32,253 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5429894109567006, 'Total loss': 0.5429894109567006} | train loss {'Reaction outcome loss': 0.5458813055153311, 'Total loss': 0.5458813055153311}
2023-01-05 07:55:32,254 INFO:     Found new best model at epoch 3
2023-01-05 07:55:32,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:55:32,255 INFO:     Epoch: 4
2023-01-05 07:55:34,400 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5059073686599731, 'Total loss': 0.5059073686599731} | train loss {'Reaction outcome loss': 0.5196333511249862, 'Total loss': 0.5196333511249862}
2023-01-05 07:55:34,401 INFO:     Found new best model at epoch 4
2023-01-05 07:55:34,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:55:34,402 INFO:     Epoch: 5
2023-01-05 07:55:36,538 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5080141445000966, 'Total loss': 0.5080141445000966} | train loss {'Reaction outcome loss': 0.5042898454261522, 'Total loss': 0.5042898454261522}
2023-01-05 07:55:36,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:55:36,538 INFO:     Epoch: 6
2023-01-05 07:55:38,685 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5216929256916046, 'Total loss': 0.5216929256916046} | train loss {'Reaction outcome loss': 0.49217253194673216, 'Total loss': 0.49217253194673216}
2023-01-05 07:55:38,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:55:38,686 INFO:     Epoch: 7
2023-01-05 07:55:40,832 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5196605195601781, 'Total loss': 0.5196605195601781} | train loss {'Reaction outcome loss': 0.4866533351749399, 'Total loss': 0.4866533351749399}
2023-01-05 07:55:40,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:55:40,832 INFO:     Epoch: 8
2023-01-05 07:55:42,979 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5193598369757334, 'Total loss': 0.5193598369757334} | train loss {'Reaction outcome loss': 0.47843459504146646, 'Total loss': 0.47843459504146646}
2023-01-05 07:55:42,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:55:42,979 INFO:     Epoch: 9
2023-01-05 07:55:45,118 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5060044765472412, 'Total loss': 0.5060044765472412} | train loss {'Reaction outcome loss': 0.4717935173615922, 'Total loss': 0.4717935173615922}
2023-01-05 07:55:45,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:55:45,119 INFO:     Epoch: 10
2023-01-05 07:55:47,254 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49059197306632996, 'Total loss': 0.49059197306632996} | train loss {'Reaction outcome loss': 0.4662953419406919, 'Total loss': 0.4662953419406919}
2023-01-05 07:55:47,254 INFO:     Found new best model at epoch 10
2023-01-05 07:55:47,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:55:47,256 INFO:     Epoch: 11
2023-01-05 07:55:49,404 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5117604017257691, 'Total loss': 0.5117604017257691} | train loss {'Reaction outcome loss': 0.4586606829216445, 'Total loss': 0.4586606829216445}
2023-01-05 07:55:49,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:55:49,404 INFO:     Epoch: 12
2023-01-05 07:55:51,551 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5008344233036042, 'Total loss': 0.5008344233036042} | train loss {'Reaction outcome loss': 0.4539315354650038, 'Total loss': 0.4539315354650038}
2023-01-05 07:55:51,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:55:51,552 INFO:     Epoch: 13
2023-01-05 07:55:53,690 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47381876011689505, 'Total loss': 0.47381876011689505} | train loss {'Reaction outcome loss': 0.45154235906300755, 'Total loss': 0.45154235906300755}
2023-01-05 07:55:53,690 INFO:     Found new best model at epoch 13
2023-01-05 07:55:53,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:55:53,691 INFO:     Epoch: 14
2023-01-05 07:55:55,816 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4817129467924436, 'Total loss': 0.4817129467924436} | train loss {'Reaction outcome loss': 0.44640391700676757, 'Total loss': 0.44640391700676757}
2023-01-05 07:55:55,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:55:55,816 INFO:     Epoch: 15
2023-01-05 07:55:57,941 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5063212017218272, 'Total loss': 0.5063212017218272} | train loss {'Reaction outcome loss': 0.444124671447016, 'Total loss': 0.444124671447016}
2023-01-05 07:55:57,942 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:55:57,942 INFO:     Epoch: 16
2023-01-05 07:56:00,062 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5145853479703267, 'Total loss': 0.5145853479703267} | train loss {'Reaction outcome loss': 0.4417569036357594, 'Total loss': 0.4417569036357594}
2023-01-05 07:56:00,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:56:00,062 INFO:     Epoch: 17
2023-01-05 07:56:02,182 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4716862440109253, 'Total loss': 0.4716862440109253} | train loss {'Reaction outcome loss': 0.43824517484890285, 'Total loss': 0.43824517484890285}
2023-01-05 07:56:02,183 INFO:     Found new best model at epoch 17
2023-01-05 07:56:02,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:56:02,184 INFO:     Epoch: 18
2023-01-05 07:56:04,312 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46607653697331747, 'Total loss': 0.46607653697331747} | train loss {'Reaction outcome loss': 0.43192077400910595, 'Total loss': 0.43192077400910595}
2023-01-05 07:56:04,313 INFO:     Found new best model at epoch 18
2023-01-05 07:56:04,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:56:04,314 INFO:     Epoch: 19
2023-01-05 07:56:06,459 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4912140915791194, 'Total loss': 0.4912140915791194} | train loss {'Reaction outcome loss': 0.4244049126214355, 'Total loss': 0.4244049126214355}
2023-01-05 07:56:06,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:56:06,460 INFO:     Epoch: 20
2023-01-05 07:56:08,585 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.47544230421384176, 'Total loss': 0.47544230421384176} | train loss {'Reaction outcome loss': 0.4224633625606551, 'Total loss': 0.4224633625606551}
2023-01-05 07:56:08,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:56:08,586 INFO:     Epoch: 21
2023-01-05 07:56:10,709 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.47282877763112385, 'Total loss': 0.47282877763112385} | train loss {'Reaction outcome loss': 0.41565730129062695, 'Total loss': 0.41565730129062695}
2023-01-05 07:56:10,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:56:10,709 INFO:     Epoch: 22
2023-01-05 07:56:12,842 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.48514507015546166, 'Total loss': 0.48514507015546166} | train loss {'Reaction outcome loss': 0.4151628201786619, 'Total loss': 0.4151628201786619}
2023-01-05 07:56:12,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:56:12,842 INFO:     Epoch: 23
2023-01-05 07:56:14,968 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4771551767985026, 'Total loss': 0.4771551767985026} | train loss {'Reaction outcome loss': 0.40756089775993004, 'Total loss': 0.40756089775993004}
2023-01-05 07:56:14,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:56:14,968 INFO:     Epoch: 24
2023-01-05 07:56:17,102 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.45708783666292824, 'Total loss': 0.45708783666292824} | train loss {'Reaction outcome loss': 0.40975186590404405, 'Total loss': 0.40975186590404405}
2023-01-05 07:56:17,103 INFO:     Found new best model at epoch 24
2023-01-05 07:56:17,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:56:17,104 INFO:     Epoch: 25
2023-01-05 07:56:19,230 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4626463413238525, 'Total loss': 0.4626463413238525} | train loss {'Reaction outcome loss': 0.40214213008319377, 'Total loss': 0.40214213008319377}
2023-01-05 07:56:19,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:56:19,230 INFO:     Epoch: 26
2023-01-05 07:56:21,345 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4840427448352178, 'Total loss': 0.4840427448352178} | train loss {'Reaction outcome loss': 0.3993217311527607, 'Total loss': 0.3993217311527607}
2023-01-05 07:56:21,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:56:21,345 INFO:     Epoch: 27
2023-01-05 07:56:23,487 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47301345666249595, 'Total loss': 0.47301345666249595} | train loss {'Reaction outcome loss': 0.39569131374685435, 'Total loss': 0.39569131374685435}
2023-01-05 07:56:23,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:56:23,488 INFO:     Epoch: 28
2023-01-05 07:56:25,623 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47842570741971335, 'Total loss': 0.47842570741971335} | train loss {'Reaction outcome loss': 0.39634537536406167, 'Total loss': 0.39634537536406167}
2023-01-05 07:56:25,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:56:25,623 INFO:     Epoch: 29
2023-01-05 07:56:27,759 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46180292367935183, 'Total loss': 0.46180292367935183} | train loss {'Reaction outcome loss': 0.3877190175010775, 'Total loss': 0.3877190175010775}
2023-01-05 07:56:27,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:56:27,761 INFO:     Epoch: 30
2023-01-05 07:56:29,899 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45855626463890076, 'Total loss': 0.45855626463890076} | train loss {'Reaction outcome loss': 0.3874327428910854, 'Total loss': 0.3874327428910854}
2023-01-05 07:56:29,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:56:29,899 INFO:     Epoch: 31
2023-01-05 07:56:32,152 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4892620762189229, 'Total loss': 0.4892620762189229} | train loss {'Reaction outcome loss': 0.38369498898132437, 'Total loss': 0.38369498898132437}
2023-01-05 07:56:32,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:56:32,152 INFO:     Epoch: 32
2023-01-05 07:56:34,370 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.486722539861997, 'Total loss': 0.486722539861997} | train loss {'Reaction outcome loss': 0.38275980813442356, 'Total loss': 0.38275980813442356}
2023-01-05 07:56:34,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:56:34,371 INFO:     Epoch: 33
2023-01-05 07:56:36,605 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.479120546579361, 'Total loss': 0.479120546579361} | train loss {'Reaction outcome loss': 0.373638783003727, 'Total loss': 0.373638783003727}
2023-01-05 07:56:36,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:56:36,605 INFO:     Epoch: 34
2023-01-05 07:56:38,863 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4579948087533315, 'Total loss': 0.4579948087533315} | train loss {'Reaction outcome loss': 0.37519816587930616, 'Total loss': 0.37519816587930616}
2023-01-05 07:56:38,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:56:38,863 INFO:     Epoch: 35
2023-01-05 07:56:41,127 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.448912384112676, 'Total loss': 0.448912384112676} | train loss {'Reaction outcome loss': 0.37807476285328395, 'Total loss': 0.37807476285328395}
2023-01-05 07:56:41,128 INFO:     Found new best model at epoch 35
2023-01-05 07:56:41,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:56:41,129 INFO:     Epoch: 36
2023-01-05 07:56:43,384 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.48990266521771747, 'Total loss': 0.48990266521771747} | train loss {'Reaction outcome loss': 0.36962681997866526, 'Total loss': 0.36962681997866526}
2023-01-05 07:56:43,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:56:43,384 INFO:     Epoch: 37
2023-01-05 07:56:45,508 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.47399232586224876, 'Total loss': 0.47399232586224876} | train loss {'Reaction outcome loss': 0.36404919026106813, 'Total loss': 0.36404919026106813}
2023-01-05 07:56:45,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:56:45,508 INFO:     Epoch: 38
2023-01-05 07:56:47,633 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4831966280937195, 'Total loss': 0.4831966280937195} | train loss {'Reaction outcome loss': 0.35983685613439903, 'Total loss': 0.35983685613439903}
2023-01-05 07:56:47,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:56:47,634 INFO:     Epoch: 39
2023-01-05 07:56:49,618 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46236774722735086, 'Total loss': 0.46236774722735086} | train loss {'Reaction outcome loss': 0.3545277495834514, 'Total loss': 0.3545277495834514}
2023-01-05 07:56:49,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:56:49,618 INFO:     Epoch: 40
2023-01-05 07:56:51,792 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4613534927368164, 'Total loss': 0.4613534927368164} | train loss {'Reaction outcome loss': 0.35877566673133493, 'Total loss': 0.35877566673133493}
2023-01-05 07:56:51,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:56:51,792 INFO:     Epoch: 41
2023-01-05 07:56:53,952 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4593964949250221, 'Total loss': 0.4593964949250221} | train loss {'Reaction outcome loss': 0.3542856371478878, 'Total loss': 0.3542856371478878}
2023-01-05 07:56:53,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:56:53,952 INFO:     Epoch: 42
2023-01-05 07:56:56,086 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4609612474838893, 'Total loss': 0.4609612474838893} | train loss {'Reaction outcome loss': 0.34937876446621263, 'Total loss': 0.34937876446621263}
2023-01-05 07:56:56,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:56:56,086 INFO:     Epoch: 43
2023-01-05 07:56:58,234 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4650312741597494, 'Total loss': 0.4650312741597494} | train loss {'Reaction outcome loss': 0.34517445757876347, 'Total loss': 0.34517445757876347}
2023-01-05 07:56:58,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:56:58,234 INFO:     Epoch: 44
2023-01-05 07:57:00,372 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4579557677110036, 'Total loss': 0.4579557677110036} | train loss {'Reaction outcome loss': 0.3374220250432726, 'Total loss': 0.3374220250432726}
2023-01-05 07:57:00,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:57:00,373 INFO:     Epoch: 45
2023-01-05 07:57:02,516 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4934153417746226, 'Total loss': 0.4934153417746226} | train loss {'Reaction outcome loss': 0.3422657884385464, 'Total loss': 0.3422657884385464}
2023-01-05 07:57:02,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:57:02,517 INFO:     Epoch: 46
2023-01-05 07:57:04,666 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46995349824428556, 'Total loss': 0.46995349824428556} | train loss {'Reaction outcome loss': 0.33553006683551045, 'Total loss': 0.33553006683551045}
2023-01-05 07:57:04,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:57:04,667 INFO:     Epoch: 47
2023-01-05 07:57:06,812 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46286264061927795, 'Total loss': 0.46286264061927795} | train loss {'Reaction outcome loss': 0.330151612659658, 'Total loss': 0.330151612659658}
2023-01-05 07:57:06,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:57:06,812 INFO:     Epoch: 48
2023-01-05 07:57:08,953 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4340623915195465, 'Total loss': 0.4340623915195465} | train loss {'Reaction outcome loss': 0.3250487717344378, 'Total loss': 0.3250487717344378}
2023-01-05 07:57:08,953 INFO:     Found new best model at epoch 48
2023-01-05 07:57:08,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:57:08,954 INFO:     Epoch: 49
2023-01-05 07:57:11,067 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5084514498710633, 'Total loss': 0.5084514498710633} | train loss {'Reaction outcome loss': 0.33466366534359265, 'Total loss': 0.33466366534359265}
2023-01-05 07:57:11,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:57:11,068 INFO:     Epoch: 50
2023-01-05 07:57:13,230 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4779312570889791, 'Total loss': 0.4779312570889791} | train loss {'Reaction outcome loss': 0.3167418942236117, 'Total loss': 0.3167418942236117}
2023-01-05 07:57:13,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:57:13,230 INFO:     Epoch: 51
2023-01-05 07:57:15,375 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45345261991024016, 'Total loss': 0.45345261991024016} | train loss {'Reaction outcome loss': 0.327996156946586, 'Total loss': 0.327996156946586}
2023-01-05 07:57:15,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:57:15,375 INFO:     Epoch: 52
2023-01-05 07:57:17,515 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4443555851777395, 'Total loss': 0.4443555851777395} | train loss {'Reaction outcome loss': 0.3185608467481432, 'Total loss': 0.3185608467481432}
2023-01-05 07:57:17,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:57:17,516 INFO:     Epoch: 53
2023-01-05 07:57:19,647 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4611450215180715, 'Total loss': 0.4611450215180715} | train loss {'Reaction outcome loss': 0.31686333774922104, 'Total loss': 0.31686333774922104}
2023-01-05 07:57:19,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:57:19,648 INFO:     Epoch: 54
2023-01-05 07:57:21,782 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4406409497062365, 'Total loss': 0.4406409497062365} | train loss {'Reaction outcome loss': 0.31474299972237896, 'Total loss': 0.31474299972237896}
2023-01-05 07:57:21,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:57:21,782 INFO:     Epoch: 55
2023-01-05 07:57:23,922 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44239159872134526, 'Total loss': 0.44239159872134526} | train loss {'Reaction outcome loss': 0.30820038108440645, 'Total loss': 0.30820038108440645}
2023-01-05 07:57:23,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:57:23,922 INFO:     Epoch: 56
2023-01-05 07:57:26,079 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45154323081175485, 'Total loss': 0.45154323081175485} | train loss {'Reaction outcome loss': 0.31323008837491056, 'Total loss': 0.31323008837491056}
2023-01-05 07:57:26,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:57:26,079 INFO:     Epoch: 57
2023-01-05 07:57:28,240 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4500551025072734, 'Total loss': 0.4500551025072734} | train loss {'Reaction outcome loss': 0.3062438359348117, 'Total loss': 0.3062438359348117}
2023-01-05 07:57:28,241 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:57:28,241 INFO:     Epoch: 58
2023-01-05 07:57:30,378 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.46413403352101645, 'Total loss': 0.46413403352101645} | train loss {'Reaction outcome loss': 0.30711647705005035, 'Total loss': 0.30711647705005035}
2023-01-05 07:57:30,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:57:30,378 INFO:     Epoch: 59
2023-01-05 07:57:32,518 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45661201775074006, 'Total loss': 0.45661201775074006} | train loss {'Reaction outcome loss': 0.3108945070446408, 'Total loss': 0.3108945070446408}
2023-01-05 07:57:32,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:57:32,518 INFO:     Epoch: 60
2023-01-05 07:57:34,668 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4505247200528781, 'Total loss': 0.4505247200528781} | train loss {'Reaction outcome loss': 0.3041553972492905, 'Total loss': 0.3041553972492905}
2023-01-05 07:57:34,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:57:34,669 INFO:     Epoch: 61
2023-01-05 07:57:36,852 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4788237730662028, 'Total loss': 0.4788237730662028} | train loss {'Reaction outcome loss': 0.2996625421963034, 'Total loss': 0.2996625421963034}
2023-01-05 07:57:36,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:57:36,852 INFO:     Epoch: 62
2023-01-05 07:57:39,001 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4533081591129303, 'Total loss': 0.4533081591129303} | train loss {'Reaction outcome loss': 0.2963331073631335, 'Total loss': 0.2963331073631335}
2023-01-05 07:57:39,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:57:39,001 INFO:     Epoch: 63
2023-01-05 07:57:41,177 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47000240385532377, 'Total loss': 0.47000240385532377} | train loss {'Reaction outcome loss': 0.2965464565195959, 'Total loss': 0.2965464565195959}
2023-01-05 07:57:41,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:57:41,178 INFO:     Epoch: 64
2023-01-05 07:57:43,318 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4355210464447737, 'Total loss': 0.4355210464447737} | train loss {'Reaction outcome loss': 0.29507474353822477, 'Total loss': 0.29507474353822477}
2023-01-05 07:57:43,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:57:43,318 INFO:     Epoch: 65
2023-01-05 07:57:45,465 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44252177675565085, 'Total loss': 0.44252177675565085} | train loss {'Reaction outcome loss': 0.29283080785705223, 'Total loss': 0.29283080785705223}
2023-01-05 07:57:45,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:57:45,466 INFO:     Epoch: 66
2023-01-05 07:57:47,643 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48887290159861246, 'Total loss': 0.48887290159861246} | train loss {'Reaction outcome loss': 0.2877940508897287, 'Total loss': 0.2877940508897287}
2023-01-05 07:57:47,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:57:47,643 INFO:     Epoch: 67
2023-01-05 07:57:49,831 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47905705620845157, 'Total loss': 0.47905705620845157} | train loss {'Reaction outcome loss': 0.29002443546034995, 'Total loss': 0.29002443546034995}
2023-01-05 07:57:49,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:57:49,832 INFO:     Epoch: 68
2023-01-05 07:57:51,967 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4850303073724111, 'Total loss': 0.4850303073724111} | train loss {'Reaction outcome loss': 0.29399024257368417, 'Total loss': 0.29399024257368417}
2023-01-05 07:57:51,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:57:51,967 INFO:     Epoch: 69
2023-01-05 07:57:54,127 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4559500922759374, 'Total loss': 0.4559500922759374} | train loss {'Reaction outcome loss': 0.28756510841585425, 'Total loss': 0.28756510841585425}
2023-01-05 07:57:54,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:57:54,128 INFO:     Epoch: 70
2023-01-05 07:57:56,265 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45220780471960703, 'Total loss': 0.45220780471960703} | train loss {'Reaction outcome loss': 0.2876766476929732, 'Total loss': 0.2876766476929732}
2023-01-05 07:57:56,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:57:56,265 INFO:     Epoch: 71
2023-01-05 07:57:58,397 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47734124064445493, 'Total loss': 0.47734124064445493} | train loss {'Reaction outcome loss': 0.28530764901996963, 'Total loss': 0.28530764901996963}
2023-01-05 07:57:58,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:57:58,397 INFO:     Epoch: 72
2023-01-05 07:58:00,547 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.5028170208136241, 'Total loss': 0.5028170208136241} | train loss {'Reaction outcome loss': 0.2801033237024489, 'Total loss': 0.2801033237024489}
2023-01-05 07:58:00,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:58:00,548 INFO:     Epoch: 73
2023-01-05 07:58:02,698 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4633112370967865, 'Total loss': 0.4633112370967865} | train loss {'Reaction outcome loss': 0.2816573026977534, 'Total loss': 0.2816573026977534}
2023-01-05 07:58:02,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:58:02,698 INFO:     Epoch: 74
2023-01-05 07:58:04,840 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47376129825909935, 'Total loss': 0.47376129825909935} | train loss {'Reaction outcome loss': 0.2795168518421859, 'Total loss': 0.2795168518421859}
2023-01-05 07:58:04,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:58:04,841 INFO:     Epoch: 75
2023-01-05 07:58:06,972 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48137270907560986, 'Total loss': 0.48137270907560986} | train loss {'Reaction outcome loss': 0.27857867024675775, 'Total loss': 0.27857867024675775}
2023-01-05 07:58:06,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:58:06,973 INFO:     Epoch: 76
2023-01-05 07:58:09,107 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.456742000579834, 'Total loss': 0.456742000579834} | train loss {'Reaction outcome loss': 0.2719784299605084, 'Total loss': 0.2719784299605084}
2023-01-05 07:58:09,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:58:09,107 INFO:     Epoch: 77
2023-01-05 07:58:11,247 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4311963587999344, 'Total loss': 0.4311963587999344} | train loss {'Reaction outcome loss': 0.27615970505034404, 'Total loss': 0.27615970505034404}
2023-01-05 07:58:11,249 INFO:     Found new best model at epoch 77
2023-01-05 07:58:11,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:58:11,250 INFO:     Epoch: 78
2023-01-05 07:58:13,400 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4719439794619878, 'Total loss': 0.4719439794619878} | train loss {'Reaction outcome loss': 0.2697820643738021, 'Total loss': 0.2697820643738021}
2023-01-05 07:58:13,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:58:13,401 INFO:     Epoch: 79
2023-01-05 07:58:15,525 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4516072084506353, 'Total loss': 0.4516072084506353} | train loss {'Reaction outcome loss': 0.28112155634121305, 'Total loss': 0.28112155634121305}
2023-01-05 07:58:15,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:58:15,525 INFO:     Epoch: 80
2023-01-05 07:58:17,656 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4676290730635325, 'Total loss': 0.4676290730635325} | train loss {'Reaction outcome loss': 0.26916561830435354, 'Total loss': 0.26916561830435354}
2023-01-05 07:58:17,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:58:17,657 INFO:     Epoch: 81
2023-01-05 07:58:19,793 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.46876280307769774, 'Total loss': 0.46876280307769774} | train loss {'Reaction outcome loss': 0.26602973828404924, 'Total loss': 0.26602973828404924}
2023-01-05 07:58:19,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:58:19,793 INFO:     Epoch: 82
2023-01-05 07:58:21,911 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44418153166770935, 'Total loss': 0.44418153166770935} | train loss {'Reaction outcome loss': 0.26204317843500713, 'Total loss': 0.26204317843500713}
2023-01-05 07:58:21,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:58:21,912 INFO:     Epoch: 83
2023-01-05 07:58:24,053 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4706117073694865, 'Total loss': 0.4706117073694865} | train loss {'Reaction outcome loss': 0.265341491285494, 'Total loss': 0.265341491285494}
2023-01-05 07:58:24,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:58:24,053 INFO:     Epoch: 84
2023-01-05 07:58:26,187 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.47332614262898765, 'Total loss': 0.47332614262898765} | train loss {'Reaction outcome loss': 0.2693849879786046, 'Total loss': 0.2693849879786046}
2023-01-05 07:58:26,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:58:26,187 INFO:     Epoch: 85
2023-01-05 07:58:28,329 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4532485008239746, 'Total loss': 0.4532485008239746} | train loss {'Reaction outcome loss': 0.26100973181263376, 'Total loss': 0.26100973181263376}
2023-01-05 07:58:28,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:58:28,329 INFO:     Epoch: 86
2023-01-05 07:58:30,483 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4484020402034124, 'Total loss': 0.4484020402034124} | train loss {'Reaction outcome loss': 0.2605700424607218, 'Total loss': 0.2605700424607218}
2023-01-05 07:58:30,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:58:30,484 INFO:     Epoch: 87
2023-01-05 07:58:32,609 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4990487575531006, 'Total loss': 0.4990487575531006} | train loss {'Reaction outcome loss': 0.2552841068143501, 'Total loss': 0.2552841068143501}
2023-01-05 07:58:32,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:58:32,609 INFO:     Epoch: 88
2023-01-05 07:58:34,753 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48438277244567873, 'Total loss': 0.48438277244567873} | train loss {'Reaction outcome loss': 0.2603514302304409, 'Total loss': 0.2603514302304409}
2023-01-05 07:58:34,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:58:34,753 INFO:     Epoch: 89
2023-01-05 07:58:36,900 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.43767517308394116, 'Total loss': 0.43767517308394116} | train loss {'Reaction outcome loss': 0.2601679251087408, 'Total loss': 0.2601679251087408}
2023-01-05 07:58:36,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:58:36,900 INFO:     Epoch: 90
2023-01-05 07:58:39,028 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4641907682021459, 'Total loss': 0.4641907682021459} | train loss {'Reaction outcome loss': 0.25437757994191057, 'Total loss': 0.25437757994191057}
2023-01-05 07:58:39,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:58:39,028 INFO:     Epoch: 91
2023-01-05 07:58:41,155 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4491337617238363, 'Total loss': 0.4491337617238363} | train loss {'Reaction outcome loss': 0.2518204013361548, 'Total loss': 0.2518204013361548}
2023-01-05 07:58:41,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:58:41,156 INFO:     Epoch: 92
2023-01-05 07:58:43,270 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4989619175593058, 'Total loss': 0.4989619175593058} | train loss {'Reaction outcome loss': 0.2554940988724358, 'Total loss': 0.2554940988724358}
2023-01-05 07:58:43,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:58:43,270 INFO:     Epoch: 93
2023-01-05 07:58:45,385 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4528680920600891, 'Total loss': 0.4528680920600891} | train loss {'Reaction outcome loss': 0.2492653749624852, 'Total loss': 0.2492653749624852}
2023-01-05 07:58:45,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:58:45,385 INFO:     Epoch: 94
2023-01-05 07:58:47,521 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4114123205343882, 'Total loss': 0.4114123205343882} | train loss {'Reaction outcome loss': 0.2568873717605959, 'Total loss': 0.2568873717605959}
2023-01-05 07:58:47,522 INFO:     Found new best model at epoch 94
2023-01-05 07:58:47,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:58:47,523 INFO:     Epoch: 95
2023-01-05 07:58:49,659 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4324935138225555, 'Total loss': 0.4324935138225555} | train loss {'Reaction outcome loss': 0.24981760598012132, 'Total loss': 0.24981760598012132}
2023-01-05 07:58:49,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:58:49,659 INFO:     Epoch: 96
2023-01-05 07:58:51,805 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4690807670354843, 'Total loss': 0.4690807670354843} | train loss {'Reaction outcome loss': 0.2501343622341426, 'Total loss': 0.2501343622341426}
2023-01-05 07:58:51,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:58:51,806 INFO:     Epoch: 97
2023-01-05 07:58:53,932 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4646061013142268, 'Total loss': 0.4646061013142268} | train loss {'Reaction outcome loss': 0.24805560646184388, 'Total loss': 0.24805560646184388}
2023-01-05 07:58:53,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:58:53,932 INFO:     Epoch: 98
2023-01-05 07:58:56,065 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44412150581677756, 'Total loss': 0.44412150581677756} | train loss {'Reaction outcome loss': 0.25222429332160223, 'Total loss': 0.25222429332160223}
2023-01-05 07:58:56,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:58:56,065 INFO:     Epoch: 99
2023-01-05 07:58:58,215 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4826126535733541, 'Total loss': 0.4826126535733541} | train loss {'Reaction outcome loss': 0.24792488654871492, 'Total loss': 0.24792488654871492}
2023-01-05 07:58:58,215 INFO:     Best model found after epoch 95 of 100.
2023-01-05 07:58:58,215 INFO:   Done with stage: TRAINING
2023-01-05 07:58:58,215 INFO:   Starting stage: EVALUATION
2023-01-05 07:58:58,354 INFO:   Done with stage: EVALUATION
2023-01-05 07:58:58,354 INFO:   Leaving out SEQ value Fold_5
2023-01-05 07:58:58,367 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 07:58:58,367 INFO:   Starting stage: FEATURE SCALING
2023-01-05 07:58:59,022 INFO:   Done with stage: FEATURE SCALING
2023-01-05 07:58:59,022 INFO:   Starting stage: SCALING TARGETS
2023-01-05 07:58:59,091 INFO:   Done with stage: SCALING TARGETS
2023-01-05 07:58:59,091 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:58:59,091 INFO:     No hyperparam tuning for this model
2023-01-05 07:58:59,091 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 07:58:59,091 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 07:58:59,092 INFO:     None feature selector for col prot
2023-01-05 07:58:59,092 INFO:     None feature selector for col prot
2023-01-05 07:58:59,092 INFO:     None feature selector for col prot
2023-01-05 07:58:59,093 INFO:     None feature selector for col chem
2023-01-05 07:58:59,093 INFO:     None feature selector for col chem
2023-01-05 07:58:59,093 INFO:     None feature selector for col chem
2023-01-05 07:58:59,093 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 07:58:59,093 INFO:   Starting stage: BUILD MODEL
2023-01-05 07:58:59,095 INFO:     Number of params in model 72901
2023-01-05 07:58:59,098 INFO:   Done with stage: BUILD MODEL
2023-01-05 07:58:59,098 INFO:   Starting stage: TRAINING
2023-01-05 07:58:59,156 INFO:     Val loss before train {'Reaction outcome loss': 1.074477207660675, 'Total loss': 1.074477207660675}
2023-01-05 07:58:59,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:58:59,156 INFO:     Epoch: 0
2023-01-05 07:59:01,306 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8672620356082916, 'Total loss': 0.8672620356082916} | train loss {'Reaction outcome loss': 0.9243629578554976, 'Total loss': 0.9243629578554976}
2023-01-05 07:59:01,307 INFO:     Found new best model at epoch 0
2023-01-05 07:59:01,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:59:01,308 INFO:     Epoch: 1
2023-01-05 07:59:03,467 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.682290542125702, 'Total loss': 0.682290542125702} | train loss {'Reaction outcome loss': 0.762148591345581, 'Total loss': 0.762148591345581}
2023-01-05 07:59:03,467 INFO:     Found new best model at epoch 1
2023-01-05 07:59:03,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:59:03,469 INFO:     Epoch: 2
2023-01-05 07:59:05,607 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5856457153956095, 'Total loss': 0.5856457153956095} | train loss {'Reaction outcome loss': 0.6299880462280218, 'Total loss': 0.6299880462280218}
2023-01-05 07:59:05,608 INFO:     Found new best model at epoch 2
2023-01-05 07:59:05,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:59:05,609 INFO:     Epoch: 3
2023-01-05 07:59:07,745 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5443429787953694, 'Total loss': 0.5443429787953694} | train loss {'Reaction outcome loss': 0.5384269046759151, 'Total loss': 0.5384269046759151}
2023-01-05 07:59:07,745 INFO:     Found new best model at epoch 3
2023-01-05 07:59:07,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:59:07,747 INFO:     Epoch: 4
2023-01-05 07:59:09,906 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5590190500020981, 'Total loss': 0.5590190500020981} | train loss {'Reaction outcome loss': 0.5174176005977273, 'Total loss': 0.5174176005977273}
2023-01-05 07:59:09,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:59:09,906 INFO:     Epoch: 5
2023-01-05 07:59:12,061 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5401712119579315, 'Total loss': 0.5401712119579315} | train loss {'Reaction outcome loss': 0.5069879257015587, 'Total loss': 0.5069879257015587}
2023-01-05 07:59:12,061 INFO:     Found new best model at epoch 5
2023-01-05 07:59:12,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:59:12,062 INFO:     Epoch: 6
2023-01-05 07:59:14,214 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5514510413010915, 'Total loss': 0.5514510413010915} | train loss {'Reaction outcome loss': 0.493893805310886, 'Total loss': 0.493893805310886}
2023-01-05 07:59:14,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:59:14,215 INFO:     Epoch: 7
2023-01-05 07:59:16,356 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5016502132018407, 'Total loss': 0.5016502132018407} | train loss {'Reaction outcome loss': 0.4910964906971524, 'Total loss': 0.4910964906971524}
2023-01-05 07:59:16,357 INFO:     Found new best model at epoch 7
2023-01-05 07:59:16,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:59:16,359 INFO:     Epoch: 8
2023-01-05 07:59:18,505 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48227432171503704, 'Total loss': 0.48227432171503704} | train loss {'Reaction outcome loss': 0.4769121834171423, 'Total loss': 0.4769121834171423}
2023-01-05 07:59:18,506 INFO:     Found new best model at epoch 8
2023-01-05 07:59:18,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:59:18,507 INFO:     Epoch: 9
2023-01-05 07:59:20,649 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5201889912287394, 'Total loss': 0.5201889912287394} | train loss {'Reaction outcome loss': 0.4972576548385879, 'Total loss': 0.4972576548385879}
2023-01-05 07:59:20,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:59:20,649 INFO:     Epoch: 10
2023-01-05 07:59:22,804 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4911167780558268, 'Total loss': 0.4911167780558268} | train loss {'Reaction outcome loss': 0.4727921844417034, 'Total loss': 0.4727921844417034}
2023-01-05 07:59:22,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:59:22,804 INFO:     Epoch: 11
2023-01-05 07:59:24,956 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5121693342924118, 'Total loss': 0.5121693342924118} | train loss {'Reaction outcome loss': 0.4670470524309338, 'Total loss': 0.4670470524309338}
2023-01-05 07:59:24,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:59:24,957 INFO:     Epoch: 12
2023-01-05 07:59:27,122 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5046386177341143, 'Total loss': 0.5046386177341143} | train loss {'Reaction outcome loss': 0.4602911124356847, 'Total loss': 0.4602911124356847}
2023-01-05 07:59:27,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:59:27,122 INFO:     Epoch: 13
2023-01-05 07:59:29,271 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47622156143188477, 'Total loss': 0.47622156143188477} | train loss {'Reaction outcome loss': 0.4492230891331058, 'Total loss': 0.4492230891331058}
2023-01-05 07:59:29,271 INFO:     Found new best model at epoch 13
2023-01-05 07:59:29,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:59:29,273 INFO:     Epoch: 14
2023-01-05 07:59:31,420 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48838292161623637, 'Total loss': 0.48838292161623637} | train loss {'Reaction outcome loss': 0.4536818265914917, 'Total loss': 0.4536818265914917}
2023-01-05 07:59:31,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:59:31,420 INFO:     Epoch: 15
2023-01-05 07:59:33,572 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.49686210652192436, 'Total loss': 0.49686210652192436} | train loss {'Reaction outcome loss': 0.4458605238562112, 'Total loss': 0.4458605238562112}
2023-01-05 07:59:33,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:59:33,573 INFO:     Epoch: 16
2023-01-05 07:59:35,736 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49381943146387736, 'Total loss': 0.49381943146387736} | train loss {'Reaction outcome loss': 0.4347804416885491, 'Total loss': 0.4347804416885491}
2023-01-05 07:59:35,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:59:35,737 INFO:     Epoch: 17
2023-01-05 07:59:37,910 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.48269311487674715, 'Total loss': 0.48269311487674715} | train loss {'Reaction outcome loss': 0.43820468289777637, 'Total loss': 0.43820468289777637}
2023-01-05 07:59:37,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:59:37,910 INFO:     Epoch: 18
2023-01-05 07:59:40,045 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.461616238951683, 'Total loss': 0.461616238951683} | train loss {'Reaction outcome loss': 0.4321269022597783, 'Total loss': 0.4321269022597783}
2023-01-05 07:59:40,045 INFO:     Found new best model at epoch 18
2023-01-05 07:59:40,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:59:40,047 INFO:     Epoch: 19
2023-01-05 07:59:42,188 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4997047285238902, 'Total loss': 0.4997047285238902} | train loss {'Reaction outcome loss': 0.4280474838314399, 'Total loss': 0.4280474838314399}
2023-01-05 07:59:42,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:59:42,188 INFO:     Epoch: 20
2023-01-05 07:59:44,327 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4780018548170725, 'Total loss': 0.4780018548170725} | train loss {'Reaction outcome loss': 0.4236793578737348, 'Total loss': 0.4236793578737348}
2023-01-05 07:59:44,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:59:44,328 INFO:     Epoch: 21
2023-01-05 07:59:46,480 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44549904217322667, 'Total loss': 0.44549904217322667} | train loss {'Reaction outcome loss': 0.4187087066896746, 'Total loss': 0.4187087066896746}
2023-01-05 07:59:46,480 INFO:     Found new best model at epoch 21
2023-01-05 07:59:46,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:59:46,481 INFO:     Epoch: 22
2023-01-05 07:59:48,642 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.49450607498486837, 'Total loss': 0.49450607498486837} | train loss {'Reaction outcome loss': 0.4099537575021859, 'Total loss': 0.4099537575021859}
2023-01-05 07:59:48,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:59:48,642 INFO:     Epoch: 23
2023-01-05 07:59:50,798 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4814450363318125, 'Total loss': 0.4814450363318125} | train loss {'Reaction outcome loss': 0.4129594153002498, 'Total loss': 0.4129594153002498}
2023-01-05 07:59:50,798 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:59:50,798 INFO:     Epoch: 24
2023-01-05 07:59:52,933 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.48114680250485736, 'Total loss': 0.48114680250485736} | train loss {'Reaction outcome loss': 0.40991713484962916, 'Total loss': 0.40991713484962916}
2023-01-05 07:59:52,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:59:52,935 INFO:     Epoch: 25
2023-01-05 07:59:55,075 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4709496061007182, 'Total loss': 0.4709496061007182} | train loss {'Reaction outcome loss': 0.40804005988225667, 'Total loss': 0.40804005988225667}
2023-01-05 07:59:55,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:59:55,075 INFO:     Epoch: 26
2023-01-05 07:59:57,231 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.48939365645249683, 'Total loss': 0.48939365645249683} | train loss {'Reaction outcome loss': 0.40057841877527267, 'Total loss': 0.40057841877527267}
2023-01-05 07:59:57,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:59:57,231 INFO:     Epoch: 27
2023-01-05 07:59:59,398 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46670827865600584, 'Total loss': 0.46670827865600584} | train loss {'Reaction outcome loss': 0.39633219921961427, 'Total loss': 0.39633219921961427}
2023-01-05 07:59:59,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 07:59:59,399 INFO:     Epoch: 28
2023-01-05 08:00:01,578 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5101960877577464, 'Total loss': 0.5101960877577464} | train loss {'Reaction outcome loss': 0.3894067753808222, 'Total loss': 0.3894067753808222}
2023-01-05 08:00:01,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:00:01,578 INFO:     Epoch: 29
2023-01-05 08:00:03,730 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4584989627202352, 'Total loss': 0.4584989627202352} | train loss {'Reaction outcome loss': 0.3952829939569684, 'Total loss': 0.3952829939569684}
2023-01-05 08:00:03,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:00:03,730 INFO:     Epoch: 30
2023-01-05 08:00:05,884 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4580805500348409, 'Total loss': 0.4580805500348409} | train loss {'Reaction outcome loss': 0.38772233007425116, 'Total loss': 0.38772233007425116}
2023-01-05 08:00:05,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:00:05,884 INFO:     Epoch: 31
2023-01-05 08:00:08,049 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4497787485520045, 'Total loss': 0.4497787485520045} | train loss {'Reaction outcome loss': 0.3844890968108118, 'Total loss': 0.3844890968108118}
2023-01-05 08:00:08,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:00:08,049 INFO:     Epoch: 32
2023-01-05 08:00:10,203 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.47381431857744855, 'Total loss': 0.47381431857744855} | train loss {'Reaction outcome loss': 0.38096925362512685, 'Total loss': 0.38096925362512685}
2023-01-05 08:00:10,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:00:10,203 INFO:     Epoch: 33
2023-01-05 08:00:12,361 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4672817538181941, 'Total loss': 0.4672817538181941} | train loss {'Reaction outcome loss': 0.3965083845499633, 'Total loss': 0.3965083845499633}
2023-01-05 08:00:12,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:00:12,362 INFO:     Epoch: 34
2023-01-05 08:00:14,529 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47287591099739074, 'Total loss': 0.47287591099739074} | train loss {'Reaction outcome loss': 0.42807975299217726, 'Total loss': 0.42807975299217726}
2023-01-05 08:00:14,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:00:14,529 INFO:     Epoch: 35
2023-01-05 08:00:16,670 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4637166420618693, 'Total loss': 0.4637166420618693} | train loss {'Reaction outcome loss': 0.38135567926160613, 'Total loss': 0.38135567926160613}
2023-01-05 08:00:16,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:00:16,670 INFO:     Epoch: 36
2023-01-05 08:00:18,819 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46042293508847554, 'Total loss': 0.46042293508847554} | train loss {'Reaction outcome loss': 0.37670162332959584, 'Total loss': 0.37670162332959584}
2023-01-05 08:00:18,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:00:18,819 INFO:     Epoch: 37
2023-01-05 08:00:20,955 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4370124340057373, 'Total loss': 0.4370124340057373} | train loss {'Reaction outcome loss': 0.37395918436780357, 'Total loss': 0.37395918436780357}
2023-01-05 08:00:20,956 INFO:     Found new best model at epoch 37
2023-01-05 08:00:20,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:00:20,957 INFO:     Epoch: 38
2023-01-05 08:00:23,113 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.43591129779815674, 'Total loss': 0.43591129779815674} | train loss {'Reaction outcome loss': 0.385734900518361, 'Total loss': 0.385734900518361}
2023-01-05 08:00:23,114 INFO:     Found new best model at epoch 38
2023-01-05 08:00:23,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:00:23,115 INFO:     Epoch: 39
2023-01-05 08:00:25,272 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4473786443471909, 'Total loss': 0.4473786443471909} | train loss {'Reaction outcome loss': 0.3598797418239553, 'Total loss': 0.3598797418239553}
2023-01-05 08:00:25,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:00:25,272 INFO:     Epoch: 40
2023-01-05 08:00:27,411 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4341521600882212, 'Total loss': 0.4341521600882212} | train loss {'Reaction outcome loss': 0.35533459359725966, 'Total loss': 0.35533459359725966}
2023-01-05 08:00:27,411 INFO:     Found new best model at epoch 40
2023-01-05 08:00:27,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:00:27,412 INFO:     Epoch: 41
2023-01-05 08:00:29,567 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43657676577568055, 'Total loss': 0.43657676577568055} | train loss {'Reaction outcome loss': 0.3599543398131441, 'Total loss': 0.3599543398131441}
2023-01-05 08:00:29,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:00:29,568 INFO:     Epoch: 42
2023-01-05 08:00:31,734 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42681130667527517, 'Total loss': 0.42681130667527517} | train loss {'Reaction outcome loss': 0.3529625585761623, 'Total loss': 0.3529625585761623}
2023-01-05 08:00:31,734 INFO:     Found new best model at epoch 42
2023-01-05 08:00:31,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:00:31,735 INFO:     Epoch: 43
2023-01-05 08:00:33,906 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47998040517171225, 'Total loss': 0.47998040517171225} | train loss {'Reaction outcome loss': 0.3485154429480104, 'Total loss': 0.3485154429480104}
2023-01-05 08:00:33,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:00:33,906 INFO:     Epoch: 44
2023-01-05 08:00:36,069 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44744813988606136, 'Total loss': 0.44744813988606136} | train loss {'Reaction outcome loss': 0.3476076934594607, 'Total loss': 0.3476076934594607}
2023-01-05 08:00:36,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:00:36,070 INFO:     Epoch: 45
2023-01-05 08:00:38,241 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4383209307988485, 'Total loss': 0.4383209307988485} | train loss {'Reaction outcome loss': 0.3464223544916435, 'Total loss': 0.3464223544916435}
2023-01-05 08:00:38,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:00:38,242 INFO:     Epoch: 46
2023-01-05 08:00:40,381 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46038590917984645, 'Total loss': 0.46038590917984645} | train loss {'Reaction outcome loss': 0.33991792290960776, 'Total loss': 0.33991792290960776}
2023-01-05 08:00:40,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:00:40,381 INFO:     Epoch: 47
2023-01-05 08:00:42,557 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42754326860109965, 'Total loss': 0.42754326860109965} | train loss {'Reaction outcome loss': 0.3372993321981335, 'Total loss': 0.3372993321981335}
2023-01-05 08:00:42,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:00:42,557 INFO:     Epoch: 48
2023-01-05 08:00:44,714 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4559949775536855, 'Total loss': 0.4559949775536855} | train loss {'Reaction outcome loss': 0.34561655049522716, 'Total loss': 0.34561655049522716}
2023-01-05 08:00:44,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:00:44,714 INFO:     Epoch: 49
2023-01-05 08:00:46,869 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45515625178813934, 'Total loss': 0.45515625178813934} | train loss {'Reaction outcome loss': 0.3582937459695909, 'Total loss': 0.3582937459695909}
2023-01-05 08:00:46,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:00:46,869 INFO:     Epoch: 50
2023-01-05 08:00:49,034 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41566313604513805, 'Total loss': 0.41566313604513805} | train loss {'Reaction outcome loss': 0.33420369510505404, 'Total loss': 0.33420369510505404}
2023-01-05 08:00:49,034 INFO:     Found new best model at epoch 50
2023-01-05 08:00:49,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:00:49,036 INFO:     Epoch: 51
2023-01-05 08:00:51,180 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.49034474889437357, 'Total loss': 0.49034474889437357} | train loss {'Reaction outcome loss': 0.3296191053653973, 'Total loss': 0.3296191053653973}
2023-01-05 08:00:51,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:00:51,181 INFO:     Epoch: 52
2023-01-05 08:00:53,337 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4058813398083051, 'Total loss': 0.4058813398083051} | train loss {'Reaction outcome loss': 0.3221752126793971, 'Total loss': 0.3221752126793971}
2023-01-05 08:00:53,337 INFO:     Found new best model at epoch 52
2023-01-05 08:00:53,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:00:53,338 INFO:     Epoch: 53
2023-01-05 08:00:55,293 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4296799699465434, 'Total loss': 0.4296799699465434} | train loss {'Reaction outcome loss': 0.31464029765924934, 'Total loss': 0.31464029765924934}
2023-01-05 08:00:55,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:00:55,293 INFO:     Epoch: 54
2023-01-05 08:00:57,445 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44231858650843303, 'Total loss': 0.44231858650843303} | train loss {'Reaction outcome loss': 0.3148409713630563, 'Total loss': 0.3148409713630563}
2023-01-05 08:00:57,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:00:57,445 INFO:     Epoch: 55
2023-01-05 08:00:59,598 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44113504787286123, 'Total loss': 0.44113504787286123} | train loss {'Reaction outcome loss': 0.31573262781181466, 'Total loss': 0.31573262781181466}
2023-01-05 08:00:59,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:00:59,599 INFO:     Epoch: 56
2023-01-05 08:01:01,737 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4208211322625478, 'Total loss': 0.4208211322625478} | train loss {'Reaction outcome loss': 0.31351476691897784, 'Total loss': 0.31351476691897784}
2023-01-05 08:01:01,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:01:01,738 INFO:     Epoch: 57
2023-01-05 08:01:03,874 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4677325944105784, 'Total loss': 0.4677325944105784} | train loss {'Reaction outcome loss': 0.3069135040612901, 'Total loss': 0.3069135040612901}
2023-01-05 08:01:03,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:01:03,874 INFO:     Epoch: 58
2023-01-05 08:01:06,021 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41778723200162254, 'Total loss': 0.41778723200162254} | train loss {'Reaction outcome loss': 0.3146265799675704, 'Total loss': 0.3146265799675704}
2023-01-05 08:01:06,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:01:06,022 INFO:     Epoch: 59
2023-01-05 08:01:08,186 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43426411747932436, 'Total loss': 0.43426411747932436} | train loss {'Reaction outcome loss': 0.3139517882002005, 'Total loss': 0.3139517882002005}
2023-01-05 08:01:08,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:01:08,186 INFO:     Epoch: 60
2023-01-05 08:01:10,341 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4548596819241842, 'Total loss': 0.4548596819241842} | train loss {'Reaction outcome loss': 0.3550796161875621, 'Total loss': 0.3550796161875621}
2023-01-05 08:01:10,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:01:10,341 INFO:     Epoch: 61
2023-01-05 08:01:12,494 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47013457616170246, 'Total loss': 0.47013457616170246} | train loss {'Reaction outcome loss': 0.3189707589403227, 'Total loss': 0.3189707589403227}
2023-01-05 08:01:12,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:01:12,495 INFO:     Epoch: 62
2023-01-05 08:01:14,617 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43834627866744996, 'Total loss': 0.43834627866744996} | train loss {'Reaction outcome loss': 0.30548302288440504, 'Total loss': 0.30548302288440504}
2023-01-05 08:01:14,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:01:14,618 INFO:     Epoch: 63
2023-01-05 08:01:16,771 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4738309860229492, 'Total loss': 0.4738309860229492} | train loss {'Reaction outcome loss': 0.2977773737655008, 'Total loss': 0.2977773737655008}
2023-01-05 08:01:16,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:01:16,772 INFO:     Epoch: 64
2023-01-05 08:01:18,929 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.45005252261956535, 'Total loss': 0.45005252261956535} | train loss {'Reaction outcome loss': 0.29705401114019414, 'Total loss': 0.29705401114019414}
2023-01-05 08:01:18,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:01:18,930 INFO:     Epoch: 65
2023-01-05 08:01:21,096 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4244740774234136, 'Total loss': 0.4244740774234136} | train loss {'Reaction outcome loss': 0.3042636514114945, 'Total loss': 0.3042636514114945}
2023-01-05 08:01:21,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:01:21,096 INFO:     Epoch: 66
2023-01-05 08:01:23,223 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40670563901464146, 'Total loss': 0.40670563901464146} | train loss {'Reaction outcome loss': 0.29875340288423974, 'Total loss': 0.29875340288423974}
2023-01-05 08:01:23,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:01:23,223 INFO:     Epoch: 67
2023-01-05 08:01:25,359 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4064458926518758, 'Total loss': 0.4064458926518758} | train loss {'Reaction outcome loss': 0.2983902594972186, 'Total loss': 0.2983902594972186}
2023-01-05 08:01:25,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:01:25,359 INFO:     Epoch: 68
2023-01-05 08:01:27,525 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.49106717184185983, 'Total loss': 0.49106717184185983} | train loss {'Reaction outcome loss': 0.2895000966205059, 'Total loss': 0.2895000966205059}
2023-01-05 08:01:27,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:01:27,525 INFO:     Epoch: 69
2023-01-05 08:01:29,691 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.42003605763117474, 'Total loss': 0.42003605763117474} | train loss {'Reaction outcome loss': 0.2920405876863262, 'Total loss': 0.2920405876863262}
2023-01-05 08:01:29,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:01:29,691 INFO:     Epoch: 70
2023-01-05 08:01:31,864 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4428640147050222, 'Total loss': 0.4428640147050222} | train loss {'Reaction outcome loss': 0.2879381235688925, 'Total loss': 0.2879381235688925}
2023-01-05 08:01:31,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:01:31,865 INFO:     Epoch: 71
2023-01-05 08:01:34,035 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4364381531874339, 'Total loss': 0.4364381531874339} | train loss {'Reaction outcome loss': 0.28364344890131515, 'Total loss': 0.28364344890131515}
2023-01-05 08:01:34,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:01:34,035 INFO:     Epoch: 72
2023-01-05 08:01:36,201 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40764146745204927, 'Total loss': 0.40764146745204927} | train loss {'Reaction outcome loss': 0.2867692093351397, 'Total loss': 0.2867692093351397}
2023-01-05 08:01:36,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:01:36,202 INFO:     Epoch: 73
2023-01-05 08:01:38,351 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44113964041074116, 'Total loss': 0.44113964041074116} | train loss {'Reaction outcome loss': 0.2845171938069921, 'Total loss': 0.2845171938069921}
2023-01-05 08:01:38,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:01:38,351 INFO:     Epoch: 74
2023-01-05 08:01:40,513 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.42577967842419945, 'Total loss': 0.42577967842419945} | train loss {'Reaction outcome loss': 0.28143213261964906, 'Total loss': 0.28143213261964906}
2023-01-05 08:01:40,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:01:40,513 INFO:     Epoch: 75
2023-01-05 08:01:42,676 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4042117198308309, 'Total loss': 0.4042117198308309} | train loss {'Reaction outcome loss': 0.2757795789427515, 'Total loss': 0.2757795789427515}
2023-01-05 08:01:42,677 INFO:     Found new best model at epoch 75
2023-01-05 08:01:42,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:01:42,678 INFO:     Epoch: 76
2023-01-05 08:01:44,826 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3849122037490209, 'Total loss': 0.3849122037490209} | train loss {'Reaction outcome loss': 0.28499951634718024, 'Total loss': 0.28499951634718024}
2023-01-05 08:01:44,826 INFO:     Found new best model at epoch 76
2023-01-05 08:01:44,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:01:44,827 INFO:     Epoch: 77
2023-01-05 08:01:46,973 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4135182976722717, 'Total loss': 0.4135182976722717} | train loss {'Reaction outcome loss': 0.3208407522584109, 'Total loss': 0.3208407522584109}
2023-01-05 08:01:46,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:01:46,974 INFO:     Epoch: 78
2023-01-05 08:01:49,114 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43359028697013857, 'Total loss': 0.43359028697013857} | train loss {'Reaction outcome loss': 0.2773259580903012, 'Total loss': 0.2773259580903012}
2023-01-05 08:01:49,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:01:49,114 INFO:     Epoch: 79
2023-01-05 08:01:51,255 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4273632695277532, 'Total loss': 0.4273632695277532} | train loss {'Reaction outcome loss': 0.27021217546628223, 'Total loss': 0.27021217546628223}
2023-01-05 08:01:51,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:01:51,256 INFO:     Epoch: 80
2023-01-05 08:01:53,411 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41656087239583334, 'Total loss': 0.41656087239583334} | train loss {'Reaction outcome loss': 0.26471009092305053, 'Total loss': 0.26471009092305053}
2023-01-05 08:01:53,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:01:53,412 INFO:     Epoch: 81
2023-01-05 08:01:55,564 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3744401524464289, 'Total loss': 0.3744401524464289} | train loss {'Reaction outcome loss': 0.26995902518957743, 'Total loss': 0.26995902518957743}
2023-01-05 08:01:55,565 INFO:     Found new best model at epoch 81
2023-01-05 08:01:55,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:01:55,566 INFO:     Epoch: 82
2023-01-05 08:01:57,734 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.43392353951931, 'Total loss': 0.43392353951931} | train loss {'Reaction outcome loss': 0.26568011668227287, 'Total loss': 0.26568011668227287}
2023-01-05 08:01:57,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:01:57,734 INFO:     Epoch: 83
2023-01-05 08:01:59,899 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.37152841488520305, 'Total loss': 0.37152841488520305} | train loss {'Reaction outcome loss': 0.26587232963546464, 'Total loss': 0.26587232963546464}
2023-01-05 08:01:59,899 INFO:     Found new best model at epoch 83
2023-01-05 08:01:59,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:01:59,900 INFO:     Epoch: 84
2023-01-05 08:02:02,033 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42014448742071786, 'Total loss': 0.42014448742071786} | train loss {'Reaction outcome loss': 0.2603373463523736, 'Total loss': 0.2603373463523736}
2023-01-05 08:02:02,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:02:02,033 INFO:     Epoch: 85
2023-01-05 08:02:04,193 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.434516320625941, 'Total loss': 0.434516320625941} | train loss {'Reaction outcome loss': 0.26468846833576326, 'Total loss': 0.26468846833576326}
2023-01-05 08:02:04,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:02:04,193 INFO:     Epoch: 86
2023-01-05 08:02:06,362 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4143509536981583, 'Total loss': 0.4143509536981583} | train loss {'Reaction outcome loss': 0.27033531265434524, 'Total loss': 0.27033531265434524}
2023-01-05 08:02:06,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:02:06,363 INFO:     Epoch: 87
2023-01-05 08:02:08,508 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.38779823084672294, 'Total loss': 0.38779823084672294} | train loss {'Reaction outcome loss': 0.2652543629452154, 'Total loss': 0.2652543629452154}
2023-01-05 08:02:08,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:02:08,509 INFO:     Epoch: 88
2023-01-05 08:02:10,672 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3962510680158933, 'Total loss': 0.3962510680158933} | train loss {'Reaction outcome loss': 0.303883125575724, 'Total loss': 0.303883125575724}
2023-01-05 08:02:10,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:02:10,673 INFO:     Epoch: 89
2023-01-05 08:02:12,815 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4311324705680211, 'Total loss': 0.4311324705680211} | train loss {'Reaction outcome loss': 0.2685174609068781, 'Total loss': 0.2685174609068781}
2023-01-05 08:02:12,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:02:12,816 INFO:     Epoch: 90
2023-01-05 08:02:14,972 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3873836020628611, 'Total loss': 0.3873836020628611} | train loss {'Reaction outcome loss': 0.27055271341046994, 'Total loss': 0.27055271341046994}
2023-01-05 08:02:14,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:02:14,973 INFO:     Epoch: 91
2023-01-05 08:02:17,116 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39574480106433235, 'Total loss': 0.39574480106433235} | train loss {'Reaction outcome loss': 0.28258055297360907, 'Total loss': 0.28258055297360907}
2023-01-05 08:02:17,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:02:17,116 INFO:     Epoch: 92
2023-01-05 08:02:19,323 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40830919792254766, 'Total loss': 0.40830919792254766} | train loss {'Reaction outcome loss': 0.2639270763574514, 'Total loss': 0.2639270763574514}
2023-01-05 08:02:19,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:02:19,324 INFO:     Epoch: 93
2023-01-05 08:02:21,565 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.40478531022866565, 'Total loss': 0.40478531022866565} | train loss {'Reaction outcome loss': 0.2546861520630942, 'Total loss': 0.2546861520630942}
2023-01-05 08:02:21,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:02:21,565 INFO:     Epoch: 94
2023-01-05 08:02:23,753 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42410008013248446, 'Total loss': 0.42410008013248446} | train loss {'Reaction outcome loss': 0.25921175756008347, 'Total loss': 0.25921175756008347}
2023-01-05 08:02:23,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:02:23,754 INFO:     Epoch: 95
2023-01-05 08:02:25,901 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.37796130279699963, 'Total loss': 0.37796130279699963} | train loss {'Reaction outcome loss': 0.26244288001675015, 'Total loss': 0.26244288001675015}
2023-01-05 08:02:25,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:02:25,902 INFO:     Epoch: 96
2023-01-05 08:02:28,080 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42163659979899726, 'Total loss': 0.42163659979899726} | train loss {'Reaction outcome loss': 0.2589794175878194, 'Total loss': 0.2589794175878194}
2023-01-05 08:02:28,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:02:28,080 INFO:     Epoch: 97
2023-01-05 08:02:30,257 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3986789127190908, 'Total loss': 0.3986789127190908} | train loss {'Reaction outcome loss': 0.25651547361614274, 'Total loss': 0.25651547361614274}
2023-01-05 08:02:30,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:02:30,258 INFO:     Epoch: 98
2023-01-05 08:02:32,439 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4088742901881536, 'Total loss': 0.4088742901881536} | train loss {'Reaction outcome loss': 0.2517326367087662, 'Total loss': 0.2517326367087662}
2023-01-05 08:02:32,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:02:32,439 INFO:     Epoch: 99
2023-01-05 08:02:34,621 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4400412897268931, 'Total loss': 0.4400412897268931} | train loss {'Reaction outcome loss': 0.252340492475238, 'Total loss': 0.252340492475238}
2023-01-05 08:02:34,621 INFO:     Best model found after epoch 84 of 100.
2023-01-05 08:02:34,622 INFO:   Done with stage: TRAINING
2023-01-05 08:02:34,622 INFO:   Starting stage: EVALUATION
2023-01-05 08:02:34,756 INFO:   Done with stage: EVALUATION
2023-01-05 08:02:34,756 INFO:   Leaving out SEQ value Fold_6
2023-01-05 08:02:34,769 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 08:02:34,769 INFO:   Starting stage: FEATURE SCALING
2023-01-05 08:02:35,429 INFO:   Done with stage: FEATURE SCALING
2023-01-05 08:02:35,429 INFO:   Starting stage: SCALING TARGETS
2023-01-05 08:02:35,499 INFO:   Done with stage: SCALING TARGETS
2023-01-05 08:02:35,499 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:02:35,499 INFO:     No hyperparam tuning for this model
2023-01-05 08:02:35,499 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:02:35,499 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 08:02:35,500 INFO:     None feature selector for col prot
2023-01-05 08:02:35,500 INFO:     None feature selector for col prot
2023-01-05 08:02:35,500 INFO:     None feature selector for col prot
2023-01-05 08:02:35,501 INFO:     None feature selector for col chem
2023-01-05 08:02:35,501 INFO:     None feature selector for col chem
2023-01-05 08:02:35,501 INFO:     None feature selector for col chem
2023-01-05 08:02:35,501 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 08:02:35,501 INFO:   Starting stage: BUILD MODEL
2023-01-05 08:02:35,503 INFO:     Number of params in model 72901
2023-01-05 08:02:35,506 INFO:   Done with stage: BUILD MODEL
2023-01-05 08:02:35,506 INFO:   Starting stage: TRAINING
2023-01-05 08:02:35,561 INFO:     Val loss before train {'Reaction outcome loss': 1.0688865105311076, 'Total loss': 1.0688865105311076}
2023-01-05 08:02:35,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:02:35,561 INFO:     Epoch: 0
2023-01-05 08:02:37,698 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8565908193588256, 'Total loss': 0.8565908193588256} | train loss {'Reaction outcome loss': 0.9139988972176714, 'Total loss': 0.9139988972176714}
2023-01-05 08:02:37,698 INFO:     Found new best model at epoch 0
2023-01-05 08:02:37,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:02:37,699 INFO:     Epoch: 1
2023-01-05 08:02:39,870 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6630193054676056, 'Total loss': 0.6630193054676056} | train loss {'Reaction outcome loss': 0.7052269044335568, 'Total loss': 0.7052269044335568}
2023-01-05 08:02:39,870 INFO:     Found new best model at epoch 1
2023-01-05 08:02:39,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:02:39,871 INFO:     Epoch: 2
2023-01-05 08:02:42,045 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5796106487512589, 'Total loss': 0.5796106487512589} | train loss {'Reaction outcome loss': 0.5721332584154735, 'Total loss': 0.5721332584154735}
2023-01-05 08:02:42,046 INFO:     Found new best model at epoch 2
2023-01-05 08:02:42,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:02:42,048 INFO:     Epoch: 3
2023-01-05 08:02:44,225 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6086559196313223, 'Total loss': 0.6086559196313223} | train loss {'Reaction outcome loss': 0.5235522985458374, 'Total loss': 0.5235522985458374}
2023-01-05 08:02:44,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:02:44,226 INFO:     Epoch: 4
2023-01-05 08:02:46,381 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5936804552872975, 'Total loss': 0.5936804552872975} | train loss {'Reaction outcome loss': 0.5106842349475041, 'Total loss': 0.5106842349475041}
2023-01-05 08:02:46,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:02:46,381 INFO:     Epoch: 5
2023-01-05 08:02:48,560 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5970399022102356, 'Total loss': 0.5970399022102356} | train loss {'Reaction outcome loss': 0.4889282653585668, 'Total loss': 0.4889282653585668}
2023-01-05 08:02:48,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:02:48,561 INFO:     Epoch: 6
2023-01-05 08:02:50,727 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5421107490857442, 'Total loss': 0.5421107490857442} | train loss {'Reaction outcome loss': 0.4826640288214391, 'Total loss': 0.4826640288214391}
2023-01-05 08:02:50,727 INFO:     Found new best model at epoch 6
2023-01-05 08:02:50,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:02:50,728 INFO:     Epoch: 7
2023-01-05 08:02:52,905 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5811492701371511, 'Total loss': 0.5811492701371511} | train loss {'Reaction outcome loss': 0.47452315817240776, 'Total loss': 0.47452315817240776}
2023-01-05 08:02:52,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:02:52,905 INFO:     Epoch: 8
2023-01-05 08:02:55,073 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5550710380077362, 'Total loss': 0.5550710380077362} | train loss {'Reaction outcome loss': 0.47378613455523655, 'Total loss': 0.47378613455523655}
2023-01-05 08:02:55,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:02:55,073 INFO:     Epoch: 9
2023-01-05 08:02:57,229 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.563589338461558, 'Total loss': 0.563589338461558} | train loss {'Reaction outcome loss': 0.46589903105790004, 'Total loss': 0.46589903105790004}
2023-01-05 08:02:57,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:02:57,230 INFO:     Epoch: 10
2023-01-05 08:02:59,394 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5810894548892975, 'Total loss': 0.5810894548892975} | train loss {'Reaction outcome loss': 0.45578891931888427, 'Total loss': 0.45578891931888427}
2023-01-05 08:02:59,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:02:59,394 INFO:     Epoch: 11
2023-01-05 08:03:01,537 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5697852551937104, 'Total loss': 0.5697852551937104} | train loss {'Reaction outcome loss': 0.45262608542661803, 'Total loss': 0.45262608542661803}
2023-01-05 08:03:01,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:03:01,538 INFO:     Epoch: 12
2023-01-05 08:03:03,722 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5496641119321187, 'Total loss': 0.5496641119321187} | train loss {'Reaction outcome loss': 0.44910226880643345, 'Total loss': 0.44910226880643345}
2023-01-05 08:03:03,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:03:03,723 INFO:     Epoch: 13
2023-01-05 08:03:05,881 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5731934731205305, 'Total loss': 0.5731934731205305} | train loss {'Reaction outcome loss': 0.4427499189058366, 'Total loss': 0.4427499189058366}
2023-01-05 08:03:05,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:03:05,881 INFO:     Epoch: 14
2023-01-05 08:03:08,048 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5334759891033173, 'Total loss': 0.5334759891033173} | train loss {'Reaction outcome loss': 0.4446577921993896, 'Total loss': 0.4446577921993896}
2023-01-05 08:03:08,048 INFO:     Found new best model at epoch 14
2023-01-05 08:03:08,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:03:08,049 INFO:     Epoch: 15
2023-01-05 08:03:10,208 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5491788903872172, 'Total loss': 0.5491788903872172} | train loss {'Reaction outcome loss': 0.43310671089896224, 'Total loss': 0.43310671089896224}
2023-01-05 08:03:10,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:03:10,209 INFO:     Epoch: 16
2023-01-05 08:03:12,347 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5609264264504115, 'Total loss': 0.5609264264504115} | train loss {'Reaction outcome loss': 0.430472847356693, 'Total loss': 0.430472847356693}
2023-01-05 08:03:12,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:03:12,348 INFO:     Epoch: 17
2023-01-05 08:03:14,514 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5483410835266114, 'Total loss': 0.5483410835266114} | train loss {'Reaction outcome loss': 0.4281217781322527, 'Total loss': 0.4281217781322527}
2023-01-05 08:03:14,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:03:14,514 INFO:     Epoch: 18
2023-01-05 08:03:16,698 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5189103275537491, 'Total loss': 0.5189103275537491} | train loss {'Reaction outcome loss': 0.4237635678305738, 'Total loss': 0.4237635678305738}
2023-01-05 08:03:16,699 INFO:     Found new best model at epoch 18
2023-01-05 08:03:16,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:03:16,700 INFO:     Epoch: 19
2023-01-05 08:03:18,862 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.534442804257075, 'Total loss': 0.534442804257075} | train loss {'Reaction outcome loss': 0.4131993580380932, 'Total loss': 0.4131993580380932}
2023-01-05 08:03:18,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:03:18,863 INFO:     Epoch: 20
2023-01-05 08:03:21,023 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5255871037642161, 'Total loss': 0.5255871037642161} | train loss {'Reaction outcome loss': 0.4186503563331783, 'Total loss': 0.4186503563331783}
2023-01-05 08:03:21,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:03:21,023 INFO:     Epoch: 21
2023-01-05 08:03:23,166 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5145830541849137, 'Total loss': 0.5145830541849137} | train loss {'Reaction outcome loss': 0.4065400682631813, 'Total loss': 0.4065400682631813}
2023-01-05 08:03:23,167 INFO:     Found new best model at epoch 21
2023-01-05 08:03:23,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:03:23,168 INFO:     Epoch: 22
2023-01-05 08:03:25,332 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5291185200214386, 'Total loss': 0.5291185200214386} | train loss {'Reaction outcome loss': 0.4067980172078962, 'Total loss': 0.4067980172078962}
2023-01-05 08:03:25,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:03:25,333 INFO:     Epoch: 23
2023-01-05 08:03:27,503 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5321165164311726, 'Total loss': 0.5321165164311726} | train loss {'Reaction outcome loss': 0.4013729727010004, 'Total loss': 0.4013729727010004}
2023-01-05 08:03:27,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:03:27,504 INFO:     Epoch: 24
2023-01-05 08:03:29,738 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5438781102498372, 'Total loss': 0.5438781102498372} | train loss {'Reaction outcome loss': 0.402588011031224, 'Total loss': 0.402588011031224}
2023-01-05 08:03:29,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:03:29,738 INFO:     Epoch: 25
2023-01-05 08:03:31,910 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5040573716163635, 'Total loss': 0.5040573716163635} | train loss {'Reaction outcome loss': 0.39167662223108407, 'Total loss': 0.39167662223108407}
2023-01-05 08:03:31,910 INFO:     Found new best model at epoch 25
2023-01-05 08:03:31,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:03:31,911 INFO:     Epoch: 26
2023-01-05 08:03:34,076 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.48515057961146035, 'Total loss': 0.48515057961146035} | train loss {'Reaction outcome loss': 0.3928594501547865, 'Total loss': 0.3928594501547865}
2023-01-05 08:03:34,076 INFO:     Found new best model at epoch 26
2023-01-05 08:03:34,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:03:34,078 INFO:     Epoch: 27
2023-01-05 08:03:36,217 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5089630901813507, 'Total loss': 0.5089630901813507} | train loss {'Reaction outcome loss': 0.3811711912389697, 'Total loss': 0.3811711912389697}
2023-01-05 08:03:36,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:03:36,217 INFO:     Epoch: 28
2023-01-05 08:03:38,393 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5331369638442993, 'Total loss': 0.5331369638442993} | train loss {'Reaction outcome loss': 0.38595437995470816, 'Total loss': 0.38595437995470816}
2023-01-05 08:03:38,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:03:38,394 INFO:     Epoch: 29
2023-01-05 08:03:40,565 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.48608955144882204, 'Total loss': 0.48608955144882204} | train loss {'Reaction outcome loss': 0.3730402717144911, 'Total loss': 0.3730402717144911}
2023-01-05 08:03:40,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:03:40,566 INFO:     Epoch: 30
2023-01-05 08:03:42,741 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5110887885093689, 'Total loss': 0.5110887885093689} | train loss {'Reaction outcome loss': 0.3745252757134851, 'Total loss': 0.3745252757134851}
2023-01-05 08:03:42,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:03:42,741 INFO:     Epoch: 31
2023-01-05 08:03:44,898 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5332192659378052, 'Total loss': 0.5332192659378052} | train loss {'Reaction outcome loss': 0.372860052148788, 'Total loss': 0.372860052148788}
2023-01-05 08:03:44,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:03:44,898 INFO:     Epoch: 32
2023-01-05 08:03:46,861 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5292248109976451, 'Total loss': 0.5292248109976451} | train loss {'Reaction outcome loss': 0.3667864557422886, 'Total loss': 0.3667864557422886}
2023-01-05 08:03:46,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:03:46,861 INFO:     Epoch: 33
2023-01-05 08:03:48,586 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5465708712736765, 'Total loss': 0.5465708712736765} | train loss {'Reaction outcome loss': 0.3667192284273327, 'Total loss': 0.3667192284273327}
2023-01-05 08:03:48,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:03:48,587 INFO:     Epoch: 34
2023-01-05 08:03:50,312 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5008304218451182, 'Total loss': 0.5008304218451182} | train loss {'Reaction outcome loss': 0.35918176787424605, 'Total loss': 0.35918176787424605}
2023-01-05 08:03:50,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:03:50,312 INFO:     Epoch: 35
2023-01-05 08:03:52,443 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4881433129310608, 'Total loss': 0.4881433129310608} | train loss {'Reaction outcome loss': 0.3575652698962697, 'Total loss': 0.3575652698962697}
2023-01-05 08:03:52,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:03:52,443 INFO:     Epoch: 36
2023-01-05 08:03:54,639 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5310253421465556, 'Total loss': 0.5310253421465556} | train loss {'Reaction outcome loss': 0.35267080842695514, 'Total loss': 0.35267080842695514}
2023-01-05 08:03:54,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:03:54,640 INFO:     Epoch: 37
2023-01-05 08:03:56,803 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.5122061133384704, 'Total loss': 0.5122061133384704} | train loss {'Reaction outcome loss': 0.3499098060255877, 'Total loss': 0.3499098060255877}
2023-01-05 08:03:56,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:03:56,803 INFO:     Epoch: 38
2023-01-05 08:03:58,970 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5261927992105484, 'Total loss': 0.5261927992105484} | train loss {'Reaction outcome loss': 0.35143333821412887, 'Total loss': 0.35143333821412887}
2023-01-05 08:03:58,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:03:58,970 INFO:     Epoch: 39
2023-01-05 08:04:01,135 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5404650290807088, 'Total loss': 0.5404650290807088} | train loss {'Reaction outcome loss': 0.33895666612184433, 'Total loss': 0.33895666612184433}
2023-01-05 08:04:01,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:04:01,136 INFO:     Epoch: 40
2023-01-05 08:04:03,297 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5042425910631816, 'Total loss': 0.5042425910631816} | train loss {'Reaction outcome loss': 0.34137621667195744, 'Total loss': 0.34137621667195744}
2023-01-05 08:04:03,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:04:03,298 INFO:     Epoch: 41
2023-01-05 08:04:05,471 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.504708981513977, 'Total loss': 0.504708981513977} | train loss {'Reaction outcome loss': 0.3402179551011604, 'Total loss': 0.3402179551011604}
2023-01-05 08:04:05,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:04:05,471 INFO:     Epoch: 42
2023-01-05 08:04:07,633 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4911332130432129, 'Total loss': 0.4911332130432129} | train loss {'Reaction outcome loss': 0.33333167850648454, 'Total loss': 0.33333167850648454}
2023-01-05 08:04:07,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:04:07,634 INFO:     Epoch: 43
2023-01-05 08:04:09,777 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4900685956080755, 'Total loss': 0.4900685956080755} | train loss {'Reaction outcome loss': 0.32995975805641514, 'Total loss': 0.32995975805641514}
2023-01-05 08:04:09,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:04:09,777 INFO:     Epoch: 44
2023-01-05 08:04:11,933 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4882936179637909, 'Total loss': 0.4882936179637909} | train loss {'Reaction outcome loss': 0.3358563148157691, 'Total loss': 0.3358563148157691}
2023-01-05 08:04:11,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:04:11,934 INFO:     Epoch: 45
2023-01-05 08:04:14,104 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4819275220235189, 'Total loss': 0.4819275220235189} | train loss {'Reaction outcome loss': 0.3226100421554345, 'Total loss': 0.3226100421554345}
2023-01-05 08:04:14,105 INFO:     Found new best model at epoch 45
2023-01-05 08:04:14,106 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:04:14,106 INFO:     Epoch: 46
2023-01-05 08:04:16,252 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.48294770916303, 'Total loss': 0.48294770916303} | train loss {'Reaction outcome loss': 0.32386320692214726, 'Total loss': 0.32386320692214726}
2023-01-05 08:04:16,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:04:16,252 INFO:     Epoch: 47
2023-01-05 08:04:18,418 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.47102671762307485, 'Total loss': 0.47102671762307485} | train loss {'Reaction outcome loss': 0.3190623320208775, 'Total loss': 0.3190623320208775}
2023-01-05 08:04:18,419 INFO:     Found new best model at epoch 47
2023-01-05 08:04:18,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:04:18,420 INFO:     Epoch: 48
2023-01-05 08:04:20,563 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4938012699286143, 'Total loss': 0.4938012699286143} | train loss {'Reaction outcome loss': 0.3107121185557614, 'Total loss': 0.3107121185557614}
2023-01-05 08:04:20,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:04:20,564 INFO:     Epoch: 49
2023-01-05 08:04:22,732 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5075098608930906, 'Total loss': 0.5075098608930906} | train loss {'Reaction outcome loss': 0.307170161338597, 'Total loss': 0.307170161338597}
2023-01-05 08:04:22,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:04:22,732 INFO:     Epoch: 50
2023-01-05 08:04:24,904 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47677138944466907, 'Total loss': 0.47677138944466907} | train loss {'Reaction outcome loss': 0.31212078275609534, 'Total loss': 0.31212078275609534}
2023-01-05 08:04:24,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:04:24,905 INFO:     Epoch: 51
2023-01-05 08:04:27,059 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4681364859143893, 'Total loss': 0.4681364859143893} | train loss {'Reaction outcome loss': 0.30393324204676847, 'Total loss': 0.30393324204676847}
2023-01-05 08:04:27,059 INFO:     Found new best model at epoch 51
2023-01-05 08:04:27,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:04:27,061 INFO:     Epoch: 52
2023-01-05 08:04:29,217 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.48996936281522113, 'Total loss': 0.48996936281522113} | train loss {'Reaction outcome loss': 0.30486122042693814, 'Total loss': 0.30486122042693814}
2023-01-05 08:04:29,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:04:29,217 INFO:     Epoch: 53
2023-01-05 08:04:31,376 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4730763018131256, 'Total loss': 0.4730763018131256} | train loss {'Reaction outcome loss': 0.29684734332714807, 'Total loss': 0.29684734332714807}
2023-01-05 08:04:31,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:04:31,376 INFO:     Epoch: 54
2023-01-05 08:04:33,557 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5035151402155559, 'Total loss': 0.5035151402155559} | train loss {'Reaction outcome loss': 0.2965013147852911, 'Total loss': 0.2965013147852911}
2023-01-05 08:04:33,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:04:33,557 INFO:     Epoch: 55
2023-01-05 08:04:35,744 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.490876908103625, 'Total loss': 0.490876908103625} | train loss {'Reaction outcome loss': 0.3014852137234237, 'Total loss': 0.3014852137234237}
2023-01-05 08:04:35,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:04:35,744 INFO:     Epoch: 56
2023-01-05 08:04:37,912 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.49462485214074453, 'Total loss': 0.49462485214074453} | train loss {'Reaction outcome loss': 0.28986751754845524, 'Total loss': 0.28986751754845524}
2023-01-05 08:04:37,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:04:37,913 INFO:     Epoch: 57
2023-01-05 08:04:40,053 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.46966803471247354, 'Total loss': 0.46966803471247354} | train loss {'Reaction outcome loss': 0.2960445474604622, 'Total loss': 0.2960445474604622}
2023-01-05 08:04:40,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:04:40,053 INFO:     Epoch: 58
2023-01-05 08:04:42,218 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4559015621741613, 'Total loss': 0.4559015621741613} | train loss {'Reaction outcome loss': 0.2943688891962547, 'Total loss': 0.2943688891962547}
2023-01-05 08:04:42,218 INFO:     Found new best model at epoch 58
2023-01-05 08:04:42,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:04:42,220 INFO:     Epoch: 59
2023-01-05 08:04:44,368 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4458723405996958, 'Total loss': 0.4458723405996958} | train loss {'Reaction outcome loss': 0.28623826609460457, 'Total loss': 0.28623826609460457}
2023-01-05 08:04:44,368 INFO:     Found new best model at epoch 59
2023-01-05 08:04:44,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:04:44,370 INFO:     Epoch: 60
2023-01-05 08:04:46,526 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.49553874830404915, 'Total loss': 0.49553874830404915} | train loss {'Reaction outcome loss': 0.28402602141353195, 'Total loss': 0.28402602141353195}
2023-01-05 08:04:46,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:04:46,526 INFO:     Epoch: 61
2023-01-05 08:04:48,663 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5414752900600434, 'Total loss': 0.5414752900600434} | train loss {'Reaction outcome loss': 0.28117535276748645, 'Total loss': 0.28117535276748645}
2023-01-05 08:04:48,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:04:48,663 INFO:     Epoch: 62
2023-01-05 08:04:50,806 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47040040294329327, 'Total loss': 0.47040040294329327} | train loss {'Reaction outcome loss': 0.28341082366526343, 'Total loss': 0.28341082366526343}
2023-01-05 08:04:50,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:04:50,806 INFO:     Epoch: 63
2023-01-05 08:04:52,970 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.49409311016400653, 'Total loss': 0.49409311016400653} | train loss {'Reaction outcome loss': 0.28120073755456654, 'Total loss': 0.28120073755456654}
2023-01-05 08:04:52,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:04:52,970 INFO:     Epoch: 64
2023-01-05 08:04:55,099 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.47171618839104973, 'Total loss': 0.47171618839104973} | train loss {'Reaction outcome loss': 0.281066784036719, 'Total loss': 0.281066784036719}
2023-01-05 08:04:55,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:04:55,100 INFO:     Epoch: 65
2023-01-05 08:04:57,246 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5086742798487346, 'Total loss': 0.5086742798487346} | train loss {'Reaction outcome loss': 0.2764586992292843, 'Total loss': 0.2764586992292843}
2023-01-05 08:04:57,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:04:57,246 INFO:     Epoch: 66
2023-01-05 08:04:59,193 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4668824185927709, 'Total loss': 0.4668824185927709} | train loss {'Reaction outcome loss': 0.2756061997157034, 'Total loss': 0.2756061997157034}
2023-01-05 08:04:59,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:04:59,193 INFO:     Epoch: 67
2023-01-05 08:05:01,348 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4824803054332733, 'Total loss': 0.4824803054332733} | train loss {'Reaction outcome loss': 0.2688190839404664, 'Total loss': 0.2688190839404664}
2023-01-05 08:05:01,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:05:01,349 INFO:     Epoch: 68
2023-01-05 08:05:03,506 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.47455358306566875, 'Total loss': 0.47455358306566875} | train loss {'Reaction outcome loss': 0.27929238606553647, 'Total loss': 0.27929238606553647}
2023-01-05 08:05:03,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:05:03,507 INFO:     Epoch: 69
2023-01-05 08:05:05,672 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.44223924577236173, 'Total loss': 0.44223924577236173} | train loss {'Reaction outcome loss': 0.2771941217785493, 'Total loss': 0.2771941217785493}
2023-01-05 08:05:05,672 INFO:     Found new best model at epoch 69
2023-01-05 08:05:05,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:05:05,673 INFO:     Epoch: 70
2023-01-05 08:05:07,827 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4656028946240743, 'Total loss': 0.4656028946240743} | train loss {'Reaction outcome loss': 0.2605829821623835, 'Total loss': 0.2605829821623835}
2023-01-05 08:05:07,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:05:07,827 INFO:     Epoch: 71
2023-01-05 08:05:09,994 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4847423096497854, 'Total loss': 0.4847423096497854} | train loss {'Reaction outcome loss': 0.26849032482569396, 'Total loss': 0.26849032482569396}
2023-01-05 08:05:09,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:05:09,994 INFO:     Epoch: 72
2023-01-05 08:05:12,168 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4968537539243698, 'Total loss': 0.4968537539243698} | train loss {'Reaction outcome loss': 0.2749535255941028, 'Total loss': 0.2749535255941028}
2023-01-05 08:05:12,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:05:12,168 INFO:     Epoch: 73
2023-01-05 08:05:14,370 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4697580566008886, 'Total loss': 0.4697580566008886} | train loss {'Reaction outcome loss': 0.2671544281127005, 'Total loss': 0.2671544281127005}
2023-01-05 08:05:14,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:05:14,371 INFO:     Epoch: 74
2023-01-05 08:05:16,572 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5012726187705994, 'Total loss': 0.5012726187705994} | train loss {'Reaction outcome loss': 0.2628938046818606, 'Total loss': 0.2628938046818606}
2023-01-05 08:05:16,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:05:16,572 INFO:     Epoch: 75
2023-01-05 08:05:18,749 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.47419582108656566, 'Total loss': 0.47419582108656566} | train loss {'Reaction outcome loss': 0.2626835105147226, 'Total loss': 0.2626835105147226}
2023-01-05 08:05:18,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:05:18,749 INFO:     Epoch: 76
2023-01-05 08:05:20,920 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5040761401255925, 'Total loss': 0.5040761401255925} | train loss {'Reaction outcome loss': 0.2717436209643791, 'Total loss': 0.2717436209643791}
2023-01-05 08:05:20,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:05:20,920 INFO:     Epoch: 77
2023-01-05 08:05:23,096 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4778686761856079, 'Total loss': 0.4778686761856079} | train loss {'Reaction outcome loss': 0.26246118939579177, 'Total loss': 0.26246118939579177}
2023-01-05 08:05:23,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:05:23,097 INFO:     Epoch: 78
2023-01-05 08:05:25,245 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4495524153113365, 'Total loss': 0.4495524153113365} | train loss {'Reaction outcome loss': 0.26054700117706175, 'Total loss': 0.26054700117706175}
2023-01-05 08:05:25,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:05:25,246 INFO:     Epoch: 79
2023-01-05 08:05:27,407 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5040111780166626, 'Total loss': 0.5040111780166626} | train loss {'Reaction outcome loss': 0.25855232662242245, 'Total loss': 0.25855232662242245}
2023-01-05 08:05:27,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:05:27,407 INFO:     Epoch: 80
2023-01-05 08:05:29,582 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.462223157286644, 'Total loss': 0.462223157286644} | train loss {'Reaction outcome loss': 0.25223493670190716, 'Total loss': 0.25223493670190716}
2023-01-05 08:05:29,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:05:29,582 INFO:     Epoch: 81
2023-01-05 08:05:31,733 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44802608092625934, 'Total loss': 0.44802608092625934} | train loss {'Reaction outcome loss': 0.24881008314473105, 'Total loss': 0.24881008314473105}
2023-01-05 08:05:31,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:05:31,734 INFO:     Epoch: 82
2023-01-05 08:05:33,888 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4626417467991511, 'Total loss': 0.4626417467991511} | train loss {'Reaction outcome loss': 0.2550770593033801, 'Total loss': 0.2550770593033801}
2023-01-05 08:05:33,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:05:33,888 INFO:     Epoch: 83
2023-01-05 08:05:36,048 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46183183739582695, 'Total loss': 0.46183183739582695} | train loss {'Reaction outcome loss': 0.24788238806481933, 'Total loss': 0.24788238806481933}
2023-01-05 08:05:36,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:05:36,048 INFO:     Epoch: 84
2023-01-05 08:05:38,219 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.48162840207417806, 'Total loss': 0.48162840207417806} | train loss {'Reaction outcome loss': 0.2532837820451182, 'Total loss': 0.2532837820451182}
2023-01-05 08:05:38,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:05:38,220 INFO:     Epoch: 85
2023-01-05 08:05:40,385 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.48660647571086885, 'Total loss': 0.48660647571086885} | train loss {'Reaction outcome loss': 0.25713420461607756, 'Total loss': 0.25713420461607756}
2023-01-05 08:05:40,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:05:40,385 INFO:     Epoch: 86
2023-01-05 08:05:42,543 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.42274369796117145, 'Total loss': 0.42274369796117145} | train loss {'Reaction outcome loss': 0.25233954480354964, 'Total loss': 0.25233954480354964}
2023-01-05 08:05:42,543 INFO:     Found new best model at epoch 86
2023-01-05 08:05:42,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:05:42,544 INFO:     Epoch: 87
2023-01-05 08:05:44,703 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4744958410660426, 'Total loss': 0.4744958410660426} | train loss {'Reaction outcome loss': 0.2494353339856067, 'Total loss': 0.2494353339856067}
2023-01-05 08:05:44,703 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:05:44,703 INFO:     Epoch: 88
2023-01-05 08:05:46,869 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4609765350818634, 'Total loss': 0.4609765350818634} | train loss {'Reaction outcome loss': 0.24968378287521512, 'Total loss': 0.24968378287521512}
2023-01-05 08:05:46,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:05:46,869 INFO:     Epoch: 89
2023-01-05 08:05:49,008 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4377238407731056, 'Total loss': 0.4377238407731056} | train loss {'Reaction outcome loss': 0.2451585688584548, 'Total loss': 0.2451585688584548}
2023-01-05 08:05:49,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:05:49,008 INFO:     Epoch: 90
2023-01-05 08:05:51,178 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.44259548286596934, 'Total loss': 0.44259548286596934} | train loss {'Reaction outcome loss': 0.24547960718804535, 'Total loss': 0.24547960718804535}
2023-01-05 08:05:51,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:05:51,179 INFO:     Epoch: 91
2023-01-05 08:05:53,344 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.49479926054676376, 'Total loss': 0.49479926054676376} | train loss {'Reaction outcome loss': 0.239105484058361, 'Total loss': 0.239105484058361}
2023-01-05 08:05:53,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:05:53,344 INFO:     Epoch: 92
2023-01-05 08:05:55,513 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47479944825172427, 'Total loss': 0.47479944825172427} | train loss {'Reaction outcome loss': 0.2498923080640472, 'Total loss': 0.2498923080640472}
2023-01-05 08:05:55,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:05:55,514 INFO:     Epoch: 93
2023-01-05 08:05:57,683 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46719497044881186, 'Total loss': 0.46719497044881186} | train loss {'Reaction outcome loss': 0.23293288072255114, 'Total loss': 0.23293288072255114}
2023-01-05 08:05:57,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:05:57,683 INFO:     Epoch: 94
2023-01-05 08:05:59,851 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.46845277945200603, 'Total loss': 0.46845277945200603} | train loss {'Reaction outcome loss': 0.24004196900780236, 'Total loss': 0.24004196900780236}
2023-01-05 08:05:59,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:05:59,852 INFO:     Epoch: 95
2023-01-05 08:06:02,024 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.476178170243899, 'Total loss': 0.476178170243899} | train loss {'Reaction outcome loss': 0.23793819214516598, 'Total loss': 0.23793819214516598}
2023-01-05 08:06:02,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:06:02,025 INFO:     Epoch: 96
2023-01-05 08:06:04,198 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4774439414342245, 'Total loss': 0.4774439414342245} | train loss {'Reaction outcome loss': 0.2308771511042215, 'Total loss': 0.2308771511042215}
2023-01-05 08:06:04,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:06:04,198 INFO:     Epoch: 97
2023-01-05 08:06:06,069 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.46668961842854817, 'Total loss': 0.46668961842854817} | train loss {'Reaction outcome loss': 0.23467653081332088, 'Total loss': 0.23467653081332088}
2023-01-05 08:06:06,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:06:06,070 INFO:     Epoch: 98
2023-01-05 08:06:07,834 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47367366353670753, 'Total loss': 0.47367366353670753} | train loss {'Reaction outcome loss': 0.2354081825618817, 'Total loss': 0.2354081825618817}
2023-01-05 08:06:07,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:06:07,835 INFO:     Epoch: 99
2023-01-05 08:06:09,731 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5059978177150091, 'Total loss': 0.5059978177150091} | train loss {'Reaction outcome loss': 0.23794621970867638, 'Total loss': 0.23794621970867638}
2023-01-05 08:06:09,732 INFO:     Best model found after epoch 87 of 100.
2023-01-05 08:06:09,732 INFO:   Done with stage: TRAINING
2023-01-05 08:06:09,732 INFO:   Starting stage: EVALUATION
2023-01-05 08:06:09,858 INFO:   Done with stage: EVALUATION
2023-01-05 08:06:09,858 INFO:   Leaving out SEQ value Fold_7
2023-01-05 08:06:09,871 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 08:06:09,871 INFO:   Starting stage: FEATURE SCALING
2023-01-05 08:06:10,532 INFO:   Done with stage: FEATURE SCALING
2023-01-05 08:06:10,532 INFO:   Starting stage: SCALING TARGETS
2023-01-05 08:06:10,602 INFO:   Done with stage: SCALING TARGETS
2023-01-05 08:06:10,602 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:06:10,602 INFO:     No hyperparam tuning for this model
2023-01-05 08:06:10,602 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:06:10,603 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 08:06:10,603 INFO:     None feature selector for col prot
2023-01-05 08:06:10,603 INFO:     None feature selector for col prot
2023-01-05 08:06:10,603 INFO:     None feature selector for col prot
2023-01-05 08:06:10,604 INFO:     None feature selector for col chem
2023-01-05 08:06:10,604 INFO:     None feature selector for col chem
2023-01-05 08:06:10,604 INFO:     None feature selector for col chem
2023-01-05 08:06:10,604 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 08:06:10,604 INFO:   Starting stage: BUILD MODEL
2023-01-05 08:06:10,606 INFO:     Number of params in model 72901
2023-01-05 08:06:10,609 INFO:   Done with stage: BUILD MODEL
2023-01-05 08:06:10,609 INFO:   Starting stage: TRAINING
2023-01-05 08:06:10,665 INFO:     Val loss before train {'Reaction outcome loss': 1.0216464281082154, 'Total loss': 1.0216464281082154}
2023-01-05 08:06:10,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:06:10,665 INFO:     Epoch: 0
2023-01-05 08:06:12,845 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8727656602859497, 'Total loss': 0.8727656602859497} | train loss {'Reaction outcome loss': 0.9177536218820496, 'Total loss': 0.9177536218820496}
2023-01-05 08:06:12,846 INFO:     Found new best model at epoch 0
2023-01-05 08:06:12,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:06:12,847 INFO:     Epoch: 1
2023-01-05 08:06:15,026 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.747908373673757, 'Total loss': 0.747908373673757} | train loss {'Reaction outcome loss': 0.753991483458543, 'Total loss': 0.753991483458543}
2023-01-05 08:06:15,026 INFO:     Found new best model at epoch 1
2023-01-05 08:06:15,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:06:15,028 INFO:     Epoch: 2
2023-01-05 08:06:17,206 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6521614332993825, 'Total loss': 0.6521614332993825} | train loss {'Reaction outcome loss': 0.5962401436984754, 'Total loss': 0.5962401436984754}
2023-01-05 08:06:17,206 INFO:     Found new best model at epoch 2
2023-01-05 08:06:17,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:06:17,208 INFO:     Epoch: 3
2023-01-05 08:06:19,389 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6035052478313446, 'Total loss': 0.6035052478313446} | train loss {'Reaction outcome loss': 0.5303722608175518, 'Total loss': 0.5303722608175518}
2023-01-05 08:06:19,389 INFO:     Found new best model at epoch 3
2023-01-05 08:06:19,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:06:19,391 INFO:     Epoch: 4
2023-01-05 08:06:21,553 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.6012092729409536, 'Total loss': 0.6012092729409536} | train loss {'Reaction outcome loss': 0.5041581254035558, 'Total loss': 0.5041581254035558}
2023-01-05 08:06:21,553 INFO:     Found new best model at epoch 4
2023-01-05 08:06:21,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:06:21,554 INFO:     Epoch: 5
2023-01-05 08:06:23,728 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5762847940127055, 'Total loss': 0.5762847940127055} | train loss {'Reaction outcome loss': 0.5024050625330274, 'Total loss': 0.5024050625330274}
2023-01-05 08:06:23,729 INFO:     Found new best model at epoch 5
2023-01-05 08:06:23,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:06:23,730 INFO:     Epoch: 6
2023-01-05 08:06:25,904 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5557256559530894, 'Total loss': 0.5557256559530894} | train loss {'Reaction outcome loss': 0.4887143129260962, 'Total loss': 0.4887143129260962}
2023-01-05 08:06:25,904 INFO:     Found new best model at epoch 6
2023-01-05 08:06:25,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:06:25,906 INFO:     Epoch: 7
2023-01-05 08:06:28,089 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.552338327964147, 'Total loss': 0.552338327964147} | train loss {'Reaction outcome loss': 0.48157233656098264, 'Total loss': 0.48157233656098264}
2023-01-05 08:06:28,089 INFO:     Found new best model at epoch 7
2023-01-05 08:06:28,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:06:28,091 INFO:     Epoch: 8
2023-01-05 08:06:30,284 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.58335689107577, 'Total loss': 0.58335689107577} | train loss {'Reaction outcome loss': 0.47843044794531076, 'Total loss': 0.47843044794531076}
2023-01-05 08:06:30,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:06:30,284 INFO:     Epoch: 9
2023-01-05 08:06:32,446 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5375620742638906, 'Total loss': 0.5375620742638906} | train loss {'Reaction outcome loss': 0.4699115222219095, 'Total loss': 0.4699115222219095}
2023-01-05 08:06:32,447 INFO:     Found new best model at epoch 9
2023-01-05 08:06:32,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:06:32,448 INFO:     Epoch: 10
2023-01-05 08:06:34,603 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5606713056564331, 'Total loss': 0.5606713056564331} | train loss {'Reaction outcome loss': 0.46358584604538733, 'Total loss': 0.46358584604538733}
2023-01-05 08:06:34,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:06:34,603 INFO:     Epoch: 11
2023-01-05 08:06:36,774 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5800806164741517, 'Total loss': 0.5800806164741517} | train loss {'Reaction outcome loss': 0.45533991336069385, 'Total loss': 0.45533991336069385}
2023-01-05 08:06:36,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:06:36,774 INFO:     Epoch: 12
2023-01-05 08:06:38,945 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5731621483961741, 'Total loss': 0.5731621483961741} | train loss {'Reaction outcome loss': 0.4533689314707952, 'Total loss': 0.4533689314707952}
2023-01-05 08:06:38,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:06:38,946 INFO:     Epoch: 13
2023-01-05 08:06:41,105 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5413989265759785, 'Total loss': 0.5413989265759785} | train loss {'Reaction outcome loss': 0.4509360391633175, 'Total loss': 0.4509360391633175}
2023-01-05 08:06:41,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:06:41,105 INFO:     Epoch: 14
2023-01-05 08:06:43,274 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5376490930716197, 'Total loss': 0.5376490930716197} | train loss {'Reaction outcome loss': 0.4442475543017852, 'Total loss': 0.4442475543017852}
2023-01-05 08:06:43,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:06:43,275 INFO:     Epoch: 15
2023-01-05 08:06:45,423 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5514639417330424, 'Total loss': 0.5514639417330424} | train loss {'Reaction outcome loss': 0.43747131776616033, 'Total loss': 0.43747131776616033}
2023-01-05 08:06:45,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:06:45,423 INFO:     Epoch: 16
2023-01-05 08:06:47,583 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5467925051848094, 'Total loss': 0.5467925051848094} | train loss {'Reaction outcome loss': 0.436445697496514, 'Total loss': 0.436445697496514}
2023-01-05 08:06:47,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:06:47,583 INFO:     Epoch: 17
2023-01-05 08:06:49,769 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5393566052118938, 'Total loss': 0.5393566052118938} | train loss {'Reaction outcome loss': 0.43584155439254607, 'Total loss': 0.43584155439254607}
2023-01-05 08:06:49,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:06:49,770 INFO:     Epoch: 18
2023-01-05 08:06:51,958 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5288033803304036, 'Total loss': 0.5288033803304036} | train loss {'Reaction outcome loss': 0.4271012126915291, 'Total loss': 0.4271012126915291}
2023-01-05 08:06:51,958 INFO:     Found new best model at epoch 18
2023-01-05 08:06:51,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:06:51,960 INFO:     Epoch: 19
2023-01-05 08:06:54,140 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5326432983080546, 'Total loss': 0.5326432983080546} | train loss {'Reaction outcome loss': 0.4257829357140331, 'Total loss': 0.4257829357140331}
2023-01-05 08:06:54,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:06:54,140 INFO:     Epoch: 20
2023-01-05 08:06:56,304 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5442696154117584, 'Total loss': 0.5442696154117584} | train loss {'Reaction outcome loss': 0.4223602286637475, 'Total loss': 0.4223602286637475}
2023-01-05 08:06:56,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:06:56,304 INFO:     Epoch: 21
2023-01-05 08:06:58,564 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5248728732268015, 'Total loss': 0.5248728732268015} | train loss {'Reaction outcome loss': 0.4176017537121308, 'Total loss': 0.4176017537121308}
2023-01-05 08:06:58,564 INFO:     Found new best model at epoch 21
2023-01-05 08:06:58,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:06:58,566 INFO:     Epoch: 22
2023-01-05 08:07:00,851 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5359633713960648, 'Total loss': 0.5359633713960648} | train loss {'Reaction outcome loss': 0.4217474820758031, 'Total loss': 0.4217474820758031}
2023-01-05 08:07:00,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:07:00,852 INFO:     Epoch: 23
2023-01-05 08:07:03,119 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5477694034576416, 'Total loss': 0.5477694034576416} | train loss {'Reaction outcome loss': 0.40932036973939473, 'Total loss': 0.40932036973939473}
2023-01-05 08:07:03,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:07:03,119 INFO:     Epoch: 24
2023-01-05 08:07:05,294 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5217397570610046, 'Total loss': 0.5217397570610046} | train loss {'Reaction outcome loss': 0.4038639110832438, 'Total loss': 0.4038639110832438}
2023-01-05 08:07:05,294 INFO:     Found new best model at epoch 24
2023-01-05 08:07:05,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:07:05,296 INFO:     Epoch: 25
2023-01-05 08:07:07,453 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5465112725893656, 'Total loss': 0.5465112725893656} | train loss {'Reaction outcome loss': 0.4014155225633284, 'Total loss': 0.4014155225633284}
2023-01-05 08:07:07,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:07:07,455 INFO:     Epoch: 26
2023-01-05 08:07:09,624 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5130691409111023, 'Total loss': 0.5130691409111023} | train loss {'Reaction outcome loss': 0.4011116815925935, 'Total loss': 0.4011116815925935}
2023-01-05 08:07:09,624 INFO:     Found new best model at epoch 26
2023-01-05 08:07:09,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:07:09,625 INFO:     Epoch: 27
2023-01-05 08:07:11,802 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.522584683696429, 'Total loss': 0.522584683696429} | train loss {'Reaction outcome loss': 0.3918957941314804, 'Total loss': 0.3918957941314804}
2023-01-05 08:07:11,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:07:11,803 INFO:     Epoch: 28
2023-01-05 08:07:13,989 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5146120190620422, 'Total loss': 0.5146120190620422} | train loss {'Reaction outcome loss': 0.39354234707914965, 'Total loss': 0.39354234707914965}
2023-01-05 08:07:13,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:07:13,990 INFO:     Epoch: 29
2023-01-05 08:07:16,151 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5128037373224894, 'Total loss': 0.5128037373224894} | train loss {'Reaction outcome loss': 0.3879355394721892, 'Total loss': 0.3879355394721892}
2023-01-05 08:07:16,151 INFO:     Found new best model at epoch 29
2023-01-05 08:07:16,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:07:16,153 INFO:     Epoch: 30
2023-01-05 08:07:18,302 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.49840958913167316, 'Total loss': 0.49840958913167316} | train loss {'Reaction outcome loss': 0.38807649515058157, 'Total loss': 0.38807649515058157}
2023-01-05 08:07:18,302 INFO:     Found new best model at epoch 30
2023-01-05 08:07:18,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:07:18,304 INFO:     Epoch: 31
2023-01-05 08:07:20,457 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5424166798591614, 'Total loss': 0.5424166798591614} | train loss {'Reaction outcome loss': 0.3792423070122619, 'Total loss': 0.3792423070122619}
2023-01-05 08:07:20,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:07:20,457 INFO:     Epoch: 32
2023-01-05 08:07:22,615 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5621057689189911, 'Total loss': 0.5621057689189911} | train loss {'Reaction outcome loss': 0.3795811577232736, 'Total loss': 0.3795811577232736}
2023-01-05 08:07:22,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:07:22,615 INFO:     Epoch: 33
2023-01-05 08:07:24,766 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5166133046150208, 'Total loss': 0.5166133046150208} | train loss {'Reaction outcome loss': 0.3735621420646402, 'Total loss': 0.3735621420646402}
2023-01-05 08:07:24,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:07:24,767 INFO:     Epoch: 34
2023-01-05 08:07:26,922 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5390380263328552, 'Total loss': 0.5390380263328552} | train loss {'Reaction outcome loss': 0.37490604979251696, 'Total loss': 0.37490604979251696}
2023-01-05 08:07:26,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:07:26,923 INFO:     Epoch: 35
2023-01-05 08:07:29,083 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5239565054575602, 'Total loss': 0.5239565054575602} | train loss {'Reaction outcome loss': 0.37501634568621534, 'Total loss': 0.37501634568621534}
2023-01-05 08:07:29,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:07:29,083 INFO:     Epoch: 36
2023-01-05 08:07:31,236 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5114788353443146, 'Total loss': 0.5114788353443146} | train loss {'Reaction outcome loss': 0.3647874591313975, 'Total loss': 0.3647874591313975}
2023-01-05 08:07:31,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:07:31,237 INFO:     Epoch: 37
2023-01-05 08:07:33,391 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.533850775162379, 'Total loss': 0.533850775162379} | train loss {'Reaction outcome loss': 0.36097283239076283, 'Total loss': 0.36097283239076283}
2023-01-05 08:07:33,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:07:33,391 INFO:     Epoch: 38
2023-01-05 08:07:35,565 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.5192978282769521, 'Total loss': 0.5192978282769521} | train loss {'Reaction outcome loss': 0.36135418984756573, 'Total loss': 0.36135418984756573}
2023-01-05 08:07:35,565 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:07:35,565 INFO:     Epoch: 39
2023-01-05 08:07:37,719 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.5181181699037551, 'Total loss': 0.5181181699037551} | train loss {'Reaction outcome loss': 0.3587426730979651, 'Total loss': 0.3587426730979651}
2023-01-05 08:07:37,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:07:37,719 INFO:     Epoch: 40
2023-01-05 08:07:39,885 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.5095165034135183, 'Total loss': 0.5095165034135183} | train loss {'Reaction outcome loss': 0.3565205490277132, 'Total loss': 0.3565205490277132}
2023-01-05 08:07:39,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:07:39,885 INFO:     Epoch: 41
2023-01-05 08:07:42,045 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.5379349937041601, 'Total loss': 0.5379349937041601} | train loss {'Reaction outcome loss': 0.34305943470676886, 'Total loss': 0.34305943470676886}
2023-01-05 08:07:42,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:07:42,045 INFO:     Epoch: 42
2023-01-05 08:07:44,196 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.5140024145444234, 'Total loss': 0.5140024145444234} | train loss {'Reaction outcome loss': 0.34941746863042294, 'Total loss': 0.34941746863042294}
2023-01-05 08:07:44,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:07:44,197 INFO:     Epoch: 43
2023-01-05 08:07:46,349 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5167222797870636, 'Total loss': 0.5167222797870636} | train loss {'Reaction outcome loss': 0.3458164613223248, 'Total loss': 0.3458164613223248}
2023-01-05 08:07:46,349 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:07:46,349 INFO:     Epoch: 44
2023-01-05 08:07:48,519 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.48273540089527767, 'Total loss': 0.48273540089527767} | train loss {'Reaction outcome loss': 0.3426992591564621, 'Total loss': 0.3426992591564621}
2023-01-05 08:07:48,519 INFO:     Found new best model at epoch 44
2023-01-05 08:07:48,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:07:48,520 INFO:     Epoch: 45
2023-01-05 08:07:50,685 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.49327336450417836, 'Total loss': 0.49327336450417836} | train loss {'Reaction outcome loss': 0.3382975225360385, 'Total loss': 0.3382975225360385}
2023-01-05 08:07:50,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:07:50,686 INFO:     Epoch: 46
2023-01-05 08:07:52,858 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5173353513081869, 'Total loss': 0.5173353513081869} | train loss {'Reaction outcome loss': 0.3364756355862325, 'Total loss': 0.3364756355862325}
2023-01-05 08:07:52,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:07:52,858 INFO:     Epoch: 47
2023-01-05 08:07:55,018 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.5261404752731323, 'Total loss': 0.5261404752731323} | train loss {'Reaction outcome loss': 0.3358767799737221, 'Total loss': 0.3358767799737221}
2023-01-05 08:07:55,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:07:55,018 INFO:     Epoch: 48
2023-01-05 08:07:57,172 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4880725987255573, 'Total loss': 0.4880725987255573} | train loss {'Reaction outcome loss': 0.32915318515218983, 'Total loss': 0.32915318515218983}
2023-01-05 08:07:57,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:07:57,172 INFO:     Epoch: 49
2023-01-05 08:07:59,329 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4914250751336416, 'Total loss': 0.4914250751336416} | train loss {'Reaction outcome loss': 0.3293621482778112, 'Total loss': 0.3293621482778112}
2023-01-05 08:07:59,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:07:59,329 INFO:     Epoch: 50
2023-01-05 08:08:01,500 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.5120841334263484, 'Total loss': 0.5120841334263484} | train loss {'Reaction outcome loss': 0.3292845087630224, 'Total loss': 0.3292845087630224}
2023-01-05 08:08:01,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:08:01,500 INFO:     Epoch: 51
2023-01-05 08:08:03,658 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4984871367613474, 'Total loss': 0.4984871367613474} | train loss {'Reaction outcome loss': 0.32212761318855765, 'Total loss': 0.32212761318855765}
2023-01-05 08:08:03,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:08:03,659 INFO:     Epoch: 52
2023-01-05 08:08:05,811 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.5067166904608409, 'Total loss': 0.5067166904608409} | train loss {'Reaction outcome loss': 0.31782159437879326, 'Total loss': 0.31782159437879326}
2023-01-05 08:08:05,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:08:05,811 INFO:     Epoch: 53
2023-01-05 08:08:07,966 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47814465363820396, 'Total loss': 0.47814465363820396} | train loss {'Reaction outcome loss': 0.31971129826152367, 'Total loss': 0.31971129826152367}
2023-01-05 08:08:07,966 INFO:     Found new best model at epoch 53
2023-01-05 08:08:07,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:08:07,967 INFO:     Epoch: 54
2023-01-05 08:08:10,111 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5255829254786174, 'Total loss': 0.5255829254786174} | train loss {'Reaction outcome loss': 0.3181668399204416, 'Total loss': 0.3181668399204416}
2023-01-05 08:08:10,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:08:10,111 INFO:     Epoch: 55
2023-01-05 08:08:12,285 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.493695201476415, 'Total loss': 0.493695201476415} | train loss {'Reaction outcome loss': 0.3169995020227742, 'Total loss': 0.3169995020227742}
2023-01-05 08:08:12,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:08:12,285 INFO:     Epoch: 56
2023-01-05 08:08:14,451 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5220574011405309, 'Total loss': 0.5220574011405309} | train loss {'Reaction outcome loss': 0.3130500682290065, 'Total loss': 0.3130500682290065}
2023-01-05 08:08:14,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:08:14,451 INFO:     Epoch: 57
2023-01-05 08:08:16,628 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4796453018983205, 'Total loss': 0.4796453018983205} | train loss {'Reaction outcome loss': 0.30299463031631946, 'Total loss': 0.30299463031631946}
2023-01-05 08:08:16,628 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:08:16,629 INFO:     Epoch: 58
2023-01-05 08:08:18,806 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47547163466612496, 'Total loss': 0.47547163466612496} | train loss {'Reaction outcome loss': 0.3113163326755973, 'Total loss': 0.3113163326755973}
2023-01-05 08:08:18,806 INFO:     Found new best model at epoch 58
2023-01-05 08:08:18,807 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:08:18,807 INFO:     Epoch: 59
2023-01-05 08:08:21,001 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5139190971851348, 'Total loss': 0.5139190971851348} | train loss {'Reaction outcome loss': 0.3048890132578056, 'Total loss': 0.3048890132578056}
2023-01-05 08:08:21,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:08:21,002 INFO:     Epoch: 60
2023-01-05 08:08:23,166 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5225896681348483, 'Total loss': 0.5225896681348483} | train loss {'Reaction outcome loss': 0.30553603326962314, 'Total loss': 0.30553603326962314}
2023-01-05 08:08:23,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:08:23,167 INFO:     Epoch: 61
2023-01-05 08:08:25,335 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5426301389932633, 'Total loss': 0.5426301389932633} | train loss {'Reaction outcome loss': 0.2953985237149986, 'Total loss': 0.2953985237149986}
2023-01-05 08:08:25,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:08:25,336 INFO:     Epoch: 62
2023-01-05 08:08:27,491 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5252676049868266, 'Total loss': 0.5252676049868266} | train loss {'Reaction outcome loss': 0.3050711172555543, 'Total loss': 0.3050711172555543}
2023-01-05 08:08:27,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:08:27,492 INFO:     Epoch: 63
2023-01-05 08:08:29,639 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4981303175290426, 'Total loss': 0.4981303175290426} | train loss {'Reaction outcome loss': 0.3011325990532387, 'Total loss': 0.3011325990532387}
2023-01-05 08:08:29,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:08:29,639 INFO:     Epoch: 64
2023-01-05 08:08:31,799 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5068948100010554, 'Total loss': 0.5068948100010554} | train loss {'Reaction outcome loss': 0.2930894975923674, 'Total loss': 0.2930894975923674}
2023-01-05 08:08:31,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:08:31,799 INFO:     Epoch: 65
2023-01-05 08:08:33,945 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4926416724920273, 'Total loss': 0.4926416724920273} | train loss {'Reaction outcome loss': 0.3030018734910428, 'Total loss': 0.3030018734910428}
2023-01-05 08:08:33,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:08:33,946 INFO:     Epoch: 66
2023-01-05 08:08:36,124 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5537207047144572, 'Total loss': 0.5537207047144572} | train loss {'Reaction outcome loss': 0.2924310211159477, 'Total loss': 0.2924310211159477}
2023-01-05 08:08:36,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:08:36,124 INFO:     Epoch: 67
2023-01-05 08:08:38,321 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.49383183717727663, 'Total loss': 0.49383183717727663} | train loss {'Reaction outcome loss': 0.2955910016846463, 'Total loss': 0.2955910016846463}
2023-01-05 08:08:38,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:08:38,322 INFO:     Epoch: 68
2023-01-05 08:08:40,495 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5084006657203038, 'Total loss': 0.5084006657203038} | train loss {'Reaction outcome loss': 0.2862597480550785, 'Total loss': 0.2862597480550785}
2023-01-05 08:08:40,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:08:40,496 INFO:     Epoch: 69
2023-01-05 08:08:42,675 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4902488430341085, 'Total loss': 0.4902488430341085} | train loss {'Reaction outcome loss': 0.2934319449030535, 'Total loss': 0.2934319449030535}
2023-01-05 08:08:42,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:08:42,675 INFO:     Epoch: 70
2023-01-05 08:08:44,861 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.5024311502774557, 'Total loss': 0.5024311502774557} | train loss {'Reaction outcome loss': 0.28890047274825803, 'Total loss': 0.28890047274825803}
2023-01-05 08:08:44,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:08:44,861 INFO:     Epoch: 71
2023-01-05 08:08:47,061 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5168298025925954, 'Total loss': 0.5168298025925954} | train loss {'Reaction outcome loss': 0.2802691814970454, 'Total loss': 0.2802691814970454}
2023-01-05 08:08:47,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:08:47,062 INFO:     Epoch: 72
2023-01-05 08:08:49,249 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4947070062160492, 'Total loss': 0.4947070062160492} | train loss {'Reaction outcome loss': 0.2915354794301496, 'Total loss': 0.2915354794301496}
2023-01-05 08:08:49,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:08:49,249 INFO:     Epoch: 73
2023-01-05 08:08:51,422 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.5273471852143605, 'Total loss': 0.5273471852143605} | train loss {'Reaction outcome loss': 0.2858632221105189, 'Total loss': 0.2858632221105189}
2023-01-05 08:08:51,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:08:51,422 INFO:     Epoch: 74
2023-01-05 08:08:53,589 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.5294419666131337, 'Total loss': 0.5294419666131337} | train loss {'Reaction outcome loss': 0.2828281043157896, 'Total loss': 0.2828281043157896}
2023-01-05 08:08:53,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:08:53,590 INFO:     Epoch: 75
2023-01-05 08:08:55,751 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.49913358440001804, 'Total loss': 0.49913358440001804} | train loss {'Reaction outcome loss': 0.2870413333258259, 'Total loss': 0.2870413333258259}
2023-01-05 08:08:55,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:08:55,752 INFO:     Epoch: 76
2023-01-05 08:08:57,937 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5133459846178691, 'Total loss': 0.5133459846178691} | train loss {'Reaction outcome loss': 0.285695789119612, 'Total loss': 0.285695789119612}
2023-01-05 08:08:57,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:08:57,937 INFO:     Epoch: 77
2023-01-05 08:09:00,114 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5379634896914164, 'Total loss': 0.5379634896914164} | train loss {'Reaction outcome loss': 0.27650153690054746, 'Total loss': 0.27650153690054746}
2023-01-05 08:09:00,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:09:00,114 INFO:     Epoch: 78
2023-01-05 08:09:02,296 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5053776154915491, 'Total loss': 0.5053776154915491} | train loss {'Reaction outcome loss': 0.2815397600861878, 'Total loss': 0.2815397600861878}
2023-01-05 08:09:02,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:09:02,297 INFO:     Epoch: 79
2023-01-05 08:09:04,249 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5151061435540517, 'Total loss': 0.5151061435540517} | train loss {'Reaction outcome loss': 0.2768246306624223, 'Total loss': 0.2768246306624223}
2023-01-05 08:09:04,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:09:04,249 INFO:     Epoch: 80
2023-01-05 08:09:06,429 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.49111731350421906, 'Total loss': 0.49111731350421906} | train loss {'Reaction outcome loss': 0.27719147382337694, 'Total loss': 0.27719147382337694}
2023-01-05 08:09:06,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:09:06,429 INFO:     Epoch: 81
2023-01-05 08:09:08,591 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.5509127497673034, 'Total loss': 0.5509127497673034} | train loss {'Reaction outcome loss': 0.27710390611407126, 'Total loss': 0.27710390611407126}
2023-01-05 08:09:08,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:09:08,591 INFO:     Epoch: 82
2023-01-05 08:09:10,766 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4862856278816859, 'Total loss': 0.4862856278816859} | train loss {'Reaction outcome loss': 0.27576311016690647, 'Total loss': 0.27576311016690647}
2023-01-05 08:09:10,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:09:10,767 INFO:     Epoch: 83
2023-01-05 08:09:12,938 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.5115336974461874, 'Total loss': 0.5115336974461874} | train loss {'Reaction outcome loss': 0.27704065022754754, 'Total loss': 0.27704065022754754}
2023-01-05 08:09:12,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:09:12,938 INFO:     Epoch: 84
2023-01-05 08:09:15,096 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5191210150718689, 'Total loss': 0.5191210150718689} | train loss {'Reaction outcome loss': 0.26690418897902707, 'Total loss': 0.26690418897902707}
2023-01-05 08:09:15,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:09:15,097 INFO:     Epoch: 85
2023-01-05 08:09:17,268 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.48851313690344494, 'Total loss': 0.48851313690344494} | train loss {'Reaction outcome loss': 0.28217297963905635, 'Total loss': 0.28217297963905635}
2023-01-05 08:09:17,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:09:17,268 INFO:     Epoch: 86
2023-01-05 08:09:19,425 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5107276459534963, 'Total loss': 0.5107276459534963} | train loss {'Reaction outcome loss': 0.26903122395868767, 'Total loss': 0.26903122395868767}
2023-01-05 08:09:19,425 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:09:19,426 INFO:     Epoch: 87
2023-01-05 08:09:21,603 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5397604972124099, 'Total loss': 0.5397604972124099} | train loss {'Reaction outcome loss': 0.27773864333272413, 'Total loss': 0.27773864333272413}
2023-01-05 08:09:21,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:09:21,603 INFO:     Epoch: 88
2023-01-05 08:09:23,815 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4922709822654724, 'Total loss': 0.4922709822654724} | train loss {'Reaction outcome loss': 0.2675891683877375, 'Total loss': 0.2675891683877375}
2023-01-05 08:09:23,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:09:23,815 INFO:     Epoch: 89
2023-01-05 08:09:26,014 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4840427244702975, 'Total loss': 0.4840427244702975} | train loss {'Reaction outcome loss': 0.2585965077315427, 'Total loss': 0.2585965077315427}
2023-01-05 08:09:26,014 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:09:26,015 INFO:     Epoch: 90
2023-01-05 08:09:28,167 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.5547329088052114, 'Total loss': 0.5547329088052114} | train loss {'Reaction outcome loss': 0.25885628813386824, 'Total loss': 0.25885628813386824}
2023-01-05 08:09:28,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:09:28,167 INFO:     Epoch: 91
2023-01-05 08:09:30,332 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4918497314055761, 'Total loss': 0.4918497314055761} | train loss {'Reaction outcome loss': 0.2671931633920768, 'Total loss': 0.2671931633920768}
2023-01-05 08:09:30,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:09:30,333 INFO:     Epoch: 92
2023-01-05 08:09:32,480 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5144887834787368, 'Total loss': 0.5144887834787368} | train loss {'Reaction outcome loss': 0.2582954166520938, 'Total loss': 0.2582954166520938}
2023-01-05 08:09:32,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:09:32,482 INFO:     Epoch: 93
2023-01-05 08:09:34,656 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.511258731285731, 'Total loss': 0.511258731285731} | train loss {'Reaction outcome loss': 0.2677893949477574, 'Total loss': 0.2677893949477574}
2023-01-05 08:09:34,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:09:34,656 INFO:     Epoch: 94
2023-01-05 08:09:36,816 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4943081657091776, 'Total loss': 0.4943081657091776} | train loss {'Reaction outcome loss': 0.2624734634002301, 'Total loss': 0.2624734634002301}
2023-01-05 08:09:36,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:09:36,816 INFO:     Epoch: 95
2023-01-05 08:09:38,966 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.49934779008229574, 'Total loss': 0.49934779008229574} | train loss {'Reaction outcome loss': 0.2598146615475954, 'Total loss': 0.2598146615475954}
2023-01-05 08:09:38,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:09:38,967 INFO:     Epoch: 96
2023-01-05 08:09:41,129 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5178899576266607, 'Total loss': 0.5178899576266607} | train loss {'Reaction outcome loss': 0.25472717249382704, 'Total loss': 0.25472717249382704}
2023-01-05 08:09:41,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:09:41,129 INFO:     Epoch: 97
2023-01-05 08:09:43,257 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4891858071088791, 'Total loss': 0.4891858071088791} | train loss {'Reaction outcome loss': 0.2623263017176936, 'Total loss': 0.2623263017176936}
2023-01-05 08:09:43,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:09:43,258 INFO:     Epoch: 98
2023-01-05 08:09:45,411 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.5008734941482544, 'Total loss': 0.5008734941482544} | train loss {'Reaction outcome loss': 0.25491063102461153, 'Total loss': 0.25491063102461153}
2023-01-05 08:09:45,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:09:45,411 INFO:     Epoch: 99
2023-01-05 08:09:47,580 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5219985554615657, 'Total loss': 0.5219985554615657} | train loss {'Reaction outcome loss': 0.2582028555458526, 'Total loss': 0.2582028555458526}
2023-01-05 08:09:47,580 INFO:     Best model found after epoch 59 of 100.
2023-01-05 08:09:47,580 INFO:   Done with stage: TRAINING
2023-01-05 08:09:47,580 INFO:   Starting stage: EVALUATION
2023-01-05 08:09:47,706 INFO:   Done with stage: EVALUATION
2023-01-05 08:09:47,706 INFO:   Leaving out SEQ value Fold_8
2023-01-05 08:09:47,718 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 08:09:47,719 INFO:   Starting stage: FEATURE SCALING
2023-01-05 08:09:48,373 INFO:   Done with stage: FEATURE SCALING
2023-01-05 08:09:48,373 INFO:   Starting stage: SCALING TARGETS
2023-01-05 08:09:48,443 INFO:   Done with stage: SCALING TARGETS
2023-01-05 08:09:48,443 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:09:48,443 INFO:     No hyperparam tuning for this model
2023-01-05 08:09:48,443 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:09:48,443 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 08:09:48,444 INFO:     None feature selector for col prot
2023-01-05 08:09:48,444 INFO:     None feature selector for col prot
2023-01-05 08:09:48,444 INFO:     None feature selector for col prot
2023-01-05 08:09:48,445 INFO:     None feature selector for col chem
2023-01-05 08:09:48,445 INFO:     None feature selector for col chem
2023-01-05 08:09:48,445 INFO:     None feature selector for col chem
2023-01-05 08:09:48,445 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 08:09:48,445 INFO:   Starting stage: BUILD MODEL
2023-01-05 08:09:48,447 INFO:     Number of params in model 72901
2023-01-05 08:09:48,450 INFO:   Done with stage: BUILD MODEL
2023-01-05 08:09:48,450 INFO:   Starting stage: TRAINING
2023-01-05 08:09:48,510 INFO:     Val loss before train {'Reaction outcome loss': 1.0784764568010965, 'Total loss': 1.0784764568010965}
2023-01-05 08:09:48,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:09:48,510 INFO:     Epoch: 0
2023-01-05 08:09:50,645 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9289819359779358, 'Total loss': 0.9289819359779358} | train loss {'Reaction outcome loss': 0.9275761198090471, 'Total loss': 0.9275761198090471}
2023-01-05 08:09:50,645 INFO:     Found new best model at epoch 0
2023-01-05 08:09:50,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:09:50,647 INFO:     Epoch: 1
2023-01-05 08:09:52,816 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6725515882174175, 'Total loss': 0.6725515882174175} | train loss {'Reaction outcome loss': 0.7393817730587309, 'Total loss': 0.7393817730587309}
2023-01-05 08:09:52,817 INFO:     Found new best model at epoch 1
2023-01-05 08:09:52,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:09:52,818 INFO:     Epoch: 2
2023-01-05 08:09:54,970 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6088320831457774, 'Total loss': 0.6088320831457774} | train loss {'Reaction outcome loss': 0.5821506013364895, 'Total loss': 0.5821506013364895}
2023-01-05 08:09:54,970 INFO:     Found new best model at epoch 2
2023-01-05 08:09:54,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:09:54,971 INFO:     Epoch: 3
2023-01-05 08:09:57,125 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6041044513384501, 'Total loss': 0.6041044513384501} | train loss {'Reaction outcome loss': 0.538545586129961, 'Total loss': 0.538545586129961}
2023-01-05 08:09:57,125 INFO:     Found new best model at epoch 3
2023-01-05 08:09:57,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:09:57,126 INFO:     Epoch: 4
2023-01-05 08:09:59,290 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5658921460310619, 'Total loss': 0.5658921460310619} | train loss {'Reaction outcome loss': 0.5046317006644381, 'Total loss': 0.5046317006644381}
2023-01-05 08:09:59,290 INFO:     Found new best model at epoch 4
2023-01-05 08:09:59,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:09:59,292 INFO:     Epoch: 5
2023-01-05 08:10:01,436 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.572778030236562, 'Total loss': 0.572778030236562} | train loss {'Reaction outcome loss': 0.49360206528765865, 'Total loss': 0.49360206528765865}
2023-01-05 08:10:01,437 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:10:01,437 INFO:     Epoch: 6
2023-01-05 08:10:03,589 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5579822957515717, 'Total loss': 0.5579822957515717} | train loss {'Reaction outcome loss': 0.48688806794608896, 'Total loss': 0.48688806794608896}
2023-01-05 08:10:03,590 INFO:     Found new best model at epoch 6
2023-01-05 08:10:03,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:10:03,591 INFO:     Epoch: 7
2023-01-05 08:10:05,746 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5209323922793071, 'Total loss': 0.5209323922793071} | train loss {'Reaction outcome loss': 0.47911979204745614, 'Total loss': 0.47911979204745614}
2023-01-05 08:10:05,746 INFO:     Found new best model at epoch 7
2023-01-05 08:10:05,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:10:05,748 INFO:     Epoch: 8
2023-01-05 08:10:07,891 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5100184520085652, 'Total loss': 0.5100184520085652} | train loss {'Reaction outcome loss': 0.46993903320728114, 'Total loss': 0.46993903320728114}
2023-01-05 08:10:07,892 INFO:     Found new best model at epoch 8
2023-01-05 08:10:07,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:10:07,893 INFO:     Epoch: 9
2023-01-05 08:10:10,044 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.564397023121516, 'Total loss': 0.564397023121516} | train loss {'Reaction outcome loss': 0.4787669910684876, 'Total loss': 0.4787669910684876}
2023-01-05 08:10:10,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:10:10,044 INFO:     Epoch: 10
2023-01-05 08:10:12,203 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5285462061564128, 'Total loss': 0.5285462061564128} | train loss {'Reaction outcome loss': 0.4737369264813437, 'Total loss': 0.4737369264813437}
2023-01-05 08:10:12,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:10:12,203 INFO:     Epoch: 11
2023-01-05 08:10:14,374 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5212908705075582, 'Total loss': 0.5212908705075582} | train loss {'Reaction outcome loss': 0.4630370824615702, 'Total loss': 0.4630370824615702}
2023-01-05 08:10:14,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:10:14,375 INFO:     Epoch: 12
2023-01-05 08:10:16,538 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4997024873892466, 'Total loss': 0.4997024873892466} | train loss {'Reaction outcome loss': 0.4540629235806578, 'Total loss': 0.4540629235806578}
2023-01-05 08:10:16,538 INFO:     Found new best model at epoch 12
2023-01-05 08:10:16,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:10:16,540 INFO:     Epoch: 13
2023-01-05 08:10:18,714 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5660874942938486, 'Total loss': 0.5660874942938486} | train loss {'Reaction outcome loss': 0.4509332460769709, 'Total loss': 0.4509332460769709}
2023-01-05 08:10:18,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:10:18,715 INFO:     Epoch: 14
2023-01-05 08:10:20,878 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5047287414471309, 'Total loss': 0.5047287414471309} | train loss {'Reaction outcome loss': 0.4505086051413209, 'Total loss': 0.4505086051413209}
2023-01-05 08:10:20,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:10:20,879 INFO:     Epoch: 15
2023-01-05 08:10:23,033 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5254450857639312, 'Total loss': 0.5254450857639312} | train loss {'Reaction outcome loss': 0.4375353766794222, 'Total loss': 0.4375353766794222}
2023-01-05 08:10:23,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:10:23,033 INFO:     Epoch: 16
2023-01-05 08:10:25,188 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.539081209897995, 'Total loss': 0.539081209897995} | train loss {'Reaction outcome loss': 0.43915363815545605, 'Total loss': 0.43915363815545605}
2023-01-05 08:10:25,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:10:25,188 INFO:     Epoch: 17
2023-01-05 08:10:27,355 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5291717410087585, 'Total loss': 0.5291717410087585} | train loss {'Reaction outcome loss': 0.4555273522771355, 'Total loss': 0.4555273522771355}
2023-01-05 08:10:27,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:10:27,355 INFO:     Epoch: 18
2023-01-05 08:10:29,535 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5377566238244375, 'Total loss': 0.5377566238244375} | train loss {'Reaction outcome loss': 0.46077875112709793, 'Total loss': 0.46077875112709793}
2023-01-05 08:10:29,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:10:29,535 INFO:     Epoch: 19
2023-01-05 08:10:31,709 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5146888419985771, 'Total loss': 0.5146888419985771} | train loss {'Reaction outcome loss': 0.4549105359052402, 'Total loss': 0.4549105359052402}
2023-01-05 08:10:31,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:10:31,709 INFO:     Epoch: 20
2023-01-05 08:10:33,879 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5082104404767355, 'Total loss': 0.5082104404767355} | train loss {'Reaction outcome loss': 0.4268167826259109, 'Total loss': 0.4268167826259109}
2023-01-05 08:10:33,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:10:33,879 INFO:     Epoch: 21
2023-01-05 08:10:36,046 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4909842332204183, 'Total loss': 0.4909842332204183} | train loss {'Reaction outcome loss': 0.4203916665477057, 'Total loss': 0.4203916665477057}
2023-01-05 08:10:36,047 INFO:     Found new best model at epoch 21
2023-01-05 08:10:36,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:10:36,048 INFO:     Epoch: 22
2023-01-05 08:10:38,216 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5240043014287948, 'Total loss': 0.5240043014287948} | train loss {'Reaction outcome loss': 0.4147407958365005, 'Total loss': 0.4147407958365005}
2023-01-05 08:10:38,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:10:38,217 INFO:     Epoch: 23
2023-01-05 08:10:40,393 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5115691145261129, 'Total loss': 0.5115691145261129} | train loss {'Reaction outcome loss': 0.42643727999234543, 'Total loss': 0.42643727999234543}
2023-01-05 08:10:40,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:10:40,394 INFO:     Epoch: 24
2023-01-05 08:10:42,535 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5276106019814809, 'Total loss': 0.5276106019814809} | train loss {'Reaction outcome loss': 0.4138270843784836, 'Total loss': 0.4138270843784836}
2023-01-05 08:10:42,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:10:42,535 INFO:     Epoch: 25
2023-01-05 08:10:44,709 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.534089740117391, 'Total loss': 0.534089740117391} | train loss {'Reaction outcome loss': 0.4016672868983469, 'Total loss': 0.4016672868983469}
2023-01-05 08:10:44,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:10:44,710 INFO:     Epoch: 26
2023-01-05 08:10:46,894 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.48200201988220215, 'Total loss': 0.48200201988220215} | train loss {'Reaction outcome loss': 0.42500433844068775, 'Total loss': 0.42500433844068775}
2023-01-05 08:10:46,894 INFO:     Found new best model at epoch 26
2023-01-05 08:10:46,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:10:46,895 INFO:     Epoch: 27
2023-01-05 08:10:49,080 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.49230178594589236, 'Total loss': 0.49230178594589236} | train loss {'Reaction outcome loss': 0.3946812482469756, 'Total loss': 0.3946812482469756}
2023-01-05 08:10:49,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:10:49,080 INFO:     Epoch: 28
2023-01-05 08:10:51,290 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5502260128657023, 'Total loss': 0.5502260128657023} | train loss {'Reaction outcome loss': 0.4025436288582674, 'Total loss': 0.4025436288582674}
2023-01-05 08:10:51,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:10:51,290 INFO:     Epoch: 29
2023-01-05 08:10:53,460 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.566036973396937, 'Total loss': 0.566036973396937} | train loss {'Reaction outcome loss': 0.4358633182996857, 'Total loss': 0.4358633182996857}
2023-01-05 08:10:53,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:10:53,461 INFO:     Epoch: 30
2023-01-05 08:10:55,632 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.531880646944046, 'Total loss': 0.531880646944046} | train loss {'Reaction outcome loss': 0.4327438868661546, 'Total loss': 0.4327438868661546}
2023-01-05 08:10:55,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:10:55,632 INFO:     Epoch: 31
2023-01-05 08:10:57,802 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5005356232325237, 'Total loss': 0.5005356232325237} | train loss {'Reaction outcome loss': 0.3872618886955973, 'Total loss': 0.3872618886955973}
2023-01-05 08:10:57,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:10:57,803 INFO:     Epoch: 32
2023-01-05 08:10:59,971 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.5215806583563487, 'Total loss': 0.5215806583563487} | train loss {'Reaction outcome loss': 0.3895754477252131, 'Total loss': 0.3895754477252131}
2023-01-05 08:10:59,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:10:59,972 INFO:     Epoch: 33
2023-01-05 08:11:02,135 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4875236481428146, 'Total loss': 0.4875236481428146} | train loss {'Reaction outcome loss': 0.40648127857033006, 'Total loss': 0.40648127857033006}
2023-01-05 08:11:02,135 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:11:02,135 INFO:     Epoch: 34
2023-01-05 08:11:04,296 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4866262296835581, 'Total loss': 0.4866262296835581} | train loss {'Reaction outcome loss': 0.37809288148715836, 'Total loss': 0.37809288148715836}
2023-01-05 08:11:04,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:11:04,297 INFO:     Epoch: 35
2023-01-05 08:11:06,474 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5193418651819229, 'Total loss': 0.5193418651819229} | train loss {'Reaction outcome loss': 0.3745170440389842, 'Total loss': 0.3745170440389842}
2023-01-05 08:11:06,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:11:06,474 INFO:     Epoch: 36
2023-01-05 08:11:08,645 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45747013787428537, 'Total loss': 0.45747013787428537} | train loss {'Reaction outcome loss': 0.36351769431359204, 'Total loss': 0.36351769431359204}
2023-01-05 08:11:08,645 INFO:     Found new best model at epoch 36
2023-01-05 08:11:08,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:11:08,646 INFO:     Epoch: 37
2023-01-05 08:11:10,817 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.48458241621653236, 'Total loss': 0.48458241621653236} | train loss {'Reaction outcome loss': 0.3688786416711029, 'Total loss': 0.3688786416711029}
2023-01-05 08:11:10,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:11:10,818 INFO:     Epoch: 38
2023-01-05 08:11:13,001 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4886874039967855, 'Total loss': 0.4886874039967855} | train loss {'Reaction outcome loss': 0.3561855680376723, 'Total loss': 0.3561855680376723}
2023-01-05 08:11:13,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:11:13,002 INFO:     Epoch: 39
2023-01-05 08:11:15,166 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.47315056721369425, 'Total loss': 0.47315056721369425} | train loss {'Reaction outcome loss': 0.357359335565536, 'Total loss': 0.357359335565536}
2023-01-05 08:11:15,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:11:15,166 INFO:     Epoch: 40
2023-01-05 08:11:17,312 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4768018126487732, 'Total loss': 0.4768018126487732} | train loss {'Reaction outcome loss': 0.36084183399318953, 'Total loss': 0.36084183399318953}
2023-01-05 08:11:17,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:11:17,312 INFO:     Epoch: 41
2023-01-05 08:11:19,475 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4806157131989797, 'Total loss': 0.4806157131989797} | train loss {'Reaction outcome loss': 0.3521132041914034, 'Total loss': 0.3521132041914034}
2023-01-05 08:11:19,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:11:19,476 INFO:     Epoch: 42
2023-01-05 08:11:21,633 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.48499791920185087, 'Total loss': 0.48499791920185087} | train loss {'Reaction outcome loss': 0.35289402632717637, 'Total loss': 0.35289402632717637}
2023-01-05 08:11:21,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:11:21,633 INFO:     Epoch: 43
2023-01-05 08:11:23,784 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4798342923323313, 'Total loss': 0.4798342923323313} | train loss {'Reaction outcome loss': 0.347220773268761, 'Total loss': 0.347220773268761}
2023-01-05 08:11:23,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:11:23,785 INFO:     Epoch: 44
2023-01-05 08:11:25,941 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4706998507181803, 'Total loss': 0.4706998507181803} | train loss {'Reaction outcome loss': 0.3371321028233438, 'Total loss': 0.3371321028233438}
2023-01-05 08:11:25,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:11:25,941 INFO:     Epoch: 45
2023-01-05 08:11:28,088 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4875753412644068, 'Total loss': 0.4875753412644068} | train loss {'Reaction outcome loss': 0.34226982040817727, 'Total loss': 0.34226982040817727}
2023-01-05 08:11:28,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:11:28,088 INFO:     Epoch: 46
2023-01-05 08:11:30,241 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.43698162933190665, 'Total loss': 0.43698162933190665} | train loss {'Reaction outcome loss': 0.3415824129723647, 'Total loss': 0.3415824129723647}
2023-01-05 08:11:30,241 INFO:     Found new best model at epoch 46
2023-01-05 08:11:30,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:11:30,243 INFO:     Epoch: 47
2023-01-05 08:11:32,390 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4615305125713348, 'Total loss': 0.4615305125713348} | train loss {'Reaction outcome loss': 0.33266680502076296, 'Total loss': 0.33266680502076296}
2023-01-05 08:11:32,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:11:32,391 INFO:     Epoch: 48
2023-01-05 08:11:34,528 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.49096541007359823, 'Total loss': 0.49096541007359823} | train loss {'Reaction outcome loss': 0.33220434575544106, 'Total loss': 0.33220434575544106}
2023-01-05 08:11:34,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:11:34,529 INFO:     Epoch: 49
2023-01-05 08:11:36,694 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.5014412452777227, 'Total loss': 0.5014412452777227} | train loss {'Reaction outcome loss': 0.32560596747667214, 'Total loss': 0.32560596747667214}
2023-01-05 08:11:36,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:11:36,694 INFO:     Epoch: 50
2023-01-05 08:11:38,862 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47896952629089357, 'Total loss': 0.47896952629089357} | train loss {'Reaction outcome loss': 0.32264929276678467, 'Total loss': 0.32264929276678467}
2023-01-05 08:11:38,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:11:38,862 INFO:     Epoch: 51
2023-01-05 08:11:41,016 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.48521606822808583, 'Total loss': 0.48521606822808583} | train loss {'Reaction outcome loss': 0.3255406707133828, 'Total loss': 0.3255406707133828}
2023-01-05 08:11:41,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:11:41,017 INFO:     Epoch: 52
2023-01-05 08:11:43,180 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4478773315747579, 'Total loss': 0.4478773315747579} | train loss {'Reaction outcome loss': 0.3237965486258727, 'Total loss': 0.3237965486258727}
2023-01-05 08:11:43,180 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:11:43,180 INFO:     Epoch: 53
2023-01-05 08:11:45,337 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.46089242696762084, 'Total loss': 0.46089242696762084} | train loss {'Reaction outcome loss': 0.33208032617804367, 'Total loss': 0.33208032617804367}
2023-01-05 08:11:45,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:11:45,337 INFO:     Epoch: 54
2023-01-05 08:11:47,488 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.463156525293986, 'Total loss': 0.463156525293986} | train loss {'Reaction outcome loss': 0.37846764344452083, 'Total loss': 0.37846764344452083}
2023-01-05 08:11:47,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:11:47,488 INFO:     Epoch: 55
2023-01-05 08:11:49,665 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44938979943593343, 'Total loss': 0.44938979943593343} | train loss {'Reaction outcome loss': 0.34525414187785075, 'Total loss': 0.34525414187785075}
2023-01-05 08:11:49,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:11:49,666 INFO:     Epoch: 56
2023-01-05 08:11:51,842 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45591808259487154, 'Total loss': 0.45591808259487154} | train loss {'Reaction outcome loss': 0.3298838222239072, 'Total loss': 0.3298838222239072}
2023-01-05 08:11:51,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:11:51,842 INFO:     Epoch: 57
2023-01-05 08:11:54,043 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.47041921416918436, 'Total loss': 0.47041921416918436} | train loss {'Reaction outcome loss': 0.3210078103900583, 'Total loss': 0.3210078103900583}
2023-01-05 08:11:54,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:11:54,043 INFO:     Epoch: 58
2023-01-05 08:11:56,208 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.47461664378643037, 'Total loss': 0.47461664378643037} | train loss {'Reaction outcome loss': 0.31767794431136176, 'Total loss': 0.31767794431136176}
2023-01-05 08:11:56,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:11:56,209 INFO:     Epoch: 59
2023-01-05 08:11:58,348 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4422840029001236, 'Total loss': 0.4422840029001236} | train loss {'Reaction outcome loss': 0.3217203272236646, 'Total loss': 0.3217203272236646}
2023-01-05 08:11:58,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:11:58,348 INFO:     Epoch: 60
2023-01-05 08:12:00,514 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5185876905918121, 'Total loss': 0.5185876905918121} | train loss {'Reaction outcome loss': 0.3314225307085376, 'Total loss': 0.3314225307085376}
2023-01-05 08:12:00,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:12:00,514 INFO:     Epoch: 61
2023-01-05 08:12:02,658 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.5275761882464091, 'Total loss': 0.5275761882464091} | train loss {'Reaction outcome loss': 0.3598053178925445, 'Total loss': 0.3598053178925445}
2023-01-05 08:12:02,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:12:02,658 INFO:     Epoch: 62
2023-01-05 08:12:04,791 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.466498660047849, 'Total loss': 0.466498660047849} | train loss {'Reaction outcome loss': 0.3212521670407707, 'Total loss': 0.3212521670407707}
2023-01-05 08:12:04,791 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:12:04,791 INFO:     Epoch: 63
2023-01-05 08:12:06,934 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47587669640779495, 'Total loss': 0.47587669640779495} | train loss {'Reaction outcome loss': 0.3128712130929816, 'Total loss': 0.3128712130929816}
2023-01-05 08:12:06,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:12:06,934 INFO:     Epoch: 64
2023-01-05 08:12:09,083 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4548837383588155, 'Total loss': 0.4548837383588155} | train loss {'Reaction outcome loss': 0.30560455815144005, 'Total loss': 0.30560455815144005}
2023-01-05 08:12:09,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:12:09,084 INFO:     Epoch: 65
2023-01-05 08:12:11,243 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5052539765834808, 'Total loss': 0.5052539765834808} | train loss {'Reaction outcome loss': 0.29649518726670276, 'Total loss': 0.29649518726670276}
2023-01-05 08:12:11,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:12:11,243 INFO:     Epoch: 66
2023-01-05 08:12:13,401 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.5103198160727819, 'Total loss': 0.5103198160727819} | train loss {'Reaction outcome loss': 0.29822935083634333, 'Total loss': 0.29822935083634333}
2023-01-05 08:12:13,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:12:13,402 INFO:     Epoch: 67
2023-01-05 08:12:15,552 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.47699715693791706, 'Total loss': 0.47699715693791706} | train loss {'Reaction outcome loss': 0.2984527171744655, 'Total loss': 0.2984527171744655}
2023-01-05 08:12:15,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:12:15,552 INFO:     Epoch: 68
2023-01-05 08:12:17,725 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5011212557554245, 'Total loss': 0.5011212557554245} | train loss {'Reaction outcome loss': 0.29943332186414173, 'Total loss': 0.29943332186414173}
2023-01-05 08:12:17,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:12:17,726 INFO:     Epoch: 69
2023-01-05 08:12:19,898 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4964855839808782, 'Total loss': 0.4964855839808782} | train loss {'Reaction outcome loss': 0.2934669712385453, 'Total loss': 0.2934669712385453}
2023-01-05 08:12:19,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:12:19,898 INFO:     Epoch: 70
2023-01-05 08:12:22,048 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4680637856324514, 'Total loss': 0.4680637856324514} | train loss {'Reaction outcome loss': 0.2909112443288694, 'Total loss': 0.2909112443288694}
2023-01-05 08:12:22,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:12:22,048 INFO:     Epoch: 71
2023-01-05 08:12:24,214 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5976532320181529, 'Total loss': 0.5976532320181529} | train loss {'Reaction outcome loss': 0.2771503433544675, 'Total loss': 0.2771503433544675}
2023-01-05 08:12:24,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:12:24,214 INFO:     Epoch: 72
2023-01-05 08:12:26,381 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4702247718969981, 'Total loss': 0.4702247718969981} | train loss {'Reaction outcome loss': 0.2934156049049689, 'Total loss': 0.2934156049049689}
2023-01-05 08:12:26,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:12:26,383 INFO:     Epoch: 73
2023-01-05 08:12:28,554 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45433000326156614, 'Total loss': 0.45433000326156614} | train loss {'Reaction outcome loss': 0.2824797886056805, 'Total loss': 0.2824797886056805}
2023-01-05 08:12:28,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:12:28,554 INFO:     Epoch: 74
2023-01-05 08:12:30,711 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4938362181186676, 'Total loss': 0.4938362181186676} | train loss {'Reaction outcome loss': 0.28079103120514937, 'Total loss': 0.28079103120514937}
2023-01-05 08:12:30,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:12:30,712 INFO:     Epoch: 75
2023-01-05 08:12:32,888 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4823225736618042, 'Total loss': 0.4823225736618042} | train loss {'Reaction outcome loss': 0.27923667017603293, 'Total loss': 0.27923667017603293}
2023-01-05 08:12:32,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:12:32,889 INFO:     Epoch: 76
2023-01-05 08:12:35,069 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45062100092569984, 'Total loss': 0.45062100092569984} | train loss {'Reaction outcome loss': 0.2707421307274764, 'Total loss': 0.2707421307274764}
2023-01-05 08:12:35,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:12:35,069 INFO:     Epoch: 77
2023-01-05 08:12:37,226 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5404269297917684, 'Total loss': 0.5404269297917684} | train loss {'Reaction outcome loss': 0.2745622382229329, 'Total loss': 0.2745622382229329}
2023-01-05 08:12:37,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:12:37,226 INFO:     Epoch: 78
2023-01-05 08:12:39,395 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.47375314434369403, 'Total loss': 0.47375314434369403} | train loss {'Reaction outcome loss': 0.28295218691156426, 'Total loss': 0.28295218691156426}
2023-01-05 08:12:39,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:12:39,396 INFO:     Epoch: 79
2023-01-05 08:12:41,567 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47077460835377377, 'Total loss': 0.47077460835377377} | train loss {'Reaction outcome loss': 0.27218681396882766, 'Total loss': 0.27218681396882766}
2023-01-05 08:12:41,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:12:41,567 INFO:     Epoch: 80
2023-01-05 08:12:43,737 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46202898025512695, 'Total loss': 0.46202898025512695} | train loss {'Reaction outcome loss': 0.2729176415339406, 'Total loss': 0.2729176415339406}
2023-01-05 08:12:43,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:12:43,737 INFO:     Epoch: 81
2023-01-05 08:12:45,879 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44478824734687805, 'Total loss': 0.44478824734687805} | train loss {'Reaction outcome loss': 0.26695552357958385, 'Total loss': 0.26695552357958385}
2023-01-05 08:12:45,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:12:45,880 INFO:     Epoch: 82
2023-01-05 08:12:48,055 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46151924729347227, 'Total loss': 0.46151924729347227} | train loss {'Reaction outcome loss': 0.265541903698223, 'Total loss': 0.265541903698223}
2023-01-05 08:12:48,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:12:48,055 INFO:     Epoch: 83
2023-01-05 08:12:50,209 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.48837791979312895, 'Total loss': 0.48837791979312895} | train loss {'Reaction outcome loss': 0.2689838745759714, 'Total loss': 0.2689838745759714}
2023-01-05 08:12:50,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:12:50,209 INFO:     Epoch: 84
2023-01-05 08:12:52,365 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4456532011429469, 'Total loss': 0.4456532011429469} | train loss {'Reaction outcome loss': 0.2603097890851263, 'Total loss': 0.2603097890851263}
2023-01-05 08:12:52,365 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:12:52,365 INFO:     Epoch: 85
2023-01-05 08:12:54,521 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46706257859865824, 'Total loss': 0.46706257859865824} | train loss {'Reaction outcome loss': 0.26670917596957355, 'Total loss': 0.26670917596957355}
2023-01-05 08:12:54,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:12:54,521 INFO:     Epoch: 86
2023-01-05 08:12:56,670 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4957469125588735, 'Total loss': 0.4957469125588735} | train loss {'Reaction outcome loss': 0.26167891687921085, 'Total loss': 0.26167891687921085}
2023-01-05 08:12:56,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:12:56,671 INFO:     Epoch: 87
2023-01-05 08:12:58,818 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.436153781414032, 'Total loss': 0.436153781414032} | train loss {'Reaction outcome loss': 0.26169524794280785, 'Total loss': 0.26169524794280785}
2023-01-05 08:12:58,818 INFO:     Found new best model at epoch 87
2023-01-05 08:12:58,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:12:58,819 INFO:     Epoch: 88
2023-01-05 08:13:00,969 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4472425142923991, 'Total loss': 0.4472425142923991} | train loss {'Reaction outcome loss': 0.25302704180517205, 'Total loss': 0.25302704180517205}
2023-01-05 08:13:00,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:13:00,969 INFO:     Epoch: 89
2023-01-05 08:13:03,104 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.49306870500246686, 'Total loss': 0.49306870500246686} | train loss {'Reaction outcome loss': 0.2621701968010461, 'Total loss': 0.2621701968010461}
2023-01-05 08:13:03,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:13:03,105 INFO:     Epoch: 90
2023-01-05 08:13:05,265 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47511456658442813, 'Total loss': 0.47511456658442813} | train loss {'Reaction outcome loss': 0.3056001144670544, 'Total loss': 0.3056001144670544}
2023-01-05 08:13:05,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:13:05,265 INFO:     Epoch: 91
2023-01-05 08:13:07,414 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.46267342766125996, 'Total loss': 0.46267342766125996} | train loss {'Reaction outcome loss': 0.2716410302293851, 'Total loss': 0.2716410302293851}
2023-01-05 08:13:07,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:13:07,414 INFO:     Epoch: 92
2023-01-05 08:13:09,412 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.5068560640017191, 'Total loss': 0.5068560640017191} | train loss {'Reaction outcome loss': 0.2701191362533448, 'Total loss': 0.2701191362533448}
2023-01-05 08:13:09,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:13:09,413 INFO:     Epoch: 93
2023-01-05 08:13:11,527 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.48959105312824247, 'Total loss': 0.48959105312824247} | train loss {'Reaction outcome loss': 0.26935389681138855, 'Total loss': 0.26935389681138855}
2023-01-05 08:13:11,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:13:11,527 INFO:     Epoch: 94
2023-01-05 08:13:13,669 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.5164047638575237, 'Total loss': 0.5164047638575237} | train loss {'Reaction outcome loss': 0.2555939758709375, 'Total loss': 0.2555939758709375}
2023-01-05 08:13:13,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:13:13,670 INFO:     Epoch: 95
2023-01-05 08:13:15,825 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.5087383141120275, 'Total loss': 0.5087383141120275} | train loss {'Reaction outcome loss': 0.27573024627982057, 'Total loss': 0.27573024627982057}
2023-01-05 08:13:15,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:13:15,826 INFO:     Epoch: 96
2023-01-05 08:13:18,002 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.5086044977108638, 'Total loss': 0.5086044977108638} | train loss {'Reaction outcome loss': 0.26019408743815037, 'Total loss': 0.26019408743815037}
2023-01-05 08:13:18,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:13:18,002 INFO:     Epoch: 97
2023-01-05 08:13:20,160 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.48007305761178337, 'Total loss': 0.48007305761178337} | train loss {'Reaction outcome loss': 0.2972636091441888, 'Total loss': 0.2972636091441888}
2023-01-05 08:13:20,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:13:20,160 INFO:     Epoch: 98
2023-01-05 08:13:22,368 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48899739384651186, 'Total loss': 0.48899739384651186} | train loss {'Reaction outcome loss': 0.252337423610447, 'Total loss': 0.252337423610447}
2023-01-05 08:13:22,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:13:22,369 INFO:     Epoch: 99
2023-01-05 08:13:24,599 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4503602201119065, 'Total loss': 0.4503602201119065} | train loss {'Reaction outcome loss': 0.25409630439692893, 'Total loss': 0.25409630439692893}
2023-01-05 08:13:24,599 INFO:     Best model found after epoch 88 of 100.
2023-01-05 08:13:24,599 INFO:   Done with stage: TRAINING
2023-01-05 08:13:24,599 INFO:   Starting stage: EVALUATION
2023-01-05 08:13:24,732 INFO:   Done with stage: EVALUATION
2023-01-05 08:13:24,732 INFO:   Leaving out SEQ value Fold_9
2023-01-05 08:13:24,745 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 08:13:24,745 INFO:   Starting stage: FEATURE SCALING
2023-01-05 08:13:25,411 INFO:   Done with stage: FEATURE SCALING
2023-01-05 08:13:25,411 INFO:   Starting stage: SCALING TARGETS
2023-01-05 08:13:25,480 INFO:   Done with stage: SCALING TARGETS
2023-01-05 08:13:25,480 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:13:25,480 INFO:     No hyperparam tuning for this model
2023-01-05 08:13:25,481 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:13:25,481 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 08:13:25,481 INFO:     None feature selector for col prot
2023-01-05 08:13:25,481 INFO:     None feature selector for col prot
2023-01-05 08:13:25,482 INFO:     None feature selector for col prot
2023-01-05 08:13:25,482 INFO:     None feature selector for col chem
2023-01-05 08:13:25,482 INFO:     None feature selector for col chem
2023-01-05 08:13:25,482 INFO:     None feature selector for col chem
2023-01-05 08:13:25,482 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 08:13:25,482 INFO:   Starting stage: BUILD MODEL
2023-01-05 08:13:25,484 INFO:     Number of params in model 72901
2023-01-05 08:13:25,487 INFO:   Done with stage: BUILD MODEL
2023-01-05 08:13:25,487 INFO:   Starting stage: TRAINING
2023-01-05 08:13:25,546 INFO:     Val loss before train {'Reaction outcome loss': 0.9795479059219361, 'Total loss': 0.9795479059219361}
2023-01-05 08:13:25,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:13:25,546 INFO:     Epoch: 0
2023-01-05 08:13:27,744 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8267888585726421, 'Total loss': 0.8267888585726421} | train loss {'Reaction outcome loss': 0.9273500186441608, 'Total loss': 0.9273500186441608}
2023-01-05 08:13:27,745 INFO:     Found new best model at epoch 0
2023-01-05 08:13:27,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:13:27,746 INFO:     Epoch: 1
2023-01-05 08:13:29,946 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6272290527820588, 'Total loss': 0.6272290527820588} | train loss {'Reaction outcome loss': 0.7353299595281105, 'Total loss': 0.7353299595281105}
2023-01-05 08:13:29,946 INFO:     Found new best model at epoch 1
2023-01-05 08:13:29,947 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:13:29,947 INFO:     Epoch: 2
2023-01-05 08:13:32,149 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.553078309694926, 'Total loss': 0.553078309694926} | train loss {'Reaction outcome loss': 0.5777781399148466, 'Total loss': 0.5777781399148466}
2023-01-05 08:13:32,150 INFO:     Found new best model at epoch 2
2023-01-05 08:13:32,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:13:32,152 INFO:     Epoch: 3
2023-01-05 08:13:34,385 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5017822285493215, 'Total loss': 0.5017822285493215} | train loss {'Reaction outcome loss': 0.5364400331832011, 'Total loss': 0.5364400331832011}
2023-01-05 08:13:34,385 INFO:     Found new best model at epoch 3
2023-01-05 08:13:34,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:13:34,387 INFO:     Epoch: 4
2023-01-05 08:13:36,547 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.47414542734622955, 'Total loss': 0.47414542734622955} | train loss {'Reaction outcome loss': 0.5202396189531695, 'Total loss': 0.5202396189531695}
2023-01-05 08:13:36,547 INFO:     Found new best model at epoch 4
2023-01-05 08:13:36,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:13:36,548 INFO:     Epoch: 5
2023-01-05 08:13:38,723 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47348810235659283, 'Total loss': 0.47348810235659283} | train loss {'Reaction outcome loss': 0.5035813840825635, 'Total loss': 0.5035813840825635}
2023-01-05 08:13:38,724 INFO:     Found new best model at epoch 5
2023-01-05 08:13:38,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:13:38,726 INFO:     Epoch: 6
2023-01-05 08:13:40,883 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49664753874142964, 'Total loss': 0.49664753874142964} | train loss {'Reaction outcome loss': 0.49501276333624705, 'Total loss': 0.49501276333624705}
2023-01-05 08:13:40,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:13:40,884 INFO:     Epoch: 7
2023-01-05 08:13:43,034 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.46153404116630553, 'Total loss': 0.46153404116630553} | train loss {'Reaction outcome loss': 0.49099786256840083, 'Total loss': 0.49099786256840083}
2023-01-05 08:13:43,034 INFO:     Found new best model at epoch 7
2023-01-05 08:13:43,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:13:43,035 INFO:     Epoch: 8
2023-01-05 08:13:45,194 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47967931230862937, 'Total loss': 0.47967931230862937} | train loss {'Reaction outcome loss': 0.48151195592613427, 'Total loss': 0.48151195592613427}
2023-01-05 08:13:45,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:13:45,194 INFO:     Epoch: 9
2023-01-05 08:13:47,363 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4598032424847285, 'Total loss': 0.4598032424847285} | train loss {'Reaction outcome loss': 0.47336716202191925, 'Total loss': 0.47336716202191925}
2023-01-05 08:13:47,363 INFO:     Found new best model at epoch 9
2023-01-05 08:13:47,364 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:13:47,364 INFO:     Epoch: 10
2023-01-05 08:13:49,534 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4472931484381358, 'Total loss': 0.4472931484381358} | train loss {'Reaction outcome loss': 0.46838432359458737, 'Total loss': 0.46838432359458737}
2023-01-05 08:13:49,534 INFO:     Found new best model at epoch 10
2023-01-05 08:13:49,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:13:49,535 INFO:     Epoch: 11
2023-01-05 08:13:51,695 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4247712969779968, 'Total loss': 0.4247712969779968} | train loss {'Reaction outcome loss': 0.4564110039050829, 'Total loss': 0.4564110039050829}
2023-01-05 08:13:51,696 INFO:     Found new best model at epoch 11
2023-01-05 08:13:51,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:13:51,698 INFO:     Epoch: 12
2023-01-05 08:13:53,855 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4503435790538788, 'Total loss': 0.4503435790538788} | train loss {'Reaction outcome loss': 0.4574248988974826, 'Total loss': 0.4574248988974826}
2023-01-05 08:13:53,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:13:53,855 INFO:     Epoch: 13
2023-01-05 08:13:56,028 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.46683626572291054, 'Total loss': 0.46683626572291054} | train loss {'Reaction outcome loss': 0.45228069159958767, 'Total loss': 0.45228069159958767}
2023-01-05 08:13:56,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:13:56,029 INFO:     Epoch: 14
2023-01-05 08:13:58,195 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4220112403233846, 'Total loss': 0.4220112403233846} | train loss {'Reaction outcome loss': 0.44365609321568417, 'Total loss': 0.44365609321568417}
2023-01-05 08:13:58,195 INFO:     Found new best model at epoch 14
2023-01-05 08:13:58,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:13:58,197 INFO:     Epoch: 15
2023-01-05 08:14:00,343 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43016394376754763, 'Total loss': 0.43016394376754763} | train loss {'Reaction outcome loss': 0.4399604250539081, 'Total loss': 0.4399604250539081}
2023-01-05 08:14:00,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:14:00,343 INFO:     Epoch: 16
2023-01-05 08:14:02,491 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4101733237504959, 'Total loss': 0.4101733237504959} | train loss {'Reaction outcome loss': 0.43360645824283467, 'Total loss': 0.43360645824283467}
2023-01-05 08:14:02,491 INFO:     Found new best model at epoch 16
2023-01-05 08:14:02,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:14:02,492 INFO:     Epoch: 17
2023-01-05 08:14:04,657 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.456079630057017, 'Total loss': 0.456079630057017} | train loss {'Reaction outcome loss': 0.42743672495069057, 'Total loss': 0.42743672495069057}
2023-01-05 08:14:04,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:14:04,657 INFO:     Epoch: 18
2023-01-05 08:14:06,813 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4369186133146286, 'Total loss': 0.4369186133146286} | train loss {'Reaction outcome loss': 0.43000942183530716, 'Total loss': 0.43000942183530716}
2023-01-05 08:14:06,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:14:06,813 INFO:     Epoch: 19
2023-01-05 08:14:08,986 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4143257329861323, 'Total loss': 0.4143257329861323} | train loss {'Reaction outcome loss': 0.41980537341820207, 'Total loss': 0.41980537341820207}
2023-01-05 08:14:08,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:14:08,987 INFO:     Epoch: 20
2023-01-05 08:14:11,151 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40678045749664304, 'Total loss': 0.40678045749664304} | train loss {'Reaction outcome loss': 0.4247098151957515, 'Total loss': 0.4247098151957515}
2023-01-05 08:14:11,151 INFO:     Found new best model at epoch 20
2023-01-05 08:14:11,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:14:11,152 INFO:     Epoch: 21
2023-01-05 08:14:13,301 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3905967652797699, 'Total loss': 0.3905967652797699} | train loss {'Reaction outcome loss': 0.4138748470411404, 'Total loss': 0.4138748470411404}
2023-01-05 08:14:13,301 INFO:     Found new best model at epoch 21
2023-01-05 08:14:13,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:14:13,303 INFO:     Epoch: 22
2023-01-05 08:14:15,496 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42753610412279763, 'Total loss': 0.42753610412279763} | train loss {'Reaction outcome loss': 0.4063801453432021, 'Total loss': 0.4063801453432021}
2023-01-05 08:14:15,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:14:15,496 INFO:     Epoch: 23
2023-01-05 08:14:17,678 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3975752721230189, 'Total loss': 0.3975752721230189} | train loss {'Reaction outcome loss': 0.40090577186014675, 'Total loss': 0.40090577186014675}
2023-01-05 08:14:17,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:14:17,678 INFO:     Epoch: 24
2023-01-05 08:14:19,886 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39251695374647777, 'Total loss': 0.39251695374647777} | train loss {'Reaction outcome loss': 0.39626987283840936, 'Total loss': 0.39626987283840936}
2023-01-05 08:14:19,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:14:19,886 INFO:     Epoch: 25
2023-01-05 08:14:22,064 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4073617766300837, 'Total loss': 0.4073617766300837} | train loss {'Reaction outcome loss': 0.38968958490484457, 'Total loss': 0.38968958490484457}
2023-01-05 08:14:22,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:14:22,064 INFO:     Epoch: 26
2023-01-05 08:14:24,225 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4070197860399882, 'Total loss': 0.4070197860399882} | train loss {'Reaction outcome loss': 0.3922613719579115, 'Total loss': 0.3922613719579115}
2023-01-05 08:14:24,225 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:14:24,225 INFO:     Epoch: 27
2023-01-05 08:14:26,396 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40190949440002444, 'Total loss': 0.40190949440002444} | train loss {'Reaction outcome loss': 0.38982443549142415, 'Total loss': 0.38982443549142415}
2023-01-05 08:14:26,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:14:26,396 INFO:     Epoch: 28
2023-01-05 08:14:28,551 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3854016055663427, 'Total loss': 0.3854016055663427} | train loss {'Reaction outcome loss': 0.3825683763607099, 'Total loss': 0.3825683763607099}
2023-01-05 08:14:28,552 INFO:     Found new best model at epoch 28
2023-01-05 08:14:28,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:14:28,554 INFO:     Epoch: 29
2023-01-05 08:14:30,714 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3972556551297506, 'Total loss': 0.3972556551297506} | train loss {'Reaction outcome loss': 0.37280595192302435, 'Total loss': 0.37280595192302435}
2023-01-05 08:14:30,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:14:30,714 INFO:     Epoch: 30
2023-01-05 08:14:32,899 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3973565647999446, 'Total loss': 0.3973565647999446} | train loss {'Reaction outcome loss': 0.37427139088565264, 'Total loss': 0.37427139088565264}
2023-01-05 08:14:32,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:14:32,899 INFO:     Epoch: 31
2023-01-05 08:14:35,064 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3744671493768692, 'Total loss': 0.3744671493768692} | train loss {'Reaction outcome loss': 0.3727495572681031, 'Total loss': 0.3727495572681031}
2023-01-05 08:14:35,064 INFO:     Found new best model at epoch 31
2023-01-05 08:14:35,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:14:35,066 INFO:     Epoch: 32
2023-01-05 08:14:37,220 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.38081786831219994, 'Total loss': 0.38081786831219994} | train loss {'Reaction outcome loss': 0.36932192683650267, 'Total loss': 0.36932192683650267}
2023-01-05 08:14:37,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:14:37,221 INFO:     Epoch: 33
2023-01-05 08:14:39,401 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.38523185402154925, 'Total loss': 0.38523185402154925} | train loss {'Reaction outcome loss': 0.36362292157613846, 'Total loss': 0.36362292157613846}
2023-01-05 08:14:39,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:14:39,403 INFO:     Epoch: 34
2023-01-05 08:14:41,548 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3818504532178243, 'Total loss': 0.3818504532178243} | train loss {'Reaction outcome loss': 0.3659450924730043, 'Total loss': 0.3659450924730043}
2023-01-05 08:14:41,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:14:41,548 INFO:     Epoch: 35
2023-01-05 08:14:43,700 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.37878940999507904, 'Total loss': 0.37878940999507904} | train loss {'Reaction outcome loss': 0.35422006776616893, 'Total loss': 0.35422006776616893}
2023-01-05 08:14:43,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:14:43,700 INFO:     Epoch: 36
2023-01-05 08:14:45,870 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.36833610335985817, 'Total loss': 0.36833610335985817} | train loss {'Reaction outcome loss': 0.35126141878349254, 'Total loss': 0.35126141878349254}
2023-01-05 08:14:45,871 INFO:     Found new best model at epoch 36
2023-01-05 08:14:45,872 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:14:45,872 INFO:     Epoch: 37
2023-01-05 08:14:48,054 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3817935138940811, 'Total loss': 0.3817935138940811} | train loss {'Reaction outcome loss': 0.3549655352850253, 'Total loss': 0.3549655352850253}
2023-01-05 08:14:48,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:14:48,055 INFO:     Epoch: 38
2023-01-05 08:14:50,218 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.37999748190244037, 'Total loss': 0.37999748190244037} | train loss {'Reaction outcome loss': 0.3490235442934484, 'Total loss': 0.3490235442934484}
2023-01-05 08:14:50,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:14:50,218 INFO:     Epoch: 39
2023-01-05 08:14:52,353 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3990828037261963, 'Total loss': 0.3990828037261963} | train loss {'Reaction outcome loss': 0.33904868508235214, 'Total loss': 0.33904868508235214}
2023-01-05 08:14:52,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:14:52,353 INFO:     Epoch: 40
2023-01-05 08:14:54,515 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.40335898796717323, 'Total loss': 0.40335898796717323} | train loss {'Reaction outcome loss': 0.33916991631692067, 'Total loss': 0.33916991631692067}
2023-01-05 08:14:54,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:14:54,515 INFO:     Epoch: 41
2023-01-05 08:14:56,675 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.37733347415924073, 'Total loss': 0.37733347415924073} | train loss {'Reaction outcome loss': 0.33783808226834994, 'Total loss': 0.33783808226834994}
2023-01-05 08:14:56,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:14:56,675 INFO:     Epoch: 42
2023-01-05 08:14:58,840 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3732585608959198, 'Total loss': 0.3732585608959198} | train loss {'Reaction outcome loss': 0.3344100850368665, 'Total loss': 0.3344100850368665}
2023-01-05 08:14:58,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:14:58,841 INFO:     Epoch: 43
2023-01-05 08:15:00,976 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3810488263765971, 'Total loss': 0.3810488263765971} | train loss {'Reaction outcome loss': 0.3342352673572754, 'Total loss': 0.3342352673572754}
2023-01-05 08:15:00,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:15:00,976 INFO:     Epoch: 44
2023-01-05 08:15:03,125 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.35620085497697196, 'Total loss': 0.35620085497697196} | train loss {'Reaction outcome loss': 0.32981837175060263, 'Total loss': 0.32981837175060263}
2023-01-05 08:15:03,125 INFO:     Found new best model at epoch 44
2023-01-05 08:15:03,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:15:03,126 INFO:     Epoch: 45
2023-01-05 08:15:05,275 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.36770131488641106, 'Total loss': 0.36770131488641106} | train loss {'Reaction outcome loss': 0.3264422716593054, 'Total loss': 0.3264422716593054}
2023-01-05 08:15:05,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:15:05,276 INFO:     Epoch: 46
2023-01-05 08:15:07,443 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.34937283595403035, 'Total loss': 0.34937283595403035} | train loss {'Reaction outcome loss': 0.3222288351089085, 'Total loss': 0.3222288351089085}
2023-01-05 08:15:07,443 INFO:     Found new best model at epoch 46
2023-01-05 08:15:07,445 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:15:07,445 INFO:     Epoch: 47
2023-01-05 08:15:09,606 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3730450908342997, 'Total loss': 0.3730450908342997} | train loss {'Reaction outcome loss': 0.31889207709567213, 'Total loss': 0.31889207709567213}
2023-01-05 08:15:09,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:15:09,607 INFO:     Epoch: 48
2023-01-05 08:15:11,751 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3686107754707336, 'Total loss': 0.3686107754707336} | train loss {'Reaction outcome loss': 0.31690141453747284, 'Total loss': 0.31690141453747284}
2023-01-05 08:15:11,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:15:11,751 INFO:     Epoch: 49
2023-01-05 08:15:13,894 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.37289507587750753, 'Total loss': 0.37289507587750753} | train loss {'Reaction outcome loss': 0.3123557730191236, 'Total loss': 0.3123557730191236}
2023-01-05 08:15:13,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:15:13,894 INFO:     Epoch: 50
2023-01-05 08:15:16,046 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3536338890592257, 'Total loss': 0.3536338890592257} | train loss {'Reaction outcome loss': 0.3173365538623789, 'Total loss': 0.3173365538623789}
2023-01-05 08:15:16,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:15:16,047 INFO:     Epoch: 51
2023-01-05 08:15:18,211 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3677781730890274, 'Total loss': 0.3677781730890274} | train loss {'Reaction outcome loss': 0.3116891543088407, 'Total loss': 0.3116891543088407}
2023-01-05 08:15:18,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:15:18,212 INFO:     Epoch: 52
2023-01-05 08:15:20,374 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3911060194174449, 'Total loss': 0.3911060194174449} | train loss {'Reaction outcome loss': 0.30590531848613106, 'Total loss': 0.30590531848613106}
2023-01-05 08:15:20,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:15:20,374 INFO:     Epoch: 53
2023-01-05 08:15:22,524 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.364622895916303, 'Total loss': 0.364622895916303} | train loss {'Reaction outcome loss': 0.31221745094613906, 'Total loss': 0.31221745094613906}
2023-01-05 08:15:22,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:15:22,525 INFO:     Epoch: 54
2023-01-05 08:15:24,670 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3651901473601659, 'Total loss': 0.3651901473601659} | train loss {'Reaction outcome loss': 0.30593763223247405, 'Total loss': 0.30593763223247405}
2023-01-05 08:15:24,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:15:24,671 INFO:     Epoch: 55
2023-01-05 08:15:26,802 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.35589965333541235, 'Total loss': 0.35589965333541235} | train loss {'Reaction outcome loss': 0.3011209850034774, 'Total loss': 0.3011209850034774}
2023-01-05 08:15:26,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:15:26,802 INFO:     Epoch: 56
2023-01-05 08:15:28,962 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38606540362040204, 'Total loss': 0.38606540362040204} | train loss {'Reaction outcome loss': 0.3073417447265305, 'Total loss': 0.3073417447265305}
2023-01-05 08:15:28,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:15:28,963 INFO:     Epoch: 57
2023-01-05 08:15:31,122 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3662573739886284, 'Total loss': 0.3662573739886284} | train loss {'Reaction outcome loss': 0.297162185170913, 'Total loss': 0.297162185170913}
2023-01-05 08:15:31,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:15:31,123 INFO:     Epoch: 58
2023-01-05 08:15:33,289 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.37232813437779744, 'Total loss': 0.37232813437779744} | train loss {'Reaction outcome loss': 0.29450547576811337, 'Total loss': 0.29450547576811337}
2023-01-05 08:15:33,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:15:33,289 INFO:     Epoch: 59
2023-01-05 08:15:35,442 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3784489373366038, 'Total loss': 0.3784489373366038} | train loss {'Reaction outcome loss': 0.29706736512831833, 'Total loss': 0.29706736512831833}
2023-01-05 08:15:35,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:15:35,442 INFO:     Epoch: 60
2023-01-05 08:15:37,595 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.36433632572491964, 'Total loss': 0.36433632572491964} | train loss {'Reaction outcome loss': 0.2944387106312311, 'Total loss': 0.2944387106312311}
2023-01-05 08:15:37,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:15:37,595 INFO:     Epoch: 61
2023-01-05 08:15:39,733 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3567595918973287, 'Total loss': 0.3567595918973287} | train loss {'Reaction outcome loss': 0.2951751507899391, 'Total loss': 0.2951751507899391}
2023-01-05 08:15:39,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:15:39,734 INFO:     Epoch: 62
2023-01-05 08:15:41,893 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.36533384919166567, 'Total loss': 0.36533384919166567} | train loss {'Reaction outcome loss': 0.286648564081007, 'Total loss': 0.286648564081007}
2023-01-05 08:15:41,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:15:41,894 INFO:     Epoch: 63
2023-01-05 08:15:44,065 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3537558610240618, 'Total loss': 0.3537558610240618} | train loss {'Reaction outcome loss': 0.28723395255390916, 'Total loss': 0.28723395255390916}
2023-01-05 08:15:44,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:15:44,065 INFO:     Epoch: 64
2023-01-05 08:15:46,241 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40116450091203054, 'Total loss': 0.40116450091203054} | train loss {'Reaction outcome loss': 0.2845006474438342, 'Total loss': 0.2845006474438342}
2023-01-05 08:15:46,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:15:46,242 INFO:     Epoch: 65
2023-01-05 08:15:48,412 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.34479798972606657, 'Total loss': 0.34479798972606657} | train loss {'Reaction outcome loss': 0.2829863653259372, 'Total loss': 0.2829863653259372}
2023-01-05 08:15:48,412 INFO:     Found new best model at epoch 65
2023-01-05 08:15:48,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:15:48,413 INFO:     Epoch: 66
2023-01-05 08:15:50,575 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.35383566419283546, 'Total loss': 0.35383566419283546} | train loss {'Reaction outcome loss': 0.2790493729931138, 'Total loss': 0.2790493729931138}
2023-01-05 08:15:50,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:15:50,575 INFO:     Epoch: 67
2023-01-05 08:15:52,738 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.37449727257092796, 'Total loss': 0.37449727257092796} | train loss {'Reaction outcome loss': 0.278920362451339, 'Total loss': 0.278920362451339}
2023-01-05 08:15:52,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:15:52,739 INFO:     Epoch: 68
2023-01-05 08:15:54,916 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3692184641957283, 'Total loss': 0.3692184641957283} | train loss {'Reaction outcome loss': 0.2791876045294402, 'Total loss': 0.2791876045294402}
2023-01-05 08:15:54,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:15:54,916 INFO:     Epoch: 69
2023-01-05 08:15:57,047 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3673747628927231, 'Total loss': 0.3673747628927231} | train loss {'Reaction outcome loss': 0.26921622430912423, 'Total loss': 0.26921622430912423}
2023-01-05 08:15:57,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:15:57,047 INFO:     Epoch: 70
2023-01-05 08:15:59,218 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3691922664642334, 'Total loss': 0.3691922664642334} | train loss {'Reaction outcome loss': 0.28862193755348237, 'Total loss': 0.28862193755348237}
2023-01-05 08:15:59,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:15:59,218 INFO:     Epoch: 71
2023-01-05 08:16:01,370 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.36576656301816307, 'Total loss': 0.36576656301816307} | train loss {'Reaction outcome loss': 0.2709826687250004, 'Total loss': 0.2709826687250004}
2023-01-05 08:16:01,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:16:01,371 INFO:     Epoch: 72
2023-01-05 08:16:03,547 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3822634945313136, 'Total loss': 0.3822634945313136} | train loss {'Reaction outcome loss': 0.2697275795903232, 'Total loss': 0.2697275795903232}
2023-01-05 08:16:03,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:16:03,547 INFO:     Epoch: 73
2023-01-05 08:16:05,715 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3458448107043902, 'Total loss': 0.3458448107043902} | train loss {'Reaction outcome loss': 0.27043274383897814, 'Total loss': 0.27043274383897814}
2023-01-05 08:16:05,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:16:05,716 INFO:     Epoch: 74
2023-01-05 08:16:07,891 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3565723620355129, 'Total loss': 0.3565723620355129} | train loss {'Reaction outcome loss': 0.2670077543692253, 'Total loss': 0.2670077543692253}
2023-01-05 08:16:07,891 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:16:07,891 INFO:     Epoch: 75
2023-01-05 08:16:10,082 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3723984936873118, 'Total loss': 0.3723984936873118} | train loss {'Reaction outcome loss': 0.2661042302066884, 'Total loss': 0.2661042302066884}
2023-01-05 08:16:10,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:16:10,082 INFO:     Epoch: 76
2023-01-05 08:16:12,249 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.35917181919018426, 'Total loss': 0.35917181919018426} | train loss {'Reaction outcome loss': 0.2622243388680344, 'Total loss': 0.2622243388680344}
2023-01-05 08:16:12,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:16:12,249 INFO:     Epoch: 77
2023-01-05 08:16:14,420 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.36557556837797167, 'Total loss': 0.36557556837797167} | train loss {'Reaction outcome loss': 0.2666853165610387, 'Total loss': 0.2666853165610387}
2023-01-05 08:16:14,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:16:14,421 INFO:     Epoch: 78
2023-01-05 08:16:16,608 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3710083425045013, 'Total loss': 0.3710083425045013} | train loss {'Reaction outcome loss': 0.267645910328476, 'Total loss': 0.267645910328476}
2023-01-05 08:16:16,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:16:16,609 INFO:     Epoch: 79
2023-01-05 08:16:18,779 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.37520106385151547, 'Total loss': 0.37520106385151547} | train loss {'Reaction outcome loss': 0.2667360747172514, 'Total loss': 0.2667360747172514}
2023-01-05 08:16:18,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:16:18,780 INFO:     Epoch: 80
2023-01-05 08:16:20,969 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.37929369509220123, 'Total loss': 0.37929369509220123} | train loss {'Reaction outcome loss': 0.2578167466964532, 'Total loss': 0.2578167466964532}
2023-01-05 08:16:20,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:16:20,969 INFO:     Epoch: 81
2023-01-05 08:16:23,141 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3880108932654063, 'Total loss': 0.3880108932654063} | train loss {'Reaction outcome loss': 0.25989315818847303, 'Total loss': 0.25989315818847303}
2023-01-05 08:16:23,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:16:23,142 INFO:     Epoch: 82
2023-01-05 08:16:25,299 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.37069192628065745, 'Total loss': 0.37069192628065745} | train loss {'Reaction outcome loss': 0.2558420520504459, 'Total loss': 0.2558420520504459}
2023-01-05 08:16:25,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:16:25,299 INFO:     Epoch: 83
2023-01-05 08:16:27,469 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3483879679193099, 'Total loss': 0.3483879679193099} | train loss {'Reaction outcome loss': 0.2572508296502304, 'Total loss': 0.2572508296502304}
2023-01-05 08:16:27,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:16:27,469 INFO:     Epoch: 84
2023-01-05 08:16:29,641 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.36775464316209155, 'Total loss': 0.36775464316209155} | train loss {'Reaction outcome loss': 0.2590392844058869, 'Total loss': 0.2590392844058869}
2023-01-05 08:16:29,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:16:29,641 INFO:     Epoch: 85
2023-01-05 08:16:31,825 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.359387011329333, 'Total loss': 0.359387011329333} | train loss {'Reaction outcome loss': 0.26190038618466915, 'Total loss': 0.26190038618466915}
2023-01-05 08:16:31,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:16:31,826 INFO:     Epoch: 86
2023-01-05 08:16:33,975 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3622406666477521, 'Total loss': 0.3622406666477521} | train loss {'Reaction outcome loss': 0.2572070821743149, 'Total loss': 0.2572070821743149}
2023-01-05 08:16:33,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:16:33,975 INFO:     Epoch: 87
2023-01-05 08:16:36,150 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3700984537601471, 'Total loss': 0.3700984537601471} | train loss {'Reaction outcome loss': 0.25083355340662844, 'Total loss': 0.25083355340662844}
2023-01-05 08:16:36,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:16:36,151 INFO:     Epoch: 88
2023-01-05 08:16:38,331 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.342568335433801, 'Total loss': 0.342568335433801} | train loss {'Reaction outcome loss': 0.2533665667338438, 'Total loss': 0.2533665667338438}
2023-01-05 08:16:38,331 INFO:     Found new best model at epoch 88
2023-01-05 08:16:38,332 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:16:38,332 INFO:     Epoch: 89
2023-01-05 08:16:40,500 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3849230552713076, 'Total loss': 0.3849230552713076} | train loss {'Reaction outcome loss': 0.2570727892919353, 'Total loss': 0.2570727892919353}
2023-01-05 08:16:40,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:16:40,500 INFO:     Epoch: 90
2023-01-05 08:16:42,683 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3431791623433431, 'Total loss': 0.3431791623433431} | train loss {'Reaction outcome loss': 0.24462610391718387, 'Total loss': 0.24462610391718387}
2023-01-05 08:16:42,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:16:42,683 INFO:     Epoch: 91
2023-01-05 08:16:44,851 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.35757258037726086, 'Total loss': 0.35757258037726086} | train loss {'Reaction outcome loss': 0.24899288905374303, 'Total loss': 0.24899288905374303}
2023-01-05 08:16:44,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:16:44,852 INFO:     Epoch: 92
2023-01-05 08:16:47,014 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.35382641553878785, 'Total loss': 0.35382641553878785} | train loss {'Reaction outcome loss': 0.24432485629989353, 'Total loss': 0.24432485629989353}
2023-01-05 08:16:47,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:16:47,015 INFO:     Epoch: 93
2023-01-05 08:16:49,197 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.38251363933086396, 'Total loss': 0.38251363933086396} | train loss {'Reaction outcome loss': 0.2516853344569568, 'Total loss': 0.2516853344569568}
2023-01-05 08:16:49,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:16:49,198 INFO:     Epoch: 94
2023-01-05 08:16:51,387 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38467867771784464, 'Total loss': 0.38467867771784464} | train loss {'Reaction outcome loss': 0.24937610172192543, 'Total loss': 0.24937610172192543}
2023-01-05 08:16:51,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:16:51,388 INFO:     Epoch: 95
2023-01-05 08:16:53,581 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.35804771731297175, 'Total loss': 0.35804771731297175} | train loss {'Reaction outcome loss': 0.24398614775510472, 'Total loss': 0.24398614775510472}
2023-01-05 08:16:53,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:16:53,582 INFO:     Epoch: 96
2023-01-05 08:16:55,792 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.38951197266578674, 'Total loss': 0.38951197266578674} | train loss {'Reaction outcome loss': 0.24519602333730092, 'Total loss': 0.24519602333730092}
2023-01-05 08:16:55,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:16:55,792 INFO:     Epoch: 97
2023-01-05 08:16:57,960 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3869981129964193, 'Total loss': 0.3869981129964193} | train loss {'Reaction outcome loss': 0.24917090737970296, 'Total loss': 0.24917090737970296}
2023-01-05 08:16:57,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:16:57,961 INFO:     Epoch: 98
2023-01-05 08:17:00,128 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.38411210278669994, 'Total loss': 0.38411210278669994} | train loss {'Reaction outcome loss': 0.24505589294519664, 'Total loss': 0.24505589294519664}
2023-01-05 08:17:00,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:17:00,128 INFO:     Epoch: 99
2023-01-05 08:17:02,300 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.37403293351332345, 'Total loss': 0.37403293351332345} | train loss {'Reaction outcome loss': 0.24752824536662563, 'Total loss': 0.24752824536662563}
2023-01-05 08:17:02,300 INFO:     Best model found after epoch 89 of 100.
2023-01-05 08:17:02,300 INFO:   Done with stage: TRAINING
2023-01-05 08:17:02,300 INFO:   Starting stage: EVALUATION
2023-01-05 08:17:02,428 INFO:   Done with stage: EVALUATION
2023-01-05 08:17:02,437 INFO:   Leaving out SEQ value Fold_0
2023-01-05 08:17:02,450 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 08:17:02,450 INFO:   Starting stage: FEATURE SCALING
2023-01-05 08:17:03,102 INFO:   Done with stage: FEATURE SCALING
2023-01-05 08:17:03,102 INFO:   Starting stage: SCALING TARGETS
2023-01-05 08:17:03,171 INFO:   Done with stage: SCALING TARGETS
2023-01-05 08:17:03,171 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:17:03,171 INFO:     No hyperparam tuning for this model
2023-01-05 08:17:03,171 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:17:03,171 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 08:17:03,172 INFO:     None feature selector for col prot
2023-01-05 08:17:03,172 INFO:     None feature selector for col prot
2023-01-05 08:17:03,172 INFO:     None feature selector for col prot
2023-01-05 08:17:03,173 INFO:     None feature selector for col chem
2023-01-05 08:17:03,173 INFO:     None feature selector for col chem
2023-01-05 08:17:03,173 INFO:     None feature selector for col chem
2023-01-05 08:17:03,173 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 08:17:03,173 INFO:   Starting stage: BUILD MODEL
2023-01-05 08:17:03,174 INFO:     Number of params in model 72901
2023-01-05 08:17:03,178 INFO:   Done with stage: BUILD MODEL
2023-01-05 08:17:03,178 INFO:   Starting stage: TRAINING
2023-01-05 08:17:03,236 INFO:     Val loss before train {'Reaction outcome loss': 0.9954461097717285, 'Total loss': 0.9954461097717285}
2023-01-05 08:17:03,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:17:03,236 INFO:     Epoch: 0
2023-01-05 08:17:05,369 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8451426684856415, 'Total loss': 0.8451426684856415} | train loss {'Reaction outcome loss': 0.9398328021277477, 'Total loss': 0.9398328021277477}
2023-01-05 08:17:05,369 INFO:     Found new best model at epoch 0
2023-01-05 08:17:05,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:17:05,370 INFO:     Epoch: 1
2023-01-05 08:17:07,510 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6567503194014231, 'Total loss': 0.6567503194014231} | train loss {'Reaction outcome loss': 0.7512980254135863, 'Total loss': 0.7512980254135863}
2023-01-05 08:17:07,511 INFO:     Found new best model at epoch 1
2023-01-05 08:17:07,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:17:07,512 INFO:     Epoch: 2
2023-01-05 08:17:09,646 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5235574126243592, 'Total loss': 0.5235574126243592} | train loss {'Reaction outcome loss': 0.5871736734670444, 'Total loss': 0.5871736734670444}
2023-01-05 08:17:09,647 INFO:     Found new best model at epoch 2
2023-01-05 08:17:09,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:17:09,648 INFO:     Epoch: 3
2023-01-05 08:17:11,770 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5142054200172425, 'Total loss': 0.5142054200172425} | train loss {'Reaction outcome loss': 0.5310114066857491, 'Total loss': 0.5310114066857491}
2023-01-05 08:17:11,771 INFO:     Found new best model at epoch 3
2023-01-05 08:17:11,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:17:11,772 INFO:     Epoch: 4
2023-01-05 08:17:13,715 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5049221495787303, 'Total loss': 0.5049221495787303} | train loss {'Reaction outcome loss': 0.5115311465287296, 'Total loss': 0.5115311465287296}
2023-01-05 08:17:13,715 INFO:     Found new best model at epoch 4
2023-01-05 08:17:13,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:17:13,717 INFO:     Epoch: 5
2023-01-05 08:17:15,856 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48922396898269654, 'Total loss': 0.48922396898269654} | train loss {'Reaction outcome loss': 0.501448204972013, 'Total loss': 0.501448204972013}
2023-01-05 08:17:15,856 INFO:     Found new best model at epoch 5
2023-01-05 08:17:15,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:17:15,857 INFO:     Epoch: 6
2023-01-05 08:17:17,997 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46079721053441364, 'Total loss': 0.46079721053441364} | train loss {'Reaction outcome loss': 0.49418287539351596, 'Total loss': 0.49418287539351596}
2023-01-05 08:17:17,998 INFO:     Found new best model at epoch 6
2023-01-05 08:17:17,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:17:17,999 INFO:     Epoch: 7
2023-01-05 08:17:20,126 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49300921758015953, 'Total loss': 0.49300921758015953} | train loss {'Reaction outcome loss': 0.4880436883464347, 'Total loss': 0.4880436883464347}
2023-01-05 08:17:20,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:17:20,126 INFO:     Epoch: 8
2023-01-05 08:17:22,247 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4862334579229355, 'Total loss': 0.4862334579229355} | train loss {'Reaction outcome loss': 0.47353582008041606, 'Total loss': 0.47353582008041606}
2023-01-05 08:17:22,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:17:22,249 INFO:     Epoch: 9
2023-01-05 08:17:24,385 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4910465757052104, 'Total loss': 0.4910465757052104} | train loss {'Reaction outcome loss': 0.4637091868169551, 'Total loss': 0.4637091868169551}
2023-01-05 08:17:24,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:17:24,386 INFO:     Epoch: 10
2023-01-05 08:17:26,522 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.466491857667764, 'Total loss': 0.466491857667764} | train loss {'Reaction outcome loss': 0.4648112736805512, 'Total loss': 0.4648112736805512}
2023-01-05 08:17:26,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:17:26,522 INFO:     Epoch: 11
2023-01-05 08:17:28,671 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48707624872525535, 'Total loss': 0.48707624872525535} | train loss {'Reaction outcome loss': 0.4605979173559777, 'Total loss': 0.4605979173559777}
2023-01-05 08:17:28,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:17:28,672 INFO:     Epoch: 12
2023-01-05 08:17:30,812 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45818467338879904, 'Total loss': 0.45818467338879904} | train loss {'Reaction outcome loss': 0.45974617870184625, 'Total loss': 0.45974617870184625}
2023-01-05 08:17:30,812 INFO:     Found new best model at epoch 12
2023-01-05 08:17:30,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:17:30,813 INFO:     Epoch: 13
2023-01-05 08:17:32,958 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4622933745384216, 'Total loss': 0.4622933745384216} | train loss {'Reaction outcome loss': 0.45024661518578984, 'Total loss': 0.45024661518578984}
2023-01-05 08:17:32,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:17:32,958 INFO:     Epoch: 14
2023-01-05 08:17:35,082 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4624159723520279, 'Total loss': 0.4624159723520279} | train loss {'Reaction outcome loss': 0.44646555169002855, 'Total loss': 0.44646555169002855}
2023-01-05 08:17:35,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:17:35,082 INFO:     Epoch: 15
2023-01-05 08:17:37,232 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4833845555782318, 'Total loss': 0.4833845555782318} | train loss {'Reaction outcome loss': 0.44243839127521445, 'Total loss': 0.44243839127521445}
2023-01-05 08:17:37,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:17:37,232 INFO:     Epoch: 16
2023-01-05 08:17:39,383 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4578444540500641, 'Total loss': 0.4578444540500641} | train loss {'Reaction outcome loss': 0.4383386899683162, 'Total loss': 0.4383386899683162}
2023-01-05 08:17:39,383 INFO:     Found new best model at epoch 16
2023-01-05 08:17:39,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:17:39,384 INFO:     Epoch: 17
2023-01-05 08:17:41,527 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49060946702957153, 'Total loss': 0.49060946702957153} | train loss {'Reaction outcome loss': 0.4360642633298888, 'Total loss': 0.4360642633298888}
2023-01-05 08:17:41,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:17:41,528 INFO:     Epoch: 18
2023-01-05 08:17:43,671 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4567137857278188, 'Total loss': 0.4567137857278188} | train loss {'Reaction outcome loss': 0.43482787520998584, 'Total loss': 0.43482787520998584}
2023-01-05 08:17:43,672 INFO:     Found new best model at epoch 18
2023-01-05 08:17:43,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:17:43,673 INFO:     Epoch: 19
2023-01-05 08:17:45,797 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46287512679894766, 'Total loss': 0.46287512679894766} | train loss {'Reaction outcome loss': 0.4286140656764925, 'Total loss': 0.4286140656764925}
2023-01-05 08:17:45,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:17:45,798 INFO:     Epoch: 20
2023-01-05 08:17:47,996 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5204208572705586, 'Total loss': 0.5204208572705586} | train loss {'Reaction outcome loss': 0.42375092322591446, 'Total loss': 0.42375092322591446}
2023-01-05 08:17:47,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:17:47,996 INFO:     Epoch: 21
2023-01-05 08:17:50,144 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4757208079099655, 'Total loss': 0.4757208079099655} | train loss {'Reaction outcome loss': 0.4222939388867277, 'Total loss': 0.4222939388867277}
2023-01-05 08:17:50,144 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:17:50,144 INFO:     Epoch: 22
2023-01-05 08:17:52,290 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.477554589509964, 'Total loss': 0.477554589509964} | train loss {'Reaction outcome loss': 0.4194497789670951, 'Total loss': 0.4194497789670951}
2023-01-05 08:17:52,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:17:52,291 INFO:     Epoch: 23
2023-01-05 08:17:54,432 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4737502187490463, 'Total loss': 0.4737502187490463} | train loss {'Reaction outcome loss': 0.4221823198625641, 'Total loss': 0.4221823198625641}
2023-01-05 08:17:54,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:17:54,432 INFO:     Epoch: 24
2023-01-05 08:17:56,561 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4797676960627238, 'Total loss': 0.4797676960627238} | train loss {'Reaction outcome loss': 0.40703971955898033, 'Total loss': 0.40703971955898033}
2023-01-05 08:17:56,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:17:56,561 INFO:     Epoch: 25
2023-01-05 08:17:58,705 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4857105811436971, 'Total loss': 0.4857105811436971} | train loss {'Reaction outcome loss': 0.406846005360793, 'Total loss': 0.406846005360793}
2023-01-05 08:17:58,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:17:58,707 INFO:     Epoch: 26
2023-01-05 08:18:00,854 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.492657736937205, 'Total loss': 0.492657736937205} | train loss {'Reaction outcome loss': 0.4068760608125777, 'Total loss': 0.4068760608125777}
2023-01-05 08:18:00,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:18:00,854 INFO:     Epoch: 27
2023-01-05 08:18:03,001 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4712049335241318, 'Total loss': 0.4712049335241318} | train loss {'Reaction outcome loss': 0.4050704518972087, 'Total loss': 0.4050704518972087}
2023-01-05 08:18:03,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:18:03,002 INFO:     Epoch: 28
2023-01-05 08:18:05,137 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44763781428337096, 'Total loss': 0.44763781428337096} | train loss {'Reaction outcome loss': 0.3950446750016978, 'Total loss': 0.3950446750016978}
2023-01-05 08:18:05,138 INFO:     Found new best model at epoch 28
2023-01-05 08:18:05,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:18:05,139 INFO:     Epoch: 29
2023-01-05 08:18:07,255 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.5007129470507304, 'Total loss': 0.5007129470507304} | train loss {'Reaction outcome loss': 0.3950306644568043, 'Total loss': 0.3950306644568043}
2023-01-05 08:18:07,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:18:07,255 INFO:     Epoch: 30
2023-01-05 08:18:09,377 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4991025984287262, 'Total loss': 0.4991025984287262} | train loss {'Reaction outcome loss': 0.3928736438770799, 'Total loss': 0.3928736438770799}
2023-01-05 08:18:09,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:18:09,377 INFO:     Epoch: 31
2023-01-05 08:18:11,529 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4461744805177053, 'Total loss': 0.4461744805177053} | train loss {'Reaction outcome loss': 0.3881225577508011, 'Total loss': 0.3881225577508011}
2023-01-05 08:18:11,529 INFO:     Found new best model at epoch 31
2023-01-05 08:18:11,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:18:11,530 INFO:     Epoch: 32
2023-01-05 08:18:13,689 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43965657651424406, 'Total loss': 0.43965657651424406} | train loss {'Reaction outcome loss': 0.3887976029493513, 'Total loss': 0.3887976029493513}
2023-01-05 08:18:13,690 INFO:     Found new best model at epoch 32
2023-01-05 08:18:13,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:18:13,691 INFO:     Epoch: 33
2023-01-05 08:18:15,836 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.444036015868187, 'Total loss': 0.444036015868187} | train loss {'Reaction outcome loss': 0.37811531634987705, 'Total loss': 0.37811531634987705}
2023-01-05 08:18:15,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:18:15,836 INFO:     Epoch: 34
2023-01-05 08:18:17,978 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4487896194060644, 'Total loss': 0.4487896194060644} | train loss {'Reaction outcome loss': 0.3785040538730848, 'Total loss': 0.3785040538730848}
2023-01-05 08:18:17,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:18:17,979 INFO:     Epoch: 35
2023-01-05 08:18:20,120 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.46033038894335426, 'Total loss': 0.46033038894335426} | train loss {'Reaction outcome loss': 0.36778118767279344, 'Total loss': 0.36778118767279344}
2023-01-05 08:18:20,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:18:20,120 INFO:     Epoch: 36
2023-01-05 08:18:22,267 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.449633526802063, 'Total loss': 0.449633526802063} | train loss {'Reaction outcome loss': 0.3704537972807884, 'Total loss': 0.3704537972807884}
2023-01-05 08:18:22,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:18:22,268 INFO:     Epoch: 37
2023-01-05 08:18:24,421 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4389580935239792, 'Total loss': 0.4389580935239792} | train loss {'Reaction outcome loss': 0.3699528498670263, 'Total loss': 0.3699528498670263}
2023-01-05 08:18:24,421 INFO:     Found new best model at epoch 37
2023-01-05 08:18:24,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:18:24,422 INFO:     Epoch: 38
2023-01-05 08:18:26,574 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4745583365360896, 'Total loss': 0.4745583365360896} | train loss {'Reaction outcome loss': 0.3636933109403527, 'Total loss': 0.3636933109403527}
2023-01-05 08:18:26,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:18:26,575 INFO:     Epoch: 39
2023-01-05 08:18:28,711 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.47327640652656555, 'Total loss': 0.47327640652656555} | train loss {'Reaction outcome loss': 0.3671736865963814, 'Total loss': 0.3671736865963814}
2023-01-05 08:18:28,711 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:18:28,711 INFO:     Epoch: 40
2023-01-05 08:18:30,845 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44687620401382444, 'Total loss': 0.44687620401382444} | train loss {'Reaction outcome loss': 0.35588070691773926, 'Total loss': 0.35588070691773926}
2023-01-05 08:18:30,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:18:30,846 INFO:     Epoch: 41
2023-01-05 08:18:32,989 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4437069614728292, 'Total loss': 0.4437069614728292} | train loss {'Reaction outcome loss': 0.3525062274378147, 'Total loss': 0.3525062274378147}
2023-01-05 08:18:32,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:18:32,989 INFO:     Epoch: 42
2023-01-05 08:18:35,147 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4523745725552241, 'Total loss': 0.4523745725552241} | train loss {'Reaction outcome loss': 0.3541509627507333, 'Total loss': 0.3541509627507333}
2023-01-05 08:18:35,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:18:35,148 INFO:     Epoch: 43
2023-01-05 08:18:37,310 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.442088516553243, 'Total loss': 0.442088516553243} | train loss {'Reaction outcome loss': 0.3505826102719255, 'Total loss': 0.3505826102719255}
2023-01-05 08:18:37,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:18:37,310 INFO:     Epoch: 44
2023-01-05 08:18:39,458 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4372217287619909, 'Total loss': 0.4372217287619909} | train loss {'Reaction outcome loss': 0.346080809355761, 'Total loss': 0.346080809355761}
2023-01-05 08:18:39,458 INFO:     Found new best model at epoch 44
2023-01-05 08:18:39,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:18:39,459 INFO:     Epoch: 45
2023-01-05 08:18:41,624 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5124291767676671, 'Total loss': 0.5124291767676671} | train loss {'Reaction outcome loss': 0.333682896623755, 'Total loss': 0.333682896623755}
2023-01-05 08:18:41,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:18:41,625 INFO:     Epoch: 46
2023-01-05 08:18:43,766 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46080127557118733, 'Total loss': 0.46080127557118733} | train loss {'Reaction outcome loss': 0.34373647442264277, 'Total loss': 0.34373647442264277}
2023-01-05 08:18:43,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:18:43,766 INFO:     Epoch: 47
2023-01-05 08:18:45,915 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48642198046048485, 'Total loss': 0.48642198046048485} | train loss {'Reaction outcome loss': 0.33583593431071646, 'Total loss': 0.33583593431071646}
2023-01-05 08:18:45,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:18:45,916 INFO:     Epoch: 48
2023-01-05 08:18:48,065 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4326545168956121, 'Total loss': 0.4326545168956121} | train loss {'Reaction outcome loss': 0.3356600723698409, 'Total loss': 0.3356600723698409}
2023-01-05 08:18:48,065 INFO:     Found new best model at epoch 48
2023-01-05 08:18:48,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:18:48,066 INFO:     Epoch: 49
2023-01-05 08:18:50,210 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.47505223552385967, 'Total loss': 0.47505223552385967} | train loss {'Reaction outcome loss': 0.327958127347766, 'Total loss': 0.327958127347766}
2023-01-05 08:18:50,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:18:50,210 INFO:     Epoch: 50
2023-01-05 08:18:52,389 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.47860611776510875, 'Total loss': 0.47860611776510875} | train loss {'Reaction outcome loss': 0.33093759132018924, 'Total loss': 0.33093759132018924}
2023-01-05 08:18:52,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:18:52,390 INFO:     Epoch: 51
2023-01-05 08:18:54,541 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4583307107289632, 'Total loss': 0.4583307107289632} | train loss {'Reaction outcome loss': 0.31668979798300856, 'Total loss': 0.31668979798300856}
2023-01-05 08:18:54,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:18:54,542 INFO:     Epoch: 52
2023-01-05 08:18:56,695 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47350776493549346, 'Total loss': 0.47350776493549346} | train loss {'Reaction outcome loss': 0.32278717558042413, 'Total loss': 0.32278717558042413}
2023-01-05 08:18:56,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:18:56,695 INFO:     Epoch: 53
2023-01-05 08:18:58,888 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4476158599058787, 'Total loss': 0.4476158599058787} | train loss {'Reaction outcome loss': 0.31714545050296034, 'Total loss': 0.31714545050296034}
2023-01-05 08:18:58,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:18:58,888 INFO:     Epoch: 54
2023-01-05 08:19:01,056 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4328454822301865, 'Total loss': 0.4328454822301865} | train loss {'Reaction outcome loss': 0.32334634429183756, 'Total loss': 0.32334634429183756}
2023-01-05 08:19:01,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:19:01,057 INFO:     Epoch: 55
2023-01-05 08:19:03,203 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4458077222108841, 'Total loss': 0.4458077222108841} | train loss {'Reaction outcome loss': 0.314020424279092, 'Total loss': 0.314020424279092}
2023-01-05 08:19:03,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:19:03,203 INFO:     Epoch: 56
2023-01-05 08:19:05,336 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46138047575950625, 'Total loss': 0.46138047575950625} | train loss {'Reaction outcome loss': 0.3089508802704785, 'Total loss': 0.3089508802704785}
2023-01-05 08:19:05,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:19:05,338 INFO:     Epoch: 57
2023-01-05 08:19:07,472 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4446371724208196, 'Total loss': 0.4446371724208196} | train loss {'Reaction outcome loss': 0.3091828955378193, 'Total loss': 0.3091828955378193}
2023-01-05 08:19:07,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:19:07,472 INFO:     Epoch: 58
2023-01-05 08:19:09,621 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41252419153849285, 'Total loss': 0.41252419153849285} | train loss {'Reaction outcome loss': 0.31276514798565935, 'Total loss': 0.31276514798565935}
2023-01-05 08:19:09,621 INFO:     Found new best model at epoch 58
2023-01-05 08:19:09,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:19:09,623 INFO:     Epoch: 59
2023-01-05 08:19:11,758 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42774477899074553, 'Total loss': 0.42774477899074553} | train loss {'Reaction outcome loss': 0.3026119811990618, 'Total loss': 0.3026119811990618}
2023-01-05 08:19:11,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:19:11,759 INFO:     Epoch: 60
2023-01-05 08:19:13,907 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4176553895076116, 'Total loss': 0.4176553895076116} | train loss {'Reaction outcome loss': 0.30560933886925234, 'Total loss': 0.30560933886925234}
2023-01-05 08:19:13,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:19:13,907 INFO:     Epoch: 61
2023-01-05 08:19:16,028 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43319651583830515, 'Total loss': 0.43319651583830515} | train loss {'Reaction outcome loss': 0.29873221861130567, 'Total loss': 0.29873221861130567}
2023-01-05 08:19:16,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:19:16,029 INFO:     Epoch: 62
2023-01-05 08:19:18,156 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4375392526388168, 'Total loss': 0.4375392526388168} | train loss {'Reaction outcome loss': 0.3030012762106031, 'Total loss': 0.3030012762106031}
2023-01-05 08:19:18,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:19:18,156 INFO:     Epoch: 63
2023-01-05 08:19:20,292 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4355263193448385, 'Total loss': 0.4355263193448385} | train loss {'Reaction outcome loss': 0.29842942406552553, 'Total loss': 0.29842942406552553}
2023-01-05 08:19:20,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:19:20,293 INFO:     Epoch: 64
2023-01-05 08:19:22,435 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44895623723665873, 'Total loss': 0.44895623723665873} | train loss {'Reaction outcome loss': 0.2911730359043301, 'Total loss': 0.2911730359043301}
2023-01-05 08:19:22,436 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:19:22,436 INFO:     Epoch: 65
2023-01-05 08:19:24,589 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4717865296329061, 'Total loss': 0.4717865296329061} | train loss {'Reaction outcome loss': 0.2878633349535674, 'Total loss': 0.2878633349535674}
2023-01-05 08:19:24,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:19:24,590 INFO:     Epoch: 66
2023-01-05 08:19:26,735 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4496234985689322, 'Total loss': 0.4496234985689322} | train loss {'Reaction outcome loss': 0.28854678488288915, 'Total loss': 0.28854678488288915}
2023-01-05 08:19:26,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:19:26,735 INFO:     Epoch: 67
2023-01-05 08:19:28,878 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4524710396925608, 'Total loss': 0.4524710396925608} | train loss {'Reaction outcome loss': 0.28696197632999315, 'Total loss': 0.28696197632999315}
2023-01-05 08:19:28,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:19:28,878 INFO:     Epoch: 68
2023-01-05 08:19:31,008 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.46518842279911043, 'Total loss': 0.46518842279911043} | train loss {'Reaction outcome loss': 0.28522533258545574, 'Total loss': 0.28522533258545574}
2023-01-05 08:19:31,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:19:31,008 INFO:     Epoch: 69
2023-01-05 08:19:33,148 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4995049277941386, 'Total loss': 0.4995049277941386} | train loss {'Reaction outcome loss': 0.28640094582997533, 'Total loss': 0.28640094582997533}
2023-01-05 08:19:33,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:19:33,149 INFO:     Epoch: 70
2023-01-05 08:19:35,288 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4278128276268641, 'Total loss': 0.4278128276268641} | train loss {'Reaction outcome loss': 0.28299797482679795, 'Total loss': 0.28299797482679795}
2023-01-05 08:19:35,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:19:35,289 INFO:     Epoch: 71
2023-01-05 08:19:37,432 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.437730218966802, 'Total loss': 0.437730218966802} | train loss {'Reaction outcome loss': 0.2811212902956635, 'Total loss': 0.2811212902956635}
2023-01-05 08:19:37,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:19:37,433 INFO:     Epoch: 72
2023-01-05 08:19:39,581 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4359159251054128, 'Total loss': 0.4359159251054128} | train loss {'Reaction outcome loss': 0.28308653808368817, 'Total loss': 0.28308653808368817}
2023-01-05 08:19:39,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:19:39,581 INFO:     Epoch: 73
2023-01-05 08:19:41,716 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.47201889753341675, 'Total loss': 0.47201889753341675} | train loss {'Reaction outcome loss': 0.277920522788254, 'Total loss': 0.277920522788254}
2023-01-05 08:19:41,717 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:19:41,717 INFO:     Epoch: 74
2023-01-05 08:19:43,851 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.47071849505106605, 'Total loss': 0.47071849505106605} | train loss {'Reaction outcome loss': 0.2752417700473953, 'Total loss': 0.2752417700473953}
2023-01-05 08:19:43,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:19:43,852 INFO:     Epoch: 75
2023-01-05 08:19:45,997 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43012930552164713, 'Total loss': 0.43012930552164713} | train loss {'Reaction outcome loss': 0.2734875738158496, 'Total loss': 0.2734875738158496}
2023-01-05 08:19:45,997 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:19:45,997 INFO:     Epoch: 76
2023-01-05 08:19:48,129 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43024387458960217, 'Total loss': 0.43024387458960217} | train loss {'Reaction outcome loss': 0.2689872648376618, 'Total loss': 0.2689872648376618}
2023-01-05 08:19:48,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:19:48,129 INFO:     Epoch: 77
2023-01-05 08:19:50,286 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.47450507481892906, 'Total loss': 0.47450507481892906} | train loss {'Reaction outcome loss': 0.2654864069441483, 'Total loss': 0.2654864069441483}
2023-01-05 08:19:50,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:19:50,287 INFO:     Epoch: 78
2023-01-05 08:19:52,440 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4195769727230072, 'Total loss': 0.4195769727230072} | train loss {'Reaction outcome loss': 0.26472592331387484, 'Total loss': 0.26472592331387484}
2023-01-05 08:19:52,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:19:52,440 INFO:     Epoch: 79
2023-01-05 08:19:54,574 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42356157849232356, 'Total loss': 0.42356157849232356} | train loss {'Reaction outcome loss': 0.2662546114289086, 'Total loss': 0.2662546114289086}
2023-01-05 08:19:54,575 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:19:54,575 INFO:     Epoch: 80
2023-01-05 08:19:56,723 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.44542988737424216, 'Total loss': 0.44542988737424216} | train loss {'Reaction outcome loss': 0.26603289376128547, 'Total loss': 0.26603289376128547}
2023-01-05 08:19:56,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:19:56,723 INFO:     Epoch: 81
2023-01-05 08:19:58,878 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.45958440701166786, 'Total loss': 0.45958440701166786} | train loss {'Reaction outcome loss': 0.25612522133483284, 'Total loss': 0.25612522133483284}
2023-01-05 08:19:58,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:19:58,879 INFO:     Epoch: 82
2023-01-05 08:20:01,037 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.46568904221057894, 'Total loss': 0.46568904221057894} | train loss {'Reaction outcome loss': 0.2623492508555633, 'Total loss': 0.2623492508555633}
2023-01-05 08:20:01,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:20:01,038 INFO:     Epoch: 83
2023-01-05 08:20:03,189 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4306843598683675, 'Total loss': 0.4306843598683675} | train loss {'Reaction outcome loss': 0.2658941865266457, 'Total loss': 0.2658941865266457}
2023-01-05 08:20:03,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:20:03,189 INFO:     Epoch: 84
2023-01-05 08:20:05,323 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4329652468363444, 'Total loss': 0.4329652468363444} | train loss {'Reaction outcome loss': 0.2648385110698695, 'Total loss': 0.2648385110698695}
2023-01-05 08:20:05,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:20:05,323 INFO:     Epoch: 85
2023-01-05 08:20:07,483 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4225957989692688, 'Total loss': 0.4225957989692688} | train loss {'Reaction outcome loss': 0.25623358680737496, 'Total loss': 0.25623358680737496}
2023-01-05 08:20:07,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:20:07,484 INFO:     Epoch: 86
2023-01-05 08:20:09,640 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4077544818321864, 'Total loss': 0.4077544818321864} | train loss {'Reaction outcome loss': 0.26264644300660295, 'Total loss': 0.26264644300660295}
2023-01-05 08:20:09,640 INFO:     Found new best model at epoch 86
2023-01-05 08:20:09,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:20:09,641 INFO:     Epoch: 87
2023-01-05 08:20:11,798 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40936275372902553, 'Total loss': 0.40936275372902553} | train loss {'Reaction outcome loss': 0.2581059871866864, 'Total loss': 0.2581059871866864}
2023-01-05 08:20:11,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:20:11,800 INFO:     Epoch: 88
2023-01-05 08:20:13,957 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.49074980517228445, 'Total loss': 0.49074980517228445} | train loss {'Reaction outcome loss': 0.2613702530625963, 'Total loss': 0.2613702530625963}
2023-01-05 08:20:13,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:20:13,958 INFO:     Epoch: 89
2023-01-05 08:20:16,107 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47512926956017815, 'Total loss': 0.47512926956017815} | train loss {'Reaction outcome loss': 0.2496943583059376, 'Total loss': 0.2496943583059376}
2023-01-05 08:20:16,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:20:16,107 INFO:     Epoch: 90
2023-01-05 08:20:18,226 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4690871467192968, 'Total loss': 0.4690871467192968} | train loss {'Reaction outcome loss': 0.2474357527170847, 'Total loss': 0.2474357527170847}
2023-01-05 08:20:18,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:20:18,227 INFO:     Epoch: 91
2023-01-05 08:20:20,373 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4462509567538897, 'Total loss': 0.4462509567538897} | train loss {'Reaction outcome loss': 0.2541739275257518, 'Total loss': 0.2541739275257518}
2023-01-05 08:20:20,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:20:20,373 INFO:     Epoch: 92
2023-01-05 08:20:22,510 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.41685209472974144, 'Total loss': 0.41685209472974144} | train loss {'Reaction outcome loss': 0.25274929924983613, 'Total loss': 0.25274929924983613}
2023-01-05 08:20:22,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:20:22,510 INFO:     Epoch: 93
2023-01-05 08:20:24,651 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.437312051653862, 'Total loss': 0.437312051653862} | train loss {'Reaction outcome loss': 0.25128238082584675, 'Total loss': 0.25128238082584675}
2023-01-05 08:20:24,651 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:20:24,651 INFO:     Epoch: 94
2023-01-05 08:20:26,803 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43869010408719383, 'Total loss': 0.43869010408719383} | train loss {'Reaction outcome loss': 0.24531492813877817, 'Total loss': 0.24531492813877817}
2023-01-05 08:20:26,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:20:26,803 INFO:     Epoch: 95
2023-01-05 08:20:28,925 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4485553612311681, 'Total loss': 0.4485553612311681} | train loss {'Reaction outcome loss': 0.257365872607614, 'Total loss': 0.257365872607614}
2023-01-05 08:20:28,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:20:28,926 INFO:     Epoch: 96
2023-01-05 08:20:31,075 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4754037300745646, 'Total loss': 0.4754037300745646} | train loss {'Reaction outcome loss': 0.24631437614396975, 'Total loss': 0.24631437614396975}
2023-01-05 08:20:31,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:20:31,076 INFO:     Epoch: 97
2023-01-05 08:20:33,237 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42782801687717437, 'Total loss': 0.42782801687717437} | train loss {'Reaction outcome loss': 0.2395447100934158, 'Total loss': 0.2395447100934158}
2023-01-05 08:20:33,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:20:33,237 INFO:     Epoch: 98
2023-01-05 08:20:35,394 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4358649303515752, 'Total loss': 0.4358649303515752} | train loss {'Reaction outcome loss': 0.2414694185501277, 'Total loss': 0.2414694185501277}
2023-01-05 08:20:35,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:20:35,395 INFO:     Epoch: 99
2023-01-05 08:20:37,551 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45281137228012086, 'Total loss': 0.45281137228012086} | train loss {'Reaction outcome loss': 0.246851272894627, 'Total loss': 0.246851272894627}
2023-01-05 08:20:37,551 INFO:     Best model found after epoch 87 of 100.
2023-01-05 08:20:37,551 INFO:   Done with stage: TRAINING
2023-01-05 08:20:37,551 INFO:   Starting stage: EVALUATION
2023-01-05 08:20:37,690 INFO:   Done with stage: EVALUATION
2023-01-05 08:20:37,691 INFO:   Leaving out SEQ value Fold_1
2023-01-05 08:20:37,703 INFO:   examples: 20,544| examples in train: 17,328 | examples in val: 912| examples in test: 2,304
2023-01-05 08:20:37,704 INFO:   Starting stage: FEATURE SCALING
2023-01-05 08:20:38,357 INFO:   Done with stage: FEATURE SCALING
2023-01-05 08:20:38,357 INFO:   Starting stage: SCALING TARGETS
2023-01-05 08:20:38,426 INFO:   Done with stage: SCALING TARGETS
2023-01-05 08:20:38,426 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:20:38,426 INFO:     No hyperparam tuning for this model
2023-01-05 08:20:38,426 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:20:38,426 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 08:20:38,427 INFO:     None feature selector for col prot
2023-01-05 08:20:38,427 INFO:     None feature selector for col prot
2023-01-05 08:20:38,427 INFO:     None feature selector for col prot
2023-01-05 08:20:38,428 INFO:     None feature selector for col chem
2023-01-05 08:20:38,428 INFO:     None feature selector for col chem
2023-01-05 08:20:38,428 INFO:     None feature selector for col chem
2023-01-05 08:20:38,428 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 08:20:38,428 INFO:   Starting stage: BUILD MODEL
2023-01-05 08:20:38,430 INFO:     Number of params in model 72901
2023-01-05 08:20:38,433 INFO:   Done with stage: BUILD MODEL
2023-01-05 08:20:38,433 INFO:   Starting stage: TRAINING
2023-01-05 08:20:38,494 INFO:     Val loss before train {'Reaction outcome loss': 1.018127965927124, 'Total loss': 1.018127965927124}
2023-01-05 08:20:38,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:20:38,494 INFO:     Epoch: 0
2023-01-05 08:20:40,590 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8393367091814677, 'Total loss': 0.8393367091814677} | train loss {'Reaction outcome loss': 0.9346710909776582, 'Total loss': 0.9346710909776582}
2023-01-05 08:20:40,590 INFO:     Found new best model at epoch 0
2023-01-05 08:20:40,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:20:40,592 INFO:     Epoch: 1
2023-01-05 08:20:42,725 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6268066346645356, 'Total loss': 0.6268066346645356} | train loss {'Reaction outcome loss': 0.7548465370252123, 'Total loss': 0.7548465370252123}
2023-01-05 08:20:42,725 INFO:     Found new best model at epoch 1
2023-01-05 08:20:42,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:20:42,727 INFO:     Epoch: 2
2023-01-05 08:20:44,852 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5542917907238006, 'Total loss': 0.5542917907238006} | train loss {'Reaction outcome loss': 0.575149709558135, 'Total loss': 0.575149709558135}
2023-01-05 08:20:44,852 INFO:     Found new best model at epoch 2
2023-01-05 08:20:44,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:20:44,854 INFO:     Epoch: 3
2023-01-05 08:20:46,981 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5312953392664591, 'Total loss': 0.5312953392664591} | train loss {'Reaction outcome loss': 0.5260984868471033, 'Total loss': 0.5260984868471033}
2023-01-05 08:20:46,983 INFO:     Found new best model at epoch 3
2023-01-05 08:20:46,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:20:46,984 INFO:     Epoch: 4
2023-01-05 08:20:49,120 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.511547311147054, 'Total loss': 0.511547311147054} | train loss {'Reaction outcome loss': 0.503771323889384, 'Total loss': 0.503771323889384}
2023-01-05 08:20:49,120 INFO:     Found new best model at epoch 4
2023-01-05 08:20:49,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:20:49,121 INFO:     Epoch: 5
2023-01-05 08:20:51,247 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5011158933242162, 'Total loss': 0.5011158933242162} | train loss {'Reaction outcome loss': 0.4963619052484027, 'Total loss': 0.4963619052484027}
2023-01-05 08:20:51,248 INFO:     Found new best model at epoch 5
2023-01-05 08:20:51,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:20:51,249 INFO:     Epoch: 6
2023-01-05 08:20:53,358 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49164096216360725, 'Total loss': 0.49164096216360725} | train loss {'Reaction outcome loss': 0.48057266187293946, 'Total loss': 0.48057266187293946}
2023-01-05 08:20:53,359 INFO:     Found new best model at epoch 6
2023-01-05 08:20:53,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:20:53,360 INFO:     Epoch: 7
2023-01-05 08:20:55,483 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.49824510316054027, 'Total loss': 0.49824510316054027} | train loss {'Reaction outcome loss': 0.4786797905430143, 'Total loss': 0.4786797905430143}
2023-01-05 08:20:55,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:20:55,483 INFO:     Epoch: 8
2023-01-05 08:20:57,602 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4939007302125295, 'Total loss': 0.4939007302125295} | train loss {'Reaction outcome loss': 0.4718850966804142, 'Total loss': 0.4718850966804142}
2023-01-05 08:20:57,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:20:57,602 INFO:     Epoch: 9
2023-01-05 08:20:59,739 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.49078359405199684, 'Total loss': 0.49078359405199684} | train loss {'Reaction outcome loss': 0.4668649759459759, 'Total loss': 0.4668649759459759}
2023-01-05 08:20:59,739 INFO:     Found new best model at epoch 9
2023-01-05 08:20:59,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:20:59,740 INFO:     Epoch: 10
2023-01-05 08:21:01,861 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47425688604513805, 'Total loss': 0.47425688604513805} | train loss {'Reaction outcome loss': 0.45845252335951336, 'Total loss': 0.45845252335951336}
2023-01-05 08:21:01,861 INFO:     Found new best model at epoch 10
2023-01-05 08:21:01,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:21:01,863 INFO:     Epoch: 11
2023-01-05 08:21:03,978 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5164758304754893, 'Total loss': 0.5164758304754893} | train loss {'Reaction outcome loss': 0.4541408839700847, 'Total loss': 0.4541408839700847}
2023-01-05 08:21:03,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:21:03,979 INFO:     Epoch: 12
2023-01-05 08:21:06,118 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5151648143927257, 'Total loss': 0.5151648143927257} | train loss {'Reaction outcome loss': 0.44866342996539227, 'Total loss': 0.44866342996539227}
2023-01-05 08:21:06,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:21:06,119 INFO:     Epoch: 13
2023-01-05 08:21:08,244 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48670775492986046, 'Total loss': 0.48670775492986046} | train loss {'Reaction outcome loss': 0.4465611201480746, 'Total loss': 0.4465611201480746}
2023-01-05 08:21:08,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:21:08,244 INFO:     Epoch: 14
2023-01-05 08:21:10,355 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48188166618347167, 'Total loss': 0.48188166618347167} | train loss {'Reaction outcome loss': 0.442574039321544, 'Total loss': 0.442574039321544}
2023-01-05 08:21:10,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:21:10,355 INFO:     Epoch: 15
2023-01-05 08:21:12,470 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4726648320754369, 'Total loss': 0.4726648320754369} | train loss {'Reaction outcome loss': 0.43714599635768203, 'Total loss': 0.43714599635768203}
2023-01-05 08:21:12,470 INFO:     Found new best model at epoch 15
2023-01-05 08:21:12,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:21:12,471 INFO:     Epoch: 16
2023-01-05 08:21:14,581 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.49744133949279784, 'Total loss': 0.49744133949279784} | train loss {'Reaction outcome loss': 0.4337593496010752, 'Total loss': 0.4337593496010752}
2023-01-05 08:21:14,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:21:14,581 INFO:     Epoch: 17
2023-01-05 08:21:16,665 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4684346616268158, 'Total loss': 0.4684346616268158} | train loss {'Reaction outcome loss': 0.4307961096622847, 'Total loss': 0.4307961096622847}
2023-01-05 08:21:16,665 INFO:     Found new best model at epoch 17
2023-01-05 08:21:16,666 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:21:16,666 INFO:     Epoch: 18
2023-01-05 08:21:18,779 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47649436791737876, 'Total loss': 0.47649436791737876} | train loss {'Reaction outcome loss': 0.42414085039133514, 'Total loss': 0.42414085039133514}
2023-01-05 08:21:18,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:21:18,779 INFO:     Epoch: 19
2023-01-05 08:21:20,695 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4899845411380132, 'Total loss': 0.4899845411380132} | train loss {'Reaction outcome loss': 0.422610536052732, 'Total loss': 0.422610536052732}
2023-01-05 08:21:20,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:21:20,695 INFO:     Epoch: 20
2023-01-05 08:21:22,821 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5180548191070556, 'Total loss': 0.5180548191070556} | train loss {'Reaction outcome loss': 0.4184046147934185, 'Total loss': 0.4184046147934185}
2023-01-05 08:21:22,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:21:22,823 INFO:     Epoch: 21
2023-01-05 08:21:24,938 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.46011913220087686, 'Total loss': 0.46011913220087686} | train loss {'Reaction outcome loss': 0.41510337280501297, 'Total loss': 0.41510337280501297}
2023-01-05 08:21:24,938 INFO:     Found new best model at epoch 21
2023-01-05 08:21:24,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:21:24,940 INFO:     Epoch: 22
2023-01-05 08:21:27,028 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4693692555030187, 'Total loss': 0.4693692555030187} | train loss {'Reaction outcome loss': 0.41319363002022697, 'Total loss': 0.41319363002022697}
2023-01-05 08:21:27,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:21:27,029 INFO:     Epoch: 23
2023-01-05 08:21:29,136 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.45418526927630104, 'Total loss': 0.45418526927630104} | train loss {'Reaction outcome loss': 0.40755085130239327, 'Total loss': 0.40755085130239327}
2023-01-05 08:21:29,137 INFO:     Found new best model at epoch 23
2023-01-05 08:21:29,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:21:29,139 INFO:     Epoch: 24
2023-01-05 08:21:31,262 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5109101891517639, 'Total loss': 0.5109101891517639} | train loss {'Reaction outcome loss': 0.40844277894584896, 'Total loss': 0.40844277894584896}
2023-01-05 08:21:31,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:21:31,262 INFO:     Epoch: 25
2023-01-05 08:21:33,378 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4529928629597028, 'Total loss': 0.4529928629597028} | train loss {'Reaction outcome loss': 0.4004884158773176, 'Total loss': 0.4004884158773176}
2023-01-05 08:21:33,378 INFO:     Found new best model at epoch 25
2023-01-05 08:21:33,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:21:33,379 INFO:     Epoch: 26
2023-01-05 08:21:35,527 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.48973267078399657, 'Total loss': 0.48973267078399657} | train loss {'Reaction outcome loss': 0.39352022235133993, 'Total loss': 0.39352022235133993}
2023-01-05 08:21:35,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:21:35,527 INFO:     Epoch: 27
2023-01-05 08:21:37,656 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.47885157267252604, 'Total loss': 0.47885157267252604} | train loss {'Reaction outcome loss': 0.3922570108597569, 'Total loss': 0.3922570108597569}
2023-01-05 08:21:37,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:21:37,657 INFO:     Epoch: 28
2023-01-05 08:21:39,750 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.46126449704170225, 'Total loss': 0.46126449704170225} | train loss {'Reaction outcome loss': 0.3895410620418422, 'Total loss': 0.3895410620418422}
2023-01-05 08:21:39,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:21:39,751 INFO:     Epoch: 29
2023-01-05 08:21:41,876 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47940772771835327, 'Total loss': 0.47940772771835327} | train loss {'Reaction outcome loss': 0.3856808217964049, 'Total loss': 0.3856808217964049}
2023-01-05 08:21:41,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:21:41,877 INFO:     Epoch: 30
2023-01-05 08:21:44,018 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4876552204291026, 'Total loss': 0.4876552204291026} | train loss {'Reaction outcome loss': 0.37908868093002324, 'Total loss': 0.37908868093002324}
2023-01-05 08:21:44,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:21:44,019 INFO:     Epoch: 31
2023-01-05 08:21:46,149 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47882106304168703, 'Total loss': 0.47882106304168703} | train loss {'Reaction outcome loss': 0.3857844946184282, 'Total loss': 0.3857844946184282}
2023-01-05 08:21:46,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:21:46,149 INFO:     Epoch: 32
2023-01-05 08:21:48,285 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4764256382981936, 'Total loss': 0.4764256382981936} | train loss {'Reaction outcome loss': 0.37272114650349775, 'Total loss': 0.37272114650349775}
2023-01-05 08:21:48,285 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:21:48,285 INFO:     Epoch: 33
2023-01-05 08:21:50,393 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4550286442041397, 'Total loss': 0.4550286442041397} | train loss {'Reaction outcome loss': 0.37765178796440035, 'Total loss': 0.37765178796440035}
2023-01-05 08:21:50,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:21:50,394 INFO:     Epoch: 34
2023-01-05 08:21:52,538 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4531014228860537, 'Total loss': 0.4531014228860537} | train loss {'Reaction outcome loss': 0.36868945566930456, 'Total loss': 0.36868945566930456}
2023-01-05 08:21:52,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:21:52,538 INFO:     Epoch: 35
2023-01-05 08:21:54,684 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.5078490475813547, 'Total loss': 0.5078490475813547} | train loss {'Reaction outcome loss': 0.36909622323743974, 'Total loss': 0.36909622323743974}
2023-01-05 08:21:54,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:21:54,685 INFO:     Epoch: 36
2023-01-05 08:21:56,824 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4493953208128611, 'Total loss': 0.4493953208128611} | train loss {'Reaction outcome loss': 0.3664980030367735, 'Total loss': 0.3664980030367735}
2023-01-05 08:21:56,824 INFO:     Found new best model at epoch 36
2023-01-05 08:21:56,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:21:56,825 INFO:     Epoch: 37
2023-01-05 08:21:58,962 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4498158648610115, 'Total loss': 0.4498158648610115} | train loss {'Reaction outcome loss': 0.3626972919130677, 'Total loss': 0.3626972919130677}
2023-01-05 08:21:58,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:21:58,963 INFO:     Epoch: 38
2023-01-05 08:22:01,140 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4485532232094556, 'Total loss': 0.4485532232094556} | train loss {'Reaction outcome loss': 0.359919759358977, 'Total loss': 0.359919759358977}
2023-01-05 08:22:01,140 INFO:     Found new best model at epoch 38
2023-01-05 08:22:01,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:22:01,142 INFO:     Epoch: 39
2023-01-05 08:22:03,290 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4740604966878891, 'Total loss': 0.4740604966878891} | train loss {'Reaction outcome loss': 0.35662919579836716, 'Total loss': 0.35662919579836716}
2023-01-05 08:22:03,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:22:03,290 INFO:     Epoch: 40
2023-01-05 08:22:05,466 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4882966331206262, 'Total loss': 0.4882966331206262} | train loss {'Reaction outcome loss': 0.353729453405221, 'Total loss': 0.353729453405221}
2023-01-05 08:22:05,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:22:05,467 INFO:     Epoch: 41
2023-01-05 08:22:07,643 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4645920266707738, 'Total loss': 0.4645920266707738} | train loss {'Reaction outcome loss': 0.3491256514158636, 'Total loss': 0.3491256514158636}
2023-01-05 08:22:07,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:22:07,643 INFO:     Epoch: 42
2023-01-05 08:22:09,829 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.47457323322693507, 'Total loss': 0.47457323322693507} | train loss {'Reaction outcome loss': 0.3546702813673283, 'Total loss': 0.3546702813673283}
2023-01-05 08:22:09,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:22:09,829 INFO:     Epoch: 43
2023-01-05 08:22:12,020 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.48858115474383035, 'Total loss': 0.48858115474383035} | train loss {'Reaction outcome loss': 0.3467027927951619, 'Total loss': 0.3467027927951619}
2023-01-05 08:22:12,020 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:22:12,020 INFO:     Epoch: 44
2023-01-05 08:22:14,162 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4547698353727659, 'Total loss': 0.4547698353727659} | train loss {'Reaction outcome loss': 0.34335701604720853, 'Total loss': 0.34335701604720853}
2023-01-05 08:22:14,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:22:14,162 INFO:     Epoch: 45
2023-01-05 08:22:16,336 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4455923054367304, 'Total loss': 0.4455923054367304} | train loss {'Reaction outcome loss': 0.3422178709776419, 'Total loss': 0.3422178709776419}
2023-01-05 08:22:16,336 INFO:     Found new best model at epoch 45
2023-01-05 08:22:16,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:22:16,338 INFO:     Epoch: 46
2023-01-05 08:22:18,512 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45977084872623286, 'Total loss': 0.45977084872623286} | train loss {'Reaction outcome loss': 0.3365573810750268, 'Total loss': 0.3365573810750268}
2023-01-05 08:22:18,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:22:18,513 INFO:     Epoch: 47
2023-01-05 08:22:20,638 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46623293360074364, 'Total loss': 0.46623293360074364} | train loss {'Reaction outcome loss': 0.33746013982819456, 'Total loss': 0.33746013982819456}
2023-01-05 08:22:20,639 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:22:20,639 INFO:     Epoch: 48
2023-01-05 08:22:22,745 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4459171666453282, 'Total loss': 0.4459171666453282} | train loss {'Reaction outcome loss': 0.333666208732832, 'Total loss': 0.333666208732832}
2023-01-05 08:22:22,745 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:22:22,746 INFO:     Epoch: 49
2023-01-05 08:22:24,852 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46479655305544537, 'Total loss': 0.46479655305544537} | train loss {'Reaction outcome loss': 0.33033676563703707, 'Total loss': 0.33033676563703707}
2023-01-05 08:22:24,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:22:24,852 INFO:     Epoch: 50
2023-01-05 08:22:27,030 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45218805770079296, 'Total loss': 0.45218805770079296} | train loss {'Reaction outcome loss': 0.3301441978484502, 'Total loss': 0.3301441978484502}
2023-01-05 08:22:27,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:22:27,030 INFO:     Epoch: 51
2023-01-05 08:22:29,206 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4364830479025841, 'Total loss': 0.4364830479025841} | train loss {'Reaction outcome loss': 0.32458962328264634, 'Total loss': 0.32458962328264634}
2023-01-05 08:22:29,207 INFO:     Found new best model at epoch 51
2023-01-05 08:22:29,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:22:29,208 INFO:     Epoch: 52
2023-01-05 08:22:31,367 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4254461884498596, 'Total loss': 0.4254461884498596} | train loss {'Reaction outcome loss': 0.3246587984318883, 'Total loss': 0.3246587984318883}
2023-01-05 08:22:31,368 INFO:     Found new best model at epoch 52
2023-01-05 08:22:31,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:22:31,369 INFO:     Epoch: 53
2023-01-05 08:22:33,531 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4228357355420788, 'Total loss': 0.4228357355420788} | train loss {'Reaction outcome loss': 0.31853403098798766, 'Total loss': 0.31853403098798766}
2023-01-05 08:22:33,531 INFO:     Found new best model at epoch 53
2023-01-05 08:22:33,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:22:33,533 INFO:     Epoch: 54
2023-01-05 08:22:35,692 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4497044324874878, 'Total loss': 0.4497044324874878} | train loss {'Reaction outcome loss': 0.3179796610398706, 'Total loss': 0.3179796610398706}
2023-01-05 08:22:35,693 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:22:35,693 INFO:     Epoch: 55
2023-01-05 08:22:37,813 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4538687159617742, 'Total loss': 0.4538687159617742} | train loss {'Reaction outcome loss': 0.3225169756975561, 'Total loss': 0.3225169756975561}
2023-01-05 08:22:37,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:22:37,813 INFO:     Epoch: 56
2023-01-05 08:22:39,980 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4386527379353841, 'Total loss': 0.4386527379353841} | train loss {'Reaction outcome loss': 0.31522050141133506, 'Total loss': 0.31522050141133506}
2023-01-05 08:22:39,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:22:39,981 INFO:     Epoch: 57
2023-01-05 08:22:42,107 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4732342620690664, 'Total loss': 0.4732342620690664} | train loss {'Reaction outcome loss': 0.30702732349453815, 'Total loss': 0.30702732349453815}
2023-01-05 08:22:42,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:22:42,108 INFO:     Epoch: 58
2023-01-05 08:22:44,234 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5123329083124797, 'Total loss': 0.5123329083124797} | train loss {'Reaction outcome loss': 0.3077545585007685, 'Total loss': 0.3077545585007685}
2023-01-05 08:22:44,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:22:44,234 INFO:     Epoch: 59
2023-01-05 08:22:46,356 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.47073205808798474, 'Total loss': 0.47073205808798474} | train loss {'Reaction outcome loss': 0.31411697334743954, 'Total loss': 0.31411697334743954}
2023-01-05 08:22:46,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:22:46,356 INFO:     Epoch: 60
2023-01-05 08:22:48,468 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.47576871514320374, 'Total loss': 0.47576871514320374} | train loss {'Reaction outcome loss': 0.30496953957030254, 'Total loss': 0.30496953957030254}
2023-01-05 08:22:48,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:22:48,469 INFO:     Epoch: 61
2023-01-05 08:22:50,596 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4804931998252869, 'Total loss': 0.4804931998252869} | train loss {'Reaction outcome loss': 0.30398735577219965, 'Total loss': 0.30398735577219965}
2023-01-05 08:22:50,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:22:50,596 INFO:     Epoch: 62
2023-01-05 08:22:52,721 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.43791769991318386, 'Total loss': 0.43791769991318386} | train loss {'Reaction outcome loss': 0.30249090624691377, 'Total loss': 0.30249090624691377}
2023-01-05 08:22:52,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:22:52,721 INFO:     Epoch: 63
2023-01-05 08:22:54,836 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.46643080314000446, 'Total loss': 0.46643080314000446} | train loss {'Reaction outcome loss': 0.30537356881637856, 'Total loss': 0.30537356881637856}
2023-01-05 08:22:54,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:22:54,837 INFO:     Epoch: 64
2023-01-05 08:22:56,951 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.5067235678434372, 'Total loss': 0.5067235678434372} | train loss {'Reaction outcome loss': 0.3038475465208182, 'Total loss': 0.3038475465208182}
2023-01-05 08:22:56,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:22:56,951 INFO:     Epoch: 65
2023-01-05 08:22:59,069 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.45509633620580037, 'Total loss': 0.45509633620580037} | train loss {'Reaction outcome loss': 0.29851505050360055, 'Total loss': 0.29851505050360055}
2023-01-05 08:22:59,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:22:59,070 INFO:     Epoch: 66
2023-01-05 08:23:01,157 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45847901701927185, 'Total loss': 0.45847901701927185} | train loss {'Reaction outcome loss': 0.30260385288358616, 'Total loss': 0.30260385288358616}
2023-01-05 08:23:01,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:23:01,157 INFO:     Epoch: 67
2023-01-05 08:23:03,284 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.43778986632823946, 'Total loss': 0.43778986632823946} | train loss {'Reaction outcome loss': 0.29268927802074, 'Total loss': 0.29268927802074}
2023-01-05 08:23:03,284 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:23:03,284 INFO:     Epoch: 68
2023-01-05 08:23:05,418 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.5032837261756261, 'Total loss': 0.5032837261756261} | train loss {'Reaction outcome loss': 0.29400300267547697, 'Total loss': 0.29400300267547697}
2023-01-05 08:23:05,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:23:05,419 INFO:     Epoch: 69
2023-01-05 08:23:07,545 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4363818346833189, 'Total loss': 0.4363818346833189} | train loss {'Reaction outcome loss': 0.2900623980071052, 'Total loss': 0.2900623980071052}
2023-01-05 08:23:07,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:23:07,545 INFO:     Epoch: 70
2023-01-05 08:23:09,672 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44265255133310955, 'Total loss': 0.44265255133310955} | train loss {'Reaction outcome loss': 0.2919070875732661, 'Total loss': 0.2919070875732661}
2023-01-05 08:23:09,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:23:09,672 INFO:     Epoch: 71
2023-01-05 08:23:11,783 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.47451360026995343, 'Total loss': 0.47451360026995343} | train loss {'Reaction outcome loss': 0.29697343894036493, 'Total loss': 0.29697343894036493}
2023-01-05 08:23:11,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:23:11,784 INFO:     Epoch: 72
2023-01-05 08:23:13,886 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44910431106885274, 'Total loss': 0.44910431106885274} | train loss {'Reaction outcome loss': 0.2828486963309265, 'Total loss': 0.2828486963309265}
2023-01-05 08:23:13,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:23:13,887 INFO:     Epoch: 73
2023-01-05 08:23:15,995 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4538546323776245, 'Total loss': 0.4538546323776245} | train loss {'Reaction outcome loss': 0.2884586502925056, 'Total loss': 0.2884586502925056}
2023-01-05 08:23:15,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:23:15,995 INFO:     Epoch: 74
2023-01-05 08:23:18,124 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44231326778729757, 'Total loss': 0.44231326778729757} | train loss {'Reaction outcome loss': 0.2823916268689606, 'Total loss': 0.2823916268689606}
2023-01-05 08:23:18,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:23:18,125 INFO:     Epoch: 75
2023-01-05 08:23:20,244 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43224067240953445, 'Total loss': 0.43224067240953445} | train loss {'Reaction outcome loss': 0.2845682840643114, 'Total loss': 0.2845682840643114}
2023-01-05 08:23:20,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:23:20,244 INFO:     Epoch: 76
2023-01-05 08:23:22,368 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4319329261779785, 'Total loss': 0.4319329261779785} | train loss {'Reaction outcome loss': 0.2825399191149706, 'Total loss': 0.2825399191149706}
2023-01-05 08:23:22,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:23:22,368 INFO:     Epoch: 77
2023-01-05 08:23:24,384 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4904982844988505, 'Total loss': 0.4904982844988505} | train loss {'Reaction outcome loss': 0.28127796598796034, 'Total loss': 0.28127796598796034}
2023-01-05 08:23:24,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:23:24,385 INFO:     Epoch: 78
2023-01-05 08:23:26,087 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4485988438129425, 'Total loss': 0.4485988438129425} | train loss {'Reaction outcome loss': 0.2728723867201827, 'Total loss': 0.2728723867201827}
2023-01-05 08:23:26,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:23:26,087 INFO:     Epoch: 79
2023-01-05 08:23:27,782 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44120091795921323, 'Total loss': 0.44120091795921323} | train loss {'Reaction outcome loss': 0.27843558759431997, 'Total loss': 0.27843558759431997}
2023-01-05 08:23:27,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:23:27,782 INFO:     Epoch: 80
2023-01-05 08:23:29,781 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5450841844081878, 'Total loss': 0.5450841844081878} | train loss {'Reaction outcome loss': 0.27782458746015365, 'Total loss': 0.27782458746015365}
2023-01-05 08:23:29,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:23:29,782 INFO:     Epoch: 81
2023-01-05 08:23:31,901 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43693525195121763, 'Total loss': 0.43693525195121763} | train loss {'Reaction outcome loss': 0.27514637214891147, 'Total loss': 0.27514637214891147}
2023-01-05 08:23:31,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:23:31,901 INFO:     Epoch: 82
2023-01-05 08:23:34,006 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3843323806921641, 'Total loss': 0.3843323806921641} | train loss {'Reaction outcome loss': 0.26850123728910713, 'Total loss': 0.26850123728910713}
2023-01-05 08:23:34,006 INFO:     Found new best model at epoch 82
2023-01-05 08:23:34,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:23:34,008 INFO:     Epoch: 83
2023-01-05 08:23:36,137 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4244162172079086, 'Total loss': 0.4244162172079086} | train loss {'Reaction outcome loss': 0.27403895886841734, 'Total loss': 0.27403895886841734}
2023-01-05 08:23:36,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:23:36,137 INFO:     Epoch: 84
2023-01-05 08:23:38,267 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.48056344985961913, 'Total loss': 0.48056344985961913} | train loss {'Reaction outcome loss': 0.2684894404150683, 'Total loss': 0.2684894404150683}
2023-01-05 08:23:38,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:23:38,267 INFO:     Epoch: 85
2023-01-05 08:23:40,385 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5151804616053899, 'Total loss': 0.5151804616053899} | train loss {'Reaction outcome loss': 0.2703511074487793, 'Total loss': 0.2703511074487793}
2023-01-05 08:23:40,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:23:40,385 INFO:     Epoch: 86
2023-01-05 08:23:42,509 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40827038685480754, 'Total loss': 0.40827038685480754} | train loss {'Reaction outcome loss': 0.26510157119963884, 'Total loss': 0.26510157119963884}
2023-01-05 08:23:42,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:23:42,510 INFO:     Epoch: 87
2023-01-05 08:23:44,586 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46203678647677104, 'Total loss': 0.46203678647677104} | train loss {'Reaction outcome loss': 0.2673459806414218, 'Total loss': 0.2673459806414218}
2023-01-05 08:23:44,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:23:44,586 INFO:     Epoch: 88
2023-01-05 08:23:46,708 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.44676304459571836, 'Total loss': 0.44676304459571836} | train loss {'Reaction outcome loss': 0.2635286938660259, 'Total loss': 0.2635286938660259}
2023-01-05 08:23:46,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:23:46,708 INFO:     Epoch: 89
2023-01-05 08:23:48,840 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40750969126820563, 'Total loss': 0.40750969126820563} | train loss {'Reaction outcome loss': 0.2679003399978924, 'Total loss': 0.2679003399978924}
2023-01-05 08:23:48,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:23:48,841 INFO:     Epoch: 90
2023-01-05 08:23:50,976 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4909824470678965, 'Total loss': 0.4909824470678965} | train loss {'Reaction outcome loss': 0.26145286594149814, 'Total loss': 0.26145286594149814}
2023-01-05 08:23:50,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:23:50,977 INFO:     Epoch: 91
2023-01-05 08:23:53,090 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4189224754770597, 'Total loss': 0.4189224754770597} | train loss {'Reaction outcome loss': 0.259429067799416, 'Total loss': 0.259429067799416}
2023-01-05 08:23:53,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:23:53,090 INFO:     Epoch: 92
2023-01-05 08:23:55,214 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4313787485162417, 'Total loss': 0.4313787485162417} | train loss {'Reaction outcome loss': 0.2585488482622423, 'Total loss': 0.2585488482622423}
2023-01-05 08:23:55,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:23:55,215 INFO:     Epoch: 93
2023-01-05 08:23:57,329 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44122443348169327, 'Total loss': 0.44122443348169327} | train loss {'Reaction outcome loss': 0.2708150567246319, 'Total loss': 0.2708150567246319}
2023-01-05 08:23:57,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:23:57,329 INFO:     Epoch: 94
2023-01-05 08:23:59,477 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.426089080174764, 'Total loss': 0.426089080174764} | train loss {'Reaction outcome loss': 0.2519646088877947, 'Total loss': 0.2519646088877947}
2023-01-05 08:23:59,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:23:59,477 INFO:     Epoch: 95
2023-01-05 08:24:01,618 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41282305816809334, 'Total loss': 0.41282305816809334} | train loss {'Reaction outcome loss': 0.25845173137379307, 'Total loss': 0.25845173137379307}
2023-01-05 08:24:01,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:24:01,619 INFO:     Epoch: 96
2023-01-05 08:24:03,698 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.470211453239123, 'Total loss': 0.470211453239123} | train loss {'Reaction outcome loss': 0.25680537421489996, 'Total loss': 0.25680537421489996}
2023-01-05 08:24:03,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:24:03,698 INFO:     Epoch: 97
2023-01-05 08:24:05,832 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42166748891274136, 'Total loss': 0.42166748891274136} | train loss {'Reaction outcome loss': 0.2532868664780446, 'Total loss': 0.2532868664780446}
2023-01-05 08:24:05,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:24:05,832 INFO:     Epoch: 98
2023-01-05 08:24:07,948 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4378847042719523, 'Total loss': 0.4378847042719523} | train loss {'Reaction outcome loss': 0.25652672846653807, 'Total loss': 0.25652672846653807}
2023-01-05 08:24:07,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:24:07,948 INFO:     Epoch: 99
2023-01-05 08:24:10,079 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4359380821386973, 'Total loss': 0.4359380821386973} | train loss {'Reaction outcome loss': 0.25955253267640116, 'Total loss': 0.25955253267640116}
2023-01-05 08:24:10,079 INFO:     Best model found after epoch 83 of 100.
2023-01-05 08:24:10,079 INFO:   Done with stage: TRAINING
2023-01-05 08:24:10,079 INFO:   Starting stage: EVALUATION
2023-01-05 08:24:10,228 INFO:   Done with stage: EVALUATION
2023-01-05 08:24:10,228 INFO:   Leaving out SEQ value Fold_2
2023-01-05 08:24:10,242 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 08:24:10,242 INFO:   Starting stage: FEATURE SCALING
2023-01-05 08:24:10,898 INFO:   Done with stage: FEATURE SCALING
2023-01-05 08:24:10,899 INFO:   Starting stage: SCALING TARGETS
2023-01-05 08:24:10,968 INFO:   Done with stage: SCALING TARGETS
2023-01-05 08:24:10,968 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:24:10,968 INFO:     No hyperparam tuning for this model
2023-01-05 08:24:10,968 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:24:10,968 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 08:24:10,969 INFO:     None feature selector for col prot
2023-01-05 08:24:10,969 INFO:     None feature selector for col prot
2023-01-05 08:24:10,969 INFO:     None feature selector for col prot
2023-01-05 08:24:10,970 INFO:     None feature selector for col chem
2023-01-05 08:24:10,970 INFO:     None feature selector for col chem
2023-01-05 08:24:10,970 INFO:     None feature selector for col chem
2023-01-05 08:24:10,970 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 08:24:10,970 INFO:   Starting stage: BUILD MODEL
2023-01-05 08:24:10,971 INFO:     Number of params in model 72901
2023-01-05 08:24:10,975 INFO:   Done with stage: BUILD MODEL
2023-01-05 08:24:10,975 INFO:   Starting stage: TRAINING
2023-01-05 08:24:11,036 INFO:     Val loss before train {'Reaction outcome loss': 0.9404022216796875, 'Total loss': 0.9404022216796875}
2023-01-05 08:24:11,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:24:11,037 INFO:     Epoch: 0
2023-01-05 08:24:13,195 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7755639572938283, 'Total loss': 0.7755639572938283} | train loss {'Reaction outcome loss': 0.9263198137202341, 'Total loss': 0.9263198137202341}
2023-01-05 08:24:13,195 INFO:     Found new best model at epoch 0
2023-01-05 08:24:13,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:24:13,196 INFO:     Epoch: 1
2023-01-05 08:24:15,352 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.585219011704127, 'Total loss': 0.585219011704127} | train loss {'Reaction outcome loss': 0.7367147301522798, 'Total loss': 0.7367147301522798}
2023-01-05 08:24:15,352 INFO:     Found new best model at epoch 1
2023-01-05 08:24:15,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:24:15,354 INFO:     Epoch: 2
2023-01-05 08:24:17,525 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5061947703361511, 'Total loss': 0.5061947703361511} | train loss {'Reaction outcome loss': 0.5857209144295126, 'Total loss': 0.5857209144295126}
2023-01-05 08:24:17,526 INFO:     Found new best model at epoch 2
2023-01-05 08:24:17,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:24:17,527 INFO:     Epoch: 3
2023-01-05 08:24:19,680 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5012058526277542, 'Total loss': 0.5012058526277542} | train loss {'Reaction outcome loss': 0.5328860748356775, 'Total loss': 0.5328860748356775}
2023-01-05 08:24:19,680 INFO:     Found new best model at epoch 3
2023-01-05 08:24:19,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:24:19,682 INFO:     Epoch: 4
2023-01-05 08:24:21,843 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.45975191791852316, 'Total loss': 0.45975191791852316} | train loss {'Reaction outcome loss': 0.5063217465117897, 'Total loss': 0.5063217465117897}
2023-01-05 08:24:21,843 INFO:     Found new best model at epoch 4
2023-01-05 08:24:21,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:24:21,845 INFO:     Epoch: 5
2023-01-05 08:24:24,001 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.483157883087794, 'Total loss': 0.483157883087794} | train loss {'Reaction outcome loss': 0.49081422692628673, 'Total loss': 0.49081422692628673}
2023-01-05 08:24:24,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:24:24,002 INFO:     Epoch: 6
2023-01-05 08:24:26,159 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4566505481799444, 'Total loss': 0.4566505481799444} | train loss {'Reaction outcome loss': 0.48408952066539856, 'Total loss': 0.48408952066539856}
2023-01-05 08:24:26,160 INFO:     Found new best model at epoch 6
2023-01-05 08:24:26,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:24:26,161 INFO:     Epoch: 7
2023-01-05 08:24:28,323 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4552760571241379, 'Total loss': 0.4552760571241379} | train loss {'Reaction outcome loss': 0.47395640528386296, 'Total loss': 0.47395640528386296}
2023-01-05 08:24:28,323 INFO:     Found new best model at epoch 7
2023-01-05 08:24:28,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:24:28,325 INFO:     Epoch: 8
2023-01-05 08:24:30,487 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4463353455066681, 'Total loss': 0.4463353455066681} | train loss {'Reaction outcome loss': 0.4663310904486381, 'Total loss': 0.4663310904486381}
2023-01-05 08:24:30,488 INFO:     Found new best model at epoch 8
2023-01-05 08:24:30,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:24:30,489 INFO:     Epoch: 9
2023-01-05 08:24:32,650 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.418487540135781, 'Total loss': 0.418487540135781} | train loss {'Reaction outcome loss': 0.461950456696576, 'Total loss': 0.461950456696576}
2023-01-05 08:24:32,651 INFO:     Found new best model at epoch 9
2023-01-05 08:24:32,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:24:32,652 INFO:     Epoch: 10
2023-01-05 08:24:34,825 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46335146625836693, 'Total loss': 0.46335146625836693} | train loss {'Reaction outcome loss': 0.46105285395321477, 'Total loss': 0.46105285395321477}
2023-01-05 08:24:34,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:24:34,825 INFO:     Epoch: 11
2023-01-05 08:24:36,991 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4183816482623418, 'Total loss': 0.4183816482623418} | train loss {'Reaction outcome loss': 0.4533706569160078, 'Total loss': 0.4533706569160078}
2023-01-05 08:24:36,992 INFO:     Found new best model at epoch 11
2023-01-05 08:24:36,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:24:36,993 INFO:     Epoch: 12
2023-01-05 08:24:39,151 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4298815965652466, 'Total loss': 0.4298815965652466} | train loss {'Reaction outcome loss': 0.442661550086653, 'Total loss': 0.442661550086653}
2023-01-05 08:24:39,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:24:39,151 INFO:     Epoch: 13
2023-01-05 08:24:41,294 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4352811614672343, 'Total loss': 0.4352811614672343} | train loss {'Reaction outcome loss': 0.4471695331748629, 'Total loss': 0.4471695331748629}
2023-01-05 08:24:41,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:24:41,294 INFO:     Epoch: 14
2023-01-05 08:24:43,448 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43329542875289917, 'Total loss': 0.43329542875289917} | train loss {'Reaction outcome loss': 0.4372290135052817, 'Total loss': 0.4372290135052817}
2023-01-05 08:24:43,448 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:24:43,448 INFO:     Epoch: 15
2023-01-05 08:24:45,606 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4345436791578929, 'Total loss': 0.4345436791578929} | train loss {'Reaction outcome loss': 0.43574980212092074, 'Total loss': 0.43574980212092074}
2023-01-05 08:24:45,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:24:45,607 INFO:     Epoch: 16
2023-01-05 08:24:47,751 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4262617905934652, 'Total loss': 0.4262617905934652} | train loss {'Reaction outcome loss': 0.42788267478960956, 'Total loss': 0.42788267478960956}
2023-01-05 08:24:47,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:24:47,752 INFO:     Epoch: 17
2023-01-05 08:24:49,901 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41130313475926716, 'Total loss': 0.41130313475926716} | train loss {'Reaction outcome loss': 0.42773816136785014, 'Total loss': 0.42773816136785014}
2023-01-05 08:24:49,901 INFO:     Found new best model at epoch 17
2023-01-05 08:24:49,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:24:49,903 INFO:     Epoch: 18
2023-01-05 08:24:52,040 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4006766681869825, 'Total loss': 0.4006766681869825} | train loss {'Reaction outcome loss': 0.42704471952511347, 'Total loss': 0.42704471952511347}
2023-01-05 08:24:52,040 INFO:     Found new best model at epoch 18
2023-01-05 08:24:52,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:24:52,042 INFO:     Epoch: 19
2023-01-05 08:24:54,174 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45598706205685935, 'Total loss': 0.45598706205685935} | train loss {'Reaction outcome loss': 0.42346509828137746, 'Total loss': 0.42346509828137746}
2023-01-05 08:24:54,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:24:54,176 INFO:     Epoch: 20
2023-01-05 08:24:56,331 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.410411928097407, 'Total loss': 0.410411928097407} | train loss {'Reaction outcome loss': 0.4164099675791753, 'Total loss': 0.4164099675791753}
2023-01-05 08:24:56,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:24:56,331 INFO:     Epoch: 21
2023-01-05 08:24:58,487 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40078600148359933, 'Total loss': 0.40078600148359933} | train loss {'Reaction outcome loss': 0.4102228970142027, 'Total loss': 0.4102228970142027}
2023-01-05 08:24:58,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:24:58,488 INFO:     Epoch: 22
2023-01-05 08:25:00,639 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42030671338240305, 'Total loss': 0.42030671338240305} | train loss {'Reaction outcome loss': 0.4036251393585901, 'Total loss': 0.4036251393585901}
2023-01-05 08:25:00,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:25:00,640 INFO:     Epoch: 23
2023-01-05 08:25:02,788 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4107804477214813, 'Total loss': 0.4107804477214813} | train loss {'Reaction outcome loss': 0.4073766325621535, 'Total loss': 0.4073766325621535}
2023-01-05 08:25:02,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:25:02,788 INFO:     Epoch: 24
2023-01-05 08:25:04,940 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.39426955580711365, 'Total loss': 0.39426955580711365} | train loss {'Reaction outcome loss': 0.4036870676861419, 'Total loss': 0.4036870676861419}
2023-01-05 08:25:04,940 INFO:     Found new best model at epoch 24
2023-01-05 08:25:04,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:25:04,941 INFO:     Epoch: 25
2023-01-05 08:25:07,071 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39139018654823304, 'Total loss': 0.39139018654823304} | train loss {'Reaction outcome loss': 0.39469294190875837, 'Total loss': 0.39469294190875837}
2023-01-05 08:25:07,072 INFO:     Found new best model at epoch 25
2023-01-05 08:25:07,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:25:07,073 INFO:     Epoch: 26
2023-01-05 08:25:09,242 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.39318781197071073, 'Total loss': 0.39318781197071073} | train loss {'Reaction outcome loss': 0.39570603028371715, 'Total loss': 0.39570603028371715}
2023-01-05 08:25:09,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:25:09,242 INFO:     Epoch: 27
2023-01-05 08:25:11,408 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.39145005444685615, 'Total loss': 0.39145005444685615} | train loss {'Reaction outcome loss': 0.39132438466354424, 'Total loss': 0.39132438466354424}
2023-01-05 08:25:11,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:25:11,408 INFO:     Epoch: 28
2023-01-05 08:25:13,566 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.39730026920636496, 'Total loss': 0.39730026920636496} | train loss {'Reaction outcome loss': 0.3864830886013806, 'Total loss': 0.3864830886013806}
2023-01-05 08:25:13,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:25:13,567 INFO:     Epoch: 29
2023-01-05 08:25:15,718 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4017898460229238, 'Total loss': 0.4017898460229238} | train loss {'Reaction outcome loss': 0.3815205044963438, 'Total loss': 0.3815205044963438}
2023-01-05 08:25:15,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:25:15,718 INFO:     Epoch: 30
2023-01-05 08:25:17,873 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.373287507891655, 'Total loss': 0.373287507891655} | train loss {'Reaction outcome loss': 0.37482960457387177, 'Total loss': 0.37482960457387177}
2023-01-05 08:25:17,873 INFO:     Found new best model at epoch 30
2023-01-05 08:25:17,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:25:17,874 INFO:     Epoch: 31
2023-01-05 08:25:20,030 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.36784917016824087, 'Total loss': 0.36784917016824087} | train loss {'Reaction outcome loss': 0.3868163587336523, 'Total loss': 0.3868163587336523}
2023-01-05 08:25:20,030 INFO:     Found new best model at epoch 31
2023-01-05 08:25:20,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:25:20,031 INFO:     Epoch: 32
2023-01-05 08:25:22,202 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3782131105661392, 'Total loss': 0.3782131105661392} | train loss {'Reaction outcome loss': 0.38677602755985613, 'Total loss': 0.38677602755985613}
2023-01-05 08:25:22,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:25:22,203 INFO:     Epoch: 33
2023-01-05 08:25:24,354 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.37482067147890724, 'Total loss': 0.37482067147890724} | train loss {'Reaction outcome loss': 0.37052941761330527, 'Total loss': 0.37052941761330527}
2023-01-05 08:25:24,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:25:24,355 INFO:     Epoch: 34
2023-01-05 08:25:26,328 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.37369923492272694, 'Total loss': 0.37369923492272694} | train loss {'Reaction outcome loss': 0.36112073551107576, 'Total loss': 0.36112073551107576}
2023-01-05 08:25:26,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:25:26,328 INFO:     Epoch: 35
2023-01-05 08:25:28,489 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.38943515022595726, 'Total loss': 0.38943515022595726} | train loss {'Reaction outcome loss': 0.35410279806608846, 'Total loss': 0.35410279806608846}
2023-01-05 08:25:28,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:25:28,489 INFO:     Epoch: 36
2023-01-05 08:25:30,265 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38076770504315693, 'Total loss': 0.38076770504315693} | train loss {'Reaction outcome loss': 0.35928482877384144, 'Total loss': 0.35928482877384144}
2023-01-05 08:25:30,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:25:30,265 INFO:     Epoch: 37
2023-01-05 08:25:32,018 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3711793581644694, 'Total loss': 0.3711793581644694} | train loss {'Reaction outcome loss': 0.3588735601608304, 'Total loss': 0.3588735601608304}
2023-01-05 08:25:32,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:25:32,019 INFO:     Epoch: 38
2023-01-05 08:25:34,003 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.380850716928641, 'Total loss': 0.380850716928641} | train loss {'Reaction outcome loss': 0.345553214756259, 'Total loss': 0.345553214756259}
2023-01-05 08:25:34,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:25:34,003 INFO:     Epoch: 39
2023-01-05 08:25:36,147 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3669769714275996, 'Total loss': 0.3669769714275996} | train loss {'Reaction outcome loss': 0.343233999836704, 'Total loss': 0.343233999836704}
2023-01-05 08:25:36,147 INFO:     Found new best model at epoch 39
2023-01-05 08:25:36,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:25:36,149 INFO:     Epoch: 40
2023-01-05 08:25:38,310 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4129350384076436, 'Total loss': 0.4129350384076436} | train loss {'Reaction outcome loss': 0.3702719271371978, 'Total loss': 0.3702719271371978}
2023-01-05 08:25:38,311 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:25:38,311 INFO:     Epoch: 41
2023-01-05 08:25:40,487 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39618650178114573, 'Total loss': 0.39618650178114573} | train loss {'Reaction outcome loss': 0.35915634468497243, 'Total loss': 0.35915634468497243}
2023-01-05 08:25:40,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:25:40,488 INFO:     Epoch: 42
2023-01-05 08:25:42,649 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3947696367899577, 'Total loss': 0.3947696367899577} | train loss {'Reaction outcome loss': 0.33893375387654395, 'Total loss': 0.33893375387654395}
2023-01-05 08:25:42,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:25:42,649 INFO:     Epoch: 43
2023-01-05 08:25:44,806 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.35706073939800265, 'Total loss': 0.35706073939800265} | train loss {'Reaction outcome loss': 0.33214506129413657, 'Total loss': 0.33214506129413657}
2023-01-05 08:25:44,807 INFO:     Found new best model at epoch 43
2023-01-05 08:25:44,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:25:44,808 INFO:     Epoch: 44
2023-01-05 08:25:46,976 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.38978423476219176, 'Total loss': 0.38978423476219176} | train loss {'Reaction outcome loss': 0.32882490627251676, 'Total loss': 0.32882490627251676}
2023-01-05 08:25:46,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:25:46,977 INFO:     Epoch: 45
2023-01-05 08:25:49,122 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.39624212980270385, 'Total loss': 0.39624212980270385} | train loss {'Reaction outcome loss': 0.3421653044844024, 'Total loss': 0.3421653044844024}
2023-01-05 08:25:49,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:25:49,122 INFO:     Epoch: 46
2023-01-05 08:25:51,289 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.35865325431029, 'Total loss': 0.35865325431029} | train loss {'Reaction outcome loss': 0.3256455169817934, 'Total loss': 0.3256455169817934}
2023-01-05 08:25:51,289 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:25:51,289 INFO:     Epoch: 47
2023-01-05 08:25:53,454 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3808110823233922, 'Total loss': 0.3808110823233922} | train loss {'Reaction outcome loss': 0.32022656875568023, 'Total loss': 0.32022656875568023}
2023-01-05 08:25:53,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:25:53,454 INFO:     Epoch: 48
2023-01-05 08:25:55,605 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42571206092834474, 'Total loss': 0.42571206092834474} | train loss {'Reaction outcome loss': 0.34216903630590095, 'Total loss': 0.34216903630590095}
2023-01-05 08:25:55,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:25:55,607 INFO:     Epoch: 49
2023-01-05 08:25:57,748 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3722793261210124, 'Total loss': 0.3722793261210124} | train loss {'Reaction outcome loss': 0.35612524122647615, 'Total loss': 0.35612524122647615}
2023-01-05 08:25:57,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:25:57,749 INFO:     Epoch: 50
2023-01-05 08:25:59,886 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3676493311921755, 'Total loss': 0.3676493311921755} | train loss {'Reaction outcome loss': 0.33271707246161025, 'Total loss': 0.33271707246161025}
2023-01-05 08:25:59,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:25:59,886 INFO:     Epoch: 51
2023-01-05 08:26:02,040 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.37196422517299654, 'Total loss': 0.37196422517299654} | train loss {'Reaction outcome loss': 0.35828344509818766, 'Total loss': 0.35828344509818766}
2023-01-05 08:26:02,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:26:02,041 INFO:     Epoch: 52
2023-01-05 08:26:04,190 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.35248436679442724, 'Total loss': 0.35248436679442724} | train loss {'Reaction outcome loss': 0.3216131149210792, 'Total loss': 0.3216131149210792}
2023-01-05 08:26:04,190 INFO:     Found new best model at epoch 52
2023-01-05 08:26:04,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:26:04,191 INFO:     Epoch: 53
2023-01-05 08:26:06,338 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3706418454647064, 'Total loss': 0.3706418454647064} | train loss {'Reaction outcome loss': 0.31557008383949153, 'Total loss': 0.31557008383949153}
2023-01-05 08:26:06,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:26:06,338 INFO:     Epoch: 54
2023-01-05 08:26:08,477 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4020841995875041, 'Total loss': 0.4020841995875041} | train loss {'Reaction outcome loss': 0.31400142542501586, 'Total loss': 0.31400142542501586}
2023-01-05 08:26:08,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:26:08,477 INFO:     Epoch: 55
2023-01-05 08:26:10,629 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.35642462770144145, 'Total loss': 0.35642462770144145} | train loss {'Reaction outcome loss': 0.31068435186339693, 'Total loss': 0.31068435186339693}
2023-01-05 08:26:10,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:26:10,629 INFO:     Epoch: 56
2023-01-05 08:26:12,800 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3586606542269389, 'Total loss': 0.3586606542269389} | train loss {'Reaction outcome loss': 0.3045617888016842, 'Total loss': 0.3045617888016842}
2023-01-05 08:26:12,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:26:12,801 INFO:     Epoch: 57
2023-01-05 08:26:14,969 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40091603100299833, 'Total loss': 0.40091603100299833} | train loss {'Reaction outcome loss': 0.30900301503127764, 'Total loss': 0.30900301503127764}
2023-01-05 08:26:14,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:26:14,970 INFO:     Epoch: 58
2023-01-05 08:26:17,139 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38729847222566605, 'Total loss': 0.38729847222566605} | train loss {'Reaction outcome loss': 0.3033223858076161, 'Total loss': 0.3033223858076161}
2023-01-05 08:26:17,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:26:17,140 INFO:     Epoch: 59
2023-01-05 08:26:19,301 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.33655323336521786, 'Total loss': 0.33655323336521786} | train loss {'Reaction outcome loss': 0.2945751478229953, 'Total loss': 0.2945751478229953}
2023-01-05 08:26:19,301 INFO:     Found new best model at epoch 59
2023-01-05 08:26:19,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:26:19,303 INFO:     Epoch: 60
2023-01-05 08:26:21,472 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.38007980287075044, 'Total loss': 0.38007980287075044} | train loss {'Reaction outcome loss': 0.2923431848007106, 'Total loss': 0.2923431848007106}
2023-01-05 08:26:21,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:26:21,472 INFO:     Epoch: 61
2023-01-05 08:26:23,631 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.37289208521445594, 'Total loss': 0.37289208521445594} | train loss {'Reaction outcome loss': 0.28966218005676847, 'Total loss': 0.28966218005676847}
2023-01-05 08:26:23,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:26:23,631 INFO:     Epoch: 62
2023-01-05 08:26:25,801 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40994974176088966, 'Total loss': 0.40994974176088966} | train loss {'Reaction outcome loss': 0.2943806731381683, 'Total loss': 0.2943806731381683}
2023-01-05 08:26:25,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:26:25,802 INFO:     Epoch: 63
2023-01-05 08:26:27,970 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.38111793945233025, 'Total loss': 0.38111793945233025} | train loss {'Reaction outcome loss': 0.2875136263884496, 'Total loss': 0.2875136263884496}
2023-01-05 08:26:27,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:26:27,970 INFO:     Epoch: 64
2023-01-05 08:26:30,137 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4223524610201518, 'Total loss': 0.4223524610201518} | train loss {'Reaction outcome loss': 0.28873918486921035, 'Total loss': 0.28873918486921035}
2023-01-05 08:26:30,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:26:30,138 INFO:     Epoch: 65
2023-01-05 08:26:32,285 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.37142394185066224, 'Total loss': 0.37142394185066224} | train loss {'Reaction outcome loss': 0.2828347426651474, 'Total loss': 0.2828347426651474}
2023-01-05 08:26:32,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:26:32,286 INFO:     Epoch: 66
2023-01-05 08:26:34,418 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.39423502087593076, 'Total loss': 0.39423502087593076} | train loss {'Reaction outcome loss': 0.2850009179201679, 'Total loss': 0.2850009179201679}
2023-01-05 08:26:34,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:26:34,418 INFO:     Epoch: 67
2023-01-05 08:26:36,558 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4086909015973409, 'Total loss': 0.4086909015973409} | train loss {'Reaction outcome loss': 0.28828387697011343, 'Total loss': 0.28828387697011343}
2023-01-05 08:26:36,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:26:36,558 INFO:     Epoch: 68
2023-01-05 08:26:38,707 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39239273269971214, 'Total loss': 0.39239273269971214} | train loss {'Reaction outcome loss': 0.28372985481932433, 'Total loss': 0.28372985481932433}
2023-01-05 08:26:38,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:26:38,707 INFO:     Epoch: 69
2023-01-05 08:26:40,866 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3676390255490939, 'Total loss': 0.3676390255490939} | train loss {'Reaction outcome loss': 0.2769237174180107, 'Total loss': 0.2769237174180107}
2023-01-05 08:26:40,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:26:40,866 INFO:     Epoch: 70
2023-01-05 08:26:43,009 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3832721789677938, 'Total loss': 0.3832721789677938} | train loss {'Reaction outcome loss': 0.2797414915690172, 'Total loss': 0.2797414915690172}
2023-01-05 08:26:43,010 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:26:43,010 INFO:     Epoch: 71
2023-01-05 08:26:45,171 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3774860004583995, 'Total loss': 0.3774860004583995} | train loss {'Reaction outcome loss': 0.27924104808303324, 'Total loss': 0.27924104808303324}
2023-01-05 08:26:45,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:26:45,172 INFO:     Epoch: 72
2023-01-05 08:26:47,319 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3897788554430008, 'Total loss': 0.3897788554430008} | train loss {'Reaction outcome loss': 0.27579190736245096, 'Total loss': 0.27579190736245096}
2023-01-05 08:26:47,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:26:47,319 INFO:     Epoch: 73
2023-01-05 08:26:49,457 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40988115072250364, 'Total loss': 0.40988115072250364} | train loss {'Reaction outcome loss': 0.27069590949416295, 'Total loss': 0.27069590949416295}
2023-01-05 08:26:49,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:26:49,457 INFO:     Epoch: 74
2023-01-05 08:26:51,611 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3961478531360626, 'Total loss': 0.3961478531360626} | train loss {'Reaction outcome loss': 0.27156360251525336, 'Total loss': 0.27156360251525336}
2023-01-05 08:26:51,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:26:51,612 INFO:     Epoch: 75
2023-01-05 08:26:53,771 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3860274970531464, 'Total loss': 0.3860274970531464} | train loss {'Reaction outcome loss': 0.27107080082962476, 'Total loss': 0.27107080082962476}
2023-01-05 08:26:53,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:26:53,771 INFO:     Epoch: 76
2023-01-05 08:26:55,914 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41499632646640144, 'Total loss': 0.41499632646640144} | train loss {'Reaction outcome loss': 0.26877436201270344, 'Total loss': 0.26877436201270344}
2023-01-05 08:26:55,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:26:55,915 INFO:     Epoch: 77
2023-01-05 08:26:58,043 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4344521790742874, 'Total loss': 0.4344521790742874} | train loss {'Reaction outcome loss': 0.27146424863916024, 'Total loss': 0.27146424863916024}
2023-01-05 08:26:58,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:26:58,043 INFO:     Epoch: 78
2023-01-05 08:27:00,229 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3902528117100398, 'Total loss': 0.3902528117100398} | train loss {'Reaction outcome loss': 0.26169751439706684, 'Total loss': 0.26169751439706684}
2023-01-05 08:27:00,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:27:00,229 INFO:     Epoch: 79
2023-01-05 08:27:02,388 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4321165333191554, 'Total loss': 0.4321165333191554} | train loss {'Reaction outcome loss': 0.26649913855046337, 'Total loss': 0.26649913855046337}
2023-01-05 08:27:02,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:27:02,389 INFO:     Epoch: 80
2023-01-05 08:27:04,537 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40166023969650266, 'Total loss': 0.40166023969650266} | train loss {'Reaction outcome loss': 0.2618476749550504, 'Total loss': 0.2618476749550504}
2023-01-05 08:27:04,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:27:04,537 INFO:     Epoch: 81
2023-01-05 08:27:06,679 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40041774113972983, 'Total loss': 0.40041774113972983} | train loss {'Reaction outcome loss': 0.2659535917756738, 'Total loss': 0.2659535917756738}
2023-01-05 08:27:06,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:27:06,679 INFO:     Epoch: 82
2023-01-05 08:27:08,848 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.36704620023568474, 'Total loss': 0.36704620023568474} | train loss {'Reaction outcome loss': 0.2639225747493649, 'Total loss': 0.2639225747493649}
2023-01-05 08:27:08,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:27:08,848 INFO:     Epoch: 83
2023-01-05 08:27:11,008 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43321299652258555, 'Total loss': 0.43321299652258555} | train loss {'Reaction outcome loss': 0.2528285759406677, 'Total loss': 0.2528285759406677}
2023-01-05 08:27:11,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:27:11,009 INFO:     Epoch: 84
2023-01-05 08:27:13,183 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3938535153865814, 'Total loss': 0.3938535153865814} | train loss {'Reaction outcome loss': 0.29400384893127973, 'Total loss': 0.29400384893127973}
2023-01-05 08:27:13,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:27:13,183 INFO:     Epoch: 85
2023-01-05 08:27:15,357 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42043145298957824, 'Total loss': 0.42043145298957824} | train loss {'Reaction outcome loss': 0.25799687867444276, 'Total loss': 0.25799687867444276}
2023-01-05 08:27:15,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:27:15,358 INFO:     Epoch: 86
2023-01-05 08:27:17,498 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3930331329504649, 'Total loss': 0.3930331329504649} | train loss {'Reaction outcome loss': 0.2625376224109525, 'Total loss': 0.2625376224109525}
2023-01-05 08:27:17,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:27:17,498 INFO:     Epoch: 87
2023-01-05 08:27:19,640 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4040807217359543, 'Total loss': 0.4040807217359543} | train loss {'Reaction outcome loss': 0.25659657812987763, 'Total loss': 0.25659657812987763}
2023-01-05 08:27:19,640 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:27:19,640 INFO:     Epoch: 88
2023-01-05 08:27:21,769 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4563420573870341, 'Total loss': 0.4563420573870341} | train loss {'Reaction outcome loss': 0.26257863856744074, 'Total loss': 0.26257863856744074}
2023-01-05 08:27:21,769 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:27:21,769 INFO:     Epoch: 89
2023-01-05 08:27:23,932 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39341467022895815, 'Total loss': 0.39341467022895815} | train loss {'Reaction outcome loss': 0.3027299363331648, 'Total loss': 0.3027299363331648}
2023-01-05 08:27:23,932 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:27:23,932 INFO:     Epoch: 90
2023-01-05 08:27:26,101 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.37304488321145374, 'Total loss': 0.37304488321145374} | train loss {'Reaction outcome loss': 0.27237305790323013, 'Total loss': 0.27237305790323013}
2023-01-05 08:27:26,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:27:26,101 INFO:     Epoch: 91
2023-01-05 08:27:28,261 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3974665840466817, 'Total loss': 0.3974665840466817} | train loss {'Reaction outcome loss': 0.27466897859467543, 'Total loss': 0.27466897859467543}
2023-01-05 08:27:28,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:27:28,261 INFO:     Epoch: 92
2023-01-05 08:27:30,408 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40723402202129366, 'Total loss': 0.40723402202129366} | train loss {'Reaction outcome loss': 0.2820368881594086, 'Total loss': 0.2820368881594086}
2023-01-05 08:27:30,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:27:30,408 INFO:     Epoch: 93
2023-01-05 08:27:32,560 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.39426821072896323, 'Total loss': 0.39426821072896323} | train loss {'Reaction outcome loss': 0.26749641755325854, 'Total loss': 0.26749641755325854}
2023-01-05 08:27:32,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:27:32,562 INFO:     Epoch: 94
2023-01-05 08:27:34,702 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4029022107521693, 'Total loss': 0.4029022107521693} | train loss {'Reaction outcome loss': 0.27415709702114144, 'Total loss': 0.27415709702114144}
2023-01-05 08:27:34,702 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:27:34,702 INFO:     Epoch: 95
2023-01-05 08:27:36,875 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3786276598771413, 'Total loss': 0.3786276598771413} | train loss {'Reaction outcome loss': 0.273067763271367, 'Total loss': 0.273067763271367}
2023-01-05 08:27:36,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:27:36,875 INFO:     Epoch: 96
2023-01-05 08:27:39,050 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3808749198913574, 'Total loss': 0.3808749198913574} | train loss {'Reaction outcome loss': 0.25893743581179046, 'Total loss': 0.25893743581179046}
2023-01-05 08:27:39,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:27:39,051 INFO:     Epoch: 97
2023-01-05 08:27:41,191 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.44373345573743184, 'Total loss': 0.44373345573743184} | train loss {'Reaction outcome loss': 0.25242637444719457, 'Total loss': 0.25242637444719457}
2023-01-05 08:27:41,191 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:27:41,191 INFO:     Epoch: 98
2023-01-05 08:27:43,354 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39599725206693015, 'Total loss': 0.39599725206693015} | train loss {'Reaction outcome loss': 0.2516475298620787, 'Total loss': 0.2516475298620787}
2023-01-05 08:27:43,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:27:43,354 INFO:     Epoch: 99
2023-01-05 08:27:45,505 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.37865077356497445, 'Total loss': 0.37865077356497445} | train loss {'Reaction outcome loss': 0.25316900658704666, 'Total loss': 0.25316900658704666}
2023-01-05 08:27:45,505 INFO:     Best model found after epoch 60 of 100.
2023-01-05 08:27:45,505 INFO:   Done with stage: TRAINING
2023-01-05 08:27:45,505 INFO:   Starting stage: EVALUATION
2023-01-05 08:27:45,638 INFO:   Done with stage: EVALUATION
2023-01-05 08:27:45,638 INFO:   Leaving out SEQ value Fold_3
2023-01-05 08:27:45,651 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 08:27:45,651 INFO:   Starting stage: FEATURE SCALING
2023-01-05 08:27:46,306 INFO:   Done with stage: FEATURE SCALING
2023-01-05 08:27:46,307 INFO:   Starting stage: SCALING TARGETS
2023-01-05 08:27:46,375 INFO:   Done with stage: SCALING TARGETS
2023-01-05 08:27:46,376 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:27:46,376 INFO:     No hyperparam tuning for this model
2023-01-05 08:27:46,376 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:27:46,376 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 08:27:46,376 INFO:     None feature selector for col prot
2023-01-05 08:27:46,377 INFO:     None feature selector for col prot
2023-01-05 08:27:46,377 INFO:     None feature selector for col prot
2023-01-05 08:27:46,377 INFO:     None feature selector for col chem
2023-01-05 08:27:46,377 INFO:     None feature selector for col chem
2023-01-05 08:27:46,377 INFO:     None feature selector for col chem
2023-01-05 08:27:46,377 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 08:27:46,377 INFO:   Starting stage: BUILD MODEL
2023-01-05 08:27:46,379 INFO:     Number of params in model 72901
2023-01-05 08:27:46,382 INFO:   Done with stage: BUILD MODEL
2023-01-05 08:27:46,382 INFO:   Starting stage: TRAINING
2023-01-05 08:27:46,441 INFO:     Val loss before train {'Reaction outcome loss': 1.0615280906359355, 'Total loss': 1.0615280906359355}
2023-01-05 08:27:46,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:27:46,442 INFO:     Epoch: 0
2023-01-05 08:27:48,612 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.9046030839284261, 'Total loss': 0.9046030839284261} | train loss {'Reaction outcome loss': 0.9169887662370563, 'Total loss': 0.9169887662370563}
2023-01-05 08:27:48,612 INFO:     Found new best model at epoch 0
2023-01-05 08:27:48,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:27:48,613 INFO:     Epoch: 1
2023-01-05 08:27:50,745 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.7108677248160045, 'Total loss': 0.7108677248160045} | train loss {'Reaction outcome loss': 0.7468549682325496, 'Total loss': 0.7468549682325496}
2023-01-05 08:27:50,745 INFO:     Found new best model at epoch 1
2023-01-05 08:27:50,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:27:50,746 INFO:     Epoch: 2
2023-01-05 08:27:52,875 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5682390987873077, 'Total loss': 0.5682390987873077} | train loss {'Reaction outcome loss': 0.5923814275762537, 'Total loss': 0.5923814275762537}
2023-01-05 08:27:52,876 INFO:     Found new best model at epoch 2
2023-01-05 08:27:52,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:27:52,877 INFO:     Epoch: 3
2023-01-05 08:27:55,023 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5510061999162038, 'Total loss': 0.5510061999162038} | train loss {'Reaction outcome loss': 0.5373964655202824, 'Total loss': 0.5373964655202824}
2023-01-05 08:27:55,023 INFO:     Found new best model at epoch 3
2023-01-05 08:27:55,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:27:55,025 INFO:     Epoch: 4
2023-01-05 08:27:57,145 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5064382205406824, 'Total loss': 0.5064382205406824} | train loss {'Reaction outcome loss': 0.5127604274631856, 'Total loss': 0.5127604274631856}
2023-01-05 08:27:57,145 INFO:     Found new best model at epoch 4
2023-01-05 08:27:57,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:27:57,147 INFO:     Epoch: 5
2023-01-05 08:27:59,292 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5434826890627543, 'Total loss': 0.5434826890627543} | train loss {'Reaction outcome loss': 0.4996788181883075, 'Total loss': 0.4996788181883075}
2023-01-05 08:27:59,292 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:27:59,292 INFO:     Epoch: 6
2023-01-05 08:28:01,431 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5203023701906204, 'Total loss': 0.5203023701906204} | train loss {'Reaction outcome loss': 0.4867387495034344, 'Total loss': 0.4867387495034344}
2023-01-05 08:28:01,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:28:01,431 INFO:     Epoch: 7
2023-01-05 08:28:03,571 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5192223807175954, 'Total loss': 0.5192223807175954} | train loss {'Reaction outcome loss': 0.48152563270631726, 'Total loss': 0.48152563270631726}
2023-01-05 08:28:03,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:28:03,573 INFO:     Epoch: 8
2023-01-05 08:28:05,707 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48213323950767517, 'Total loss': 0.48213323950767517} | train loss {'Reaction outcome loss': 0.4761933784781795, 'Total loss': 0.4761933784781795}
2023-01-05 08:28:05,707 INFO:     Found new best model at epoch 8
2023-01-05 08:28:05,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:28:05,708 INFO:     Epoch: 9
2023-01-05 08:28:07,856 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47659050424893695, 'Total loss': 0.47659050424893695} | train loss {'Reaction outcome loss': 0.46786145538419155, 'Total loss': 0.46786145538419155}
2023-01-05 08:28:07,857 INFO:     Found new best model at epoch 9
2023-01-05 08:28:07,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:28:07,858 INFO:     Epoch: 10
2023-01-05 08:28:10,000 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.49995120664437614, 'Total loss': 0.49995120664437614} | train loss {'Reaction outcome loss': 0.45887754122034097, 'Total loss': 0.45887754122034097}
2023-01-05 08:28:10,001 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:28:10,001 INFO:     Epoch: 11
2023-01-05 08:28:12,147 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.47434076269467673, 'Total loss': 0.47434076269467673} | train loss {'Reaction outcome loss': 0.4584951651565758, 'Total loss': 0.4584951651565758}
2023-01-05 08:28:12,147 INFO:     Found new best model at epoch 11
2023-01-05 08:28:12,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:28:12,148 INFO:     Epoch: 12
2023-01-05 08:28:14,289 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4848999996980031, 'Total loss': 0.4848999996980031} | train loss {'Reaction outcome loss': 0.45026386422770365, 'Total loss': 0.45026386422770365}
2023-01-05 08:28:14,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:28:14,290 INFO:     Epoch: 13
2023-01-05 08:28:16,415 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5054641306400299, 'Total loss': 0.5054641306400299} | train loss {'Reaction outcome loss': 0.44450245063492666, 'Total loss': 0.44450245063492666}
2023-01-05 08:28:16,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:28:16,415 INFO:     Epoch: 14
2023-01-05 08:28:18,566 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4650652498006821, 'Total loss': 0.4650652498006821} | train loss {'Reaction outcome loss': 0.43511928669808114, 'Total loss': 0.43511928669808114}
2023-01-05 08:28:18,566 INFO:     Found new best model at epoch 14
2023-01-05 08:28:18,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:28:18,567 INFO:     Epoch: 15
2023-01-05 08:28:20,707 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4759071469306946, 'Total loss': 0.4759071469306946} | train loss {'Reaction outcome loss': 0.43563211275326025, 'Total loss': 0.43563211275326025}
2023-01-05 08:28:20,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:28:20,708 INFO:     Epoch: 16
2023-01-05 08:28:22,838 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44960416158040367, 'Total loss': 0.44960416158040367} | train loss {'Reaction outcome loss': 0.43292383074542107, 'Total loss': 0.43292383074542107}
2023-01-05 08:28:22,839 INFO:     Found new best model at epoch 16
2023-01-05 08:28:22,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:28:22,840 INFO:     Epoch: 17
2023-01-05 08:28:24,976 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46059546768665316, 'Total loss': 0.46059546768665316} | train loss {'Reaction outcome loss': 0.41925950463001543, 'Total loss': 0.41925950463001543}
2023-01-05 08:28:24,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:28:24,976 INFO:     Epoch: 18
2023-01-05 08:28:27,109 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4525926361481349, 'Total loss': 0.4525926361481349} | train loss {'Reaction outcome loss': 0.4216808469304235, 'Total loss': 0.4216808469304235}
2023-01-05 08:28:27,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:28:27,109 INFO:     Epoch: 19
2023-01-05 08:28:29,252 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.46055700480937956, 'Total loss': 0.46055700480937956} | train loss {'Reaction outcome loss': 0.4169800125417255, 'Total loss': 0.4169800125417255}
2023-01-05 08:28:29,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:28:29,253 INFO:     Epoch: 20
2023-01-05 08:28:31,398 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4826694577932358, 'Total loss': 0.4826694577932358} | train loss {'Reaction outcome loss': 0.41373033545938603, 'Total loss': 0.41373033545938603}
2023-01-05 08:28:31,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:28:31,398 INFO:     Epoch: 21
2023-01-05 08:28:33,533 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.521051158507665, 'Total loss': 0.521051158507665} | train loss {'Reaction outcome loss': 0.41026803475187157, 'Total loss': 0.41026803475187157}
2023-01-05 08:28:33,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:28:33,534 INFO:     Epoch: 22
2023-01-05 08:28:35,680 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4383800466855367, 'Total loss': 0.4383800466855367} | train loss {'Reaction outcome loss': 0.4024815080967142, 'Total loss': 0.4024815080967142}
2023-01-05 08:28:35,680 INFO:     Found new best model at epoch 22
2023-01-05 08:28:35,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:28:35,681 INFO:     Epoch: 23
2023-01-05 08:28:37,823 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4552203198273977, 'Total loss': 0.4552203198273977} | train loss {'Reaction outcome loss': 0.40258402830405987, 'Total loss': 0.40258402830405987}
2023-01-05 08:28:37,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:28:37,823 INFO:     Epoch: 24
2023-01-05 08:28:39,948 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4633162677288055, 'Total loss': 0.4633162677288055} | train loss {'Reaction outcome loss': 0.39477464709526455, 'Total loss': 0.39477464709526455}
2023-01-05 08:28:39,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:28:39,949 INFO:     Epoch: 25
2023-01-05 08:28:42,097 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4486383616924286, 'Total loss': 0.4486383616924286} | train loss {'Reaction outcome loss': 0.39539044298531806, 'Total loss': 0.39539044298531806}
2023-01-05 08:28:42,098 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:28:42,098 INFO:     Epoch: 26
2023-01-05 08:28:44,220 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4405774096647898, 'Total loss': 0.4405774096647898} | train loss {'Reaction outcome loss': 0.3904781965709431, 'Total loss': 0.3904781965709431}
2023-01-05 08:28:44,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:28:44,221 INFO:     Epoch: 27
2023-01-05 08:28:46,356 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4506386359532674, 'Total loss': 0.4506386359532674} | train loss {'Reaction outcome loss': 0.3921526253987581, 'Total loss': 0.3921526253987581}
2023-01-05 08:28:46,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:28:46,356 INFO:     Epoch: 28
2023-01-05 08:28:48,556 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4689735949039459, 'Total loss': 0.4689735949039459} | train loss {'Reaction outcome loss': 0.38328442695267473, 'Total loss': 0.38328442695267473}
2023-01-05 08:28:48,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:28:48,557 INFO:     Epoch: 29
2023-01-05 08:28:50,678 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4349279053509235, 'Total loss': 0.4349279053509235} | train loss {'Reaction outcome loss': 0.377537607348391, 'Total loss': 0.377537607348391}
2023-01-05 08:28:50,678 INFO:     Found new best model at epoch 29
2023-01-05 08:28:50,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:28:50,680 INFO:     Epoch: 30
2023-01-05 08:28:52,830 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42336442073186237, 'Total loss': 0.42336442073186237} | train loss {'Reaction outcome loss': 0.374002133451757, 'Total loss': 0.374002133451757}
2023-01-05 08:28:52,831 INFO:     Found new best model at epoch 30
2023-01-05 08:28:52,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:28:52,832 INFO:     Epoch: 31
2023-01-05 08:28:54,967 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4342520882685979, 'Total loss': 0.4342520882685979} | train loss {'Reaction outcome loss': 0.3754209336098079, 'Total loss': 0.3754209336098079}
2023-01-05 08:28:54,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:28:54,968 INFO:     Epoch: 32
2023-01-05 08:28:57,098 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4441208014885584, 'Total loss': 0.4441208014885584} | train loss {'Reaction outcome loss': 0.3710920237304963, 'Total loss': 0.3710920237304963}
2023-01-05 08:28:57,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:28:57,099 INFO:     Epoch: 33
2023-01-05 08:28:59,262 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44982937971750897, 'Total loss': 0.44982937971750897} | train loss {'Reaction outcome loss': 0.37137523279849427, 'Total loss': 0.37137523279849427}
2023-01-05 08:28:59,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:28:59,262 INFO:     Epoch: 34
2023-01-05 08:29:01,409 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4097551902135213, 'Total loss': 0.4097551902135213} | train loss {'Reaction outcome loss': 0.36547201503436644, 'Total loss': 0.36547201503436644}
2023-01-05 08:29:01,409 INFO:     Found new best model at epoch 34
2023-01-05 08:29:01,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:29:01,410 INFO:     Epoch: 35
2023-01-05 08:29:03,528 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4588315377632777, 'Total loss': 0.4588315377632777} | train loss {'Reaction outcome loss': 0.36381171553672015, 'Total loss': 0.36381171553672015}
2023-01-05 08:29:03,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:29:03,529 INFO:     Epoch: 36
2023-01-05 08:29:05,673 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45635815858840945, 'Total loss': 0.45635815858840945} | train loss {'Reaction outcome loss': 0.35479829359403897, 'Total loss': 0.35479829359403897}
2023-01-05 08:29:05,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:29:05,674 INFO:     Epoch: 37
2023-01-05 08:29:07,799 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4263416121403376, 'Total loss': 0.4263416121403376} | train loss {'Reaction outcome loss': 0.35222240980891956, 'Total loss': 0.35222240980891956}
2023-01-05 08:29:07,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:29:07,799 INFO:     Epoch: 38
2023-01-05 08:29:09,945 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.45636479258537294, 'Total loss': 0.45636479258537294} | train loss {'Reaction outcome loss': 0.35368211910933695, 'Total loss': 0.35368211910933695}
2023-01-05 08:29:09,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:29:09,946 INFO:     Epoch: 39
2023-01-05 08:29:12,049 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45382181107997893, 'Total loss': 0.45382181107997893} | train loss {'Reaction outcome loss': 0.3442824814646017, 'Total loss': 0.3442824814646017}
2023-01-05 08:29:12,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:29:12,049 INFO:     Epoch: 40
2023-01-05 08:29:14,189 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4298454999923706, 'Total loss': 0.4298454999923706} | train loss {'Reaction outcome loss': 0.34399013019306757, 'Total loss': 0.34399013019306757}
2023-01-05 08:29:14,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:29:14,189 INFO:     Epoch: 41
2023-01-05 08:29:16,334 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4125940303007762, 'Total loss': 0.4125940303007762} | train loss {'Reaction outcome loss': 0.3370242860482071, 'Total loss': 0.3370242860482071}
2023-01-05 08:29:16,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:29:16,335 INFO:     Epoch: 42
2023-01-05 08:29:18,474 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41242528359095254, 'Total loss': 0.41242528359095254} | train loss {'Reaction outcome loss': 0.33495952195791534, 'Total loss': 0.33495952195791534}
2023-01-05 08:29:18,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:29:18,474 INFO:     Epoch: 43
2023-01-05 08:29:20,609 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4174967845280965, 'Total loss': 0.4174967845280965} | train loss {'Reaction outcome loss': 0.33367176781043467, 'Total loss': 0.33367176781043467}
2023-01-05 08:29:20,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:29:20,610 INFO:     Epoch: 44
2023-01-05 08:29:22,756 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42486374949415523, 'Total loss': 0.42486374949415523} | train loss {'Reaction outcome loss': 0.33334129485182273, 'Total loss': 0.33334129485182273}
2023-01-05 08:29:22,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:29:22,757 INFO:     Epoch: 45
2023-01-05 08:29:24,906 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.46081714729468026, 'Total loss': 0.46081714729468026} | train loss {'Reaction outcome loss': 0.32573987281584477, 'Total loss': 0.32573987281584477}
2023-01-05 08:29:24,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:29:24,906 INFO:     Epoch: 46
2023-01-05 08:29:27,052 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3724205096562703, 'Total loss': 0.3724205096562703} | train loss {'Reaction outcome loss': 0.32426344131157075, 'Total loss': 0.32426344131157075}
2023-01-05 08:29:27,053 INFO:     Found new best model at epoch 46
2023-01-05 08:29:27,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:29:27,054 INFO:     Epoch: 47
2023-01-05 08:29:29,206 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4192993705471357, 'Total loss': 0.4192993705471357} | train loss {'Reaction outcome loss': 0.3247159033290523, 'Total loss': 0.3247159033290523}
2023-01-05 08:29:29,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:29:29,207 INFO:     Epoch: 48
2023-01-05 08:29:31,128 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4288703133662542, 'Total loss': 0.4288703133662542} | train loss {'Reaction outcome loss': 0.3154205344446795, 'Total loss': 0.3154205344446795}
2023-01-05 08:29:31,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:29:31,128 INFO:     Epoch: 49
2023-01-05 08:29:33,280 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4649212032556534, 'Total loss': 0.4649212032556534} | train loss {'Reaction outcome loss': 0.31821813135520444, 'Total loss': 0.31821813135520444}
2023-01-05 08:29:33,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:29:33,280 INFO:     Epoch: 50
2023-01-05 08:29:35,421 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43293921649456024, 'Total loss': 0.43293921649456024} | train loss {'Reaction outcome loss': 0.31659219151997303, 'Total loss': 0.31659219151997303}
2023-01-05 08:29:35,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:29:35,421 INFO:     Epoch: 51
2023-01-05 08:29:37,545 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43905895749727886, 'Total loss': 0.43905895749727886} | train loss {'Reaction outcome loss': 0.31193572316905516, 'Total loss': 0.31193572316905516}
2023-01-05 08:29:37,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:29:37,545 INFO:     Epoch: 52
2023-01-05 08:29:39,696 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4205980320771535, 'Total loss': 0.4205980320771535} | train loss {'Reaction outcome loss': 0.31700455696721164, 'Total loss': 0.31700455696721164}
2023-01-05 08:29:39,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:29:39,697 INFO:     Epoch: 53
2023-01-05 08:29:41,836 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.41377627551555635, 'Total loss': 0.41377627551555635} | train loss {'Reaction outcome loss': 0.3017803191893048, 'Total loss': 0.3017803191893048}
2023-01-05 08:29:41,837 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:29:41,837 INFO:     Epoch: 54
2023-01-05 08:29:43,976 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3912983775138855, 'Total loss': 0.3912983775138855} | train loss {'Reaction outcome loss': 0.30921526378764336, 'Total loss': 0.30921526378764336}
2023-01-05 08:29:43,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:29:43,976 INFO:     Epoch: 55
2023-01-05 08:29:46,108 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40791452725728355, 'Total loss': 0.40791452725728355} | train loss {'Reaction outcome loss': 0.30464763446769, 'Total loss': 0.30464763446769}
2023-01-05 08:29:46,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:29:46,109 INFO:     Epoch: 56
2023-01-05 08:29:48,246 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46320613523324333, 'Total loss': 0.46320613523324333} | train loss {'Reaction outcome loss': 0.30180041369173555, 'Total loss': 0.30180041369173555}
2023-01-05 08:29:48,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:29:48,247 INFO:     Epoch: 57
2023-01-05 08:29:50,382 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4309270809094111, 'Total loss': 0.4309270809094111} | train loss {'Reaction outcome loss': 0.3056731398316312, 'Total loss': 0.3056731398316312}
2023-01-05 08:29:50,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:29:50,382 INFO:     Epoch: 58
2023-01-05 08:29:52,514 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.423240331808726, 'Total loss': 0.423240331808726} | train loss {'Reaction outcome loss': 0.29558671134841313, 'Total loss': 0.29558671134841313}
2023-01-05 08:29:52,514 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:29:52,514 INFO:     Epoch: 59
2023-01-05 08:29:54,652 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4347231109937032, 'Total loss': 0.4347231109937032} | train loss {'Reaction outcome loss': 0.29415006400682986, 'Total loss': 0.29415006400682986}
2023-01-05 08:29:54,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:29:54,653 INFO:     Epoch: 60
2023-01-05 08:29:56,797 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.41688480973243713, 'Total loss': 0.41688480973243713} | train loss {'Reaction outcome loss': 0.29372255752484006, 'Total loss': 0.29372255752484006}
2023-01-05 08:29:56,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:29:56,797 INFO:     Epoch: 61
2023-01-05 08:29:58,943 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4090186933676402, 'Total loss': 0.4090186933676402} | train loss {'Reaction outcome loss': 0.28791512555319937, 'Total loss': 0.28791512555319937}
2023-01-05 08:29:58,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:29:58,944 INFO:     Epoch: 62
2023-01-05 08:30:01,078 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40313259661197665, 'Total loss': 0.40313259661197665} | train loss {'Reaction outcome loss': 0.2909302559200224, 'Total loss': 0.2909302559200224}
2023-01-05 08:30:01,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:30:01,078 INFO:     Epoch: 63
2023-01-05 08:30:03,222 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39068384567896525, 'Total loss': 0.39068384567896525} | train loss {'Reaction outcome loss': 0.28601923785530603, 'Total loss': 0.28601923785530603}
2023-01-05 08:30:03,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:30:03,223 INFO:     Epoch: 64
2023-01-05 08:30:05,357 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.41769518206516904, 'Total loss': 0.41769518206516904} | train loss {'Reaction outcome loss': 0.28558117817173073, 'Total loss': 0.28558117817173073}
2023-01-05 08:30:05,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:30:05,357 INFO:     Epoch: 65
2023-01-05 08:30:07,504 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.433462397257487, 'Total loss': 0.433462397257487} | train loss {'Reaction outcome loss': 0.28096710165942107, 'Total loss': 0.28096710165942107}
2023-01-05 08:30:07,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:30:07,505 INFO:     Epoch: 66
2023-01-05 08:30:09,664 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4118139048417409, 'Total loss': 0.4118139048417409} | train loss {'Reaction outcome loss': 0.27902416187601214, 'Total loss': 0.27902416187601214}
2023-01-05 08:30:09,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:30:09,664 INFO:     Epoch: 67
2023-01-05 08:30:11,796 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.438280858596166, 'Total loss': 0.438280858596166} | train loss {'Reaction outcome loss': 0.2850940044246095, 'Total loss': 0.2850940044246095}
2023-01-05 08:30:11,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:30:11,796 INFO:     Epoch: 68
2023-01-05 08:30:13,939 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40638228058815, 'Total loss': 0.40638228058815} | train loss {'Reaction outcome loss': 0.27719280200126845, 'Total loss': 0.27719280200126845}
2023-01-05 08:30:13,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:30:13,939 INFO:     Epoch: 69
2023-01-05 08:30:16,120 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.37844618161519367, 'Total loss': 0.37844618161519367} | train loss {'Reaction outcome loss': 0.2736854801029513, 'Total loss': 0.2736854801029513}
2023-01-05 08:30:16,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:30:16,121 INFO:     Epoch: 70
2023-01-05 08:30:18,268 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4260716160138448, 'Total loss': 0.4260716160138448} | train loss {'Reaction outcome loss': 0.2786357862117526, 'Total loss': 0.2786357862117526}
2023-01-05 08:30:18,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:30:18,269 INFO:     Epoch: 71
2023-01-05 08:30:20,429 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4035306264956792, 'Total loss': 0.4035306264956792} | train loss {'Reaction outcome loss': 0.26864388845042214, 'Total loss': 0.26864388845042214}
2023-01-05 08:30:20,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:30:20,430 INFO:     Epoch: 72
2023-01-05 08:30:22,594 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4061442971229553, 'Total loss': 0.4061442971229553} | train loss {'Reaction outcome loss': 0.27600045382103205, 'Total loss': 0.27600045382103205}
2023-01-05 08:30:22,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:30:22,595 INFO:     Epoch: 73
2023-01-05 08:30:24,736 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39293217758337656, 'Total loss': 0.39293217758337656} | train loss {'Reaction outcome loss': 0.2706969226181725, 'Total loss': 0.2706969226181725}
2023-01-05 08:30:24,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:30:24,737 INFO:     Epoch: 74
2023-01-05 08:30:26,873 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41776210168997446, 'Total loss': 0.41776210168997446} | train loss {'Reaction outcome loss': 0.27026002773598873, 'Total loss': 0.27026002773598873}
2023-01-05 08:30:26,873 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:30:26,873 INFO:     Epoch: 75
2023-01-05 08:30:29,007 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4137203802665075, 'Total loss': 0.4137203802665075} | train loss {'Reaction outcome loss': 0.266627872082995, 'Total loss': 0.266627872082995}
2023-01-05 08:30:29,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:30:29,007 INFO:     Epoch: 76
2023-01-05 08:30:31,153 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.41423681179682414, 'Total loss': 0.41423681179682414} | train loss {'Reaction outcome loss': 0.269908176434837, 'Total loss': 0.269908176434837}
2023-01-05 08:30:31,153 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:30:31,153 INFO:     Epoch: 77
2023-01-05 08:30:33,317 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4331875006357829, 'Total loss': 0.4331875006357829} | train loss {'Reaction outcome loss': 0.25862979676724573, 'Total loss': 0.25862979676724573}
2023-01-05 08:30:33,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:30:33,317 INFO:     Epoch: 78
2023-01-05 08:30:35,437 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3900506302714348, 'Total loss': 0.3900506302714348} | train loss {'Reaction outcome loss': 0.26370784011243026, 'Total loss': 0.26370784011243026}
2023-01-05 08:30:35,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:30:35,438 INFO:     Epoch: 79
2023-01-05 08:30:37,592 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41265336026748023, 'Total loss': 0.41265336026748023} | train loss {'Reaction outcome loss': 0.26536378278755224, 'Total loss': 0.26536378278755224}
2023-01-05 08:30:37,592 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:30:37,592 INFO:     Epoch: 80
2023-01-05 08:30:39,773 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40269767940044404, 'Total loss': 0.40269767940044404} | train loss {'Reaction outcome loss': 0.25908127615412513, 'Total loss': 0.25908127615412513}
2023-01-05 08:30:39,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:30:39,773 INFO:     Epoch: 81
2023-01-05 08:30:41,944 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4220379710197449, 'Total loss': 0.4220379710197449} | train loss {'Reaction outcome loss': 0.25858943242811677, 'Total loss': 0.25858943242811677}
2023-01-05 08:30:41,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:30:41,944 INFO:     Epoch: 82
2023-01-05 08:30:44,091 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4797971000274022, 'Total loss': 0.4797971000274022} | train loss {'Reaction outcome loss': 0.2536556268376963, 'Total loss': 0.2536556268376963}
2023-01-05 08:30:44,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:30:44,091 INFO:     Epoch: 83
2023-01-05 08:30:46,222 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41544852157433826, 'Total loss': 0.41544852157433826} | train loss {'Reaction outcome loss': 0.2519216677600402, 'Total loss': 0.2519216677600402}
2023-01-05 08:30:46,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:30:46,223 INFO:     Epoch: 84
2023-01-05 08:30:48,361 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40046895742416383, 'Total loss': 0.40046895742416383} | train loss {'Reaction outcome loss': 0.25439170574694325, 'Total loss': 0.25439170574694325}
2023-01-05 08:30:48,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:30:48,362 INFO:     Epoch: 85
2023-01-05 08:30:50,503 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4245305409034093, 'Total loss': 0.4245305409034093} | train loss {'Reaction outcome loss': 0.25627528429850116, 'Total loss': 0.25627528429850116}
2023-01-05 08:30:50,503 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:30:50,503 INFO:     Epoch: 86
2023-01-05 08:30:52,633 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4567687789599101, 'Total loss': 0.4567687789599101} | train loss {'Reaction outcome loss': 0.2526211682161241, 'Total loss': 0.2526211682161241}
2023-01-05 08:30:52,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:30:52,634 INFO:     Epoch: 87
2023-01-05 08:30:54,781 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.46069194227457044, 'Total loss': 0.46069194227457044} | train loss {'Reaction outcome loss': 0.24935681920587308, 'Total loss': 0.24935681920587308}
2023-01-05 08:30:54,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:30:54,782 INFO:     Epoch: 88
2023-01-05 08:30:56,910 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.38970362146695453, 'Total loss': 0.38970362146695453} | train loss {'Reaction outcome loss': 0.25392776757697044, 'Total loss': 0.25392776757697044}
2023-01-05 08:30:56,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:30:56,911 INFO:     Epoch: 89
2023-01-05 08:30:59,027 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4058169225851695, 'Total loss': 0.4058169225851695} | train loss {'Reaction outcome loss': 0.24433266939834142, 'Total loss': 0.24433266939834142}
2023-01-05 08:30:59,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:30:59,028 INFO:     Epoch: 90
2023-01-05 08:31:01,170 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4122693419456482, 'Total loss': 0.4122693419456482} | train loss {'Reaction outcome loss': 0.25238101417710496, 'Total loss': 0.25238101417710496}
2023-01-05 08:31:01,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:31:01,171 INFO:     Epoch: 91
2023-01-05 08:31:03,313 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4148664534091949, 'Total loss': 0.4148664534091949} | train loss {'Reaction outcome loss': 0.25395598856138657, 'Total loss': 0.25395598856138657}
2023-01-05 08:31:03,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:31:03,313 INFO:     Epoch: 92
2023-01-05 08:31:05,482 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43785336017608645, 'Total loss': 0.43785336017608645} | train loss {'Reaction outcome loss': 0.2523282374197365, 'Total loss': 0.2523282374197365}
2023-01-05 08:31:05,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:31:05,483 INFO:     Epoch: 93
2023-01-05 08:31:07,662 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4201462189356486, 'Total loss': 0.4201462189356486} | train loss {'Reaction outcome loss': 0.2407344956353525, 'Total loss': 0.2407344956353525}
2023-01-05 08:31:07,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:31:07,662 INFO:     Epoch: 94
2023-01-05 08:31:09,787 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4113941510518392, 'Total loss': 0.4113941510518392} | train loss {'Reaction outcome loss': 0.2480056640886507, 'Total loss': 0.2480056640886507}
2023-01-05 08:31:09,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:31:09,788 INFO:     Epoch: 95
2023-01-05 08:31:11,928 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44328627387682595, 'Total loss': 0.44328627387682595} | train loss {'Reaction outcome loss': 0.24993222445162566, 'Total loss': 0.24993222445162566}
2023-01-05 08:31:11,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:31:11,929 INFO:     Epoch: 96
2023-01-05 08:31:14,063 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4012852678696314, 'Total loss': 0.4012852678696314} | train loss {'Reaction outcome loss': 0.24357973638198752, 'Total loss': 0.24357973638198752}
2023-01-05 08:31:14,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:31:14,063 INFO:     Epoch: 97
2023-01-05 08:31:16,193 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.40260875324408213, 'Total loss': 0.40260875324408213} | train loss {'Reaction outcome loss': 0.23998140427028083, 'Total loss': 0.23998140427028083}
2023-01-05 08:31:16,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:31:16,193 INFO:     Epoch: 98
2023-01-05 08:31:18,338 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.410774294535319, 'Total loss': 0.410774294535319} | train loss {'Reaction outcome loss': 0.24425766595226506, 'Total loss': 0.24425766595226506}
2023-01-05 08:31:18,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:31:18,338 INFO:     Epoch: 99
2023-01-05 08:31:20,483 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4145172198613485, 'Total loss': 0.4145172198613485} | train loss {'Reaction outcome loss': 0.23970271069420018, 'Total loss': 0.23970271069420018}
2023-01-05 08:31:20,483 INFO:     Best model found after epoch 47 of 100.
2023-01-05 08:31:20,484 INFO:   Done with stage: TRAINING
2023-01-05 08:31:20,484 INFO:   Starting stage: EVALUATION
2023-01-05 08:31:20,630 INFO:   Done with stage: EVALUATION
2023-01-05 08:31:20,630 INFO:   Leaving out SEQ value Fold_4
2023-01-05 08:31:20,643 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 08:31:20,643 INFO:   Starting stage: FEATURE SCALING
2023-01-05 08:31:21,296 INFO:   Done with stage: FEATURE SCALING
2023-01-05 08:31:21,296 INFO:   Starting stage: SCALING TARGETS
2023-01-05 08:31:21,365 INFO:   Done with stage: SCALING TARGETS
2023-01-05 08:31:21,366 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:31:21,367 INFO:     No hyperparam tuning for this model
2023-01-05 08:31:21,367 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:31:21,367 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 08:31:21,367 INFO:     None feature selector for col prot
2023-01-05 08:31:21,368 INFO:     None feature selector for col prot
2023-01-05 08:31:21,368 INFO:     None feature selector for col prot
2023-01-05 08:31:21,368 INFO:     None feature selector for col chem
2023-01-05 08:31:21,368 INFO:     None feature selector for col chem
2023-01-05 08:31:21,368 INFO:     None feature selector for col chem
2023-01-05 08:31:21,368 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 08:31:21,368 INFO:   Starting stage: BUILD MODEL
2023-01-05 08:31:21,370 INFO:     Number of params in model 72901
2023-01-05 08:31:21,373 INFO:   Done with stage: BUILD MODEL
2023-01-05 08:31:21,373 INFO:   Starting stage: TRAINING
2023-01-05 08:31:21,433 INFO:     Val loss before train {'Reaction outcome loss': 1.0464155276616414, 'Total loss': 1.0464155276616414}
2023-01-05 08:31:21,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:31:21,433 INFO:     Epoch: 0
2023-01-05 08:31:23,600 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8995917280515034, 'Total loss': 0.8995917280515034} | train loss {'Reaction outcome loss': 0.9461272212572477, 'Total loss': 0.9461272212572477}
2023-01-05 08:31:23,600 INFO:     Found new best model at epoch 0
2023-01-05 08:31:23,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:31:23,602 INFO:     Epoch: 1
2023-01-05 08:31:25,758 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6834316551685333, 'Total loss': 0.6834316551685333} | train loss {'Reaction outcome loss': 0.7780201488883917, 'Total loss': 0.7780201488883917}
2023-01-05 08:31:25,758 INFO:     Found new best model at epoch 1
2023-01-05 08:31:25,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:31:25,760 INFO:     Epoch: 2
2023-01-05 08:31:27,913 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.6112097303072611, 'Total loss': 0.6112097303072611} | train loss {'Reaction outcome loss': 0.6160416130769985, 'Total loss': 0.6160416130769985}
2023-01-05 08:31:27,914 INFO:     Found new best model at epoch 2
2023-01-05 08:31:27,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:31:27,915 INFO:     Epoch: 3
2023-01-05 08:31:30,083 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5517572303613026, 'Total loss': 0.5517572303613026} | train loss {'Reaction outcome loss': 0.5583291441632522, 'Total loss': 0.5583291441632522}
2023-01-05 08:31:30,084 INFO:     Found new best model at epoch 3
2023-01-05 08:31:30,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:31:30,085 INFO:     Epoch: 4
2023-01-05 08:31:32,246 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5355618794759115, 'Total loss': 0.5355618794759115} | train loss {'Reaction outcome loss': 0.5256245649463434, 'Total loss': 0.5256245649463434}
2023-01-05 08:31:32,246 INFO:     Found new best model at epoch 4
2023-01-05 08:31:32,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:31:32,248 INFO:     Epoch: 5
2023-01-05 08:31:34,411 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5270725429058075, 'Total loss': 0.5270725429058075} | train loss {'Reaction outcome loss': 0.5086762559758197, 'Total loss': 0.5086762559758197}
2023-01-05 08:31:34,411 INFO:     Found new best model at epoch 5
2023-01-05 08:31:34,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:31:34,413 INFO:     Epoch: 6
2023-01-05 08:31:36,586 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5401052802801132, 'Total loss': 0.5401052802801132} | train loss {'Reaction outcome loss': 0.5048106449659551, 'Total loss': 0.5048106449659551}
2023-01-05 08:31:36,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:31:36,587 INFO:     Epoch: 7
2023-01-05 08:31:38,754 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5360076904296875, 'Total loss': 0.5360076904296875} | train loss {'Reaction outcome loss': 0.489665068390137, 'Total loss': 0.489665068390137}
2023-01-05 08:31:38,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:31:38,754 INFO:     Epoch: 8
2023-01-05 08:31:40,944 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5427773118019104, 'Total loss': 0.5427773118019104} | train loss {'Reaction outcome loss': 0.4866613368587804, 'Total loss': 0.4866613368587804}
2023-01-05 08:31:40,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:31:40,945 INFO:     Epoch: 9
2023-01-05 08:31:43,109 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5367103884617488, 'Total loss': 0.5367103884617488} | train loss {'Reaction outcome loss': 0.47483362386588157, 'Total loss': 0.47483362386588157}
2023-01-05 08:31:43,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:31:43,109 INFO:     Epoch: 10
2023-01-05 08:31:45,275 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5172285358111064, 'Total loss': 0.5172285358111064} | train loss {'Reaction outcome loss': 0.4713372822165059, 'Total loss': 0.4713372822165059}
2023-01-05 08:31:45,275 INFO:     Found new best model at epoch 10
2023-01-05 08:31:45,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:31:45,276 INFO:     Epoch: 11
2023-01-05 08:31:47,446 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5406838019688924, 'Total loss': 0.5406838019688924} | train loss {'Reaction outcome loss': 0.46863831794864436, 'Total loss': 0.46863831794864436}
2023-01-05 08:31:47,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:31:47,447 INFO:     Epoch: 12
2023-01-05 08:31:49,607 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5081997692584992, 'Total loss': 0.5081997692584992} | train loss {'Reaction outcome loss': 0.4629064092029303, 'Total loss': 0.4629064092029303}
2023-01-05 08:31:49,607 INFO:     Found new best model at epoch 12
2023-01-05 08:31:49,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:31:49,609 INFO:     Epoch: 13
2023-01-05 08:31:51,778 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5297759175300598, 'Total loss': 0.5297759175300598} | train loss {'Reaction outcome loss': 0.4599745115971307, 'Total loss': 0.4599745115971307}
2023-01-05 08:31:51,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:31:51,778 INFO:     Epoch: 14
2023-01-05 08:31:53,956 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5062429974476497, 'Total loss': 0.5062429974476497} | train loss {'Reaction outcome loss': 0.4538003977670566, 'Total loss': 0.4538003977670566}
2023-01-05 08:31:53,957 INFO:     Found new best model at epoch 14
2023-01-05 08:31:53,958 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:31:53,959 INFO:     Epoch: 15
2023-01-05 08:31:56,123 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.506942629814148, 'Total loss': 0.506942629814148} | train loss {'Reaction outcome loss': 0.4471979146345858, 'Total loss': 0.4471979146345858}
2023-01-05 08:31:56,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:31:56,124 INFO:     Epoch: 16
2023-01-05 08:31:58,316 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5216894388198853, 'Total loss': 0.5216894388198853} | train loss {'Reaction outcome loss': 0.44900501145567706, 'Total loss': 0.44900501145567706}
2023-01-05 08:31:58,316 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:31:58,316 INFO:     Epoch: 17
2023-01-05 08:32:00,493 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5020826955636343, 'Total loss': 0.5020826955636343} | train loss {'Reaction outcome loss': 0.4438058375666718, 'Total loss': 0.4438058375666718}
2023-01-05 08:32:00,493 INFO:     Found new best model at epoch 17
2023-01-05 08:32:00,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:32:00,495 INFO:     Epoch: 18
2023-01-05 08:32:02,662 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5072932422161103, 'Total loss': 0.5072932422161103} | train loss {'Reaction outcome loss': 0.43425044605663105, 'Total loss': 0.43425044605663105}
2023-01-05 08:32:02,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:32:02,662 INFO:     Epoch: 19
2023-01-05 08:32:04,837 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4948159376780192, 'Total loss': 0.4948159376780192} | train loss {'Reaction outcome loss': 0.4367076266651119, 'Total loss': 0.4367076266651119}
2023-01-05 08:32:04,838 INFO:     Found new best model at epoch 19
2023-01-05 08:32:04,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:32:04,839 INFO:     Epoch: 20
2023-01-05 08:32:06,998 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.524744443098704, 'Total loss': 0.524744443098704} | train loss {'Reaction outcome loss': 0.4319699242280709, 'Total loss': 0.4319699242280709}
2023-01-05 08:32:06,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:32:06,998 INFO:     Epoch: 21
2023-01-05 08:32:09,176 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.48029026985168455, 'Total loss': 0.48029026985168455} | train loss {'Reaction outcome loss': 0.42818038644343076, 'Total loss': 0.42818038644343076}
2023-01-05 08:32:09,176 INFO:     Found new best model at epoch 21
2023-01-05 08:32:09,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:32:09,177 INFO:     Epoch: 22
2023-01-05 08:32:11,356 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4946707765261332, 'Total loss': 0.4946707765261332} | train loss {'Reaction outcome loss': 0.4248755542487444, 'Total loss': 0.4248755542487444}
2023-01-05 08:32:11,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:32:11,356 INFO:     Epoch: 23
2023-01-05 08:32:13,520 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4738933583100637, 'Total loss': 0.4738933583100637} | train loss {'Reaction outcome loss': 0.4211973327107808, 'Total loss': 0.4211973327107808}
2023-01-05 08:32:13,521 INFO:     Found new best model at epoch 23
2023-01-05 08:32:13,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:32:13,522 INFO:     Epoch: 24
2023-01-05 08:32:15,682 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4671392381191254, 'Total loss': 0.4671392381191254} | train loss {'Reaction outcome loss': 0.41931376105934276, 'Total loss': 0.41931376105934276}
2023-01-05 08:32:15,682 INFO:     Found new best model at epoch 24
2023-01-05 08:32:15,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:32:15,684 INFO:     Epoch: 25
2023-01-05 08:32:17,840 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4958408296108246, 'Total loss': 0.4958408296108246} | train loss {'Reaction outcome loss': 0.41393857322875344, 'Total loss': 0.41393857322875344}
2023-01-05 08:32:17,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:32:17,840 INFO:     Epoch: 26
2023-01-05 08:32:19,988 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.49743982156117755, 'Total loss': 0.49743982156117755} | train loss {'Reaction outcome loss': 0.4163372161586362, 'Total loss': 0.4163372161586362}
2023-01-05 08:32:19,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:32:19,989 INFO:     Epoch: 27
2023-01-05 08:32:22,159 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.49080654978752136, 'Total loss': 0.49080654978752136} | train loss {'Reaction outcome loss': 0.40702641010284424, 'Total loss': 0.40702641010284424}
2023-01-05 08:32:22,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:32:22,159 INFO:     Epoch: 28
2023-01-05 08:32:24,323 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4512806991736094, 'Total loss': 0.4512806991736094} | train loss {'Reaction outcome loss': 0.405236124615807, 'Total loss': 0.405236124615807}
2023-01-05 08:32:24,324 INFO:     Found new best model at epoch 28
2023-01-05 08:32:24,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:32:24,326 INFO:     Epoch: 29
2023-01-05 08:32:26,455 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46501269141832985, 'Total loss': 0.46501269141832985} | train loss {'Reaction outcome loss': 0.4085616258507601, 'Total loss': 0.4085616258507601}
2023-01-05 08:32:26,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:32:26,456 INFO:     Epoch: 30
2023-01-05 08:32:28,603 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4695829709370931, 'Total loss': 0.4695829709370931} | train loss {'Reaction outcome loss': 0.40277874195403573, 'Total loss': 0.40277874195403573}
2023-01-05 08:32:28,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:32:28,603 INFO:     Epoch: 31
2023-01-05 08:32:30,739 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.46566692789395653, 'Total loss': 0.46566692789395653} | train loss {'Reaction outcome loss': 0.39629682328296484, 'Total loss': 0.39629682328296484}
2023-01-05 08:32:30,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:32:30,740 INFO:     Epoch: 32
2023-01-05 08:32:32,898 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.48007771869500476, 'Total loss': 0.48007771869500476} | train loss {'Reaction outcome loss': 0.39413293589592413, 'Total loss': 0.39413293589592413}
2023-01-05 08:32:32,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:32:32,898 INFO:     Epoch: 33
2023-01-05 08:32:35,031 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5083736618359883, 'Total loss': 0.5083736618359883} | train loss {'Reaction outcome loss': 0.3880424627543356, 'Total loss': 0.3880424627543356}
2023-01-05 08:32:35,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:32:35,031 INFO:     Epoch: 34
2023-01-05 08:32:37,176 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5116356194019318, 'Total loss': 0.5116356194019318} | train loss {'Reaction outcome loss': 0.391301615452831, 'Total loss': 0.391301615452831}
2023-01-05 08:32:37,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:32:37,176 INFO:     Epoch: 35
2023-01-05 08:32:39,331 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45650426745414735, 'Total loss': 0.45650426745414735} | train loss {'Reaction outcome loss': 0.38540158727431556, 'Total loss': 0.38540158727431556}
2023-01-05 08:32:39,331 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:32:39,331 INFO:     Epoch: 36
2023-01-05 08:32:41,495 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.5040172129869461, 'Total loss': 0.5040172129869461} | train loss {'Reaction outcome loss': 0.38891522147918006, 'Total loss': 0.38891522147918006}
2023-01-05 08:32:41,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:32:41,495 INFO:     Epoch: 37
2023-01-05 08:32:43,637 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4875014126300812, 'Total loss': 0.4875014126300812} | train loss {'Reaction outcome loss': 0.38283066655969794, 'Total loss': 0.38283066655969794}
2023-01-05 08:32:43,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:32:43,637 INFO:     Epoch: 38
2023-01-05 08:32:45,805 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4558952366312345, 'Total loss': 0.4558952366312345} | train loss {'Reaction outcome loss': 0.38194205384661145, 'Total loss': 0.38194205384661145}
2023-01-05 08:32:45,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:32:45,806 INFO:     Epoch: 39
2023-01-05 08:32:47,970 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46213462750116985, 'Total loss': 0.46213462750116985} | train loss {'Reaction outcome loss': 0.3755825920171686, 'Total loss': 0.3755825920171686}
2023-01-05 08:32:47,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:32:47,971 INFO:     Epoch: 40
2023-01-05 08:32:50,120 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44751412272453306, 'Total loss': 0.44751412272453306} | train loss {'Reaction outcome loss': 0.3706900082017541, 'Total loss': 0.3706900082017541}
2023-01-05 08:32:50,120 INFO:     Found new best model at epoch 40
2023-01-05 08:32:50,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:32:50,122 INFO:     Epoch: 41
2023-01-05 08:32:52,290 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4572812298933665, 'Total loss': 0.4572812298933665} | train loss {'Reaction outcome loss': 0.3692169059807643, 'Total loss': 0.3692169059807643}
2023-01-05 08:32:52,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:32:52,290 INFO:     Epoch: 42
2023-01-05 08:32:54,443 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.43300966123739876, 'Total loss': 0.43300966123739876} | train loss {'Reaction outcome loss': 0.368788761433066, 'Total loss': 0.368788761433066}
2023-01-05 08:32:54,444 INFO:     Found new best model at epoch 42
2023-01-05 08:32:54,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:32:54,446 INFO:     Epoch: 43
2023-01-05 08:32:56,610 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4478058030207952, 'Total loss': 0.4478058030207952} | train loss {'Reaction outcome loss': 0.3636240290498045, 'Total loss': 0.3636240290498045}
2023-01-05 08:32:56,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:32:56,610 INFO:     Epoch: 44
2023-01-05 08:32:58,789 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4734527111053467, 'Total loss': 0.4734527111053467} | train loss {'Reaction outcome loss': 0.3620747768652999, 'Total loss': 0.3620747768652999}
2023-01-05 08:32:58,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:32:58,789 INFO:     Epoch: 45
2023-01-05 08:33:00,964 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4930833220481873, 'Total loss': 0.4930833220481873} | train loss {'Reaction outcome loss': 0.3599712979115734, 'Total loss': 0.3599712979115734}
2023-01-05 08:33:00,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:33:00,965 INFO:     Epoch: 46
2023-01-05 08:33:03,148 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4626377373933792, 'Total loss': 0.4626377373933792} | train loss {'Reaction outcome loss': 0.35952296350084056, 'Total loss': 0.35952296350084056}
2023-01-05 08:33:03,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:33:03,148 INFO:     Epoch: 47
2023-01-05 08:33:05,309 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.46249035795529686, 'Total loss': 0.46249035795529686} | train loss {'Reaction outcome loss': 0.3550440038315656, 'Total loss': 0.3550440038315656}
2023-01-05 08:33:05,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:33:05,309 INFO:     Epoch: 48
2023-01-05 08:33:07,476 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.44182597200075785, 'Total loss': 0.44182597200075785} | train loss {'Reaction outcome loss': 0.35134524919280935, 'Total loss': 0.35134524919280935}
2023-01-05 08:33:07,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:33:07,476 INFO:     Epoch: 49
2023-01-05 08:33:09,641 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.48522463341554006, 'Total loss': 0.48522463341554006} | train loss {'Reaction outcome loss': 0.3473871502527691, 'Total loss': 0.3473871502527691}
2023-01-05 08:33:09,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:33:09,641 INFO:     Epoch: 50
2023-01-05 08:33:11,816 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45074781427780786, 'Total loss': 0.45074781427780786} | train loss {'Reaction outcome loss': 0.3504266368648851, 'Total loss': 0.3504266368648851}
2023-01-05 08:33:11,816 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:33:11,817 INFO:     Epoch: 51
2023-01-05 08:33:13,967 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4555804262558619, 'Total loss': 0.4555804262558619} | train loss {'Reaction outcome loss': 0.3416674154867764, 'Total loss': 0.3416674154867764}
2023-01-05 08:33:13,967 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:33:13,968 INFO:     Epoch: 52
2023-01-05 08:33:16,137 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.46023099223772684, 'Total loss': 0.46023099223772684} | train loss {'Reaction outcome loss': 0.3460944721791288, 'Total loss': 0.3460944721791288}
2023-01-05 08:33:16,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:33:16,138 INFO:     Epoch: 53
2023-01-05 08:33:18,294 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4467165450255076, 'Total loss': 0.4467165450255076} | train loss {'Reaction outcome loss': 0.3405446859365766, 'Total loss': 0.3405446859365766}
2023-01-05 08:33:18,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:33:18,295 INFO:     Epoch: 54
2023-01-05 08:33:20,476 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4524183054765066, 'Total loss': 0.4524183054765066} | train loss {'Reaction outcome loss': 0.33966560326920087, 'Total loss': 0.33966560326920087}
2023-01-05 08:33:20,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:33:20,476 INFO:     Epoch: 55
2023-01-05 08:33:22,641 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47150029440720875, 'Total loss': 0.47150029440720875} | train loss {'Reaction outcome loss': 0.33300104621622967, 'Total loss': 0.33300104621622967}
2023-01-05 08:33:22,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:33:22,641 INFO:     Epoch: 56
2023-01-05 08:33:24,821 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.44366565148035686, 'Total loss': 0.44366565148035686} | train loss {'Reaction outcome loss': 0.32991680543237645, 'Total loss': 0.32991680543237645}
2023-01-05 08:33:24,821 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:33:24,822 INFO:     Epoch: 57
2023-01-05 08:33:26,983 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4365127464135488, 'Total loss': 0.4365127464135488} | train loss {'Reaction outcome loss': 0.3342581340229468, 'Total loss': 0.3342581340229468}
2023-01-05 08:33:26,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:33:26,983 INFO:     Epoch: 58
2023-01-05 08:33:29,127 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45095274845759076, 'Total loss': 0.45095274845759076} | train loss {'Reaction outcome loss': 0.3212384881471899, 'Total loss': 0.3212384881471899}
2023-01-05 08:33:29,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:33:29,128 INFO:     Epoch: 59
2023-01-05 08:33:31,331 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4592047532399495, 'Total loss': 0.4592047532399495} | train loss {'Reaction outcome loss': 0.32189778402609087, 'Total loss': 0.32189778402609087}
2023-01-05 08:33:31,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:33:31,333 INFO:     Epoch: 60
2023-01-05 08:33:33,492 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4480670173962911, 'Total loss': 0.4480670173962911} | train loss {'Reaction outcome loss': 0.3144928075588352, 'Total loss': 0.3144928075588352}
2023-01-05 08:33:33,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:33:33,492 INFO:     Epoch: 61
2023-01-05 08:33:35,529 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42775386770566304, 'Total loss': 0.42775386770566304} | train loss {'Reaction outcome loss': 0.31361960439475434, 'Total loss': 0.31361960439475434}
2023-01-05 08:33:35,529 INFO:     Found new best model at epoch 61
2023-01-05 08:33:35,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:33:35,531 INFO:     Epoch: 62
2023-01-05 08:33:37,620 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42486687302589415, 'Total loss': 0.42486687302589415} | train loss {'Reaction outcome loss': 0.3172746136085221, 'Total loss': 0.3172746136085221}
2023-01-05 08:33:37,620 INFO:     Found new best model at epoch 62
2023-01-05 08:33:37,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:33:37,622 INFO:     Epoch: 63
2023-01-05 08:33:39,771 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.449897775053978, 'Total loss': 0.449897775053978} | train loss {'Reaction outcome loss': 0.30949162460513924, 'Total loss': 0.30949162460513924}
2023-01-05 08:33:39,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:33:39,772 INFO:     Epoch: 64
2023-01-05 08:33:41,928 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4547892520825068, 'Total loss': 0.4547892520825068} | train loss {'Reaction outcome loss': 0.30957735114687185, 'Total loss': 0.30957735114687185}
2023-01-05 08:33:41,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:33:41,929 INFO:     Epoch: 65
2023-01-05 08:33:44,097 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.42164181023836134, 'Total loss': 0.42164181023836134} | train loss {'Reaction outcome loss': 0.3038549860838518, 'Total loss': 0.3038549860838518}
2023-01-05 08:33:44,097 INFO:     Found new best model at epoch 65
2023-01-05 08:33:44,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:33:44,099 INFO:     Epoch: 66
2023-01-05 08:33:46,286 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.43464245200157164, 'Total loss': 0.43464245200157164} | train loss {'Reaction outcome loss': 0.30094704809279216, 'Total loss': 0.30094704809279216}
2023-01-05 08:33:46,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:33:46,286 INFO:     Epoch: 67
2023-01-05 08:33:48,455 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4228720227877299, 'Total loss': 0.4228720227877299} | train loss {'Reaction outcome loss': 0.30297616316469567, 'Total loss': 0.30297616316469567}
2023-01-05 08:33:48,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:33:48,456 INFO:     Epoch: 68
2023-01-05 08:33:50,620 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45499208370844524, 'Total loss': 0.45499208370844524} | train loss {'Reaction outcome loss': 0.30180246319742837, 'Total loss': 0.30180246319742837}
2023-01-05 08:33:50,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:33:50,621 INFO:     Epoch: 69
2023-01-05 08:33:52,765 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4406303405761719, 'Total loss': 0.4406303405761719} | train loss {'Reaction outcome loss': 0.29634536025433766, 'Total loss': 0.29634536025433766}
2023-01-05 08:33:52,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:33:52,765 INFO:     Epoch: 70
2023-01-05 08:33:54,929 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43110037843386334, 'Total loss': 0.43110037843386334} | train loss {'Reaction outcome loss': 0.2929874892054052, 'Total loss': 0.2929874892054052}
2023-01-05 08:33:54,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:33:54,929 INFO:     Epoch: 71
2023-01-05 08:33:57,079 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4456705162922541, 'Total loss': 0.4456705162922541} | train loss {'Reaction outcome loss': 0.2919420266813104, 'Total loss': 0.2919420266813104}
2023-01-05 08:33:57,079 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:33:57,079 INFO:     Epoch: 72
2023-01-05 08:33:59,208 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42351770450671516, 'Total loss': 0.42351770450671516} | train loss {'Reaction outcome loss': 0.29036319561786816, 'Total loss': 0.29036319561786816}
2023-01-05 08:33:59,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:33:59,208 INFO:     Epoch: 73
2023-01-05 08:34:01,369 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.43215673267841337, 'Total loss': 0.43215673267841337} | train loss {'Reaction outcome loss': 0.28656257847693856, 'Total loss': 0.28656257847693856}
2023-01-05 08:34:01,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:34:01,370 INFO:     Epoch: 74
2023-01-05 08:34:03,525 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4370275338490804, 'Total loss': 0.4370275338490804} | train loss {'Reaction outcome loss': 0.2802582875311052, 'Total loss': 0.2802582875311052}
2023-01-05 08:34:03,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:34:03,526 INFO:     Epoch: 75
2023-01-05 08:34:05,704 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.42992879350980123, 'Total loss': 0.42992879350980123} | train loss {'Reaction outcome loss': 0.2792362455776237, 'Total loss': 0.2792362455776237}
2023-01-05 08:34:05,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:34:05,705 INFO:     Epoch: 76
2023-01-05 08:34:07,881 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4528479506572088, 'Total loss': 0.4528479506572088} | train loss {'Reaction outcome loss': 0.2838331755613807, 'Total loss': 0.2838331755613807}
2023-01-05 08:34:07,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:34:07,882 INFO:     Epoch: 77
2023-01-05 08:34:10,053 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.45688407321770985, 'Total loss': 0.45688407321770985} | train loss {'Reaction outcome loss': 0.2717883377756238, 'Total loss': 0.2717883377756238}
2023-01-05 08:34:10,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:34:10,053 INFO:     Epoch: 78
2023-01-05 08:34:12,231 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41767741938432057, 'Total loss': 0.41767741938432057} | train loss {'Reaction outcome loss': 0.2791648901972099, 'Total loss': 0.2791648901972099}
2023-01-05 08:34:12,231 INFO:     Found new best model at epoch 78
2023-01-05 08:34:12,232 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:34:12,233 INFO:     Epoch: 79
2023-01-05 08:34:14,407 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.43230252067248026, 'Total loss': 0.43230252067248026} | train loss {'Reaction outcome loss': 0.2809502025158397, 'Total loss': 0.2809502025158397}
2023-01-05 08:34:14,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:34:14,407 INFO:     Epoch: 80
2023-01-05 08:34:16,556 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.45136504669984184, 'Total loss': 0.45136504669984184} | train loss {'Reaction outcome loss': 0.2674493176815527, 'Total loss': 0.2674493176815527}
2023-01-05 08:34:16,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:34:16,556 INFO:     Epoch: 81
2023-01-05 08:34:18,725 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.455679859717687, 'Total loss': 0.455679859717687} | train loss {'Reaction outcome loss': 0.2768845581029296, 'Total loss': 0.2768845581029296}
2023-01-05 08:34:18,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:34:18,726 INFO:     Epoch: 82
2023-01-05 08:34:20,900 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45224662323792775, 'Total loss': 0.45224662323792775} | train loss {'Reaction outcome loss': 0.280908056558362, 'Total loss': 0.280908056558362}
2023-01-05 08:34:20,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:34:20,901 INFO:     Epoch: 83
2023-01-05 08:34:23,056 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.419802180926005, 'Total loss': 0.419802180926005} | train loss {'Reaction outcome loss': 0.27109756807557944, 'Total loss': 0.27109756807557944}
2023-01-05 08:34:23,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:34:23,056 INFO:     Epoch: 84
2023-01-05 08:34:25,232 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4094300478696823, 'Total loss': 0.4094300478696823} | train loss {'Reaction outcome loss': 0.2651172950594864, 'Total loss': 0.2651172950594864}
2023-01-05 08:34:25,232 INFO:     Found new best model at epoch 84
2023-01-05 08:34:25,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:34:25,234 INFO:     Epoch: 85
2023-01-05 08:34:27,388 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4395353895922502, 'Total loss': 0.4395353895922502} | train loss {'Reaction outcome loss': 0.2608436220039745, 'Total loss': 0.2608436220039745}
2023-01-05 08:34:27,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:34:27,388 INFO:     Epoch: 86
2023-01-05 08:34:29,572 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4359302545587222, 'Total loss': 0.4359302545587222} | train loss {'Reaction outcome loss': 0.2655856251474537, 'Total loss': 0.2655856251474537}
2023-01-05 08:34:29,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:34:29,572 INFO:     Epoch: 87
2023-01-05 08:34:31,771 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.43898520270983377, 'Total loss': 0.43898520270983377} | train loss {'Reaction outcome loss': 0.2641027466619273, 'Total loss': 0.2641027466619273}
2023-01-05 08:34:31,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:34:31,773 INFO:     Epoch: 88
2023-01-05 08:34:33,949 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.418603840470314, 'Total loss': 0.418603840470314} | train loss {'Reaction outcome loss': 0.256682725354276, 'Total loss': 0.256682725354276}
2023-01-05 08:34:33,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:34:33,949 INFO:     Epoch: 89
2023-01-05 08:34:36,107 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4329189588626226, 'Total loss': 0.4329189588626226} | train loss {'Reaction outcome loss': 0.25258215235055353, 'Total loss': 0.25258215235055353}
2023-01-05 08:34:36,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:34:36,107 INFO:     Epoch: 90
2023-01-05 08:34:38,287 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41062055230140687, 'Total loss': 0.41062055230140687} | train loss {'Reaction outcome loss': 0.2566642536065585, 'Total loss': 0.2566642536065585}
2023-01-05 08:34:38,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:34:38,288 INFO:     Epoch: 91
2023-01-05 08:34:40,483 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4710210929314295, 'Total loss': 0.4710210929314295} | train loss {'Reaction outcome loss': 0.2566222429127577, 'Total loss': 0.2566222429127577}
2023-01-05 08:34:40,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:34:40,483 INFO:     Epoch: 92
2023-01-05 08:34:42,672 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4559586336215337, 'Total loss': 0.4559586336215337} | train loss {'Reaction outcome loss': 0.2578903872129719, 'Total loss': 0.2578903872129719}
2023-01-05 08:34:42,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:34:42,672 INFO:     Epoch: 93
2023-01-05 08:34:44,871 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44347696204980214, 'Total loss': 0.44347696204980214} | train loss {'Reaction outcome loss': 0.2538854932473024, 'Total loss': 0.2538854932473024}
2023-01-05 08:34:44,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:34:44,871 INFO:     Epoch: 94
2023-01-05 08:34:47,057 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43932510217030846, 'Total loss': 0.43932510217030846} | train loss {'Reaction outcome loss': 0.2514182658872772, 'Total loss': 0.2514182658872772}
2023-01-05 08:34:47,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:34:47,057 INFO:     Epoch: 95
2023-01-05 08:34:49,261 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.449892408400774, 'Total loss': 0.449892408400774} | train loss {'Reaction outcome loss': 0.25542432417427374, 'Total loss': 0.25542432417427374}
2023-01-05 08:34:49,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:34:49,261 INFO:     Epoch: 96
2023-01-05 08:34:51,438 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4240695814291636, 'Total loss': 0.4240695814291636} | train loss {'Reaction outcome loss': 0.24867615573081298, 'Total loss': 0.24867615573081298}
2023-01-05 08:34:51,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:34:51,438 INFO:     Epoch: 97
2023-01-05 08:34:53,632 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45820295115311943, 'Total loss': 0.45820295115311943} | train loss {'Reaction outcome loss': 0.24779520150852333, 'Total loss': 0.24779520150852333}
2023-01-05 08:34:53,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:34:53,632 INFO:     Epoch: 98
2023-01-05 08:34:55,826 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41246288021405536, 'Total loss': 0.41246288021405536} | train loss {'Reaction outcome loss': 0.24692679011004065, 'Total loss': 0.24692679011004065}
2023-01-05 08:34:55,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:34:55,826 INFO:     Epoch: 99
2023-01-05 08:34:57,967 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42932795683542885, 'Total loss': 0.42932795683542885} | train loss {'Reaction outcome loss': 0.2471376512441717, 'Total loss': 0.2471376512441717}
2023-01-05 08:34:57,967 INFO:     Best model found after epoch 85 of 100.
2023-01-05 08:34:57,967 INFO:   Done with stage: TRAINING
2023-01-05 08:34:57,967 INFO:   Starting stage: EVALUATION
2023-01-05 08:34:58,092 INFO:   Done with stage: EVALUATION
2023-01-05 08:34:58,092 INFO:   Leaving out SEQ value Fold_5
2023-01-05 08:34:58,104 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 08:34:58,104 INFO:   Starting stage: FEATURE SCALING
2023-01-05 08:34:58,757 INFO:   Done with stage: FEATURE SCALING
2023-01-05 08:34:58,757 INFO:   Starting stage: SCALING TARGETS
2023-01-05 08:34:58,827 INFO:   Done with stage: SCALING TARGETS
2023-01-05 08:34:58,827 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:34:58,827 INFO:     No hyperparam tuning for this model
2023-01-05 08:34:58,827 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:34:58,827 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 08:34:58,828 INFO:     None feature selector for col prot
2023-01-05 08:34:58,828 INFO:     None feature selector for col prot
2023-01-05 08:34:58,828 INFO:     None feature selector for col prot
2023-01-05 08:34:58,829 INFO:     None feature selector for col chem
2023-01-05 08:34:58,829 INFO:     None feature selector for col chem
2023-01-05 08:34:58,829 INFO:     None feature selector for col chem
2023-01-05 08:34:58,829 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 08:34:58,829 INFO:   Starting stage: BUILD MODEL
2023-01-05 08:34:58,831 INFO:     Number of params in model 72901
2023-01-05 08:34:58,834 INFO:   Done with stage: BUILD MODEL
2023-01-05 08:34:58,834 INFO:   Starting stage: TRAINING
2023-01-05 08:34:58,894 INFO:     Val loss before train {'Reaction outcome loss': 1.0874426205952963, 'Total loss': 1.0874426205952963}
2023-01-05 08:34:58,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:34:58,894 INFO:     Epoch: 0
2023-01-05 08:35:01,052 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.888806164264679, 'Total loss': 0.888806164264679} | train loss {'Reaction outcome loss': 0.9166714453435354, 'Total loss': 0.9166714453435354}
2023-01-05 08:35:01,052 INFO:     Found new best model at epoch 0
2023-01-05 08:35:01,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:35:01,053 INFO:     Epoch: 1
2023-01-05 08:35:03,204 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6350455800692241, 'Total loss': 0.6350455800692241} | train loss {'Reaction outcome loss': 0.7336447481977065, 'Total loss': 0.7336447481977065}
2023-01-05 08:35:03,204 INFO:     Found new best model at epoch 1
2023-01-05 08:35:03,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:35:03,205 INFO:     Epoch: 2
2023-01-05 08:35:05,366 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5170491298039754, 'Total loss': 0.5170491298039754} | train loss {'Reaction outcome loss': 0.581791989883219, 'Total loss': 0.581791989883219}
2023-01-05 08:35:05,366 INFO:     Found new best model at epoch 2
2023-01-05 08:35:05,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:35:05,367 INFO:     Epoch: 3
2023-01-05 08:35:07,518 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.536011544863383, 'Total loss': 0.536011544863383} | train loss {'Reaction outcome loss': 0.5394008776334964, 'Total loss': 0.5394008776334964}
2023-01-05 08:35:07,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:35:07,519 INFO:     Epoch: 4
2023-01-05 08:35:09,685 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5275379379590353, 'Total loss': 0.5275379379590353} | train loss {'Reaction outcome loss': 0.5183436480680372, 'Total loss': 0.5183436480680372}
2023-01-05 08:35:09,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:35:09,685 INFO:     Epoch: 5
2023-01-05 08:35:11,843 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5189043879508972, 'Total loss': 0.5189043879508972} | train loss {'Reaction outcome loss': 0.5022274438507747, 'Total loss': 0.5022274438507747}
2023-01-05 08:35:11,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:35:11,843 INFO:     Epoch: 6
2023-01-05 08:35:14,017 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5136228700478872, 'Total loss': 0.5136228700478872} | train loss {'Reaction outcome loss': 0.49952953046633175, 'Total loss': 0.49952953046633175}
2023-01-05 08:35:14,018 INFO:     Found new best model at epoch 6
2023-01-05 08:35:14,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:35:14,019 INFO:     Epoch: 7
2023-01-05 08:35:16,208 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5266721924146016, 'Total loss': 0.5266721924146016} | train loss {'Reaction outcome loss': 0.4877185335992734, 'Total loss': 0.4877185335992734}
2023-01-05 08:35:16,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:35:16,208 INFO:     Epoch: 8
2023-01-05 08:35:18,396 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47956884702046715, 'Total loss': 0.47956884702046715} | train loss {'Reaction outcome loss': 0.4779493928333555, 'Total loss': 0.4779493928333555}
2023-01-05 08:35:18,396 INFO:     Found new best model at epoch 8
2023-01-05 08:35:18,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:35:18,398 INFO:     Epoch: 9
2023-01-05 08:35:20,600 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4922039200862249, 'Total loss': 0.4922039200862249} | train loss {'Reaction outcome loss': 0.46935243359294493, 'Total loss': 0.46935243359294493}
2023-01-05 08:35:20,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:35:20,600 INFO:     Epoch: 10
2023-01-05 08:35:22,751 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.518281634648641, 'Total loss': 0.518281634648641} | train loss {'Reaction outcome loss': 0.47125913424120436, 'Total loss': 0.47125913424120436}
2023-01-05 08:35:22,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:35:22,752 INFO:     Epoch: 11
2023-01-05 08:35:24,908 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49028746287027997, 'Total loss': 0.49028746287027997} | train loss {'Reaction outcome loss': 0.45674319629314053, 'Total loss': 0.45674319629314053}
2023-01-05 08:35:24,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:35:24,908 INFO:     Epoch: 12
2023-01-05 08:35:27,073 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4775401612122854, 'Total loss': 0.4775401612122854} | train loss {'Reaction outcome loss': 0.4567884942651659, 'Total loss': 0.4567884942651659}
2023-01-05 08:35:27,074 INFO:     Found new best model at epoch 12
2023-01-05 08:35:27,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:35:27,075 INFO:     Epoch: 13
2023-01-05 08:35:29,235 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4726898322502772, 'Total loss': 0.4726898322502772} | train loss {'Reaction outcome loss': 0.4902326525391444, 'Total loss': 0.4902326525391444}
2023-01-05 08:35:29,235 INFO:     Found new best model at epoch 13
2023-01-05 08:35:29,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:35:29,237 INFO:     Epoch: 14
2023-01-05 08:35:31,402 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45616758465766905, 'Total loss': 0.45616758465766905} | train loss {'Reaction outcome loss': 0.4430385544192572, 'Total loss': 0.4430385544192572}
2023-01-05 08:35:31,402 INFO:     Found new best model at epoch 14
2023-01-05 08:35:31,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:35:31,403 INFO:     Epoch: 15
2023-01-05 08:35:33,553 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4660855064789454, 'Total loss': 0.4660855064789454} | train loss {'Reaction outcome loss': 0.4399906213705738, 'Total loss': 0.4399906213705738}
2023-01-05 08:35:33,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:35:33,553 INFO:     Epoch: 16
2023-01-05 08:35:35,716 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4588578224182129, 'Total loss': 0.4588578224182129} | train loss {'Reaction outcome loss': 0.4407510629946204, 'Total loss': 0.4407510629946204}
2023-01-05 08:35:35,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:35:35,717 INFO:     Epoch: 17
2023-01-05 08:35:37,868 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4755152811606725, 'Total loss': 0.4755152811606725} | train loss {'Reaction outcome loss': 0.4370347789583215, 'Total loss': 0.4370347789583215}
2023-01-05 08:35:37,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:35:37,869 INFO:     Epoch: 18
2023-01-05 08:35:40,019 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5046815345684688, 'Total loss': 0.5046815345684688} | train loss {'Reaction outcome loss': 0.44480246213683183, 'Total loss': 0.44480246213683183}
2023-01-05 08:35:40,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:35:40,019 INFO:     Epoch: 19
2023-01-05 08:35:42,189 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4773929586013158, 'Total loss': 0.4773929586013158} | train loss {'Reaction outcome loss': 0.4617669356497493, 'Total loss': 0.4617669356497493}
2023-01-05 08:35:42,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:35:42,189 INFO:     Epoch: 20
2023-01-05 08:35:44,346 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45975957016150154, 'Total loss': 0.45975957016150154} | train loss {'Reaction outcome loss': 0.42160807895487634, 'Total loss': 0.42160807895487634}
2023-01-05 08:35:44,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:35:44,347 INFO:     Epoch: 21
2023-01-05 08:35:46,502 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4525815322995186, 'Total loss': 0.4525815322995186} | train loss {'Reaction outcome loss': 0.4182847580928153, 'Total loss': 0.4182847580928153}
2023-01-05 08:35:46,503 INFO:     Found new best model at epoch 21
2023-01-05 08:35:46,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:35:46,504 INFO:     Epoch: 22
2023-01-05 08:35:48,649 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4598416348298391, 'Total loss': 0.4598416348298391} | train loss {'Reaction outcome loss': 0.4288797457365022, 'Total loss': 0.4288797457365022}
2023-01-05 08:35:48,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:35:48,649 INFO:     Epoch: 23
2023-01-05 08:35:50,817 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4850163559118907, 'Total loss': 0.4850163559118907} | train loss {'Reaction outcome loss': 0.44682147546900786, 'Total loss': 0.44682147546900786}
2023-01-05 08:35:50,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:35:50,818 INFO:     Epoch: 24
2023-01-05 08:35:52,964 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.47171662549177806, 'Total loss': 0.47171662549177806} | train loss {'Reaction outcome loss': 0.41374852879823226, 'Total loss': 0.41374852879823226}
2023-01-05 08:35:52,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:35:52,965 INFO:     Epoch: 25
2023-01-05 08:35:55,123 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4486443738142649, 'Total loss': 0.4486443738142649} | train loss {'Reaction outcome loss': 0.41140972873519943, 'Total loss': 0.41140972873519943}
2023-01-05 08:35:55,123 INFO:     Found new best model at epoch 25
2023-01-05 08:35:55,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:35:55,125 INFO:     Epoch: 26
2023-01-05 08:35:57,274 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44066673119862876, 'Total loss': 0.44066673119862876} | train loss {'Reaction outcome loss': 0.4057496430055387, 'Total loss': 0.4057496430055387}
2023-01-05 08:35:57,274 INFO:     Found new best model at epoch 26
2023-01-05 08:35:57,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:35:57,275 INFO:     Epoch: 27
2023-01-05 08:35:59,420 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43713884949684145, 'Total loss': 0.43713884949684145} | train loss {'Reaction outcome loss': 0.4278583418226976, 'Total loss': 0.4278583418226976}
2023-01-05 08:35:59,420 INFO:     Found new best model at epoch 27
2023-01-05 08:35:59,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:35:59,422 INFO:     Epoch: 28
2023-01-05 08:36:01,580 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4327648977438609, 'Total loss': 0.4327648977438609} | train loss {'Reaction outcome loss': 0.3973170090534225, 'Total loss': 0.3973170090534225}
2023-01-05 08:36:01,581 INFO:     Found new best model at epoch 28
2023-01-05 08:36:01,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:36:01,582 INFO:     Epoch: 29
2023-01-05 08:36:03,738 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4218324859937032, 'Total loss': 0.4218324859937032} | train loss {'Reaction outcome loss': 0.3939285676045377, 'Total loss': 0.3939285676045377}
2023-01-05 08:36:03,739 INFO:     Found new best model at epoch 29
2023-01-05 08:36:03,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:36:03,741 INFO:     Epoch: 30
2023-01-05 08:36:05,895 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4278045187393824, 'Total loss': 0.4278045187393824} | train loss {'Reaction outcome loss': 0.3895740117236594, 'Total loss': 0.3895740117236594}
2023-01-05 08:36:05,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:36:05,895 INFO:     Epoch: 31
2023-01-05 08:36:08,033 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.44083790977795917, 'Total loss': 0.44083790977795917} | train loss {'Reaction outcome loss': 0.3853640219574605, 'Total loss': 0.3853640219574605}
2023-01-05 08:36:08,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:36:08,034 INFO:     Epoch: 32
2023-01-05 08:36:10,187 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4739925463994344, 'Total loss': 0.4739925463994344} | train loss {'Reaction outcome loss': 0.38651156717695406, 'Total loss': 0.38651156717695406}
2023-01-05 08:36:10,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:36:10,187 INFO:     Epoch: 33
2023-01-05 08:36:12,328 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.45287800232569375, 'Total loss': 0.45287800232569375} | train loss {'Reaction outcome loss': 0.3787272478554202, 'Total loss': 0.3787272478554202}
2023-01-05 08:36:12,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:36:12,328 INFO:     Epoch: 34
2023-01-05 08:36:14,488 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42185094753901164, 'Total loss': 0.42185094753901164} | train loss {'Reaction outcome loss': 0.37497603634382476, 'Total loss': 0.37497603634382476}
2023-01-05 08:36:14,489 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:36:14,489 INFO:     Epoch: 35
2023-01-05 08:36:16,656 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4276117473840714, 'Total loss': 0.4276117473840714} | train loss {'Reaction outcome loss': 0.3716028721706159, 'Total loss': 0.3716028721706159}
2023-01-05 08:36:16,656 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:36:16,656 INFO:     Epoch: 36
2023-01-05 08:36:18,806 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42895746529102324, 'Total loss': 0.42895746529102324} | train loss {'Reaction outcome loss': 0.3712044037014678, 'Total loss': 0.3712044037014678}
2023-01-05 08:36:18,806 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:36:18,806 INFO:     Epoch: 37
2023-01-05 08:36:20,974 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4111986517906189, 'Total loss': 0.4111986517906189} | train loss {'Reaction outcome loss': 0.3655588942321787, 'Total loss': 0.3655588942321787}
2023-01-05 08:36:20,974 INFO:     Found new best model at epoch 37
2023-01-05 08:36:20,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:36:20,976 INFO:     Epoch: 38
2023-01-05 08:36:23,157 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4704609473546346, 'Total loss': 0.4704609473546346} | train loss {'Reaction outcome loss': 0.3628702818220346, 'Total loss': 0.3628702818220346}
2023-01-05 08:36:23,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:36:23,157 INFO:     Epoch: 39
2023-01-05 08:36:25,354 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42399224936962127, 'Total loss': 0.42399224936962127} | train loss {'Reaction outcome loss': 0.35949631683794997, 'Total loss': 0.35949631683794997}
2023-01-05 08:36:25,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:36:25,355 INFO:     Epoch: 40
2023-01-05 08:36:27,512 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42554745376110076, 'Total loss': 0.42554745376110076} | train loss {'Reaction outcome loss': 0.3510178766918598, 'Total loss': 0.3510178766918598}
2023-01-05 08:36:27,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:36:27,512 INFO:     Epoch: 41
2023-01-05 08:36:29,680 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4517922639846802, 'Total loss': 0.4517922639846802} | train loss {'Reaction outcome loss': 0.3518414418892159, 'Total loss': 0.3518414418892159}
2023-01-05 08:36:29,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:36:29,680 INFO:     Epoch: 42
2023-01-05 08:36:31,822 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4447585145632426, 'Total loss': 0.4447585145632426} | train loss {'Reaction outcome loss': 0.3512950650001585, 'Total loss': 0.3512950650001585}
2023-01-05 08:36:31,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:36:31,823 INFO:     Epoch: 43
2023-01-05 08:36:33,981 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41704695820808413, 'Total loss': 0.41704695820808413} | train loss {'Reaction outcome loss': 0.3447515339307163, 'Total loss': 0.3447515339307163}
2023-01-05 08:36:33,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:36:33,982 INFO:     Epoch: 44
2023-01-05 08:36:36,125 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42119577129681907, 'Total loss': 0.42119577129681907} | train loss {'Reaction outcome loss': 0.34614600910656695, 'Total loss': 0.34614600910656695}
2023-01-05 08:36:36,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:36:36,125 INFO:     Epoch: 45
2023-01-05 08:36:38,278 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41318849424521126, 'Total loss': 0.41318849424521126} | train loss {'Reaction outcome loss': 0.343582206081761, 'Total loss': 0.343582206081761}
2023-01-05 08:36:38,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:36:38,279 INFO:     Epoch: 46
2023-01-05 08:36:40,462 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.46681113690137865, 'Total loss': 0.46681113690137865} | train loss {'Reaction outcome loss': 0.35304582090306, 'Total loss': 0.35304582090306}
2023-01-05 08:36:40,462 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:36:40,462 INFO:     Epoch: 47
2023-01-05 08:36:42,609 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43688739140828453, 'Total loss': 0.43688739140828453} | train loss {'Reaction outcome loss': 0.34197162116027396, 'Total loss': 0.34197162116027396}
2023-01-05 08:36:42,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:36:42,609 INFO:     Epoch: 48
2023-01-05 08:36:44,783 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.43527860641479493, 'Total loss': 0.43527860641479493} | train loss {'Reaction outcome loss': 0.3453322131927184, 'Total loss': 0.3453322131927184}
2023-01-05 08:36:44,784 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:36:44,784 INFO:     Epoch: 49
2023-01-05 08:36:46,932 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.41049396296342217, 'Total loss': 0.41049396296342217} | train loss {'Reaction outcome loss': 0.34170131987377605, 'Total loss': 0.34170131987377605}
2023-01-05 08:36:46,933 INFO:     Found new best model at epoch 49
2023-01-05 08:36:46,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:36:46,934 INFO:     Epoch: 50
2023-01-05 08:36:49,104 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4627916177113851, 'Total loss': 0.4627916177113851} | train loss {'Reaction outcome loss': 0.33025280876166146, 'Total loss': 0.33025280876166146}
2023-01-05 08:36:49,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:36:49,105 INFO:     Epoch: 51
2023-01-05 08:36:51,260 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40869506597518923, 'Total loss': 0.40869506597518923} | train loss {'Reaction outcome loss': 0.32602990201026527, 'Total loss': 0.32602990201026527}
2023-01-05 08:36:51,261 INFO:     Found new best model at epoch 51
2023-01-05 08:36:51,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:36:51,262 INFO:     Epoch: 52
2023-01-05 08:36:53,438 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39833667278289797, 'Total loss': 0.39833667278289797} | train loss {'Reaction outcome loss': 0.3252146681420593, 'Total loss': 0.3252146681420593}
2023-01-05 08:36:53,438 INFO:     Found new best model at epoch 52
2023-01-05 08:36:53,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:36:53,439 INFO:     Epoch: 53
2023-01-05 08:36:55,588 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4154843697945277, 'Total loss': 0.4154843697945277} | train loss {'Reaction outcome loss': 0.3163174705679816, 'Total loss': 0.3163174705679816}
2023-01-05 08:36:55,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:36:55,588 INFO:     Epoch: 54
2023-01-05 08:36:57,746 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4195533975958824, 'Total loss': 0.4195533975958824} | train loss {'Reaction outcome loss': 0.3243043787450111, 'Total loss': 0.3243043787450111}
2023-01-05 08:36:57,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:36:57,746 INFO:     Epoch: 55
2023-01-05 08:36:59,936 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44560773273309073, 'Total loss': 0.44560773273309073} | train loss {'Reaction outcome loss': 0.3211581589033206, 'Total loss': 0.3211581589033206}
2023-01-05 08:36:59,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:36:59,936 INFO:     Epoch: 56
2023-01-05 08:37:02,093 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4360561619202296, 'Total loss': 0.4360561619202296} | train loss {'Reaction outcome loss': 0.36354617414273915, 'Total loss': 0.36354617414273915}
2023-01-05 08:37:02,094 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:37:02,094 INFO:     Epoch: 57
2023-01-05 08:37:04,251 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4207329213619232, 'Total loss': 0.4207329213619232} | train loss {'Reaction outcome loss': 0.3225667838663524, 'Total loss': 0.3225667838663524}
2023-01-05 08:37:04,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:37:04,252 INFO:     Epoch: 58
2023-01-05 08:37:06,392 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.39452799956003826, 'Total loss': 0.39452799956003826} | train loss {'Reaction outcome loss': 0.3114689475615455, 'Total loss': 0.3114689475615455}
2023-01-05 08:37:06,392 INFO:     Found new best model at epoch 58
2023-01-05 08:37:06,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:37:06,393 INFO:     Epoch: 59
2023-01-05 08:37:08,549 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42477362950642905, 'Total loss': 0.42477362950642905} | train loss {'Reaction outcome loss': 0.3086950999630431, 'Total loss': 0.3086950999630431}
2023-01-05 08:37:08,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:37:08,549 INFO:     Epoch: 60
2023-01-05 08:37:10,686 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40739708542823794, 'Total loss': 0.40739708542823794} | train loss {'Reaction outcome loss': 0.31007046372616204, 'Total loss': 0.31007046372616204}
2023-01-05 08:37:10,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:37:10,686 INFO:     Epoch: 61
2023-01-05 08:37:12,846 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43530830343564353, 'Total loss': 0.43530830343564353} | train loss {'Reaction outcome loss': 0.3025264077177912, 'Total loss': 0.3025264077177912}
2023-01-05 08:37:12,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:37:12,846 INFO:     Epoch: 62
2023-01-05 08:37:15,015 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4127478688955307, 'Total loss': 0.4127478688955307} | train loss {'Reaction outcome loss': 0.306353312932871, 'Total loss': 0.306353312932871}
2023-01-05 08:37:15,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:37:15,015 INFO:     Epoch: 63
2023-01-05 08:37:17,203 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4076378067334493, 'Total loss': 0.4076378067334493} | train loss {'Reaction outcome loss': 0.30941030702999106, 'Total loss': 0.30941030702999106}
2023-01-05 08:37:17,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:37:17,203 INFO:     Epoch: 64
2023-01-05 08:37:19,353 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4313317358493805, 'Total loss': 0.4313317358493805} | train loss {'Reaction outcome loss': 0.3093556671882507, 'Total loss': 0.3093556671882507}
2023-01-05 08:37:19,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:37:19,354 INFO:     Epoch: 65
2023-01-05 08:37:21,508 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.39181005756060283, 'Total loss': 0.39181005756060283} | train loss {'Reaction outcome loss': 0.30682453498298273, 'Total loss': 0.30682453498298273}
2023-01-05 08:37:21,509 INFO:     Found new best model at epoch 65
2023-01-05 08:37:21,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:37:21,510 INFO:     Epoch: 66
2023-01-05 08:37:23,691 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4161499679088593, 'Total loss': 0.4161499679088593} | train loss {'Reaction outcome loss': 0.3360132067964028, 'Total loss': 0.3360132067964028}
2023-01-05 08:37:23,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:37:23,691 INFO:     Epoch: 67
2023-01-05 08:37:25,862 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.408685968319575, 'Total loss': 0.408685968319575} | train loss {'Reaction outcome loss': 0.301128140758669, 'Total loss': 0.301128140758669}
2023-01-05 08:37:25,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:37:25,862 INFO:     Epoch: 68
2023-01-05 08:37:28,053 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4049388160308202, 'Total loss': 0.4049388160308202} | train loss {'Reaction outcome loss': 0.2979832208452733, 'Total loss': 0.2979832208452733}
2023-01-05 08:37:28,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:37:28,054 INFO:     Epoch: 69
2023-01-05 08:37:30,227 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3988941301902135, 'Total loss': 0.3988941301902135} | train loss {'Reaction outcome loss': 0.28752799666078016, 'Total loss': 0.28752799666078016}
2023-01-05 08:37:30,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:37:30,227 INFO:     Epoch: 70
2023-01-05 08:37:32,391 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39433353034158547, 'Total loss': 0.39433353034158547} | train loss {'Reaction outcome loss': 0.29577789104719093, 'Total loss': 0.29577789104719093}
2023-01-05 08:37:32,391 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:37:32,391 INFO:     Epoch: 71
2023-01-05 08:37:34,561 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.41357207943995794, 'Total loss': 0.41357207943995794} | train loss {'Reaction outcome loss': 0.3139646945477369, 'Total loss': 0.3139646945477369}
2023-01-05 08:37:34,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:37:34,561 INFO:     Epoch: 72
2023-01-05 08:37:36,723 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3955778380235036, 'Total loss': 0.3955778380235036} | train loss {'Reaction outcome loss': 0.2835939232303434, 'Total loss': 0.2835939232303434}
2023-01-05 08:37:36,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:37:36,724 INFO:     Epoch: 73
2023-01-05 08:37:38,895 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4164273788531621, 'Total loss': 0.4164273788531621} | train loss {'Reaction outcome loss': 0.2865295808119497, 'Total loss': 0.2865295808119497}
2023-01-05 08:37:38,895 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:37:38,896 INFO:     Epoch: 74
2023-01-05 08:37:41,059 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3894487013419469, 'Total loss': 0.3894487013419469} | train loss {'Reaction outcome loss': 0.28956286044611235, 'Total loss': 0.28956286044611235}
2023-01-05 08:37:41,060 INFO:     Found new best model at epoch 74
2023-01-05 08:37:41,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:37:41,062 INFO:     Epoch: 75
2023-01-05 08:37:42,998 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.43266343971093496, 'Total loss': 0.43266343971093496} | train loss {'Reaction outcome loss': 0.2888794968755552, 'Total loss': 0.2888794968755552}
2023-01-05 08:37:42,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:37:42,999 INFO:     Epoch: 76
2023-01-05 08:37:45,141 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3967605988184611, 'Total loss': 0.3967605988184611} | train loss {'Reaction outcome loss': 0.29730740857675025, 'Total loss': 0.29730740857675025}
2023-01-05 08:37:45,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:37:45,141 INFO:     Epoch: 77
2023-01-05 08:37:47,290 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4061119884252548, 'Total loss': 0.4061119884252548} | train loss {'Reaction outcome loss': 0.3560427931252111, 'Total loss': 0.3560427931252111}
2023-01-05 08:37:47,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:37:47,291 INFO:     Epoch: 78
2023-01-05 08:37:49,446 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4176176091035207, 'Total loss': 0.4176176091035207} | train loss {'Reaction outcome loss': 0.2936341934286959, 'Total loss': 0.2936341934286959}
2023-01-05 08:37:49,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:37:49,446 INFO:     Epoch: 79
2023-01-05 08:37:51,593 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.41979847848415375, 'Total loss': 0.41979847848415375} | train loss {'Reaction outcome loss': 0.2939097320612864, 'Total loss': 0.2939097320612864}
2023-01-05 08:37:51,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:37:51,594 INFO:     Epoch: 80
2023-01-05 08:37:53,734 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4675714870293935, 'Total loss': 0.4675714870293935} | train loss {'Reaction outcome loss': 0.29142651821409044, 'Total loss': 0.29142651821409044}
2023-01-05 08:37:53,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:37:53,735 INFO:     Epoch: 81
2023-01-05 08:37:55,882 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4194069276253382, 'Total loss': 0.4194069276253382} | train loss {'Reaction outcome loss': 0.28364027672163816, 'Total loss': 0.28364027672163816}
2023-01-05 08:37:55,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:37:55,883 INFO:     Epoch: 82
2023-01-05 08:37:58,029 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3933454225460688, 'Total loss': 0.3933454225460688} | train loss {'Reaction outcome loss': 0.27984695247226005, 'Total loss': 0.27984695247226005}
2023-01-05 08:37:58,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:37:58,030 INFO:     Epoch: 83
2023-01-05 08:38:00,178 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41822111904621123, 'Total loss': 0.41822111904621123} | train loss {'Reaction outcome loss': 0.2800505268724932, 'Total loss': 0.2800505268724932}
2023-01-05 08:38:00,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:38:00,178 INFO:     Epoch: 84
2023-01-05 08:38:02,335 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38912443319956463, 'Total loss': 0.38912443319956463} | train loss {'Reaction outcome loss': 0.27312869312827126, 'Total loss': 0.27312869312827126}
2023-01-05 08:38:02,336 INFO:     Found new best model at epoch 84
2023-01-05 08:38:02,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:38:02,337 INFO:     Epoch: 85
2023-01-05 08:38:04,482 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3928113808234533, 'Total loss': 0.3928113808234533} | train loss {'Reaction outcome loss': 0.2741014787347724, 'Total loss': 0.2741014787347724}
2023-01-05 08:38:04,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:38:04,482 INFO:     Epoch: 86
2023-01-05 08:38:06,629 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.408707590897878, 'Total loss': 0.408707590897878} | train loss {'Reaction outcome loss': 0.27820785420582345, 'Total loss': 0.27820785420582345}
2023-01-05 08:38:06,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:38:06,629 INFO:     Epoch: 87
2023-01-05 08:38:08,786 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3861330250898997, 'Total loss': 0.3861330250898997} | train loss {'Reaction outcome loss': 0.2745560953567358, 'Total loss': 0.2745560953567358}
2023-01-05 08:38:08,786 INFO:     Found new best model at epoch 87
2023-01-05 08:38:08,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:38:08,787 INFO:     Epoch: 88
2023-01-05 08:38:10,955 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4063816428184509, 'Total loss': 0.4063816428184509} | train loss {'Reaction outcome loss': 0.26959870667179936, 'Total loss': 0.26959870667179936}
2023-01-05 08:38:10,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:38:10,956 INFO:     Epoch: 89
2023-01-05 08:38:13,147 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4257223854462306, 'Total loss': 0.4257223854462306} | train loss {'Reaction outcome loss': 0.2734426374174317, 'Total loss': 0.2734426374174317}
2023-01-05 08:38:13,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:38:13,147 INFO:     Epoch: 90
2023-01-05 08:38:15,290 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3858937342961629, 'Total loss': 0.3858937342961629} | train loss {'Reaction outcome loss': 0.2758369880417983, 'Total loss': 0.2758369880417983}
2023-01-05 08:38:15,290 INFO:     Found new best model at epoch 90
2023-01-05 08:38:15,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:38:15,291 INFO:     Epoch: 91
2023-01-05 08:38:17,439 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.36070523659388226, 'Total loss': 0.36070523659388226} | train loss {'Reaction outcome loss': 0.2962909569673618, 'Total loss': 0.2962909569673618}
2023-01-05 08:38:17,439 INFO:     Found new best model at epoch 91
2023-01-05 08:38:17,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:38:17,440 INFO:     Epoch: 92
2023-01-05 08:38:19,583 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4501799583435059, 'Total loss': 0.4501799583435059} | train loss {'Reaction outcome loss': 0.27221693782089657, 'Total loss': 0.27221693782089657}
2023-01-05 08:38:19,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:38:19,583 INFO:     Epoch: 93
2023-01-05 08:38:21,742 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.38916240135828656, 'Total loss': 0.38916240135828656} | train loss {'Reaction outcome loss': 0.26006050323576346, 'Total loss': 0.26006050323576346}
2023-01-05 08:38:21,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:38:21,742 INFO:     Epoch: 94
2023-01-05 08:38:23,885 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.39677993059158323, 'Total loss': 0.39677993059158323} | train loss {'Reaction outcome loss': 0.26316378842306143, 'Total loss': 0.26316378842306143}
2023-01-05 08:38:23,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:38:23,886 INFO:     Epoch: 95
2023-01-05 08:38:26,049 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3842526396115621, 'Total loss': 0.3842526396115621} | train loss {'Reaction outcome loss': 0.266345446653416, 'Total loss': 0.266345446653416}
2023-01-05 08:38:26,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:38:26,049 INFO:     Epoch: 96
2023-01-05 08:38:28,200 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4143420388301214, 'Total loss': 0.4143420388301214} | train loss {'Reaction outcome loss': 0.2640738788168823, 'Total loss': 0.2640738788168823}
2023-01-05 08:38:28,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:38:28,201 INFO:     Epoch: 97
2023-01-05 08:38:30,328 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3895666052897771, 'Total loss': 0.3895666052897771} | train loss {'Reaction outcome loss': 0.25990428764076123, 'Total loss': 0.25990428764076123}
2023-01-05 08:38:30,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:38:30,329 INFO:     Epoch: 98
2023-01-05 08:38:32,498 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41164309332768123, 'Total loss': 0.41164309332768123} | train loss {'Reaction outcome loss': 0.25956926102061634, 'Total loss': 0.25956926102061634}
2023-01-05 08:38:32,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:38:32,499 INFO:     Epoch: 99
2023-01-05 08:38:34,660 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3845716521143913, 'Total loss': 0.3845716521143913} | train loss {'Reaction outcome loss': 0.2606207549544996, 'Total loss': 0.2606207549544996}
2023-01-05 08:38:34,661 INFO:     Best model found after epoch 92 of 100.
2023-01-05 08:38:34,661 INFO:   Done with stage: TRAINING
2023-01-05 08:38:34,661 INFO:   Starting stage: EVALUATION
2023-01-05 08:38:34,793 INFO:   Done with stage: EVALUATION
2023-01-05 08:38:34,793 INFO:   Leaving out SEQ value Fold_6
2023-01-05 08:38:34,806 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 08:38:34,806 INFO:   Starting stage: FEATURE SCALING
2023-01-05 08:38:35,464 INFO:   Done with stage: FEATURE SCALING
2023-01-05 08:38:35,464 INFO:   Starting stage: SCALING TARGETS
2023-01-05 08:38:35,535 INFO:   Done with stage: SCALING TARGETS
2023-01-05 08:38:35,535 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:38:35,535 INFO:     No hyperparam tuning for this model
2023-01-05 08:38:35,535 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:38:35,535 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 08:38:35,536 INFO:     None feature selector for col prot
2023-01-05 08:38:35,536 INFO:     None feature selector for col prot
2023-01-05 08:38:35,536 INFO:     None feature selector for col prot
2023-01-05 08:38:35,537 INFO:     None feature selector for col chem
2023-01-05 08:38:35,537 INFO:     None feature selector for col chem
2023-01-05 08:38:35,537 INFO:     None feature selector for col chem
2023-01-05 08:38:35,537 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 08:38:35,537 INFO:   Starting stage: BUILD MODEL
2023-01-05 08:38:35,538 INFO:     Number of params in model 72901
2023-01-05 08:38:35,542 INFO:   Done with stage: BUILD MODEL
2023-01-05 08:38:35,542 INFO:   Starting stage: TRAINING
2023-01-05 08:38:35,602 INFO:     Val loss before train {'Reaction outcome loss': 1.018391458193461, 'Total loss': 1.018391458193461}
2023-01-05 08:38:35,602 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:38:35,602 INFO:     Epoch: 0
2023-01-05 08:38:37,765 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8532644947369893, 'Total loss': 0.8532644947369893} | train loss {'Reaction outcome loss': 0.9367432218811572, 'Total loss': 0.9367432218811572}
2023-01-05 08:38:37,765 INFO:     Found new best model at epoch 0
2023-01-05 08:38:37,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:38:37,766 INFO:     Epoch: 1
2023-01-05 08:38:39,923 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.622011133035024, 'Total loss': 0.622011133035024} | train loss {'Reaction outcome loss': 0.7457265828060329, 'Total loss': 0.7457265828060329}
2023-01-05 08:38:39,924 INFO:     Found new best model at epoch 1
2023-01-05 08:38:39,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:38:39,925 INFO:     Epoch: 2
2023-01-05 08:38:42,082 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5525892972946167, 'Total loss': 0.5525892972946167} | train loss {'Reaction outcome loss': 0.5823883404585428, 'Total loss': 0.5823883404585428}
2023-01-05 08:38:42,082 INFO:     Found new best model at epoch 2
2023-01-05 08:38:42,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:38:42,083 INFO:     Epoch: 3
2023-01-05 08:38:44,249 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5390326023101807, 'Total loss': 0.5390326023101807} | train loss {'Reaction outcome loss': 0.5324579236847399, 'Total loss': 0.5324579236847399}
2023-01-05 08:38:44,249 INFO:     Found new best model at epoch 3
2023-01-05 08:38:44,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:38:44,250 INFO:     Epoch: 4
2023-01-05 08:38:46,438 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5217093586921692, 'Total loss': 0.5217093586921692} | train loss {'Reaction outcome loss': 0.5093356085813433, 'Total loss': 0.5093356085813433}
2023-01-05 08:38:46,438 INFO:     Found new best model at epoch 4
2023-01-05 08:38:46,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:38:46,439 INFO:     Epoch: 5
2023-01-05 08:38:48,606 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5288717250029246, 'Total loss': 0.5288717250029246} | train loss {'Reaction outcome loss': 0.49566721023204957, 'Total loss': 0.49566721023204957}
2023-01-05 08:38:48,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:38:48,607 INFO:     Epoch: 6
2023-01-05 08:38:50,766 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5331810454527537, 'Total loss': 0.5331810454527537} | train loss {'Reaction outcome loss': 0.48700303409504114, 'Total loss': 0.48700303409504114}
2023-01-05 08:38:50,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:38:50,766 INFO:     Epoch: 7
2023-01-05 08:38:52,930 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5312150935331981, 'Total loss': 0.5312150935331981} | train loss {'Reaction outcome loss': 0.47928528234846757, 'Total loss': 0.47928528234846757}
2023-01-05 08:38:52,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:38:52,930 INFO:     Epoch: 8
2023-01-05 08:38:55,089 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5006161292394002, 'Total loss': 0.5006161292394002} | train loss {'Reaction outcome loss': 0.47151812695854406, 'Total loss': 0.47151812695854406}
2023-01-05 08:38:55,089 INFO:     Found new best model at epoch 8
2023-01-05 08:38:55,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:38:55,090 INFO:     Epoch: 9
2023-01-05 08:38:57,270 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.497103222211202, 'Total loss': 0.497103222211202} | train loss {'Reaction outcome loss': 0.4644037037011949, 'Total loss': 0.4644037037011949}
2023-01-05 08:38:57,271 INFO:     Found new best model at epoch 9
2023-01-05 08:38:57,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:38:57,272 INFO:     Epoch: 10
2023-01-05 08:38:59,454 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5073372582594554, 'Total loss': 0.5073372582594554} | train loss {'Reaction outcome loss': 0.46210843351558656, 'Total loss': 0.46210843351558656}
2023-01-05 08:38:59,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:38:59,454 INFO:     Epoch: 11
2023-01-05 08:39:01,634 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5232143819332122, 'Total loss': 0.5232143819332122} | train loss {'Reaction outcome loss': 0.450224964358316, 'Total loss': 0.450224964358316}
2023-01-05 08:39:01,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:39:01,635 INFO:     Epoch: 12
2023-01-05 08:39:03,794 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5130511452754338, 'Total loss': 0.5130511452754338} | train loss {'Reaction outcome loss': 0.4470426291496315, 'Total loss': 0.4470426291496315}
2023-01-05 08:39:03,795 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:39:03,795 INFO:     Epoch: 13
2023-01-05 08:39:05,946 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5048435191313426, 'Total loss': 0.5048435191313426} | train loss {'Reaction outcome loss': 0.4433412503464558, 'Total loss': 0.4433412503464558}
2023-01-05 08:39:05,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:39:05,947 INFO:     Epoch: 14
2023-01-05 08:39:08,116 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.49938406149546305, 'Total loss': 0.49938406149546305} | train loss {'Reaction outcome loss': 0.4427671639067171, 'Total loss': 0.4427671639067171}
2023-01-05 08:39:08,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:39:08,117 INFO:     Epoch: 15
2023-01-05 08:39:10,287 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5063162396351496, 'Total loss': 0.5063162396351496} | train loss {'Reaction outcome loss': 0.4290405438964117, 'Total loss': 0.4290405438964117}
2023-01-05 08:39:10,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:39:10,287 INFO:     Epoch: 16
2023-01-05 08:39:12,460 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5045686562856039, 'Total loss': 0.5045686562856039} | train loss {'Reaction outcome loss': 0.4262741226366711, 'Total loss': 0.4262741226366711}
2023-01-05 08:39:12,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:39:12,460 INFO:     Epoch: 17
2023-01-05 08:39:14,632 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49773177603880564, 'Total loss': 0.49773177603880564} | train loss {'Reaction outcome loss': 0.4234643747714022, 'Total loss': 0.4234643747714022}
2023-01-05 08:39:14,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:39:14,633 INFO:     Epoch: 18
2023-01-05 08:39:16,774 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.48813742995262144, 'Total loss': 0.48813742995262144} | train loss {'Reaction outcome loss': 0.42332886721575735, 'Total loss': 0.42332886721575735}
2023-01-05 08:39:16,774 INFO:     Found new best model at epoch 18
2023-01-05 08:39:16,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:39:16,776 INFO:     Epoch: 19
2023-01-05 08:39:18,958 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47213170528411863, 'Total loss': 0.47213170528411863} | train loss {'Reaction outcome loss': 0.41683448044186466, 'Total loss': 0.41683448044186466}
2023-01-05 08:39:18,958 INFO:     Found new best model at epoch 19
2023-01-05 08:39:18,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:39:18,959 INFO:     Epoch: 20
2023-01-05 08:39:21,128 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4909346262613932, 'Total loss': 0.4909346262613932} | train loss {'Reaction outcome loss': 0.41008574359576194, 'Total loss': 0.41008574359576194}
2023-01-05 08:39:21,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:39:21,128 INFO:     Epoch: 21
2023-01-05 08:39:23,307 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4677478780349096, 'Total loss': 0.4677478780349096} | train loss {'Reaction outcome loss': 0.40366165049454794, 'Total loss': 0.40366165049454794}
2023-01-05 08:39:23,307 INFO:     Found new best model at epoch 21
2023-01-05 08:39:23,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:39:23,308 INFO:     Epoch: 22
2023-01-05 08:39:25,475 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.48309692939122517, 'Total loss': 0.48309692939122517} | train loss {'Reaction outcome loss': 0.4037198005277758, 'Total loss': 0.4037198005277758}
2023-01-05 08:39:25,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:39:25,475 INFO:     Epoch: 23
2023-01-05 08:39:27,698 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.515254137913386, 'Total loss': 0.515254137913386} | train loss {'Reaction outcome loss': 0.39732389149360275, 'Total loss': 0.39732389149360275}
2023-01-05 08:39:27,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:39:27,699 INFO:     Epoch: 24
2023-01-05 08:39:29,882 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.469385439157486, 'Total loss': 0.469385439157486} | train loss {'Reaction outcome loss': 0.39554635957152406, 'Total loss': 0.39554635957152406}
2023-01-05 08:39:29,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:39:29,882 INFO:     Epoch: 25
2023-01-05 08:39:32,031 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4519666035970052, 'Total loss': 0.4519666035970052} | train loss {'Reaction outcome loss': 0.38629865842713346, 'Total loss': 0.38629865842713346}
2023-01-05 08:39:32,031 INFO:     Found new best model at epoch 25
2023-01-05 08:39:32,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:39:32,032 INFO:     Epoch: 26
2023-01-05 08:39:34,200 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4934395064910253, 'Total loss': 0.4934395064910253} | train loss {'Reaction outcome loss': 0.38583281515199785, 'Total loss': 0.38583281515199785}
2023-01-05 08:39:34,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:39:34,201 INFO:     Epoch: 27
2023-01-05 08:39:36,375 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4899471640586853, 'Total loss': 0.4899471640586853} | train loss {'Reaction outcome loss': 0.3853098445770327, 'Total loss': 0.3853098445770327}
2023-01-05 08:39:36,375 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:39:36,376 INFO:     Epoch: 28
2023-01-05 08:39:38,547 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4646272321542104, 'Total loss': 0.4646272321542104} | train loss {'Reaction outcome loss': 0.371725543338254, 'Total loss': 0.371725543338254}
2023-01-05 08:39:38,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:39:38,548 INFO:     Epoch: 29
2023-01-05 08:39:40,698 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46915883123874663, 'Total loss': 0.46915883123874663} | train loss {'Reaction outcome loss': 0.37732022392835857, 'Total loss': 0.37732022392835857}
2023-01-05 08:39:40,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:39:40,699 INFO:     Epoch: 30
2023-01-05 08:39:42,861 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.47500511407852175, 'Total loss': 0.47500511407852175} | train loss {'Reaction outcome loss': 0.36881491777214764, 'Total loss': 0.36881491777214764}
2023-01-05 08:39:42,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:39:42,862 INFO:     Epoch: 31
2023-01-05 08:39:45,016 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47148786584536234, 'Total loss': 0.47148786584536234} | train loss {'Reaction outcome loss': 0.36853989133012854, 'Total loss': 0.36853989133012854}
2023-01-05 08:39:45,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:39:45,017 INFO:     Epoch: 32
2023-01-05 08:39:47,192 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4799619853496552, 'Total loss': 0.4799619853496552} | train loss {'Reaction outcome loss': 0.35976302923654824, 'Total loss': 0.35976302923654824}
2023-01-05 08:39:47,192 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:39:47,192 INFO:     Epoch: 33
2023-01-05 08:39:49,369 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4615347435077031, 'Total loss': 0.4615347435077031} | train loss {'Reaction outcome loss': 0.35955397765881747, 'Total loss': 0.35955397765881747}
2023-01-05 08:39:49,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:39:49,370 INFO:     Epoch: 34
2023-01-05 08:39:51,541 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.44908032615979515, 'Total loss': 0.44908032615979515} | train loss {'Reaction outcome loss': 0.3546058672752621, 'Total loss': 0.3546058672752621}
2023-01-05 08:39:51,541 INFO:     Found new best model at epoch 34
2023-01-05 08:39:51,542 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:39:51,542 INFO:     Epoch: 35
2023-01-05 08:39:53,706 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4586511174837748, 'Total loss': 0.4586511174837748} | train loss {'Reaction outcome loss': 0.3526348823997518, 'Total loss': 0.3526348823997518}
2023-01-05 08:39:53,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:39:53,707 INFO:     Epoch: 36
2023-01-05 08:39:55,857 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45479290982087456, 'Total loss': 0.45479290982087456} | train loss {'Reaction outcome loss': 0.35695525971560704, 'Total loss': 0.35695525971560704}
2023-01-05 08:39:55,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:39:55,858 INFO:     Epoch: 37
2023-01-05 08:39:58,014 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4624327838420868, 'Total loss': 0.4624327838420868} | train loss {'Reaction outcome loss': 0.34339359238582395, 'Total loss': 0.34339359238582395}
2023-01-05 08:39:58,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:39:58,015 INFO:     Epoch: 38
2023-01-05 08:40:00,186 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4723940432071686, 'Total loss': 0.4723940432071686} | train loss {'Reaction outcome loss': 0.3400539195548326, 'Total loss': 0.3400539195548326}
2023-01-05 08:40:00,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:40:00,186 INFO:     Epoch: 39
2023-01-05 08:40:02,338 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4909043471018473, 'Total loss': 0.4909043471018473} | train loss {'Reaction outcome loss': 0.34101449792350674, 'Total loss': 0.34101449792350674}
2023-01-05 08:40:02,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:40:02,339 INFO:     Epoch: 40
2023-01-05 08:40:04,472 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44389997820059457, 'Total loss': 0.44389997820059457} | train loss {'Reaction outcome loss': 0.3394071572335834, 'Total loss': 0.3394071572335834}
2023-01-05 08:40:04,473 INFO:     Found new best model at epoch 40
2023-01-05 08:40:04,474 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:40:04,474 INFO:     Epoch: 41
2023-01-05 08:40:06,635 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4448809802532196, 'Total loss': 0.4448809802532196} | train loss {'Reaction outcome loss': 0.3290351190291587, 'Total loss': 0.3290351190291587}
2023-01-05 08:40:06,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:40:06,635 INFO:     Epoch: 42
2023-01-05 08:40:08,801 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.45243659019470217, 'Total loss': 0.45243659019470217} | train loss {'Reaction outcome loss': 0.3275774903326473, 'Total loss': 0.3275774903326473}
2023-01-05 08:40:08,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:40:08,801 INFO:     Epoch: 43
2023-01-05 08:40:10,954 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4497551113367081, 'Total loss': 0.4497551113367081} | train loss {'Reaction outcome loss': 0.3327402519700975, 'Total loss': 0.3327402519700975}
2023-01-05 08:40:10,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:40:10,955 INFO:     Epoch: 44
2023-01-05 08:40:13,113 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4659057676792145, 'Total loss': 0.4659057676792145} | train loss {'Reaction outcome loss': 0.3249229127104102, 'Total loss': 0.3249229127104102}
2023-01-05 08:40:13,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:40:13,113 INFO:     Epoch: 45
2023-01-05 08:40:15,250 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4157023141781489, 'Total loss': 0.4157023141781489} | train loss {'Reaction outcome loss': 0.3108818287749368, 'Total loss': 0.3108818287749368}
2023-01-05 08:40:15,250 INFO:     Found new best model at epoch 45
2023-01-05 08:40:15,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:40:15,252 INFO:     Epoch: 46
2023-01-05 08:40:17,424 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4623683492342631, 'Total loss': 0.4623683492342631} | train loss {'Reaction outcome loss': 0.3160925965339268, 'Total loss': 0.3160925965339268}
2023-01-05 08:40:17,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:40:17,425 INFO:     Epoch: 47
2023-01-05 08:40:19,594 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4618418037891388, 'Total loss': 0.4618418037891388} | train loss {'Reaction outcome loss': 0.30828392238016594, 'Total loss': 0.30828392238016594}
2023-01-05 08:40:19,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:40:19,594 INFO:     Epoch: 48
2023-01-05 08:40:21,764 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4395833104848862, 'Total loss': 0.4395833104848862} | train loss {'Reaction outcome loss': 0.31464732021416136, 'Total loss': 0.31464732021416136}
2023-01-05 08:40:21,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:40:21,764 INFO:     Epoch: 49
2023-01-05 08:40:23,938 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4388110230366389, 'Total loss': 0.4388110230366389} | train loss {'Reaction outcome loss': 0.30524112144317006, 'Total loss': 0.30524112144317006}
2023-01-05 08:40:23,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:40:23,939 INFO:     Epoch: 50
2023-01-05 08:40:26,075 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.45647871494293213, 'Total loss': 0.45647871494293213} | train loss {'Reaction outcome loss': 0.3067585629972525, 'Total loss': 0.3067585629972525}
2023-01-05 08:40:26,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:40:26,076 INFO:     Epoch: 51
2023-01-05 08:40:28,227 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4029790788888931, 'Total loss': 0.4029790788888931} | train loss {'Reaction outcome loss': 0.3083733088246106, 'Total loss': 0.3083733088246106}
2023-01-05 08:40:28,227 INFO:     Found new best model at epoch 51
2023-01-05 08:40:28,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:40:28,228 INFO:     Epoch: 52
2023-01-05 08:40:30,381 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.45351525843143464, 'Total loss': 0.45351525843143464} | train loss {'Reaction outcome loss': 0.296055499800491, 'Total loss': 0.296055499800491}
2023-01-05 08:40:30,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:40:30,381 INFO:     Epoch: 53
2023-01-05 08:40:32,534 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4280328412850698, 'Total loss': 0.4280328412850698} | train loss {'Reaction outcome loss': 0.29759378542968945, 'Total loss': 0.29759378542968945}
2023-01-05 08:40:32,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:40:32,534 INFO:     Epoch: 54
2023-01-05 08:40:34,697 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4176377693812052, 'Total loss': 0.4176377693812052} | train loss {'Reaction outcome loss': 0.29649505454925856, 'Total loss': 0.29649505454925856}
2023-01-05 08:40:34,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:40:34,697 INFO:     Epoch: 55
2023-01-05 08:40:36,871 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.418859260280927, 'Total loss': 0.418859260280927} | train loss {'Reaction outcome loss': 0.2957339516239046, 'Total loss': 0.2957339516239046}
2023-01-05 08:40:36,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:40:36,871 INFO:     Epoch: 56
2023-01-05 08:40:38,999 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.458484614888827, 'Total loss': 0.458484614888827} | train loss {'Reaction outcome loss': 0.29116392760984733, 'Total loss': 0.29116392760984733}
2023-01-05 08:40:39,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:40:39,000 INFO:     Epoch: 57
2023-01-05 08:40:41,163 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45153706272443134, 'Total loss': 0.45153706272443134} | train loss {'Reaction outcome loss': 0.28665025166440955, 'Total loss': 0.28665025166440955}
2023-01-05 08:40:41,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:40:41,165 INFO:     Epoch: 58
2023-01-05 08:40:43,338 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4266366442044576, 'Total loss': 0.4266366442044576} | train loss {'Reaction outcome loss': 0.2858619802574281, 'Total loss': 0.2858619802574281}
2023-01-05 08:40:43,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:40:43,338 INFO:     Epoch: 59
2023-01-05 08:40:45,507 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43844518562157947, 'Total loss': 0.43844518562157947} | train loss {'Reaction outcome loss': 0.28536223778870995, 'Total loss': 0.28536223778870995}
2023-01-05 08:40:45,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:40:45,508 INFO:     Epoch: 60
2023-01-05 08:40:47,683 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4430656413237254, 'Total loss': 0.4430656413237254} | train loss {'Reaction outcome loss': 0.2789480283130162, 'Total loss': 0.2789480283130162}
2023-01-05 08:40:47,684 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:40:47,684 INFO:     Epoch: 61
2023-01-05 08:40:49,840 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4005626370509466, 'Total loss': 0.4005626370509466} | train loss {'Reaction outcome loss': 0.284003187024744, 'Total loss': 0.284003187024744}
2023-01-05 08:40:49,840 INFO:     Found new best model at epoch 61
2023-01-05 08:40:49,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:40:49,841 INFO:     Epoch: 62
2023-01-05 08:40:52,033 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4013238858897239, 'Total loss': 0.4013238858897239} | train loss {'Reaction outcome loss': 0.28332343481696254, 'Total loss': 0.28332343481696254}
2023-01-05 08:40:52,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:40:52,033 INFO:     Epoch: 63
2023-01-05 08:40:54,210 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4365928411483765, 'Total loss': 0.4365928411483765} | train loss {'Reaction outcome loss': 0.2853775168987603, 'Total loss': 0.2853775168987603}
2023-01-05 08:40:54,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:40:54,210 INFO:     Epoch: 64
2023-01-05 08:40:56,387 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.418999083340168, 'Total loss': 0.418999083340168} | train loss {'Reaction outcome loss': 0.2752564840610492, 'Total loss': 0.2752564840610492}
2023-01-05 08:40:56,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:40:56,387 INFO:     Epoch: 65
2023-01-05 08:40:58,572 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4216680869460106, 'Total loss': 0.4216680869460106} | train loss {'Reaction outcome loss': 0.2718942900413533, 'Total loss': 0.2718942900413533}
2023-01-05 08:40:58,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:40:58,572 INFO:     Epoch: 66
2023-01-05 08:41:00,746 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42930087794860206, 'Total loss': 0.42930087794860206} | train loss {'Reaction outcome loss': 0.27656765690994606, 'Total loss': 0.27656765690994606}
2023-01-05 08:41:00,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:41:00,747 INFO:     Epoch: 67
2023-01-05 08:41:02,876 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4361041804154714, 'Total loss': 0.4361041804154714} | train loss {'Reaction outcome loss': 0.2700985269318419, 'Total loss': 0.2700985269318419}
2023-01-05 08:41:02,876 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:41:02,876 INFO:     Epoch: 68
2023-01-05 08:41:05,047 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42555776437123616, 'Total loss': 0.42555776437123616} | train loss {'Reaction outcome loss': 0.2641302205299427, 'Total loss': 0.2641302205299427}
2023-01-05 08:41:05,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:41:05,047 INFO:     Epoch: 69
2023-01-05 08:41:07,218 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4045857638120651, 'Total loss': 0.4045857638120651} | train loss {'Reaction outcome loss': 0.27094014486573664, 'Total loss': 0.27094014486573664}
2023-01-05 08:41:07,218 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:41:07,218 INFO:     Epoch: 70
2023-01-05 08:41:09,395 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45760622521241506, 'Total loss': 0.45760622521241506} | train loss {'Reaction outcome loss': 0.26843672448143846, 'Total loss': 0.26843672448143846}
2023-01-05 08:41:09,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:41:09,396 INFO:     Epoch: 71
2023-01-05 08:41:11,555 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.38887263759970664, 'Total loss': 0.38887263759970664} | train loss {'Reaction outcome loss': 0.25912786756611905, 'Total loss': 0.25912786756611905}
2023-01-05 08:41:11,556 INFO:     Found new best model at epoch 71
2023-01-05 08:41:11,557 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:41:11,557 INFO:     Epoch: 72
2023-01-05 08:41:13,701 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4092932641506195, 'Total loss': 0.4092932641506195} | train loss {'Reaction outcome loss': 0.2606295857995426, 'Total loss': 0.2606295857995426}
2023-01-05 08:41:13,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:41:13,701 INFO:     Epoch: 73
2023-01-05 08:41:15,877 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42056761582692465, 'Total loss': 0.42056761582692465} | train loss {'Reaction outcome loss': 0.2655325681778068, 'Total loss': 0.2655325681778068}
2023-01-05 08:41:15,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:41:15,877 INFO:     Epoch: 74
2023-01-05 08:41:18,047 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.44516844550768536, 'Total loss': 0.44516844550768536} | train loss {'Reaction outcome loss': 0.2652058832428085, 'Total loss': 0.2652058832428085}
2023-01-05 08:41:18,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:41:18,048 INFO:     Epoch: 75
2023-01-05 08:41:20,230 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41957730750242866, 'Total loss': 0.41957730750242866} | train loss {'Reaction outcome loss': 0.26676839057504054, 'Total loss': 0.26676839057504054}
2023-01-05 08:41:20,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:41:20,230 INFO:     Epoch: 76
2023-01-05 08:41:22,394 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42139473458131155, 'Total loss': 0.42139473458131155} | train loss {'Reaction outcome loss': 0.26412258906431146, 'Total loss': 0.26412258906431146}
2023-01-05 08:41:22,395 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:41:22,395 INFO:     Epoch: 77
2023-01-05 08:41:24,527 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.46711307267347973, 'Total loss': 0.46711307267347973} | train loss {'Reaction outcome loss': 0.2654873944872768, 'Total loss': 0.2654873944872768}
2023-01-05 08:41:24,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:41:24,528 INFO:     Epoch: 78
2023-01-05 08:41:26,719 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.43544867833455403, 'Total loss': 0.43544867833455403} | train loss {'Reaction outcome loss': 0.2668153263278817, 'Total loss': 0.2668153263278817}
2023-01-05 08:41:26,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:41:26,719 INFO:     Epoch: 79
2023-01-05 08:41:28,877 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4226909359296163, 'Total loss': 0.4226909359296163} | train loss {'Reaction outcome loss': 0.2616234447417061, 'Total loss': 0.2616234447417061}
2023-01-05 08:41:28,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:41:28,878 INFO:     Epoch: 80
2023-01-05 08:41:31,035 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4352342496315638, 'Total loss': 0.4352342496315638} | train loss {'Reaction outcome loss': 0.25391019133696274, 'Total loss': 0.25391019133696274}
2023-01-05 08:41:31,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:41:31,036 INFO:     Epoch: 81
2023-01-05 08:41:33,219 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4150904287894567, 'Total loss': 0.4150904287894567} | train loss {'Reaction outcome loss': 0.2580268522152939, 'Total loss': 0.2580268522152939}
2023-01-05 08:41:33,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:41:33,219 INFO:     Epoch: 82
2023-01-05 08:41:35,390 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40429536638160546, 'Total loss': 0.40429536638160546} | train loss {'Reaction outcome loss': 0.2497969381275859, 'Total loss': 0.2497969381275859}
2023-01-05 08:41:35,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:41:35,390 INFO:     Epoch: 83
2023-01-05 08:41:37,525 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.43895431359608966, 'Total loss': 0.43895431359608966} | train loss {'Reaction outcome loss': 0.25416010136746325, 'Total loss': 0.25416010136746325}
2023-01-05 08:41:37,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:41:37,526 INFO:     Epoch: 84
2023-01-05 08:41:39,701 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4365720942616463, 'Total loss': 0.4365720942616463} | train loss {'Reaction outcome loss': 0.2602292345197945, 'Total loss': 0.2602292345197945}
2023-01-05 08:41:39,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:41:39,701 INFO:     Epoch: 85
2023-01-05 08:41:41,887 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4114036291837692, 'Total loss': 0.4114036291837692} | train loss {'Reaction outcome loss': 0.24696869329156, 'Total loss': 0.24696869329156}
2023-01-05 08:41:41,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:41:41,889 INFO:     Epoch: 86
2023-01-05 08:41:44,088 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4350319986542066, 'Total loss': 0.4350319986542066} | train loss {'Reaction outcome loss': 0.24586073908658987, 'Total loss': 0.24586073908658987}
2023-01-05 08:41:44,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:41:44,088 INFO:     Epoch: 87
2023-01-05 08:41:46,158 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42768122752507526, 'Total loss': 0.42768122752507526} | train loss {'Reaction outcome loss': 0.2567336886637047, 'Total loss': 0.2567336886637047}
2023-01-05 08:41:46,158 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:41:46,158 INFO:     Epoch: 88
2023-01-05 08:41:48,212 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40669109870990117, 'Total loss': 0.40669109870990117} | train loss {'Reaction outcome loss': 0.2508014062695232, 'Total loss': 0.2508014062695232}
2023-01-05 08:41:48,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:41:48,213 INFO:     Epoch: 89
2023-01-05 08:41:50,379 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41480511526266733, 'Total loss': 0.41480511526266733} | train loss {'Reaction outcome loss': 0.24573978623005457, 'Total loss': 0.24573978623005457}
2023-01-05 08:41:50,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:41:50,380 INFO:     Epoch: 90
2023-01-05 08:41:52,547 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40608533620834353, 'Total loss': 0.40608533620834353} | train loss {'Reaction outcome loss': 0.2457124488428235, 'Total loss': 0.2457124488428235}
2023-01-05 08:41:52,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:41:52,547 INFO:     Epoch: 91
2023-01-05 08:41:54,721 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4390266825755437, 'Total loss': 0.4390266825755437} | train loss {'Reaction outcome loss': 0.24754972409604903, 'Total loss': 0.24754972409604903}
2023-01-05 08:41:54,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:41:54,722 INFO:     Epoch: 92
2023-01-05 08:41:56,892 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4246941193938255, 'Total loss': 0.4246941193938255} | train loss {'Reaction outcome loss': 0.2418910115015851, 'Total loss': 0.2418910115015851}
2023-01-05 08:41:56,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:41:56,892 INFO:     Epoch: 93
2023-01-05 08:41:59,057 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4219277570645014, 'Total loss': 0.4219277570645014} | train loss {'Reaction outcome loss': 0.23600592568436038, 'Total loss': 0.23600592568436038}
2023-01-05 08:41:59,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:41:59,057 INFO:     Epoch: 94
2023-01-05 08:42:01,228 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.41527794500192006, 'Total loss': 0.41527794500192006} | train loss {'Reaction outcome loss': 0.23836655212088828, 'Total loss': 0.23836655212088828}
2023-01-05 08:42:01,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:42:01,229 INFO:     Epoch: 95
2023-01-05 08:42:03,410 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.468359911441803, 'Total loss': 0.468359911441803} | train loss {'Reaction outcome loss': 0.24387969082685368, 'Total loss': 0.24387969082685368}
2023-01-05 08:42:03,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:42:03,410 INFO:     Epoch: 96
2023-01-05 08:42:05,582 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43739007314046224, 'Total loss': 0.43739007314046224} | train loss {'Reaction outcome loss': 0.23747632565104573, 'Total loss': 0.23747632565104573}
2023-01-05 08:42:05,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:42:05,582 INFO:     Epoch: 97
2023-01-05 08:42:07,773 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43558743099371594, 'Total loss': 0.43558743099371594} | train loss {'Reaction outcome loss': 0.23884261763967332, 'Total loss': 0.23884261763967332}
2023-01-05 08:42:07,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:42:07,773 INFO:     Epoch: 98
2023-01-05 08:42:09,981 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.446647040049235, 'Total loss': 0.446647040049235} | train loss {'Reaction outcome loss': 0.23410602581993228, 'Total loss': 0.23410602581993228}
2023-01-05 08:42:09,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:42:09,982 INFO:     Epoch: 99
2023-01-05 08:42:12,117 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.450858873128891, 'Total loss': 0.450858873128891} | train loss {'Reaction outcome loss': 0.23598510809646187, 'Total loss': 0.23598510809646187}
2023-01-05 08:42:12,118 INFO:     Best model found after epoch 72 of 100.
2023-01-05 08:42:12,118 INFO:   Done with stage: TRAINING
2023-01-05 08:42:12,118 INFO:   Starting stage: EVALUATION
2023-01-05 08:42:12,243 INFO:   Done with stage: EVALUATION
2023-01-05 08:42:12,243 INFO:   Leaving out SEQ value Fold_7
2023-01-05 08:42:12,256 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 08:42:12,256 INFO:   Starting stage: FEATURE SCALING
2023-01-05 08:42:12,909 INFO:   Done with stage: FEATURE SCALING
2023-01-05 08:42:12,909 INFO:   Starting stage: SCALING TARGETS
2023-01-05 08:42:12,978 INFO:   Done with stage: SCALING TARGETS
2023-01-05 08:42:12,978 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:42:12,978 INFO:     No hyperparam tuning for this model
2023-01-05 08:42:12,978 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:42:12,978 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 08:42:12,979 INFO:     None feature selector for col prot
2023-01-05 08:42:12,979 INFO:     None feature selector for col prot
2023-01-05 08:42:12,979 INFO:     None feature selector for col prot
2023-01-05 08:42:12,980 INFO:     None feature selector for col chem
2023-01-05 08:42:12,980 INFO:     None feature selector for col chem
2023-01-05 08:42:12,980 INFO:     None feature selector for col chem
2023-01-05 08:42:12,980 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 08:42:12,980 INFO:   Starting stage: BUILD MODEL
2023-01-05 08:42:12,982 INFO:     Number of params in model 72901
2023-01-05 08:42:12,985 INFO:   Done with stage: BUILD MODEL
2023-01-05 08:42:12,985 INFO:   Starting stage: TRAINING
2023-01-05 08:42:13,045 INFO:     Val loss before train {'Reaction outcome loss': 1.045299804210663, 'Total loss': 1.045299804210663}
2023-01-05 08:42:13,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:42:13,045 INFO:     Epoch: 0
2023-01-05 08:42:15,198 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8566544969876607, 'Total loss': 0.8566544969876607} | train loss {'Reaction outcome loss': 0.9150284127379856, 'Total loss': 0.9150284127379856}
2023-01-05 08:42:15,199 INFO:     Found new best model at epoch 0
2023-01-05 08:42:15,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:42:15,200 INFO:     Epoch: 1
2023-01-05 08:42:17,342 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6851118048032124, 'Total loss': 0.6851118048032124} | train loss {'Reaction outcome loss': 0.7515640790662627, 'Total loss': 0.7515640790662627}
2023-01-05 08:42:17,343 INFO:     Found new best model at epoch 1
2023-01-05 08:42:17,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:42:17,344 INFO:     Epoch: 2
2023-01-05 08:42:19,482 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5632444560527802, 'Total loss': 0.5632444560527802} | train loss {'Reaction outcome loss': 0.6089591753200023, 'Total loss': 0.6089591753200023}
2023-01-05 08:42:19,483 INFO:     Found new best model at epoch 2
2023-01-05 08:42:19,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:42:19,484 INFO:     Epoch: 3
2023-01-05 08:42:21,623 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5167613704999288, 'Total loss': 0.5167613704999288} | train loss {'Reaction outcome loss': 0.5403701310610249, 'Total loss': 0.5403701310610249}
2023-01-05 08:42:21,623 INFO:     Found new best model at epoch 3
2023-01-05 08:42:21,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:42:21,624 INFO:     Epoch: 4
2023-01-05 08:42:23,740 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.49846384723981224, 'Total loss': 0.49846384723981224} | train loss {'Reaction outcome loss': 0.5183927394504094, 'Total loss': 0.5183927394504094}
2023-01-05 08:42:23,740 INFO:     Found new best model at epoch 4
2023-01-05 08:42:23,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:42:23,742 INFO:     Epoch: 5
2023-01-05 08:42:25,879 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5119457006454468, 'Total loss': 0.5119457006454468} | train loss {'Reaction outcome loss': 0.49871938265044324, 'Total loss': 0.49871938265044324}
2023-01-05 08:42:25,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:42:25,879 INFO:     Epoch: 6
2023-01-05 08:42:28,024 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4724871794382731, 'Total loss': 0.4724871794382731} | train loss {'Reaction outcome loss': 0.4956201889626954, 'Total loss': 0.4956201889626954}
2023-01-05 08:42:28,024 INFO:     Found new best model at epoch 6
2023-01-05 08:42:28,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:42:28,026 INFO:     Epoch: 7
2023-01-05 08:42:30,168 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45805457631746926, 'Total loss': 0.45805457631746926} | train loss {'Reaction outcome loss': 0.4878308451904433, 'Total loss': 0.4878308451904433}
2023-01-05 08:42:30,168 INFO:     Found new best model at epoch 7
2023-01-05 08:42:30,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:42:30,169 INFO:     Epoch: 8
2023-01-05 08:42:32,314 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.47618619600931805, 'Total loss': 0.47618619600931805} | train loss {'Reaction outcome loss': 0.47772741807203223, 'Total loss': 0.47772741807203223}
2023-01-05 08:42:32,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:42:32,314 INFO:     Epoch: 9
2023-01-05 08:42:34,440 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4645060122013092, 'Total loss': 0.4645060122013092} | train loss {'Reaction outcome loss': 0.47295670940058077, 'Total loss': 0.47295670940058077}
2023-01-05 08:42:34,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:42:34,441 INFO:     Epoch: 10
2023-01-05 08:42:36,613 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.46628398696581524, 'Total loss': 0.46628398696581524} | train loss {'Reaction outcome loss': 0.46447060599814366, 'Total loss': 0.46447060599814366}
2023-01-05 08:42:36,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:42:36,614 INFO:     Epoch: 11
2023-01-05 08:42:38,757 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4634070704380671, 'Total loss': 0.4634070704380671} | train loss {'Reaction outcome loss': 0.46441489131781305, 'Total loss': 0.46441489131781305}
2023-01-05 08:42:38,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:42:38,758 INFO:     Epoch: 12
2023-01-05 08:42:40,907 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4424069841702779, 'Total loss': 0.4424069841702779} | train loss {'Reaction outcome loss': 0.456388085047259, 'Total loss': 0.456388085047259}
2023-01-05 08:42:40,907 INFO:     Found new best model at epoch 12
2023-01-05 08:42:40,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:42:40,908 INFO:     Epoch: 13
2023-01-05 08:42:43,064 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.450237829486529, 'Total loss': 0.450237829486529} | train loss {'Reaction outcome loss': 0.45054798872366436, 'Total loss': 0.45054798872366436}
2023-01-05 08:42:43,065 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:42:43,065 INFO:     Epoch: 14
2023-01-05 08:42:45,219 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46416965425014495, 'Total loss': 0.46416965425014495} | train loss {'Reaction outcome loss': 0.44871694523922717, 'Total loss': 0.44871694523922717}
2023-01-05 08:42:45,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:42:45,219 INFO:     Epoch: 15
2023-01-05 08:42:47,330 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45327793757120766, 'Total loss': 0.45327793757120766} | train loss {'Reaction outcome loss': 0.44303306771347123, 'Total loss': 0.44303306771347123}
2023-01-05 08:42:47,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:42:47,331 INFO:     Epoch: 16
2023-01-05 08:42:49,467 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.427342248459657, 'Total loss': 0.427342248459657} | train loss {'Reaction outcome loss': 0.4435922866755158, 'Total loss': 0.4435922866755158}
2023-01-05 08:42:49,467 INFO:     Found new best model at epoch 16
2023-01-05 08:42:49,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:42:49,468 INFO:     Epoch: 17
2023-01-05 08:42:51,642 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43454344471295675, 'Total loss': 0.43454344471295675} | train loss {'Reaction outcome loss': 0.44139596248847723, 'Total loss': 0.44139596248847723}
2023-01-05 08:42:51,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:42:51,642 INFO:     Epoch: 18
2023-01-05 08:42:53,778 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.469594211379687, 'Total loss': 0.469594211379687} | train loss {'Reaction outcome loss': 0.4328366981914444, 'Total loss': 0.4328366981914444}
2023-01-05 08:42:53,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:42:53,779 INFO:     Epoch: 19
2023-01-05 08:42:55,920 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.47148031493028003, 'Total loss': 0.47148031493028003} | train loss {'Reaction outcome loss': 0.4323641180339521, 'Total loss': 0.4323641180339521}
2023-01-05 08:42:55,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:42:55,921 INFO:     Epoch: 20
2023-01-05 08:42:58,040 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44035819669564563, 'Total loss': 0.44035819669564563} | train loss {'Reaction outcome loss': 0.4284139394107526, 'Total loss': 0.4284139394107526}
2023-01-05 08:42:58,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:42:58,040 INFO:     Epoch: 21
2023-01-05 08:42:59,802 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4732731382052104, 'Total loss': 0.4732731382052104} | train loss {'Reaction outcome loss': 0.4260016201458273, 'Total loss': 0.4260016201458273}
2023-01-05 08:42:59,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:42:59,803 INFO:     Epoch: 22
2023-01-05 08:43:01,519 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.43645459214846294, 'Total loss': 0.43645459214846294} | train loss {'Reaction outcome loss': 0.42173805873650705, 'Total loss': 0.42173805873650705}
2023-01-05 08:43:01,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:43:01,519 INFO:     Epoch: 23
2023-01-05 08:43:03,447 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4280748128890991, 'Total loss': 0.4280748128890991} | train loss {'Reaction outcome loss': 0.4207551058137069, 'Total loss': 0.4207551058137069}
2023-01-05 08:43:03,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:43:03,447 INFO:     Epoch: 24
2023-01-05 08:43:05,588 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.41172868609428404, 'Total loss': 0.41172868609428404} | train loss {'Reaction outcome loss': 0.4185821754980261, 'Total loss': 0.4185821754980261}
2023-01-05 08:43:05,588 INFO:     Found new best model at epoch 24
2023-01-05 08:43:05,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:43:05,590 INFO:     Epoch: 25
2023-01-05 08:43:07,729 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.428876738746961, 'Total loss': 0.428876738746961} | train loss {'Reaction outcome loss': 0.4100189089883853, 'Total loss': 0.4100189089883853}
2023-01-05 08:43:07,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:43:07,729 INFO:     Epoch: 26
2023-01-05 08:43:09,887 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4250743274887403, 'Total loss': 0.4250743274887403} | train loss {'Reaction outcome loss': 0.40994428571340813, 'Total loss': 0.40994428571340813}
2023-01-05 08:43:09,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:43:09,887 INFO:     Epoch: 27
2023-01-05 08:43:12,035 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4195944007486105, 'Total loss': 0.4195944007486105} | train loss {'Reaction outcome loss': 0.4061181826421814, 'Total loss': 0.4061181826421814}
2023-01-05 08:43:12,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:43:12,036 INFO:     Epoch: 28
2023-01-05 08:43:14,165 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4410763502120972, 'Total loss': 0.4410763502120972} | train loss {'Reaction outcome loss': 0.40413786960344245, 'Total loss': 0.40413786960344245}
2023-01-05 08:43:14,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:43:14,165 INFO:     Epoch: 29
2023-01-05 08:43:16,363 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46207872629165647, 'Total loss': 0.46207872629165647} | train loss {'Reaction outcome loss': 0.40449470510012914, 'Total loss': 0.40449470510012914}
2023-01-05 08:43:16,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:43:16,363 INFO:     Epoch: 30
2023-01-05 08:43:18,495 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43511473735173545, 'Total loss': 0.43511473735173545} | train loss {'Reaction outcome loss': 0.39363395118147787, 'Total loss': 0.39363395118147787}
2023-01-05 08:43:18,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:43:18,495 INFO:     Epoch: 31
2023-01-05 08:43:20,662 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4215504159530004, 'Total loss': 0.4215504159530004} | train loss {'Reaction outcome loss': 0.3986410869788514, 'Total loss': 0.3986410869788514}
2023-01-05 08:43:20,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:43:20,662 INFO:     Epoch: 32
2023-01-05 08:43:22,835 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42300527493158974, 'Total loss': 0.42300527493158974} | train loss {'Reaction outcome loss': 0.39589254520017736, 'Total loss': 0.39589254520017736}
2023-01-05 08:43:22,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:43:22,836 INFO:     Epoch: 33
2023-01-05 08:43:25,021 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4224313239256541, 'Total loss': 0.4224313239256541} | train loss {'Reaction outcome loss': 0.3918118906499696, 'Total loss': 0.3918118906499696}
2023-01-05 08:43:25,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:43:25,021 INFO:     Epoch: 34
2023-01-05 08:43:27,168 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.442822173734506, 'Total loss': 0.442822173734506} | train loss {'Reaction outcome loss': 0.39049508003857886, 'Total loss': 0.39049508003857886}
2023-01-05 08:43:27,168 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:43:27,168 INFO:     Epoch: 35
2023-01-05 08:43:29,309 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.415477055311203, 'Total loss': 0.415477055311203} | train loss {'Reaction outcome loss': 0.38553688740425734, 'Total loss': 0.38553688740425734}
2023-01-05 08:43:29,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:43:29,311 INFO:     Epoch: 36
2023-01-05 08:43:31,447 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4186399688323339, 'Total loss': 0.4186399688323339} | train loss {'Reaction outcome loss': 0.38312584852432685, 'Total loss': 0.38312584852432685}
2023-01-05 08:43:31,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:43:31,447 INFO:     Epoch: 37
2023-01-05 08:43:33,587 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4343133956193924, 'Total loss': 0.4343133956193924} | train loss {'Reaction outcome loss': 0.37797922363681513, 'Total loss': 0.37797922363681513}
2023-01-05 08:43:33,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:43:33,587 INFO:     Epoch: 38
2023-01-05 08:43:35,734 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42318937281767527, 'Total loss': 0.42318937281767527} | train loss {'Reaction outcome loss': 0.37950305924852834, 'Total loss': 0.37950305924852834}
2023-01-05 08:43:35,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:43:35,735 INFO:     Epoch: 39
2023-01-05 08:43:37,870 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4085562576850255, 'Total loss': 0.4085562576850255} | train loss {'Reaction outcome loss': 0.3718847755043611, 'Total loss': 0.3718847755043611}
2023-01-05 08:43:37,870 INFO:     Found new best model at epoch 39
2023-01-05 08:43:37,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:43:37,872 INFO:     Epoch: 40
2023-01-05 08:43:40,076 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42108589758475623, 'Total loss': 0.42108589758475623} | train loss {'Reaction outcome loss': 0.37075243137069863, 'Total loss': 0.37075243137069863}
2023-01-05 08:43:40,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:43:40,076 INFO:     Epoch: 41
2023-01-05 08:43:42,226 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.43757512072722116, 'Total loss': 0.43757512072722116} | train loss {'Reaction outcome loss': 0.36944612017730727, 'Total loss': 0.36944612017730727}
2023-01-05 08:43:42,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:43:42,226 INFO:     Epoch: 42
2023-01-05 08:43:44,367 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4069322591026624, 'Total loss': 0.4069322591026624} | train loss {'Reaction outcome loss': 0.35717807198963025, 'Total loss': 0.35717807198963025}
2023-01-05 08:43:44,367 INFO:     Found new best model at epoch 42
2023-01-05 08:43:44,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:43:44,369 INFO:     Epoch: 43
2023-01-05 08:43:46,520 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4346497684717178, 'Total loss': 0.4346497684717178} | train loss {'Reaction outcome loss': 0.3602291196040864, 'Total loss': 0.3602291196040864}
2023-01-05 08:43:46,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:43:46,520 INFO:     Epoch: 44
2023-01-05 08:43:48,666 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.39280296564102174, 'Total loss': 0.39280296564102174} | train loss {'Reaction outcome loss': 0.35125965644082013, 'Total loss': 0.35125965644082013}
2023-01-05 08:43:48,667 INFO:     Found new best model at epoch 44
2023-01-05 08:43:48,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:43:48,669 INFO:     Epoch: 45
2023-01-05 08:43:50,813 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41142585476239524, 'Total loss': 0.41142585476239524} | train loss {'Reaction outcome loss': 0.35835409001277313, 'Total loss': 0.35835409001277313}
2023-01-05 08:43:50,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:43:50,813 INFO:     Epoch: 46
2023-01-05 08:43:52,969 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3980097969373067, 'Total loss': 0.3980097969373067} | train loss {'Reaction outcome loss': 0.35319236263524006, 'Total loss': 0.35319236263524006}
2023-01-05 08:43:52,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:43:52,969 INFO:     Epoch: 47
2023-01-05 08:43:55,095 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.38592293759187063, 'Total loss': 0.38592293759187063} | train loss {'Reaction outcome loss': 0.3456645804817659, 'Total loss': 0.3456645804817659}
2023-01-05 08:43:55,095 INFO:     Found new best model at epoch 47
2023-01-05 08:43:55,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:43:55,096 INFO:     Epoch: 48
2023-01-05 08:43:57,230 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.40006079177061715, 'Total loss': 0.40006079177061715} | train loss {'Reaction outcome loss': 0.3429485221468184, 'Total loss': 0.3429485221468184}
2023-01-05 08:43:57,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:43:57,230 INFO:     Epoch: 49
2023-01-05 08:43:59,380 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4331172078847885, 'Total loss': 0.4331172078847885} | train loss {'Reaction outcome loss': 0.3405264456939958, 'Total loss': 0.3405264456939958}
2023-01-05 08:43:59,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:43:59,381 INFO:     Epoch: 50
2023-01-05 08:44:01,520 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.40428167283535005, 'Total loss': 0.40428167283535005} | train loss {'Reaction outcome loss': 0.33547497635884005, 'Total loss': 0.33547497635884005}
2023-01-05 08:44:01,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:44:01,520 INFO:     Epoch: 51
2023-01-05 08:44:03,671 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4215465555588404, 'Total loss': 0.4215465555588404} | train loss {'Reaction outcome loss': 0.3373868614911054, 'Total loss': 0.3373868614911054}
2023-01-05 08:44:03,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:44:03,671 INFO:     Epoch: 52
2023-01-05 08:44:05,815 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3946928262710571, 'Total loss': 0.3946928262710571} | train loss {'Reaction outcome loss': 0.33648039378824024, 'Total loss': 0.33648039378824024}
2023-01-05 08:44:05,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:44:05,817 INFO:     Epoch: 53
2023-01-05 08:44:07,945 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4216397017240524, 'Total loss': 0.4216397017240524} | train loss {'Reaction outcome loss': 0.329754104361917, 'Total loss': 0.329754104361917}
2023-01-05 08:44:07,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:44:07,945 INFO:     Epoch: 54
2023-01-05 08:44:10,077 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.408075800538063, 'Total loss': 0.408075800538063} | train loss {'Reaction outcome loss': 0.334030103930918, 'Total loss': 0.334030103930918}
2023-01-05 08:44:10,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:44:10,077 INFO:     Epoch: 55
2023-01-05 08:44:12,212 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39201157093048095, 'Total loss': 0.39201157093048095} | train loss {'Reaction outcome loss': 0.32498518230706236, 'Total loss': 0.32498518230706236}
2023-01-05 08:44:12,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:44:12,213 INFO:     Epoch: 56
2023-01-05 08:44:14,354 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.39905953605969746, 'Total loss': 0.39905953605969746} | train loss {'Reaction outcome loss': 0.3293900247799219, 'Total loss': 0.3293900247799219}
2023-01-05 08:44:14,355 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:44:14,355 INFO:     Epoch: 57
2023-01-05 08:44:16,507 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4140139162540436, 'Total loss': 0.4140139162540436} | train loss {'Reaction outcome loss': 0.3134736525588227, 'Total loss': 0.3134736525588227}
2023-01-05 08:44:16,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:44:16,507 INFO:     Epoch: 58
2023-01-05 08:44:18,648 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3991203914086024, 'Total loss': 0.3991203914086024} | train loss {'Reaction outcome loss': 0.3216623093416221, 'Total loss': 0.3216623093416221}
2023-01-05 08:44:18,648 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:44:18,648 INFO:     Epoch: 59
2023-01-05 08:44:20,810 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4313182304302851, 'Total loss': 0.4313182304302851} | train loss {'Reaction outcome loss': 0.30866257399048685, 'Total loss': 0.30866257399048685}
2023-01-05 08:44:20,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:44:20,811 INFO:     Epoch: 60
2023-01-05 08:44:22,978 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3918396959702174, 'Total loss': 0.3918396959702174} | train loss {'Reaction outcome loss': 0.3117322396677341, 'Total loss': 0.3117322396677341}
2023-01-05 08:44:22,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:44:22,978 INFO:     Epoch: 61
2023-01-05 08:44:25,103 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.39824356734752653, 'Total loss': 0.39824356734752653} | train loss {'Reaction outcome loss': 0.3106313930538884, 'Total loss': 0.3106313930538884}
2023-01-05 08:44:25,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:44:25,104 INFO:     Epoch: 62
2023-01-05 08:44:27,259 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.37646602690219877, 'Total loss': 0.37646602690219877} | train loss {'Reaction outcome loss': 0.30637798422308515, 'Total loss': 0.30637798422308515}
2023-01-05 08:44:27,259 INFO:     Found new best model at epoch 62
2023-01-05 08:44:27,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:44:27,260 INFO:     Epoch: 63
2023-01-05 08:44:29,385 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.39595832029978434, 'Total loss': 0.39595832029978434} | train loss {'Reaction outcome loss': 0.3082572420936649, 'Total loss': 0.3082572420936649}
2023-01-05 08:44:29,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:44:29,385 INFO:     Epoch: 64
2023-01-05 08:44:31,545 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3863615651925405, 'Total loss': 0.3863615651925405} | train loss {'Reaction outcome loss': 0.30846637703587104, 'Total loss': 0.30846637703587104}
2023-01-05 08:44:31,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:44:31,546 INFO:     Epoch: 65
2023-01-05 08:44:33,704 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4021890163421631, 'Total loss': 0.4021890163421631} | train loss {'Reaction outcome loss': 0.2991848266105691, 'Total loss': 0.2991848266105691}
2023-01-05 08:44:33,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:44:33,704 INFO:     Epoch: 66
2023-01-05 08:44:35,856 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4070557097593943, 'Total loss': 0.4070557097593943} | train loss {'Reaction outcome loss': 0.29517347884303247, 'Total loss': 0.29517347884303247}
2023-01-05 08:44:35,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:44:35,857 INFO:     Epoch: 67
2023-01-05 08:44:37,994 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.41113540108005203, 'Total loss': 0.41113540108005203} | train loss {'Reaction outcome loss': 0.2977885219819137, 'Total loss': 0.2977885219819137}
2023-01-05 08:44:37,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:44:37,994 INFO:     Epoch: 68
2023-01-05 08:44:40,125 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39816043625275294, 'Total loss': 0.39816043625275294} | train loss {'Reaction outcome loss': 0.29853021267828717, 'Total loss': 0.29853021267828717}
2023-01-05 08:44:40,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:44:40,125 INFO:     Epoch: 69
2023-01-05 08:44:42,268 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3993640452623367, 'Total loss': 0.3993640452623367} | train loss {'Reaction outcome loss': 0.2937705696825563, 'Total loss': 0.2937705696825563}
2023-01-05 08:44:42,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:44:42,269 INFO:     Epoch: 70
2023-01-05 08:44:44,421 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4348172639807065, 'Total loss': 0.4348172639807065} | train loss {'Reaction outcome loss': 0.2905881973119439, 'Total loss': 0.2905881973119439}
2023-01-05 08:44:44,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:44:44,421 INFO:     Epoch: 71
2023-01-05 08:44:46,584 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.42943380971749623, 'Total loss': 0.42943380971749623} | train loss {'Reaction outcome loss': 0.2914500877492293, 'Total loss': 0.2914500877492293}
2023-01-05 08:44:46,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:44:46,584 INFO:     Epoch: 72
2023-01-05 08:44:48,725 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4199713170528412, 'Total loss': 0.4199713170528412} | train loss {'Reaction outcome loss': 0.2858170521289219, 'Total loss': 0.2858170521289219}
2023-01-05 08:44:48,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:44:48,725 INFO:     Epoch: 73
2023-01-05 08:44:50,873 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.45324843128522235, 'Total loss': 0.45324843128522235} | train loss {'Reaction outcome loss': 0.2864221878975195, 'Total loss': 0.2864221878975195}
2023-01-05 08:44:50,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:44:50,874 INFO:     Epoch: 74
2023-01-05 08:44:52,950 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.41047148654858273, 'Total loss': 0.41047148654858273} | train loss {'Reaction outcome loss': 0.28568306400773735, 'Total loss': 0.28568306400773735}
2023-01-05 08:44:52,950 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:44:52,950 INFO:     Epoch: 75
2023-01-05 08:44:54,694 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.405201185743014, 'Total loss': 0.405201185743014} | train loss {'Reaction outcome loss': 0.2817739749422474, 'Total loss': 0.2817739749422474}
2023-01-05 08:44:54,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:44:54,695 INFO:     Epoch: 76
2023-01-05 08:44:56,431 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.393794787923495, 'Total loss': 0.393794787923495} | train loss {'Reaction outcome loss': 0.2814839232413873, 'Total loss': 0.2814839232413873}
2023-01-05 08:44:56,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:44:56,431 INFO:     Epoch: 77
2023-01-05 08:44:58,401 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4174458434184392, 'Total loss': 0.4174458434184392} | train loss {'Reaction outcome loss': 0.27691534324719086, 'Total loss': 0.27691534324719086}
2023-01-05 08:44:58,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:44:58,402 INFO:     Epoch: 78
2023-01-05 08:45:00,543 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.39766089916229247, 'Total loss': 0.39766089916229247} | train loss {'Reaction outcome loss': 0.28158400896392816, 'Total loss': 0.28158400896392816}
2023-01-05 08:45:00,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:45:00,544 INFO:     Epoch: 79
2023-01-05 08:45:02,695 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3790148064494133, 'Total loss': 0.3790148064494133} | train loss {'Reaction outcome loss': 0.279032869386847, 'Total loss': 0.279032869386847}
2023-01-05 08:45:02,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:45:02,695 INFO:     Epoch: 80
2023-01-05 08:45:04,831 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.40719830195109047, 'Total loss': 0.40719830195109047} | train loss {'Reaction outcome loss': 0.2689553668083501, 'Total loss': 0.2689553668083501}
2023-01-05 08:45:04,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:45:04,832 INFO:     Epoch: 81
2023-01-05 08:45:06,978 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3805009603500366, 'Total loss': 0.3805009603500366} | train loss {'Reaction outcome loss': 0.2708969690095987, 'Total loss': 0.2708969690095987}
2023-01-05 08:45:06,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:45:06,978 INFO:     Epoch: 82
2023-01-05 08:45:09,111 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.40393699407577516, 'Total loss': 0.40393699407577516} | train loss {'Reaction outcome loss': 0.268673638432511, 'Total loss': 0.268673638432511}
2023-01-05 08:45:09,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:45:09,111 INFO:     Epoch: 83
2023-01-05 08:45:11,243 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4211824079354604, 'Total loss': 0.4211824079354604} | train loss {'Reaction outcome loss': 0.2714599335335032, 'Total loss': 0.2714599335335032}
2023-01-05 08:45:11,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:45:11,244 INFO:     Epoch: 84
2023-01-05 08:45:13,383 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38161722471316656, 'Total loss': 0.38161722471316656} | train loss {'Reaction outcome loss': 0.2651737124733899, 'Total loss': 0.2651737124733899}
2023-01-05 08:45:13,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:45:13,383 INFO:     Epoch: 85
2023-01-05 08:45:15,541 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3983028213183085, 'Total loss': 0.3983028213183085} | train loss {'Reaction outcome loss': 0.26807876054986113, 'Total loss': 0.26807876054986113}
2023-01-05 08:45:15,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:45:15,541 INFO:     Epoch: 86
2023-01-05 08:45:17,692 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3951126237710317, 'Total loss': 0.3951126237710317} | train loss {'Reaction outcome loss': 0.26297983466681557, 'Total loss': 0.26297983466681557}
2023-01-05 08:45:17,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:45:17,693 INFO:     Epoch: 87
2023-01-05 08:45:19,844 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41361819406350453, 'Total loss': 0.41361819406350453} | train loss {'Reaction outcome loss': 0.2589765991539742, 'Total loss': 0.2589765991539742}
2023-01-05 08:45:19,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:45:19,844 INFO:     Epoch: 88
2023-01-05 08:45:21,976 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3880306869745255, 'Total loss': 0.3880306869745255} | train loss {'Reaction outcome loss': 0.26426448543508446, 'Total loss': 0.26426448543508446}
2023-01-05 08:45:21,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:45:21,976 INFO:     Epoch: 89
2023-01-05 08:45:24,121 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41934912900129956, 'Total loss': 0.41934912900129956} | train loss {'Reaction outcome loss': 0.26459214536228426, 'Total loss': 0.26459214536228426}
2023-01-05 08:45:24,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:45:24,121 INFO:     Epoch: 90
2023-01-05 08:45:26,235 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3809024433294932, 'Total loss': 0.3809024433294932} | train loss {'Reaction outcome loss': 0.25662101372858903, 'Total loss': 0.25662101372858903}
2023-01-05 08:45:26,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:45:26,235 INFO:     Epoch: 91
2023-01-05 08:45:28,390 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.42482589880625404, 'Total loss': 0.42482589880625404} | train loss {'Reaction outcome loss': 0.26706008065192804, 'Total loss': 0.26706008065192804}
2023-01-05 08:45:28,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:45:28,390 INFO:     Epoch: 92
2023-01-05 08:45:30,537 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3908621321121852, 'Total loss': 0.3908621321121852} | train loss {'Reaction outcome loss': 0.259212171264591, 'Total loss': 0.259212171264591}
2023-01-05 08:45:30,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:45:30,538 INFO:     Epoch: 93
2023-01-05 08:45:32,678 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3764348407586416, 'Total loss': 0.3764348407586416} | train loss {'Reaction outcome loss': 0.2602036392153071, 'Total loss': 0.2602036392153071}
2023-01-05 08:45:32,679 INFO:     Found new best model at epoch 93
2023-01-05 08:45:32,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:45:32,680 INFO:     Epoch: 94
2023-01-05 08:45:34,811 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4118542641401291, 'Total loss': 0.4118542641401291} | train loss {'Reaction outcome loss': 0.2547269306233982, 'Total loss': 0.2547269306233982}
2023-01-05 08:45:34,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:45:34,811 INFO:     Epoch: 95
2023-01-05 08:45:36,988 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.36014349162578585, 'Total loss': 0.36014349162578585} | train loss {'Reaction outcome loss': 0.2477946718814817, 'Total loss': 0.2477946718814817}
2023-01-05 08:45:36,989 INFO:     Found new best model at epoch 95
2023-01-05 08:45:36,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:45:36,990 INFO:     Epoch: 96
2023-01-05 08:45:39,130 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.39696423560380933, 'Total loss': 0.39696423560380933} | train loss {'Reaction outcome loss': 0.25713603741006696, 'Total loss': 0.25713603741006696}
2023-01-05 08:45:39,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:45:39,131 INFO:     Epoch: 97
2023-01-05 08:45:41,253 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.41035937865575156, 'Total loss': 0.41035937865575156} | train loss {'Reaction outcome loss': 0.24909495867544065, 'Total loss': 0.24909495867544065}
2023-01-05 08:45:41,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:45:41,253 INFO:     Epoch: 98
2023-01-05 08:45:43,384 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4049097716808319, 'Total loss': 0.4049097716808319} | train loss {'Reaction outcome loss': 0.25596335887854554, 'Total loss': 0.25596335887854554}
2023-01-05 08:45:43,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:45:43,385 INFO:     Epoch: 99
2023-01-05 08:45:45,509 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3944316267967224, 'Total loss': 0.3944316267967224} | train loss {'Reaction outcome loss': 0.2499247269473807, 'Total loss': 0.2499247269473807}
2023-01-05 08:45:45,509 INFO:     Best model found after epoch 96 of 100.
2023-01-05 08:45:45,509 INFO:   Done with stage: TRAINING
2023-01-05 08:45:45,509 INFO:   Starting stage: EVALUATION
2023-01-05 08:45:45,646 INFO:   Done with stage: EVALUATION
2023-01-05 08:45:45,646 INFO:   Leaving out SEQ value Fold_8
2023-01-05 08:45:45,659 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 08:45:45,659 INFO:   Starting stage: FEATURE SCALING
2023-01-05 08:45:46,319 INFO:   Done with stage: FEATURE SCALING
2023-01-05 08:45:46,319 INFO:   Starting stage: SCALING TARGETS
2023-01-05 08:45:46,389 INFO:   Done with stage: SCALING TARGETS
2023-01-05 08:45:46,389 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:45:46,389 INFO:     No hyperparam tuning for this model
2023-01-05 08:45:46,389 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:45:46,389 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 08:45:46,390 INFO:     None feature selector for col prot
2023-01-05 08:45:46,390 INFO:     None feature selector for col prot
2023-01-05 08:45:46,390 INFO:     None feature selector for col prot
2023-01-05 08:45:46,391 INFO:     None feature selector for col chem
2023-01-05 08:45:46,391 INFO:     None feature selector for col chem
2023-01-05 08:45:46,391 INFO:     None feature selector for col chem
2023-01-05 08:45:46,391 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 08:45:46,391 INFO:   Starting stage: BUILD MODEL
2023-01-05 08:45:46,392 INFO:     Number of params in model 72901
2023-01-05 08:45:46,396 INFO:   Done with stage: BUILD MODEL
2023-01-05 08:45:46,396 INFO:   Starting stage: TRAINING
2023-01-05 08:45:46,454 INFO:     Val loss before train {'Reaction outcome loss': 0.9602710525194804, 'Total loss': 0.9602710525194804}
2023-01-05 08:45:46,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:45:46,454 INFO:     Epoch: 0
2023-01-05 08:45:48,616 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7522656758626302, 'Total loss': 0.7522656758626302} | train loss {'Reaction outcome loss': 0.9118276812969993, 'Total loss': 0.9118276812969993}
2023-01-05 08:45:48,617 INFO:     Found new best model at epoch 0
2023-01-05 08:45:48,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:45:48,618 INFO:     Epoch: 1
2023-01-05 08:45:50,576 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.585027551651001, 'Total loss': 0.585027551651001} | train loss {'Reaction outcome loss': 0.7182715172586889, 'Total loss': 0.7182715172586889}
2023-01-05 08:45:50,576 INFO:     Found new best model at epoch 1
2023-01-05 08:45:50,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:45:50,577 INFO:     Epoch: 2
2023-01-05 08:45:52,739 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5157497684160869, 'Total loss': 0.5157497684160869} | train loss {'Reaction outcome loss': 0.5771992299100552, 'Total loss': 0.5771992299100552}
2023-01-05 08:45:52,739 INFO:     Found new best model at epoch 2
2023-01-05 08:45:52,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:45:52,740 INFO:     Epoch: 3
2023-01-05 08:45:54,888 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.472747274239858, 'Total loss': 0.472747274239858} | train loss {'Reaction outcome loss': 0.5354416412351795, 'Total loss': 0.5354416412351795}
2023-01-05 08:45:54,888 INFO:     Found new best model at epoch 3
2023-01-05 08:45:54,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:45:54,890 INFO:     Epoch: 4
2023-01-05 08:45:57,038 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4544518649578094, 'Total loss': 0.4544518649578094} | train loss {'Reaction outcome loss': 0.5153580249324172, 'Total loss': 0.5153580249324172}
2023-01-05 08:45:57,038 INFO:     Found new best model at epoch 4
2023-01-05 08:45:57,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:45:57,039 INFO:     Epoch: 5
2023-01-05 08:45:59,183 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4373318245013555, 'Total loss': 0.4373318245013555} | train loss {'Reaction outcome loss': 0.5010164451082691, 'Total loss': 0.5010164451082691}
2023-01-05 08:45:59,183 INFO:     Found new best model at epoch 5
2023-01-05 08:45:59,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:45:59,185 INFO:     Epoch: 6
2023-01-05 08:46:01,336 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.43370242714881896, 'Total loss': 0.43370242714881896} | train loss {'Reaction outcome loss': 0.4914463957509409, 'Total loss': 0.4914463957509409}
2023-01-05 08:46:01,336 INFO:     Found new best model at epoch 6
2023-01-05 08:46:01,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:46:01,337 INFO:     Epoch: 7
2023-01-05 08:46:03,491 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.43063055276870726, 'Total loss': 0.43063055276870726} | train loss {'Reaction outcome loss': 0.48546002729920273, 'Total loss': 0.48546002729920273}
2023-01-05 08:46:03,491 INFO:     Found new best model at epoch 7
2023-01-05 08:46:03,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:46:03,493 INFO:     Epoch: 8
2023-01-05 08:46:05,637 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.43938435316085817, 'Total loss': 0.43938435316085817} | train loss {'Reaction outcome loss': 0.47576593518902677, 'Total loss': 0.47576593518902677}
2023-01-05 08:46:05,637 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:46:05,637 INFO:     Epoch: 9
2023-01-05 08:46:07,769 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4299029101928075, 'Total loss': 0.4299029101928075} | train loss {'Reaction outcome loss': 0.47299881849693476, 'Total loss': 0.47299881849693476}
2023-01-05 08:46:07,770 INFO:     Found new best model at epoch 9
2023-01-05 08:46:07,771 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:46:07,771 INFO:     Epoch: 10
2023-01-05 08:46:09,924 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41945463518301646, 'Total loss': 0.41945463518301646} | train loss {'Reaction outcome loss': 0.46055709374295245, 'Total loss': 0.46055709374295245}
2023-01-05 08:46:09,924 INFO:     Found new best model at epoch 10
2023-01-05 08:46:09,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:46:09,926 INFO:     Epoch: 11
2023-01-05 08:46:12,108 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.42935560941696166, 'Total loss': 0.42935560941696166} | train loss {'Reaction outcome loss': 0.4562945251322825, 'Total loss': 0.4562945251322825}
2023-01-05 08:46:12,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:46:12,108 INFO:     Epoch: 12
2023-01-05 08:46:14,264 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43080631693204247, 'Total loss': 0.43080631693204247} | train loss {'Reaction outcome loss': 0.45861196071447446, 'Total loss': 0.45861196071447446}
2023-01-05 08:46:14,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:46:14,265 INFO:     Epoch: 13
2023-01-05 08:46:16,419 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4039023319880168, 'Total loss': 0.4039023319880168} | train loss {'Reaction outcome loss': 0.4504471979093896, 'Total loss': 0.4504471979093896}
2023-01-05 08:46:16,420 INFO:     Found new best model at epoch 13
2023-01-05 08:46:16,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:46:16,421 INFO:     Epoch: 14
2023-01-05 08:46:18,552 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4123553454875946, 'Total loss': 0.4123553454875946} | train loss {'Reaction outcome loss': 0.4453889612471584, 'Total loss': 0.4453889612471584}
2023-01-05 08:46:18,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:46:18,553 INFO:     Epoch: 15
2023-01-05 08:46:20,710 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4148880511522293, 'Total loss': 0.4148880511522293} | train loss {'Reaction outcome loss': 0.44568991876251, 'Total loss': 0.44568991876251}
2023-01-05 08:46:20,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:46:20,710 INFO:     Epoch: 16
2023-01-05 08:46:22,861 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4277494152386983, 'Total loss': 0.4277494152386983} | train loss {'Reaction outcome loss': 0.4380478658293128, 'Total loss': 0.4380478658293128}
2023-01-05 08:46:22,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:46:22,862 INFO:     Epoch: 17
2023-01-05 08:46:25,043 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.40592304269472756, 'Total loss': 0.40592304269472756} | train loss {'Reaction outcome loss': 0.43338641949293844, 'Total loss': 0.43338641949293844}
2023-01-05 08:46:25,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:46:25,043 INFO:     Epoch: 18
2023-01-05 08:46:27,221 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.42277189493179324, 'Total loss': 0.42277189493179324} | train loss {'Reaction outcome loss': 0.42808454833413717, 'Total loss': 0.42808454833413717}
2023-01-05 08:46:27,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:46:27,222 INFO:     Epoch: 19
2023-01-05 08:46:29,372 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4060686508814494, 'Total loss': 0.4060686508814494} | train loss {'Reaction outcome loss': 0.4253438168376792, 'Total loss': 0.4253438168376792}
2023-01-05 08:46:29,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:46:29,373 INFO:     Epoch: 20
2023-01-05 08:46:31,551 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.40286996563275657, 'Total loss': 0.40286996563275657} | train loss {'Reaction outcome loss': 0.4220602875474558, 'Total loss': 0.4220602875474558}
2023-01-05 08:46:31,551 INFO:     Found new best model at epoch 20
2023-01-05 08:46:31,552 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:46:31,552 INFO:     Epoch: 21
2023-01-05 08:46:33,718 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.42730607589085895, 'Total loss': 0.42730607589085895} | train loss {'Reaction outcome loss': 0.41552395785113105, 'Total loss': 0.41552395785113105}
2023-01-05 08:46:33,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:46:33,718 INFO:     Epoch: 22
2023-01-05 08:46:35,901 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.3951521654923757, 'Total loss': 0.3951521654923757} | train loss {'Reaction outcome loss': 0.411168767683988, 'Total loss': 0.411168767683988}
2023-01-05 08:46:35,901 INFO:     Found new best model at epoch 22
2023-01-05 08:46:35,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:46:35,902 INFO:     Epoch: 23
2023-01-05 08:46:38,063 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4116175283988317, 'Total loss': 0.4116175283988317} | train loss {'Reaction outcome loss': 0.40554594033354024, 'Total loss': 0.40554594033354024}
2023-01-05 08:46:38,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:46:38,063 INFO:     Epoch: 24
2023-01-05 08:46:40,219 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3752743870019913, 'Total loss': 0.3752743870019913} | train loss {'Reaction outcome loss': 0.4088222434481989, 'Total loss': 0.4088222434481989}
2023-01-05 08:46:40,220 INFO:     Found new best model at epoch 24
2023-01-05 08:46:40,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:46:40,221 INFO:     Epoch: 25
2023-01-05 08:46:42,376 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.39432874917984007, 'Total loss': 0.39432874917984007} | train loss {'Reaction outcome loss': 0.39724627465332457, 'Total loss': 0.39724627465332457}
2023-01-05 08:46:42,376 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:46:42,377 INFO:     Epoch: 26
2023-01-05 08:46:44,535 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3849461863438288, 'Total loss': 0.3849461863438288} | train loss {'Reaction outcome loss': 0.40168642217717015, 'Total loss': 0.40168642217717015}
2023-01-05 08:46:44,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:46:44,535 INFO:     Epoch: 27
2023-01-05 08:46:46,673 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.3736458013455073, 'Total loss': 0.3736458013455073} | train loss {'Reaction outcome loss': 0.3924696429864594, 'Total loss': 0.3924696429864594}
2023-01-05 08:46:46,673 INFO:     Found new best model at epoch 27
2023-01-05 08:46:46,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:46:46,675 INFO:     Epoch: 28
2023-01-05 08:46:48,832 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.409566338857015, 'Total loss': 0.409566338857015} | train loss {'Reaction outcome loss': 0.3852903897796727, 'Total loss': 0.3852903897796727}
2023-01-05 08:46:48,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:46:48,832 INFO:     Epoch: 29
2023-01-05 08:46:51,000 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39300954242547353, 'Total loss': 0.39300954242547353} | train loss {'Reaction outcome loss': 0.38648293046314364, 'Total loss': 0.38648293046314364}
2023-01-05 08:46:51,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:46:51,000 INFO:     Epoch: 30
2023-01-05 08:46:53,163 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3975882351398468, 'Total loss': 0.3975882351398468} | train loss {'Reaction outcome loss': 0.37846833480932224, 'Total loss': 0.37846833480932224}
2023-01-05 08:46:53,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:46:53,164 INFO:     Epoch: 31
2023-01-05 08:46:55,325 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3874949961900711, 'Total loss': 0.3874949961900711} | train loss {'Reaction outcome loss': 0.373949367808521, 'Total loss': 0.373949367808521}
2023-01-05 08:46:55,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:46:55,325 INFO:     Epoch: 32
2023-01-05 08:46:57,454 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4234030614296595, 'Total loss': 0.4234030614296595} | train loss {'Reaction outcome loss': 0.3707434592049044, 'Total loss': 0.3707434592049044}
2023-01-05 08:46:57,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:46:57,454 INFO:     Epoch: 33
2023-01-05 08:46:59,578 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4180112838745117, 'Total loss': 0.4180112838745117} | train loss {'Reaction outcome loss': 0.36757422339453594, 'Total loss': 0.36757422339453594}
2023-01-05 08:46:59,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:46:59,579 INFO:     Epoch: 34
2023-01-05 08:47:01,813 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3875542014837265, 'Total loss': 0.3875542014837265} | train loss {'Reaction outcome loss': 0.3634299730162543, 'Total loss': 0.3634299730162543}
2023-01-05 08:47:01,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:47:01,814 INFO:     Epoch: 35
2023-01-05 08:47:04,053 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.37600874056418737, 'Total loss': 0.37600874056418737} | train loss {'Reaction outcome loss': 0.35672162153122655, 'Total loss': 0.35672162153122655}
2023-01-05 08:47:04,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:47:04,054 INFO:     Epoch: 36
2023-01-05 08:47:06,247 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43673048714796703, 'Total loss': 0.43673048714796703} | train loss {'Reaction outcome loss': 0.355129713535524, 'Total loss': 0.355129713535524}
2023-01-05 08:47:06,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:47:06,248 INFO:     Epoch: 37
2023-01-05 08:47:08,414 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.37079832156499226, 'Total loss': 0.37079832156499226} | train loss {'Reaction outcome loss': 0.3561662112762782, 'Total loss': 0.3561662112762782}
2023-01-05 08:47:08,414 INFO:     Found new best model at epoch 37
2023-01-05 08:47:08,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:47:08,415 INFO:     Epoch: 38
2023-01-05 08:47:10,564 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3859019190073013, 'Total loss': 0.3859019190073013} | train loss {'Reaction outcome loss': 0.3518477871422303, 'Total loss': 0.3518477871422303}
2023-01-05 08:47:10,564 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:47:10,564 INFO:     Epoch: 39
2023-01-05 08:47:12,722 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.39801657100518545, 'Total loss': 0.39801657100518545} | train loss {'Reaction outcome loss': 0.35052003852673386, 'Total loss': 0.35052003852673386}
2023-01-05 08:47:12,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:47:12,723 INFO:     Epoch: 40
2023-01-05 08:47:14,886 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3893497198820114, 'Total loss': 0.3893497198820114} | train loss {'Reaction outcome loss': 0.34608340341369165, 'Total loss': 0.34608340341369165}
2023-01-05 08:47:14,886 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:47:14,886 INFO:     Epoch: 41
2023-01-05 08:47:17,036 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3694763590892156, 'Total loss': 0.3694763590892156} | train loss {'Reaction outcome loss': 0.33977485559746246, 'Total loss': 0.33977485559746246}
2023-01-05 08:47:17,036 INFO:     Found new best model at epoch 41
2023-01-05 08:47:17,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:47:17,037 INFO:     Epoch: 42
2023-01-05 08:47:19,216 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.39435731371243793, 'Total loss': 0.39435731371243793} | train loss {'Reaction outcome loss': 0.33365923409024084, 'Total loss': 0.33365923409024084}
2023-01-05 08:47:19,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:47:19,217 INFO:     Epoch: 43
2023-01-05 08:47:21,366 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3943758894999822, 'Total loss': 0.3943758894999822} | train loss {'Reaction outcome loss': 0.3369593156320093, 'Total loss': 0.3369593156320093}
2023-01-05 08:47:21,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:47:21,366 INFO:     Epoch: 44
2023-01-05 08:47:23,521 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4165332545836767, 'Total loss': 0.4165332545836767} | train loss {'Reaction outcome loss': 0.33640883448752257, 'Total loss': 0.33640883448752257}
2023-01-05 08:47:23,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:47:23,521 INFO:     Epoch: 45
2023-01-05 08:47:25,695 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4123280564943949, 'Total loss': 0.4123280564943949} | train loss {'Reaction outcome loss': 0.32724589940550525, 'Total loss': 0.32724589940550525}
2023-01-05 08:47:25,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:47:25,696 INFO:     Epoch: 46
2023-01-05 08:47:27,875 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41639610230922697, 'Total loss': 0.41639610230922697} | train loss {'Reaction outcome loss': 0.32467295678621594, 'Total loss': 0.32467295678621594}
2023-01-05 08:47:27,875 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:47:27,875 INFO:     Epoch: 47
2023-01-05 08:47:30,043 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.39266880849997204, 'Total loss': 0.39266880849997204} | train loss {'Reaction outcome loss': 0.3218612716556779, 'Total loss': 0.3218612716556779}
2023-01-05 08:47:30,044 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:47:30,044 INFO:     Epoch: 48
2023-01-05 08:47:32,212 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39416766464710234, 'Total loss': 0.39416766464710234} | train loss {'Reaction outcome loss': 0.32583131409831856, 'Total loss': 0.32583131409831856}
2023-01-05 08:47:32,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:47:32,212 INFO:     Epoch: 49
2023-01-05 08:47:34,385 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3917875011761983, 'Total loss': 0.3917875011761983} | train loss {'Reaction outcome loss': 0.31973476898906894, 'Total loss': 0.31973476898906894}
2023-01-05 08:47:34,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:47:34,385 INFO:     Epoch: 50
2023-01-05 08:47:36,560 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.38645343780517577, 'Total loss': 0.38645343780517577} | train loss {'Reaction outcome loss': 0.3198985705548891, 'Total loss': 0.3198985705548891}
2023-01-05 08:47:36,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:47:36,561 INFO:     Epoch: 51
2023-01-05 08:47:38,738 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41402150491873424, 'Total loss': 0.41402150491873424} | train loss {'Reaction outcome loss': 0.3163961882464292, 'Total loss': 0.3163961882464292}
2023-01-05 08:47:38,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:47:38,739 INFO:     Epoch: 52
2023-01-05 08:47:40,918 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.36055081288019813, 'Total loss': 0.36055081288019813} | train loss {'Reaction outcome loss': 0.30820342981750787, 'Total loss': 0.30820342981750787}
2023-01-05 08:47:40,918 INFO:     Found new best model at epoch 52
2023-01-05 08:47:40,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:47:40,920 INFO:     Epoch: 53
2023-01-05 08:47:43,082 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.35118829309940336, 'Total loss': 0.35118829309940336} | train loss {'Reaction outcome loss': 0.3102836705179421, 'Total loss': 0.3102836705179421}
2023-01-05 08:47:43,082 INFO:     Found new best model at epoch 53
2023-01-05 08:47:43,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:47:43,084 INFO:     Epoch: 54
2023-01-05 08:47:45,242 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3861100415388743, 'Total loss': 0.3861100415388743} | train loss {'Reaction outcome loss': 0.309804633179081, 'Total loss': 0.309804633179081}
2023-01-05 08:47:45,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:47:45,242 INFO:     Epoch: 55
2023-01-05 08:47:47,409 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3761796792348226, 'Total loss': 0.3761796792348226} | train loss {'Reaction outcome loss': 0.3013219035597054, 'Total loss': 0.3013219035597054}
2023-01-05 08:47:47,409 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:47:47,409 INFO:     Epoch: 56
2023-01-05 08:47:49,584 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4182336419820786, 'Total loss': 0.4182336419820786} | train loss {'Reaction outcome loss': 0.2986866615255387, 'Total loss': 0.2986866615255387}
2023-01-05 08:47:49,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:47:49,585 INFO:     Epoch: 57
2023-01-05 08:47:51,739 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3946043193340302, 'Total loss': 0.3946043193340302} | train loss {'Reaction outcome loss': 0.30505857102922584, 'Total loss': 0.30505857102922584}
2023-01-05 08:47:51,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:47:51,739 INFO:     Epoch: 58
2023-01-05 08:47:53,904 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4136506716410319, 'Total loss': 0.4136506716410319} | train loss {'Reaction outcome loss': 0.300722962857261, 'Total loss': 0.300722962857261}
2023-01-05 08:47:53,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:47:53,905 INFO:     Epoch: 59
2023-01-05 08:47:56,061 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3724735746781031, 'Total loss': 0.3724735746781031} | train loss {'Reaction outcome loss': 0.2942759206901819, 'Total loss': 0.2942759206901819}
2023-01-05 08:47:56,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:47:56,061 INFO:     Epoch: 60
2023-01-05 08:47:58,231 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.37777627805868785, 'Total loss': 0.37777627805868785} | train loss {'Reaction outcome loss': 0.29669098136442235, 'Total loss': 0.29669098136442235}
2023-01-05 08:47:58,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:47:58,232 INFO:     Epoch: 61
2023-01-05 08:48:00,383 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3987168642381827, 'Total loss': 0.3987168642381827} | train loss {'Reaction outcome loss': 0.3032142602256919, 'Total loss': 0.3032142602256919}
2023-01-05 08:48:00,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:48:00,383 INFO:     Epoch: 62
2023-01-05 08:48:02,569 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.387265478571256, 'Total loss': 0.387265478571256} | train loss {'Reaction outcome loss': 0.28750234070344954, 'Total loss': 0.28750234070344954}
2023-01-05 08:48:02,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:48:02,569 INFO:     Epoch: 63
2023-01-05 08:48:04,744 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44542898138364156, 'Total loss': 0.44542898138364156} | train loss {'Reaction outcome loss': 0.29207588635411935, 'Total loss': 0.29207588635411935}
2023-01-05 08:48:04,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:48:04,744 INFO:     Epoch: 64
2023-01-05 08:48:06,913 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.416539658109347, 'Total loss': 0.416539658109347} | train loss {'Reaction outcome loss': 0.2875395171371178, 'Total loss': 0.2875395171371178}
2023-01-05 08:48:06,914 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:48:06,914 INFO:     Epoch: 65
2023-01-05 08:48:09,061 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3743027528127035, 'Total loss': 0.3743027528127035} | train loss {'Reaction outcome loss': 0.28988962403972657, 'Total loss': 0.28988962403972657}
2023-01-05 08:48:09,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:48:09,062 INFO:     Epoch: 66
2023-01-05 08:48:11,237 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3819318433602651, 'Total loss': 0.3819318433602651} | train loss {'Reaction outcome loss': 0.2822734552169965, 'Total loss': 0.2822734552169965}
2023-01-05 08:48:11,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:48:11,237 INFO:     Epoch: 67
2023-01-05 08:48:13,434 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3826500455538432, 'Total loss': 0.3826500455538432} | train loss {'Reaction outcome loss': 0.28152906571915004, 'Total loss': 0.28152906571915004}
2023-01-05 08:48:13,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:48:13,435 INFO:     Epoch: 68
2023-01-05 08:48:15,612 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3806541075309118, 'Total loss': 0.3806541075309118} | train loss {'Reaction outcome loss': 0.2787109987426966, 'Total loss': 0.2787109987426966}
2023-01-05 08:48:15,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:48:15,613 INFO:     Epoch: 69
2023-01-05 08:48:17,767 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3780221352974574, 'Total loss': 0.3780221352974574} | train loss {'Reaction outcome loss': 0.27343367727385964, 'Total loss': 0.27343367727385964}
2023-01-05 08:48:17,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:48:17,767 INFO:     Epoch: 70
2023-01-05 08:48:19,917 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42111950715382895, 'Total loss': 0.42111950715382895} | train loss {'Reaction outcome loss': 0.27798232888056484, 'Total loss': 0.27798232888056484}
2023-01-05 08:48:19,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:48:19,918 INFO:     Epoch: 71
2023-01-05 08:48:22,068 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3803552101055781, 'Total loss': 0.3803552101055781} | train loss {'Reaction outcome loss': 0.27472068413769296, 'Total loss': 0.27472068413769296}
2023-01-05 08:48:22,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:48:22,068 INFO:     Epoch: 72
2023-01-05 08:48:24,242 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3769918215771516, 'Total loss': 0.3769918215771516} | train loss {'Reaction outcome loss': 0.2741053213536847, 'Total loss': 0.2741053213536847}
2023-01-05 08:48:24,242 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:48:24,242 INFO:     Epoch: 73
2023-01-05 08:48:26,399 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39468689759572345, 'Total loss': 0.39468689759572345} | train loss {'Reaction outcome loss': 0.27717175938538696, 'Total loss': 0.27717175938538696}
2023-01-05 08:48:26,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:48:26,400 INFO:     Epoch: 74
2023-01-05 08:48:28,567 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.39951552351315817, 'Total loss': 0.39951552351315817} | train loss {'Reaction outcome loss': 0.2677922947298641, 'Total loss': 0.2677922947298641}
2023-01-05 08:48:28,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:48:28,568 INFO:     Epoch: 75
2023-01-05 08:48:30,734 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4028525918722153, 'Total loss': 0.4028525918722153} | train loss {'Reaction outcome loss': 0.27129703052745396, 'Total loss': 0.27129703052745396}
2023-01-05 08:48:30,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:48:30,734 INFO:     Epoch: 76
2023-01-05 08:48:32,878 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.36978555619716647, 'Total loss': 0.36978555619716647} | train loss {'Reaction outcome loss': 0.2700738436155801, 'Total loss': 0.2700738436155801}
2023-01-05 08:48:32,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:48:32,879 INFO:     Epoch: 77
2023-01-05 08:48:35,061 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3959749013185501, 'Total loss': 0.3959749013185501} | train loss {'Reaction outcome loss': 0.26859162849061435, 'Total loss': 0.26859162849061435}
2023-01-05 08:48:35,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:48:35,061 INFO:     Epoch: 78
2023-01-05 08:48:37,231 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.38648019582033155, 'Total loss': 0.38648019582033155} | train loss {'Reaction outcome loss': 0.2619676803867417, 'Total loss': 0.2619676803867417}
2023-01-05 08:48:37,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:48:37,232 INFO:     Epoch: 79
2023-01-05 08:48:39,398 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42952382067839306, 'Total loss': 0.42952382067839306} | train loss {'Reaction outcome loss': 0.26983297262542516, 'Total loss': 0.26983297262542516}
2023-01-05 08:48:39,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:48:39,399 INFO:     Epoch: 80
2023-01-05 08:48:41,595 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3831042657295863, 'Total loss': 0.3831042657295863} | train loss {'Reaction outcome loss': 0.26870227383200873, 'Total loss': 0.26870227383200873}
2023-01-05 08:48:41,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:48:41,596 INFO:     Epoch: 81
2023-01-05 08:48:43,778 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.38033526788155236, 'Total loss': 0.38033526788155236} | train loss {'Reaction outcome loss': 0.26081458136224145, 'Total loss': 0.26081458136224145}
2023-01-05 08:48:43,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:48:43,778 INFO:     Epoch: 82
2023-01-05 08:48:45,979 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3826711192727089, 'Total loss': 0.3826711192727089} | train loss {'Reaction outcome loss': 0.2580307340955476, 'Total loss': 0.2580307340955476}
2023-01-05 08:48:45,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:48:45,979 INFO:     Epoch: 83
2023-01-05 08:48:48,171 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3776188611984253, 'Total loss': 0.3776188611984253} | train loss {'Reaction outcome loss': 0.26498914557082126, 'Total loss': 0.26498914557082126}
2023-01-05 08:48:48,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:48:48,172 INFO:     Epoch: 84
2023-01-05 08:48:50,342 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38758188088734946, 'Total loss': 0.38758188088734946} | train loss {'Reaction outcome loss': 0.24922371092202, 'Total loss': 0.24922371092202}
2023-01-05 08:48:50,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:48:50,342 INFO:     Epoch: 85
2023-01-05 08:48:52,528 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3956463158130646, 'Total loss': 0.3956463158130646} | train loss {'Reaction outcome loss': 0.25258349999785423, 'Total loss': 0.25258349999785423}
2023-01-05 08:48:52,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:48:52,528 INFO:     Epoch: 86
2023-01-05 08:48:54,703 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3673477411270142, 'Total loss': 0.3673477411270142} | train loss {'Reaction outcome loss': 0.2588282546889212, 'Total loss': 0.2588282546889212}
2023-01-05 08:48:54,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:48:54,704 INFO:     Epoch: 87
2023-01-05 08:48:56,913 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41105855305989586, 'Total loss': 0.41105855305989586} | train loss {'Reaction outcome loss': 0.25331980499711276, 'Total loss': 0.25331980499711276}
2023-01-05 08:48:56,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:48:56,913 INFO:     Epoch: 88
2023-01-05 08:48:59,120 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.40556959609190624, 'Total loss': 0.40556959609190624} | train loss {'Reaction outcome loss': 0.25669351634350923, 'Total loss': 0.25669351634350923}
2023-01-05 08:48:59,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:48:59,121 INFO:     Epoch: 89
2023-01-05 08:49:01,312 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41361687481403353, 'Total loss': 0.41361687481403353} | train loss {'Reaction outcome loss': 0.25252876387714046, 'Total loss': 0.25252876387714046}
2023-01-05 08:49:01,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:49:01,313 INFO:     Epoch: 90
2023-01-05 08:49:03,478 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.381704843044281, 'Total loss': 0.381704843044281} | train loss {'Reaction outcome loss': 0.2501568375390682, 'Total loss': 0.2501568375390682}
2023-01-05 08:49:03,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:49:03,478 INFO:     Epoch: 91
2023-01-05 08:49:05,671 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3916146904230118, 'Total loss': 0.3916146904230118} | train loss {'Reaction outcome loss': 0.25119821311038537, 'Total loss': 0.25119821311038537}
2023-01-05 08:49:05,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:49:05,671 INFO:     Epoch: 92
2023-01-05 08:49:07,841 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.400924222668012, 'Total loss': 0.400924222668012} | train loss {'Reaction outcome loss': 0.24590135760780168, 'Total loss': 0.24590135760780168}
2023-01-05 08:49:07,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:49:07,841 INFO:     Epoch: 93
2023-01-05 08:49:10,045 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3819088170925776, 'Total loss': 0.3819088170925776} | train loss {'Reaction outcome loss': 0.2466768688650042, 'Total loss': 0.2466768688650042}
2023-01-05 08:49:10,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:49:10,046 INFO:     Epoch: 94
2023-01-05 08:49:12,251 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.36796759963035586, 'Total loss': 0.36796759963035586} | train loss {'Reaction outcome loss': 0.2447899505092564, 'Total loss': 0.2447899505092564}
2023-01-05 08:49:12,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:49:12,251 INFO:     Epoch: 95
2023-01-05 08:49:14,439 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.37991920560598375, 'Total loss': 0.37991920560598375} | train loss {'Reaction outcome loss': 0.2509273168385459, 'Total loss': 0.2509273168385459}
2023-01-05 08:49:14,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:49:14,439 INFO:     Epoch: 96
2023-01-05 08:49:16,641 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.35402690383295216, 'Total loss': 0.35402690383295216} | train loss {'Reaction outcome loss': 0.2479009904935687, 'Total loss': 0.2479009904935687}
2023-01-05 08:49:16,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:49:16,643 INFO:     Epoch: 97
2023-01-05 08:49:18,822 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3854457139968872, 'Total loss': 0.3854457139968872} | train loss {'Reaction outcome loss': 0.2514260699737158, 'Total loss': 0.2514260699737158}
2023-01-05 08:49:18,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:49:18,822 INFO:     Epoch: 98
2023-01-05 08:49:21,017 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3895764112472534, 'Total loss': 0.3895764112472534} | train loss {'Reaction outcome loss': 0.2518625686664659, 'Total loss': 0.2518625686664659}
2023-01-05 08:49:21,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:49:21,017 INFO:     Epoch: 99
2023-01-05 08:49:23,215 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.37808149655659995, 'Total loss': 0.37808149655659995} | train loss {'Reaction outcome loss': 0.24641110756121817, 'Total loss': 0.24641110756121817}
2023-01-05 08:49:23,215 INFO:     Best model found after epoch 54 of 100.
2023-01-05 08:49:23,216 INFO:   Done with stage: TRAINING
2023-01-05 08:49:23,216 INFO:   Starting stage: EVALUATION
2023-01-05 08:49:23,343 INFO:   Done with stage: EVALUATION
2023-01-05 08:49:23,343 INFO:   Leaving out SEQ value Fold_9
2023-01-05 08:49:23,356 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 08:49:23,356 INFO:   Starting stage: FEATURE SCALING
2023-01-05 08:49:24,018 INFO:   Done with stage: FEATURE SCALING
2023-01-05 08:49:24,018 INFO:   Starting stage: SCALING TARGETS
2023-01-05 08:49:24,088 INFO:   Done with stage: SCALING TARGETS
2023-01-05 08:49:24,089 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:49:24,089 INFO:     No hyperparam tuning for this model
2023-01-05 08:49:24,089 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:49:24,089 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 08:49:24,089 INFO:     None feature selector for col prot
2023-01-05 08:49:24,090 INFO:     None feature selector for col prot
2023-01-05 08:49:24,090 INFO:     None feature selector for col prot
2023-01-05 08:49:24,090 INFO:     None feature selector for col chem
2023-01-05 08:49:24,090 INFO:     None feature selector for col chem
2023-01-05 08:49:24,090 INFO:     None feature selector for col chem
2023-01-05 08:49:24,090 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 08:49:24,091 INFO:   Starting stage: BUILD MODEL
2023-01-05 08:49:24,092 INFO:     Number of params in model 72901
2023-01-05 08:49:24,095 INFO:   Done with stage: BUILD MODEL
2023-01-05 08:49:24,095 INFO:   Starting stage: TRAINING
2023-01-05 08:49:24,156 INFO:     Val loss before train {'Reaction outcome loss': 0.9363236218690872, 'Total loss': 0.9363236218690872}
2023-01-05 08:49:24,156 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:49:24,157 INFO:     Epoch: 0
2023-01-05 08:49:26,300 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8287075797716776, 'Total loss': 0.8287075797716776} | train loss {'Reaction outcome loss': 0.936418083158956, 'Total loss': 0.936418083158956}
2023-01-05 08:49:26,300 INFO:     Found new best model at epoch 0
2023-01-05 08:49:26,301 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:49:26,302 INFO:     Epoch: 1
2023-01-05 08:49:28,471 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6415503938992818, 'Total loss': 0.6415503938992818} | train loss {'Reaction outcome loss': 0.7657780030715293, 'Total loss': 0.7657780030715293}
2023-01-05 08:49:28,471 INFO:     Found new best model at epoch 1
2023-01-05 08:49:28,472 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:49:28,472 INFO:     Epoch: 2
2023-01-05 08:49:30,619 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5688648184140523, 'Total loss': 0.5688648184140523} | train loss {'Reaction outcome loss': 0.603105062045211, 'Total loss': 0.603105062045211}
2023-01-05 08:49:30,619 INFO:     Found new best model at epoch 2
2023-01-05 08:49:30,620 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:49:30,620 INFO:     Epoch: 3
2023-01-05 08:49:32,798 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5333468347787857, 'Total loss': 0.5333468347787857} | train loss {'Reaction outcome loss': 0.5441839348902737, 'Total loss': 0.5441839348902737}
2023-01-05 08:49:32,798 INFO:     Found new best model at epoch 3
2023-01-05 08:49:32,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:49:32,799 INFO:     Epoch: 4
2023-01-05 08:49:34,957 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.529211300611496, 'Total loss': 0.529211300611496} | train loss {'Reaction outcome loss': 0.5238475171930116, 'Total loss': 0.5238475171930116}
2023-01-05 08:49:34,958 INFO:     Found new best model at epoch 4
2023-01-05 08:49:34,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:49:34,959 INFO:     Epoch: 5
2023-01-05 08:49:37,105 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5081284483273824, 'Total loss': 0.5081284483273824} | train loss {'Reaction outcome loss': 0.502820880935136, 'Total loss': 0.502820880935136}
2023-01-05 08:49:37,106 INFO:     Found new best model at epoch 5
2023-01-05 08:49:37,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:49:37,108 INFO:     Epoch: 6
2023-01-05 08:49:39,282 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.514298415184021, 'Total loss': 0.514298415184021} | train loss {'Reaction outcome loss': 0.49517593006400956, 'Total loss': 0.49517593006400956}
2023-01-05 08:49:39,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:49:39,282 INFO:     Epoch: 7
2023-01-05 08:49:41,433 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5066517412662506, 'Total loss': 0.5066517412662506} | train loss {'Reaction outcome loss': 0.4938451328067669, 'Total loss': 0.4938451328067669}
2023-01-05 08:49:41,434 INFO:     Found new best model at epoch 7
2023-01-05 08:49:41,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:49:41,435 INFO:     Epoch: 8
2023-01-05 08:49:43,583 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5100576867659886, 'Total loss': 0.5100576867659886} | train loss {'Reaction outcome loss': 0.4878572386999925, 'Total loss': 0.4878572386999925}
2023-01-05 08:49:43,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:49:43,583 INFO:     Epoch: 9
2023-01-05 08:49:45,739 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5092723488807678, 'Total loss': 0.5092723488807678} | train loss {'Reaction outcome loss': 0.4770823421726084, 'Total loss': 0.4770823421726084}
2023-01-05 08:49:45,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:49:45,740 INFO:     Epoch: 10
2023-01-05 08:49:47,889 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5032610674699147, 'Total loss': 0.5032610674699147} | train loss {'Reaction outcome loss': 0.4675514601494533, 'Total loss': 0.4675514601494533}
2023-01-05 08:49:47,889 INFO:     Found new best model at epoch 10
2023-01-05 08:49:47,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:49:47,891 INFO:     Epoch: 11
2023-01-05 08:49:50,113 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4921288013458252, 'Total loss': 0.4921288013458252} | train loss {'Reaction outcome loss': 0.4702935156655376, 'Total loss': 0.4702935156655376}
2023-01-05 08:49:50,113 INFO:     Found new best model at epoch 11
2023-01-05 08:49:50,114 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:49:50,114 INFO:     Epoch: 12
2023-01-05 08:49:52,343 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4907890687386195, 'Total loss': 0.4907890687386195} | train loss {'Reaction outcome loss': 0.4631450716633876, 'Total loss': 0.4631450716633876}
2023-01-05 08:49:52,344 INFO:     Found new best model at epoch 12
2023-01-05 08:49:52,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:49:52,346 INFO:     Epoch: 13
2023-01-05 08:49:54,295 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47904047966003416, 'Total loss': 0.47904047966003416} | train loss {'Reaction outcome loss': 0.45529031747719273, 'Total loss': 0.45529031747719273}
2023-01-05 08:49:54,296 INFO:     Found new best model at epoch 13
2023-01-05 08:49:54,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:49:54,297 INFO:     Epoch: 14
2023-01-05 08:49:56,454 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5178156077861786, 'Total loss': 0.5178156077861786} | train loss {'Reaction outcome loss': 0.47265759855508804, 'Total loss': 0.47265759855508804}
2023-01-05 08:49:56,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:49:56,455 INFO:     Epoch: 15
2023-01-05 08:49:58,657 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48710489173730215, 'Total loss': 0.48710489173730215} | train loss {'Reaction outcome loss': 0.4418667276234676, 'Total loss': 0.4418667276234676}
2023-01-05 08:49:58,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:49:58,657 INFO:     Epoch: 16
2023-01-05 08:50:00,811 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4788495570421219, 'Total loss': 0.4788495570421219} | train loss {'Reaction outcome loss': 0.43707109988073184, 'Total loss': 0.43707109988073184}
2023-01-05 08:50:00,812 INFO:     Found new best model at epoch 16
2023-01-05 08:50:00,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:50:00,813 INFO:     Epoch: 17
2023-01-05 08:50:02,982 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4804983596007029, 'Total loss': 0.4804983596007029} | train loss {'Reaction outcome loss': 0.4398175245825795, 'Total loss': 0.4398175245825795}
2023-01-05 08:50:02,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:50:02,983 INFO:     Epoch: 18
2023-01-05 08:50:05,128 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4783323009808858, 'Total loss': 0.4783323009808858} | train loss {'Reaction outcome loss': 0.43743574219769327, 'Total loss': 0.43743574219769327}
2023-01-05 08:50:05,128 INFO:     Found new best model at epoch 18
2023-01-05 08:50:05,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:50:05,129 INFO:     Epoch: 19
2023-01-05 08:50:07,282 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4839506924152374, 'Total loss': 0.4839506924152374} | train loss {'Reaction outcome loss': 0.4386410874078823, 'Total loss': 0.4386410874078823}
2023-01-05 08:50:07,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:50:07,282 INFO:     Epoch: 20
2023-01-05 08:50:09,426 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4722966174284617, 'Total loss': 0.4722966174284617} | train loss {'Reaction outcome loss': 0.4249520859498855, 'Total loss': 0.4249520859498855}
2023-01-05 08:50:09,426 INFO:     Found new best model at epoch 20
2023-01-05 08:50:09,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:50:09,427 INFO:     Epoch: 21
2023-01-05 08:50:11,542 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4755773862202962, 'Total loss': 0.4755773862202962} | train loss {'Reaction outcome loss': 0.42673035788259545, 'Total loss': 0.42673035788259545}
2023-01-05 08:50:11,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:50:11,543 INFO:     Epoch: 22
2023-01-05 08:50:13,705 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.49505192240079243, 'Total loss': 0.49505192240079243} | train loss {'Reaction outcome loss': 0.4191623678771725, 'Total loss': 0.4191623678771725}
2023-01-05 08:50:13,705 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:50:13,706 INFO:     Epoch: 23
2023-01-05 08:50:15,856 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4371377686659495, 'Total loss': 0.4371377686659495} | train loss {'Reaction outcome loss': 0.4165420700235805, 'Total loss': 0.4165420700235805}
2023-01-05 08:50:15,857 INFO:     Found new best model at epoch 23
2023-01-05 08:50:15,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:50:15,858 INFO:     Epoch: 24
2023-01-05 08:50:18,022 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5032491395870845, 'Total loss': 0.5032491395870845} | train loss {'Reaction outcome loss': 0.4113161229069574, 'Total loss': 0.4113161229069574}
2023-01-05 08:50:18,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:50:18,022 INFO:     Epoch: 25
2023-01-05 08:50:20,164 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45970011353492735, 'Total loss': 0.45970011353492735} | train loss {'Reaction outcome loss': 0.40380678274601267, 'Total loss': 0.40380678274601267}
2023-01-05 08:50:20,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:50:20,164 INFO:     Epoch: 26
2023-01-05 08:50:22,320 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.48149590094884237, 'Total loss': 0.48149590094884237} | train loss {'Reaction outcome loss': 0.40789499229081033, 'Total loss': 0.40789499229081033}
2023-01-05 08:50:22,320 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:50:22,320 INFO:     Epoch: 27
2023-01-05 08:50:24,451 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.46594091852506003, 'Total loss': 0.46594091852506003} | train loss {'Reaction outcome loss': 0.40489559232061595, 'Total loss': 0.40489559232061595}
2023-01-05 08:50:24,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:50:24,451 INFO:     Epoch: 28
2023-01-05 08:50:26,609 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.5377446472644806, 'Total loss': 0.5377446472644806} | train loss {'Reaction outcome loss': 0.4149038319516441, 'Total loss': 0.4149038319516441}
2023-01-05 08:50:26,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:50:26,610 INFO:     Epoch: 29
2023-01-05 08:50:28,766 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4886974553267161, 'Total loss': 0.4886974553267161} | train loss {'Reaction outcome loss': 0.4710307394194862, 'Total loss': 0.4710307394194862}
2023-01-05 08:50:28,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:50:28,767 INFO:     Epoch: 30
2023-01-05 08:50:30,919 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.543373417854309, 'Total loss': 0.543373417854309} | train loss {'Reaction outcome loss': 0.41547949355942587, 'Total loss': 0.41547949355942587}
2023-01-05 08:50:30,919 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:50:30,919 INFO:     Epoch: 31
2023-01-05 08:50:33,061 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.48536555071671805, 'Total loss': 0.48536555071671805} | train loss {'Reaction outcome loss': 0.3953256404594235, 'Total loss': 0.3953256404594235}
2023-01-05 08:50:33,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:50:33,061 INFO:     Epoch: 32
2023-01-05 08:50:35,212 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4950009008248647, 'Total loss': 0.4950009008248647} | train loss {'Reaction outcome loss': 0.3902212819949204, 'Total loss': 0.3902212819949204}
2023-01-05 08:50:35,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:50:35,213 INFO:     Epoch: 33
2023-01-05 08:50:37,368 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.46239220798015596, 'Total loss': 0.46239220798015596} | train loss {'Reaction outcome loss': 0.3851905304506637, 'Total loss': 0.3851905304506637}
2023-01-05 08:50:37,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:50:37,368 INFO:     Epoch: 34
2023-01-05 08:50:39,529 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5219692746798198, 'Total loss': 0.5219692746798198} | train loss {'Reaction outcome loss': 0.3842874073247979, 'Total loss': 0.3842874073247979}
2023-01-05 08:50:39,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:50:39,529 INFO:     Epoch: 35
2023-01-05 08:50:41,670 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.45527544418970745, 'Total loss': 0.45527544418970745} | train loss {'Reaction outcome loss': 0.38221399973322084, 'Total loss': 0.38221399973322084}
2023-01-05 08:50:41,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:50:41,670 INFO:     Epoch: 36
2023-01-05 08:50:43,844 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43798939883708954, 'Total loss': 0.43798939883708954} | train loss {'Reaction outcome loss': 0.36983168607379857, 'Total loss': 0.36983168607379857}
2023-01-05 08:50:43,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:50:43,844 INFO:     Epoch: 37
2023-01-05 08:50:45,997 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4630915865302086, 'Total loss': 0.4630915865302086} | train loss {'Reaction outcome loss': 0.3675745508941965, 'Total loss': 0.3675745508941965}
2023-01-05 08:50:45,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:50:45,998 INFO:     Epoch: 38
2023-01-05 08:50:48,166 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4551366706689199, 'Total loss': 0.4551366706689199} | train loss {'Reaction outcome loss': 0.36533267742893455, 'Total loss': 0.36533267742893455}
2023-01-05 08:50:48,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:50:48,167 INFO:     Epoch: 39
2023-01-05 08:50:50,327 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.449069020152092, 'Total loss': 0.449069020152092} | train loss {'Reaction outcome loss': 0.3555210449233435, 'Total loss': 0.3555210449233435}
2023-01-05 08:50:50,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:50:50,327 INFO:     Epoch: 40
2023-01-05 08:50:52,470 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4717685470978419, 'Total loss': 0.4717685470978419} | train loss {'Reaction outcome loss': 0.36074912234510814, 'Total loss': 0.36074912234510814}
2023-01-05 08:50:52,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:50:52,470 INFO:     Epoch: 41
2023-01-05 08:50:54,656 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4295650859673818, 'Total loss': 0.4295650859673818} | train loss {'Reaction outcome loss': 0.3499209249317916, 'Total loss': 0.3499209249317916}
2023-01-05 08:50:54,656 INFO:     Found new best model at epoch 41
2023-01-05 08:50:54,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:50:54,657 INFO:     Epoch: 42
2023-01-05 08:50:56,811 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4625040511290232, 'Total loss': 0.4625040511290232} | train loss {'Reaction outcome loss': 0.3554342506665136, 'Total loss': 0.3554342506665136}
2023-01-05 08:50:56,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:50:56,811 INFO:     Epoch: 43
2023-01-05 08:50:58,955 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.44750309785207115, 'Total loss': 0.44750309785207115} | train loss {'Reaction outcome loss': 0.34658108946894284, 'Total loss': 0.34658108946894284}
2023-01-05 08:50:58,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:50:58,956 INFO:     Epoch: 44
2023-01-05 08:51:01,115 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4426795264085134, 'Total loss': 0.4426795264085134} | train loss {'Reaction outcome loss': 0.34929034830597433, 'Total loss': 0.34929034830597433}
2023-01-05 08:51:01,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:51:01,116 INFO:     Epoch: 45
2023-01-05 08:51:03,272 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.5001241902510325, 'Total loss': 0.5001241902510325} | train loss {'Reaction outcome loss': 0.34021686894846137, 'Total loss': 0.34021686894846137}
2023-01-05 08:51:03,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:51:03,272 INFO:     Epoch: 46
2023-01-05 08:51:05,417 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4634219805399577, 'Total loss': 0.4634219805399577} | train loss {'Reaction outcome loss': 0.3530529215003944, 'Total loss': 0.3530529215003944}
2023-01-05 08:51:05,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:51:05,418 INFO:     Epoch: 47
2023-01-05 08:51:07,577 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4632036437590917, 'Total loss': 0.4632036437590917} | train loss {'Reaction outcome loss': 0.3374234912259018, 'Total loss': 0.3374234912259018}
2023-01-05 08:51:07,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:51:07,577 INFO:     Epoch: 48
2023-01-05 08:51:09,726 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.49306950668493904, 'Total loss': 0.49306950668493904} | train loss {'Reaction outcome loss': 0.33794423644903343, 'Total loss': 0.33794423644903343}
2023-01-05 08:51:09,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:51:09,726 INFO:     Epoch: 49
2023-01-05 08:51:11,882 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.46879769961039225, 'Total loss': 0.46879769961039225} | train loss {'Reaction outcome loss': 0.34672241189105407, 'Total loss': 0.34672241189105407}
2023-01-05 08:51:11,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:51:11,883 INFO:     Epoch: 50
2023-01-05 08:51:14,032 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.46193529963493346, 'Total loss': 0.46193529963493346} | train loss {'Reaction outcome loss': 0.3301535519244878, 'Total loss': 0.3301535519244878}
2023-01-05 08:51:14,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:51:14,032 INFO:     Epoch: 51
2023-01-05 08:51:16,172 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4588330239057541, 'Total loss': 0.4588330239057541} | train loss {'Reaction outcome loss': 0.34511215048774646, 'Total loss': 0.34511215048774646}
2023-01-05 08:51:16,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:51:16,172 INFO:     Epoch: 52
2023-01-05 08:51:18,350 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.49651842514673866, 'Total loss': 0.49651842514673866} | train loss {'Reaction outcome loss': 0.3314780963287837, 'Total loss': 0.3314780963287837}
2023-01-05 08:51:18,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:51:18,350 INFO:     Epoch: 53
2023-01-05 08:51:20,511 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4665727064013481, 'Total loss': 0.4665727064013481} | train loss {'Reaction outcome loss': 0.3352674692734212, 'Total loss': 0.3352674692734212}
2023-01-05 08:51:20,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:51:20,511 INFO:     Epoch: 54
2023-01-05 08:51:22,658 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4701494430502256, 'Total loss': 0.4701494430502256} | train loss {'Reaction outcome loss': 0.32892272592879884, 'Total loss': 0.32892272592879884}
2023-01-05 08:51:22,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:51:22,658 INFO:     Epoch: 55
2023-01-05 08:51:24,817 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4803907891114553, 'Total loss': 0.4803907891114553} | train loss {'Reaction outcome loss': 0.3275860223136302, 'Total loss': 0.3275860223136302}
2023-01-05 08:51:24,817 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:51:24,818 INFO:     Epoch: 56
2023-01-05 08:51:26,978 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.5076629002888997, 'Total loss': 0.5076629002888997} | train loss {'Reaction outcome loss': 0.415412893022775, 'Total loss': 0.415412893022775}
2023-01-05 08:51:26,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:51:26,979 INFO:     Epoch: 57
2023-01-05 08:51:29,137 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4801584452390671, 'Total loss': 0.4801584452390671} | train loss {'Reaction outcome loss': 0.3368182693055765, 'Total loss': 0.3368182693055765}
2023-01-05 08:51:29,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:51:29,137 INFO:     Epoch: 58
2023-01-05 08:51:31,309 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5011122763156891, 'Total loss': 0.5011122763156891} | train loss {'Reaction outcome loss': 0.3254439273943612, 'Total loss': 0.3254439273943612}
2023-01-05 08:51:31,309 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:51:31,309 INFO:     Epoch: 59
2023-01-05 08:51:33,469 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.49116647938887276, 'Total loss': 0.49116647938887276} | train loss {'Reaction outcome loss': 0.32899054323417554, 'Total loss': 0.32899054323417554}
2023-01-05 08:51:33,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:51:33,470 INFO:     Epoch: 60
2023-01-05 08:51:35,634 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.44192051887512207, 'Total loss': 0.44192051887512207} | train loss {'Reaction outcome loss': 0.4032974390016086, 'Total loss': 0.4032974390016086}
2023-01-05 08:51:35,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:51:35,635 INFO:     Epoch: 61
2023-01-05 08:51:37,799 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47353373765945433, 'Total loss': 0.47353373765945433} | train loss {'Reaction outcome loss': 0.35596431094492564, 'Total loss': 0.35596431094492564}
2023-01-05 08:51:37,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:51:37,799 INFO:     Epoch: 62
2023-01-05 08:51:39,949 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4542599022388458, 'Total loss': 0.4542599022388458} | train loss {'Reaction outcome loss': 0.3154400947582674, 'Total loss': 0.3154400947582674}
2023-01-05 08:51:39,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:51:39,950 INFO:     Epoch: 63
2023-01-05 08:51:42,104 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4857954651117325, 'Total loss': 0.4857954651117325} | train loss {'Reaction outcome loss': 0.3048997005309397, 'Total loss': 0.3048997005309397}
2023-01-05 08:51:42,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:51:42,105 INFO:     Epoch: 64
2023-01-05 08:51:44,255 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4396555165449778, 'Total loss': 0.4396555165449778} | train loss {'Reaction outcome loss': 0.30819230432203715, 'Total loss': 0.30819230432203715}
2023-01-05 08:51:44,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:51:44,255 INFO:     Epoch: 65
2023-01-05 08:51:46,426 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4609491025408109, 'Total loss': 0.4609491025408109} | train loss {'Reaction outcome loss': 0.3026370860001855, 'Total loss': 0.3026370860001855}
2023-01-05 08:51:46,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:51:46,427 INFO:     Epoch: 66
2023-01-05 08:51:48,573 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4693901638189952, 'Total loss': 0.4693901638189952} | train loss {'Reaction outcome loss': 0.3055138950627567, 'Total loss': 0.3055138950627567}
2023-01-05 08:51:48,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:51:48,574 INFO:     Epoch: 67
2023-01-05 08:51:50,740 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4553301642338435, 'Total loss': 0.4553301642338435} | train loss {'Reaction outcome loss': 0.30669216964009177, 'Total loss': 0.30669216964009177}
2023-01-05 08:51:50,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:51:50,740 INFO:     Epoch: 68
2023-01-05 08:51:52,903 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.44260760545730593, 'Total loss': 0.44260760545730593} | train loss {'Reaction outcome loss': 0.2929763891327678, 'Total loss': 0.2929763891327678}
2023-01-05 08:51:52,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:51:52,903 INFO:     Epoch: 69
2023-01-05 08:51:55,067 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4392729957898458, 'Total loss': 0.4392729957898458} | train loss {'Reaction outcome loss': 0.2903130909200052, 'Total loss': 0.2903130909200052}
2023-01-05 08:51:55,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:51:55,068 INFO:     Epoch: 70
2023-01-05 08:51:57,213 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.43598195115725197, 'Total loss': 0.43598195115725197} | train loss {'Reaction outcome loss': 0.28621002873810736, 'Total loss': 0.28621002873810736}
2023-01-05 08:51:57,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:51:57,214 INFO:     Epoch: 71
2023-01-05 08:51:59,391 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4236343224843343, 'Total loss': 0.4236343224843343} | train loss {'Reaction outcome loss': 0.29046579911748954, 'Total loss': 0.29046579911748954}
2023-01-05 08:51:59,392 INFO:     Found new best model at epoch 71
2023-01-05 08:51:59,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:51:59,393 INFO:     Epoch: 72
2023-01-05 08:52:01,554 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4645240346590678, 'Total loss': 0.4645240346590678} | train loss {'Reaction outcome loss': 0.2870503235945775, 'Total loss': 0.2870503235945775}
2023-01-05 08:52:01,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:52:01,554 INFO:     Epoch: 73
2023-01-05 08:52:03,696 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4928302804629008, 'Total loss': 0.4928302804629008} | train loss {'Reaction outcome loss': 0.29259816271023475, 'Total loss': 0.29259816271023475}
2023-01-05 08:52:03,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:52:03,696 INFO:     Epoch: 74
2023-01-05 08:52:05,857 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.46015206972757977, 'Total loss': 0.46015206972757977} | train loss {'Reaction outcome loss': 0.3575058907702349, 'Total loss': 0.3575058907702349}
2023-01-05 08:52:05,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:52:05,857 INFO:     Epoch: 75
2023-01-05 08:52:08,007 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.45252756973107655, 'Total loss': 0.45252756973107655} | train loss {'Reaction outcome loss': 0.2991513093575781, 'Total loss': 0.2991513093575781}
2023-01-05 08:52:08,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:52:08,008 INFO:     Epoch: 76
2023-01-05 08:52:10,178 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44640350341796875, 'Total loss': 0.44640350341796875} | train loss {'Reaction outcome loss': 0.2832308837682501, 'Total loss': 0.2832308837682501}
2023-01-05 08:52:10,178 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:52:10,178 INFO:     Epoch: 77
2023-01-05 08:52:12,335 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4558577636877696, 'Total loss': 0.4558577636877696} | train loss {'Reaction outcome loss': 0.31302301308977, 'Total loss': 0.31302301308977}
2023-01-05 08:52:12,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:52:12,336 INFO:     Epoch: 78
2023-01-05 08:52:14,477 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45496454536914827, 'Total loss': 0.45496454536914827} | train loss {'Reaction outcome loss': 0.2893907482123367, 'Total loss': 0.2893907482123367}
2023-01-05 08:52:14,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:52:14,477 INFO:     Epoch: 79
2023-01-05 08:52:16,636 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.47642884266873203, 'Total loss': 0.47642884266873203} | train loss {'Reaction outcome loss': 0.2724460917156978, 'Total loss': 0.2724460917156978}
2023-01-05 08:52:16,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:52:16,636 INFO:     Epoch: 80
2023-01-05 08:52:18,786 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4563789834578832, 'Total loss': 0.4563789834578832} | train loss {'Reaction outcome loss': 0.27419863958909013, 'Total loss': 0.27419863958909013}
2023-01-05 08:52:18,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:52:18,787 INFO:     Epoch: 81
2023-01-05 08:52:20,933 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.43614912529786426, 'Total loss': 0.43614912529786426} | train loss {'Reaction outcome loss': 0.2736603000835664, 'Total loss': 0.2736603000835664}
2023-01-05 08:52:20,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:52:20,933 INFO:     Epoch: 82
2023-01-05 08:52:23,117 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4628353814284007, 'Total loss': 0.4628353814284007} | train loss {'Reaction outcome loss': 0.2743568623209021, 'Total loss': 0.2743568623209021}
2023-01-05 08:52:23,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:52:23,117 INFO:     Epoch: 83
2023-01-05 08:52:25,288 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.46098517775535586, 'Total loss': 0.46098517775535586} | train loss {'Reaction outcome loss': 0.2675841795820473, 'Total loss': 0.2675841795820473}
2023-01-05 08:52:25,288 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:52:25,288 INFO:     Epoch: 84
2023-01-05 08:52:27,502 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.49927031944195427, 'Total loss': 0.49927031944195427} | train loss {'Reaction outcome loss': 0.27075616055568075, 'Total loss': 0.27075616055568075}
2023-01-05 08:52:27,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:52:27,502 INFO:     Epoch: 85
2023-01-05 08:52:29,760 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4885148763656616, 'Total loss': 0.4885148763656616} | train loss {'Reaction outcome loss': 0.26314430818319373, 'Total loss': 0.26314430818319373}
2023-01-05 08:52:29,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:52:29,760 INFO:     Epoch: 86
2023-01-05 08:52:31,975 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.41077363590399424, 'Total loss': 0.41077363590399424} | train loss {'Reaction outcome loss': 0.2651169402659803, 'Total loss': 0.2651169402659803}
2023-01-05 08:52:31,976 INFO:     Found new best model at epoch 86
2023-01-05 08:52:31,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:52:31,977 INFO:     Epoch: 87
2023-01-05 08:52:34,189 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.44711743195851644, 'Total loss': 0.44711743195851644} | train loss {'Reaction outcome loss': 0.30664248468330724, 'Total loss': 0.30664248468330724}
2023-01-05 08:52:34,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:52:34,189 INFO:     Epoch: 88
2023-01-05 08:52:36,421 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.41934459706147514, 'Total loss': 0.41934459706147514} | train loss {'Reaction outcome loss': 0.2809475698926743, 'Total loss': 0.2809475698926743}
2023-01-05 08:52:36,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:52:36,421 INFO:     Epoch: 89
2023-01-05 08:52:38,660 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4773945997158686, 'Total loss': 0.4773945997158686} | train loss {'Reaction outcome loss': 0.27234403106917127, 'Total loss': 0.27234403106917127}
2023-01-05 08:52:38,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:52:38,661 INFO:     Epoch: 90
2023-01-05 08:52:40,907 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.47756491204102836, 'Total loss': 0.47756491204102836} | train loss {'Reaction outcome loss': 0.26407778391317616, 'Total loss': 0.26407778391317616}
2023-01-05 08:52:40,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:52:40,907 INFO:     Epoch: 91
2023-01-05 08:52:43,137 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5052359322706859, 'Total loss': 0.5052359322706859} | train loss {'Reaction outcome loss': 0.26445668474669853, 'Total loss': 0.26445668474669853}
2023-01-05 08:52:43,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:52:43,138 INFO:     Epoch: 92
2023-01-05 08:52:45,317 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.47131415208180744, 'Total loss': 0.47131415208180744} | train loss {'Reaction outcome loss': 0.26913109314095296, 'Total loss': 0.26913109314095296}
2023-01-05 08:52:45,317 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:52:45,317 INFO:     Epoch: 93
2023-01-05 08:52:47,486 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4440283050139745, 'Total loss': 0.4440283050139745} | train loss {'Reaction outcome loss': 0.2681149755211057, 'Total loss': 0.2681149755211057}
2023-01-05 08:52:47,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:52:47,486 INFO:     Epoch: 94
2023-01-05 08:52:49,644 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4456417540709178, 'Total loss': 0.4456417540709178} | train loss {'Reaction outcome loss': 0.26137520592200797, 'Total loss': 0.26137520592200797}
2023-01-05 08:52:49,645 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:52:49,645 INFO:     Epoch: 95
2023-01-05 08:52:51,907 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.42054368114719787, 'Total loss': 0.42054368114719787} | train loss {'Reaction outcome loss': 0.2553503614562678, 'Total loss': 0.2553503614562678}
2023-01-05 08:52:51,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:52:51,908 INFO:     Epoch: 96
2023-01-05 08:52:54,124 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4647075335184733, 'Total loss': 0.4647075335184733} | train loss {'Reaction outcome loss': 0.2561292126909762, 'Total loss': 0.2561292126909762}
2023-01-05 08:52:54,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:52:54,125 INFO:     Epoch: 97
2023-01-05 08:52:56,299 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4362877349058787, 'Total loss': 0.4362877349058787} | train loss {'Reaction outcome loss': 0.25836271034989977, 'Total loss': 0.25836271034989977}
2023-01-05 08:52:56,299 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:52:56,299 INFO:     Epoch: 98
2023-01-05 08:52:58,454 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4546840190887451, 'Total loss': 0.4546840190887451} | train loss {'Reaction outcome loss': 0.2530959889594722, 'Total loss': 0.2530959889594722}
2023-01-05 08:52:58,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:52:58,455 INFO:     Epoch: 99
2023-01-05 08:53:00,617 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4732019732395808, 'Total loss': 0.4732019732395808} | train loss {'Reaction outcome loss': 0.25440830944917514, 'Total loss': 0.25440830944917514}
2023-01-05 08:53:00,617 INFO:     Best model found after epoch 87 of 100.
2023-01-05 08:53:00,617 INFO:   Done with stage: TRAINING
2023-01-05 08:53:00,617 INFO:   Starting stage: EVALUATION
2023-01-05 08:53:00,747 INFO:   Done with stage: EVALUATION
2023-01-05 08:53:00,756 INFO:   Leaving out SEQ value Fold_0
2023-01-05 08:53:00,769 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 08:53:00,769 INFO:   Starting stage: FEATURE SCALING
2023-01-05 08:53:01,427 INFO:   Done with stage: FEATURE SCALING
2023-01-05 08:53:01,427 INFO:   Starting stage: SCALING TARGETS
2023-01-05 08:53:01,496 INFO:   Done with stage: SCALING TARGETS
2023-01-05 08:53:01,496 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:53:01,496 INFO:     No hyperparam tuning for this model
2023-01-05 08:53:01,496 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:53:01,496 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 08:53:01,497 INFO:     None feature selector for col prot
2023-01-05 08:53:01,497 INFO:     None feature selector for col prot
2023-01-05 08:53:01,497 INFO:     None feature selector for col prot
2023-01-05 08:53:01,498 INFO:     None feature selector for col chem
2023-01-05 08:53:01,498 INFO:     None feature selector for col chem
2023-01-05 08:53:01,498 INFO:     None feature selector for col chem
2023-01-05 08:53:01,498 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 08:53:01,498 INFO:   Starting stage: BUILD MODEL
2023-01-05 08:53:01,500 INFO:     Number of params in model 72901
2023-01-05 08:53:01,503 INFO:   Done with stage: BUILD MODEL
2023-01-05 08:53:01,503 INFO:   Starting stage: TRAINING
2023-01-05 08:53:01,561 INFO:     Val loss before train {'Reaction outcome loss': 1.0395347634951273, 'Total loss': 1.0395347634951273}
2023-01-05 08:53:01,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:53:01,561 INFO:     Epoch: 0
2023-01-05 08:53:03,697 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8662424286206564, 'Total loss': 0.8662424286206564} | train loss {'Reaction outcome loss': 0.9316809641836333, 'Total loss': 0.9316809641836333}
2023-01-05 08:53:03,698 INFO:     Found new best model at epoch 0
2023-01-05 08:53:03,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:53:03,699 INFO:     Epoch: 1
2023-01-05 08:53:05,818 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6188209235668183, 'Total loss': 0.6188209235668183} | train loss {'Reaction outcome loss': 0.7463607397610253, 'Total loss': 0.7463607397610253}
2023-01-05 08:53:05,818 INFO:     Found new best model at epoch 1
2023-01-05 08:53:05,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:53:05,820 INFO:     Epoch: 2
2023-01-05 08:53:07,938 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5537126779556274, 'Total loss': 0.5537126779556274} | train loss {'Reaction outcome loss': 0.5923282778176078, 'Total loss': 0.5923282778176078}
2023-01-05 08:53:07,938 INFO:     Found new best model at epoch 2
2023-01-05 08:53:07,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:53:07,940 INFO:     Epoch: 3
2023-01-05 08:53:10,086 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.558122307062149, 'Total loss': 0.558122307062149} | train loss {'Reaction outcome loss': 0.5444291849641034, 'Total loss': 0.5444291849641034}
2023-01-05 08:53:10,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:53:10,086 INFO:     Epoch: 4
2023-01-05 08:53:12,210 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5000188946723938, 'Total loss': 0.5000188946723938} | train loss {'Reaction outcome loss': 0.5201412524728879, 'Total loss': 0.5201412524728879}
2023-01-05 08:53:12,211 INFO:     Found new best model at epoch 4
2023-01-05 08:53:12,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:53:12,213 INFO:     Epoch: 5
2023-01-05 08:53:14,338 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5217863579591115, 'Total loss': 0.5217863579591115} | train loss {'Reaction outcome loss': 0.5045508687948659, 'Total loss': 0.5045508687948659}
2023-01-05 08:53:14,338 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:53:14,338 INFO:     Epoch: 6
2023-01-05 08:53:16,469 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.528747155268987, 'Total loss': 0.528747155268987} | train loss {'Reaction outcome loss': 0.48892517088756077, 'Total loss': 0.48892517088756077}
2023-01-05 08:53:16,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:53:16,469 INFO:     Epoch: 7
2023-01-05 08:53:18,601 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5100479185581207, 'Total loss': 0.5100479185581207} | train loss {'Reaction outcome loss': 0.48507893433536053, 'Total loss': 0.48507893433536053}
2023-01-05 08:53:18,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:53:18,602 INFO:     Epoch: 8
2023-01-05 08:53:20,725 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4822886308034261, 'Total loss': 0.4822886308034261} | train loss {'Reaction outcome loss': 0.48152594714269153, 'Total loss': 0.48152594714269153}
2023-01-05 08:53:20,725 INFO:     Found new best model at epoch 8
2023-01-05 08:53:20,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:53:20,726 INFO:     Epoch: 9
2023-01-05 08:53:22,857 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5050505459308624, 'Total loss': 0.5050505459308624} | train loss {'Reaction outcome loss': 0.47420688452076737, 'Total loss': 0.47420688452076737}
2023-01-05 08:53:22,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:53:22,858 INFO:     Epoch: 10
2023-01-05 08:53:24,980 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5149508734544118, 'Total loss': 0.5149508734544118} | train loss {'Reaction outcome loss': 0.465450120559574, 'Total loss': 0.465450120559574}
2023-01-05 08:53:24,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:53:24,981 INFO:     Epoch: 11
2023-01-05 08:53:27,119 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4954283833503723, 'Total loss': 0.4954283833503723} | train loss {'Reaction outcome loss': 0.462672624002843, 'Total loss': 0.462672624002843}
2023-01-05 08:53:27,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:53:27,119 INFO:     Epoch: 12
2023-01-05 08:53:29,247 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4845540463924408, 'Total loss': 0.4845540463924408} | train loss {'Reaction outcome loss': 0.45635617567892495, 'Total loss': 0.45635617567892495}
2023-01-05 08:53:29,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:53:29,247 INFO:     Epoch: 13
2023-01-05 08:53:31,377 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.49989896615346274, 'Total loss': 0.49989896615346274} | train loss {'Reaction outcome loss': 0.4600192937646469, 'Total loss': 0.4600192937646469}
2023-01-05 08:53:31,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:53:31,377 INFO:     Epoch: 14
2023-01-05 08:53:33,506 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5188933730125427, 'Total loss': 0.5188933730125427} | train loss {'Reaction outcome loss': 0.4543205083612978, 'Total loss': 0.4543205083612978}
2023-01-05 08:53:33,506 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:53:33,506 INFO:     Epoch: 15
2023-01-05 08:53:35,646 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.485775351524353, 'Total loss': 0.485775351524353} | train loss {'Reaction outcome loss': 0.4478582147590435, 'Total loss': 0.4478582147590435}
2023-01-05 08:53:35,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:53:35,646 INFO:     Epoch: 16
2023-01-05 08:53:37,759 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4825273315111796, 'Total loss': 0.4825273315111796} | train loss {'Reaction outcome loss': 0.44268566666402087, 'Total loss': 0.44268566666402087}
2023-01-05 08:53:37,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:53:37,759 INFO:     Epoch: 17
2023-01-05 08:53:39,879 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46999943231542907, 'Total loss': 0.46999943231542907} | train loss {'Reaction outcome loss': 0.4371131923947021, 'Total loss': 0.4371131923947021}
2023-01-05 08:53:39,879 INFO:     Found new best model at epoch 17
2023-01-05 08:53:39,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:53:39,881 INFO:     Epoch: 18
2023-01-05 08:53:42,077 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47867835660775504, 'Total loss': 0.47867835660775504} | train loss {'Reaction outcome loss': 0.4296277974643847, 'Total loss': 0.4296277974643847}
2023-01-05 08:53:42,077 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:53:42,077 INFO:     Epoch: 19
2023-01-05 08:53:44,230 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.48446255723635356, 'Total loss': 0.48446255723635356} | train loss {'Reaction outcome loss': 0.4324549432762348, 'Total loss': 0.4324549432762348}
2023-01-05 08:53:44,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:53:44,230 INFO:     Epoch: 20
2023-01-05 08:53:46,359 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4920619448026021, 'Total loss': 0.4920619448026021} | train loss {'Reaction outcome loss': 0.4265917715528151, 'Total loss': 0.4265917715528151}
2023-01-05 08:53:46,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:53:46,359 INFO:     Epoch: 21
2023-01-05 08:53:48,467 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4585343549648921, 'Total loss': 0.4585343549648921} | train loss {'Reaction outcome loss': 0.4232167319061547, 'Total loss': 0.4232167319061547}
2023-01-05 08:53:48,468 INFO:     Found new best model at epoch 21
2023-01-05 08:53:48,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:53:48,469 INFO:     Epoch: 22
2023-01-05 08:53:50,602 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.45188495715459187, 'Total loss': 0.45188495715459187} | train loss {'Reaction outcome loss': 0.4175724434754709, 'Total loss': 0.4175724434754709}
2023-01-05 08:53:50,602 INFO:     Found new best model at epoch 22
2023-01-05 08:53:50,603 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:53:50,604 INFO:     Epoch: 23
2023-01-05 08:53:52,718 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4797738969326019, 'Total loss': 0.4797738969326019} | train loss {'Reaction outcome loss': 0.4118998742723552, 'Total loss': 0.4118998742723552}
2023-01-05 08:53:52,718 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:53:52,718 INFO:     Epoch: 24
2023-01-05 08:53:54,844 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4726246953010559, 'Total loss': 0.4726246953010559} | train loss {'Reaction outcome loss': 0.4083875130562887, 'Total loss': 0.4083875130562887}
2023-01-05 08:53:54,844 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:53:54,845 INFO:     Epoch: 25
2023-01-05 08:53:56,983 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4663474917411804, 'Total loss': 0.4663474917411804} | train loss {'Reaction outcome loss': 0.4086136578915328, 'Total loss': 0.4086136578915328}
2023-01-05 08:53:56,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:53:56,983 INFO:     Epoch: 26
2023-01-05 08:53:59,100 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.471794335047404, 'Total loss': 0.471794335047404} | train loss {'Reaction outcome loss': 0.3955926111199125, 'Total loss': 0.3955926111199125}
2023-01-05 08:53:59,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:53:59,101 INFO:     Epoch: 27
2023-01-05 08:54:01,025 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4210783213376999, 'Total loss': 0.4210783213376999} | train loss {'Reaction outcome loss': 0.39341214369900906, 'Total loss': 0.39341214369900906}
2023-01-05 08:54:01,025 INFO:     Found new best model at epoch 27
2023-01-05 08:54:01,026 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:54:01,026 INFO:     Epoch: 28
2023-01-05 08:54:03,160 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44212365547815957, 'Total loss': 0.44212365547815957} | train loss {'Reaction outcome loss': 0.3912602965957927, 'Total loss': 0.3912602965957927}
2023-01-05 08:54:03,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:54:03,160 INFO:     Epoch: 29
2023-01-05 08:54:05,274 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4480190674463908, 'Total loss': 0.4480190674463908} | train loss {'Reaction outcome loss': 0.38639957523041396, 'Total loss': 0.38639957523041396}
2023-01-05 08:54:05,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:54:05,274 INFO:     Epoch: 30
2023-01-05 08:54:07,401 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4672974541783333, 'Total loss': 0.4672974541783333} | train loss {'Reaction outcome loss': 0.38474691977357345, 'Total loss': 0.38474691977357345}
2023-01-05 08:54:07,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:54:07,402 INFO:     Epoch: 31
2023-01-05 08:54:09,530 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.473128675421079, 'Total loss': 0.473128675421079} | train loss {'Reaction outcome loss': 0.38272643883297913, 'Total loss': 0.38272643883297913}
2023-01-05 08:54:09,530 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:54:09,531 INFO:     Epoch: 32
2023-01-05 08:54:11,681 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4493139833211899, 'Total loss': 0.4493139833211899} | train loss {'Reaction outcome loss': 0.3784329481966739, 'Total loss': 0.3784329481966739}
2023-01-05 08:54:11,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:54:11,681 INFO:     Epoch: 33
2023-01-05 08:54:13,800 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4313130815823873, 'Total loss': 0.4313130815823873} | train loss {'Reaction outcome loss': 0.37119952167799003, 'Total loss': 0.37119952167799003}
2023-01-05 08:54:13,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:54:13,800 INFO:     Epoch: 34
2023-01-05 08:54:15,959 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4409979561964671, 'Total loss': 0.4409979561964671} | train loss {'Reaction outcome loss': 0.3759003120073437, 'Total loss': 0.3759003120073437}
2023-01-05 08:54:15,959 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:54:15,959 INFO:     Epoch: 35
2023-01-05 08:54:18,088 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4537794892986616, 'Total loss': 0.4537794892986616} | train loss {'Reaction outcome loss': 0.36245711901000816, 'Total loss': 0.36245711901000816}
2023-01-05 08:54:18,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:54:18,088 INFO:     Epoch: 36
2023-01-05 08:54:20,209 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.45053440729777017, 'Total loss': 0.45053440729777017} | train loss {'Reaction outcome loss': 0.359511300132875, 'Total loss': 0.359511300132875}
2023-01-05 08:54:20,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:54:20,209 INFO:     Epoch: 37
2023-01-05 08:54:22,351 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4526997079451879, 'Total loss': 0.4526997079451879} | train loss {'Reaction outcome loss': 0.3606223828111687, 'Total loss': 0.3606223828111687}
2023-01-05 08:54:22,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:54:22,351 INFO:     Epoch: 38
2023-01-05 08:54:24,501 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42591847976048786, 'Total loss': 0.42591847976048786} | train loss {'Reaction outcome loss': 0.3582744358284195, 'Total loss': 0.3582744358284195}
2023-01-05 08:54:24,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:54:24,503 INFO:     Epoch: 39
2023-01-05 08:54:26,661 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42254619002342225, 'Total loss': 0.42254619002342225} | train loss {'Reaction outcome loss': 0.34841163684851933, 'Total loss': 0.34841163684851933}
2023-01-05 08:54:26,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:54:26,661 INFO:     Epoch: 40
2023-01-05 08:54:28,852 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4253656143943469, 'Total loss': 0.4253656143943469} | train loss {'Reaction outcome loss': 0.3512662797894356, 'Total loss': 0.3512662797894356}
2023-01-05 08:54:28,852 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:54:28,852 INFO:     Epoch: 41
2023-01-05 08:54:30,996 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.421931433180968, 'Total loss': 0.421931433180968} | train loss {'Reaction outcome loss': 0.3472882653892475, 'Total loss': 0.3472882653892475}
2023-01-05 08:54:30,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:54:30,997 INFO:     Epoch: 42
2023-01-05 08:54:33,122 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.42897856334845225, 'Total loss': 0.42897856334845225} | train loss {'Reaction outcome loss': 0.34619059330736196, 'Total loss': 0.34619059330736196}
2023-01-05 08:54:33,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:54:33,123 INFO:     Epoch: 43
2023-01-05 08:54:35,247 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42361671725908917, 'Total loss': 0.42361671725908917} | train loss {'Reaction outcome loss': 0.3453332328774633, 'Total loss': 0.3453332328774633}
2023-01-05 08:54:35,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:54:35,247 INFO:     Epoch: 44
2023-01-05 08:54:37,372 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4451023350159327, 'Total loss': 0.4451023350159327} | train loss {'Reaction outcome loss': 0.33663702504641385, 'Total loss': 0.33663702504641385}
2023-01-05 08:54:37,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:54:37,372 INFO:     Epoch: 45
2023-01-05 08:54:39,512 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4201516588528951, 'Total loss': 0.4201516588528951} | train loss {'Reaction outcome loss': 0.34503812291217545, 'Total loss': 0.34503812291217545}
2023-01-05 08:54:39,512 INFO:     Found new best model at epoch 45
2023-01-05 08:54:39,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:54:39,513 INFO:     Epoch: 46
2023-01-05 08:54:41,652 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4660719315210978, 'Total loss': 0.4660719315210978} | train loss {'Reaction outcome loss': 0.3297528192727235, 'Total loss': 0.3297528192727235}
2023-01-05 08:54:41,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:54:41,652 INFO:     Epoch: 47
2023-01-05 08:54:43,799 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3926417022943497, 'Total loss': 0.3926417022943497} | train loss {'Reaction outcome loss': 0.33202531188726425, 'Total loss': 0.33202531188726425}
2023-01-05 08:54:43,800 INFO:     Found new best model at epoch 47
2023-01-05 08:54:43,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:54:43,801 INFO:     Epoch: 48
2023-01-05 08:54:45,929 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4330719371636709, 'Total loss': 0.4330719371636709} | train loss {'Reaction outcome loss': 0.3230968782012045, 'Total loss': 0.3230968782012045}
2023-01-05 08:54:45,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:54:45,929 INFO:     Epoch: 49
2023-01-05 08:54:48,049 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4125398953755697, 'Total loss': 0.4125398953755697} | train loss {'Reaction outcome loss': 0.321091466739665, 'Total loss': 0.321091466739665}
2023-01-05 08:54:48,050 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:54:48,050 INFO:     Epoch: 50
2023-01-05 08:54:50,177 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42003870407740274, 'Total loss': 0.42003870407740274} | train loss {'Reaction outcome loss': 0.3211913979646281, 'Total loss': 0.3211913979646281}
2023-01-05 08:54:50,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:54:50,177 INFO:     Epoch: 51
2023-01-05 08:54:52,312 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3976276750365893, 'Total loss': 0.3976276750365893} | train loss {'Reaction outcome loss': 0.323188144224186, 'Total loss': 0.323188144224186}
2023-01-05 08:54:52,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:54:52,312 INFO:     Epoch: 52
2023-01-05 08:54:54,450 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39712074349323906, 'Total loss': 0.39712074349323906} | train loss {'Reaction outcome loss': 0.3184918905098508, 'Total loss': 0.3184918905098508}
2023-01-05 08:54:54,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:54:54,450 INFO:     Epoch: 53
2023-01-05 08:54:56,595 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4472759226957957, 'Total loss': 0.4472759226957957} | train loss {'Reaction outcome loss': 0.3190997245646741, 'Total loss': 0.3190997245646741}
2023-01-05 08:54:56,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:54:56,596 INFO:     Epoch: 54
2023-01-05 08:54:58,724 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4114575147628784, 'Total loss': 0.4114575147628784} | train loss {'Reaction outcome loss': 0.30848752516899663, 'Total loss': 0.30848752516899663}
2023-01-05 08:54:58,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:54:58,725 INFO:     Epoch: 55
2023-01-05 08:55:00,830 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41281140396992366, 'Total loss': 0.41281140396992366} | train loss {'Reaction outcome loss': 0.30890891202011683, 'Total loss': 0.30890891202011683}
2023-01-05 08:55:00,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:55:00,831 INFO:     Epoch: 56
2023-01-05 08:55:02,976 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.43621590733528137, 'Total loss': 0.43621590733528137} | train loss {'Reaction outcome loss': 0.304309106275548, 'Total loss': 0.304309106275548}
2023-01-05 08:55:02,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:55:02,977 INFO:     Epoch: 57
2023-01-05 08:55:05,108 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41150718530019126, 'Total loss': 0.41150718530019126} | train loss {'Reaction outcome loss': 0.30008604911828995, 'Total loss': 0.30008604911828995}
2023-01-05 08:55:05,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:55:05,108 INFO:     Epoch: 58
2023-01-05 08:55:07,246 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4173805395762126, 'Total loss': 0.4173805395762126} | train loss {'Reaction outcome loss': 0.2976257071089353, 'Total loss': 0.2976257071089353}
2023-01-05 08:55:07,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:55:07,246 INFO:     Epoch: 59
2023-01-05 08:55:09,373 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.41810783445835115, 'Total loss': 0.41810783445835115} | train loss {'Reaction outcome loss': 0.3004859709010942, 'Total loss': 0.3004859709010942}
2023-01-05 08:55:09,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:55:09,373 INFO:     Epoch: 60
2023-01-05 08:55:11,518 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.400428764273723, 'Total loss': 0.400428764273723} | train loss {'Reaction outcome loss': 0.3006990103282198, 'Total loss': 0.3006990103282198}
2023-01-05 08:55:11,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:55:11,518 INFO:     Epoch: 61
2023-01-05 08:55:13,635 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4223911921183268, 'Total loss': 0.4223911921183268} | train loss {'Reaction outcome loss': 0.2894161218219865, 'Total loss': 0.2894161218219865}
2023-01-05 08:55:13,635 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:55:13,635 INFO:     Epoch: 62
2023-01-05 08:55:15,804 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4526966502269109, 'Total loss': 0.4526966502269109} | train loss {'Reaction outcome loss': 0.2889558128115252, 'Total loss': 0.2889558128115252}
2023-01-05 08:55:15,804 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:55:15,804 INFO:     Epoch: 63
2023-01-05 08:55:17,939 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40934837559858955, 'Total loss': 0.40934837559858955} | train loss {'Reaction outcome loss': 0.28660383476556217, 'Total loss': 0.28660383476556217}
2023-01-05 08:55:17,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:55:17,940 INFO:     Epoch: 64
2023-01-05 08:55:20,064 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42737049410740535, 'Total loss': 0.42737049410740535} | train loss {'Reaction outcome loss': 0.2868108445010318, 'Total loss': 0.2868108445010318}
2023-01-05 08:55:20,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:55:20,064 INFO:     Epoch: 65
2023-01-05 08:55:22,181 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.409422937532266, 'Total loss': 0.409422937532266} | train loss {'Reaction outcome loss': 0.28628181196395713, 'Total loss': 0.28628181196395713}
2023-01-05 08:55:22,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:55:22,181 INFO:     Epoch: 66
2023-01-05 08:55:24,293 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4206863542397817, 'Total loss': 0.4206863542397817} | train loss {'Reaction outcome loss': 0.2876565414922733, 'Total loss': 0.2876565414922733}
2023-01-05 08:55:24,293 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:55:24,293 INFO:     Epoch: 67
2023-01-05 08:55:26,412 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42558961510658266, 'Total loss': 0.42558961510658266} | train loss {'Reaction outcome loss': 0.2828241530533907, 'Total loss': 0.2828241530533907}
2023-01-05 08:55:26,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:55:26,412 INFO:     Epoch: 68
2023-01-05 08:55:28,547 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4441537782549858, 'Total loss': 0.4441537782549858} | train loss {'Reaction outcome loss': 0.27587805416462197, 'Total loss': 0.27587805416462197}
2023-01-05 08:55:28,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:55:28,548 INFO:     Epoch: 69
2023-01-05 08:55:30,663 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4312049021323522, 'Total loss': 0.4312049021323522} | train loss {'Reaction outcome loss': 0.277148017496632, 'Total loss': 0.277148017496632}
2023-01-05 08:55:30,664 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:55:30,664 INFO:     Epoch: 70
2023-01-05 08:55:32,784 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.41673142512639366, 'Total loss': 0.41673142512639366} | train loss {'Reaction outcome loss': 0.2731997646037897, 'Total loss': 0.2731997646037897}
2023-01-05 08:55:32,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:55:32,785 INFO:     Epoch: 71
2023-01-05 08:55:34,998 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.46230752567450206, 'Total loss': 0.46230752567450206} | train loss {'Reaction outcome loss': 0.27671361193196836, 'Total loss': 0.27671361193196836}
2023-01-05 08:55:34,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:55:34,999 INFO:     Epoch: 72
2023-01-05 08:55:37,218 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3918510506550471, 'Total loss': 0.3918510506550471} | train loss {'Reaction outcome loss': 0.271600512706124, 'Total loss': 0.271600512706124}
2023-01-05 08:55:37,219 INFO:     Found new best model at epoch 72
2023-01-05 08:55:37,221 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:55:37,221 INFO:     Epoch: 73
2023-01-05 08:55:39,433 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.39644747575124106, 'Total loss': 0.39644747575124106} | train loss {'Reaction outcome loss': 0.269235579160987, 'Total loss': 0.269235579160987}
2023-01-05 08:55:39,433 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:55:39,433 INFO:     Epoch: 74
2023-01-05 08:55:41,672 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4227042317390442, 'Total loss': 0.4227042317390442} | train loss {'Reaction outcome loss': 0.2653546232974877, 'Total loss': 0.2653546232974877}
2023-01-05 08:55:41,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:55:41,672 INFO:     Epoch: 75
2023-01-05 08:55:43,812 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4120830227931341, 'Total loss': 0.4120830227931341} | train loss {'Reaction outcome loss': 0.27215143488924, 'Total loss': 0.27215143488924}
2023-01-05 08:55:43,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:55:43,812 INFO:     Epoch: 76
2023-01-05 08:55:45,924 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4007857501506805, 'Total loss': 0.4007857501506805} | train loss {'Reaction outcome loss': 0.2629153580697131, 'Total loss': 0.2629153580697131}
2023-01-05 08:55:45,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:55:45,924 INFO:     Epoch: 77
2023-01-05 08:55:48,060 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40178431073824566, 'Total loss': 0.40178431073824566} | train loss {'Reaction outcome loss': 0.27202666744617, 'Total loss': 0.27202666744617}
2023-01-05 08:55:48,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:55:48,060 INFO:     Epoch: 78
2023-01-05 08:55:50,224 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3797524094581604, 'Total loss': 0.3797524094581604} | train loss {'Reaction outcome loss': 0.2622557027659712, 'Total loss': 0.2622557027659712}
2023-01-05 08:55:50,224 INFO:     Found new best model at epoch 78
2023-01-05 08:55:50,226 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:55:50,226 INFO:     Epoch: 79
2023-01-05 08:55:52,368 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40652659833431243, 'Total loss': 0.40652659833431243} | train loss {'Reaction outcome loss': 0.26509402787149716, 'Total loss': 0.26509402787149716}
2023-01-05 08:55:52,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:55:52,369 INFO:     Epoch: 80
2023-01-05 08:55:54,566 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43812133769194284, 'Total loss': 0.43812133769194284} | train loss {'Reaction outcome loss': 0.2628658120486423, 'Total loss': 0.2628658120486423}
2023-01-05 08:55:54,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:55:54,566 INFO:     Epoch: 81
2023-01-05 08:55:56,714 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39124067723751066, 'Total loss': 0.39124067723751066} | train loss {'Reaction outcome loss': 0.2659133709831177, 'Total loss': 0.2659133709831177}
2023-01-05 08:55:56,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:55:56,714 INFO:     Epoch: 82
2023-01-05 08:55:58,832 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4095649207631747, 'Total loss': 0.4095649207631747} | train loss {'Reaction outcome loss': 0.25262281536566517, 'Total loss': 0.25262281536566517}
2023-01-05 08:55:58,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:55:58,832 INFO:     Epoch: 83
2023-01-05 08:56:00,962 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41036519408226013, 'Total loss': 0.41036519408226013} | train loss {'Reaction outcome loss': 0.25915834883459077, 'Total loss': 0.25915834883459077}
2023-01-05 08:56:00,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:56:00,962 INFO:     Epoch: 84
2023-01-05 08:56:03,086 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3963065619270007, 'Total loss': 0.3963065619270007} | train loss {'Reaction outcome loss': 0.2586112821841762, 'Total loss': 0.2586112821841762}
2023-01-05 08:56:03,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:56:03,086 INFO:     Epoch: 85
2023-01-05 08:56:05,215 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3793686417241891, 'Total loss': 0.3793686417241891} | train loss {'Reaction outcome loss': 0.25283565649586004, 'Total loss': 0.25283565649586004}
2023-01-05 08:56:05,216 INFO:     Found new best model at epoch 85
2023-01-05 08:56:05,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:56:05,217 INFO:     Epoch: 86
2023-01-05 08:56:07,361 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4017532169818878, 'Total loss': 0.4017532169818878} | train loss {'Reaction outcome loss': 0.2513569348022668, 'Total loss': 0.2513569348022668}
2023-01-05 08:56:07,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:56:07,362 INFO:     Epoch: 87
2023-01-05 08:56:09,509 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40079653859138487, 'Total loss': 0.40079653859138487} | train loss {'Reaction outcome loss': 0.2571489471894601, 'Total loss': 0.2571489471894601}
2023-01-05 08:56:09,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:56:09,509 INFO:     Epoch: 88
2023-01-05 08:56:11,610 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4383802443742752, 'Total loss': 0.4383802443742752} | train loss {'Reaction outcome loss': 0.24865125134641672, 'Total loss': 0.24865125134641672}
2023-01-05 08:56:11,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:56:11,611 INFO:     Epoch: 89
2023-01-05 08:56:13,748 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4083577553431193, 'Total loss': 0.4083577553431193} | train loss {'Reaction outcome loss': 0.255056759138612, 'Total loss': 0.255056759138612}
2023-01-05 08:56:13,749 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:56:13,749 INFO:     Epoch: 90
2023-01-05 08:56:15,878 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3896868189175924, 'Total loss': 0.3896868189175924} | train loss {'Reaction outcome loss': 0.2494658399373293, 'Total loss': 0.2494658399373293}
2023-01-05 08:56:15,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:56:15,878 INFO:     Epoch: 91
2023-01-05 08:56:18,006 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39136920173962914, 'Total loss': 0.39136920173962914} | train loss {'Reaction outcome loss': 0.2459934857966256, 'Total loss': 0.2459934857966256}
2023-01-05 08:56:18,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:56:18,006 INFO:     Epoch: 92
2023-01-05 08:56:20,128 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39309522112210593, 'Total loss': 0.39309522112210593} | train loss {'Reaction outcome loss': 0.24806724234490934, 'Total loss': 0.24806724234490934}
2023-01-05 08:56:20,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:56:20,128 INFO:     Epoch: 93
2023-01-05 08:56:22,227 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3799785333996018, 'Total loss': 0.3799785333996018} | train loss {'Reaction outcome loss': 0.24524274433072465, 'Total loss': 0.24524274433072465}
2023-01-05 08:56:22,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:56:22,228 INFO:     Epoch: 94
2023-01-05 08:56:24,371 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44249245127042136, 'Total loss': 0.44249245127042136} | train loss {'Reaction outcome loss': 0.24695467878214633, 'Total loss': 0.24695467878214633}
2023-01-05 08:56:24,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:56:24,371 INFO:     Epoch: 95
2023-01-05 08:56:26,481 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4012569139401118, 'Total loss': 0.4012569139401118} | train loss {'Reaction outcome loss': 0.24524462996662533, 'Total loss': 0.24524462996662533}
2023-01-05 08:56:26,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:56:26,482 INFO:     Epoch: 96
2023-01-05 08:56:28,610 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4529781351486842, 'Total loss': 0.4529781351486842} | train loss {'Reaction outcome loss': 0.24142702377951927, 'Total loss': 0.24142702377951927}
2023-01-05 08:56:28,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:56:28,610 INFO:     Epoch: 97
2023-01-05 08:56:30,738 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.38429555743932725, 'Total loss': 0.38429555743932725} | train loss {'Reaction outcome loss': 0.2555445531233601, 'Total loss': 0.2555445531233601}
2023-01-05 08:56:30,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:56:30,738 INFO:     Epoch: 98
2023-01-05 08:56:32,846 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.40602460329731305, 'Total loss': 0.40602460329731305} | train loss {'Reaction outcome loss': 0.2418619584713648, 'Total loss': 0.2418619584713648}
2023-01-05 08:56:32,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:56:32,846 INFO:     Epoch: 99
2023-01-05 08:56:34,947 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.39913459370533627, 'Total loss': 0.39913459370533627} | train loss {'Reaction outcome loss': 0.2378323157147987, 'Total loss': 0.2378323157147987}
2023-01-05 08:56:34,947 INFO:     Best model found after epoch 86 of 100.
2023-01-05 08:56:34,947 INFO:   Done with stage: TRAINING
2023-01-05 08:56:34,947 INFO:   Starting stage: EVALUATION
2023-01-05 08:56:35,085 INFO:   Done with stage: EVALUATION
2023-01-05 08:56:35,085 INFO:   Leaving out SEQ value Fold_1
2023-01-05 08:56:35,097 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 08:56:35,098 INFO:   Starting stage: FEATURE SCALING
2023-01-05 08:56:35,744 INFO:   Done with stage: FEATURE SCALING
2023-01-05 08:56:35,744 INFO:   Starting stage: SCALING TARGETS
2023-01-05 08:56:35,812 INFO:   Done with stage: SCALING TARGETS
2023-01-05 08:56:35,812 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:56:35,812 INFO:     No hyperparam tuning for this model
2023-01-05 08:56:35,812 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 08:56:35,812 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 08:56:35,813 INFO:     None feature selector for col prot
2023-01-05 08:56:35,813 INFO:     None feature selector for col prot
2023-01-05 08:56:35,813 INFO:     None feature selector for col prot
2023-01-05 08:56:35,813 INFO:     None feature selector for col chem
2023-01-05 08:56:35,814 INFO:     None feature selector for col chem
2023-01-05 08:56:35,814 INFO:     None feature selector for col chem
2023-01-05 08:56:35,814 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 08:56:35,814 INFO:   Starting stage: BUILD MODEL
2023-01-05 08:56:35,815 INFO:     Number of params in model 72901
2023-01-05 08:56:35,818 INFO:   Done with stage: BUILD MODEL
2023-01-05 08:56:35,818 INFO:   Starting stage: TRAINING
2023-01-05 08:56:35,879 INFO:     Val loss before train {'Reaction outcome loss': 0.9976681033770244, 'Total loss': 0.9976681033770244}
2023-01-05 08:56:35,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:56:35,879 INFO:     Epoch: 0
2023-01-05 08:56:37,982 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7565853297710419, 'Total loss': 0.7565853297710419} | train loss {'Reaction outcome loss': 0.9330454495919012, 'Total loss': 0.9330454495919012}
2023-01-05 08:56:37,982 INFO:     Found new best model at epoch 0
2023-01-05 08:56:37,983 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:56:37,983 INFO:     Epoch: 1
2023-01-05 08:56:40,082 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5815610229969025, 'Total loss': 0.5815610229969025} | train loss {'Reaction outcome loss': 0.7361914233787217, 'Total loss': 0.7361914233787217}
2023-01-05 08:56:40,082 INFO:     Found new best model at epoch 1
2023-01-05 08:56:40,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:56:40,084 INFO:     Epoch: 2
2023-01-05 08:56:42,192 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5013568411270778, 'Total loss': 0.5013568411270778} | train loss {'Reaction outcome loss': 0.5792589106046371, 'Total loss': 0.5792589106046371}
2023-01-05 08:56:42,193 INFO:     Found new best model at epoch 2
2023-01-05 08:56:42,194 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:56:42,194 INFO:     Epoch: 3
2023-01-05 08:56:44,322 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4901290754477183, 'Total loss': 0.4901290754477183} | train loss {'Reaction outcome loss': 0.5270204054613183, 'Total loss': 0.5270204054613183}
2023-01-05 08:56:44,322 INFO:     Found new best model at epoch 3
2023-01-05 08:56:44,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:56:44,323 INFO:     Epoch: 4
2023-01-05 08:56:46,414 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.465026980638504, 'Total loss': 0.465026980638504} | train loss {'Reaction outcome loss': 0.508757956271624, 'Total loss': 0.508757956271624}
2023-01-05 08:56:46,414 INFO:     Found new best model at epoch 4
2023-01-05 08:56:46,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:56:46,415 INFO:     Epoch: 5
2023-01-05 08:56:48,520 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45345851182937624, 'Total loss': 0.45345851182937624} | train loss {'Reaction outcome loss': 0.4938082953874212, 'Total loss': 0.4938082953874212}
2023-01-05 08:56:48,521 INFO:     Found new best model at epoch 5
2023-01-05 08:56:48,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:56:48,522 INFO:     Epoch: 6
2023-01-05 08:56:50,633 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.48740246693293254, 'Total loss': 0.48740246693293254} | train loss {'Reaction outcome loss': 0.4858405327927457, 'Total loss': 0.4858405327927457}
2023-01-05 08:56:50,633 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:56:50,634 INFO:     Epoch: 7
2023-01-05 08:56:52,732 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4592733681201935, 'Total loss': 0.4592733681201935} | train loss {'Reaction outcome loss': 0.4806855452267358, 'Total loss': 0.4806855452267358}
2023-01-05 08:56:52,732 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:56:52,732 INFO:     Epoch: 8
2023-01-05 08:56:54,859 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4360014021396637, 'Total loss': 0.4360014021396637} | train loss {'Reaction outcome loss': 0.4694840482225383, 'Total loss': 0.4694840482225383}
2023-01-05 08:56:54,859 INFO:     Found new best model at epoch 8
2023-01-05 08:56:54,861 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:56:54,861 INFO:     Epoch: 9
2023-01-05 08:56:56,954 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4586408644914627, 'Total loss': 0.4586408644914627} | train loss {'Reaction outcome loss': 0.46496615213525555, 'Total loss': 0.46496615213525555}
2023-01-05 08:56:56,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:56:56,955 INFO:     Epoch: 10
2023-01-05 08:56:59,058 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4581131120522817, 'Total loss': 0.4581131120522817} | train loss {'Reaction outcome loss': 0.4641916666479006, 'Total loss': 0.4641916666479006}
2023-01-05 08:56:59,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:56:59,059 INFO:     Epoch: 11
2023-01-05 08:57:01,171 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.420370685060819, 'Total loss': 0.420370685060819} | train loss {'Reaction outcome loss': 0.4535374886145557, 'Total loss': 0.4535374886145557}
2023-01-05 08:57:01,172 INFO:     Found new best model at epoch 11
2023-01-05 08:57:01,173 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:57:01,173 INFO:     Epoch: 12
2023-01-05 08:57:03,274 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45988377730051677, 'Total loss': 0.45988377730051677} | train loss {'Reaction outcome loss': 0.4468594964348922, 'Total loss': 0.4468594964348922}
2023-01-05 08:57:03,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:57:03,274 INFO:     Epoch: 13
2023-01-05 08:57:05,380 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44821658730506897, 'Total loss': 0.44821658730506897} | train loss {'Reaction outcome loss': 0.44315822047256204, 'Total loss': 0.44315822047256204}
2023-01-05 08:57:05,380 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:57:05,381 INFO:     Epoch: 14
2023-01-05 08:57:07,492 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4299575606981913, 'Total loss': 0.4299575606981913} | train loss {'Reaction outcome loss': 0.44364885208162946, 'Total loss': 0.44364885208162946}
2023-01-05 08:57:07,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:57:07,492 INFO:     Epoch: 15
2023-01-05 08:57:09,593 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4440867225329081, 'Total loss': 0.4440867225329081} | train loss {'Reaction outcome loss': 0.43612626771422197, 'Total loss': 0.43612626771422197}
2023-01-05 08:57:09,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:57:09,593 INFO:     Epoch: 16
2023-01-05 08:57:11,741 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.43857049544652305, 'Total loss': 0.43857049544652305} | train loss {'Reaction outcome loss': 0.4283583286578638, 'Total loss': 0.4283583286578638}
2023-01-05 08:57:11,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:57:11,742 INFO:     Epoch: 17
2023-01-05 08:57:13,849 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44526599446932474, 'Total loss': 0.44526599446932474} | train loss {'Reaction outcome loss': 0.42239153189380674, 'Total loss': 0.42239153189380674}
2023-01-05 08:57:13,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:57:13,849 INFO:     Epoch: 18
2023-01-05 08:57:15,966 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44183561503887175, 'Total loss': 0.44183561503887175} | train loss {'Reaction outcome loss': 0.42535169438941633, 'Total loss': 0.42535169438941633}
2023-01-05 08:57:15,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:57:15,966 INFO:     Epoch: 19
2023-01-05 08:57:18,071 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41809338281551994, 'Total loss': 0.41809338281551994} | train loss {'Reaction outcome loss': 0.41823957218740976, 'Total loss': 0.41823957218740976}
2023-01-05 08:57:18,072 INFO:     Found new best model at epoch 19
2023-01-05 08:57:18,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:57:18,073 INFO:     Epoch: 20
2023-01-05 08:57:20,187 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4216071327527364, 'Total loss': 0.4216071327527364} | train loss {'Reaction outcome loss': 0.413534837061145, 'Total loss': 0.413534837061145}
2023-01-05 08:57:20,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:57:20,187 INFO:     Epoch: 21
2023-01-05 08:57:22,273 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43203018804391224, 'Total loss': 0.43203018804391224} | train loss {'Reaction outcome loss': 0.4101311179408192, 'Total loss': 0.4101311179408192}
2023-01-05 08:57:22,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:57:22,273 INFO:     Epoch: 22
2023-01-05 08:57:24,374 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42709267089764275, 'Total loss': 0.42709267089764275} | train loss {'Reaction outcome loss': 0.3978564367785941, 'Total loss': 0.3978564367785941}
2023-01-05 08:57:24,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:57:24,374 INFO:     Epoch: 23
2023-01-05 08:57:26,492 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.42219337125619255, 'Total loss': 0.42219337125619255} | train loss {'Reaction outcome loss': 0.4017508309470476, 'Total loss': 0.4017508309470476}
2023-01-05 08:57:26,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:57:26,493 INFO:     Epoch: 24
2023-01-05 08:57:28,568 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.42096452713012694, 'Total loss': 0.42096452713012694} | train loss {'Reaction outcome loss': 0.39290232029165667, 'Total loss': 0.39290232029165667}
2023-01-05 08:57:28,568 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:57:28,568 INFO:     Epoch: 25
2023-01-05 08:57:30,681 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4461885114510854, 'Total loss': 0.4461885114510854} | train loss {'Reaction outcome loss': 0.3945317916626478, 'Total loss': 0.3945317916626478}
2023-01-05 08:57:30,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:57:30,681 INFO:     Epoch: 26
2023-01-05 08:57:32,783 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4258529245853424, 'Total loss': 0.4258529245853424} | train loss {'Reaction outcome loss': 0.39405644676872414, 'Total loss': 0.39405644676872414}
2023-01-05 08:57:32,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:57:32,783 INFO:     Epoch: 27
2023-01-05 08:57:34,898 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4199132372935613, 'Total loss': 0.4199132372935613} | train loss {'Reaction outcome loss': 0.38194527158880753, 'Total loss': 0.38194527158880753}
2023-01-05 08:57:34,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:57:34,899 INFO:     Epoch: 28
2023-01-05 08:57:36,998 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43314802199602126, 'Total loss': 0.43314802199602126} | train loss {'Reaction outcome loss': 0.38264367072741046, 'Total loss': 0.38264367072741046}
2023-01-05 08:57:36,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:57:36,999 INFO:     Epoch: 29
2023-01-05 08:57:39,138 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4258351961771647, 'Total loss': 0.4258351961771647} | train loss {'Reaction outcome loss': 0.37228019804741347, 'Total loss': 0.37228019804741347}
2023-01-05 08:57:39,138 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:57:39,138 INFO:     Epoch: 30
2023-01-05 08:57:41,267 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4062855084737142, 'Total loss': 0.4062855084737142} | train loss {'Reaction outcome loss': 0.3758288360044469, 'Total loss': 0.3758288360044469}
2023-01-05 08:57:41,267 INFO:     Found new best model at epoch 30
2023-01-05 08:57:41,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:57:41,269 INFO:     Epoch: 31
2023-01-05 08:57:43,378 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4100767860809962, 'Total loss': 0.4100767860809962} | train loss {'Reaction outcome loss': 0.3743781882073105, 'Total loss': 0.3743781882073105}
2023-01-05 08:57:43,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:57:43,379 INFO:     Epoch: 32
2023-01-05 08:57:45,493 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4330338875452677, 'Total loss': 0.4330338875452677} | train loss {'Reaction outcome loss': 0.3708839465177407, 'Total loss': 0.3708839465177407}
2023-01-05 08:57:45,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:57:45,493 INFO:     Epoch: 33
2023-01-05 08:57:47,615 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.44330906718969343, 'Total loss': 0.44330906718969343} | train loss {'Reaction outcome loss': 0.36761366018522396, 'Total loss': 0.36761366018522396}
2023-01-05 08:57:47,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:57:47,615 INFO:     Epoch: 34
2023-01-05 08:57:49,724 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42401296496391294, 'Total loss': 0.42401296496391294} | train loss {'Reaction outcome loss': 0.3666740155228189, 'Total loss': 0.3666740155228189}
2023-01-05 08:57:49,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:57:49,724 INFO:     Epoch: 35
2023-01-05 08:57:51,821 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3920592541495959, 'Total loss': 0.3920592541495959} | train loss {'Reaction outcome loss': 0.35624690141773574, 'Total loss': 0.35624690141773574}
2023-01-05 08:57:51,821 INFO:     Found new best model at epoch 35
2023-01-05 08:57:51,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:57:51,823 INFO:     Epoch: 36
2023-01-05 08:57:53,939 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4249080946048101, 'Total loss': 0.4249080946048101} | train loss {'Reaction outcome loss': 0.35932620261272374, 'Total loss': 0.35932620261272374}
2023-01-05 08:57:53,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:57:53,940 INFO:     Epoch: 37
2023-01-05 08:57:56,053 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4517983098824819, 'Total loss': 0.4517983098824819} | train loss {'Reaction outcome loss': 0.3468264770714471, 'Total loss': 0.3468264770714471}
2023-01-05 08:57:56,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:57:56,053 INFO:     Epoch: 38
2023-01-05 08:57:58,171 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.39231043457984927, 'Total loss': 0.39231043457984927} | train loss {'Reaction outcome loss': 0.3434479453322226, 'Total loss': 0.3434479453322226}
2023-01-05 08:57:58,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:57:58,171 INFO:     Epoch: 39
2023-01-05 08:58:00,243 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.415643543501695, 'Total loss': 0.415643543501695} | train loss {'Reaction outcome loss': 0.34901876470250803, 'Total loss': 0.34901876470250803}
2023-01-05 08:58:00,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:58:00,246 INFO:     Epoch: 40
2023-01-05 08:58:02,165 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4253168344497681, 'Total loss': 0.4253168344497681} | train loss {'Reaction outcome loss': 0.3464338297065157, 'Total loss': 0.3464338297065157}
2023-01-05 08:58:02,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:58:02,165 INFO:     Epoch: 41
2023-01-05 08:58:04,269 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4546777953704198, 'Total loss': 0.4546777953704198} | train loss {'Reaction outcome loss': 0.3389076525413424, 'Total loss': 0.3389076525413424}
2023-01-05 08:58:04,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:58:04,269 INFO:     Epoch: 42
2023-01-05 08:58:06,339 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4137742320696513, 'Total loss': 0.4137742320696513} | train loss {'Reaction outcome loss': 0.3311406898101533, 'Total loss': 0.3311406898101533}
2023-01-05 08:58:06,339 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:58:06,339 INFO:     Epoch: 43
2023-01-05 08:58:08,439 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40379840433597564, 'Total loss': 0.40379840433597564} | train loss {'Reaction outcome loss': 0.3339744087199878, 'Total loss': 0.3339744087199878}
2023-01-05 08:58:08,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:58:08,439 INFO:     Epoch: 44
2023-01-05 08:58:10,532 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40920991798241935, 'Total loss': 0.40920991798241935} | train loss {'Reaction outcome loss': 0.3296425425699049, 'Total loss': 0.3296425425699049}
2023-01-05 08:58:10,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:58:10,532 INFO:     Epoch: 45
2023-01-05 08:58:12,649 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3946684569120407, 'Total loss': 0.3946684569120407} | train loss {'Reaction outcome loss': 0.32905852764736127, 'Total loss': 0.32905852764736127}
2023-01-05 08:58:12,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:58:12,650 INFO:     Epoch: 46
2023-01-05 08:58:14,799 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.42295570572217306, 'Total loss': 0.42295570572217306} | train loss {'Reaction outcome loss': 0.3226875195374889, 'Total loss': 0.3226875195374889}
2023-01-05 08:58:14,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:58:14,799 INFO:     Epoch: 47
2023-01-05 08:58:16,888 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42419120321671167, 'Total loss': 0.42419120321671167} | train loss {'Reaction outcome loss': 0.3242002642529942, 'Total loss': 0.3242002642529942}
2023-01-05 08:58:16,888 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:58:16,888 INFO:     Epoch: 48
2023-01-05 08:58:18,959 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38338328500588736, 'Total loss': 0.38338328500588736} | train loss {'Reaction outcome loss': 0.32509103542479284, 'Total loss': 0.32509103542479284}
2023-01-05 08:58:18,959 INFO:     Found new best model at epoch 48
2023-01-05 08:58:18,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:58:18,960 INFO:     Epoch: 49
2023-01-05 08:58:21,076 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39892949362595875, 'Total loss': 0.39892949362595875} | train loss {'Reaction outcome loss': 0.3222904457663098, 'Total loss': 0.3222904457663098}
2023-01-05 08:58:21,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:58:21,077 INFO:     Epoch: 50
2023-01-05 08:58:23,197 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4314628442128499, 'Total loss': 0.4314628442128499} | train loss {'Reaction outcome loss': 0.3179800938678919, 'Total loss': 0.3179800938678919}
2023-01-05 08:58:23,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:58:23,198 INFO:     Epoch: 51
2023-01-05 08:58:25,326 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4013116680085659, 'Total loss': 0.4013116680085659} | train loss {'Reaction outcome loss': 0.31291470918668446, 'Total loss': 0.31291470918668446}
2023-01-05 08:58:25,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:58:25,327 INFO:     Epoch: 52
2023-01-05 08:58:27,433 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41018816630045574, 'Total loss': 0.41018816630045574} | train loss {'Reaction outcome loss': 0.2965043142682662, 'Total loss': 0.2965043142682662}
2023-01-05 08:58:27,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:58:27,434 INFO:     Epoch: 53
2023-01-05 08:58:29,544 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4010247041781743, 'Total loss': 0.4010247041781743} | train loss {'Reaction outcome loss': 0.31114737163331824, 'Total loss': 0.31114737163331824}
2023-01-05 08:58:29,545 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:58:29,545 INFO:     Epoch: 54
2023-01-05 08:58:31,668 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.38683985037108265, 'Total loss': 0.38683985037108265} | train loss {'Reaction outcome loss': 0.30536483498766037, 'Total loss': 0.30536483498766037}
2023-01-05 08:58:31,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:58:31,668 INFO:     Epoch: 55
2023-01-05 08:58:33,801 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.41018953720728557, 'Total loss': 0.41018953720728557} | train loss {'Reaction outcome loss': 0.31232561109873064, 'Total loss': 0.31232561109873064}
2023-01-05 08:58:33,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:58:33,801 INFO:     Epoch: 56
2023-01-05 08:58:35,934 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.38504465321699777, 'Total loss': 0.38504465321699777} | train loss {'Reaction outcome loss': 0.30785310025034596, 'Total loss': 0.30785310025034596}
2023-01-05 08:58:35,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:58:35,935 INFO:     Epoch: 57
2023-01-05 08:58:38,063 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41581271787484486, 'Total loss': 0.41581271787484486} | train loss {'Reaction outcome loss': 0.3016714182729921, 'Total loss': 0.3016714182729921}
2023-01-05 08:58:38,063 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:58:38,063 INFO:     Epoch: 58
2023-01-05 08:58:40,162 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.40732502440611523, 'Total loss': 0.40732502440611523} | train loss {'Reaction outcome loss': 0.29893184641552883, 'Total loss': 0.29893184641552883}
2023-01-05 08:58:40,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:58:40,162 INFO:     Epoch: 59
2023-01-05 08:58:42,243 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.42841294159491855, 'Total loss': 0.42841294159491855} | train loss {'Reaction outcome loss': 0.3014217001338401, 'Total loss': 0.3014217001338401}
2023-01-05 08:58:42,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:58:42,244 INFO:     Epoch: 60
2023-01-05 08:58:44,382 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42271316846211754, 'Total loss': 0.42271316846211754} | train loss {'Reaction outcome loss': 0.2938011598086705, 'Total loss': 0.2938011598086705}
2023-01-05 08:58:44,382 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:58:44,383 INFO:     Epoch: 61
2023-01-05 08:58:46,469 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38944785396258036, 'Total loss': 0.38944785396258036} | train loss {'Reaction outcome loss': 0.293839093556043, 'Total loss': 0.293839093556043}
2023-01-05 08:58:46,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:58:46,469 INFO:     Epoch: 62
2023-01-05 08:58:48,545 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40971829295158385, 'Total loss': 0.40971829295158385} | train loss {'Reaction outcome loss': 0.2923206935099659, 'Total loss': 0.2923206935099659}
2023-01-05 08:58:48,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:58:48,546 INFO:     Epoch: 63
2023-01-05 08:58:50,647 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4294423535466194, 'Total loss': 0.4294423535466194} | train loss {'Reaction outcome loss': 0.28321496234105453, 'Total loss': 0.28321496234105453}
2023-01-05 08:58:50,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:58:50,647 INFO:     Epoch: 64
2023-01-05 08:58:52,731 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.39972423017024994, 'Total loss': 0.39972423017024994} | train loss {'Reaction outcome loss': 0.29648275425943144, 'Total loss': 0.29648275425943144}
2023-01-05 08:58:52,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:58:52,731 INFO:     Epoch: 65
2023-01-05 08:58:54,851 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4297288149595261, 'Total loss': 0.4297288149595261} | train loss {'Reaction outcome loss': 0.2854037512991115, 'Total loss': 0.2854037512991115}
2023-01-05 08:58:54,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:58:54,851 INFO:     Epoch: 66
2023-01-05 08:58:56,940 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4355290085077286, 'Total loss': 0.4355290085077286} | train loss {'Reaction outcome loss': 0.2878383489284855, 'Total loss': 0.2878383489284855}
2023-01-05 08:58:56,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:58:56,941 INFO:     Epoch: 67
2023-01-05 08:58:59,025 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.40169572035471596, 'Total loss': 0.40169572035471596} | train loss {'Reaction outcome loss': 0.2905558696574103, 'Total loss': 0.2905558696574103}
2023-01-05 08:58:59,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:58:59,025 INFO:     Epoch: 68
2023-01-05 08:59:01,131 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41531887153784436, 'Total loss': 0.41531887153784436} | train loss {'Reaction outcome loss': 0.27940691630593945, 'Total loss': 0.27940691630593945}
2023-01-05 08:59:01,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:59:01,131 INFO:     Epoch: 69
2023-01-05 08:59:03,231 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3979295790195465, 'Total loss': 0.3979295790195465} | train loss {'Reaction outcome loss': 0.2814602540282492, 'Total loss': 0.2814602540282492}
2023-01-05 08:59:03,231 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:59:03,232 INFO:     Epoch: 70
2023-01-05 08:59:05,327 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4359975318113963, 'Total loss': 0.4359975318113963} | train loss {'Reaction outcome loss': 0.27632056653200493, 'Total loss': 0.27632056653200493}
2023-01-05 08:59:05,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:59:05,328 INFO:     Epoch: 71
2023-01-05 08:59:07,428 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4135964718957742, 'Total loss': 0.4135964718957742} | train loss {'Reaction outcome loss': 0.2795723001710581, 'Total loss': 0.2795723001710581}
2023-01-05 08:59:07,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:59:07,429 INFO:     Epoch: 72
2023-01-05 08:59:09,527 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.46485989540815353, 'Total loss': 0.46485989540815353} | train loss {'Reaction outcome loss': 0.27130692881824325, 'Total loss': 0.27130692881824325}
2023-01-05 08:59:09,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:59:09,527 INFO:     Epoch: 73
2023-01-05 08:59:11,628 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4437399337689082, 'Total loss': 0.4437399337689082} | train loss {'Reaction outcome loss': 0.27832926278865905, 'Total loss': 0.27832926278865905}
2023-01-05 08:59:11,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:59:11,629 INFO:     Epoch: 74
2023-01-05 08:59:13,747 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4536216934521993, 'Total loss': 0.4536216934521993} | train loss {'Reaction outcome loss': 0.27209075613722317, 'Total loss': 0.27209075613722317}
2023-01-05 08:59:13,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:59:13,747 INFO:     Epoch: 75
2023-01-05 08:59:15,838 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44938672383626305, 'Total loss': 0.44938672383626305} | train loss {'Reaction outcome loss': 0.27698777274085873, 'Total loss': 0.27698777274085873}
2023-01-05 08:59:15,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:59:15,838 INFO:     Epoch: 76
2023-01-05 08:59:17,930 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42494933754205705, 'Total loss': 0.42494933754205705} | train loss {'Reaction outcome loss': 0.2682476973460212, 'Total loss': 0.2682476973460212}
2023-01-05 08:59:17,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:59:17,931 INFO:     Epoch: 77
2023-01-05 08:59:20,043 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4462706943353017, 'Total loss': 0.4462706943353017} | train loss {'Reaction outcome loss': 0.27194379754092574, 'Total loss': 0.27194379754092574}
2023-01-05 08:59:20,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:59:20,043 INFO:     Epoch: 78
2023-01-05 08:59:22,126 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4184990584850311, 'Total loss': 0.4184990584850311} | train loss {'Reaction outcome loss': 0.27263085350367056, 'Total loss': 0.27263085350367056}
2023-01-05 08:59:22,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:59:22,127 INFO:     Epoch: 79
2023-01-05 08:59:24,223 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42456378738085426, 'Total loss': 0.42456378738085426} | train loss {'Reaction outcome loss': 0.26502615707606947, 'Total loss': 0.26502615707606947}
2023-01-05 08:59:24,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:59:24,224 INFO:     Epoch: 80
2023-01-05 08:59:26,306 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.39883223523696265, 'Total loss': 0.39883223523696265} | train loss {'Reaction outcome loss': 0.2654852745782611, 'Total loss': 0.2654852745782611}
2023-01-05 08:59:26,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:59:26,306 INFO:     Epoch: 81
2023-01-05 08:59:28,399 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4257183462381363, 'Total loss': 0.4257183462381363} | train loss {'Reaction outcome loss': 0.26498284359482954, 'Total loss': 0.26498284359482954}
2023-01-05 08:59:28,399 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:59:28,400 INFO:     Epoch: 82
2023-01-05 08:59:30,480 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41759809454282126, 'Total loss': 0.41759809454282126} | train loss {'Reaction outcome loss': 0.2681136183019211, 'Total loss': 0.2681136183019211}
2023-01-05 08:59:30,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:59:30,480 INFO:     Epoch: 83
2023-01-05 08:59:32,567 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.411162926753362, 'Total loss': 0.411162926753362} | train loss {'Reaction outcome loss': 0.2677366524377335, 'Total loss': 0.2677366524377335}
2023-01-05 08:59:32,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:59:32,567 INFO:     Epoch: 84
2023-01-05 08:59:34,679 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43203789194424946, 'Total loss': 0.43203789194424946} | train loss {'Reaction outcome loss': 0.26669097475598763, 'Total loss': 0.26669097475598763}
2023-01-05 08:59:34,679 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:59:34,679 INFO:     Epoch: 85
2023-01-05 08:59:36,772 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41312483648459114, 'Total loss': 0.41312483648459114} | train loss {'Reaction outcome loss': 0.2604273778461192, 'Total loss': 0.2604273778461192}
2023-01-05 08:59:36,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:59:36,772 INFO:     Epoch: 86
2023-01-05 08:59:38,863 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4031981070836385, 'Total loss': 0.4031981070836385} | train loss {'Reaction outcome loss': 0.25784551734988487, 'Total loss': 0.25784551734988487}
2023-01-05 08:59:38,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:59:38,864 INFO:     Epoch: 87
2023-01-05 08:59:40,977 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4577345738808314, 'Total loss': 0.4577345738808314} | train loss {'Reaction outcome loss': 0.26371378159272846, 'Total loss': 0.26371378159272846}
2023-01-05 08:59:40,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:59:40,977 INFO:     Epoch: 88
2023-01-05 08:59:43,085 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4398170823852221, 'Total loss': 0.4398170823852221} | train loss {'Reaction outcome loss': 0.26313685631229927, 'Total loss': 0.26313685631229927}
2023-01-05 08:59:43,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:59:43,086 INFO:     Epoch: 89
2023-01-05 08:59:45,184 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41951489448547363, 'Total loss': 0.41951489448547363} | train loss {'Reaction outcome loss': 0.2618081082120864, 'Total loss': 0.2618081082120864}
2023-01-05 08:59:45,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:59:45,185 INFO:     Epoch: 90
2023-01-05 08:59:47,275 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4359838843345642, 'Total loss': 0.4359838843345642} | train loss {'Reaction outcome loss': 0.2544988837147499, 'Total loss': 0.2544988837147499}
2023-01-05 08:59:47,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:59:47,275 INFO:     Epoch: 91
2023-01-05 08:59:49,362 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.40856887549161913, 'Total loss': 0.40856887549161913} | train loss {'Reaction outcome loss': 0.25320216903911674, 'Total loss': 0.25320216903911674}
2023-01-05 08:59:49,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:59:49,363 INFO:     Epoch: 92
2023-01-05 08:59:51,449 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.40021799206733705, 'Total loss': 0.40021799206733705} | train loss {'Reaction outcome loss': 0.2534553511306154, 'Total loss': 0.2534553511306154}
2023-01-05 08:59:51,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:59:51,449 INFO:     Epoch: 93
2023-01-05 08:59:53,540 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.37959369719028474, 'Total loss': 0.37959369719028474} | train loss {'Reaction outcome loss': 0.24816937335719266, 'Total loss': 0.24816937335719266}
2023-01-05 08:59:53,540 INFO:     Found new best model at epoch 93
2023-01-05 08:59:53,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:59:53,542 INFO:     Epoch: 94
2023-01-05 08:59:55,660 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42546482185522716, 'Total loss': 0.42546482185522716} | train loss {'Reaction outcome loss': 0.2513475081862977, 'Total loss': 0.2513475081862977}
2023-01-05 08:59:55,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:59:55,660 INFO:     Epoch: 95
2023-01-05 08:59:57,776 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3787671678854773, 'Total loss': 0.3787671678854773} | train loss {'Reaction outcome loss': 0.2580606231098845, 'Total loss': 0.2580606231098845}
2023-01-05 08:59:57,776 INFO:     Found new best model at epoch 95
2023-01-05 08:59:57,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:59:57,777 INFO:     Epoch: 96
2023-01-05 08:59:59,880 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43348306020100913, 'Total loss': 0.43348306020100913} | train loss {'Reaction outcome loss': 0.2544608708185545, 'Total loss': 0.2544608708185545}
2023-01-05 08:59:59,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 08:59:59,880 INFO:     Epoch: 97
2023-01-05 09:00:01,991 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4151072350641092, 'Total loss': 0.4151072350641092} | train loss {'Reaction outcome loss': 0.24849281063724826, 'Total loss': 0.24849281063724826}
2023-01-05 09:00:01,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:00:01,991 INFO:     Epoch: 98
2023-01-05 09:00:04,096 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42969666719436644, 'Total loss': 0.42969666719436644} | train loss {'Reaction outcome loss': 0.2513802199264186, 'Total loss': 0.2513802199264186}
2023-01-05 09:00:04,096 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:00:04,096 INFO:     Epoch: 99
2023-01-05 09:00:06,176 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.42564554810523986, 'Total loss': 0.42564554810523986} | train loss {'Reaction outcome loss': 0.25164832507198964, 'Total loss': 0.25164832507198964}
2023-01-05 09:00:06,176 INFO:     Best model found after epoch 96 of 100.
2023-01-05 09:00:06,176 INFO:   Done with stage: TRAINING
2023-01-05 09:00:06,176 INFO:   Starting stage: EVALUATION
2023-01-05 09:00:06,312 INFO:   Done with stage: EVALUATION
2023-01-05 09:00:06,312 INFO:   Leaving out SEQ value Fold_2
2023-01-05 09:00:06,324 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 09:00:06,324 INFO:   Starting stage: FEATURE SCALING
2023-01-05 09:00:06,969 INFO:   Done with stage: FEATURE SCALING
2023-01-05 09:00:06,969 INFO:   Starting stage: SCALING TARGETS
2023-01-05 09:00:07,035 INFO:   Done with stage: SCALING TARGETS
2023-01-05 09:00:07,036 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:00:07,036 INFO:     No hyperparam tuning for this model
2023-01-05 09:00:07,036 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:00:07,036 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 09:00:07,036 INFO:     None feature selector for col prot
2023-01-05 09:00:07,037 INFO:     None feature selector for col prot
2023-01-05 09:00:07,037 INFO:     None feature selector for col prot
2023-01-05 09:00:07,037 INFO:     None feature selector for col chem
2023-01-05 09:00:07,037 INFO:     None feature selector for col chem
2023-01-05 09:00:07,037 INFO:     None feature selector for col chem
2023-01-05 09:00:07,037 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 09:00:07,037 INFO:   Starting stage: BUILD MODEL
2023-01-05 09:00:07,039 INFO:     Number of params in model 72901
2023-01-05 09:00:07,042 INFO:   Done with stage: BUILD MODEL
2023-01-05 09:00:07,042 INFO:   Starting stage: TRAINING
2023-01-05 09:00:07,101 INFO:     Val loss before train {'Reaction outcome loss': 0.9698051412900289, 'Total loss': 0.9698051412900289}
2023-01-05 09:00:07,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:00:07,101 INFO:     Epoch: 0
2023-01-05 09:00:09,198 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7979286710421244, 'Total loss': 0.7979286710421244} | train loss {'Reaction outcome loss': 0.9228897455377855, 'Total loss': 0.9228897455377855}
2023-01-05 09:00:09,198 INFO:     Found new best model at epoch 0
2023-01-05 09:00:09,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:00:09,200 INFO:     Epoch: 1
2023-01-05 09:00:11,323 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6194211125373841, 'Total loss': 0.6194211125373841} | train loss {'Reaction outcome loss': 0.7345699877410695, 'Total loss': 0.7345699877410695}
2023-01-05 09:00:11,323 INFO:     Found new best model at epoch 1
2023-01-05 09:00:11,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:00:11,324 INFO:     Epoch: 2
2023-01-05 09:00:13,413 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5455373346805572, 'Total loss': 0.5455373346805572} | train loss {'Reaction outcome loss': 0.5942643897994286, 'Total loss': 0.5942643897994286}
2023-01-05 09:00:13,414 INFO:     Found new best model at epoch 2
2023-01-05 09:00:13,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:00:13,415 INFO:     Epoch: 3
2023-01-05 09:00:15,512 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48995495239893594, 'Total loss': 0.48995495239893594} | train loss {'Reaction outcome loss': 0.5463076718691466, 'Total loss': 0.5463076718691466}
2023-01-05 09:00:15,512 INFO:     Found new best model at epoch 3
2023-01-05 09:00:15,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:00:15,514 INFO:     Epoch: 4
2023-01-05 09:00:17,629 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5279231707255045, 'Total loss': 0.5279231707255045} | train loss {'Reaction outcome loss': 0.5283070162741764, 'Total loss': 0.5283070162741764}
2023-01-05 09:00:17,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:00:17,629 INFO:     Epoch: 5
2023-01-05 09:00:19,739 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4678422729174296, 'Total loss': 0.4678422729174296} | train loss {'Reaction outcome loss': 0.5344625177482764, 'Total loss': 0.5344625177482764}
2023-01-05 09:00:19,740 INFO:     Found new best model at epoch 5
2023-01-05 09:00:19,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:00:19,741 INFO:     Epoch: 6
2023-01-05 09:00:21,866 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.46855158110459644, 'Total loss': 0.46855158110459644} | train loss {'Reaction outcome loss': 0.501494624260543, 'Total loss': 0.501494624260543}
2023-01-05 09:00:21,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:00:21,866 INFO:     Epoch: 7
2023-01-05 09:00:23,984 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.476348156730334, 'Total loss': 0.476348156730334} | train loss {'Reaction outcome loss': 0.4878556116414931, 'Total loss': 0.4878556116414931}
2023-01-05 09:00:23,985 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:00:23,985 INFO:     Epoch: 8
2023-01-05 09:00:26,100 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4871442625919978, 'Total loss': 0.4871442625919978} | train loss {'Reaction outcome loss': 0.4879458998532399, 'Total loss': 0.4879458998532399}
2023-01-05 09:00:26,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:00:26,101 INFO:     Epoch: 9
2023-01-05 09:00:28,230 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4818928708632787, 'Total loss': 0.4818928708632787} | train loss {'Reaction outcome loss': 0.47744143202050426, 'Total loss': 0.47744143202050426}
2023-01-05 09:00:28,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:00:28,230 INFO:     Epoch: 10
2023-01-05 09:00:30,350 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4644893983999888, 'Total loss': 0.4644893983999888} | train loss {'Reaction outcome loss': 0.4730815180118425, 'Total loss': 0.4730815180118425}
2023-01-05 09:00:30,350 INFO:     Found new best model at epoch 10
2023-01-05 09:00:30,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:00:30,351 INFO:     Epoch: 11
2023-01-05 09:00:32,492 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44708274205525717, 'Total loss': 0.44708274205525717} | train loss {'Reaction outcome loss': 0.4653341739229264, 'Total loss': 0.4653341739229264}
2023-01-05 09:00:32,493 INFO:     Found new best model at epoch 11
2023-01-05 09:00:32,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:00:32,494 INFO:     Epoch: 12
2023-01-05 09:00:34,604 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45603748261928556, 'Total loss': 0.45603748261928556} | train loss {'Reaction outcome loss': 0.4642459675130827, 'Total loss': 0.4642459675130827}
2023-01-05 09:00:34,604 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:00:34,604 INFO:     Epoch: 13
2023-01-05 09:00:36,724 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45933894713719686, 'Total loss': 0.45933894713719686} | train loss {'Reaction outcome loss': 0.4578904088323369, 'Total loss': 0.4578904088323369}
2023-01-05 09:00:36,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:00:36,724 INFO:     Epoch: 14
2023-01-05 09:00:38,832 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4580820471048355, 'Total loss': 0.4580820471048355} | train loss {'Reaction outcome loss': 0.45151842033753736, 'Total loss': 0.45151842033753736}
2023-01-05 09:00:38,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:00:38,833 INFO:     Epoch: 15
2023-01-05 09:00:40,941 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4386692653099696, 'Total loss': 0.4386692653099696} | train loss {'Reaction outcome loss': 0.44927678904766083, 'Total loss': 0.44927678904766083}
2023-01-05 09:00:40,942 INFO:     Found new best model at epoch 15
2023-01-05 09:00:40,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:00:40,943 INFO:     Epoch: 16
2023-01-05 09:00:43,109 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44190304974714917, 'Total loss': 0.44190304974714917} | train loss {'Reaction outcome loss': 0.44328077599714993, 'Total loss': 0.44328077599714993}
2023-01-05 09:00:43,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:00:43,110 INFO:     Epoch: 17
2023-01-05 09:00:45,234 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.44701248506704966, 'Total loss': 0.44701248506704966} | train loss {'Reaction outcome loss': 0.4384423531591892, 'Total loss': 0.4384423531591892}
2023-01-05 09:00:45,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:00:45,235 INFO:     Epoch: 18
2023-01-05 09:00:47,368 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4428157796462377, 'Total loss': 0.4428157796462377} | train loss {'Reaction outcome loss': 0.4448222489141778, 'Total loss': 0.4448222489141778}
2023-01-05 09:00:47,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:00:47,368 INFO:     Epoch: 19
2023-01-05 09:00:49,486 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.44399570127328236, 'Total loss': 0.44399570127328236} | train loss {'Reaction outcome loss': 0.43469316077729064, 'Total loss': 0.43469316077729064}
2023-01-05 09:00:49,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:00:49,487 INFO:     Epoch: 20
2023-01-05 09:00:51,642 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.45530641774336494, 'Total loss': 0.45530641774336494} | train loss {'Reaction outcome loss': 0.4293433521212875, 'Total loss': 0.4293433521212875}
2023-01-05 09:00:51,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:00:51,642 INFO:     Epoch: 21
2023-01-05 09:00:53,798 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.427073273062706, 'Total loss': 0.427073273062706} | train loss {'Reaction outcome loss': 0.4397110850524927, 'Total loss': 0.4397110850524927}
2023-01-05 09:00:53,798 INFO:     Found new best model at epoch 21
2023-01-05 09:00:53,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:00:53,799 INFO:     Epoch: 22
2023-01-05 09:00:55,920 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.44335528562466303, 'Total loss': 0.44335528562466303} | train loss {'Reaction outcome loss': 0.4246554133225826, 'Total loss': 0.4246554133225826}
2023-01-05 09:00:55,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:00:55,921 INFO:     Epoch: 23
2023-01-05 09:00:58,056 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4342117557922999, 'Total loss': 0.4342117557922999} | train loss {'Reaction outcome loss': 0.44169667587224126, 'Total loss': 0.44169667587224126}
2023-01-05 09:00:58,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:00:58,057 INFO:     Epoch: 24
2023-01-05 09:01:00,177 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4519690215587616, 'Total loss': 0.4519690215587616} | train loss {'Reaction outcome loss': 0.45374772257670976, 'Total loss': 0.45374772257670976}
2023-01-05 09:01:00,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:01:00,177 INFO:     Epoch: 25
2023-01-05 09:01:02,318 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4651626686255137, 'Total loss': 0.4651626686255137} | train loss {'Reaction outcome loss': 0.4188755282625541, 'Total loss': 0.4188755282625541}
2023-01-05 09:01:02,319 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:01:02,319 INFO:     Epoch: 26
2023-01-05 09:01:04,460 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42748188773790996, 'Total loss': 0.42748188773790996} | train loss {'Reaction outcome loss': 0.4165702534272619, 'Total loss': 0.4165702534272619}
2023-01-05 09:01:04,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:01:04,461 INFO:     Epoch: 27
2023-01-05 09:01:06,626 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43976265788078306, 'Total loss': 0.43976265788078306} | train loss {'Reaction outcome loss': 0.41030250675016694, 'Total loss': 0.41030250675016694}
2023-01-05 09:01:06,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:01:06,626 INFO:     Epoch: 28
2023-01-05 09:01:08,779 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4240125209093094, 'Total loss': 0.4240125209093094} | train loss {'Reaction outcome loss': 0.4079590498324673, 'Total loss': 0.4079590498324673}
2023-01-05 09:01:08,779 INFO:     Found new best model at epoch 28
2023-01-05 09:01:08,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:01:08,781 INFO:     Epoch: 29
2023-01-05 09:01:10,905 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4214498907327652, 'Total loss': 0.4214498907327652} | train loss {'Reaction outcome loss': 0.40008081833197584, 'Total loss': 0.40008081833197584}
2023-01-05 09:01:10,905 INFO:     Found new best model at epoch 29
2023-01-05 09:01:10,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:01:10,906 INFO:     Epoch: 30
2023-01-05 09:01:13,024 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42385807434717815, 'Total loss': 0.42385807434717815} | train loss {'Reaction outcome loss': 0.3965646681794222, 'Total loss': 0.3965646681794222}
2023-01-05 09:01:13,024 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:01:13,024 INFO:     Epoch: 31
2023-01-05 09:01:15,163 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4696462084849676, 'Total loss': 0.4696462084849676} | train loss {'Reaction outcome loss': 0.39611550156426517, 'Total loss': 0.39611550156426517}
2023-01-05 09:01:15,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:01:15,164 INFO:     Epoch: 32
2023-01-05 09:01:17,298 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4496829112370809, 'Total loss': 0.4496829112370809} | train loss {'Reaction outcome loss': 0.3892506074301217, 'Total loss': 0.3892506074301217}
2023-01-05 09:01:17,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:01:17,298 INFO:     Epoch: 33
2023-01-05 09:01:19,448 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4434914231300354, 'Total loss': 0.4434914231300354} | train loss {'Reaction outcome loss': 0.3851491611626377, 'Total loss': 0.3851491611626377}
2023-01-05 09:01:19,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:01:19,449 INFO:     Epoch: 34
2023-01-05 09:01:21,597 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4562514583269755, 'Total loss': 0.4562514583269755} | train loss {'Reaction outcome loss': 0.38217106048503646, 'Total loss': 0.38217106048503646}
2023-01-05 09:01:21,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:01:21,597 INFO:     Epoch: 35
2023-01-05 09:01:23,706 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4380424569050471, 'Total loss': 0.4380424569050471} | train loss {'Reaction outcome loss': 0.3861285116898058, 'Total loss': 0.3861285116898058}
2023-01-05 09:01:23,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:01:23,706 INFO:     Epoch: 36
2023-01-05 09:01:25,847 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41580204168955487, 'Total loss': 0.41580204168955487} | train loss {'Reaction outcome loss': 0.3851417361039911, 'Total loss': 0.3851417361039911}
2023-01-05 09:01:25,848 INFO:     Found new best model at epoch 36
2023-01-05 09:01:25,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:01:25,850 INFO:     Epoch: 37
2023-01-05 09:01:28,002 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4321047027905782, 'Total loss': 0.4321047027905782} | train loss {'Reaction outcome loss': 0.3730291946292551, 'Total loss': 0.3730291946292551}
2023-01-05 09:01:28,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:01:28,002 INFO:     Epoch: 38
2023-01-05 09:01:30,157 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4222476363182068, 'Total loss': 0.4222476363182068} | train loss {'Reaction outcome loss': 0.37103417626433616, 'Total loss': 0.37103417626433616}
2023-01-05 09:01:30,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:01:30,157 INFO:     Epoch: 39
2023-01-05 09:01:32,283 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44796274999777475, 'Total loss': 0.44796274999777475} | train loss {'Reaction outcome loss': 0.3763653046950914, 'Total loss': 0.3763653046950914}
2023-01-05 09:01:32,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:01:32,283 INFO:     Epoch: 40
2023-01-05 09:01:34,406 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4457266797622045, 'Total loss': 0.4457266797622045} | train loss {'Reaction outcome loss': 0.3630611710415932, 'Total loss': 0.3630611710415932}
2023-01-05 09:01:34,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:01:34,406 INFO:     Epoch: 41
2023-01-05 09:01:36,528 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4160967816909154, 'Total loss': 0.4160967816909154} | train loss {'Reaction outcome loss': 0.3608724104942403, 'Total loss': 0.3608724104942403}
2023-01-05 09:01:36,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:01:36,528 INFO:     Epoch: 42
2023-01-05 09:01:38,671 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4511236548423767, 'Total loss': 0.4511236548423767} | train loss {'Reaction outcome loss': 0.3711491985047452, 'Total loss': 0.3711491985047452}
2023-01-05 09:01:38,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:01:38,672 INFO:     Epoch: 43
2023-01-05 09:01:40,792 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.407558207710584, 'Total loss': 0.407558207710584} | train loss {'Reaction outcome loss': 0.35787146830167016, 'Total loss': 0.35787146830167016}
2023-01-05 09:01:40,792 INFO:     Found new best model at epoch 43
2023-01-05 09:01:40,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:01:40,793 INFO:     Epoch: 44
2023-01-05 09:01:42,957 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42471264451742174, 'Total loss': 0.42471264451742174} | train loss {'Reaction outcome loss': 0.34917887538313813, 'Total loss': 0.34917887538313813}
2023-01-05 09:01:42,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:01:42,957 INFO:     Epoch: 45
2023-01-05 09:01:45,075 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4457564135392507, 'Total loss': 0.4457564135392507} | train loss {'Reaction outcome loss': 0.3580447649718195, 'Total loss': 0.3580447649718195}
2023-01-05 09:01:45,075 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:01:45,075 INFO:     Epoch: 46
2023-01-05 09:01:47,183 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.45573370258013407, 'Total loss': 0.45573370258013407} | train loss {'Reaction outcome loss': 0.375107301897673, 'Total loss': 0.375107301897673}
2023-01-05 09:01:47,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:01:47,183 INFO:     Epoch: 47
2023-01-05 09:01:49,294 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.43180770725011824, 'Total loss': 0.43180770725011824} | train loss {'Reaction outcome loss': 0.3482074244082838, 'Total loss': 0.3482074244082838}
2023-01-05 09:01:49,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:01:49,294 INFO:     Epoch: 48
2023-01-05 09:01:51,424 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41740401784578957, 'Total loss': 0.41740401784578957} | train loss {'Reaction outcome loss': 0.34649976509862807, 'Total loss': 0.34649976509862807}
2023-01-05 09:01:51,424 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:01:51,424 INFO:     Epoch: 49
2023-01-05 09:01:53,555 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39625812669595084, 'Total loss': 0.39625812669595084} | train loss {'Reaction outcome loss': 0.34068204435803584, 'Total loss': 0.34068204435803584}
2023-01-05 09:01:53,555 INFO:     Found new best model at epoch 49
2023-01-05 09:01:53,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:01:53,556 INFO:     Epoch: 50
2023-01-05 09:01:55,685 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4157525817553202, 'Total loss': 0.4157525817553202} | train loss {'Reaction outcome loss': 0.33953278255986347, 'Total loss': 0.33953278255986347}
2023-01-05 09:01:55,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:01:55,686 INFO:     Epoch: 51
2023-01-05 09:01:57,819 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41833776036898296, 'Total loss': 0.41833776036898296} | train loss {'Reaction outcome loss': 0.3303305800039105, 'Total loss': 0.3303305800039105}
2023-01-05 09:01:57,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:01:57,819 INFO:     Epoch: 52
2023-01-05 09:01:59,949 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4215217888355255, 'Total loss': 0.4215217888355255} | train loss {'Reaction outcome loss': 0.326507847820682, 'Total loss': 0.326507847820682}
2023-01-05 09:01:59,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:01:59,949 INFO:     Epoch: 53
2023-01-05 09:02:01,903 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.43375911315282184, 'Total loss': 0.43375911315282184} | train loss {'Reaction outcome loss': 0.33121090200122283, 'Total loss': 0.33121090200122283}
2023-01-05 09:02:01,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:02:01,904 INFO:     Epoch: 54
2023-01-05 09:02:04,028 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41362177232901254, 'Total loss': 0.41362177232901254} | train loss {'Reaction outcome loss': 0.33178915100353956, 'Total loss': 0.33178915100353956}
2023-01-05 09:02:04,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:02:04,028 INFO:     Epoch: 55
2023-01-05 09:02:06,160 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4231520394484202, 'Total loss': 0.4231520394484202} | train loss {'Reaction outcome loss': 0.32717914315045177, 'Total loss': 0.32717914315045177}
2023-01-05 09:02:06,160 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:02:06,160 INFO:     Epoch: 56
2023-01-05 09:02:08,272 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4142867068449656, 'Total loss': 0.4142867068449656} | train loss {'Reaction outcome loss': 0.32745490689505485, 'Total loss': 0.32745490689505485}
2023-01-05 09:02:08,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:02:08,272 INFO:     Epoch: 57
2023-01-05 09:02:10,385 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.430231315890948, 'Total loss': 0.430231315890948} | train loss {'Reaction outcome loss': 0.33167442108135775, 'Total loss': 0.33167442108135775}
2023-01-05 09:02:10,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:02:10,386 INFO:     Epoch: 58
2023-01-05 09:02:12,498 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.41823528011639916, 'Total loss': 0.41823528011639916} | train loss {'Reaction outcome loss': 0.3144781873249314, 'Total loss': 0.3144781873249314}
2023-01-05 09:02:12,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:02:12,499 INFO:     Epoch: 59
2023-01-05 09:02:14,600 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4041545331478119, 'Total loss': 0.4041545331478119} | train loss {'Reaction outcome loss': 0.3149354655120144, 'Total loss': 0.3149354655120144}
2023-01-05 09:02:14,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:02:14,600 INFO:     Epoch: 60
2023-01-05 09:02:16,696 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4305095374584198, 'Total loss': 0.4305095374584198} | train loss {'Reaction outcome loss': 0.3116421502094507, 'Total loss': 0.3116421502094507}
2023-01-05 09:02:16,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:02:16,696 INFO:     Epoch: 61
2023-01-05 09:02:18,838 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.41904507726430895, 'Total loss': 0.41904507726430895} | train loss {'Reaction outcome loss': 0.30557839051260194, 'Total loss': 0.30557839051260194}
2023-01-05 09:02:18,838 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:02:18,838 INFO:     Epoch: 62
2023-01-05 09:02:20,993 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4261835058530172, 'Total loss': 0.4261835058530172} | train loss {'Reaction outcome loss': 0.3041389887575465, 'Total loss': 0.3041389887575465}
2023-01-05 09:02:20,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:02:20,993 INFO:     Epoch: 63
2023-01-05 09:02:23,140 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40643616716066994, 'Total loss': 0.40643616716066994} | train loss {'Reaction outcome loss': 0.30337527466189634, 'Total loss': 0.30337527466189634}
2023-01-05 09:02:23,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:02:23,141 INFO:     Epoch: 64
2023-01-05 09:02:25,271 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.40105678339799244, 'Total loss': 0.40105678339799244} | train loss {'Reaction outcome loss': 0.3055030059767887, 'Total loss': 0.3055030059767887}
2023-01-05 09:02:25,272 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:02:25,272 INFO:     Epoch: 65
2023-01-05 09:02:27,388 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4160798413058122, 'Total loss': 0.4160798413058122} | train loss {'Reaction outcome loss': 0.3024290559386089, 'Total loss': 0.3024290559386089}
2023-01-05 09:02:27,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:02:27,388 INFO:     Epoch: 66
2023-01-05 09:02:29,516 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4050316721200943, 'Total loss': 0.4050316721200943} | train loss {'Reaction outcome loss': 0.294997102311016, 'Total loss': 0.294997102311016}
2023-01-05 09:02:29,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:02:29,517 INFO:     Epoch: 67
2023-01-05 09:02:31,625 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3917628645896912, 'Total loss': 0.3917628645896912} | train loss {'Reaction outcome loss': 0.2927714227023872, 'Total loss': 0.2927714227023872}
2023-01-05 09:02:31,625 INFO:     Found new best model at epoch 67
2023-01-05 09:02:31,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:02:31,627 INFO:     Epoch: 68
2023-01-05 09:02:33,754 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.414368012547493, 'Total loss': 0.414368012547493} | train loss {'Reaction outcome loss': 0.2868172218516955, 'Total loss': 0.2868172218516955}
2023-01-05 09:02:33,754 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:02:33,754 INFO:     Epoch: 69
2023-01-05 09:02:35,680 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40000875492890675, 'Total loss': 0.40000875492890675} | train loss {'Reaction outcome loss': 0.297677946775524, 'Total loss': 0.297677946775524}
2023-01-05 09:02:35,680 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:02:35,681 INFO:     Epoch: 70
2023-01-05 09:02:37,439 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39626434445381165, 'Total loss': 0.39626434445381165} | train loss {'Reaction outcome loss': 0.28773841915139253, 'Total loss': 0.28773841915139253}
2023-01-05 09:02:37,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:02:37,440 INFO:     Epoch: 71
2023-01-05 09:02:39,250 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4023206820090612, 'Total loss': 0.4023206820090612} | train loss {'Reaction outcome loss': 0.29019117679432593, 'Total loss': 0.29019117679432593}
2023-01-05 09:02:39,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:02:39,250 INFO:     Epoch: 72
2023-01-05 09:02:41,362 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.42869254350662234, 'Total loss': 0.42869254350662234} | train loss {'Reaction outcome loss': 0.2922848462244408, 'Total loss': 0.2922848462244408}
2023-01-05 09:02:41,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:02:41,363 INFO:     Epoch: 73
2023-01-05 09:02:43,504 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41850179731845855, 'Total loss': 0.41850179731845855} | train loss {'Reaction outcome loss': 0.28453779178739025, 'Total loss': 0.28453779178739025}
2023-01-05 09:02:43,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:02:43,504 INFO:     Epoch: 74
2023-01-05 09:02:45,641 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3992554490764936, 'Total loss': 0.3992554490764936} | train loss {'Reaction outcome loss': 0.2942338272135374, 'Total loss': 0.2942338272135374}
2023-01-05 09:02:45,641 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:02:45,641 INFO:     Epoch: 75
2023-01-05 09:02:47,779 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4232585286100706, 'Total loss': 0.4232585286100706} | train loss {'Reaction outcome loss': 0.2815208703977987, 'Total loss': 0.2815208703977987}
2023-01-05 09:02:47,779 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:02:47,779 INFO:     Epoch: 76
2023-01-05 09:02:49,918 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.43445588151613873, 'Total loss': 0.43445588151613873} | train loss {'Reaction outcome loss': 0.276325565840639, 'Total loss': 0.276325565840639}
2023-01-05 09:02:49,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:02:49,918 INFO:     Epoch: 77
2023-01-05 09:02:52,033 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40183382034301757, 'Total loss': 0.40183382034301757} | train loss {'Reaction outcome loss': 0.28039564416014956, 'Total loss': 0.28039564416014956}
2023-01-05 09:02:52,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:02:52,033 INFO:     Epoch: 78
2023-01-05 09:02:54,201 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4006619801123937, 'Total loss': 0.4006619801123937} | train loss {'Reaction outcome loss': 0.2748872225488742, 'Total loss': 0.2748872225488742}
2023-01-05 09:02:54,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:02:54,202 INFO:     Epoch: 79
2023-01-05 09:02:56,407 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.408428222934405, 'Total loss': 0.408428222934405} | train loss {'Reaction outcome loss': 0.2718252194189109, 'Total loss': 0.2718252194189109}
2023-01-05 09:02:56,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:02:56,407 INFO:     Epoch: 80
2023-01-05 09:02:58,609 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4341173181931178, 'Total loss': 0.4341173181931178} | train loss {'Reaction outcome loss': 0.27735898580969026, 'Total loss': 0.27735898580969026}
2023-01-05 09:02:58,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:02:58,609 INFO:     Epoch: 81
2023-01-05 09:03:00,803 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4382272700468699, 'Total loss': 0.4382272700468699} | train loss {'Reaction outcome loss': 0.2774485111045921, 'Total loss': 0.2774485111045921}
2023-01-05 09:03:00,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:03:00,803 INFO:     Epoch: 82
2023-01-05 09:03:02,940 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41942140956719715, 'Total loss': 0.41942140956719715} | train loss {'Reaction outcome loss': 0.2646133435529022, 'Total loss': 0.2646133435529022}
2023-01-05 09:03:02,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:03:02,942 INFO:     Epoch: 83
2023-01-05 09:03:05,143 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4477468798557917, 'Total loss': 0.4477468798557917} | train loss {'Reaction outcome loss': 0.27020597834295285, 'Total loss': 0.27020597834295285}
2023-01-05 09:03:05,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:03:05,144 INFO:     Epoch: 84
2023-01-05 09:03:07,282 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.406671005487442, 'Total loss': 0.406671005487442} | train loss {'Reaction outcome loss': 0.2790664732333887, 'Total loss': 0.2790664732333887}
2023-01-05 09:03:07,282 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:03:07,282 INFO:     Epoch: 85
2023-01-05 09:03:09,432 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.40968496203422544, 'Total loss': 0.40968496203422544} | train loss {'Reaction outcome loss': 0.27146467530047114, 'Total loss': 0.27146467530047114}
2023-01-05 09:03:09,432 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:03:09,433 INFO:     Epoch: 86
2023-01-05 09:03:11,571 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4228907843430837, 'Total loss': 0.4228907843430837} | train loss {'Reaction outcome loss': 0.2653841822999918, 'Total loss': 0.2653841822999918}
2023-01-05 09:03:11,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:03:11,571 INFO:     Epoch: 87
2023-01-05 09:03:13,737 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41531467040379844, 'Total loss': 0.41531467040379844} | train loss {'Reaction outcome loss': 0.2712389911201013, 'Total loss': 0.2712389911201013}
2023-01-05 09:03:13,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:03:13,737 INFO:     Epoch: 88
2023-01-05 09:03:15,860 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3984118570884069, 'Total loss': 0.3984118570884069} | train loss {'Reaction outcome loss': 0.27173384949834883, 'Total loss': 0.27173384949834883}
2023-01-05 09:03:15,860 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:03:15,860 INFO:     Epoch: 89
2023-01-05 09:03:17,983 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38270137210687, 'Total loss': 0.38270137210687} | train loss {'Reaction outcome loss': 0.2953810832814138, 'Total loss': 0.2953810832814138}
2023-01-05 09:03:17,983 INFO:     Found new best model at epoch 89
2023-01-05 09:03:17,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:03:17,985 INFO:     Epoch: 90
2023-01-05 09:03:20,141 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40687521596749626, 'Total loss': 0.40687521596749626} | train loss {'Reaction outcome loss': 0.27103549746823485, 'Total loss': 0.27103549746823485}
2023-01-05 09:03:20,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:03:20,141 INFO:     Epoch: 91
2023-01-05 09:03:22,270 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4401325861612956, 'Total loss': 0.4401325861612956} | train loss {'Reaction outcome loss': 0.2746450101144349, 'Total loss': 0.2746450101144349}
2023-01-05 09:03:22,270 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:03:22,271 INFO:     Epoch: 92
2023-01-05 09:03:24,386 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4604475736618042, 'Total loss': 0.4604475736618042} | train loss {'Reaction outcome loss': 0.2582566453113585, 'Total loss': 0.2582566453113585}
2023-01-05 09:03:24,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:03:24,386 INFO:     Epoch: 93
2023-01-05 09:03:26,587 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4167071660359701, 'Total loss': 0.4167071660359701} | train loss {'Reaction outcome loss': 0.2563494124041281, 'Total loss': 0.2563494124041281}
2023-01-05 09:03:26,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:03:26,587 INFO:     Epoch: 94
2023-01-05 09:03:28,710 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.43459781010945636, 'Total loss': 0.43459781010945636} | train loss {'Reaction outcome loss': 0.2619298954830257, 'Total loss': 0.2619298954830257}
2023-01-05 09:03:28,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:03:28,710 INFO:     Epoch: 95
2023-01-05 09:03:30,829 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4026070694128672, 'Total loss': 0.4026070694128672} | train loss {'Reaction outcome loss': 0.267731005548621, 'Total loss': 0.267731005548621}
2023-01-05 09:03:30,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:03:30,829 INFO:     Epoch: 96
2023-01-05 09:03:32,977 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4172834763924281, 'Total loss': 0.4172834763924281} | train loss {'Reaction outcome loss': 0.25682359901459323, 'Total loss': 0.25682359901459323}
2023-01-05 09:03:32,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:03:32,977 INFO:     Epoch: 97
2023-01-05 09:03:35,130 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43048735285798706, 'Total loss': 0.43048735285798706} | train loss {'Reaction outcome loss': 0.2496786716569593, 'Total loss': 0.2496786716569593}
2023-01-05 09:03:35,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:03:35,130 INFO:     Epoch: 98
2023-01-05 09:03:37,286 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.42197205722332, 'Total loss': 0.42197205722332} | train loss {'Reaction outcome loss': 0.2623426355746325, 'Total loss': 0.2623426355746325}
2023-01-05 09:03:37,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:03:37,287 INFO:     Epoch: 99
2023-01-05 09:03:39,439 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4357001264890035, 'Total loss': 0.4357001264890035} | train loss {'Reaction outcome loss': 0.2599001044923764, 'Total loss': 0.2599001044923764}
2023-01-05 09:03:39,439 INFO:     Best model found after epoch 90 of 100.
2023-01-05 09:03:39,439 INFO:   Done with stage: TRAINING
2023-01-05 09:03:39,439 INFO:   Starting stage: EVALUATION
2023-01-05 09:03:39,569 INFO:   Done with stage: EVALUATION
2023-01-05 09:03:39,569 INFO:   Leaving out SEQ value Fold_3
2023-01-05 09:03:39,582 INFO:   examples: 20,544| examples in train: 17,510 | examples in val: 922| examples in test: 2,112
2023-01-05 09:03:39,582 INFO:   Starting stage: FEATURE SCALING
2023-01-05 09:03:40,237 INFO:   Done with stage: FEATURE SCALING
2023-01-05 09:03:40,237 INFO:   Starting stage: SCALING TARGETS
2023-01-05 09:03:40,305 INFO:   Done with stage: SCALING TARGETS
2023-01-05 09:03:40,306 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:03:40,306 INFO:     No hyperparam tuning for this model
2023-01-05 09:03:40,306 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:03:40,306 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 09:03:40,307 INFO:     None feature selector for col prot
2023-01-05 09:03:40,307 INFO:     None feature selector for col prot
2023-01-05 09:03:40,307 INFO:     None feature selector for col prot
2023-01-05 09:03:40,307 INFO:     None feature selector for col chem
2023-01-05 09:03:40,307 INFO:     None feature selector for col chem
2023-01-05 09:03:40,307 INFO:     None feature selector for col chem
2023-01-05 09:03:40,308 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 09:03:40,308 INFO:   Starting stage: BUILD MODEL
2023-01-05 09:03:40,309 INFO:     Number of params in model 72901
2023-01-05 09:03:40,312 INFO:   Done with stage: BUILD MODEL
2023-01-05 09:03:40,312 INFO:   Starting stage: TRAINING
2023-01-05 09:03:40,371 INFO:     Val loss before train {'Reaction outcome loss': 1.0511422395706176, 'Total loss': 1.0511422395706176}
2023-01-05 09:03:40,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:03:40,371 INFO:     Epoch: 0
2023-01-05 09:03:42,530 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8665002028147379, 'Total loss': 0.8665002028147379} | train loss {'Reaction outcome loss': 0.9321609652825515, 'Total loss': 0.9321609652825515}
2023-01-05 09:03:42,531 INFO:     Found new best model at epoch 0
2023-01-05 09:03:42,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:03:42,532 INFO:     Epoch: 1
2023-01-05 09:03:44,653 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6917398889859517, 'Total loss': 0.6917398889859517} | train loss {'Reaction outcome loss': 0.7425118725012688, 'Total loss': 0.7425118725012688}
2023-01-05 09:03:44,654 INFO:     Found new best model at epoch 1
2023-01-05 09:03:44,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:03:44,655 INFO:     Epoch: 2
2023-01-05 09:03:46,788 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5960263709227244, 'Total loss': 0.5960263709227244} | train loss {'Reaction outcome loss': 0.5913002645991144, 'Total loss': 0.5913002645991144}
2023-01-05 09:03:46,788 INFO:     Found new best model at epoch 2
2023-01-05 09:03:46,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:03:46,789 INFO:     Epoch: 3
2023-01-05 09:03:48,894 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.6130544145901998, 'Total loss': 0.6130544145901998} | train loss {'Reaction outcome loss': 0.5324696428584357, 'Total loss': 0.5324696428584357}
2023-01-05 09:03:48,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:03:48,894 INFO:     Epoch: 4
2023-01-05 09:03:50,985 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5775815705458324, 'Total loss': 0.5775815705458324} | train loss {'Reaction outcome loss': 0.5056757898661342, 'Total loss': 0.5056757898661342}
2023-01-05 09:03:50,985 INFO:     Found new best model at epoch 4
2023-01-05 09:03:50,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:03:50,987 INFO:     Epoch: 5
2023-01-05 09:03:53,112 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5519885947306951, 'Total loss': 0.5519885947306951} | train loss {'Reaction outcome loss': 0.49670834931796487, 'Total loss': 0.49670834931796487}
2023-01-05 09:03:53,112 INFO:     Found new best model at epoch 5
2023-01-05 09:03:53,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:03:53,113 INFO:     Epoch: 6
2023-01-05 09:03:55,213 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5434236387411754, 'Total loss': 0.5434236387411754} | train loss {'Reaction outcome loss': 0.4892696460341885, 'Total loss': 0.4892696460341885}
2023-01-05 09:03:55,214 INFO:     Found new best model at epoch 6
2023-01-05 09:03:55,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:03:55,215 INFO:     Epoch: 7
2023-01-05 09:03:57,324 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5558438837528229, 'Total loss': 0.5558438837528229} | train loss {'Reaction outcome loss': 0.4780862621799873, 'Total loss': 0.4780862621799873}
2023-01-05 09:03:57,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:03:57,325 INFO:     Epoch: 8
2023-01-05 09:03:59,428 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5300257861614227, 'Total loss': 0.5300257861614227} | train loss {'Reaction outcome loss': 0.47644469446509424, 'Total loss': 0.47644469446509424}
2023-01-05 09:03:59,428 INFO:     Found new best model at epoch 8
2023-01-05 09:03:59,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:03:59,429 INFO:     Epoch: 9
2023-01-05 09:04:01,525 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5407038648923238, 'Total loss': 0.5407038648923238} | train loss {'Reaction outcome loss': 0.4641977541529349, 'Total loss': 0.4641977541529349}
2023-01-05 09:04:01,525 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:04:01,525 INFO:     Epoch: 10
2023-01-05 09:04:03,629 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5222992012898128, 'Total loss': 0.5222992012898128} | train loss {'Reaction outcome loss': 0.4604918327536026, 'Total loss': 0.4604918327536026}
2023-01-05 09:04:03,629 INFO:     Found new best model at epoch 10
2023-01-05 09:04:03,630 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:04:03,630 INFO:     Epoch: 11
2023-01-05 09:04:05,742 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5386354168256123, 'Total loss': 0.5386354168256123} | train loss {'Reaction outcome loss': 0.45107663004067694, 'Total loss': 0.45107663004067694}
2023-01-05 09:04:05,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:04:05,742 INFO:     Epoch: 12
2023-01-05 09:04:07,851 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5279171347618103, 'Total loss': 0.5279171347618103} | train loss {'Reaction outcome loss': 0.44708475280199605, 'Total loss': 0.44708475280199605}
2023-01-05 09:04:07,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:04:07,852 INFO:     Epoch: 13
2023-01-05 09:04:09,943 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5125491579373678, 'Total loss': 0.5125491579373678} | train loss {'Reaction outcome loss': 0.446197468705856, 'Total loss': 0.446197468705856}
2023-01-05 09:04:09,943 INFO:     Found new best model at epoch 13
2023-01-05 09:04:09,944 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:04:09,945 INFO:     Epoch: 14
2023-01-05 09:04:12,039 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5276311775048573, 'Total loss': 0.5276311775048573} | train loss {'Reaction outcome loss': 0.44026775418841924, 'Total loss': 0.44026775418841924}
2023-01-05 09:04:12,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:04:12,039 INFO:     Epoch: 15
2023-01-05 09:04:14,165 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5294958551724752, 'Total loss': 0.5294958551724752} | train loss {'Reaction outcome loss': 0.4321954751210491, 'Total loss': 0.4321954751210491}
2023-01-05 09:04:14,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:04:14,166 INFO:     Epoch: 16
2023-01-05 09:04:16,013 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5231947521368663, 'Total loss': 0.5231947521368663} | train loss {'Reaction outcome loss': 0.43153596378482173, 'Total loss': 0.43153596378482173}
2023-01-05 09:04:16,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:04:16,014 INFO:     Epoch: 17
2023-01-05 09:04:17,743 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5100110193093618, 'Total loss': 0.5100110193093618} | train loss {'Reaction outcome loss': 0.42497769759519255, 'Total loss': 0.42497769759519255}
2023-01-05 09:04:17,743 INFO:     Found new best model at epoch 17
2023-01-05 09:04:17,744 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:04:17,744 INFO:     Epoch: 18
2023-01-05 09:04:19,615 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4857475350300471, 'Total loss': 0.4857475350300471} | train loss {'Reaction outcome loss': 0.4234175858271383, 'Total loss': 0.4234175858271383}
2023-01-05 09:04:19,615 INFO:     Found new best model at epoch 18
2023-01-05 09:04:19,617 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:04:19,617 INFO:     Epoch: 19
2023-01-05 09:04:21,745 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4921350538730621, 'Total loss': 0.4921350538730621} | train loss {'Reaction outcome loss': 0.41738172226252346, 'Total loss': 0.41738172226252346}
2023-01-05 09:04:21,746 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:04:21,746 INFO:     Epoch: 20
2023-01-05 09:04:23,855 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5225912352403005, 'Total loss': 0.5225912352403005} | train loss {'Reaction outcome loss': 0.40942398001895336, 'Total loss': 0.40942398001895336}
2023-01-05 09:04:23,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:04:23,855 INFO:     Epoch: 21
2023-01-05 09:04:25,951 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5017085353533427, 'Total loss': 0.5017085353533427} | train loss {'Reaction outcome loss': 0.40490828753605373, 'Total loss': 0.40490828753605373}
2023-01-05 09:04:25,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:04:25,952 INFO:     Epoch: 22
2023-01-05 09:04:28,048 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4953909873962402, 'Total loss': 0.4953909873962402} | train loss {'Reaction outcome loss': 0.40409419663848667, 'Total loss': 0.40409419663848667}
2023-01-05 09:04:28,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:04:28,049 INFO:     Epoch: 23
2023-01-05 09:04:30,167 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.5117729783058167, 'Total loss': 0.5117729783058167} | train loss {'Reaction outcome loss': 0.39562834791132134, 'Total loss': 0.39562834791132134}
2023-01-05 09:04:30,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:04:30,167 INFO:     Epoch: 24
2023-01-05 09:04:32,279 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.48461525241533915, 'Total loss': 0.48461525241533915} | train loss {'Reaction outcome loss': 0.39631578833354214, 'Total loss': 0.39631578833354214}
2023-01-05 09:04:32,279 INFO:     Found new best model at epoch 24
2023-01-05 09:04:32,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:04:32,281 INFO:     Epoch: 25
2023-01-05 09:04:34,392 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.48357606629530586, 'Total loss': 0.48357606629530586} | train loss {'Reaction outcome loss': 0.3950976092558708, 'Total loss': 0.3950976092558708}
2023-01-05 09:04:34,393 INFO:     Found new best model at epoch 25
2023-01-05 09:04:34,394 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:04:34,394 INFO:     Epoch: 26
2023-01-05 09:04:36,495 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.475619371732076, 'Total loss': 0.475619371732076} | train loss {'Reaction outcome loss': 0.3906079378441302, 'Total loss': 0.3906079378441302}
2023-01-05 09:04:36,495 INFO:     Found new best model at epoch 26
2023-01-05 09:04:36,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:04:36,497 INFO:     Epoch: 27
2023-01-05 09:04:38,612 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.45887790322303773, 'Total loss': 0.45887790322303773} | train loss {'Reaction outcome loss': 0.38271663816523377, 'Total loss': 0.38271663816523377}
2023-01-05 09:04:38,612 INFO:     Found new best model at epoch 27
2023-01-05 09:04:38,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:04:38,613 INFO:     Epoch: 28
2023-01-05 09:04:40,716 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.483930641412735, 'Total loss': 0.483930641412735} | train loss {'Reaction outcome loss': 0.378744605493589, 'Total loss': 0.378744605493589}
2023-01-05 09:04:40,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:04:40,716 INFO:     Epoch: 29
2023-01-05 09:04:42,841 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.49042913417021433, 'Total loss': 0.49042913417021433} | train loss {'Reaction outcome loss': 0.3826421449763061, 'Total loss': 0.3826421449763061}
2023-01-05 09:04:42,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:04:42,841 INFO:     Epoch: 30
2023-01-05 09:04:44,959 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4979387531677882, 'Total loss': 0.4979387531677882} | train loss {'Reaction outcome loss': 0.36757625614965916, 'Total loss': 0.36757625614965916}
2023-01-05 09:04:44,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:04:44,961 INFO:     Epoch: 31
2023-01-05 09:04:47,059 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.47066342929999033, 'Total loss': 0.47066342929999033} | train loss {'Reaction outcome loss': 0.36772729714747765, 'Total loss': 0.36772729714747765}
2023-01-05 09:04:47,059 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:04:47,060 INFO:     Epoch: 32
2023-01-05 09:04:49,188 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.454944704969724, 'Total loss': 0.454944704969724} | train loss {'Reaction outcome loss': 0.3624214911493507, 'Total loss': 0.3624214911493507}
2023-01-05 09:04:49,188 INFO:     Found new best model at epoch 32
2023-01-05 09:04:49,189 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:04:49,189 INFO:     Epoch: 33
2023-01-05 09:04:51,285 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.49626872738202416, 'Total loss': 0.49626872738202416} | train loss {'Reaction outcome loss': 0.3627002355336708, 'Total loss': 0.3627002355336708}
2023-01-05 09:04:51,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:04:51,286 INFO:     Epoch: 34
2023-01-05 09:04:53,421 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4781980892022451, 'Total loss': 0.4781980892022451} | train loss {'Reaction outcome loss': 0.36836372566049114, 'Total loss': 0.36836372566049114}
2023-01-05 09:04:53,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:04:53,421 INFO:     Epoch: 35
2023-01-05 09:04:55,528 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4463803768157959, 'Total loss': 0.4463803768157959} | train loss {'Reaction outcome loss': 0.35723744797771867, 'Total loss': 0.35723744797771867}
2023-01-05 09:04:55,528 INFO:     Found new best model at epoch 35
2023-01-05 09:04:55,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:04:55,530 INFO:     Epoch: 36
2023-01-05 09:04:57,645 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.46244293451309204, 'Total loss': 0.46244293451309204} | train loss {'Reaction outcome loss': 0.3548548534566904, 'Total loss': 0.3548548534566904}
2023-01-05 09:04:57,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:04:57,646 INFO:     Epoch: 37
2023-01-05 09:04:59,770 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4668987346192201, 'Total loss': 0.4668987346192201} | train loss {'Reaction outcome loss': 0.3494747417305943, 'Total loss': 0.3494747417305943}
2023-01-05 09:04:59,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:04:59,770 INFO:     Epoch: 38
2023-01-05 09:05:01,869 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46560509900252023, 'Total loss': 0.46560509900252023} | train loss {'Reaction outcome loss': 0.3543683805224234, 'Total loss': 0.3543683805224234}
2023-01-05 09:05:01,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:05:01,869 INFO:     Epoch: 39
2023-01-05 09:05:03,962 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4804259320100149, 'Total loss': 0.4804259320100149} | train loss {'Reaction outcome loss': 0.3460809530785484, 'Total loss': 0.3460809530785484}
2023-01-05 09:05:03,963 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:05:03,963 INFO:     Epoch: 40
2023-01-05 09:05:06,078 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4638818840185801, 'Total loss': 0.4638818840185801} | train loss {'Reaction outcome loss': 0.34585251504161063, 'Total loss': 0.34585251504161063}
2023-01-05 09:05:06,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:05:06,078 INFO:     Epoch: 41
2023-01-05 09:05:08,198 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4434519628683726, 'Total loss': 0.4434519628683726} | train loss {'Reaction outcome loss': 0.34082197234795913, 'Total loss': 0.34082197234795913}
2023-01-05 09:05:08,198 INFO:     Found new best model at epoch 41
2023-01-05 09:05:08,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:05:08,199 INFO:     Epoch: 42
2023-01-05 09:05:10,295 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.48915824592113494, 'Total loss': 0.48915824592113494} | train loss {'Reaction outcome loss': 0.3425416942876186, 'Total loss': 0.3425416942876186}
2023-01-05 09:05:10,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:05:10,296 INFO:     Epoch: 43
2023-01-05 09:05:12,427 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.5300614356994628, 'Total loss': 0.5300614356994628} | train loss {'Reaction outcome loss': 0.3358505865572578, 'Total loss': 0.3358505865572578}
2023-01-05 09:05:12,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:05:12,428 INFO:     Epoch: 44
2023-01-05 09:05:14,558 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4511769483486811, 'Total loss': 0.4511769483486811} | train loss {'Reaction outcome loss': 0.3398652945502396, 'Total loss': 0.3398652945502396}
2023-01-05 09:05:14,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:05:14,559 INFO:     Epoch: 45
2023-01-05 09:05:16,699 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4856996218363444, 'Total loss': 0.4856996218363444} | train loss {'Reaction outcome loss': 0.3311540457236506, 'Total loss': 0.3311540457236506}
2023-01-05 09:05:16,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:05:16,699 INFO:     Epoch: 46
2023-01-05 09:05:18,820 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47017263770103457, 'Total loss': 0.47017263770103457} | train loss {'Reaction outcome loss': 0.3335678470558929, 'Total loss': 0.3335678470558929}
2023-01-05 09:05:18,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:05:18,820 INFO:     Epoch: 47
2023-01-05 09:05:20,954 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.48780741095542907, 'Total loss': 0.48780741095542907} | train loss {'Reaction outcome loss': 0.3309840744456453, 'Total loss': 0.3309840744456453}
2023-01-05 09:05:20,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:05:20,955 INFO:     Epoch: 48
2023-01-05 09:05:23,073 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4732673088709513, 'Total loss': 0.4732673088709513} | train loss {'Reaction outcome loss': 0.3260693727129132, 'Total loss': 0.3260693727129132}
2023-01-05 09:05:23,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:05:23,073 INFO:     Epoch: 49
2023-01-05 09:05:25,217 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4904793461163839, 'Total loss': 0.4904793461163839} | train loss {'Reaction outcome loss': 0.317224114725407, 'Total loss': 0.317224114725407}
2023-01-05 09:05:25,217 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:05:25,217 INFO:     Epoch: 50
2023-01-05 09:05:27,347 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4491120715936025, 'Total loss': 0.4491120715936025} | train loss {'Reaction outcome loss': 0.3221443214990797, 'Total loss': 0.3221443214990797}
2023-01-05 09:05:27,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:05:27,348 INFO:     Epoch: 51
2023-01-05 09:05:29,478 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.448835551738739, 'Total loss': 0.448835551738739} | train loss {'Reaction outcome loss': 0.31702444748613084, 'Total loss': 0.31702444748613084}
2023-01-05 09:05:29,479 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:05:29,479 INFO:     Epoch: 52
2023-01-05 09:05:31,616 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47687451442082723, 'Total loss': 0.47687451442082723} | train loss {'Reaction outcome loss': 0.3134732040012405, 'Total loss': 0.3134732040012405}
2023-01-05 09:05:31,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:05:31,616 INFO:     Epoch: 53
2023-01-05 09:05:33,756 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.47787198225657146, 'Total loss': 0.47787198225657146} | train loss {'Reaction outcome loss': 0.31102906726300716, 'Total loss': 0.31102906726300716}
2023-01-05 09:05:33,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:05:33,757 INFO:     Epoch: 54
2023-01-05 09:05:35,869 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.48770806988080345, 'Total loss': 0.48770806988080345} | train loss {'Reaction outcome loss': 0.3103082801358108, 'Total loss': 0.3103082801358108}
2023-01-05 09:05:35,869 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:05:35,869 INFO:     Epoch: 55
2023-01-05 09:05:38,002 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44804726789395016, 'Total loss': 0.44804726789395016} | train loss {'Reaction outcome loss': 0.3086615642464727, 'Total loss': 0.3086615642464727}
2023-01-05 09:05:38,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:05:38,003 INFO:     Epoch: 56
2023-01-05 09:05:40,125 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.46821266909440357, 'Total loss': 0.46821266909440357} | train loss {'Reaction outcome loss': 0.304018881919719, 'Total loss': 0.304018881919719}
2023-01-05 09:05:40,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:05:40,125 INFO:     Epoch: 57
2023-01-05 09:05:42,252 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45191317796707153, 'Total loss': 0.45191317796707153} | train loss {'Reaction outcome loss': 0.3016609009219347, 'Total loss': 0.3016609009219347}
2023-01-05 09:05:42,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:05:42,252 INFO:     Epoch: 58
2023-01-05 09:05:44,386 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4534927288691203, 'Total loss': 0.4534927288691203} | train loss {'Reaction outcome loss': 0.30213117243273413, 'Total loss': 0.30213117243273413}
2023-01-05 09:05:44,386 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:05:44,386 INFO:     Epoch: 59
2023-01-05 09:05:46,497 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4582299674550692, 'Total loss': 0.4582299674550692} | train loss {'Reaction outcome loss': 0.29683839528393136, 'Total loss': 0.29683839528393136}
2023-01-05 09:05:46,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:05:46,497 INFO:     Epoch: 60
2023-01-05 09:05:48,620 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.42907346884409586, 'Total loss': 0.42907346884409586} | train loss {'Reaction outcome loss': 0.29365958262534037, 'Total loss': 0.29365958262534037}
2023-01-05 09:05:48,620 INFO:     Found new best model at epoch 60
2023-01-05 09:05:48,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:05:48,621 INFO:     Epoch: 61
2023-01-05 09:05:50,720 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.45548181732495624, 'Total loss': 0.45548181732495624} | train loss {'Reaction outcome loss': 0.292714421712134, 'Total loss': 0.292714421712134}
2023-01-05 09:05:50,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:05:50,722 INFO:     Epoch: 62
2023-01-05 09:05:52,888 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4450016885995865, 'Total loss': 0.4450016885995865} | train loss {'Reaction outcome loss': 0.2933890033703651, 'Total loss': 0.2933890033703651}
2023-01-05 09:05:52,889 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:05:52,889 INFO:     Epoch: 63
2023-01-05 09:05:55,087 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.44596568246682483, 'Total loss': 0.44596568246682483} | train loss {'Reaction outcome loss': 0.2868498879872317, 'Total loss': 0.2868498879872317}
2023-01-05 09:05:55,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:05:55,087 INFO:     Epoch: 64
2023-01-05 09:05:57,255 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4435979504138231, 'Total loss': 0.4435979504138231} | train loss {'Reaction outcome loss': 0.29060261767276013, 'Total loss': 0.29060261767276013}
2023-01-05 09:05:57,256 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:05:57,256 INFO:     Epoch: 65
2023-01-05 09:05:59,372 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4287518257896105, 'Total loss': 0.4287518257896105} | train loss {'Reaction outcome loss': 0.2821792029592134, 'Total loss': 0.2821792029592134}
2023-01-05 09:05:59,372 INFO:     Found new best model at epoch 65
2023-01-05 09:05:59,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:05:59,373 INFO:     Epoch: 66
2023-01-05 09:06:01,303 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4759473929802577, 'Total loss': 0.4759473929802577} | train loss {'Reaction outcome loss': 0.2786720880327651, 'Total loss': 0.2786720880327651}
2023-01-05 09:06:01,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:06:01,304 INFO:     Epoch: 67
2023-01-05 09:06:03,408 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.460796986023585, 'Total loss': 0.460796986023585} | train loss {'Reaction outcome loss': 0.28150555922439063, 'Total loss': 0.28150555922439063}
2023-01-05 09:06:03,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:06:03,408 INFO:     Epoch: 68
2023-01-05 09:06:05,519 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.45883949995040896, 'Total loss': 0.45883949995040896} | train loss {'Reaction outcome loss': 0.281302945933094, 'Total loss': 0.281302945933094}
2023-01-05 09:06:05,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:06:05,519 INFO:     Epoch: 69
2023-01-05 09:06:07,636 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4774206856886546, 'Total loss': 0.4774206856886546} | train loss {'Reaction outcome loss': 0.27843540757350677, 'Total loss': 0.27843540757350677}
2023-01-05 09:06:07,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:06:07,636 INFO:     Epoch: 70
2023-01-05 09:06:09,732 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.45204074680805206, 'Total loss': 0.45204074680805206} | train loss {'Reaction outcome loss': 0.2755702684776191, 'Total loss': 0.2755702684776191}
2023-01-05 09:06:09,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:06:09,733 INFO:     Epoch: 71
2023-01-05 09:06:11,857 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4080521948635578, 'Total loss': 0.4080521948635578} | train loss {'Reaction outcome loss': 0.27065748037484877, 'Total loss': 0.27065748037484877}
2023-01-05 09:06:11,857 INFO:     Found new best model at epoch 71
2023-01-05 09:06:11,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:06:11,858 INFO:     Epoch: 72
2023-01-05 09:06:13,978 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4506753812233607, 'Total loss': 0.4506753812233607} | train loss {'Reaction outcome loss': 0.27012755201082594, 'Total loss': 0.27012755201082594}
2023-01-05 09:06:13,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:06:13,978 INFO:     Epoch: 73
2023-01-05 09:06:16,083 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4603770852088928, 'Total loss': 0.4603770852088928} | train loss {'Reaction outcome loss': 0.2670425597007257, 'Total loss': 0.2670425597007257}
2023-01-05 09:06:16,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:06:16,084 INFO:     Epoch: 74
2023-01-05 09:06:18,209 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.423952109615008, 'Total loss': 0.423952109615008} | train loss {'Reaction outcome loss': 0.26967583690518443, 'Total loss': 0.26967583690518443}
2023-01-05 09:06:18,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:06:18,209 INFO:     Epoch: 75
2023-01-05 09:06:20,345 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.429727507630984, 'Total loss': 0.429727507630984} | train loss {'Reaction outcome loss': 0.26337211793900406, 'Total loss': 0.26337211793900406}
2023-01-05 09:06:20,345 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:06:20,345 INFO:     Epoch: 76
2023-01-05 09:06:22,455 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.447448186079661, 'Total loss': 0.447448186079661} | train loss {'Reaction outcome loss': 0.2581256246126264, 'Total loss': 0.2581256246126264}
2023-01-05 09:06:22,455 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:06:22,455 INFO:     Epoch: 77
2023-01-05 09:06:24,584 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.42831938962141675, 'Total loss': 0.42831938962141675} | train loss {'Reaction outcome loss': 0.2599934714839515, 'Total loss': 0.2599934714839515}
2023-01-05 09:06:24,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:06:24,584 INFO:     Epoch: 78
2023-01-05 09:06:26,681 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4811655352512995, 'Total loss': 0.4811655352512995} | train loss {'Reaction outcome loss': 0.258444552622518, 'Total loss': 0.258444552622518}
2023-01-05 09:06:26,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:06:26,682 INFO:     Epoch: 79
2023-01-05 09:06:28,786 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4789694259564082, 'Total loss': 0.4789694259564082} | train loss {'Reaction outcome loss': 0.258175830268403, 'Total loss': 0.258175830268403}
2023-01-05 09:06:28,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:06:28,786 INFO:     Epoch: 80
2023-01-05 09:06:30,909 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.43854710658391316, 'Total loss': 0.43854710658391316} | train loss {'Reaction outcome loss': 0.2512853281558865, 'Total loss': 0.2512853281558865}
2023-01-05 09:06:30,910 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:06:30,910 INFO:     Epoch: 81
2023-01-05 09:06:33,013 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4498957902193069, 'Total loss': 0.4498957902193069} | train loss {'Reaction outcome loss': 0.25313712260176013, 'Total loss': 0.25313712260176013}
2023-01-05 09:06:33,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:06:33,014 INFO:     Epoch: 82
2023-01-05 09:06:35,185 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4306533619761467, 'Total loss': 0.4306533619761467} | train loss {'Reaction outcome loss': 0.25112609746084164, 'Total loss': 0.25112609746084164}
2023-01-05 09:06:35,186 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:06:35,186 INFO:     Epoch: 83
2023-01-05 09:06:37,378 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4891911933819453, 'Total loss': 0.4891911933819453} | train loss {'Reaction outcome loss': 0.25483754224545, 'Total loss': 0.25483754224545}
2023-01-05 09:06:37,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:06:37,378 INFO:     Epoch: 84
2023-01-05 09:06:39,484 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4823047677675883, 'Total loss': 0.4823047677675883} | train loss {'Reaction outcome loss': 0.2540054366835495, 'Total loss': 0.2540054366835495}
2023-01-05 09:06:39,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:06:39,484 INFO:     Epoch: 85
2023-01-05 09:06:41,608 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.41141603092352547, 'Total loss': 0.41141603092352547} | train loss {'Reaction outcome loss': 0.24929978893254034, 'Total loss': 0.24929978893254034}
2023-01-05 09:06:41,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:06:41,608 INFO:     Epoch: 86
2023-01-05 09:06:43,715 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.5033081710338593, 'Total loss': 0.5033081710338593} | train loss {'Reaction outcome loss': 0.25039233878445233, 'Total loss': 0.25039233878445233}
2023-01-05 09:06:43,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:06:43,715 INFO:     Epoch: 87
2023-01-05 09:06:45,801 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45295442938804625, 'Total loss': 0.45295442938804625} | train loss {'Reaction outcome loss': 0.251344154901585, 'Total loss': 0.251344154901585}
2023-01-05 09:06:45,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:06:45,802 INFO:     Epoch: 88
2023-01-05 09:06:47,921 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.47869392335414884, 'Total loss': 0.47869392335414884} | train loss {'Reaction outcome loss': 0.2473667235229246, 'Total loss': 0.2473667235229246}
2023-01-05 09:06:47,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:06:47,921 INFO:     Epoch: 89
2023-01-05 09:06:50,018 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.44370862742265066, 'Total loss': 0.44370862742265066} | train loss {'Reaction outcome loss': 0.23882332002322604, 'Total loss': 0.23882332002322604}
2023-01-05 09:06:50,019 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:06:50,019 INFO:     Epoch: 90
2023-01-05 09:06:52,097 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4820779860019684, 'Total loss': 0.4820779860019684} | train loss {'Reaction outcome loss': 0.23786502207092342, 'Total loss': 0.23786502207092342}
2023-01-05 09:06:52,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:06:52,098 INFO:     Epoch: 91
2023-01-05 09:06:54,183 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4873730023701986, 'Total loss': 0.4873730023701986} | train loss {'Reaction outcome loss': 0.24343260969749114, 'Total loss': 0.24343260969749114}
2023-01-05 09:06:54,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:06:54,183 INFO:     Epoch: 92
2023-01-05 09:06:56,297 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.43406205202142395, 'Total loss': 0.43406205202142395} | train loss {'Reaction outcome loss': 0.24153517393300133, 'Total loss': 0.24153517393300133}
2023-01-05 09:06:56,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:06:56,298 INFO:     Epoch: 93
2023-01-05 09:06:58,441 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4287769178549449, 'Total loss': 0.4287769178549449} | train loss {'Reaction outcome loss': 0.23446436768846354, 'Total loss': 0.23446436768846354}
2023-01-05 09:06:58,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:06:58,441 INFO:     Epoch: 94
2023-01-05 09:07:00,585 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4219032943248749, 'Total loss': 0.4219032943248749} | train loss {'Reaction outcome loss': 0.2483408323074453, 'Total loss': 0.2483408323074453}
2023-01-05 09:07:00,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:07:00,585 INFO:     Epoch: 95
2023-01-05 09:07:02,724 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4665865739186605, 'Total loss': 0.4665865739186605} | train loss {'Reaction outcome loss': 0.23864179801019111, 'Total loss': 0.23864179801019111}
2023-01-05 09:07:02,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:07:02,725 INFO:     Epoch: 96
2023-01-05 09:07:04,880 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4574435810248057, 'Total loss': 0.4574435810248057} | train loss {'Reaction outcome loss': 0.23083350619124451, 'Total loss': 0.23083350619124451}
2023-01-05 09:07:04,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:07:04,880 INFO:     Epoch: 97
2023-01-05 09:07:07,035 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.43516961882511773, 'Total loss': 0.43516961882511773} | train loss {'Reaction outcome loss': 0.23419039089055935, 'Total loss': 0.23419039089055935}
2023-01-05 09:07:07,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:07:07,035 INFO:     Epoch: 98
2023-01-05 09:07:09,165 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43199706077575684, 'Total loss': 0.43199706077575684} | train loss {'Reaction outcome loss': 0.2335981763423468, 'Total loss': 0.2335981763423468}
2023-01-05 09:07:09,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:07:09,166 INFO:     Epoch: 99
2023-01-05 09:07:11,333 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4619982957839966, 'Total loss': 0.4619982957839966} | train loss {'Reaction outcome loss': 0.2367954110509179, 'Total loss': 0.2367954110509179}
2023-01-05 09:07:11,333 INFO:     Best model found after epoch 72 of 100.
2023-01-05 09:07:11,333 INFO:   Done with stage: TRAINING
2023-01-05 09:07:11,333 INFO:   Starting stage: EVALUATION
2023-01-05 09:07:11,471 INFO:   Done with stage: EVALUATION
2023-01-05 09:07:11,471 INFO:   Leaving out SEQ value Fold_4
2023-01-05 09:07:11,484 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 09:07:11,484 INFO:   Starting stage: FEATURE SCALING
2023-01-05 09:07:12,134 INFO:   Done with stage: FEATURE SCALING
2023-01-05 09:07:12,134 INFO:   Starting stage: SCALING TARGETS
2023-01-05 09:07:12,203 INFO:   Done with stage: SCALING TARGETS
2023-01-05 09:07:12,203 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:07:12,203 INFO:     No hyperparam tuning for this model
2023-01-05 09:07:12,203 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:07:12,203 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 09:07:12,204 INFO:     None feature selector for col prot
2023-01-05 09:07:12,204 INFO:     None feature selector for col prot
2023-01-05 09:07:12,204 INFO:     None feature selector for col prot
2023-01-05 09:07:12,205 INFO:     None feature selector for col chem
2023-01-05 09:07:12,205 INFO:     None feature selector for col chem
2023-01-05 09:07:12,205 INFO:     None feature selector for col chem
2023-01-05 09:07:12,205 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 09:07:12,205 INFO:   Starting stage: BUILD MODEL
2023-01-05 09:07:12,206 INFO:     Number of params in model 72901
2023-01-05 09:07:12,210 INFO:   Done with stage: BUILD MODEL
2023-01-05 09:07:12,210 INFO:   Starting stage: TRAINING
2023-01-05 09:07:12,269 INFO:     Val loss before train {'Reaction outcome loss': 0.8394862055778504, 'Total loss': 0.8394862055778504}
2023-01-05 09:07:12,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:07:12,269 INFO:     Epoch: 0
2023-01-05 09:07:14,429 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7280723432699839, 'Total loss': 0.7280723432699839} | train loss {'Reaction outcome loss': 0.9322950262306393, 'Total loss': 0.9322950262306393}
2023-01-05 09:07:14,429 INFO:     Found new best model at epoch 0
2023-01-05 09:07:14,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:07:14,431 INFO:     Epoch: 1
2023-01-05 09:07:16,613 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5394641498724619, 'Total loss': 0.5394641498724619} | train loss {'Reaction outcome loss': 0.7452818388659237, 'Total loss': 0.7452818388659237}
2023-01-05 09:07:16,613 INFO:     Found new best model at epoch 1
2023-01-05 09:07:16,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:07:16,615 INFO:     Epoch: 2
2023-01-05 09:07:18,785 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5172950208187104, 'Total loss': 0.5172950208187104} | train loss {'Reaction outcome loss': 0.5938829114134221, 'Total loss': 0.5938829114134221}
2023-01-05 09:07:18,785 INFO:     Found new best model at epoch 2
2023-01-05 09:07:18,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:07:18,786 INFO:     Epoch: 3
2023-01-05 09:07:20,948 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48415271441141766, 'Total loss': 0.48415271441141766} | train loss {'Reaction outcome loss': 0.5429909694602416, 'Total loss': 0.5429909694602416}
2023-01-05 09:07:20,948 INFO:     Found new best model at epoch 3
2023-01-05 09:07:20,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:07:20,949 INFO:     Epoch: 4
2023-01-05 09:07:23,138 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.466274497906367, 'Total loss': 0.466274497906367} | train loss {'Reaction outcome loss': 0.5196330443672512, 'Total loss': 0.5196330443672512}
2023-01-05 09:07:23,139 INFO:     Found new best model at epoch 4
2023-01-05 09:07:23,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:07:23,140 INFO:     Epoch: 5
2023-01-05 09:07:25,277 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4654321829477946, 'Total loss': 0.4654321829477946} | train loss {'Reaction outcome loss': 0.5083054060883707, 'Total loss': 0.5083054060883707}
2023-01-05 09:07:25,277 INFO:     Found new best model at epoch 5
2023-01-05 09:07:25,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:07:25,279 INFO:     Epoch: 6
2023-01-05 09:07:27,462 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4782791167497635, 'Total loss': 0.4782791167497635} | train loss {'Reaction outcome loss': 0.4886259341585463, 'Total loss': 0.4886259341585463}
2023-01-05 09:07:27,463 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:07:27,463 INFO:     Epoch: 7
2023-01-05 09:07:29,622 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.45074366132418314, 'Total loss': 0.45074366132418314} | train loss {'Reaction outcome loss': 0.48057165625842585, 'Total loss': 0.48057165625842585}
2023-01-05 09:07:29,622 INFO:     Found new best model at epoch 7
2023-01-05 09:07:29,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:07:29,623 INFO:     Epoch: 8
2023-01-05 09:07:31,765 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45399321913719176, 'Total loss': 0.45399321913719176} | train loss {'Reaction outcome loss': 0.47265775920865394, 'Total loss': 0.47265775920865394}
2023-01-05 09:07:31,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:07:31,766 INFO:     Epoch: 9
2023-01-05 09:07:33,930 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.44555865923563637, 'Total loss': 0.44555865923563637} | train loss {'Reaction outcome loss': 0.4668343197626055, 'Total loss': 0.4668343197626055}
2023-01-05 09:07:33,930 INFO:     Found new best model at epoch 9
2023-01-05 09:07:33,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:07:33,931 INFO:     Epoch: 10
2023-01-05 09:07:36,104 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45732895731925965, 'Total loss': 0.45732895731925965} | train loss {'Reaction outcome loss': 0.46452158720036835, 'Total loss': 0.46452158720036835}
2023-01-05 09:07:36,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:07:36,104 INFO:     Epoch: 11
2023-01-05 09:07:38,278 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43611135085423786, 'Total loss': 0.43611135085423786} | train loss {'Reaction outcome loss': 0.46106752731661865, 'Total loss': 0.46106752731661865}
2023-01-05 09:07:38,280 INFO:     Found new best model at epoch 11
2023-01-05 09:07:38,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:07:38,281 INFO:     Epoch: 12
2023-01-05 09:07:40,455 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.42950336933135985, 'Total loss': 0.42950336933135985} | train loss {'Reaction outcome loss': 0.45339836414917745, 'Total loss': 0.45339836414917745}
2023-01-05 09:07:40,456 INFO:     Found new best model at epoch 12
2023-01-05 09:07:40,457 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:07:40,457 INFO:     Epoch: 13
2023-01-05 09:07:42,615 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4345949858427048, 'Total loss': 0.4345949858427048} | train loss {'Reaction outcome loss': 0.45312228836659074, 'Total loss': 0.45312228836659074}
2023-01-05 09:07:42,615 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:07:42,615 INFO:     Epoch: 14
2023-01-05 09:07:44,780 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.42690904835859933, 'Total loss': 0.42690904835859933} | train loss {'Reaction outcome loss': 0.5304294277591617, 'Total loss': 0.5304294277591617}
2023-01-05 09:07:44,781 INFO:     Found new best model at epoch 14
2023-01-05 09:07:44,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:07:44,782 INFO:     Epoch: 15
2023-01-05 09:07:46,972 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4342430571715037, 'Total loss': 0.4342430571715037} | train loss {'Reaction outcome loss': 0.45651406836628483, 'Total loss': 0.45651406836628483}
2023-01-05 09:07:46,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:07:46,972 INFO:     Epoch: 16
2023-01-05 09:07:49,107 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4135559966166814, 'Total loss': 0.4135559966166814} | train loss {'Reaction outcome loss': 0.4405134169391586, 'Total loss': 0.4405134169391586}
2023-01-05 09:07:49,107 INFO:     Found new best model at epoch 16
2023-01-05 09:07:49,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:07:49,108 INFO:     Epoch: 17
2023-01-05 09:07:51,201 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.41625382006168365, 'Total loss': 0.41625382006168365} | train loss {'Reaction outcome loss': 0.43262053769000847, 'Total loss': 0.43262053769000847}
2023-01-05 09:07:51,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:07:51,201 INFO:     Epoch: 18
2023-01-05 09:07:53,304 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3956142832835515, 'Total loss': 0.3956142832835515} | train loss {'Reaction outcome loss': 0.4269299562210622, 'Total loss': 0.4269299562210622}
2023-01-05 09:07:53,304 INFO:     Found new best model at epoch 18
2023-01-05 09:07:53,305 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:07:53,305 INFO:     Epoch: 19
2023-01-05 09:07:55,477 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4438193062941233, 'Total loss': 0.4438193062941233} | train loss {'Reaction outcome loss': 0.42555004928895424, 'Total loss': 0.42555004928895424}
2023-01-05 09:07:55,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:07:55,477 INFO:     Epoch: 20
2023-01-05 09:07:57,676 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.41162870526313783, 'Total loss': 0.41162870526313783} | train loss {'Reaction outcome loss': 0.4213535009606647, 'Total loss': 0.4213535009606647}
2023-01-05 09:07:57,677 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:07:57,677 INFO:     Epoch: 21
2023-01-05 09:07:59,829 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.39763799210389456, 'Total loss': 0.39763799210389456} | train loss {'Reaction outcome loss': 0.4168243345035159, 'Total loss': 0.4168243345035159}
2023-01-05 09:07:59,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:07:59,830 INFO:     Epoch: 22
2023-01-05 09:08:01,979 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4201001266638438, 'Total loss': 0.4201001266638438} | train loss {'Reaction outcome loss': 0.4236782718365683, 'Total loss': 0.4236782718365683}
2023-01-05 09:08:01,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:08:01,980 INFO:     Epoch: 23
2023-01-05 09:08:04,128 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.40493921637535096, 'Total loss': 0.40493921637535096} | train loss {'Reaction outcome loss': 0.409424918923279, 'Total loss': 0.409424918923279}
2023-01-05 09:08:04,128 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:08:04,128 INFO:     Epoch: 24
2023-01-05 09:08:06,254 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4073012113571167, 'Total loss': 0.4073012113571167} | train loss {'Reaction outcome loss': 0.4031692005261995, 'Total loss': 0.4031692005261995}
2023-01-05 09:08:06,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:08:06,254 INFO:     Epoch: 25
2023-01-05 09:08:08,396 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4282368799050649, 'Total loss': 0.4282368799050649} | train loss {'Reaction outcome loss': 0.4060208393679257, 'Total loss': 0.4060208393679257}
2023-01-05 09:08:08,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:08:08,396 INFO:     Epoch: 26
2023-01-05 09:08:10,499 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.38746409515539804, 'Total loss': 0.38746409515539804} | train loss {'Reaction outcome loss': 0.3983270224429282, 'Total loss': 0.3983270224429282}
2023-01-05 09:08:10,499 INFO:     Found new best model at epoch 26
2023-01-05 09:08:10,501 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:08:10,501 INFO:     Epoch: 27
2023-01-05 09:08:12,626 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4365932116905848, 'Total loss': 0.4365932116905848} | train loss {'Reaction outcome loss': 0.39753990702540276, 'Total loss': 0.39753990702540276}
2023-01-05 09:08:12,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:08:12,626 INFO:     Epoch: 28
2023-01-05 09:08:14,750 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4044796893994013, 'Total loss': 0.4044796893994013} | train loss {'Reaction outcome loss': 0.3915262287040394, 'Total loss': 0.3915262287040394}
2023-01-05 09:08:14,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:08:14,751 INFO:     Epoch: 29
2023-01-05 09:08:16,866 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3735423351327578, 'Total loss': 0.3735423351327578} | train loss {'Reaction outcome loss': 0.39229618655129644, 'Total loss': 0.39229618655129644}
2023-01-05 09:08:16,866 INFO:     Found new best model at epoch 29
2023-01-05 09:08:16,867 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:08:16,867 INFO:     Epoch: 30
2023-01-05 09:08:18,982 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4090336541334788, 'Total loss': 0.4090336541334788} | train loss {'Reaction outcome loss': 0.3923076325082693, 'Total loss': 0.3923076325082693}
2023-01-05 09:08:18,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:08:18,982 INFO:     Epoch: 31
2023-01-05 09:08:21,135 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.37186315457026164, 'Total loss': 0.37186315457026164} | train loss {'Reaction outcome loss': 0.38992014010369347, 'Total loss': 0.38992014010369347}
2023-01-05 09:08:21,136 INFO:     Found new best model at epoch 31
2023-01-05 09:08:21,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:08:21,137 INFO:     Epoch: 32
2023-01-05 09:08:23,269 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4178350587685903, 'Total loss': 0.4178350587685903} | train loss {'Reaction outcome loss': 0.38401341040119313, 'Total loss': 0.38401341040119313}
2023-01-05 09:08:23,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:08:23,269 INFO:     Epoch: 33
2023-01-05 09:08:25,419 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3938088675340017, 'Total loss': 0.3938088675340017} | train loss {'Reaction outcome loss': 0.3824032375562018, 'Total loss': 0.3824032375562018}
2023-01-05 09:08:25,419 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:08:25,419 INFO:     Epoch: 34
2023-01-05 09:08:27,581 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.36347526460886004, 'Total loss': 0.36347526460886004} | train loss {'Reaction outcome loss': 0.37563529292094533, 'Total loss': 0.37563529292094533}
2023-01-05 09:08:27,582 INFO:     Found new best model at epoch 34
2023-01-05 09:08:27,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:08:27,583 INFO:     Epoch: 35
2023-01-05 09:08:29,710 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.38440359632174176, 'Total loss': 0.38440359632174176} | train loss {'Reaction outcome loss': 0.39669893989111704, 'Total loss': 0.39669893989111704}
2023-01-05 09:08:29,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:08:29,711 INFO:     Epoch: 36
2023-01-05 09:08:31,853 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.3955523024002711, 'Total loss': 0.3955523024002711} | train loss {'Reaction outcome loss': 0.3687389069405533, 'Total loss': 0.3687389069405533}
2023-01-05 09:08:31,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:08:31,853 INFO:     Epoch: 37
2023-01-05 09:08:33,987 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3878074616193771, 'Total loss': 0.3878074616193771} | train loss {'Reaction outcome loss': 0.36604993376354483, 'Total loss': 0.36604993376354483}
2023-01-05 09:08:33,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:08:33,988 INFO:     Epoch: 38
2023-01-05 09:08:36,129 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.38577947914600375, 'Total loss': 0.38577947914600375} | train loss {'Reaction outcome loss': 0.36392389059039776, 'Total loss': 0.36392389059039776}
2023-01-05 09:08:36,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:08:36,129 INFO:     Epoch: 39
2023-01-05 09:08:38,286 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3747716555992762, 'Total loss': 0.3747716555992762} | train loss {'Reaction outcome loss': 0.36882280223611474, 'Total loss': 0.36882280223611474}
2023-01-05 09:08:38,286 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:08:38,286 INFO:     Epoch: 40
2023-01-05 09:08:40,447 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.3581323981285095, 'Total loss': 0.3581323981285095} | train loss {'Reaction outcome loss': 0.37143117758998834, 'Total loss': 0.37143117758998834}
2023-01-05 09:08:40,448 INFO:     Found new best model at epoch 40
2023-01-05 09:08:40,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:08:40,449 INFO:     Epoch: 41
2023-01-05 09:08:42,594 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39408834973971046, 'Total loss': 0.39408834973971046} | train loss {'Reaction outcome loss': 0.3571281480616417, 'Total loss': 0.3571281480616417}
2023-01-05 09:08:42,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:08:42,595 INFO:     Epoch: 42
2023-01-05 09:08:44,725 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.3633552432060242, 'Total loss': 0.3633552432060242} | train loss {'Reaction outcome loss': 0.3464103447968491, 'Total loss': 0.3464103447968491}
2023-01-05 09:08:44,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:08:44,726 INFO:     Epoch: 43
2023-01-05 09:08:46,901 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.3868078708648682, 'Total loss': 0.3868078708648682} | train loss {'Reaction outcome loss': 0.3447640807045399, 'Total loss': 0.3447640807045399}
2023-01-05 09:08:46,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:08:46,901 INFO:     Epoch: 44
2023-01-05 09:08:49,036 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3764825085798899, 'Total loss': 0.3764825085798899} | train loss {'Reaction outcome loss': 0.36059121882030065, 'Total loss': 0.36059121882030065}
2023-01-05 09:08:49,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:08:49,036 INFO:     Epoch: 45
2023-01-05 09:08:51,179 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3767849147319794, 'Total loss': 0.3767849147319794} | train loss {'Reaction outcome loss': 0.3976528535114493, 'Total loss': 0.3976528535114493}
2023-01-05 09:08:51,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:08:51,180 INFO:     Epoch: 46
2023-01-05 09:08:53,324 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3633015294869741, 'Total loss': 0.3633015294869741} | train loss {'Reaction outcome loss': 0.3387315267624428, 'Total loss': 0.3387315267624428}
2023-01-05 09:08:53,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:08:53,325 INFO:     Epoch: 47
2023-01-05 09:08:55,444 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40684294601281484, 'Total loss': 0.40684294601281484} | train loss {'Reaction outcome loss': 0.33655599809413694, 'Total loss': 0.33655599809413694}
2023-01-05 09:08:55,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:08:55,444 INFO:     Epoch: 48
2023-01-05 09:08:57,572 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.37534337441126503, 'Total loss': 0.37534337441126503} | train loss {'Reaction outcome loss': 0.33363033506042405, 'Total loss': 0.33363033506042405}
2023-01-05 09:08:57,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:08:57,572 INFO:     Epoch: 49
2023-01-05 09:08:59,706 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.37911305924256644, 'Total loss': 0.37911305924256644} | train loss {'Reaction outcome loss': 0.33522912865315657, 'Total loss': 0.33522912865315657}
2023-01-05 09:08:59,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:08:59,707 INFO:     Epoch: 50
2023-01-05 09:09:01,828 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3787319928407669, 'Total loss': 0.3787319928407669} | train loss {'Reaction outcome loss': 0.3278932822463305, 'Total loss': 0.3278932822463305}
2023-01-05 09:09:01,828 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:09:01,828 INFO:     Epoch: 51
2023-01-05 09:09:03,950 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3863923877477646, 'Total loss': 0.3863923877477646} | train loss {'Reaction outcome loss': 0.3311841860763641, 'Total loss': 0.3311841860763641}
2023-01-05 09:09:03,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:09:03,951 INFO:     Epoch: 52
2023-01-05 09:09:06,057 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3693803995847702, 'Total loss': 0.3693803995847702} | train loss {'Reaction outcome loss': 0.320524994108448, 'Total loss': 0.320524994108448}
2023-01-05 09:09:06,057 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:09:06,058 INFO:     Epoch: 53
2023-01-05 09:09:08,199 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39408463339010874, 'Total loss': 0.39408463339010874} | train loss {'Reaction outcome loss': 0.32351138943003194, 'Total loss': 0.32351138943003194}
2023-01-05 09:09:08,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:09:08,200 INFO:     Epoch: 54
2023-01-05 09:09:10,310 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4118198320269585, 'Total loss': 0.4118198320269585} | train loss {'Reaction outcome loss': 0.31997541000769625, 'Total loss': 0.31997541000769625}
2023-01-05 09:09:10,310 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:09:10,310 INFO:     Epoch: 55
2023-01-05 09:09:12,430 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4185171683629354, 'Total loss': 0.4185171683629354} | train loss {'Reaction outcome loss': 0.36223772043983143, 'Total loss': 0.36223772043983143}
2023-01-05 09:09:12,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:09:12,431 INFO:     Epoch: 56
2023-01-05 09:09:14,572 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3735189119974772, 'Total loss': 0.3735189119974772} | train loss {'Reaction outcome loss': 0.352215428782654, 'Total loss': 0.352215428782654}
2023-01-05 09:09:14,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:09:14,572 INFO:     Epoch: 57
2023-01-05 09:09:16,700 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40560874541600545, 'Total loss': 0.40560874541600545} | train loss {'Reaction outcome loss': 0.3323703942587599, 'Total loss': 0.3323703942587599}
2023-01-05 09:09:16,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:09:16,700 INFO:     Epoch: 58
2023-01-05 09:09:18,811 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.39261493980884554, 'Total loss': 0.39261493980884554} | train loss {'Reaction outcome loss': 0.35077940744172403, 'Total loss': 0.35077940744172403}
2023-01-05 09:09:18,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:09:18,811 INFO:     Epoch: 59
2023-01-05 09:09:20,927 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4077948113282522, 'Total loss': 0.4077948113282522} | train loss {'Reaction outcome loss': 0.3180777295931256, 'Total loss': 0.3180777295931256}
2023-01-05 09:09:20,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:09:20,928 INFO:     Epoch: 60
2023-01-05 09:09:23,059 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4097818444172541, 'Total loss': 0.4097818444172541} | train loss {'Reaction outcome loss': 0.3136283011397978, 'Total loss': 0.3136283011397978}
2023-01-05 09:09:23,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:09:23,060 INFO:     Epoch: 61
2023-01-05 09:09:25,181 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4288606425126394, 'Total loss': 0.4288606425126394} | train loss {'Reaction outcome loss': 0.3040243560213191, 'Total loss': 0.3040243560213191}
2023-01-05 09:09:25,181 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:09:25,181 INFO:     Epoch: 62
2023-01-05 09:09:27,313 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3761864195267359, 'Total loss': 0.3761864195267359} | train loss {'Reaction outcome loss': 0.3094397514005718, 'Total loss': 0.3094397514005718}
2023-01-05 09:09:27,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:09:27,314 INFO:     Epoch: 63
2023-01-05 09:09:29,437 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3462209274371465, 'Total loss': 0.3462209274371465} | train loss {'Reaction outcome loss': 0.3374426313389647, 'Total loss': 0.3374426313389647}
2023-01-05 09:09:29,437 INFO:     Found new best model at epoch 63
2023-01-05 09:09:29,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:09:29,439 INFO:     Epoch: 64
2023-01-05 09:09:31,550 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.38353860477606455, 'Total loss': 0.38353860477606455} | train loss {'Reaction outcome loss': 0.30914134413773275, 'Total loss': 0.30914134413773275}
2023-01-05 09:09:31,550 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:09:31,550 INFO:     Epoch: 65
2023-01-05 09:09:33,658 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41330946882565817, 'Total loss': 0.41330946882565817} | train loss {'Reaction outcome loss': 0.2983686128087963, 'Total loss': 0.2983686128087963}
2023-01-05 09:09:33,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:09:33,659 INFO:     Epoch: 66
2023-01-05 09:09:35,803 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3980619639158249, 'Total loss': 0.3980619639158249} | train loss {'Reaction outcome loss': 0.2983567339816954, 'Total loss': 0.2983567339816954}
2023-01-05 09:09:35,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:09:35,803 INFO:     Epoch: 67
2023-01-05 09:09:37,937 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3422679200768471, 'Total loss': 0.3422679200768471} | train loss {'Reaction outcome loss': 0.2977789810224288, 'Total loss': 0.2977789810224288}
2023-01-05 09:09:37,937 INFO:     Found new best model at epoch 67
2023-01-05 09:09:37,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:09:37,938 INFO:     Epoch: 68
2023-01-05 09:09:40,106 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.41808039247989653, 'Total loss': 0.41808039247989653} | train loss {'Reaction outcome loss': 0.29722543085074943, 'Total loss': 0.29722543085074943}
2023-01-05 09:09:40,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:09:40,107 INFO:     Epoch: 69
2023-01-05 09:09:42,204 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.37903298139572145, 'Total loss': 0.37903298139572145} | train loss {'Reaction outcome loss': 0.31459646319727536, 'Total loss': 0.31459646319727536}
2023-01-05 09:09:42,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:09:42,205 INFO:     Epoch: 70
2023-01-05 09:09:44,333 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.34286130368709566, 'Total loss': 0.34286130368709566} | train loss {'Reaction outcome loss': 0.2928853155117131, 'Total loss': 0.2928853155117131}
2023-01-05 09:09:44,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:09:44,333 INFO:     Epoch: 71
2023-01-05 09:09:46,471 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3464682628711065, 'Total loss': 0.3464682628711065} | train loss {'Reaction outcome loss': 0.290260771447219, 'Total loss': 0.290260771447219}
2023-01-05 09:09:46,471 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:09:46,472 INFO:     Epoch: 72
2023-01-05 09:09:48,595 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3431137979030609, 'Total loss': 0.3431137979030609} | train loss {'Reaction outcome loss': 0.2908576277069464, 'Total loss': 0.2908576277069464}
2023-01-05 09:09:48,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:09:48,596 INFO:     Epoch: 73
2023-01-05 09:09:50,734 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.38929481705029806, 'Total loss': 0.38929481705029806} | train loss {'Reaction outcome loss': 0.2814977400534638, 'Total loss': 0.2814977400534638}
2023-01-05 09:09:50,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:09:50,734 INFO:     Epoch: 74
2023-01-05 09:09:52,840 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.36651355723539986, 'Total loss': 0.36651355723539986} | train loss {'Reaction outcome loss': 0.28270213439743425, 'Total loss': 0.28270213439743425}
2023-01-05 09:09:52,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:09:52,841 INFO:     Epoch: 75
2023-01-05 09:09:54,988 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.39476306388775506, 'Total loss': 0.39476306388775506} | train loss {'Reaction outcome loss': 0.28307923981573485, 'Total loss': 0.28307923981573485}
2023-01-05 09:09:54,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:09:54,989 INFO:     Epoch: 76
2023-01-05 09:09:57,125 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4289470593134562, 'Total loss': 0.4289470593134562} | train loss {'Reaction outcome loss': 0.2738844519616037, 'Total loss': 0.2738844519616037}
2023-01-05 09:09:57,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:09:57,126 INFO:     Epoch: 77
2023-01-05 09:09:59,266 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3601674288511276, 'Total loss': 0.3601674288511276} | train loss {'Reaction outcome loss': 0.276879201410971, 'Total loss': 0.276879201410971}
2023-01-05 09:09:59,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:09:59,266 INFO:     Epoch: 78
2023-01-05 09:10:01,306 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.378434020280838, 'Total loss': 0.378434020280838} | train loss {'Reaction outcome loss': 0.28697591705481434, 'Total loss': 0.28697591705481434}
2023-01-05 09:10:01,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:10:01,306 INFO:     Epoch: 79
2023-01-05 09:10:03,366 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3981803218523661, 'Total loss': 0.3981803218523661} | train loss {'Reaction outcome loss': 0.2675625104301076, 'Total loss': 0.2675625104301076}
2023-01-05 09:10:03,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:10:03,367 INFO:     Epoch: 80
2023-01-05 09:10:05,492 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4038345068693161, 'Total loss': 0.4038345068693161} | train loss {'Reaction outcome loss': 0.27853188783173327, 'Total loss': 0.27853188783173327}
2023-01-05 09:10:05,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:10:05,493 INFO:     Epoch: 81
2023-01-05 09:10:07,610 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3453404744466146, 'Total loss': 0.3453404744466146} | train loss {'Reaction outcome loss': 0.2728771216833316, 'Total loss': 0.2728771216833316}
2023-01-05 09:10:07,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:10:07,610 INFO:     Epoch: 82
2023-01-05 09:10:09,757 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.38374188244342805, 'Total loss': 0.38374188244342805} | train loss {'Reaction outcome loss': 0.26968202986619505, 'Total loss': 0.26968202986619505}
2023-01-05 09:10:09,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:10:09,758 INFO:     Epoch: 83
2023-01-05 09:10:11,897 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3860032218197981, 'Total loss': 0.3860032218197981} | train loss {'Reaction outcome loss': 0.2676218516327563, 'Total loss': 0.2676218516327563}
2023-01-05 09:10:11,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:10:11,897 INFO:     Epoch: 84
2023-01-05 09:10:14,042 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.38553184767564136, 'Total loss': 0.38553184767564136} | train loss {'Reaction outcome loss': 0.26682508231960644, 'Total loss': 0.26682508231960644}
2023-01-05 09:10:14,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:10:14,043 INFO:     Epoch: 85
2023-01-05 09:10:16,148 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.37048866947491965, 'Total loss': 0.37048866947491965} | train loss {'Reaction outcome loss': 0.26385801823462185, 'Total loss': 0.26385801823462185}
2023-01-05 09:10:16,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:10:16,149 INFO:     Epoch: 86
2023-01-05 09:10:18,289 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.33539515535036724, 'Total loss': 0.33539515535036724} | train loss {'Reaction outcome loss': 0.2688485483421939, 'Total loss': 0.2688485483421939}
2023-01-05 09:10:18,289 INFO:     Found new best model at epoch 86
2023-01-05 09:10:18,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:10:18,290 INFO:     Epoch: 87
2023-01-05 09:10:20,421 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3560503005981445, 'Total loss': 0.3560503005981445} | train loss {'Reaction outcome loss': 0.2722337296398017, 'Total loss': 0.2722337296398017}
2023-01-05 09:10:20,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:10:20,421 INFO:     Epoch: 88
2023-01-05 09:10:22,563 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.38555928468704226, 'Total loss': 0.38555928468704226} | train loss {'Reaction outcome loss': 0.26350880943346716, 'Total loss': 0.26350880943346716}
2023-01-05 09:10:22,563 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:10:22,563 INFO:     Epoch: 89
2023-01-05 09:10:24,701 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.38006008714437484, 'Total loss': 0.38006008714437484} | train loss {'Reaction outcome loss': 0.2766418346217361, 'Total loss': 0.2766418346217361}
2023-01-05 09:10:24,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:10:24,701 INFO:     Epoch: 90
2023-01-05 09:10:26,825 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.35862850745519004, 'Total loss': 0.35862850745519004} | train loss {'Reaction outcome loss': 0.30297146904817107, 'Total loss': 0.30297146904817107}
2023-01-05 09:10:26,826 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:10:26,826 INFO:     Epoch: 91
2023-01-05 09:10:28,956 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3841368277867635, 'Total loss': 0.3841368277867635} | train loss {'Reaction outcome loss': 0.28169758360077074, 'Total loss': 0.28169758360077074}
2023-01-05 09:10:28,956 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:10:28,956 INFO:     Epoch: 92
2023-01-05 09:10:31,088 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3504931877056758, 'Total loss': 0.3504931877056758} | train loss {'Reaction outcome loss': 0.30721144977471104, 'Total loss': 0.30721144977471104}
2023-01-05 09:10:31,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:10:31,088 INFO:     Epoch: 93
2023-01-05 09:10:33,223 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3522710333267848, 'Total loss': 0.3522710333267848} | train loss {'Reaction outcome loss': 0.26753316959429474, 'Total loss': 0.26753316959429474}
2023-01-05 09:10:33,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:10:33,224 INFO:     Epoch: 94
2023-01-05 09:10:35,385 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.37636538247267404, 'Total loss': 0.37636538247267404} | train loss {'Reaction outcome loss': 0.2697478635371595, 'Total loss': 0.2697478635371595}
2023-01-05 09:10:35,385 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:10:35,385 INFO:     Epoch: 95
2023-01-05 09:10:37,519 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3873510976632436, 'Total loss': 0.3873510976632436} | train loss {'Reaction outcome loss': 0.3093980254058767, 'Total loss': 0.3093980254058767}
2023-01-05 09:10:37,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:10:37,520 INFO:     Epoch: 96
2023-01-05 09:10:39,641 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.36789948294560115, 'Total loss': 0.36789948294560115} | train loss {'Reaction outcome loss': 0.27843363928622095, 'Total loss': 0.27843363928622095}
2023-01-05 09:10:39,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:10:39,642 INFO:     Epoch: 97
2023-01-05 09:10:41,762 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3576492667198181, 'Total loss': 0.3576492667198181} | train loss {'Reaction outcome loss': 0.2696499201718826, 'Total loss': 0.2696499201718826}
2023-01-05 09:10:41,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:10:41,762 INFO:     Epoch: 98
2023-01-05 09:10:43,901 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3757676030198733, 'Total loss': 0.3757676030198733} | train loss {'Reaction outcome loss': 0.2950250404023066, 'Total loss': 0.2950250404023066}
2023-01-05 09:10:43,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:10:43,901 INFO:     Epoch: 99
2023-01-05 09:10:46,034 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.37357959101597465, 'Total loss': 0.37357959101597465} | train loss {'Reaction outcome loss': 0.2672696035611359, 'Total loss': 0.2672696035611359}
2023-01-05 09:10:46,034 INFO:     Best model found after epoch 87 of 100.
2023-01-05 09:10:46,034 INFO:   Done with stage: TRAINING
2023-01-05 09:10:46,035 INFO:   Starting stage: EVALUATION
2023-01-05 09:10:46,166 INFO:   Done with stage: EVALUATION
2023-01-05 09:10:46,166 INFO:   Leaving out SEQ value Fold_5
2023-01-05 09:10:46,178 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 09:10:46,178 INFO:   Starting stage: FEATURE SCALING
2023-01-05 09:10:46,827 INFO:   Done with stage: FEATURE SCALING
2023-01-05 09:10:46,828 INFO:   Starting stage: SCALING TARGETS
2023-01-05 09:10:46,896 INFO:   Done with stage: SCALING TARGETS
2023-01-05 09:10:46,896 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:10:46,896 INFO:     No hyperparam tuning for this model
2023-01-05 09:10:46,896 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:10:46,896 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 09:10:46,897 INFO:     None feature selector for col prot
2023-01-05 09:10:46,897 INFO:     None feature selector for col prot
2023-01-05 09:10:46,897 INFO:     None feature selector for col prot
2023-01-05 09:10:46,898 INFO:     None feature selector for col chem
2023-01-05 09:10:46,898 INFO:     None feature selector for col chem
2023-01-05 09:10:46,898 INFO:     None feature selector for col chem
2023-01-05 09:10:46,898 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 09:10:46,898 INFO:   Starting stage: BUILD MODEL
2023-01-05 09:10:46,899 INFO:     Number of params in model 72901
2023-01-05 09:10:46,902 INFO:   Done with stage: BUILD MODEL
2023-01-05 09:10:46,902 INFO:   Starting stage: TRAINING
2023-01-05 09:10:46,962 INFO:     Val loss before train {'Reaction outcome loss': 0.993837841351827, 'Total loss': 0.993837841351827}
2023-01-05 09:10:46,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:10:46,962 INFO:     Epoch: 0
2023-01-05 09:10:49,087 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8380706350008646, 'Total loss': 0.8380706350008646} | train loss {'Reaction outcome loss': 0.9460212680837308, 'Total loss': 0.9460212680837308}
2023-01-05 09:10:49,087 INFO:     Found new best model at epoch 0
2023-01-05 09:10:49,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:10:49,088 INFO:     Epoch: 1
2023-01-05 09:10:51,222 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6679652015368144, 'Total loss': 0.6679652015368144} | train loss {'Reaction outcome loss': 0.7765615076794952, 'Total loss': 0.7765615076794952}
2023-01-05 09:10:51,222 INFO:     Found new best model at epoch 1
2023-01-05 09:10:51,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:10:51,223 INFO:     Epoch: 2
2023-01-05 09:10:53,339 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5569499274094899, 'Total loss': 0.5569499274094899} | train loss {'Reaction outcome loss': 0.6202350619252408, 'Total loss': 0.6202350619252408}
2023-01-05 09:10:53,339 INFO:     Found new best model at epoch 2
2023-01-05 09:10:53,340 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:10:53,341 INFO:     Epoch: 3
2023-01-05 09:10:55,479 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5098751773436864, 'Total loss': 0.5098751773436864} | train loss {'Reaction outcome loss': 0.5454242796458922, 'Total loss': 0.5454242796458922}
2023-01-05 09:10:55,480 INFO:     Found new best model at epoch 3
2023-01-05 09:10:55,481 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:10:55,481 INFO:     Epoch: 4
2023-01-05 09:10:57,623 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5082402149836223, 'Total loss': 0.5082402149836223} | train loss {'Reaction outcome loss': 0.525014392681931, 'Total loss': 0.525014392681931}
2023-01-05 09:10:57,623 INFO:     Found new best model at epoch 4
2023-01-05 09:10:57,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:10:57,625 INFO:     Epoch: 5
2023-01-05 09:10:59,754 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5004805783430736, 'Total loss': 0.5004805783430736} | train loss {'Reaction outcome loss': 0.503667433554515, 'Total loss': 0.503667433554515}
2023-01-05 09:10:59,754 INFO:     Found new best model at epoch 5
2023-01-05 09:10:59,755 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:10:59,755 INFO:     Epoch: 6
2023-01-05 09:11:01,906 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4733055830001831, 'Total loss': 0.4733055830001831} | train loss {'Reaction outcome loss': 0.49205332187538975, 'Total loss': 0.49205332187538975}
2023-01-05 09:11:01,906 INFO:     Found new best model at epoch 6
2023-01-05 09:11:01,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:11:01,908 INFO:     Epoch: 7
2023-01-05 09:11:04,021 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5003345668315887, 'Total loss': 0.5003345668315887} | train loss {'Reaction outcome loss': 0.4807440212487314, 'Total loss': 0.4807440212487314}
2023-01-05 09:11:04,022 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:11:04,022 INFO:     Epoch: 8
2023-01-05 09:11:06,146 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5105512758096059, 'Total loss': 0.5105512758096059} | train loss {'Reaction outcome loss': 0.4755082328397014, 'Total loss': 0.4755082328397014}
2023-01-05 09:11:06,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:11:06,146 INFO:     Epoch: 9
2023-01-05 09:11:08,288 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4645778963963191, 'Total loss': 0.4645778963963191} | train loss {'Reaction outcome loss': 0.4715904032387888, 'Total loss': 0.4715904032387888}
2023-01-05 09:11:08,288 INFO:     Found new best model at epoch 9
2023-01-05 09:11:08,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:11:08,290 INFO:     Epoch: 10
2023-01-05 09:11:10,429 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47217101653416954, 'Total loss': 0.47217101653416954} | train loss {'Reaction outcome loss': 0.46657526068093547, 'Total loss': 0.46657526068093547}
2023-01-05 09:11:10,429 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:11:10,429 INFO:     Epoch: 11
2023-01-05 09:11:12,591 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.48157737255096433, 'Total loss': 0.48157737255096433} | train loss {'Reaction outcome loss': 0.45682426926676545, 'Total loss': 0.45682426926676545}
2023-01-05 09:11:12,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:11:12,591 INFO:     Epoch: 12
2023-01-05 09:11:14,783 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4809458245833715, 'Total loss': 0.4809458245833715} | train loss {'Reaction outcome loss': 0.45896691030113274, 'Total loss': 0.45896691030113274}
2023-01-05 09:11:14,783 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:11:14,783 INFO:     Epoch: 13
2023-01-05 09:11:16,923 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.45508715212345124, 'Total loss': 0.45508715212345124} | train loss {'Reaction outcome loss': 0.4528446131880103, 'Total loss': 0.4528446131880103}
2023-01-05 09:11:16,923 INFO:     Found new best model at epoch 13
2023-01-05 09:11:16,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:11:16,925 INFO:     Epoch: 14
2023-01-05 09:11:19,078 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.48223033746083577, 'Total loss': 0.48223033746083577} | train loss {'Reaction outcome loss': 0.44656456915480136, 'Total loss': 0.44656456915480136}
2023-01-05 09:11:19,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:11:19,078 INFO:     Epoch: 15
2023-01-05 09:11:21,243 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45486825903256733, 'Total loss': 0.45486825903256733} | train loss {'Reaction outcome loss': 0.441560526401988, 'Total loss': 0.441560526401988}
2023-01-05 09:11:21,243 INFO:     Found new best model at epoch 15
2023-01-05 09:11:21,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:11:21,244 INFO:     Epoch: 16
2023-01-05 09:11:23,404 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4526455233494441, 'Total loss': 0.4526455233494441} | train loss {'Reaction outcome loss': 0.4358136984738202, 'Total loss': 0.4358136984738202}
2023-01-05 09:11:23,405 INFO:     Found new best model at epoch 16
2023-01-05 09:11:23,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:11:23,406 INFO:     Epoch: 17
2023-01-05 09:11:25,564 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4452017158269882, 'Total loss': 0.4452017158269882} | train loss {'Reaction outcome loss': 0.43525221561912164, 'Total loss': 0.43525221561912164}
2023-01-05 09:11:25,564 INFO:     Found new best model at epoch 17
2023-01-05 09:11:25,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:11:25,566 INFO:     Epoch: 18
2023-01-05 09:11:27,709 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.452122496565183, 'Total loss': 0.452122496565183} | train loss {'Reaction outcome loss': 0.4232930250008614, 'Total loss': 0.4232930250008614}
2023-01-05 09:11:27,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:11:27,709 INFO:     Epoch: 19
2023-01-05 09:11:29,857 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45003396570682525, 'Total loss': 0.45003396570682525} | train loss {'Reaction outcome loss': 0.4224010125770896, 'Total loss': 0.4224010125770896}
2023-01-05 09:11:29,857 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:11:29,858 INFO:     Epoch: 20
2023-01-05 09:11:32,021 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43777269224325815, 'Total loss': 0.43777269224325815} | train loss {'Reaction outcome loss': 0.41951817903492855, 'Total loss': 0.41951817903492855}
2023-01-05 09:11:32,021 INFO:     Found new best model at epoch 20
2023-01-05 09:11:32,023 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:11:32,023 INFO:     Epoch: 21
2023-01-05 09:11:34,186 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45644182960192364, 'Total loss': 0.45644182960192364} | train loss {'Reaction outcome loss': 0.41174880000981184, 'Total loss': 0.41174880000981184}
2023-01-05 09:11:34,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:11:34,188 INFO:     Epoch: 22
2023-01-05 09:11:36,368 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4433241019646327, 'Total loss': 0.4433241019646327} | train loss {'Reaction outcome loss': 0.4111826652492857, 'Total loss': 0.4111826652492857}
2023-01-05 09:11:36,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:11:36,368 INFO:     Epoch: 23
2023-01-05 09:11:38,475 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4513330022493998, 'Total loss': 0.4513330022493998} | train loss {'Reaction outcome loss': 0.4024494656963469, 'Total loss': 0.4024494656963469}
2023-01-05 09:11:38,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:11:38,475 INFO:     Epoch: 24
2023-01-05 09:11:40,605 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4521768321593603, 'Total loss': 0.4521768321593603} | train loss {'Reaction outcome loss': 0.39932216044905383, 'Total loss': 0.39932216044905383}
2023-01-05 09:11:40,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:11:40,606 INFO:     Epoch: 25
2023-01-05 09:11:42,746 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4359019120534261, 'Total loss': 0.4359019120534261} | train loss {'Reaction outcome loss': 0.39670668311067436, 'Total loss': 0.39670668311067436}
2023-01-05 09:11:42,746 INFO:     Found new best model at epoch 25
2023-01-05 09:11:42,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:11:42,748 INFO:     Epoch: 26
2023-01-05 09:11:44,880 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.44993354777495065, 'Total loss': 0.44993354777495065} | train loss {'Reaction outcome loss': 0.39139734708875523, 'Total loss': 0.39139734708875523}
2023-01-05 09:11:44,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:11:44,880 INFO:     Epoch: 27
2023-01-05 09:11:47,008 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.49256103734175366, 'Total loss': 0.49256103734175366} | train loss {'Reaction outcome loss': 0.3883776443906209, 'Total loss': 0.3883776443906209}
2023-01-05 09:11:47,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:11:47,008 INFO:     Epoch: 28
2023-01-05 09:11:49,115 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44516215324401853, 'Total loss': 0.44516215324401853} | train loss {'Reaction outcome loss': 0.38528443205873025, 'Total loss': 0.38528443205873025}
2023-01-05 09:11:49,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:11:49,115 INFO:     Epoch: 29
2023-01-05 09:11:51,233 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4397610157728195, 'Total loss': 0.4397610157728195} | train loss {'Reaction outcome loss': 0.38602825975052285, 'Total loss': 0.38602825975052285}
2023-01-05 09:11:51,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:11:51,233 INFO:     Epoch: 30
2023-01-05 09:11:53,360 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4503957241773605, 'Total loss': 0.4503957241773605} | train loss {'Reaction outcome loss': 0.3785490986726344, 'Total loss': 0.3785490986726344}
2023-01-05 09:11:53,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:11:53,361 INFO:     Epoch: 31
2023-01-05 09:11:55,513 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4483413736025492, 'Total loss': 0.4483413736025492} | train loss {'Reaction outcome loss': 0.37786359229673117, 'Total loss': 0.37786359229673117}
2023-01-05 09:11:55,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:11:55,513 INFO:     Epoch: 32
2023-01-05 09:11:57,667 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.41824885283907254, 'Total loss': 0.41824885283907254} | train loss {'Reaction outcome loss': 0.3751062302974587, 'Total loss': 0.3751062302974587}
2023-01-05 09:11:57,667 INFO:     Found new best model at epoch 32
2023-01-05 09:11:57,668 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:11:57,668 INFO:     Epoch: 33
2023-01-05 09:11:59,831 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4552710860967636, 'Total loss': 0.4552710860967636} | train loss {'Reaction outcome loss': 0.3697098725431663, 'Total loss': 0.3697098725431663}
2023-01-05 09:11:59,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:11:59,832 INFO:     Epoch: 34
2023-01-05 09:12:01,970 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.49616795778274536, 'Total loss': 0.49616795778274536} | train loss {'Reaction outcome loss': 0.3650678539319159, 'Total loss': 0.3650678539319159}
2023-01-05 09:12:01,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:12:01,970 INFO:     Epoch: 35
2023-01-05 09:12:04,095 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.41531474788983663, 'Total loss': 0.41531474788983663} | train loss {'Reaction outcome loss': 0.36537948570849665, 'Total loss': 0.36537948570849665}
2023-01-05 09:12:04,096 INFO:     Found new best model at epoch 35
2023-01-05 09:12:04,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:12:04,097 INFO:     Epoch: 36
2023-01-05 09:12:06,240 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42216080526510874, 'Total loss': 0.42216080526510874} | train loss {'Reaction outcome loss': 0.35691545410115366, 'Total loss': 0.35691545410115366}
2023-01-05 09:12:06,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:12:06,240 INFO:     Epoch: 37
2023-01-05 09:12:08,348 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42818602323532107, 'Total loss': 0.42818602323532107} | train loss {'Reaction outcome loss': 0.3565273276573914, 'Total loss': 0.3565273276573914}
2023-01-05 09:12:08,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:12:08,348 INFO:     Epoch: 38
2023-01-05 09:12:10,490 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46540284355481465, 'Total loss': 0.46540284355481465} | train loss {'Reaction outcome loss': 0.34973511468309787, 'Total loss': 0.34973511468309787}
2023-01-05 09:12:10,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:12:10,491 INFO:     Epoch: 39
2023-01-05 09:12:12,614 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4213755078613758, 'Total loss': 0.4213755078613758} | train loss {'Reaction outcome loss': 0.3473351328004999, 'Total loss': 0.3473351328004999}
2023-01-05 09:12:12,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:12:12,614 INFO:     Epoch: 40
2023-01-05 09:12:14,712 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42626907825469973, 'Total loss': 0.42626907825469973} | train loss {'Reaction outcome loss': 0.34861488774795396, 'Total loss': 0.34861488774795396}
2023-01-05 09:12:14,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:12:14,712 INFO:     Epoch: 41
2023-01-05 09:12:16,845 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.42536775370438895, 'Total loss': 0.42536775370438895} | train loss {'Reaction outcome loss': 0.33973344514946646, 'Total loss': 0.33973344514946646}
2023-01-05 09:12:16,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:12:16,845 INFO:     Epoch: 42
2023-01-05 09:12:18,999 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.44927377502123517, 'Total loss': 0.44927377502123517} | train loss {'Reaction outcome loss': 0.33818552605404323, 'Total loss': 0.33818552605404323}
2023-01-05 09:12:19,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:12:19,000 INFO:     Epoch: 43
2023-01-05 09:12:21,129 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43552545458078384, 'Total loss': 0.43552545458078384} | train loss {'Reaction outcome loss': 0.3297048489889298, 'Total loss': 0.3297048489889298}
2023-01-05 09:12:21,129 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:12:21,129 INFO:     Epoch: 44
2023-01-05 09:12:23,259 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.39574471712112425, 'Total loss': 0.39574471712112425} | train loss {'Reaction outcome loss': 0.32769809706331593, 'Total loss': 0.32769809706331593}
2023-01-05 09:12:23,260 INFO:     Found new best model at epoch 44
2023-01-05 09:12:23,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:12:23,261 INFO:     Epoch: 45
2023-01-05 09:12:25,396 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4123141825199127, 'Total loss': 0.4123141825199127} | train loss {'Reaction outcome loss': 0.32519405380913496, 'Total loss': 0.32519405380913496}
2023-01-05 09:12:25,396 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:12:25,396 INFO:     Epoch: 46
2023-01-05 09:12:27,551 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.451940131187439, 'Total loss': 0.451940131187439} | train loss {'Reaction outcome loss': 0.32403569957678496, 'Total loss': 0.32403569957678496}
2023-01-05 09:12:27,551 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:12:27,551 INFO:     Epoch: 47
2023-01-05 09:12:29,672 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4152996788422267, 'Total loss': 0.4152996788422267} | train loss {'Reaction outcome loss': 0.3241191390457997, 'Total loss': 0.3241191390457997}
2023-01-05 09:12:29,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:12:29,672 INFO:     Epoch: 48
2023-01-05 09:12:31,827 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4409203896919886, 'Total loss': 0.4409203896919886} | train loss {'Reaction outcome loss': 0.32113418243959924, 'Total loss': 0.32113418243959924}
2023-01-05 09:12:31,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:12:31,827 INFO:     Epoch: 49
2023-01-05 09:12:33,977 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4184920330842336, 'Total loss': 0.4184920330842336} | train loss {'Reaction outcome loss': 0.3154939683658552, 'Total loss': 0.3154939683658552}
2023-01-05 09:12:33,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:12:33,977 INFO:     Epoch: 50
2023-01-05 09:12:36,141 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4222729325294495, 'Total loss': 0.4222729325294495} | train loss {'Reaction outcome loss': 0.30593413062097796, 'Total loss': 0.30593413062097796}
2023-01-05 09:12:36,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:12:36,141 INFO:     Epoch: 51
2023-01-05 09:12:38,293 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41516169607639314, 'Total loss': 0.41516169607639314} | train loss {'Reaction outcome loss': 0.31151783506685216, 'Total loss': 0.31151783506685216}
2023-01-05 09:12:38,294 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:12:38,294 INFO:     Epoch: 52
2023-01-05 09:12:40,453 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.386841577788194, 'Total loss': 0.386841577788194} | train loss {'Reaction outcome loss': 0.3091107155549397, 'Total loss': 0.3091107155549397}
2023-01-05 09:12:40,454 INFO:     Found new best model at epoch 52
2023-01-05 09:12:40,456 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:12:40,456 INFO:     Epoch: 53
2023-01-05 09:12:42,621 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3981127401192983, 'Total loss': 0.3981127401192983} | train loss {'Reaction outcome loss': 0.30268236370051166, 'Total loss': 0.30268236370051166}
2023-01-05 09:12:42,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:12:42,621 INFO:     Epoch: 54
2023-01-05 09:12:44,778 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4031360606352488, 'Total loss': 0.4031360606352488} | train loss {'Reaction outcome loss': 0.3007660985181263, 'Total loss': 0.3007660985181263}
2023-01-05 09:12:44,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:12:44,778 INFO:     Epoch: 55
2023-01-05 09:12:46,929 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4047885219256083, 'Total loss': 0.4047885219256083} | train loss {'Reaction outcome loss': 0.29707129555165984, 'Total loss': 0.29707129555165984}
2023-01-05 09:12:46,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:12:46,930 INFO:     Epoch: 56
2023-01-05 09:12:49,058 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4181704451640447, 'Total loss': 0.4181704451640447} | train loss {'Reaction outcome loss': 0.29398113046688723, 'Total loss': 0.29398113046688723}
2023-01-05 09:12:49,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:12:49,058 INFO:     Epoch: 57
2023-01-05 09:12:51,206 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.41935181319713594, 'Total loss': 0.41935181319713594} | train loss {'Reaction outcome loss': 0.2964546050446021, 'Total loss': 0.2964546050446021}
2023-01-05 09:12:51,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:12:51,206 INFO:     Epoch: 58
2023-01-05 09:12:53,328 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4094989577929179, 'Total loss': 0.4094989577929179} | train loss {'Reaction outcome loss': 0.2901975780940658, 'Total loss': 0.2901975780940658}
2023-01-05 09:12:53,328 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:12:53,328 INFO:     Epoch: 59
2023-01-05 09:12:55,476 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3965893089771271, 'Total loss': 0.3965893089771271} | train loss {'Reaction outcome loss': 0.2892292445451559, 'Total loss': 0.2892292445451559}
2023-01-05 09:12:55,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:12:55,476 INFO:     Epoch: 60
2023-01-05 09:12:57,629 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4024361009399096, 'Total loss': 0.4024361009399096} | train loss {'Reaction outcome loss': 0.28954571513761684, 'Total loss': 0.28954571513761684}
2023-01-05 09:12:57,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:12:57,629 INFO:     Epoch: 61
2023-01-05 09:12:59,787 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.42770995100339254, 'Total loss': 0.42770995100339254} | train loss {'Reaction outcome loss': 0.27980533881038966, 'Total loss': 0.27980533881038966}
2023-01-05 09:12:59,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:12:59,788 INFO:     Epoch: 62
2023-01-05 09:13:01,914 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41675658424695333, 'Total loss': 0.41675658424695333} | train loss {'Reaction outcome loss': 0.28108436158364, 'Total loss': 0.28108436158364}
2023-01-05 09:13:01,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:13:01,915 INFO:     Epoch: 63
2023-01-05 09:13:04,066 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42345021764437357, 'Total loss': 0.42345021764437357} | train loss {'Reaction outcome loss': 0.29066516035354095, 'Total loss': 0.29066516035354095}
2023-01-05 09:13:04,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:13:04,066 INFO:     Epoch: 64
2023-01-05 09:13:06,210 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4295429617166519, 'Total loss': 0.4295429617166519} | train loss {'Reaction outcome loss': 0.27491905330428146, 'Total loss': 0.27491905330428146}
2023-01-05 09:13:06,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:13:06,210 INFO:     Epoch: 65
2023-01-05 09:13:08,359 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40894283056259156, 'Total loss': 0.40894283056259156} | train loss {'Reaction outcome loss': 0.27419806157477494, 'Total loss': 0.27419806157477494}
2023-01-05 09:13:08,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:13:08,359 INFO:     Epoch: 66
2023-01-05 09:13:10,465 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4008266478776932, 'Total loss': 0.4008266478776932} | train loss {'Reaction outcome loss': 0.2772345359870888, 'Total loss': 0.2772345359870888}
2023-01-05 09:13:10,465 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:13:10,465 INFO:     Epoch: 67
2023-01-05 09:13:12,594 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4068803032239278, 'Total loss': 0.4068803032239278} | train loss {'Reaction outcome loss': 0.2796100404530441, 'Total loss': 0.2796100404530441}
2023-01-05 09:13:12,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:13:12,594 INFO:     Epoch: 68
2023-01-05 09:13:14,739 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.39675993621349337, 'Total loss': 0.39675993621349337} | train loss {'Reaction outcome loss': 0.26864966603554113, 'Total loss': 0.26864966603554113}
2023-01-05 09:13:14,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:13:14,740 INFO:     Epoch: 69
2023-01-05 09:13:16,893 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3977896680434545, 'Total loss': 0.3977896680434545} | train loss {'Reaction outcome loss': 0.269038240105882, 'Total loss': 0.269038240105882}
2023-01-05 09:13:16,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:13:16,894 INFO:     Epoch: 70
2023-01-05 09:13:19,048 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.39176105161507924, 'Total loss': 0.39176105161507924} | train loss {'Reaction outcome loss': 0.2751310816982808, 'Total loss': 0.2751310816982808}
2023-01-05 09:13:19,048 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:13:19,048 INFO:     Epoch: 71
2023-01-05 09:13:21,206 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40209955871105196, 'Total loss': 0.40209955871105196} | train loss {'Reaction outcome loss': 0.26723373918003984, 'Total loss': 0.26723373918003984}
2023-01-05 09:13:21,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:13:21,206 INFO:     Epoch: 72
2023-01-05 09:13:23,360 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.37896788169940315, 'Total loss': 0.37896788169940315} | train loss {'Reaction outcome loss': 0.26861246711564407, 'Total loss': 0.26861246711564407}
2023-01-05 09:13:23,361 INFO:     Found new best model at epoch 72
2023-01-05 09:13:23,362 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:13:23,362 INFO:     Epoch: 73
2023-01-05 09:13:25,517 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3996525079011917, 'Total loss': 0.3996525079011917} | train loss {'Reaction outcome loss': 0.2570015392283025, 'Total loss': 0.2570015392283025}
2023-01-05 09:13:25,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:13:25,518 INFO:     Epoch: 74
2023-01-05 09:13:27,675 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3822093099355698, 'Total loss': 0.3822093099355698} | train loss {'Reaction outcome loss': 0.2635086171786277, 'Total loss': 0.2635086171786277}
2023-01-05 09:13:27,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:13:27,675 INFO:     Epoch: 75
2023-01-05 09:13:29,819 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4413013776143392, 'Total loss': 0.4413013776143392} | train loss {'Reaction outcome loss': 0.2650707302823501, 'Total loss': 0.2650707302823501}
2023-01-05 09:13:29,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:13:29,819 INFO:     Epoch: 76
2023-01-05 09:13:31,945 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4267246246337891, 'Total loss': 0.4267246246337891} | train loss {'Reaction outcome loss': 0.25976370504993396, 'Total loss': 0.25976370504993396}
2023-01-05 09:13:31,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:13:31,945 INFO:     Epoch: 77
2023-01-05 09:13:34,102 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3995388607184092, 'Total loss': 0.3995388607184092} | train loss {'Reaction outcome loss': 0.2615745841770934, 'Total loss': 0.2615745841770934}
2023-01-05 09:13:34,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:13:34,103 INFO:     Epoch: 78
2023-01-05 09:13:36,232 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.41648289461930593, 'Total loss': 0.41648289461930593} | train loss {'Reaction outcome loss': 0.2549898398750956, 'Total loss': 0.2549898398750956}
2023-01-05 09:13:36,233 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:13:36,233 INFO:     Epoch: 79
2023-01-05 09:13:38,379 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.40391697486241657, 'Total loss': 0.40391697486241657} | train loss {'Reaction outcome loss': 0.25461527017291485, 'Total loss': 0.25461527017291485}
2023-01-05 09:13:38,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:13:38,379 INFO:     Epoch: 80
2023-01-05 09:13:40,516 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4116923580567042, 'Total loss': 0.4116923580567042} | train loss {'Reaction outcome loss': 0.2539088961799437, 'Total loss': 0.2539088961799437}
2023-01-05 09:13:40,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:13:40,516 INFO:     Epoch: 81
2023-01-05 09:13:42,652 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.41664173603057864, 'Total loss': 0.41664173603057864} | train loss {'Reaction outcome loss': 0.26550651755896715, 'Total loss': 0.26550651755896715}
2023-01-05 09:13:42,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:13:42,652 INFO:     Epoch: 82
2023-01-05 09:13:44,786 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4210633983214696, 'Total loss': 0.4210633983214696} | train loss {'Reaction outcome loss': 0.25931033091317013, 'Total loss': 0.25931033091317013}
2023-01-05 09:13:44,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:13:44,786 INFO:     Epoch: 83
2023-01-05 09:13:46,906 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.37137909829616544, 'Total loss': 0.37137909829616544} | train loss {'Reaction outcome loss': 0.25218895313730094, 'Total loss': 0.25218895313730094}
2023-01-05 09:13:46,907 INFO:     Found new best model at epoch 83
2023-01-05 09:13:46,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:13:46,908 INFO:     Epoch: 84
2023-01-05 09:13:49,040 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4096310466527939, 'Total loss': 0.4096310466527939} | train loss {'Reaction outcome loss': 0.25397480709565673, 'Total loss': 0.25397480709565673}
2023-01-05 09:13:49,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:13:49,041 INFO:     Epoch: 85
2023-01-05 09:13:51,181 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.450042716662089, 'Total loss': 0.450042716662089} | train loss {'Reaction outcome loss': 0.24571640782784468, 'Total loss': 0.24571640782784468}
2023-01-05 09:13:51,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:13:51,182 INFO:     Epoch: 86
2023-01-05 09:13:53,330 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.37426048641403514, 'Total loss': 0.37426048641403514} | train loss {'Reaction outcome loss': 0.2529334998134833, 'Total loss': 0.2529334998134833}
2023-01-05 09:13:53,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:13:53,331 INFO:     Epoch: 87
2023-01-05 09:13:55,482 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.42715030213197075, 'Total loss': 0.42715030213197075} | train loss {'Reaction outcome loss': 0.24251263284726263, 'Total loss': 0.24251263284726263}
2023-01-05 09:13:55,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:13:55,482 INFO:     Epoch: 88
2023-01-05 09:13:57,622 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3720856239398321, 'Total loss': 0.3720856239398321} | train loss {'Reaction outcome loss': 0.24557702697221767, 'Total loss': 0.24557702697221767}
2023-01-05 09:13:57,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:13:57,622 INFO:     Epoch: 89
2023-01-05 09:13:59,742 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.40228976209958395, 'Total loss': 0.40228976209958395} | train loss {'Reaction outcome loss': 0.24376606545831322, 'Total loss': 0.24376606545831322}
2023-01-05 09:13:59,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:13:59,742 INFO:     Epoch: 90
2023-01-05 09:14:01,887 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.40620498259862264, 'Total loss': 0.40620498259862264} | train loss {'Reaction outcome loss': 0.24461885247150914, 'Total loss': 0.24461885247150914}
2023-01-05 09:14:01,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:14:01,888 INFO:     Epoch: 91
2023-01-05 09:14:03,836 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.39362866183122, 'Total loss': 0.39362866183122} | train loss {'Reaction outcome loss': 0.24807491004198037, 'Total loss': 0.24807491004198037}
2023-01-05 09:14:03,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:14:03,836 INFO:     Epoch: 92
2023-01-05 09:14:05,965 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4383218268553416, 'Total loss': 0.4383218268553416} | train loss {'Reaction outcome loss': 0.2446652547009155, 'Total loss': 0.2446652547009155}
2023-01-05 09:14:05,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:14:05,965 INFO:     Epoch: 93
2023-01-05 09:14:08,113 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4303742339213689, 'Total loss': 0.4303742339213689} | train loss {'Reaction outcome loss': 0.24456626277699367, 'Total loss': 0.24456626277699367}
2023-01-05 09:14:08,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:14:08,113 INFO:     Epoch: 94
2023-01-05 09:14:10,247 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40281403362751006, 'Total loss': 0.40281403362751006} | train loss {'Reaction outcome loss': 0.24069350293504632, 'Total loss': 0.24069350293504632}
2023-01-05 09:14:10,247 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:14:10,247 INFO:     Epoch: 95
2023-01-05 09:14:12,377 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4297559012969335, 'Total loss': 0.4297559012969335} | train loss {'Reaction outcome loss': 0.23524519393644178, 'Total loss': 0.23524519393644178}
2023-01-05 09:14:12,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:14:12,378 INFO:     Epoch: 96
2023-01-05 09:14:14,517 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4201010877887408, 'Total loss': 0.4201010877887408} | train loss {'Reaction outcome loss': 0.23661356018553573, 'Total loss': 0.23661356018553573}
2023-01-05 09:14:14,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:14:14,517 INFO:     Epoch: 97
2023-01-05 09:14:16,669 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4107996056477229, 'Total loss': 0.4107996056477229} | train loss {'Reaction outcome loss': 0.2471203405598333, 'Total loss': 0.2471203405598333}
2023-01-05 09:14:16,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:14:16,670 INFO:     Epoch: 98
2023-01-05 09:14:18,824 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41558666080236434, 'Total loss': 0.41558666080236434} | train loss {'Reaction outcome loss': 0.2396195128439028, 'Total loss': 0.2396195128439028}
2023-01-05 09:14:18,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:14:18,824 INFO:     Epoch: 99
2023-01-05 09:14:20,961 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41781105399131774, 'Total loss': 0.41781105399131774} | train loss {'Reaction outcome loss': 0.23898287241209284, 'Total loss': 0.23898287241209284}
2023-01-05 09:14:20,961 INFO:     Best model found after epoch 84 of 100.
2023-01-05 09:14:20,961 INFO:   Done with stage: TRAINING
2023-01-05 09:14:20,961 INFO:   Starting stage: EVALUATION
2023-01-05 09:14:21,087 INFO:   Done with stage: EVALUATION
2023-01-05 09:14:21,087 INFO:   Leaving out SEQ value Fold_6
2023-01-05 09:14:21,100 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 09:14:21,100 INFO:   Starting stage: FEATURE SCALING
2023-01-05 09:14:21,749 INFO:   Done with stage: FEATURE SCALING
2023-01-05 09:14:21,749 INFO:   Starting stage: SCALING TARGETS
2023-01-05 09:14:21,818 INFO:   Done with stage: SCALING TARGETS
2023-01-05 09:14:21,819 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:14:21,819 INFO:     No hyperparam tuning for this model
2023-01-05 09:14:21,819 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:14:21,820 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 09:14:21,820 INFO:     None feature selector for col prot
2023-01-05 09:14:21,820 INFO:     None feature selector for col prot
2023-01-05 09:14:21,820 INFO:     None feature selector for col prot
2023-01-05 09:14:21,821 INFO:     None feature selector for col chem
2023-01-05 09:14:21,821 INFO:     None feature selector for col chem
2023-01-05 09:14:21,821 INFO:     None feature selector for col chem
2023-01-05 09:14:21,821 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 09:14:21,821 INFO:   Starting stage: BUILD MODEL
2023-01-05 09:14:21,824 INFO:     Number of params in model 72901
2023-01-05 09:14:21,826 INFO:   Done with stage: BUILD MODEL
2023-01-05 09:14:21,826 INFO:   Starting stage: TRAINING
2023-01-05 09:14:21,884 INFO:     Val loss before train {'Reaction outcome loss': 0.9919947584470113, 'Total loss': 0.9919947584470113}
2023-01-05 09:14:21,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:14:21,884 INFO:     Epoch: 0
2023-01-05 09:14:24,027 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7934792975584666, 'Total loss': 0.7934792975584666} | train loss {'Reaction outcome loss': 0.9222109566672124, 'Total loss': 0.9222109566672124}
2023-01-05 09:14:24,027 INFO:     Found new best model at epoch 0
2023-01-05 09:14:24,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:14:24,028 INFO:     Epoch: 1
2023-01-05 09:14:26,162 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.573904440800349, 'Total loss': 0.573904440800349} | train loss {'Reaction outcome loss': 0.7265766875006839, 'Total loss': 0.7265766875006839}
2023-01-05 09:14:26,162 INFO:     Found new best model at epoch 1
2023-01-05 09:14:26,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:14:26,163 INFO:     Epoch: 2
2023-01-05 09:14:28,296 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5157079736391703, 'Total loss': 0.5157079736391703} | train loss {'Reaction outcome loss': 0.5752917925651738, 'Total loss': 0.5752917925651738}
2023-01-05 09:14:28,296 INFO:     Found new best model at epoch 2
2023-01-05 09:14:28,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:14:28,298 INFO:     Epoch: 3
2023-01-05 09:14:30,440 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4990630507469177, 'Total loss': 0.4990630507469177} | train loss {'Reaction outcome loss': 0.5285940416700518, 'Total loss': 0.5285940416700518}
2023-01-05 09:14:30,440 INFO:     Found new best model at epoch 3
2023-01-05 09:14:30,441 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:14:30,441 INFO:     Epoch: 4
2023-01-05 09:14:32,626 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.507155571381251, 'Total loss': 0.507155571381251} | train loss {'Reaction outcome loss': 0.5045688523796211, 'Total loss': 0.5045688523796211}
2023-01-05 09:14:32,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:14:32,626 INFO:     Epoch: 5
2023-01-05 09:14:34,771 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4896026770273844, 'Total loss': 0.4896026770273844} | train loss {'Reaction outcome loss': 0.48942298047409893, 'Total loss': 0.48942298047409893}
2023-01-05 09:14:34,771 INFO:     Found new best model at epoch 5
2023-01-05 09:14:34,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:14:34,773 INFO:     Epoch: 6
2023-01-05 09:14:36,916 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4834664483865102, 'Total loss': 0.4834664483865102} | train loss {'Reaction outcome loss': 0.4812957343334953, 'Total loss': 0.4812957343334953}
2023-01-05 09:14:36,917 INFO:     Found new best model at epoch 6
2023-01-05 09:14:36,918 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:14:36,918 INFO:     Epoch: 7
2023-01-05 09:14:39,024 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.48824174602826437, 'Total loss': 0.48824174602826437} | train loss {'Reaction outcome loss': 0.4749024515107706, 'Total loss': 0.4749024515107706}
2023-01-05 09:14:39,025 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:14:39,025 INFO:     Epoch: 8
2023-01-05 09:14:41,211 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5071395248174667, 'Total loss': 0.5071395248174667} | train loss {'Reaction outcome loss': 0.4747589190585026, 'Total loss': 0.4747589190585026}
2023-01-05 09:14:41,212 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:14:41,212 INFO:     Epoch: 9
2023-01-05 09:14:43,330 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.523441876967748, 'Total loss': 0.523441876967748} | train loss {'Reaction outcome loss': 0.4841762918614499, 'Total loss': 0.4841762918614499}
2023-01-05 09:14:43,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:14:43,330 INFO:     Epoch: 10
2023-01-05 09:14:45,476 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5027954598267873, 'Total loss': 0.5027954598267873} | train loss {'Reaction outcome loss': 0.4656847393807107, 'Total loss': 0.4656847393807107}
2023-01-05 09:14:45,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:14:45,477 INFO:     Epoch: 11
2023-01-05 09:14:47,589 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49203356305758156, 'Total loss': 0.49203356305758156} | train loss {'Reaction outcome loss': 0.454771360571349, 'Total loss': 0.454771360571349}
2023-01-05 09:14:47,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:14:47,589 INFO:     Epoch: 12
2023-01-05 09:14:49,728 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4765436281760534, 'Total loss': 0.4765436281760534} | train loss {'Reaction outcome loss': 0.45851989597777254, 'Total loss': 0.45851989597777254}
2023-01-05 09:14:49,728 INFO:     Found new best model at epoch 12
2023-01-05 09:14:49,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:14:49,729 INFO:     Epoch: 13
2023-01-05 09:14:51,841 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.48347729742527007, 'Total loss': 0.48347729742527007} | train loss {'Reaction outcome loss': 0.4404823517382982, 'Total loss': 0.4404823517382982}
2023-01-05 09:14:51,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:14:51,841 INFO:     Epoch: 14
2023-01-05 09:14:53,963 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4627087195714315, 'Total loss': 0.4627087195714315} | train loss {'Reaction outcome loss': 0.43911769238395104, 'Total loss': 0.43911769238395104}
2023-01-05 09:14:53,964 INFO:     Found new best model at epoch 14
2023-01-05 09:14:53,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:14:53,966 INFO:     Epoch: 15
2023-01-05 09:14:56,108 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4603056122859319, 'Total loss': 0.4603056122859319} | train loss {'Reaction outcome loss': 0.4348826741496475, 'Total loss': 0.4348826741496475}
2023-01-05 09:14:56,108 INFO:     Found new best model at epoch 15
2023-01-05 09:14:56,110 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:14:56,110 INFO:     Epoch: 16
2023-01-05 09:14:58,308 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48684931397438047, 'Total loss': 0.48684931397438047} | train loss {'Reaction outcome loss': 0.4276303465205319, 'Total loss': 0.4276303465205319}
2023-01-05 09:14:58,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:14:58,309 INFO:     Epoch: 17
2023-01-05 09:15:00,548 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4745944341023763, 'Total loss': 0.4745944341023763} | train loss {'Reaction outcome loss': 0.42773047658493335, 'Total loss': 0.42773047658493335}
2023-01-05 09:15:00,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:15:00,549 INFO:     Epoch: 18
2023-01-05 09:15:02,721 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4659479742248853, 'Total loss': 0.4659479742248853} | train loss {'Reaction outcome loss': 0.4199351978798707, 'Total loss': 0.4199351978798707}
2023-01-05 09:15:02,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:15:02,721 INFO:     Epoch: 19
2023-01-05 09:15:04,903 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.473591352502505, 'Total loss': 0.473591352502505} | train loss {'Reaction outcome loss': 0.41350404303196137, 'Total loss': 0.41350404303196137}
2023-01-05 09:15:04,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:15:04,903 INFO:     Epoch: 20
2023-01-05 09:15:07,058 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5131728659073512, 'Total loss': 0.5131728659073512} | train loss {'Reaction outcome loss': 0.4185963281146858, 'Total loss': 0.4185963281146858}
2023-01-05 09:15:07,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:15:07,058 INFO:     Epoch: 21
2023-01-05 09:15:09,229 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.44819696942965187, 'Total loss': 0.44819696942965187} | train loss {'Reaction outcome loss': 0.41980105835819564, 'Total loss': 0.41980105835819564}
2023-01-05 09:15:09,229 INFO:     Found new best model at epoch 21
2023-01-05 09:15:09,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:15:09,230 INFO:     Epoch: 22
2023-01-05 09:15:11,367 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47192638317743935, 'Total loss': 0.47192638317743935} | train loss {'Reaction outcome loss': 0.42007759791137517, 'Total loss': 0.42007759791137517}
2023-01-05 09:15:11,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:15:11,367 INFO:     Epoch: 23
2023-01-05 09:15:13,520 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4617206444342931, 'Total loss': 0.4617206444342931} | train loss {'Reaction outcome loss': 0.4101327329442121, 'Total loss': 0.4101327329442121}
2023-01-05 09:15:13,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:15:13,520 INFO:     Epoch: 24
2023-01-05 09:15:15,657 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4844156004488468, 'Total loss': 0.4844156004488468} | train loss {'Reaction outcome loss': 0.39885281050658744, 'Total loss': 0.39885281050658744}
2023-01-05 09:15:15,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:15:15,658 INFO:     Epoch: 25
2023-01-05 09:15:17,774 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4577846944332123, 'Total loss': 0.4577846944332123} | train loss {'Reaction outcome loss': 0.41606929601318593, 'Total loss': 0.41606929601318593}
2023-01-05 09:15:17,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:15:17,774 INFO:     Epoch: 26
2023-01-05 09:15:19,877 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4873941053946813, 'Total loss': 0.4873941053946813} | train loss {'Reaction outcome loss': 0.3929043349985411, 'Total loss': 0.3929043349985411}
2023-01-05 09:15:19,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:15:19,878 INFO:     Epoch: 27
2023-01-05 09:15:21,976 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.43398512303829195, 'Total loss': 0.43398512303829195} | train loss {'Reaction outcome loss': 0.3840332494161186, 'Total loss': 0.3840332494161186}
2023-01-05 09:15:21,976 INFO:     Found new best model at epoch 27
2023-01-05 09:15:21,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:15:21,977 INFO:     Epoch: 28
2023-01-05 09:15:24,098 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4489010532697042, 'Total loss': 0.4489010532697042} | train loss {'Reaction outcome loss': 0.3886378754362248, 'Total loss': 0.3886378754362248}
2023-01-05 09:15:24,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:15:24,099 INFO:     Epoch: 29
2023-01-05 09:15:26,236 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.45388264457384747, 'Total loss': 0.45388264457384747} | train loss {'Reaction outcome loss': 0.4015419666496767, 'Total loss': 0.4015419666496767}
2023-01-05 09:15:26,236 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:15:26,236 INFO:     Epoch: 30
2023-01-05 09:15:28,363 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4670112808545431, 'Total loss': 0.4670112808545431} | train loss {'Reaction outcome loss': 0.3820301702007255, 'Total loss': 0.3820301702007255}
2023-01-05 09:15:28,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:15:28,363 INFO:     Epoch: 31
2023-01-05 09:15:30,475 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4482276062170664, 'Total loss': 0.4482276062170664} | train loss {'Reaction outcome loss': 0.3777219262783942, 'Total loss': 0.3777219262783942}
2023-01-05 09:15:30,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:15:30,476 INFO:     Epoch: 32
2023-01-05 09:15:32,577 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4728976527849833, 'Total loss': 0.4728976527849833} | train loss {'Reaction outcome loss': 0.372944077598336, 'Total loss': 0.372944077598336}
2023-01-05 09:15:32,577 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:15:32,577 INFO:     Epoch: 33
2023-01-05 09:15:34,695 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.483011402686437, 'Total loss': 0.483011402686437} | train loss {'Reaction outcome loss': 0.37338606415289466, 'Total loss': 0.37338606415289466}
2023-01-05 09:15:34,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:15:34,695 INFO:     Epoch: 34
2023-01-05 09:15:36,826 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4795112073421478, 'Total loss': 0.4795112073421478} | train loss {'Reaction outcome loss': 0.36472740877028287, 'Total loss': 0.36472740877028287}
2023-01-05 09:15:36,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:15:36,827 INFO:     Epoch: 35
2023-01-05 09:15:38,954 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.44367241064707436, 'Total loss': 0.44367241064707436} | train loss {'Reaction outcome loss': 0.3615972246228974, 'Total loss': 0.3615972246228974}
2023-01-05 09:15:38,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:15:38,954 INFO:     Epoch: 36
2023-01-05 09:15:41,074 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.44735031525293983, 'Total loss': 0.44735031525293983} | train loss {'Reaction outcome loss': 0.35534474498622265, 'Total loss': 0.35534474498622265}
2023-01-05 09:15:41,074 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:15:41,074 INFO:     Epoch: 37
2023-01-05 09:15:43,225 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4326075216134389, 'Total loss': 0.4326075216134389} | train loss {'Reaction outcome loss': 0.3577676952371131, 'Total loss': 0.3577676952371131}
2023-01-05 09:15:43,225 INFO:     Found new best model at epoch 37
2023-01-05 09:15:43,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:15:43,227 INFO:     Epoch: 38
2023-01-05 09:15:45,323 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4277549256881078, 'Total loss': 0.4277549256881078} | train loss {'Reaction outcome loss': 0.35141293671272317, 'Total loss': 0.35141293671272317}
2023-01-05 09:15:45,323 INFO:     Found new best model at epoch 38
2023-01-05 09:15:45,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:15:45,324 INFO:     Epoch: 39
2023-01-05 09:15:47,496 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.43406995733579, 'Total loss': 0.43406995733579} | train loss {'Reaction outcome loss': 0.3421751923379961, 'Total loss': 0.3421751923379961}
2023-01-05 09:15:47,496 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:15:47,496 INFO:     Epoch: 40
2023-01-05 09:15:49,668 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44150144358476, 'Total loss': 0.44150144358476} | train loss {'Reaction outcome loss': 0.34353311731146, 'Total loss': 0.34353311731146}
2023-01-05 09:15:49,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:15:49,669 INFO:     Epoch: 41
2023-01-05 09:15:51,849 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45426102379957833, 'Total loss': 0.45426102379957833} | train loss {'Reaction outcome loss': 0.3367865835734056, 'Total loss': 0.3367865835734056}
2023-01-05 09:15:51,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:15:51,849 INFO:     Epoch: 42
2023-01-05 09:15:53,999 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4710104485352834, 'Total loss': 0.4710104485352834} | train loss {'Reaction outcome loss': 0.33307230734752247, 'Total loss': 0.33307230734752247}
2023-01-05 09:15:53,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:15:53,999 INFO:     Epoch: 43
2023-01-05 09:15:56,134 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.43648257156213127, 'Total loss': 0.43648257156213127} | train loss {'Reaction outcome loss': 0.33799504520994966, 'Total loss': 0.33799504520994966}
2023-01-05 09:15:56,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:15:56,134 INFO:     Epoch: 44
2023-01-05 09:15:58,229 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.46355883876482645, 'Total loss': 0.46355883876482645} | train loss {'Reaction outcome loss': 0.33402384586456785, 'Total loss': 0.33402384586456785}
2023-01-05 09:15:58,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:15:58,229 INFO:     Epoch: 45
2023-01-05 09:16:00,348 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40990205903848015, 'Total loss': 0.40990205903848015} | train loss {'Reaction outcome loss': 0.3283250858852019, 'Total loss': 0.3283250858852019}
2023-01-05 09:16:00,349 INFO:     Found new best model at epoch 45
2023-01-05 09:16:00,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:16:00,351 INFO:     Epoch: 46
2023-01-05 09:16:02,492 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4448370705048243, 'Total loss': 0.4448370705048243} | train loss {'Reaction outcome loss': 0.32461254240951204, 'Total loss': 0.32461254240951204}
2023-01-05 09:16:02,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:16:02,493 INFO:     Epoch: 47
2023-01-05 09:16:04,651 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3945531944433848, 'Total loss': 0.3945531944433848} | train loss {'Reaction outcome loss': 0.33133961702359543, 'Total loss': 0.33133961702359543}
2023-01-05 09:16:04,651 INFO:     Found new best model at epoch 47
2023-01-05 09:16:04,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:16:04,652 INFO:     Epoch: 48
2023-01-05 09:16:06,784 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41550473868846893, 'Total loss': 0.41550473868846893} | train loss {'Reaction outcome loss': 0.3569821430314535, 'Total loss': 0.3569821430314535}
2023-01-05 09:16:06,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:16:06,785 INFO:     Epoch: 49
2023-01-05 09:16:08,924 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4135452300310135, 'Total loss': 0.4135452300310135} | train loss {'Reaction outcome loss': 0.3295056663944548, 'Total loss': 0.3295056663944548}
2023-01-05 09:16:08,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:16:08,924 INFO:     Epoch: 50
2023-01-05 09:16:11,056 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4062935287753741, 'Total loss': 0.4062935287753741} | train loss {'Reaction outcome loss': 0.3257462207035607, 'Total loss': 0.3257462207035607}
2023-01-05 09:16:11,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:16:11,056 INFO:     Epoch: 51
2023-01-05 09:16:13,193 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.40131317724784216, 'Total loss': 0.40131317724784216} | train loss {'Reaction outcome loss': 0.327714144775266, 'Total loss': 0.327714144775266}
2023-01-05 09:16:13,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:16:13,193 INFO:     Epoch: 52
2023-01-05 09:16:15,353 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4044099976619085, 'Total loss': 0.4044099976619085} | train loss {'Reaction outcome loss': 0.31761118307211134, 'Total loss': 0.31761118307211134}
2023-01-05 09:16:15,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:16:15,353 INFO:     Epoch: 53
2023-01-05 09:16:17,458 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4183501392602921, 'Total loss': 0.4183501392602921} | train loss {'Reaction outcome loss': 0.3094343613846686, 'Total loss': 0.3094343613846686}
2023-01-05 09:16:17,458 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:16:17,459 INFO:     Epoch: 54
2023-01-05 09:16:19,620 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.44862543443838754, 'Total loss': 0.44862543443838754} | train loss {'Reaction outcome loss': 0.31601711744577554, 'Total loss': 0.31601711744577554}
2023-01-05 09:16:19,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:16:19,621 INFO:     Epoch: 55
2023-01-05 09:16:21,765 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4252520124117533, 'Total loss': 0.4252520124117533} | train loss {'Reaction outcome loss': 0.3308759833318249, 'Total loss': 0.3308759833318249}
2023-01-05 09:16:21,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:16:21,765 INFO:     Epoch: 56
2023-01-05 09:16:23,916 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4277977168560028, 'Total loss': 0.4277977168560028} | train loss {'Reaction outcome loss': 0.31003708181785533, 'Total loss': 0.31003708181785533}
2023-01-05 09:16:23,916 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:16:23,916 INFO:     Epoch: 57
2023-01-05 09:16:26,072 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.40263380159934364, 'Total loss': 0.40263380159934364} | train loss {'Reaction outcome loss': 0.3105551226982388, 'Total loss': 0.3105551226982388}
2023-01-05 09:16:26,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:16:26,072 INFO:     Epoch: 58
2023-01-05 09:16:28,209 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4115822046995163, 'Total loss': 0.4115822046995163} | train loss {'Reaction outcome loss': 0.37478531162191114, 'Total loss': 0.37478531162191114}
2023-01-05 09:16:28,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:16:28,209 INFO:     Epoch: 59
2023-01-05 09:16:30,359 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4057433858513832, 'Total loss': 0.4057433858513832} | train loss {'Reaction outcome loss': 0.3067578654466332, 'Total loss': 0.3067578654466332}
2023-01-05 09:16:30,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:16:30,361 INFO:     Epoch: 60
2023-01-05 09:16:32,518 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4198473374048869, 'Total loss': 0.4198473374048869} | train loss {'Reaction outcome loss': 0.30208596100538154, 'Total loss': 0.30208596100538154}
2023-01-05 09:16:32,518 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:16:32,518 INFO:     Epoch: 61
2023-01-05 09:16:34,648 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38105372389157616, 'Total loss': 0.38105372389157616} | train loss {'Reaction outcome loss': 0.29825348994531387, 'Total loss': 0.29825348994531387}
2023-01-05 09:16:34,648 INFO:     Found new best model at epoch 61
2023-01-05 09:16:34,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:16:34,649 INFO:     Epoch: 62
2023-01-05 09:16:36,761 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4435473958651225, 'Total loss': 0.4435473958651225} | train loss {'Reaction outcome loss': 0.2976841403810861, 'Total loss': 0.2976841403810861}
2023-01-05 09:16:36,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:16:36,762 INFO:     Epoch: 63
2023-01-05 09:16:38,900 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.40930358866850536, 'Total loss': 0.40930358866850536} | train loss {'Reaction outcome loss': 0.29311725969993224, 'Total loss': 0.29311725969993224}
2023-01-05 09:16:38,900 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:16:38,901 INFO:     Epoch: 64
2023-01-05 09:16:41,068 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42203098932902017, 'Total loss': 0.42203098932902017} | train loss {'Reaction outcome loss': 0.28776002772539633, 'Total loss': 0.28776002772539633}
2023-01-05 09:16:41,068 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:16:41,068 INFO:     Epoch: 65
2023-01-05 09:16:43,220 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.38748230735460915, 'Total loss': 0.38748230735460915} | train loss {'Reaction outcome loss': 0.2961445431718712, 'Total loss': 0.2961445431718712}
2023-01-05 09:16:43,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:16:43,220 INFO:     Epoch: 66
2023-01-05 09:16:45,346 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.40740355253219607, 'Total loss': 0.40740355253219607} | train loss {'Reaction outcome loss': 0.29234772196471476, 'Total loss': 0.29234772196471476}
2023-01-05 09:16:45,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:16:45,346 INFO:     Epoch: 67
2023-01-05 09:16:47,466 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4111419230699539, 'Total loss': 0.4111419230699539} | train loss {'Reaction outcome loss': 0.2807005448423455, 'Total loss': 0.2807005448423455}
2023-01-05 09:16:47,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:16:47,466 INFO:     Epoch: 68
2023-01-05 09:16:49,610 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.42533310850461326, 'Total loss': 0.42533310850461326} | train loss {'Reaction outcome loss': 0.280746658088005, 'Total loss': 0.280746658088005}
2023-01-05 09:16:49,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:16:49,611 INFO:     Epoch: 69
2023-01-05 09:16:51,733 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.40084783534208934, 'Total loss': 0.40084783534208934} | train loss {'Reaction outcome loss': 0.2837875533875996, 'Total loss': 0.2837875533875996}
2023-01-05 09:16:51,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:16:51,734 INFO:     Epoch: 70
2023-01-05 09:16:53,858 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.44130791425704957, 'Total loss': 0.44130791425704957} | train loss {'Reaction outcome loss': 0.2826177938638822, 'Total loss': 0.2826177938638822}
2023-01-05 09:16:53,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:16:53,858 INFO:     Epoch: 71
2023-01-05 09:16:55,974 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.436996861298879, 'Total loss': 0.436996861298879} | train loss {'Reaction outcome loss': 0.35314870890199573, 'Total loss': 0.35314870890199573}
2023-01-05 09:16:55,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:16:55,975 INFO:     Epoch: 72
2023-01-05 09:16:58,104 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4107829570770264, 'Total loss': 0.4107829570770264} | train loss {'Reaction outcome loss': 0.29389359798991843, 'Total loss': 0.29389359798991843}
2023-01-05 09:16:58,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:16:58,104 INFO:     Epoch: 73
2023-01-05 09:17:00,238 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4419877529144287, 'Total loss': 0.4419877529144287} | train loss {'Reaction outcome loss': 0.294799975288249, 'Total loss': 0.294799975288249}
2023-01-05 09:17:00,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:17:00,238 INFO:     Epoch: 74
2023-01-05 09:17:02,344 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4286259373029073, 'Total loss': 0.4286259373029073} | train loss {'Reaction outcome loss': 0.31758189499142, 'Total loss': 0.31758189499142}
2023-01-05 09:17:02,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:17:02,344 INFO:     Epoch: 75
2023-01-05 09:17:04,453 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.41359935303529105, 'Total loss': 0.41359935303529105} | train loss {'Reaction outcome loss': 0.2768252757968435, 'Total loss': 0.2768252757968435}
2023-01-05 09:17:04,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:17:04,453 INFO:     Epoch: 76
2023-01-05 09:17:06,596 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.42670998672644295, 'Total loss': 0.42670998672644295} | train loss {'Reaction outcome loss': 0.2801774285748041, 'Total loss': 0.2801774285748041}
2023-01-05 09:17:06,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:17:06,597 INFO:     Epoch: 77
2023-01-05 09:17:08,740 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.39080093304316205, 'Total loss': 0.39080093304316205} | train loss {'Reaction outcome loss': 0.2789831613324326, 'Total loss': 0.2789831613324326}
2023-01-05 09:17:08,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:17:08,741 INFO:     Epoch: 78
2023-01-05 09:17:10,925 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4177611738443375, 'Total loss': 0.4177611738443375} | train loss {'Reaction outcome loss': 0.2747043747211506, 'Total loss': 0.2747043747211506}
2023-01-05 09:17:10,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:17:10,925 INFO:     Epoch: 79
2023-01-05 09:17:13,081 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4033704996109009, 'Total loss': 0.4033704996109009} | train loss {'Reaction outcome loss': 0.280836699584472, 'Total loss': 0.280836699584472}
2023-01-05 09:17:13,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:17:13,082 INFO:     Epoch: 80
2023-01-05 09:17:15,201 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3950705319643021, 'Total loss': 0.3950705319643021} | train loss {'Reaction outcome loss': 0.336350839558071, 'Total loss': 0.336350839558071}
2023-01-05 09:17:15,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:17:15,201 INFO:     Epoch: 81
2023-01-05 09:17:17,360 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40535588959852853, 'Total loss': 0.40535588959852853} | train loss {'Reaction outcome loss': 0.3558916408362785, 'Total loss': 0.3558916408362785}
2023-01-05 09:17:17,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:17:17,360 INFO:     Epoch: 82
2023-01-05 09:17:19,461 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3859176824490229, 'Total loss': 0.3859176824490229} | train loss {'Reaction outcome loss': 0.30062599550486385, 'Total loss': 0.30062599550486385}
2023-01-05 09:17:19,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:17:19,461 INFO:     Epoch: 83
2023-01-05 09:17:21,578 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3800439288218816, 'Total loss': 0.3800439288218816} | train loss {'Reaction outcome loss': 0.28456702100727166, 'Total loss': 0.28456702100727166}
2023-01-05 09:17:21,578 INFO:     Found new best model at epoch 83
2023-01-05 09:17:21,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:17:21,579 INFO:     Epoch: 84
2023-01-05 09:17:23,685 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3749404708544413, 'Total loss': 0.3749404708544413} | train loss {'Reaction outcome loss': 0.27475333570138266, 'Total loss': 0.27475333570138266}
2023-01-05 09:17:23,685 INFO:     Found new best model at epoch 84
2023-01-05 09:17:23,686 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:17:23,686 INFO:     Epoch: 85
2023-01-05 09:17:25,795 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4268489231665929, 'Total loss': 0.4268489231665929} | train loss {'Reaction outcome loss': 0.2771632040823823, 'Total loss': 0.2771632040823823}
2023-01-05 09:17:25,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:17:25,796 INFO:     Epoch: 86
2023-01-05 09:17:27,931 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.39930046995480856, 'Total loss': 0.39930046995480856} | train loss {'Reaction outcome loss': 0.2696556391369929, 'Total loss': 0.2696556391369929}
2023-01-05 09:17:27,931 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:17:27,931 INFO:     Epoch: 87
2023-01-05 09:17:30,072 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4296209116776784, 'Total loss': 0.4296209116776784} | train loss {'Reaction outcome loss': 0.2665097095112129, 'Total loss': 0.2665097095112129}
2023-01-05 09:17:30,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:17:30,073 INFO:     Epoch: 88
2023-01-05 09:17:32,229 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4747973424692949, 'Total loss': 0.4747973424692949} | train loss {'Reaction outcome loss': 0.28382548084819986, 'Total loss': 0.28382548084819986}
2023-01-05 09:17:32,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:17:32,229 INFO:     Epoch: 89
2023-01-05 09:17:34,374 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.41151176889737445, 'Total loss': 0.41151176889737445} | train loss {'Reaction outcome loss': 0.43341590703525784, 'Total loss': 0.43341590703525784}
2023-01-05 09:17:34,374 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:17:34,374 INFO:     Epoch: 90
2023-01-05 09:17:36,528 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4305573006470998, 'Total loss': 0.4305573006470998} | train loss {'Reaction outcome loss': 0.30706169140656764, 'Total loss': 0.30706169140656764}
2023-01-05 09:17:36,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:17:36,528 INFO:     Epoch: 91
2023-01-05 09:17:38,647 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3957184463739395, 'Total loss': 0.3957184463739395} | train loss {'Reaction outcome loss': 0.28501397978507687, 'Total loss': 0.28501397978507687}
2023-01-05 09:17:38,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:17:38,647 INFO:     Epoch: 92
2023-01-05 09:17:40,794 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3930995990832647, 'Total loss': 0.3930995990832647} | train loss {'Reaction outcome loss': 0.2810505636819247, 'Total loss': 0.2810505636819247}
2023-01-05 09:17:40,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:17:40,794 INFO:     Epoch: 93
2023-01-05 09:17:42,935 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.36287903090318047, 'Total loss': 0.36287903090318047} | train loss {'Reaction outcome loss': 0.285383224433315, 'Total loss': 0.285383224433315}
2023-01-05 09:17:42,936 INFO:     Found new best model at epoch 93
2023-01-05 09:17:42,937 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:17:42,937 INFO:     Epoch: 94
2023-01-05 09:17:45,076 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.40394096076488495, 'Total loss': 0.40394096076488495} | train loss {'Reaction outcome loss': 0.2875612436439859, 'Total loss': 0.2875612436439859}
2023-01-05 09:17:45,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:17:45,077 INFO:     Epoch: 95
2023-01-05 09:17:47,208 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.41664182345072426, 'Total loss': 0.41664182345072426} | train loss {'Reaction outcome loss': 0.269072343483108, 'Total loss': 0.269072343483108}
2023-01-05 09:17:47,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:17:47,208 INFO:     Epoch: 96
2023-01-05 09:17:49,352 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.40608504315217336, 'Total loss': 0.40608504315217336} | train loss {'Reaction outcome loss': 0.2614947935681034, 'Total loss': 0.2614947935681034}
2023-01-05 09:17:49,353 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:17:49,353 INFO:     Epoch: 97
2023-01-05 09:17:51,487 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4063093860944112, 'Total loss': 0.4063093860944112} | train loss {'Reaction outcome loss': 0.26527103722522344, 'Total loss': 0.26527103722522344}
2023-01-05 09:17:51,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:17:51,487 INFO:     Epoch: 98
2023-01-05 09:17:53,636 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4131277362505595, 'Total loss': 0.4131277362505595} | train loss {'Reaction outcome loss': 0.26008319255277496, 'Total loss': 0.26008319255277496}
2023-01-05 09:17:53,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:17:53,636 INFO:     Epoch: 99
2023-01-05 09:17:55,768 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4286869158347448, 'Total loss': 0.4286869158347448} | train loss {'Reaction outcome loss': 0.2540877085431956, 'Total loss': 0.2540877085431956}
2023-01-05 09:17:55,768 INFO:     Best model found after epoch 94 of 100.
2023-01-05 09:17:55,768 INFO:   Done with stage: TRAINING
2023-01-05 09:17:55,768 INFO:   Starting stage: EVALUATION
2023-01-05 09:17:55,901 INFO:   Done with stage: EVALUATION
2023-01-05 09:17:55,901 INFO:   Leaving out SEQ value Fold_7
2023-01-05 09:17:55,914 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 09:17:55,914 INFO:   Starting stage: FEATURE SCALING
2023-01-05 09:17:56,567 INFO:   Done with stage: FEATURE SCALING
2023-01-05 09:17:56,567 INFO:   Starting stage: SCALING TARGETS
2023-01-05 09:17:56,635 INFO:   Done with stage: SCALING TARGETS
2023-01-05 09:17:56,635 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:17:56,635 INFO:     No hyperparam tuning for this model
2023-01-05 09:17:56,635 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:17:56,635 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 09:17:56,636 INFO:     None feature selector for col prot
2023-01-05 09:17:56,636 INFO:     None feature selector for col prot
2023-01-05 09:17:56,636 INFO:     None feature selector for col prot
2023-01-05 09:17:56,637 INFO:     None feature selector for col chem
2023-01-05 09:17:56,637 INFO:     None feature selector for col chem
2023-01-05 09:17:56,637 INFO:     None feature selector for col chem
2023-01-05 09:17:56,637 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 09:17:56,637 INFO:   Starting stage: BUILD MODEL
2023-01-05 09:17:56,638 INFO:     Number of params in model 72901
2023-01-05 09:17:56,642 INFO:   Done with stage: BUILD MODEL
2023-01-05 09:17:56,642 INFO:   Starting stage: TRAINING
2023-01-05 09:17:56,701 INFO:     Val loss before train {'Reaction outcome loss': 1.0411970138549804, 'Total loss': 1.0411970138549804}
2023-01-05 09:17:56,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:17:56,702 INFO:     Epoch: 0
2023-01-05 09:17:58,839 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8491108616193136, 'Total loss': 0.8491108616193136} | train loss {'Reaction outcome loss': 0.9285774593767913, 'Total loss': 0.9285774593767913}
2023-01-05 09:17:58,840 INFO:     Found new best model at epoch 0
2023-01-05 09:17:58,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:17:58,841 INFO:     Epoch: 1
2023-01-05 09:18:00,976 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6443349291880925, 'Total loss': 0.6443349291880925} | train loss {'Reaction outcome loss': 0.6999253039990646, 'Total loss': 0.6999253039990646}
2023-01-05 09:18:00,976 INFO:     Found new best model at epoch 1
2023-01-05 09:18:00,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:18:00,977 INFO:     Epoch: 2
2023-01-05 09:18:03,047 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5767092943191529, 'Total loss': 0.5767092943191529} | train loss {'Reaction outcome loss': 0.5603998176807511, 'Total loss': 0.5603998176807511}
2023-01-05 09:18:03,047 INFO:     Found new best model at epoch 2
2023-01-05 09:18:03,049 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:18:03,049 INFO:     Epoch: 3
2023-01-05 09:18:04,986 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5627477447191874, 'Total loss': 0.5627477447191874} | train loss {'Reaction outcome loss': 0.5193020750134103, 'Total loss': 0.5193020750134103}
2023-01-05 09:18:04,987 INFO:     Found new best model at epoch 3
2023-01-05 09:18:04,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:18:04,988 INFO:     Epoch: 4
2023-01-05 09:18:07,119 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5590436279773712, 'Total loss': 0.5590436279773712} | train loss {'Reaction outcome loss': 0.507746214667956, 'Total loss': 0.507746214667956}
2023-01-05 09:18:07,119 INFO:     Found new best model at epoch 4
2023-01-05 09:18:07,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:18:07,121 INFO:     Epoch: 5
2023-01-05 09:18:09,258 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5460045586029688, 'Total loss': 0.5460045586029688} | train loss {'Reaction outcome loss': 0.49691029199554276, 'Total loss': 0.49691029199554276}
2023-01-05 09:18:09,258 INFO:     Found new best model at epoch 5
2023-01-05 09:18:09,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:18:09,259 INFO:     Epoch: 6
2023-01-05 09:18:11,384 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5501306980848313, 'Total loss': 0.5501306980848313} | train loss {'Reaction outcome loss': 0.48513910251305153, 'Total loss': 0.48513910251305153}
2023-01-05 09:18:11,384 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:18:11,385 INFO:     Epoch: 7
2023-01-05 09:18:13,483 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5255435605843862, 'Total loss': 0.5255435605843862} | train loss {'Reaction outcome loss': 0.4798925332725048, 'Total loss': 0.4798925332725048}
2023-01-05 09:18:13,484 INFO:     Found new best model at epoch 7
2023-01-05 09:18:13,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:18:13,486 INFO:     Epoch: 8
2023-01-05 09:18:15,616 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5343372066815694, 'Total loss': 0.5343372066815694} | train loss {'Reaction outcome loss': 0.4934309945531203, 'Total loss': 0.4934309945531203}
2023-01-05 09:18:15,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:18:15,616 INFO:     Epoch: 9
2023-01-05 09:18:17,739 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5270354648431143, 'Total loss': 0.5270354648431143} | train loss {'Reaction outcome loss': 0.46742249585424916, 'Total loss': 0.46742249585424916}
2023-01-05 09:18:17,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:18:17,739 INFO:     Epoch: 10
2023-01-05 09:18:19,880 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5367188533147176, 'Total loss': 0.5367188533147176} | train loss {'Reaction outcome loss': 0.46153942951122706, 'Total loss': 0.46153942951122706}
2023-01-05 09:18:19,881 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:18:19,881 INFO:     Epoch: 11
2023-01-05 09:18:21,998 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5086698253949483, 'Total loss': 0.5086698253949483} | train loss {'Reaction outcome loss': 0.44967690417947975, 'Total loss': 0.44967690417947975}
2023-01-05 09:18:21,998 INFO:     Found new best model at epoch 11
2023-01-05 09:18:22,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:18:22,000 INFO:     Epoch: 12
2023-01-05 09:18:24,147 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5062801857789357, 'Total loss': 0.5062801857789357} | train loss {'Reaction outcome loss': 0.4465191826760273, 'Total loss': 0.4465191826760273}
2023-01-05 09:18:24,147 INFO:     Found new best model at epoch 12
2023-01-05 09:18:24,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:18:24,149 INFO:     Epoch: 13
2023-01-05 09:18:26,271 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5619312167167664, 'Total loss': 0.5619312167167664} | train loss {'Reaction outcome loss': 0.44723718199183815, 'Total loss': 0.44723718199183815}
2023-01-05 09:18:26,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:18:26,271 INFO:     Epoch: 14
2023-01-05 09:18:28,417 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5032670259475708, 'Total loss': 0.5032670259475708} | train loss {'Reaction outcome loss': 0.4401826616781561, 'Total loss': 0.4401826616781561}
2023-01-05 09:18:28,417 INFO:     Found new best model at epoch 14
2023-01-05 09:18:28,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:18:28,418 INFO:     Epoch: 15
2023-01-05 09:18:30,556 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5231405079364777, 'Total loss': 0.5231405079364777} | train loss {'Reaction outcome loss': 0.44212108189105126, 'Total loss': 0.44212108189105126}
2023-01-05 09:18:30,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:18:30,556 INFO:     Epoch: 16
2023-01-05 09:18:32,689 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4941060483455658, 'Total loss': 0.4941060483455658} | train loss {'Reaction outcome loss': 0.4591263760265302, 'Total loss': 0.4591263760265302}
2023-01-05 09:18:32,690 INFO:     Found new best model at epoch 16
2023-01-05 09:18:32,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:18:32,691 INFO:     Epoch: 17
2023-01-05 09:18:34,840 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.49307039578755696, 'Total loss': 0.49307039578755696} | train loss {'Reaction outcome loss': 0.4433526862412691, 'Total loss': 0.4433526862412691}
2023-01-05 09:18:34,840 INFO:     Found new best model at epoch 17
2023-01-05 09:18:34,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:18:34,841 INFO:     Epoch: 18
2023-01-05 09:18:36,984 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5047953406969706, 'Total loss': 0.5047953406969706} | train loss {'Reaction outcome loss': 0.4552519749040189, 'Total loss': 0.4552519749040189}
2023-01-05 09:18:36,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:18:36,984 INFO:     Epoch: 19
2023-01-05 09:18:39,119 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5168840249379476, 'Total loss': 0.5168840249379476} | train loss {'Reaction outcome loss': 0.41664643735144846, 'Total loss': 0.41664643735144846}
2023-01-05 09:18:39,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:18:39,119 INFO:     Epoch: 20
2023-01-05 09:18:41,253 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5264614085356395, 'Total loss': 0.5264614085356395} | train loss {'Reaction outcome loss': 0.41792240504013456, 'Total loss': 0.41792240504013456}
2023-01-05 09:18:41,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:18:41,253 INFO:     Epoch: 21
2023-01-05 09:18:43,390 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.478844819466273, 'Total loss': 0.478844819466273} | train loss {'Reaction outcome loss': 0.4150845607661683, 'Total loss': 0.4150845607661683}
2023-01-05 09:18:43,391 INFO:     Found new best model at epoch 21
2023-01-05 09:18:43,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:18:43,392 INFO:     Epoch: 22
2023-01-05 09:18:45,527 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47373170057932534, 'Total loss': 0.47373170057932534} | train loss {'Reaction outcome loss': 0.40136295258286037, 'Total loss': 0.40136295258286037}
2023-01-05 09:18:45,527 INFO:     Found new best model at epoch 22
2023-01-05 09:18:45,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:18:45,529 INFO:     Epoch: 23
2023-01-05 09:18:47,622 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.48960322539011636, 'Total loss': 0.48960322539011636} | train loss {'Reaction outcome loss': 0.4013865355780159, 'Total loss': 0.4013865355780159}
2023-01-05 09:18:47,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:18:47,622 INFO:     Epoch: 24
2023-01-05 09:18:49,729 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46901110212008157, 'Total loss': 0.46901110212008157} | train loss {'Reaction outcome loss': 0.40526031265440193, 'Total loss': 0.40526031265440193}
2023-01-05 09:18:49,729 INFO:     Found new best model at epoch 24
2023-01-05 09:18:49,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:18:49,731 INFO:     Epoch: 25
2023-01-05 09:18:51,871 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4878653327624003, 'Total loss': 0.4878653327624003} | train loss {'Reaction outcome loss': 0.39268313456272735, 'Total loss': 0.39268313456272735}
2023-01-05 09:18:51,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:18:51,872 INFO:     Epoch: 26
2023-01-05 09:18:53,995 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.501144431034724, 'Total loss': 0.501144431034724} | train loss {'Reaction outcome loss': 0.3885954974997585, 'Total loss': 0.3885954974997585}
2023-01-05 09:18:53,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:18:53,995 INFO:     Epoch: 27
2023-01-05 09:18:56,141 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4837634841601054, 'Total loss': 0.4837634841601054} | train loss {'Reaction outcome loss': 0.4065832198476014, 'Total loss': 0.4065832198476014}
2023-01-05 09:18:56,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:18:56,141 INFO:     Epoch: 28
2023-01-05 09:18:58,273 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4615360776583354, 'Total loss': 0.4615360776583354} | train loss {'Reaction outcome loss': 0.3859556889856585, 'Total loss': 0.3859556889856585}
2023-01-05 09:18:58,273 INFO:     Found new best model at epoch 28
2023-01-05 09:18:58,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:18:58,275 INFO:     Epoch: 29
2023-01-05 09:19:00,406 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.46247651080290475, 'Total loss': 0.46247651080290475} | train loss {'Reaction outcome loss': 0.38487614672361076, 'Total loss': 0.38487614672361076}
2023-01-05 09:19:00,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:19:00,407 INFO:     Epoch: 30
2023-01-05 09:19:02,546 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4764463663101196, 'Total loss': 0.4764463663101196} | train loss {'Reaction outcome loss': 0.37506455407761363, 'Total loss': 0.37506455407761363}
2023-01-05 09:19:02,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:19:02,547 INFO:     Epoch: 31
2023-01-05 09:19:04,661 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.5110307554403941, 'Total loss': 0.5110307554403941} | train loss {'Reaction outcome loss': 0.37735359057589213, 'Total loss': 0.37735359057589213}
2023-01-05 09:19:04,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:19:04,661 INFO:     Epoch: 32
2023-01-05 09:19:06,796 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4792706290880839, 'Total loss': 0.4792706290880839} | train loss {'Reaction outcome loss': 0.3700151464461511, 'Total loss': 0.3700151464461511}
2023-01-05 09:19:06,796 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:19:06,796 INFO:     Epoch: 33
2023-01-05 09:19:08,923 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.47700246969858806, 'Total loss': 0.47700246969858806} | train loss {'Reaction outcome loss': 0.3660305588627639, 'Total loss': 0.3660305588627639}
2023-01-05 09:19:08,923 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:19:08,923 INFO:     Epoch: 34
2023-01-05 09:19:11,080 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.5083160499731699, 'Total loss': 0.5083160499731699} | train loss {'Reaction outcome loss': 0.36184151692525146, 'Total loss': 0.36184151692525146}
2023-01-05 09:19:11,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:19:11,080 INFO:     Epoch: 35
2023-01-05 09:19:13,218 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4573378533124924, 'Total loss': 0.4573378533124924} | train loss {'Reaction outcome loss': 0.36022640710723575, 'Total loss': 0.36022640710723575}
2023-01-05 09:19:13,218 INFO:     Found new best model at epoch 35
2023-01-05 09:19:13,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:19:13,219 INFO:     Epoch: 36
2023-01-05 09:19:15,325 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4730939368406932, 'Total loss': 0.4730939368406932} | train loss {'Reaction outcome loss': 0.3534175456650015, 'Total loss': 0.3534175456650015}
2023-01-05 09:19:15,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:19:15,325 INFO:     Epoch: 37
2023-01-05 09:19:17,458 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46711014608542123, 'Total loss': 0.46711014608542123} | train loss {'Reaction outcome loss': 0.35205135345998884, 'Total loss': 0.35205135345998884}
2023-01-05 09:19:17,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:19:17,459 INFO:     Epoch: 38
2023-01-05 09:19:19,607 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.47519856691360474, 'Total loss': 0.47519856691360474} | train loss {'Reaction outcome loss': 0.34792895727925655, 'Total loss': 0.34792895727925655}
2023-01-05 09:19:19,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:19:19,608 INFO:     Epoch: 39
2023-01-05 09:19:21,747 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.46337061921755474, 'Total loss': 0.46337061921755474} | train loss {'Reaction outcome loss': 0.35025194532953313, 'Total loss': 0.35025194532953313}
2023-01-05 09:19:21,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:19:21,747 INFO:     Epoch: 40
2023-01-05 09:19:23,852 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45731308261553444, 'Total loss': 0.45731308261553444} | train loss {'Reaction outcome loss': 0.36457232116431376, 'Total loss': 0.36457232116431376}
2023-01-05 09:19:23,852 INFO:     Found new best model at epoch 40
2023-01-05 09:19:23,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:19:23,853 INFO:     Epoch: 41
2023-01-05 09:19:26,003 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4605163713296255, 'Total loss': 0.4605163713296255} | train loss {'Reaction outcome loss': 0.34915057727598847, 'Total loss': 0.34915057727598847}
2023-01-05 09:19:26,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:19:26,004 INFO:     Epoch: 42
2023-01-05 09:19:28,136 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4333487439900637, 'Total loss': 0.4333487439900637} | train loss {'Reaction outcome loss': 0.3421011517708934, 'Total loss': 0.3421011517708934}
2023-01-05 09:19:28,136 INFO:     Found new best model at epoch 42
2023-01-05 09:19:28,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:19:28,137 INFO:     Epoch: 43
2023-01-05 09:19:30,279 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.47475288112958275, 'Total loss': 0.47475288112958275} | train loss {'Reaction outcome loss': 0.35036919766740093, 'Total loss': 0.35036919766740093}
2023-01-05 09:19:30,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:19:30,279 INFO:     Epoch: 44
2023-01-05 09:19:32,401 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4259213993946711, 'Total loss': 0.4259213993946711} | train loss {'Reaction outcome loss': 0.36134069748104725, 'Total loss': 0.36134069748104725}
2023-01-05 09:19:32,401 INFO:     Found new best model at epoch 44
2023-01-05 09:19:32,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:19:32,402 INFO:     Epoch: 45
2023-01-05 09:19:34,527 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4814614415168762, 'Total loss': 0.4814614415168762} | train loss {'Reaction outcome loss': 0.3276465374207043, 'Total loss': 0.3276465374207043}
2023-01-05 09:19:34,527 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:19:34,527 INFO:     Epoch: 46
2023-01-05 09:19:36,625 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44818982084592185, 'Total loss': 0.44818982084592185} | train loss {'Reaction outcome loss': 0.3238640154603923, 'Total loss': 0.3238640154603923}
2023-01-05 09:19:36,625 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:19:36,625 INFO:     Epoch: 47
2023-01-05 09:19:38,773 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4718938191731771, 'Total loss': 0.4718938191731771} | train loss {'Reaction outcome loss': 0.31501133119066554, 'Total loss': 0.31501133119066554}
2023-01-05 09:19:38,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:19:38,774 INFO:     Epoch: 48
2023-01-05 09:19:40,904 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4589997708797455, 'Total loss': 0.4589997708797455} | train loss {'Reaction outcome loss': 0.3240720372701037, 'Total loss': 0.3240720372701037}
2023-01-05 09:19:40,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:19:40,904 INFO:     Epoch: 49
2023-01-05 09:19:43,043 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4708764165639877, 'Total loss': 0.4708764165639877} | train loss {'Reaction outcome loss': 0.32125902237991494, 'Total loss': 0.32125902237991494}
2023-01-05 09:19:43,043 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:19:43,044 INFO:     Epoch: 50
2023-01-05 09:19:45,179 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4615682870149612, 'Total loss': 0.4615682870149612} | train loss {'Reaction outcome loss': 0.3239712641698661, 'Total loss': 0.3239712641698661}
2023-01-05 09:19:45,179 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:19:45,179 INFO:     Epoch: 51
2023-01-05 09:19:47,307 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4398597518603007, 'Total loss': 0.4398597518603007} | train loss {'Reaction outcome loss': 0.3073357592857328, 'Total loss': 0.3073357592857328}
2023-01-05 09:19:47,307 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:19:47,307 INFO:     Epoch: 52
2023-01-05 09:19:49,435 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44753161271413167, 'Total loss': 0.44753161271413167} | train loss {'Reaction outcome loss': 0.3020481573577221, 'Total loss': 0.3020481573577221}
2023-01-05 09:19:49,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:19:49,435 INFO:     Epoch: 53
2023-01-05 09:19:51,578 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4660035053888957, 'Total loss': 0.4660035053888957} | train loss {'Reaction outcome loss': 0.3016775542681622, 'Total loss': 0.3016775542681622}
2023-01-05 09:19:51,578 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:19:51,578 INFO:     Epoch: 54
2023-01-05 09:19:53,731 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4281885226567586, 'Total loss': 0.4281885226567586} | train loss {'Reaction outcome loss': 0.3014303836202076, 'Total loss': 0.3014303836202076}
2023-01-05 09:19:53,731 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:19:53,732 INFO:     Epoch: 55
2023-01-05 09:19:55,876 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43356112440427147, 'Total loss': 0.43356112440427147} | train loss {'Reaction outcome loss': 0.2959554402707685, 'Total loss': 0.2959554402707685}
2023-01-05 09:19:55,877 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:19:55,877 INFO:     Epoch: 56
2023-01-05 09:19:58,016 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4238119572401047, 'Total loss': 0.4238119572401047} | train loss {'Reaction outcome loss': 0.2957111317799359, 'Total loss': 0.2957111317799359}
2023-01-05 09:19:58,016 INFO:     Found new best model at epoch 56
2023-01-05 09:19:58,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:19:58,017 INFO:     Epoch: 57
2023-01-05 09:20:00,140 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4862395127614339, 'Total loss': 0.4862395127614339} | train loss {'Reaction outcome loss': 0.29209997992813075, 'Total loss': 0.29209997992813075}
2023-01-05 09:20:00,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:20:00,140 INFO:     Epoch: 58
2023-01-05 09:20:02,282 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.481071670850118, 'Total loss': 0.481071670850118} | train loss {'Reaction outcome loss': 0.2944084720667519, 'Total loss': 0.2944084720667519}
2023-01-05 09:20:02,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:20:02,283 INFO:     Epoch: 59
2023-01-05 09:20:04,484 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.44892673889795937, 'Total loss': 0.44892673889795937} | train loss {'Reaction outcome loss': 0.29663682197207125, 'Total loss': 0.29663682197207125}
2023-01-05 09:20:04,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:20:04,484 INFO:     Epoch: 60
2023-01-05 09:20:06,605 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4744407872358958, 'Total loss': 0.4744407872358958} | train loss {'Reaction outcome loss': 0.293411247076659, 'Total loss': 0.293411247076659}
2023-01-05 09:20:06,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:20:06,605 INFO:     Epoch: 61
2023-01-05 09:20:08,728 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.43873115281263986, 'Total loss': 0.43873115281263986} | train loss {'Reaction outcome loss': 0.283606920040388, 'Total loss': 0.283606920040388}
2023-01-05 09:20:08,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:20:08,728 INFO:     Epoch: 62
2023-01-05 09:20:10,864 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.46304227113723756, 'Total loss': 0.46304227113723756} | train loss {'Reaction outcome loss': 0.28342863678952435, 'Total loss': 0.28342863678952435}
2023-01-05 09:20:10,864 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:20:10,864 INFO:     Epoch: 63
2023-01-05 09:20:13,014 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.45251945555210116, 'Total loss': 0.45251945555210116} | train loss {'Reaction outcome loss': 0.2881529305022264, 'Total loss': 0.2881529305022264}
2023-01-05 09:20:13,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:20:13,015 INFO:     Epoch: 64
2023-01-05 09:20:15,146 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.44811268548170724, 'Total loss': 0.44811268548170724} | train loss {'Reaction outcome loss': 0.3027763697048784, 'Total loss': 0.3027763697048784}
2023-01-05 09:20:15,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:20:15,147 INFO:     Epoch: 65
2023-01-05 09:20:17,291 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4593937357266744, 'Total loss': 0.4593937357266744} | train loss {'Reaction outcome loss': 0.29573898981122865, 'Total loss': 0.29573898981122865}
2023-01-05 09:20:17,291 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:20:17,291 INFO:     Epoch: 66
2023-01-05 09:20:19,421 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48129335741202034, 'Total loss': 0.48129335741202034} | train loss {'Reaction outcome loss': 0.2916563129300535, 'Total loss': 0.2916563129300535}
2023-01-05 09:20:19,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:20:19,421 INFO:     Epoch: 67
2023-01-05 09:20:21,517 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4489257136980693, 'Total loss': 0.4489257136980693} | train loss {'Reaction outcome loss': 0.29407993926788156, 'Total loss': 0.29407993926788156}
2023-01-05 09:20:21,517 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:20:21,518 INFO:     Epoch: 68
2023-01-05 09:20:23,665 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4329468210538228, 'Total loss': 0.4329468210538228} | train loss {'Reaction outcome loss': 0.29187331822839147, 'Total loss': 0.29187331822839147}
2023-01-05 09:20:23,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:20:23,665 INFO:     Epoch: 69
2023-01-05 09:20:25,789 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4357518086830775, 'Total loss': 0.4357518086830775} | train loss {'Reaction outcome loss': 0.2764888796137362, 'Total loss': 0.2764888796137362}
2023-01-05 09:20:25,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:20:25,789 INFO:     Epoch: 70
2023-01-05 09:20:27,914 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.458436385790507, 'Total loss': 0.458436385790507} | train loss {'Reaction outcome loss': 0.28493410927963536, 'Total loss': 0.28493410927963536}
2023-01-05 09:20:27,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:20:27,915 INFO:     Epoch: 71
2023-01-05 09:20:30,036 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.467809530099233, 'Total loss': 0.467809530099233} | train loss {'Reaction outcome loss': 0.2812808427695637, 'Total loss': 0.2812808427695637}
2023-01-05 09:20:30,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:20:30,036 INFO:     Epoch: 72
2023-01-05 09:20:32,186 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.407590706149737, 'Total loss': 0.407590706149737} | train loss {'Reaction outcome loss': 0.2769845619838199, 'Total loss': 0.2769845619838199}
2023-01-05 09:20:32,187 INFO:     Found new best model at epoch 72
2023-01-05 09:20:32,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:20:32,188 INFO:     Epoch: 73
2023-01-05 09:20:34,289 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4379817167917887, 'Total loss': 0.4379817167917887} | train loss {'Reaction outcome loss': 0.26851335341158067, 'Total loss': 0.26851335341158067}
2023-01-05 09:20:34,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:20:34,290 INFO:     Epoch: 74
2023-01-05 09:20:36,415 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4691076159477234, 'Total loss': 0.4691076159477234} | train loss {'Reaction outcome loss': 0.27790182629267796, 'Total loss': 0.27790182629267796}
2023-01-05 09:20:36,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:20:36,416 INFO:     Epoch: 75
2023-01-05 09:20:38,543 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4459334184726079, 'Total loss': 0.4459334184726079} | train loss {'Reaction outcome loss': 0.2804451955725317, 'Total loss': 0.2804451955725317}
2023-01-05 09:20:38,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:20:38,544 INFO:     Epoch: 76
2023-01-05 09:20:40,683 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.46368988702694575, 'Total loss': 0.46368988702694575} | train loss {'Reaction outcome loss': 0.28556067367131566, 'Total loss': 0.28556067367131566}
2023-01-05 09:20:40,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:20:40,684 INFO:     Epoch: 77
2023-01-05 09:20:42,792 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.43042397101720176, 'Total loss': 0.43042397101720176} | train loss {'Reaction outcome loss': 0.2799959749985567, 'Total loss': 0.2799959749985567}
2023-01-05 09:20:42,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:20:42,792 INFO:     Epoch: 78
2023-01-05 09:20:44,939 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4276677290598551, 'Total loss': 0.4276677290598551} | train loss {'Reaction outcome loss': 0.2693564171401878, 'Total loss': 0.2693564171401878}
2023-01-05 09:20:44,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:20:44,939 INFO:     Epoch: 79
2023-01-05 09:20:47,091 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.5006013850371043, 'Total loss': 0.5006013850371043} | train loss {'Reaction outcome loss': 0.26251839886527456, 'Total loss': 0.26251839886527456}
2023-01-05 09:20:47,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:20:47,091 INFO:     Epoch: 80
2023-01-05 09:20:49,207 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.46934912701447806, 'Total loss': 0.46934912701447806} | train loss {'Reaction outcome loss': 0.2725197375698042, 'Total loss': 0.2725197375698042}
2023-01-05 09:20:49,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:20:49,207 INFO:     Epoch: 81
2023-01-05 09:20:51,357 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.460054616133372, 'Total loss': 0.460054616133372} | train loss {'Reaction outcome loss': 0.26725096482635086, 'Total loss': 0.26725096482635086}
2023-01-05 09:20:51,358 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:20:51,358 INFO:     Epoch: 82
2023-01-05 09:20:53,483 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4538564453522364, 'Total loss': 0.4538564453522364} | train loss {'Reaction outcome loss': 0.2596632302536265, 'Total loss': 0.2596632302536265}
2023-01-05 09:20:53,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:20:53,483 INFO:     Epoch: 83
2023-01-05 09:20:55,604 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4495958333214124, 'Total loss': 0.4495958333214124} | train loss {'Reaction outcome loss': 0.2658210446167251, 'Total loss': 0.2658210446167251}
2023-01-05 09:20:55,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:20:55,605 INFO:     Epoch: 84
2023-01-05 09:20:57,733 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.43458860615889233, 'Total loss': 0.43458860615889233} | train loss {'Reaction outcome loss': 0.26641472740912053, 'Total loss': 0.26641472740912053}
2023-01-05 09:20:57,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:20:57,733 INFO:     Epoch: 85
2023-01-05 09:20:59,866 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.46336770902077357, 'Total loss': 0.46336770902077357} | train loss {'Reaction outcome loss': 0.2603621715140922, 'Total loss': 0.2603621715140922}
2023-01-05 09:20:59,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:20:59,866 INFO:     Epoch: 86
2023-01-05 09:21:01,977 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.440959844738245, 'Total loss': 0.440959844738245} | train loss {'Reaction outcome loss': 0.25643427010990033, 'Total loss': 0.25643427010990033}
2023-01-05 09:21:01,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:21:01,978 INFO:     Epoch: 87
2023-01-05 09:21:04,119 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4298858612775803, 'Total loss': 0.4298858612775803} | train loss {'Reaction outcome loss': 0.25893138142545585, 'Total loss': 0.25893138142545585}
2023-01-05 09:21:04,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:21:04,120 INFO:     Epoch: 88
2023-01-05 09:21:06,249 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.4662304182847341, 'Total loss': 0.4662304182847341} | train loss {'Reaction outcome loss': 0.2588761822009236, 'Total loss': 0.2588761822009236}
2023-01-05 09:21:06,249 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:21:06,249 INFO:     Epoch: 89
2023-01-05 09:21:08,369 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4713095063964526, 'Total loss': 0.4713095063964526} | train loss {'Reaction outcome loss': 0.2568506795265105, 'Total loss': 0.2568506795265105}
2023-01-05 09:21:08,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:21:08,370 INFO:     Epoch: 90
2023-01-05 09:21:10,500 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43533260424931847, 'Total loss': 0.43533260424931847} | train loss {'Reaction outcome loss': 0.2849753137067993, 'Total loss': 0.2849753137067993}
2023-01-05 09:21:10,500 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:21:10,500 INFO:     Epoch: 91
2023-01-05 09:21:12,636 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4269123679647843, 'Total loss': 0.4269123679647843} | train loss {'Reaction outcome loss': 0.2523132722467974, 'Total loss': 0.2523132722467974}
2023-01-05 09:21:12,636 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:21:12,636 INFO:     Epoch: 92
2023-01-05 09:21:14,786 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4323152462641398, 'Total loss': 0.4323152462641398} | train loss {'Reaction outcome loss': 0.25131965720662475, 'Total loss': 0.25131965720662475}
2023-01-05 09:21:14,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:21:14,787 INFO:     Epoch: 93
2023-01-05 09:21:16,962 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.44426846206188203, 'Total loss': 0.44426846206188203} | train loss {'Reaction outcome loss': 0.2435556428871401, 'Total loss': 0.2435556428871401}
2023-01-05 09:21:16,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:21:16,963 INFO:     Epoch: 94
2023-01-05 09:21:19,136 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4587095657984416, 'Total loss': 0.4587095657984416} | train loss {'Reaction outcome loss': 0.24472414328888786, 'Total loss': 0.24472414328888786}
2023-01-05 09:21:19,136 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:21:19,136 INFO:     Epoch: 95
2023-01-05 09:21:21,278 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4338896284500758, 'Total loss': 0.4338896284500758} | train loss {'Reaction outcome loss': 0.2401581671446616, 'Total loss': 0.2401581671446616}
2023-01-05 09:21:21,279 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:21:21,279 INFO:     Epoch: 96
2023-01-05 09:21:23,414 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.44252264201641084, 'Total loss': 0.44252264201641084} | train loss {'Reaction outcome loss': 0.24398589296860324, 'Total loss': 0.24398589296860324}
2023-01-05 09:21:23,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:21:23,414 INFO:     Epoch: 97
2023-01-05 09:21:25,523 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.42770276268323265, 'Total loss': 0.42770276268323265} | train loss {'Reaction outcome loss': 0.2414471840037141, 'Total loss': 0.2414471840037141}
2023-01-05 09:21:25,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:21:25,524 INFO:     Epoch: 98
2023-01-05 09:21:27,622 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.43990973234176634, 'Total loss': 0.43990973234176634} | train loss {'Reaction outcome loss': 0.2429773033017873, 'Total loss': 0.2429773033017873}
2023-01-05 09:21:27,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:21:27,623 INFO:     Epoch: 99
2023-01-05 09:21:29,740 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.41989462574323017, 'Total loss': 0.41989462574323017} | train loss {'Reaction outcome loss': 0.23422218196471964, 'Total loss': 0.23422218196471964}
2023-01-05 09:21:29,740 INFO:     Best model found after epoch 73 of 100.
2023-01-05 09:21:29,740 INFO:   Done with stage: TRAINING
2023-01-05 09:21:29,740 INFO:   Starting stage: EVALUATION
2023-01-05 09:21:29,872 INFO:   Done with stage: EVALUATION
2023-01-05 09:21:29,872 INFO:   Leaving out SEQ value Fold_8
2023-01-05 09:21:29,885 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 09:21:29,885 INFO:   Starting stage: FEATURE SCALING
2023-01-05 09:21:30,540 INFO:   Done with stage: FEATURE SCALING
2023-01-05 09:21:30,541 INFO:   Starting stage: SCALING TARGETS
2023-01-05 09:21:30,609 INFO:   Done with stage: SCALING TARGETS
2023-01-05 09:21:30,609 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:21:30,609 INFO:     No hyperparam tuning for this model
2023-01-05 09:21:30,609 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:21:30,609 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 09:21:30,610 INFO:     None feature selector for col prot
2023-01-05 09:21:30,610 INFO:     None feature selector for col prot
2023-01-05 09:21:30,610 INFO:     None feature selector for col prot
2023-01-05 09:21:30,610 INFO:     None feature selector for col chem
2023-01-05 09:21:30,611 INFO:     None feature selector for col chem
2023-01-05 09:21:30,611 INFO:     None feature selector for col chem
2023-01-05 09:21:30,611 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 09:21:30,611 INFO:   Starting stage: BUILD MODEL
2023-01-05 09:21:30,612 INFO:     Number of params in model 72901
2023-01-05 09:21:30,615 INFO:   Done with stage: BUILD MODEL
2023-01-05 09:21:30,615 INFO:   Starting stage: TRAINING
2023-01-05 09:21:30,673 INFO:     Val loss before train {'Reaction outcome loss': 0.9959608316421509, 'Total loss': 0.9959608316421509}
2023-01-05 09:21:30,673 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:21:30,674 INFO:     Epoch: 0
2023-01-05 09:21:32,845 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8604660828908285, 'Total loss': 0.8604660828908285} | train loss {'Reaction outcome loss': 0.910722594667267, 'Total loss': 0.910722594667267}
2023-01-05 09:21:32,846 INFO:     Found new best model at epoch 0
2023-01-05 09:21:32,847 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:21:32,847 INFO:     Epoch: 1
2023-01-05 09:21:35,006 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6744786739349365, 'Total loss': 0.6744786739349365} | train loss {'Reaction outcome loss': 0.7392530552633516, 'Total loss': 0.7392530552633516}
2023-01-05 09:21:35,006 INFO:     Found new best model at epoch 1
2023-01-05 09:21:35,007 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:21:35,008 INFO:     Epoch: 2
2023-01-05 09:21:37,165 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5515956918398539, 'Total loss': 0.5515956918398539} | train loss {'Reaction outcome loss': 0.5880197203639663, 'Total loss': 0.5880197203639663}
2023-01-05 09:21:37,166 INFO:     Found new best model at epoch 2
2023-01-05 09:21:37,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:21:37,167 INFO:     Epoch: 3
2023-01-05 09:21:39,273 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5481867452462514, 'Total loss': 0.5481867452462514} | train loss {'Reaction outcome loss': 0.5266524653185854, 'Total loss': 0.5266524653185854}
2023-01-05 09:21:39,274 INFO:     Found new best model at epoch 3
2023-01-05 09:21:39,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:21:39,275 INFO:     Epoch: 4
2023-01-05 09:21:41,389 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5097403109073639, 'Total loss': 0.5097403109073639} | train loss {'Reaction outcome loss': 0.5105161453996386, 'Total loss': 0.5105161453996386}
2023-01-05 09:21:41,389 INFO:     Found new best model at epoch 4
2023-01-05 09:21:41,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:21:41,390 INFO:     Epoch: 5
2023-01-05 09:21:43,507 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5381430347760519, 'Total loss': 0.5381430347760519} | train loss {'Reaction outcome loss': 0.49222622953710105, 'Total loss': 0.49222622953710105}
2023-01-05 09:21:43,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:21:43,508 INFO:     Epoch: 6
2023-01-05 09:21:45,709 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5409366448720296, 'Total loss': 0.5409366448720296} | train loss {'Reaction outcome loss': 0.4836733040464667, 'Total loss': 0.4836733040464667}
2023-01-05 09:21:45,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:21:45,709 INFO:     Epoch: 7
2023-01-05 09:21:47,905 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5141695767641068, 'Total loss': 0.5141695767641068} | train loss {'Reaction outcome loss': 0.4785757987818002, 'Total loss': 0.4785757987818002}
2023-01-05 09:21:47,906 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:21:47,906 INFO:     Epoch: 8
2023-01-05 09:21:50,070 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.52032830119133, 'Total loss': 0.52032830119133} | train loss {'Reaction outcome loss': 0.4680324682877177, 'Total loss': 0.4680324682877177}
2023-01-05 09:21:50,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:21:50,070 INFO:     Epoch: 9
2023-01-05 09:21:52,209 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5181333382924398, 'Total loss': 0.5181333382924398} | train loss {'Reaction outcome loss': 0.46371686101068943, 'Total loss': 0.46371686101068943}
2023-01-05 09:21:52,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:21:52,210 INFO:     Epoch: 10
2023-01-05 09:21:54,373 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5205554922421773, 'Total loss': 0.5205554922421773} | train loss {'Reaction outcome loss': 0.45800184390265425, 'Total loss': 0.45800184390265425}
2023-01-05 09:21:54,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:21:54,373 INFO:     Epoch: 11
2023-01-05 09:21:56,534 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4901680588722229, 'Total loss': 0.4901680588722229} | train loss {'Reaction outcome loss': 0.4553527430573226, 'Total loss': 0.4553527430573226}
2023-01-05 09:21:56,534 INFO:     Found new best model at epoch 11
2023-01-05 09:21:56,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:21:56,536 INFO:     Epoch: 12
2023-01-05 09:21:58,630 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.48478684822718304, 'Total loss': 0.48478684822718304} | train loss {'Reaction outcome loss': 0.45016658005915283, 'Total loss': 0.45016658005915283}
2023-01-05 09:21:58,630 INFO:     Found new best model at epoch 12
2023-01-05 09:21:58,632 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:21:58,632 INFO:     Epoch: 13
2023-01-05 09:22:00,705 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5185163954893748, 'Total loss': 0.5185163954893748} | train loss {'Reaction outcome loss': 0.4478815931540269, 'Total loss': 0.4478815931540269}
2023-01-05 09:22:00,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:22:00,706 INFO:     Epoch: 14
2023-01-05 09:22:02,748 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5563651780287425, 'Total loss': 0.5563651780287425} | train loss {'Reaction outcome loss': 0.4442406803260356, 'Total loss': 0.4442406803260356}
2023-01-05 09:22:02,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:22:02,748 INFO:     Epoch: 15
2023-01-05 09:22:04,716 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5013671924670537, 'Total loss': 0.5013671924670537} | train loss {'Reaction outcome loss': 0.437549590081959, 'Total loss': 0.437549590081959}
2023-01-05 09:22:04,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:22:04,716 INFO:     Epoch: 16
2023-01-05 09:22:06,813 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.48493183553218844, 'Total loss': 0.48493183553218844} | train loss {'Reaction outcome loss': 0.4323834632779216, 'Total loss': 0.4323834632779216}
2023-01-05 09:22:06,813 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:22:06,813 INFO:     Epoch: 17
2023-01-05 09:22:08,968 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5743389189243316, 'Total loss': 0.5743389189243316} | train loss {'Reaction outcome loss': 0.4271978878385418, 'Total loss': 0.4271978878385418}
2023-01-05 09:22:08,969 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:22:08,969 INFO:     Epoch: 18
2023-01-05 09:22:11,065 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.490651669104894, 'Total loss': 0.490651669104894} | train loss {'Reaction outcome loss': 0.42642698114935734, 'Total loss': 0.42642698114935734}
2023-01-05 09:22:11,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:22:11,066 INFO:     Epoch: 19
2023-01-05 09:22:13,036 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5288146982590357, 'Total loss': 0.5288146982590357} | train loss {'Reaction outcome loss': 0.4190178854670717, 'Total loss': 0.4190178854670717}
2023-01-05 09:22:13,037 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:22:13,038 INFO:     Epoch: 20
2023-01-05 09:22:14,770 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4979259411493937, 'Total loss': 0.4979259411493937} | train loss {'Reaction outcome loss': 0.42266689852262157, 'Total loss': 0.42266689852262157}
2023-01-05 09:22:14,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:22:14,770 INFO:     Epoch: 21
2023-01-05 09:22:16,481 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4934840887784958, 'Total loss': 0.4934840887784958} | train loss {'Reaction outcome loss': 0.4155515506044849, 'Total loss': 0.4155515506044849}
2023-01-05 09:22:16,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:22:16,482 INFO:     Epoch: 22
2023-01-05 09:22:18,572 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5103758911291758, 'Total loss': 0.5103758911291758} | train loss {'Reaction outcome loss': 0.40667050754849293, 'Total loss': 0.40667050754849293}
2023-01-05 09:22:18,572 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:22:18,572 INFO:     Epoch: 23
2023-01-05 09:22:20,647 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.48471925059954324, 'Total loss': 0.48471925059954324} | train loss {'Reaction outcome loss': 0.4071800033033112, 'Total loss': 0.4071800033033112}
2023-01-05 09:22:20,647 INFO:     Found new best model at epoch 23
2023-01-05 09:22:20,649 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:22:20,649 INFO:     Epoch: 24
2023-01-05 09:22:22,743 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.500080539782842, 'Total loss': 0.500080539782842} | train loss {'Reaction outcome loss': 0.40303199260662764, 'Total loss': 0.40303199260662764}
2023-01-05 09:22:22,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:22:22,743 INFO:     Epoch: 25
2023-01-05 09:22:24,840 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.47608098288377126, 'Total loss': 0.47608098288377126} | train loss {'Reaction outcome loss': 0.39886451608095413, 'Total loss': 0.39886451608095413}
2023-01-05 09:22:24,840 INFO:     Found new best model at epoch 25
2023-01-05 09:22:24,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:22:24,842 INFO:     Epoch: 26
2023-01-05 09:22:26,940 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.5060678530484438, 'Total loss': 0.5060678530484438} | train loss {'Reaction outcome loss': 0.391150292241093, 'Total loss': 0.391150292241093}
2023-01-05 09:22:26,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:22:26,940 INFO:     Epoch: 27
2023-01-05 09:22:29,033 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.49200380643208824, 'Total loss': 0.49200380643208824} | train loss {'Reaction outcome loss': 0.3989996763266923, 'Total loss': 0.3989996763266923}
2023-01-05 09:22:29,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:22:29,034 INFO:     Epoch: 28
2023-01-05 09:22:31,203 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.48612251778443655, 'Total loss': 0.48612251778443655} | train loss {'Reaction outcome loss': 0.3924208925866382, 'Total loss': 0.3924208925866382}
2023-01-05 09:22:31,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:22:31,203 INFO:     Epoch: 29
2023-01-05 09:22:33,310 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4434005891283353, 'Total loss': 0.4434005891283353} | train loss {'Reaction outcome loss': 0.38904106133914257, 'Total loss': 0.38904106133914257}
2023-01-05 09:22:33,311 INFO:     Found new best model at epoch 29
2023-01-05 09:22:33,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:22:33,313 INFO:     Epoch: 30
2023-01-05 09:22:35,439 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45866168836752574, 'Total loss': 0.45866168836752574} | train loss {'Reaction outcome loss': 0.3850565728468773, 'Total loss': 0.3850565728468773}
2023-01-05 09:22:35,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:22:35,439 INFO:     Epoch: 31
2023-01-05 09:22:37,555 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.48152640064557395, 'Total loss': 0.48152640064557395} | train loss {'Reaction outcome loss': 0.38506431648364436, 'Total loss': 0.38506431648364436}
2023-01-05 09:22:37,555 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:22:37,555 INFO:     Epoch: 32
2023-01-05 09:22:39,643 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.565072359641393, 'Total loss': 0.565072359641393} | train loss {'Reaction outcome loss': 0.381412699054449, 'Total loss': 0.381412699054449}
2023-01-05 09:22:39,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:22:39,643 INFO:     Epoch: 33
2023-01-05 09:22:41,758 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.5122615953286489, 'Total loss': 0.5122615953286489} | train loss {'Reaction outcome loss': 0.3782796568540863, 'Total loss': 0.3782796568540863}
2023-01-05 09:22:41,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:22:41,758 INFO:     Epoch: 34
2023-01-05 09:22:43,869 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4923750817775726, 'Total loss': 0.4923750817775726} | train loss {'Reaction outcome loss': 0.3748699323762031, 'Total loss': 0.3748699323762031}
2023-01-05 09:22:43,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:22:43,870 INFO:     Epoch: 35
2023-01-05 09:22:45,973 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4958660423755646, 'Total loss': 0.4958660423755646} | train loss {'Reaction outcome loss': 0.37178096658253407, 'Total loss': 0.37178096658253407}
2023-01-05 09:22:45,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:22:45,973 INFO:     Epoch: 36
2023-01-05 09:22:48,058 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.43279975596815345, 'Total loss': 0.43279975596815345} | train loss {'Reaction outcome loss': 0.3652036420100338, 'Total loss': 0.3652036420100338}
2023-01-05 09:22:48,058 INFO:     Found new best model at epoch 36
2023-01-05 09:22:48,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:22:48,060 INFO:     Epoch: 37
2023-01-05 09:22:50,171 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4872540483872096, 'Total loss': 0.4872540483872096} | train loss {'Reaction outcome loss': 0.3632603828614448, 'Total loss': 0.3632603828614448}
2023-01-05 09:22:50,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:22:50,172 INFO:     Epoch: 38
2023-01-05 09:22:52,262 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4542644634842873, 'Total loss': 0.4542644634842873} | train loss {'Reaction outcome loss': 0.35838238274057704, 'Total loss': 0.35838238274057704}
2023-01-05 09:22:52,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:22:52,262 INFO:     Epoch: 39
2023-01-05 09:22:54,373 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4679122646649679, 'Total loss': 0.4679122646649679} | train loss {'Reaction outcome loss': 0.361705930350901, 'Total loss': 0.361705930350901}
2023-01-05 09:22:54,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:22:54,374 INFO:     Epoch: 40
2023-01-05 09:22:56,494 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.45797021041313807, 'Total loss': 0.45797021041313807} | train loss {'Reaction outcome loss': 0.3554746618310174, 'Total loss': 0.3554746618310174}
2023-01-05 09:22:56,495 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:22:56,495 INFO:     Epoch: 41
2023-01-05 09:22:58,579 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.44199100534121194, 'Total loss': 0.44199100534121194} | train loss {'Reaction outcome loss': 0.35375692576661216, 'Total loss': 0.35375692576661216}
2023-01-05 09:22:58,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:22:58,579 INFO:     Epoch: 42
2023-01-05 09:23:00,660 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46369200348854067, 'Total loss': 0.46369200348854067} | train loss {'Reaction outcome loss': 0.3550223219225477, 'Total loss': 0.3550223219225477}
2023-01-05 09:23:00,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:23:00,660 INFO:     Epoch: 43
2023-01-05 09:23:02,750 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4334760416299105, 'Total loss': 0.4334760416299105} | train loss {'Reaction outcome loss': 0.3452180017932103, 'Total loss': 0.3452180017932103}
2023-01-05 09:23:02,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:23:02,750 INFO:     Epoch: 44
2023-01-05 09:23:04,845 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.44422166248162587, 'Total loss': 0.44422166248162587} | train loss {'Reaction outcome loss': 0.3483742961298415, 'Total loss': 0.3483742961298415}
2023-01-05 09:23:04,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:23:04,845 INFO:     Epoch: 45
2023-01-05 09:23:06,970 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4398247838020325, 'Total loss': 0.4398247838020325} | train loss {'Reaction outcome loss': 0.3485075552221183, 'Total loss': 0.3485075552221183}
2023-01-05 09:23:06,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:23:06,970 INFO:     Epoch: 46
2023-01-05 09:23:09,063 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.47533223231633503, 'Total loss': 0.47533223231633503} | train loss {'Reaction outcome loss': 0.34135765946664653, 'Total loss': 0.34135765946664653}
2023-01-05 09:23:09,064 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:23:09,064 INFO:     Epoch: 47
2023-01-05 09:23:11,163 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4698261350393295, 'Total loss': 0.4698261350393295} | train loss {'Reaction outcome loss': 0.333830884033507, 'Total loss': 0.333830884033507}
2023-01-05 09:23:11,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:23:11,163 INFO:     Epoch: 48
2023-01-05 09:23:13,265 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.486030646165212, 'Total loss': 0.486030646165212} | train loss {'Reaction outcome loss': 0.33608974789306795, 'Total loss': 0.33608974789306795}
2023-01-05 09:23:13,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:23:13,266 INFO:     Epoch: 49
2023-01-05 09:23:15,371 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45264607270558677, 'Total loss': 0.45264607270558677} | train loss {'Reaction outcome loss': 0.3303087519621647, 'Total loss': 0.3303087519621647}
2023-01-05 09:23:15,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:23:15,371 INFO:     Epoch: 50
2023-01-05 09:23:17,460 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4876682539780935, 'Total loss': 0.4876682539780935} | train loss {'Reaction outcome loss': 0.3333589920003117, 'Total loss': 0.3333589920003117}
2023-01-05 09:23:17,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:23:17,460 INFO:     Epoch: 51
2023-01-05 09:23:19,561 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.45857826670010887, 'Total loss': 0.45857826670010887} | train loss {'Reaction outcome loss': 0.3309910251271157, 'Total loss': 0.3309910251271157}
2023-01-05 09:23:19,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:23:19,562 INFO:     Epoch: 52
2023-01-05 09:23:21,675 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.47018009225527446, 'Total loss': 0.47018009225527446} | train loss {'Reaction outcome loss': 0.32681993951836785, 'Total loss': 0.32681993951836785}
2023-01-05 09:23:21,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:23:21,675 INFO:     Epoch: 53
2023-01-05 09:23:23,757 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5177355368932088, 'Total loss': 0.5177355368932088} | train loss {'Reaction outcome loss': 0.3238259423762942, 'Total loss': 0.3238259423762942}
2023-01-05 09:23:23,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:23:23,758 INFO:     Epoch: 54
2023-01-05 09:23:25,826 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.437261729935805, 'Total loss': 0.437261729935805} | train loss {'Reaction outcome loss': 0.3179819136721529, 'Total loss': 0.3179819136721529}
2023-01-05 09:23:25,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:23:25,827 INFO:     Epoch: 55
2023-01-05 09:23:27,907 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.47105311198780936, 'Total loss': 0.47105311198780936} | train loss {'Reaction outcome loss': 0.31832243022491863, 'Total loss': 0.31832243022491863}
2023-01-05 09:23:27,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:23:27,907 INFO:     Epoch: 56
2023-01-05 09:23:30,041 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.45622414847215015, 'Total loss': 0.45622414847215015} | train loss {'Reaction outcome loss': 0.3186698879623588, 'Total loss': 0.3186698879623588}
2023-01-05 09:23:30,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:23:30,041 INFO:     Epoch: 57
2023-01-05 09:23:32,127 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44490684270858766, 'Total loss': 0.44490684270858766} | train loss {'Reaction outcome loss': 0.3221322106531797, 'Total loss': 0.3221322106531797}
2023-01-05 09:23:32,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:23:32,127 INFO:     Epoch: 58
2023-01-05 09:23:34,252 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.5135168333848318, 'Total loss': 0.5135168333848318} | train loss {'Reaction outcome loss': 0.3065376420652037, 'Total loss': 0.3065376420652037}
2023-01-05 09:23:34,252 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:23:34,252 INFO:     Epoch: 59
2023-01-05 09:23:36,397 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4923708071311315, 'Total loss': 0.4923708071311315} | train loss {'Reaction outcome loss': 0.31091776567992274, 'Total loss': 0.31091776567992274}
2023-01-05 09:23:36,397 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:23:36,397 INFO:     Epoch: 60
2023-01-05 09:23:38,180 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4303896526495616, 'Total loss': 0.4303896526495616} | train loss {'Reaction outcome loss': 0.3122188865101381, 'Total loss': 0.3122188865101381}
2023-01-05 09:23:38,180 INFO:     Found new best model at epoch 60
2023-01-05 09:23:38,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:23:38,182 INFO:     Epoch: 61
2023-01-05 09:23:39,917 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.47815451870361964, 'Total loss': 0.47815451870361964} | train loss {'Reaction outcome loss': 0.3053082500076119, 'Total loss': 0.3053082500076119}
2023-01-05 09:23:39,917 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:23:39,917 INFO:     Epoch: 62
2023-01-05 09:23:41,851 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.5165720283985138, 'Total loss': 0.5165720283985138} | train loss {'Reaction outcome loss': 0.3054326395794149, 'Total loss': 0.3054326395794149}
2023-01-05 09:23:41,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:23:41,851 INFO:     Epoch: 63
2023-01-05 09:23:43,957 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.47585413555304207, 'Total loss': 0.47585413555304207} | train loss {'Reaction outcome loss': 0.30448243795679164, 'Total loss': 0.30448243795679164}
2023-01-05 09:23:43,957 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:23:43,957 INFO:     Epoch: 64
2023-01-05 09:23:46,067 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4706083178520203, 'Total loss': 0.4706083178520203} | train loss {'Reaction outcome loss': 0.30639326886270507, 'Total loss': 0.30639326886270507}
2023-01-05 09:23:46,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:23:46,067 INFO:     Epoch: 65
2023-01-05 09:23:48,187 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4511210769414902, 'Total loss': 0.4511210769414902} | train loss {'Reaction outcome loss': 0.3018292293512013, 'Total loss': 0.3018292293512013}
2023-01-05 09:23:48,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:23:48,187 INFO:     Epoch: 66
2023-01-05 09:23:50,314 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4567472845315933, 'Total loss': 0.4567472845315933} | train loss {'Reaction outcome loss': 0.29737684202991127, 'Total loss': 0.29737684202991127}
2023-01-05 09:23:50,314 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:23:50,314 INFO:     Epoch: 67
2023-01-05 09:23:52,407 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4483416277915239, 'Total loss': 0.4483416277915239} | train loss {'Reaction outcome loss': 0.2949568320597921, 'Total loss': 0.2949568320597921}
2023-01-05 09:23:52,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:23:52,408 INFO:     Epoch: 68
2023-01-05 09:23:54,515 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4427752350767454, 'Total loss': 0.4427752350767454} | train loss {'Reaction outcome loss': 0.3053938847021524, 'Total loss': 0.3053938847021524}
2023-01-05 09:23:54,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:23:54,515 INFO:     Epoch: 69
2023-01-05 09:23:56,620 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46446237166722615, 'Total loss': 0.46446237166722615} | train loss {'Reaction outcome loss': 0.2973782687751583, 'Total loss': 0.2973782687751583}
2023-01-05 09:23:56,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:23:56,621 INFO:     Epoch: 70
2023-01-05 09:23:58,714 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40339392026265464, 'Total loss': 0.40339392026265464} | train loss {'Reaction outcome loss': 0.29330020343318525, 'Total loss': 0.29330020343318525}
2023-01-05 09:23:58,714 INFO:     Found new best model at epoch 70
2023-01-05 09:23:58,716 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:23:58,716 INFO:     Epoch: 71
2023-01-05 09:24:00,880 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4735758443673452, 'Total loss': 0.4735758443673452} | train loss {'Reaction outcome loss': 0.28993410506582523, 'Total loss': 0.28993410506582523}
2023-01-05 09:24:00,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:24:00,880 INFO:     Epoch: 72
2023-01-05 09:24:02,988 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.45504838128884634, 'Total loss': 0.45504838128884634} | train loss {'Reaction outcome loss': 0.28938694838639145, 'Total loss': 0.28938694838639145}
2023-01-05 09:24:02,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:24:02,989 INFO:     Epoch: 73
2023-01-05 09:24:05,087 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4323445647954941, 'Total loss': 0.4323445647954941} | train loss {'Reaction outcome loss': 0.288899696844838, 'Total loss': 0.288899696844838}
2023-01-05 09:24:05,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:24:05,087 INFO:     Epoch: 74
2023-01-05 09:24:07,200 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4399953752756119, 'Total loss': 0.4399953752756119} | train loss {'Reaction outcome loss': 0.2909177195812975, 'Total loss': 0.2909177195812975}
2023-01-05 09:24:07,201 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:24:07,201 INFO:     Epoch: 75
2023-01-05 09:24:09,322 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.44929669598738353, 'Total loss': 0.44929669598738353} | train loss {'Reaction outcome loss': 0.2812182212951201, 'Total loss': 0.2812182212951201}
2023-01-05 09:24:09,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:24:09,323 INFO:     Epoch: 76
2023-01-05 09:24:11,450 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.45266299446423847, 'Total loss': 0.45266299446423847} | train loss {'Reaction outcome loss': 0.2806208423601511, 'Total loss': 0.2806208423601511}
2023-01-05 09:24:11,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:24:11,451 INFO:     Epoch: 77
2023-01-05 09:24:13,543 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4440772342185179, 'Total loss': 0.4440772342185179} | train loss {'Reaction outcome loss': 0.28711838609515095, 'Total loss': 0.28711838609515095}
2023-01-05 09:24:13,543 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:24:13,543 INFO:     Epoch: 78
2023-01-05 09:24:15,664 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4490059375762939, 'Total loss': 0.4490059375762939} | train loss {'Reaction outcome loss': 0.2786331026449854, 'Total loss': 0.2786331026449854}
2023-01-05 09:24:15,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:24:15,665 INFO:     Epoch: 79
2023-01-05 09:24:17,818 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4315408984820048, 'Total loss': 0.4315408984820048} | train loss {'Reaction outcome loss': 0.2766069481592803, 'Total loss': 0.2766069481592803}
2023-01-05 09:24:17,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:24:17,818 INFO:     Epoch: 80
2023-01-05 09:24:19,996 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5011518766482671, 'Total loss': 0.5011518766482671} | train loss {'Reaction outcome loss': 0.27568869356529946, 'Total loss': 0.27568869356529946}
2023-01-05 09:24:19,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:24:19,996 INFO:     Epoch: 81
2023-01-05 09:24:22,162 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.42423175275325775, 'Total loss': 0.42423175275325775} | train loss {'Reaction outcome loss': 0.274115190790086, 'Total loss': 0.274115190790086}
2023-01-05 09:24:22,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:24:22,162 INFO:     Epoch: 82
2023-01-05 09:24:24,304 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.45635289661586287, 'Total loss': 0.45635289661586287} | train loss {'Reaction outcome loss': 0.27270437543700027, 'Total loss': 0.27270437543700027}
2023-01-05 09:24:24,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:24:24,304 INFO:     Epoch: 83
2023-01-05 09:24:26,449 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.448916158080101, 'Total loss': 0.448916158080101} | train loss {'Reaction outcome loss': 0.27076565236835687, 'Total loss': 0.27076565236835687}
2023-01-05 09:24:26,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:24:26,450 INFO:     Epoch: 84
2023-01-05 09:24:28,610 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4843777269124985, 'Total loss': 0.4843777269124985} | train loss {'Reaction outcome loss': 0.2660565179646452, 'Total loss': 0.2660565179646452}
2023-01-05 09:24:28,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:24:28,611 INFO:     Epoch: 85
2023-01-05 09:24:30,782 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.43769798974196117, 'Total loss': 0.43769798974196117} | train loss {'Reaction outcome loss': 0.27681104735822687, 'Total loss': 0.27681104735822687}
2023-01-05 09:24:30,782 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:24:30,782 INFO:     Epoch: 86
2023-01-05 09:24:32,906 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4696501230200132, 'Total loss': 0.4696501230200132} | train loss {'Reaction outcome loss': 0.2629101591205204, 'Total loss': 0.2629101591205204}
2023-01-05 09:24:32,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:24:32,907 INFO:     Epoch: 87
2023-01-05 09:24:35,030 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41950816512107847, 'Total loss': 0.41950816512107847} | train loss {'Reaction outcome loss': 0.26221899711441643, 'Total loss': 0.26221899711441643}
2023-01-05 09:24:35,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:24:35,030 INFO:     Epoch: 88
2023-01-05 09:24:37,137 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.471360082924366, 'Total loss': 0.471360082924366} | train loss {'Reaction outcome loss': 0.2595082432604753, 'Total loss': 0.2595082432604753}
2023-01-05 09:24:37,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:24:37,137 INFO:     Epoch: 89
2023-01-05 09:24:39,255 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4561035652955373, 'Total loss': 0.4561035652955373} | train loss {'Reaction outcome loss': 0.2687654276907226, 'Total loss': 0.2687654276907226}
2023-01-05 09:24:39,255 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:24:39,255 INFO:     Epoch: 90
2023-01-05 09:24:41,416 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4740052064259847, 'Total loss': 0.4740052064259847} | train loss {'Reaction outcome loss': 0.26404962818319105, 'Total loss': 0.26404962818319105}
2023-01-05 09:24:41,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:24:41,416 INFO:     Epoch: 91
2023-01-05 09:24:43,547 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.44884831408659615, 'Total loss': 0.44884831408659615} | train loss {'Reaction outcome loss': 0.2555063864550529, 'Total loss': 0.2555063864550529}
2023-01-05 09:24:43,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:24:43,547 INFO:     Epoch: 92
2023-01-05 09:24:45,700 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4554045875867208, 'Total loss': 0.4554045875867208} | train loss {'Reaction outcome loss': 0.2591542751961575, 'Total loss': 0.2591542751961575}
2023-01-05 09:24:45,701 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:24:45,701 INFO:     Epoch: 93
2023-01-05 09:24:47,829 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.5330550918976465, 'Total loss': 0.5330550918976465} | train loss {'Reaction outcome loss': 0.25781648372719573, 'Total loss': 0.25781648372719573}
2023-01-05 09:24:47,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:24:47,829 INFO:     Epoch: 94
2023-01-05 09:24:49,906 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4307707657416662, 'Total loss': 0.4307707657416662} | train loss {'Reaction outcome loss': 0.25699571470283106, 'Total loss': 0.25699571470283106}
2023-01-05 09:24:49,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:24:49,907 INFO:     Epoch: 95
2023-01-05 09:24:51,996 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4652176946401596, 'Total loss': 0.4652176946401596} | train loss {'Reaction outcome loss': 0.26180465989865553, 'Total loss': 0.26180465989865553}
2023-01-05 09:24:51,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:24:51,996 INFO:     Epoch: 96
2023-01-05 09:24:54,097 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4898405621449153, 'Total loss': 0.4898405621449153} | train loss {'Reaction outcome loss': 0.2604817372913926, 'Total loss': 0.2604817372913926}
2023-01-05 09:24:54,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:24:54,097 INFO:     Epoch: 97
2023-01-05 09:24:56,197 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.49122611383597053, 'Total loss': 0.49122611383597053} | train loss {'Reaction outcome loss': 0.25419435222315917, 'Total loss': 0.25419435222315917}
2023-01-05 09:24:56,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:24:56,198 INFO:     Epoch: 98
2023-01-05 09:24:58,280 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.47885164121786755, 'Total loss': 0.47885164121786755} | train loss {'Reaction outcome loss': 0.25602002314977595, 'Total loss': 0.25602002314977595}
2023-01-05 09:24:58,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:24:58,281 INFO:     Epoch: 99
2023-01-05 09:25:00,391 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.45802719791730245, 'Total loss': 0.45802719791730245} | train loss {'Reaction outcome loss': 0.25473538351555663, 'Total loss': 0.25473538351555663}
2023-01-05 09:25:00,391 INFO:     Best model found after epoch 71 of 100.
2023-01-05 09:25:00,392 INFO:   Done with stage: TRAINING
2023-01-05 09:25:00,392 INFO:   Starting stage: EVALUATION
2023-01-05 09:25:00,536 INFO:   Done with stage: EVALUATION
2023-01-05 09:25:00,537 INFO:   Leaving out SEQ value Fold_9
2023-01-05 09:25:00,549 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 09:25:00,549 INFO:   Starting stage: FEATURE SCALING
2023-01-05 09:25:01,195 INFO:   Done with stage: FEATURE SCALING
2023-01-05 09:25:01,195 INFO:   Starting stage: SCALING TARGETS
2023-01-05 09:25:01,263 INFO:   Done with stage: SCALING TARGETS
2023-01-05 09:25:01,263 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:25:01,263 INFO:     No hyperparam tuning for this model
2023-01-05 09:25:01,263 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:25:01,263 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 09:25:01,264 INFO:     None feature selector for col prot
2023-01-05 09:25:01,264 INFO:     None feature selector for col prot
2023-01-05 09:25:01,264 INFO:     None feature selector for col prot
2023-01-05 09:25:01,264 INFO:     None feature selector for col chem
2023-01-05 09:25:01,265 INFO:     None feature selector for col chem
2023-01-05 09:25:01,265 INFO:     None feature selector for col chem
2023-01-05 09:25:01,265 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 09:25:01,265 INFO:   Starting stage: BUILD MODEL
2023-01-05 09:25:01,266 INFO:     Number of params in model 72901
2023-01-05 09:25:01,269 INFO:   Done with stage: BUILD MODEL
2023-01-05 09:25:01,269 INFO:   Starting stage: TRAINING
2023-01-05 09:25:01,330 INFO:     Val loss before train {'Reaction outcome loss': 0.9731259266535441, 'Total loss': 0.9731259266535441}
2023-01-05 09:25:01,330 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:25:01,330 INFO:     Epoch: 0
2023-01-05 09:25:03,421 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7649352431297303, 'Total loss': 0.7649352431297303} | train loss {'Reaction outcome loss': 0.9328253026241842, 'Total loss': 0.9328253026241842}
2023-01-05 09:25:03,422 INFO:     Found new best model at epoch 0
2023-01-05 09:25:03,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:25:03,423 INFO:     Epoch: 1
2023-01-05 09:25:05,540 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6200859347979227, 'Total loss': 0.6200859347979227} | train loss {'Reaction outcome loss': 0.7508128805463945, 'Total loss': 0.7508128805463945}
2023-01-05 09:25:05,540 INFO:     Found new best model at epoch 1
2023-01-05 09:25:05,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:25:05,541 INFO:     Epoch: 2
2023-01-05 09:25:07,657 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.4693952868382136, 'Total loss': 0.4693952868382136} | train loss {'Reaction outcome loss': 0.6031423879760331, 'Total loss': 0.6031423879760331}
2023-01-05 09:25:07,657 INFO:     Found new best model at epoch 2
2023-01-05 09:25:07,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:25:07,658 INFO:     Epoch: 3
2023-01-05 09:25:09,760 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.43363404671351113, 'Total loss': 0.43363404671351113} | train loss {'Reaction outcome loss': 0.5347570966983187, 'Total loss': 0.5347570966983187}
2023-01-05 09:25:09,761 INFO:     Found new best model at epoch 3
2023-01-05 09:25:09,762 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:25:09,762 INFO:     Epoch: 4
2023-01-05 09:25:11,865 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.43274224003156025, 'Total loss': 0.43274224003156025} | train loss {'Reaction outcome loss': 0.5529995177993956, 'Total loss': 0.5529995177993956}
2023-01-05 09:25:11,865 INFO:     Found new best model at epoch 4
2023-01-05 09:25:11,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:25:11,867 INFO:     Epoch: 5
2023-01-05 09:25:14,005 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.45254143079121906, 'Total loss': 0.45254143079121906} | train loss {'Reaction outcome loss': 0.50006128097142, 'Total loss': 0.50006128097142}
2023-01-05 09:25:14,005 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:25:14,005 INFO:     Epoch: 6
2023-01-05 09:25:16,124 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.42991953194141386, 'Total loss': 0.42991953194141386} | train loss {'Reaction outcome loss': 0.49407534165336564, 'Total loss': 0.49407534165336564}
2023-01-05 09:25:16,124 INFO:     Found new best model at epoch 6
2023-01-05 09:25:16,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:25:16,125 INFO:     Epoch: 7
2023-01-05 09:25:18,297 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4176884382963181, 'Total loss': 0.4176884382963181} | train loss {'Reaction outcome loss': 0.4889245176876801, 'Total loss': 0.4889245176876801}
2023-01-05 09:25:18,297 INFO:     Found new best model at epoch 7
2023-01-05 09:25:18,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:25:18,298 INFO:     Epoch: 8
2023-01-05 09:25:20,459 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.42464826901753744, 'Total loss': 0.42464826901753744} | train loss {'Reaction outcome loss': 0.4842460153006908, 'Total loss': 0.4842460153006908}
2023-01-05 09:25:20,459 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:25:20,459 INFO:     Epoch: 9
2023-01-05 09:25:22,596 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.43138480484485625, 'Total loss': 0.43138480484485625} | train loss {'Reaction outcome loss': 0.47002274294694263, 'Total loss': 0.47002274294694263}
2023-01-05 09:25:22,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:25:22,596 INFO:     Epoch: 10
2023-01-05 09:25:24,718 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4153327286243439, 'Total loss': 0.4153327286243439} | train loss {'Reaction outcome loss': 0.4653264699323251, 'Total loss': 0.4653264699323251}
2023-01-05 09:25:24,718 INFO:     Found new best model at epoch 10
2023-01-05 09:25:24,719 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:25:24,720 INFO:     Epoch: 11
2023-01-05 09:25:26,858 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4217802455027898, 'Total loss': 0.4217802455027898} | train loss {'Reaction outcome loss': 0.4623792529421115, 'Total loss': 0.4623792529421115}
2023-01-05 09:25:26,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:25:26,858 INFO:     Epoch: 12
2023-01-05 09:25:29,016 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.41170649727185565, 'Total loss': 0.41170649727185565} | train loss {'Reaction outcome loss': 0.4555444796923953, 'Total loss': 0.4555444796923953}
2023-01-05 09:25:29,016 INFO:     Found new best model at epoch 12
2023-01-05 09:25:29,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:25:29,017 INFO:     Epoch: 13
2023-01-05 09:25:31,147 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.42021863758563993, 'Total loss': 0.42021863758563993} | train loss {'Reaction outcome loss': 0.45319820558011153, 'Total loss': 0.45319820558011153}
2023-01-05 09:25:31,147 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:25:31,147 INFO:     Epoch: 14
2023-01-05 09:25:33,287 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.43828349908192954, 'Total loss': 0.43828349908192954} | train loss {'Reaction outcome loss': 0.4475251531795315, 'Total loss': 0.4475251531795315}
2023-01-05 09:25:33,287 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:25:33,287 INFO:     Epoch: 15
2023-01-05 09:25:35,398 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4345090667406718, 'Total loss': 0.4345090667406718} | train loss {'Reaction outcome loss': 0.44465020381967013, 'Total loss': 0.44465020381967013}
2023-01-05 09:25:35,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:25:35,398 INFO:     Epoch: 16
2023-01-05 09:25:37,509 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.39616556353867055, 'Total loss': 0.39616556353867055} | train loss {'Reaction outcome loss': 0.4399612524641165, 'Total loss': 0.4399612524641165}
2023-01-05 09:25:37,509 INFO:     Found new best model at epoch 16
2023-01-05 09:25:37,511 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:25:37,511 INFO:     Epoch: 17
2023-01-05 09:25:39,620 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4095526615778605, 'Total loss': 0.4095526615778605} | train loss {'Reaction outcome loss': 0.43761832860932837, 'Total loss': 0.43761832860932837}
2023-01-05 09:25:39,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:25:39,621 INFO:     Epoch: 18
2023-01-05 09:25:41,752 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.41358728110790255, 'Total loss': 0.41358728110790255} | train loss {'Reaction outcome loss': 0.43690115444875066, 'Total loss': 0.43690115444875066}
2023-01-05 09:25:41,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:25:41,752 INFO:     Epoch: 19
2023-01-05 09:25:43,884 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4320752531290054, 'Total loss': 0.4320752531290054} | train loss {'Reaction outcome loss': 0.44045485294275527, 'Total loss': 0.44045485294275527}
2023-01-05 09:25:43,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:25:43,885 INFO:     Epoch: 20
2023-01-05 09:25:46,016 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4046109467744827, 'Total loss': 0.4046109467744827} | train loss {'Reaction outcome loss': 0.4629471500984568, 'Total loss': 0.4629471500984568}
2023-01-05 09:25:46,016 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:25:46,017 INFO:     Epoch: 21
2023-01-05 09:25:48,144 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.40880170911550523, 'Total loss': 0.40880170911550523} | train loss {'Reaction outcome loss': 0.4531756386808727, 'Total loss': 0.4531756386808727}
2023-01-05 09:25:48,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:25:48,145 INFO:     Epoch: 22
2023-01-05 09:25:50,254 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4089419295390447, 'Total loss': 0.4089419295390447} | train loss {'Reaction outcome loss': 0.42360347876514215, 'Total loss': 0.42360347876514215}
2023-01-05 09:25:50,254 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:25:50,254 INFO:     Epoch: 23
2023-01-05 09:25:52,366 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.3924019545316696, 'Total loss': 0.3924019545316696} | train loss {'Reaction outcome loss': 0.4285377855885072, 'Total loss': 0.4285377855885072}
2023-01-05 09:25:52,366 INFO:     Found new best model at epoch 23
2023-01-05 09:25:52,367 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:25:52,367 INFO:     Epoch: 24
2023-01-05 09:25:54,477 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.40433346331119535, 'Total loss': 0.40433346331119535} | train loss {'Reaction outcome loss': 0.41806135562744556, 'Total loss': 0.41806135562744556}
2023-01-05 09:25:54,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:25:54,477 INFO:     Epoch: 25
2023-01-05 09:25:56,605 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.37634818255901337, 'Total loss': 0.37634818255901337} | train loss {'Reaction outcome loss': 0.41217898431806016, 'Total loss': 0.41217898431806016}
2023-01-05 09:25:56,605 INFO:     Found new best model at epoch 25
2023-01-05 09:25:56,606 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:25:56,606 INFO:     Epoch: 26
2023-01-05 09:25:58,736 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.42552992701530457, 'Total loss': 0.42552992701530457} | train loss {'Reaction outcome loss': 0.414411854268848, 'Total loss': 0.414411854268848}
2023-01-05 09:25:58,737 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:25:58,737 INFO:     Epoch: 27
2023-01-05 09:26:00,851 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.40488882760206857, 'Total loss': 0.40488882760206857} | train loss {'Reaction outcome loss': 0.4284519298521775, 'Total loss': 0.4284519298521775}
2023-01-05 09:26:00,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:26:00,851 INFO:     Epoch: 28
2023-01-05 09:26:02,781 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41293198664983116, 'Total loss': 0.41293198664983116} | train loss {'Reaction outcome loss': 0.4046417588395053, 'Total loss': 0.4046417588395053}
2023-01-05 09:26:02,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:26:02,781 INFO:     Epoch: 29
2023-01-05 09:26:04,891 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.37326493064562477, 'Total loss': 0.37326493064562477} | train loss {'Reaction outcome loss': 0.4021981730753475, 'Total loss': 0.4021981730753475}
2023-01-05 09:26:04,892 INFO:     Found new best model at epoch 29
2023-01-05 09:26:04,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:26:04,893 INFO:     Epoch: 30
2023-01-05 09:26:07,012 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.375803554058075, 'Total loss': 0.375803554058075} | train loss {'Reaction outcome loss': 0.40012076900651056, 'Total loss': 0.40012076900651056}
2023-01-05 09:26:07,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:26:07,012 INFO:     Epoch: 31
2023-01-05 09:26:09,162 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.376822766661644, 'Total loss': 0.376822766661644} | train loss {'Reaction outcome loss': 0.3923308830438317, 'Total loss': 0.3923308830438317}
2023-01-05 09:26:09,163 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:26:09,163 INFO:     Epoch: 32
2023-01-05 09:26:11,274 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.38124622603257496, 'Total loss': 0.38124622603257496} | train loss {'Reaction outcome loss': 0.39720733501556993, 'Total loss': 0.39720733501556993}
2023-01-05 09:26:11,274 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:26:11,274 INFO:     Epoch: 33
2023-01-05 09:26:13,392 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.3779438982407252, 'Total loss': 0.3779438982407252} | train loss {'Reaction outcome loss': 0.398859497608509, 'Total loss': 0.398859497608509}
2023-01-05 09:26:13,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:26:13,392 INFO:     Epoch: 34
2023-01-05 09:26:15,510 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.38718619545300803, 'Total loss': 0.38718619545300803} | train loss {'Reaction outcome loss': 0.3834098255246172, 'Total loss': 0.3834098255246172}
2023-01-05 09:26:15,512 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:26:15,512 INFO:     Epoch: 35
2023-01-05 09:26:17,670 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4026623179515203, 'Total loss': 0.4026623179515203} | train loss {'Reaction outcome loss': 0.3827148706962665, 'Total loss': 0.3827148706962665}
2023-01-05 09:26:17,670 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:26:17,670 INFO:     Epoch: 36
2023-01-05 09:26:19,825 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.38346890807151796, 'Total loss': 0.38346890807151796} | train loss {'Reaction outcome loss': 0.3815744113998717, 'Total loss': 0.3815744113998717}
2023-01-05 09:26:19,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:26:19,825 INFO:     Epoch: 37
2023-01-05 09:26:21,972 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.38067807952562965, 'Total loss': 0.38067807952562965} | train loss {'Reaction outcome loss': 0.3787135175172833, 'Total loss': 0.3787135175172833}
2023-01-05 09:26:21,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:26:21,973 INFO:     Epoch: 38
2023-01-05 09:26:24,114 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.36207406719525653, 'Total loss': 0.36207406719525653} | train loss {'Reaction outcome loss': 0.37810274185207876, 'Total loss': 0.37810274185207876}
2023-01-05 09:26:24,114 INFO:     Found new best model at epoch 38
2023-01-05 09:26:24,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:26:24,116 INFO:     Epoch: 39
2023-01-05 09:26:26,268 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4009120712677638, 'Total loss': 0.4009120712677638} | train loss {'Reaction outcome loss': 0.37315289174085076, 'Total loss': 0.37315289174085076}
2023-01-05 09:26:26,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:26:26,268 INFO:     Epoch: 40
2023-01-05 09:26:28,428 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.371148348848025, 'Total loss': 0.371148348848025} | train loss {'Reaction outcome loss': 0.3875784369529751, 'Total loss': 0.3875784369529751}
2023-01-05 09:26:28,428 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:26:28,428 INFO:     Epoch: 41
2023-01-05 09:26:30,580 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.36103904048601787, 'Total loss': 0.36103904048601787} | train loss {'Reaction outcome loss': 0.3684932984195758, 'Total loss': 0.3684932984195758}
2023-01-05 09:26:30,580 INFO:     Found new best model at epoch 41
2023-01-05 09:26:30,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:26:30,582 INFO:     Epoch: 42
2023-01-05 09:26:32,713 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38544738789399463, 'Total loss': 0.38544738789399463} | train loss {'Reaction outcome loss': 0.38900528695471026, 'Total loss': 0.38900528695471026}
2023-01-05 09:26:32,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:26:32,713 INFO:     Epoch: 43
2023-01-05 09:26:34,824 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.37691213799019657, 'Total loss': 0.37691213799019657} | train loss {'Reaction outcome loss': 0.3616401004327454, 'Total loss': 0.3616401004327454}
2023-01-05 09:26:34,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:26:34,825 INFO:     Epoch: 44
2023-01-05 09:26:36,945 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.36909990111986796, 'Total loss': 0.36909990111986796} | train loss {'Reaction outcome loss': 0.3587276081756717, 'Total loss': 0.3587276081756717}
2023-01-05 09:26:36,945 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:26:36,945 INFO:     Epoch: 45
2023-01-05 09:26:39,083 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41438696583112083, 'Total loss': 0.41438696583112083} | train loss {'Reaction outcome loss': 0.3613356275456971, 'Total loss': 0.3613356275456971}
2023-01-05 09:26:39,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:26:39,084 INFO:     Epoch: 46
2023-01-05 09:26:41,188 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4212518612543742, 'Total loss': 0.4212518612543742} | train loss {'Reaction outcome loss': 0.39795681518381054, 'Total loss': 0.39795681518381054}
2023-01-05 09:26:41,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:26:41,188 INFO:     Epoch: 47
2023-01-05 09:26:43,306 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40970208048820494, 'Total loss': 0.40970208048820494} | train loss {'Reaction outcome loss': 0.40575491314402956, 'Total loss': 0.40575491314402956}
2023-01-05 09:26:43,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:26:43,306 INFO:     Epoch: 48
2023-01-05 09:26:45,449 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38552214403947194, 'Total loss': 0.38552214403947194} | train loss {'Reaction outcome loss': 0.3583763043001375, 'Total loss': 0.3583763043001375}
2023-01-05 09:26:45,449 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:26:45,449 INFO:     Epoch: 49
2023-01-05 09:26:47,540 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.38686783015728, 'Total loss': 0.38686783015728} | train loss {'Reaction outcome loss': 0.3451636175893288, 'Total loss': 0.3451636175893288}
2023-01-05 09:26:47,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:26:47,540 INFO:     Epoch: 50
2023-01-05 09:26:49,645 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.39023477335770923, 'Total loss': 0.39023477335770923} | train loss {'Reaction outcome loss': 0.3378424443949041, 'Total loss': 0.3378424443949041}
2023-01-05 09:26:49,646 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:26:49,646 INFO:     Epoch: 51
2023-01-05 09:26:51,766 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.39328347345193226, 'Total loss': 0.39328347345193226} | train loss {'Reaction outcome loss': 0.3423582613721247, 'Total loss': 0.3423582613721247}
2023-01-05 09:26:51,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:26:51,766 INFO:     Epoch: 52
2023-01-05 09:26:53,874 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.391821426153183, 'Total loss': 0.391821426153183} | train loss {'Reaction outcome loss': 0.3351625565554823, 'Total loss': 0.3351625565554823}
2023-01-05 09:26:53,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:26:53,874 INFO:     Epoch: 53
2023-01-05 09:26:55,983 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.37983498970667523, 'Total loss': 0.37983498970667523} | train loss {'Reaction outcome loss': 0.32993742223524075, 'Total loss': 0.32993742223524075}
2023-01-05 09:26:55,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:26:55,984 INFO:     Epoch: 54
2023-01-05 09:26:58,103 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40328619281450906, 'Total loss': 0.40328619281450906} | train loss {'Reaction outcome loss': 0.3308471776055766, 'Total loss': 0.3308471776055766}
2023-01-05 09:26:58,103 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:26:58,103 INFO:     Epoch: 55
2023-01-05 09:27:00,266 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39625324606895446, 'Total loss': 0.39625324606895446} | train loss {'Reaction outcome loss': 0.356345194823824, 'Total loss': 0.356345194823824}
2023-01-05 09:27:00,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:27:00,266 INFO:     Epoch: 56
2023-01-05 09:27:02,408 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.37684201300144193, 'Total loss': 0.37684201300144193} | train loss {'Reaction outcome loss': 0.32898120605392067, 'Total loss': 0.32898120605392067}
2023-01-05 09:27:02,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:27:02,408 INFO:     Epoch: 57
2023-01-05 09:27:04,549 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3634302218755086, 'Total loss': 0.3634302218755086} | train loss {'Reaction outcome loss': 0.3236342782417879, 'Total loss': 0.3236342782417879}
2023-01-05 09:27:04,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:27:04,549 INFO:     Epoch: 58
2023-01-05 09:27:06,686 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.35875539084275565, 'Total loss': 0.35875539084275565} | train loss {'Reaction outcome loss': 0.321780482434615, 'Total loss': 0.321780482434615}
2023-01-05 09:27:06,686 INFO:     Found new best model at epoch 58
2023-01-05 09:27:06,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:27:06,687 INFO:     Epoch: 59
2023-01-05 09:27:08,780 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3948306192954381, 'Total loss': 0.3948306192954381} | train loss {'Reaction outcome loss': 0.31589547412959684, 'Total loss': 0.31589547412959684}
2023-01-05 09:27:08,780 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:27:08,781 INFO:     Epoch: 60
2023-01-05 09:27:10,884 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.36502687335014344, 'Total loss': 0.36502687335014344} | train loss {'Reaction outcome loss': 0.31847645209959213, 'Total loss': 0.31847645209959213}
2023-01-05 09:27:10,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:27:10,884 INFO:     Epoch: 61
2023-01-05 09:27:13,014 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3382401113708814, 'Total loss': 0.3382401113708814} | train loss {'Reaction outcome loss': 0.31844062505262916, 'Total loss': 0.31844062505262916}
2023-01-05 09:27:13,014 INFO:     Found new best model at epoch 61
2023-01-05 09:27:13,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:27:13,015 INFO:     Epoch: 62
2023-01-05 09:27:15,137 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.39142264425754547, 'Total loss': 0.39142264425754547} | train loss {'Reaction outcome loss': 0.3367383239482993, 'Total loss': 0.3367383239482993}
2023-01-05 09:27:15,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:27:15,137 INFO:     Epoch: 63
2023-01-05 09:27:17,268 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3445169225335121, 'Total loss': 0.3445169225335121} | train loss {'Reaction outcome loss': 0.31675567413828726, 'Total loss': 0.31675567413828726}
2023-01-05 09:27:17,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:27:17,268 INFO:     Epoch: 64
2023-01-05 09:27:19,389 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.42116779188315073, 'Total loss': 0.42116779188315073} | train loss {'Reaction outcome loss': 0.31420251538140187, 'Total loss': 0.31420251538140187}
2023-01-05 09:27:19,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:27:19,390 INFO:     Epoch: 65
2023-01-05 09:27:21,508 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3603570550680161, 'Total loss': 0.3603570550680161} | train loss {'Reaction outcome loss': 0.35063741352615063, 'Total loss': 0.35063741352615063}
2023-01-05 09:27:21,509 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:27:21,509 INFO:     Epoch: 66
2023-01-05 09:27:23,631 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.3718903144200643, 'Total loss': 0.3718903144200643} | train loss {'Reaction outcome loss': 0.3085812970294037, 'Total loss': 0.3085812970294037}
2023-01-05 09:27:23,631 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:27:23,631 INFO:     Epoch: 67
2023-01-05 09:27:25,764 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38628448943297067, 'Total loss': 0.38628448943297067} | train loss {'Reaction outcome loss': 0.29847982307552706, 'Total loss': 0.29847982307552706}
2023-01-05 09:27:25,765 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:27:25,765 INFO:     Epoch: 68
2023-01-05 09:27:27,868 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3545948912700017, 'Total loss': 0.3545948912700017} | train loss {'Reaction outcome loss': 0.3037582879778052, 'Total loss': 0.3037582879778052}
2023-01-05 09:27:27,868 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:27:27,868 INFO:     Epoch: 69
2023-01-05 09:27:29,992 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3706969584027926, 'Total loss': 0.3706969584027926} | train loss {'Reaction outcome loss': 0.2945648673072962, 'Total loss': 0.2945648673072962}
2023-01-05 09:27:29,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:27:29,993 INFO:     Epoch: 70
2023-01-05 09:27:32,124 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3810497423013051, 'Total loss': 0.3810497423013051} | train loss {'Reaction outcome loss': 0.2932970885130867, 'Total loss': 0.2932970885130867}
2023-01-05 09:27:32,124 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:27:32,125 INFO:     Epoch: 71
2023-01-05 09:27:34,222 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3838061451911926, 'Total loss': 0.3838061451911926} | train loss {'Reaction outcome loss': 0.2988894029682421, 'Total loss': 0.2988894029682421}
2023-01-05 09:27:34,222 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:27:34,222 INFO:     Epoch: 72
2023-01-05 09:27:36,346 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3692595486839612, 'Total loss': 0.3692595486839612} | train loss {'Reaction outcome loss': 0.2864519077187836, 'Total loss': 0.2864519077187836}
2023-01-05 09:27:36,346 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:27:36,346 INFO:     Epoch: 73
2023-01-05 09:27:38,470 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.3712487647930781, 'Total loss': 0.3712487647930781} | train loss {'Reaction outcome loss': 0.2918782887429478, 'Total loss': 0.2918782887429478}
2023-01-05 09:27:38,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:27:38,470 INFO:     Epoch: 74
2023-01-05 09:27:40,605 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.348116268714269, 'Total loss': 0.348116268714269} | train loss {'Reaction outcome loss': 0.28898047555686796, 'Total loss': 0.28898047555686796}
2023-01-05 09:27:40,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:27:40,606 INFO:     Epoch: 75
2023-01-05 09:27:42,732 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3775727540254593, 'Total loss': 0.3775727540254593} | train loss {'Reaction outcome loss': 0.2881671639152573, 'Total loss': 0.2881671639152573}
2023-01-05 09:27:42,733 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:27:42,733 INFO:     Epoch: 76
2023-01-05 09:27:44,829 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.34659038335084913, 'Total loss': 0.34659038335084913} | train loss {'Reaction outcome loss': 0.2859160487904497, 'Total loss': 0.2859160487904497}
2023-01-05 09:27:44,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:27:44,829 INFO:     Epoch: 77
2023-01-05 09:27:46,982 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3905004382133484, 'Total loss': 0.3905004382133484} | train loss {'Reaction outcome loss': 0.2831179082353154, 'Total loss': 0.2831179082353154}
2023-01-05 09:27:46,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:27:46,982 INFO:     Epoch: 78
2023-01-05 09:27:49,085 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.38466467907031376, 'Total loss': 0.38466467907031376} | train loss {'Reaction outcome loss': 0.28451112892619584, 'Total loss': 0.28451112892619584}
2023-01-05 09:27:49,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:27:49,085 INFO:     Epoch: 79
2023-01-05 09:27:51,216 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3724534740050634, 'Total loss': 0.3724534740050634} | train loss {'Reaction outcome loss': 0.28196591846442415, 'Total loss': 0.28196591846442415}
2023-01-05 09:27:51,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:27:51,216 INFO:     Epoch: 80
2023-01-05 09:27:53,335 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3487951397895813, 'Total loss': 0.3487951397895813} | train loss {'Reaction outcome loss': 0.2757014973946186, 'Total loss': 0.2757014973946186}
2023-01-05 09:27:53,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:27:53,335 INFO:     Epoch: 81
2023-01-05 09:27:55,451 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3684648111462593, 'Total loss': 0.3684648111462593} | train loss {'Reaction outcome loss': 0.2826042206214734, 'Total loss': 0.2826042206214734}
2023-01-05 09:27:55,452 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:27:55,452 INFO:     Epoch: 82
2023-01-05 09:27:57,558 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.351804581284523, 'Total loss': 0.351804581284523} | train loss {'Reaction outcome loss': 0.27594838965307933, 'Total loss': 0.27594838965307933}
2023-01-05 09:27:57,558 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:27:57,558 INFO:     Epoch: 83
2023-01-05 09:27:59,673 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3712550441424052, 'Total loss': 0.3712550441424052} | train loss {'Reaction outcome loss': 0.2757684643139077, 'Total loss': 0.2757684643139077}
2023-01-05 09:27:59,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:27:59,674 INFO:     Epoch: 84
2023-01-05 09:28:01,798 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.33315465847651166, 'Total loss': 0.33315465847651166} | train loss {'Reaction outcome loss': 0.2730032633975287, 'Total loss': 0.2730032633975287}
2023-01-05 09:28:01,799 INFO:     Found new best model at epoch 84
2023-01-05 09:28:01,800 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:28:01,800 INFO:     Epoch: 85
2023-01-05 09:28:03,960 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3619453489780426, 'Total loss': 0.3619453489780426} | train loss {'Reaction outcome loss': 0.2754943898247987, 'Total loss': 0.2754943898247987}
2023-01-05 09:28:03,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:28:03,961 INFO:     Epoch: 86
2023-01-05 09:28:06,073 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.36652744735280673, 'Total loss': 0.36652744735280673} | train loss {'Reaction outcome loss': 0.2710328932473625, 'Total loss': 0.2710328932473625}
2023-01-05 09:28:06,073 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:28:06,074 INFO:     Epoch: 87
2023-01-05 09:28:08,181 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.36622295280297595, 'Total loss': 0.36622295280297595} | train loss {'Reaction outcome loss': 0.2637115267254716, 'Total loss': 0.2637115267254716}
2023-01-05 09:28:08,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:28:08,182 INFO:     Epoch: 88
2023-01-05 09:28:10,281 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3645405804117521, 'Total loss': 0.3645405804117521} | train loss {'Reaction outcome loss': 0.2725097931174062, 'Total loss': 0.2725097931174062}
2023-01-05 09:28:10,281 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:28:10,281 INFO:     Epoch: 89
2023-01-05 09:28:12,406 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3793593794107437, 'Total loss': 0.3793593794107437} | train loss {'Reaction outcome loss': 0.2620491146319208, 'Total loss': 0.2620491146319208}
2023-01-05 09:28:12,406 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:28:12,406 INFO:     Epoch: 90
2023-01-05 09:28:14,522 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.36070206413666406, 'Total loss': 0.36070206413666406} | train loss {'Reaction outcome loss': 0.26264432971483853, 'Total loss': 0.26264432971483853}
2023-01-05 09:28:14,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:28:14,522 INFO:     Epoch: 91
2023-01-05 09:28:16,643 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.36356980303923286, 'Total loss': 0.36356980303923286} | train loss {'Reaction outcome loss': 0.2661673506937813, 'Total loss': 0.2661673506937813}
2023-01-05 09:28:16,643 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:28:16,644 INFO:     Epoch: 92
2023-01-05 09:28:18,758 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3783909489711126, 'Total loss': 0.3783909489711126} | train loss {'Reaction outcome loss': 0.26134479290319007, 'Total loss': 0.26134479290319007}
2023-01-05 09:28:18,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:28:18,758 INFO:     Epoch: 93
2023-01-05 09:28:20,853 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.3853682180245717, 'Total loss': 0.3853682180245717} | train loss {'Reaction outcome loss': 0.26404025410706905, 'Total loss': 0.26404025410706905}
2023-01-05 09:28:20,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:28:20,854 INFO:     Epoch: 94
2023-01-05 09:28:22,979 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.35965761144955954, 'Total loss': 0.35965761144955954} | train loss {'Reaction outcome loss': 0.2656814377717809, 'Total loss': 0.2656814377717809}
2023-01-05 09:28:22,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:28:22,979 INFO:     Epoch: 95
2023-01-05 09:28:25,159 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.38036707242329915, 'Total loss': 0.38036707242329915} | train loss {'Reaction outcome loss': 0.26214245936084213, 'Total loss': 0.26214245936084213}
2023-01-05 09:28:25,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:28:25,159 INFO:     Epoch: 96
2023-01-05 09:28:27,307 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3823209551473459, 'Total loss': 0.3823209551473459} | train loss {'Reaction outcome loss': 0.2680646381948305, 'Total loss': 0.2680646381948305}
2023-01-05 09:28:27,308 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:28:27,308 INFO:     Epoch: 97
2023-01-05 09:28:29,450 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.364029527703921, 'Total loss': 0.364029527703921} | train loss {'Reaction outcome loss': 0.29926846090086695, 'Total loss': 0.29926846090086695}
2023-01-05 09:28:29,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:28:29,451 INFO:     Epoch: 98
2023-01-05 09:28:31,585 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.37098894864320753, 'Total loss': 0.37098894864320753} | train loss {'Reaction outcome loss': 0.2643134352800163, 'Total loss': 0.2643134352800163}
2023-01-05 09:28:31,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:28:31,586 INFO:     Epoch: 99
2023-01-05 09:28:33,706 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3302956958611806, 'Total loss': 0.3302956958611806} | train loss {'Reaction outcome loss': 0.25780985749704577, 'Total loss': 0.25780985749704577}
2023-01-05 09:28:33,706 INFO:     Found new best model at epoch 99
2023-01-05 09:28:33,707 INFO:     Best model found after epoch 100 of 100.
2023-01-05 09:28:33,707 INFO:   Done with stage: TRAINING
2023-01-05 09:28:33,707 INFO:   Starting stage: EVALUATION
2023-01-05 09:28:33,840 INFO:   Done with stage: EVALUATION
2023-01-05 09:28:33,848 INFO:   Leaving out SEQ value Fold_0
2023-01-05 09:28:33,861 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 09:28:33,861 INFO:   Starting stage: FEATURE SCALING
2023-01-05 09:28:34,509 INFO:   Done with stage: FEATURE SCALING
2023-01-05 09:28:34,509 INFO:   Starting stage: SCALING TARGETS
2023-01-05 09:28:34,577 INFO:   Done with stage: SCALING TARGETS
2023-01-05 09:28:34,577 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:28:34,577 INFO:     No hyperparam tuning for this model
2023-01-05 09:28:34,577 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:28:34,578 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 09:28:34,578 INFO:     None feature selector for col prot
2023-01-05 09:28:34,578 INFO:     None feature selector for col prot
2023-01-05 09:28:34,578 INFO:     None feature selector for col prot
2023-01-05 09:28:34,579 INFO:     None feature selector for col chem
2023-01-05 09:28:34,579 INFO:     None feature selector for col chem
2023-01-05 09:28:34,579 INFO:     None feature selector for col chem
2023-01-05 09:28:34,579 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 09:28:34,579 INFO:   Starting stage: BUILD MODEL
2023-01-05 09:28:34,581 INFO:     Number of params in model 72901
2023-01-05 09:28:34,584 INFO:   Done with stage: BUILD MODEL
2023-01-05 09:28:34,584 INFO:   Starting stage: TRAINING
2023-01-05 09:28:34,642 INFO:     Val loss before train {'Reaction outcome loss': 1.0873199780782064, 'Total loss': 1.0873199780782064}
2023-01-05 09:28:34,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:28:34,642 INFO:     Epoch: 0
2023-01-05 09:28:36,765 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8879499197006225, 'Total loss': 0.8879499197006225} | train loss {'Reaction outcome loss': 0.9301424196151935, 'Total loss': 0.9301424196151935}
2023-01-05 09:28:36,765 INFO:     Found new best model at epoch 0
2023-01-05 09:28:36,766 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:28:36,766 INFO:     Epoch: 1
2023-01-05 09:28:38,952 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6062866687774658, 'Total loss': 0.6062866687774658} | train loss {'Reaction outcome loss': 0.7420911219078994, 'Total loss': 0.7420911219078994}
2023-01-05 09:28:38,953 INFO:     Found new best model at epoch 1
2023-01-05 09:28:38,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:28:38,954 INFO:     Epoch: 2
2023-01-05 09:28:41,166 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5102294643719991, 'Total loss': 0.5102294643719991} | train loss {'Reaction outcome loss': 0.5786329167692558, 'Total loss': 0.5786329167692558}
2023-01-05 09:28:41,166 INFO:     Found new best model at epoch 2
2023-01-05 09:28:41,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:28:41,167 INFO:     Epoch: 3
2023-01-05 09:28:43,312 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5006626009941101, 'Total loss': 0.5006626009941101} | train loss {'Reaction outcome loss': 0.5360017137473746, 'Total loss': 0.5360017137473746}
2023-01-05 09:28:43,312 INFO:     Found new best model at epoch 3
2023-01-05 09:28:43,313 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:28:43,313 INFO:     Epoch: 4
2023-01-05 09:28:45,467 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4654018213351568, 'Total loss': 0.4654018213351568} | train loss {'Reaction outcome loss': 0.5145803026423075, 'Total loss': 0.5145803026423075}
2023-01-05 09:28:45,467 INFO:     Found new best model at epoch 4
2023-01-05 09:28:45,469 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:28:45,469 INFO:     Epoch: 5
2023-01-05 09:28:47,610 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4820684254169464, 'Total loss': 0.4820684254169464} | train loss {'Reaction outcome loss': 0.5092819460412062, 'Total loss': 0.5092819460412062}
2023-01-05 09:28:47,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:28:47,610 INFO:     Epoch: 6
2023-01-05 09:28:49,752 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4728533824284871, 'Total loss': 0.4728533824284871} | train loss {'Reaction outcome loss': 0.49349535348406737, 'Total loss': 0.49349535348406737}
2023-01-05 09:28:49,752 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:28:49,752 INFO:     Epoch: 7
2023-01-05 09:28:51,902 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4560359934965769, 'Total loss': 0.4560359934965769} | train loss {'Reaction outcome loss': 0.48794843693958945, 'Total loss': 0.48794843693958945}
2023-01-05 09:28:51,902 INFO:     Found new best model at epoch 7
2023-01-05 09:28:51,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:28:51,904 INFO:     Epoch: 8
2023-01-05 09:28:54,045 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.45576500793298086, 'Total loss': 0.45576500793298086} | train loss {'Reaction outcome loss': 0.47868582868165727, 'Total loss': 0.47868582868165727}
2023-01-05 09:28:54,045 INFO:     Found new best model at epoch 8
2023-01-05 09:28:54,046 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:28:54,046 INFO:     Epoch: 9
2023-01-05 09:28:56,184 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4630200127760569, 'Total loss': 0.4630200127760569} | train loss {'Reaction outcome loss': 0.4671984540325576, 'Total loss': 0.4671984540325576}
2023-01-05 09:28:56,184 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:28:56,184 INFO:     Epoch: 10
2023-01-05 09:28:58,341 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4596776723861694, 'Total loss': 0.4596776723861694} | train loss {'Reaction outcome loss': 0.469532779937583, 'Total loss': 0.469532779937583}
2023-01-05 09:28:58,342 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:28:58,342 INFO:     Epoch: 11
2023-01-05 09:29:00,497 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.454546132683754, 'Total loss': 0.454546132683754} | train loss {'Reaction outcome loss': 0.45515053861400584, 'Total loss': 0.45515053861400584}
2023-01-05 09:29:00,497 INFO:     Found new best model at epoch 11
2023-01-05 09:29:00,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:29:00,498 INFO:     Epoch: 12
2023-01-05 09:29:02,622 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.45434902906417846, 'Total loss': 0.45434902906417846} | train loss {'Reaction outcome loss': 0.4490014055146552, 'Total loss': 0.4490014055146552}
2023-01-05 09:29:02,622 INFO:     Found new best model at epoch 12
2023-01-05 09:29:02,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:29:02,623 INFO:     Epoch: 13
2023-01-05 09:29:04,768 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4544108663996061, 'Total loss': 0.4544108663996061} | train loss {'Reaction outcome loss': 0.4523769445629601, 'Total loss': 0.4523769445629601}
2023-01-05 09:29:04,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:29:04,768 INFO:     Epoch: 14
2023-01-05 09:29:06,907 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4604780395825704, 'Total loss': 0.4604780395825704} | train loss {'Reaction outcome loss': 0.4450893425517648, 'Total loss': 0.4450893425517648}
2023-01-05 09:29:06,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:29:06,907 INFO:     Epoch: 15
2023-01-05 09:29:09,035 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.48203614056110383, 'Total loss': 0.48203614056110383} | train loss {'Reaction outcome loss': 0.4414658454125342, 'Total loss': 0.4414658454125342}
2023-01-05 09:29:09,036 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:29:09,036 INFO:     Epoch: 16
2023-01-05 09:29:11,166 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4383533378442129, 'Total loss': 0.4383533378442129} | train loss {'Reaction outcome loss': 0.44051183188550064, 'Total loss': 0.44051183188550064}
2023-01-05 09:29:11,166 INFO:     Found new best model at epoch 16
2023-01-05 09:29:11,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:29:11,167 INFO:     Epoch: 17
2023-01-05 09:29:13,323 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4429820954799652, 'Total loss': 0.4429820954799652} | train loss {'Reaction outcome loss': 0.44072806187297986, 'Total loss': 0.44072806187297986}
2023-01-05 09:29:13,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:29:13,324 INFO:     Epoch: 18
2023-01-05 09:29:15,466 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5261256158351898, 'Total loss': 0.5261256158351898} | train loss {'Reaction outcome loss': 0.5593690740288761, 'Total loss': 0.5593690740288761}
2023-01-05 09:29:15,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:29:15,467 INFO:     Epoch: 19
2023-01-05 09:29:17,593 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5047664195299149, 'Total loss': 0.5047664195299149} | train loss {'Reaction outcome loss': 0.5302251792998741, 'Total loss': 0.5302251792998741}
2023-01-05 09:29:17,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:29:17,593 INFO:     Epoch: 20
2023-01-05 09:29:19,723 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.5108136971791585, 'Total loss': 0.5108136971791585} | train loss {'Reaction outcome loss': 0.5190521513746269, 'Total loss': 0.5190521513746269}
2023-01-05 09:29:19,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:29:19,723 INFO:     Epoch: 21
2023-01-05 09:29:21,858 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4857662240664164, 'Total loss': 0.4857662240664164} | train loss {'Reaction outcome loss': 0.5089352708149607, 'Total loss': 0.5089352708149607}
2023-01-05 09:29:21,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:29:21,859 INFO:     Epoch: 22
2023-01-05 09:29:23,979 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.49950272440910337, 'Total loss': 0.49950272440910337} | train loss {'Reaction outcome loss': 0.5073661727533825, 'Total loss': 0.5073661727533825}
2023-01-05 09:29:23,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:29:23,979 INFO:     Epoch: 23
2023-01-05 09:29:26,077 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.48807975351810456, 'Total loss': 0.48807975351810456} | train loss {'Reaction outcome loss': 0.48091058460050734, 'Total loss': 0.48091058460050734}
2023-01-05 09:29:26,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:29:26,078 INFO:     Epoch: 24
2023-01-05 09:29:28,196 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.46725009282430013, 'Total loss': 0.46725009282430013} | train loss {'Reaction outcome loss': 0.471441761766007, 'Total loss': 0.471441761766007}
2023-01-05 09:29:28,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:29:28,197 INFO:     Epoch: 25
2023-01-05 09:29:30,343 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.45462371011575065, 'Total loss': 0.45462371011575065} | train loss {'Reaction outcome loss': 0.4811619339558039, 'Total loss': 0.4811619339558039}
2023-01-05 09:29:30,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:29:30,343 INFO:     Epoch: 26
2023-01-05 09:29:32,469 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.45321389883756635, 'Total loss': 0.45321389883756635} | train loss {'Reaction outcome loss': 0.4550294882239963, 'Total loss': 0.4550294882239963}
2023-01-05 09:29:32,470 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:29:32,470 INFO:     Epoch: 27
2023-01-05 09:29:34,623 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4548757533232371, 'Total loss': 0.4548757533232371} | train loss {'Reaction outcome loss': 0.4443556321911392, 'Total loss': 0.4443556321911392}
2023-01-05 09:29:34,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:29:34,623 INFO:     Epoch: 28
2023-01-05 09:29:36,757 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4463937630256017, 'Total loss': 0.4463937630256017} | train loss {'Reaction outcome loss': 0.442974271099429, 'Total loss': 0.442974271099429}
2023-01-05 09:29:36,757 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:29:36,757 INFO:     Epoch: 29
2023-01-05 09:29:38,900 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4367784559726715, 'Total loss': 0.4367784559726715} | train loss {'Reaction outcome loss': 0.43884311314078345, 'Total loss': 0.43884311314078345}
2023-01-05 09:29:38,901 INFO:     Found new best model at epoch 29
2023-01-05 09:29:38,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:29:38,902 INFO:     Epoch: 30
2023-01-05 09:29:41,014 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4328743785619736, 'Total loss': 0.4328743785619736} | train loss {'Reaction outcome loss': 0.43093336744071997, 'Total loss': 0.43093336744071997}
2023-01-05 09:29:41,014 INFO:     Found new best model at epoch 30
2023-01-05 09:29:41,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:29:41,016 INFO:     Epoch: 31
2023-01-05 09:29:43,170 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4474668751160304, 'Total loss': 0.4474668751160304} | train loss {'Reaction outcome loss': 0.42680025506474456, 'Total loss': 0.42680025506474456}
2023-01-05 09:29:43,170 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:29:43,170 INFO:     Epoch: 32
2023-01-05 09:29:45,340 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.46351101994514465, 'Total loss': 0.46351101994514465} | train loss {'Reaction outcome loss': 0.4143517252624683, 'Total loss': 0.4143517252624683}
2023-01-05 09:29:45,341 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:29:45,341 INFO:     Epoch: 33
2023-01-05 09:29:47,536 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.42641018430391947, 'Total loss': 0.42641018430391947} | train loss {'Reaction outcome loss': 0.41375887491679536, 'Total loss': 0.41375887491679536}
2023-01-05 09:29:47,536 INFO:     Found new best model at epoch 33
2023-01-05 09:29:47,537 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:29:47,537 INFO:     Epoch: 34
2023-01-05 09:29:49,665 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4693657437960307, 'Total loss': 0.4693657437960307} | train loss {'Reaction outcome loss': 0.40698211094486003, 'Total loss': 0.40698211094486003}
2023-01-05 09:29:49,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:29:49,665 INFO:     Epoch: 35
2023-01-05 09:29:51,815 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4509865939617157, 'Total loss': 0.4509865939617157} | train loss {'Reaction outcome loss': 0.40708130880839366, 'Total loss': 0.40708130880839366}
2023-01-05 09:29:51,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:29:51,815 INFO:     Epoch: 36
2023-01-05 09:29:53,921 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4442074477672577, 'Total loss': 0.4442074477672577} | train loss {'Reaction outcome loss': 0.3978162784655781, 'Total loss': 0.3978162784655781}
2023-01-05 09:29:53,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:29:53,921 INFO:     Epoch: 37
2023-01-05 09:29:56,041 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.45112425486246743, 'Total loss': 0.45112425486246743} | train loss {'Reaction outcome loss': 0.3911407620416603, 'Total loss': 0.3911407620416603}
2023-01-05 09:29:56,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:29:56,041 INFO:     Epoch: 38
2023-01-05 09:29:58,148 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.4269828935464223, 'Total loss': 0.4269828935464223} | train loss {'Reaction outcome loss': 0.39051853295877925, 'Total loss': 0.39051853295877925}
2023-01-05 09:29:58,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:29:58,149 INFO:     Epoch: 39
2023-01-05 09:30:00,257 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.42855739990870156, 'Total loss': 0.42855739990870156} | train loss {'Reaction outcome loss': 0.37820253571650636, 'Total loss': 0.37820253571650636}
2023-01-05 09:30:00,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:30:00,258 INFO:     Epoch: 40
2023-01-05 09:30:02,193 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.44292661249637605, 'Total loss': 0.44292661249637605} | train loss {'Reaction outcome loss': 0.3796852520410565, 'Total loss': 0.3796852520410565}
2023-01-05 09:30:02,193 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:30:02,193 INFO:     Epoch: 41
2023-01-05 09:30:04,288 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4227507253487905, 'Total loss': 0.4227507253487905} | train loss {'Reaction outcome loss': 0.3755651422096349, 'Total loss': 0.3755651422096349}
2023-01-05 09:30:04,289 INFO:     Found new best model at epoch 41
2023-01-05 09:30:04,290 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:30:04,290 INFO:     Epoch: 42
2023-01-05 09:30:06,409 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4102728346983592, 'Total loss': 0.4102728346983592} | train loss {'Reaction outcome loss': 0.37631159405345505, 'Total loss': 0.37631159405345505}
2023-01-05 09:30:06,409 INFO:     Found new best model at epoch 42
2023-01-05 09:30:06,410 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:30:06,410 INFO:     Epoch: 43
2023-01-05 09:30:08,516 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41706449488798775, 'Total loss': 0.41706449488798775} | train loss {'Reaction outcome loss': 0.3726091545270891, 'Total loss': 0.3726091545270891}
2023-01-05 09:30:08,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:30:08,516 INFO:     Epoch: 44
2023-01-05 09:30:10,621 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4349810073773066, 'Total loss': 0.4349810073773066} | train loss {'Reaction outcome loss': 0.360687225129948, 'Total loss': 0.360687225129948}
2023-01-05 09:30:10,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:30:10,622 INFO:     Epoch: 45
2023-01-05 09:30:12,724 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4272487640380859, 'Total loss': 0.4272487640380859} | train loss {'Reaction outcome loss': 0.3591370561326334, 'Total loss': 0.3591370561326334}
2023-01-05 09:30:12,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:30:12,725 INFO:     Epoch: 46
2023-01-05 09:30:14,835 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44936605989933015, 'Total loss': 0.44936605989933015} | train loss {'Reaction outcome loss': 0.35600968728354876, 'Total loss': 0.35600968728354876}
2023-01-05 09:30:14,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:30:14,837 INFO:     Epoch: 47
2023-01-05 09:30:16,972 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4153599133094152, 'Total loss': 0.4153599133094152} | train loss {'Reaction outcome loss': 0.3805452322459145, 'Total loss': 0.3805452322459145}
2023-01-05 09:30:16,972 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:30:16,972 INFO:     Epoch: 48
2023-01-05 09:30:19,100 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.45810763637224833, 'Total loss': 0.45810763637224833} | train loss {'Reaction outcome loss': 0.3580436020603646, 'Total loss': 0.3580436020603646}
2023-01-05 09:30:19,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:30:19,101 INFO:     Epoch: 49
2023-01-05 09:30:21,239 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.44438115855058036, 'Total loss': 0.44438115855058036} | train loss {'Reaction outcome loss': 0.3486518645743448, 'Total loss': 0.3486518645743448}
2023-01-05 09:30:21,240 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:30:21,240 INFO:     Epoch: 50
2023-01-05 09:30:23,401 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.43852876623471576, 'Total loss': 0.43852876623471576} | train loss {'Reaction outcome loss': 0.34462234185522667, 'Total loss': 0.34462234185522667}
2023-01-05 09:30:23,401 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:30:23,402 INFO:     Epoch: 51
2023-01-05 09:30:25,537 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4082440515359243, 'Total loss': 0.4082440515359243} | train loss {'Reaction outcome loss': 0.33872776092502516, 'Total loss': 0.33872776092502516}
2023-01-05 09:30:25,537 INFO:     Found new best model at epoch 51
2023-01-05 09:30:25,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:30:25,538 INFO:     Epoch: 52
2023-01-05 09:30:27,709 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44100206593672436, 'Total loss': 0.44100206593672436} | train loss {'Reaction outcome loss': 0.34288969887015613, 'Total loss': 0.34288969887015613}
2023-01-05 09:30:27,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:30:27,709 INFO:     Epoch: 53
2023-01-05 09:30:29,859 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.45889636675516765, 'Total loss': 0.45889636675516765} | train loss {'Reaction outcome loss': 0.3852996242408087, 'Total loss': 0.3852996242408087}
2023-01-05 09:30:29,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:30:29,859 INFO:     Epoch: 54
2023-01-05 09:30:31,988 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.5271349847316742, 'Total loss': 0.5271349847316742} | train loss {'Reaction outcome loss': 0.46382975907729723, 'Total loss': 0.46382975907729723}
2023-01-05 09:30:31,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:30:31,988 INFO:     Epoch: 55
2023-01-05 09:30:34,126 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4987658520539602, 'Total loss': 0.4987658520539602} | train loss {'Reaction outcome loss': 0.4204014925991243, 'Total loss': 0.4204014925991243}
2023-01-05 09:30:34,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:30:34,127 INFO:     Epoch: 56
2023-01-05 09:30:36,268 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.48049615422884623, 'Total loss': 0.48049615422884623} | train loss {'Reaction outcome loss': 0.40053978860648215, 'Total loss': 0.40053978860648215}
2023-01-05 09:30:36,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:30:36,268 INFO:     Epoch: 57
2023-01-05 09:30:38,381 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.45084501802921295, 'Total loss': 0.45084501802921295} | train loss {'Reaction outcome loss': 0.3874399332950513, 'Total loss': 0.3874399332950513}
2023-01-05 09:30:38,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:30:38,382 INFO:     Epoch: 58
2023-01-05 09:30:40,508 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4948139568169912, 'Total loss': 0.4948139568169912} | train loss {'Reaction outcome loss': 0.42872640962773206, 'Total loss': 0.42872640962773206}
2023-01-05 09:30:40,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:30:40,508 INFO:     Epoch: 59
2023-01-05 09:30:42,629 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4826384613911311, 'Total loss': 0.4826384613911311} | train loss {'Reaction outcome loss': 0.37408303293278033, 'Total loss': 0.37408303293278033}
2023-01-05 09:30:42,629 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:30:42,629 INFO:     Epoch: 60
2023-01-05 09:30:44,758 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.43096005817254385, 'Total loss': 0.43096005817254385} | train loss {'Reaction outcome loss': 0.3614797250408193, 'Total loss': 0.3614797250408193}
2023-01-05 09:30:44,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:30:44,758 INFO:     Epoch: 61
2023-01-05 09:30:46,879 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4443775812784831, 'Total loss': 0.4443775812784831} | train loss {'Reaction outcome loss': 0.35006788914240355, 'Total loss': 0.35006788914240355}
2023-01-05 09:30:46,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:30:46,879 INFO:     Epoch: 62
2023-01-05 09:30:48,986 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.40683580885330833, 'Total loss': 0.40683580885330833} | train loss {'Reaction outcome loss': 0.34236750993928267, 'Total loss': 0.34236750993928267}
2023-01-05 09:30:48,986 INFO:     Found new best model at epoch 62
2023-01-05 09:30:48,988 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:30:48,988 INFO:     Epoch: 63
2023-01-05 09:30:51,114 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3962000240882238, 'Total loss': 0.3962000240882238} | train loss {'Reaction outcome loss': 0.3293897320340941, 'Total loss': 0.3293897320340941}
2023-01-05 09:30:51,115 INFO:     Found new best model at epoch 63
2023-01-05 09:30:51,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:30:51,116 INFO:     Epoch: 64
2023-01-05 09:30:53,259 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4369806110858917, 'Total loss': 0.4369806110858917} | train loss {'Reaction outcome loss': 0.32588643628590996, 'Total loss': 0.32588643628590996}
2023-01-05 09:30:53,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:30:53,259 INFO:     Epoch: 65
2023-01-05 09:30:55,442 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.40570255120595294, 'Total loss': 0.40570255120595294} | train loss {'Reaction outcome loss': 0.34567381876210374, 'Total loss': 0.34567381876210374}
2023-01-05 09:30:55,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:30:55,442 INFO:     Epoch: 66
2023-01-05 09:30:57,592 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4140009433031082, 'Total loss': 0.4140009433031082} | train loss {'Reaction outcome loss': 0.33022680287789286, 'Total loss': 0.33022680287789286}
2023-01-05 09:30:57,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:30:57,593 INFO:     Epoch: 67
2023-01-05 09:30:59,738 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.42804829478263856, 'Total loss': 0.42804829478263856} | train loss {'Reaction outcome loss': 0.32520308715385804, 'Total loss': 0.32520308715385804}
2023-01-05 09:30:59,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:30:59,738 INFO:     Epoch: 68
2023-01-05 09:31:01,862 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.40008547306060793, 'Total loss': 0.40008547306060793} | train loss {'Reaction outcome loss': 0.3456258334023743, 'Total loss': 0.3456258334023743}
2023-01-05 09:31:01,863 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:31:01,863 INFO:     Epoch: 69
2023-01-05 09:31:03,979 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4057626416285833, 'Total loss': 0.4057626416285833} | train loss {'Reaction outcome loss': 0.32777233296276437, 'Total loss': 0.32777233296276437}
2023-01-05 09:31:03,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:31:03,979 INFO:     Epoch: 70
2023-01-05 09:31:06,134 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.410993500550588, 'Total loss': 0.410993500550588} | train loss {'Reaction outcome loss': 0.3095257501725269, 'Total loss': 0.3095257501725269}
2023-01-05 09:31:06,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:31:06,134 INFO:     Epoch: 71
2023-01-05 09:31:08,245 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3974437942107519, 'Total loss': 0.3974437942107519} | train loss {'Reaction outcome loss': 0.31008684184116253, 'Total loss': 0.31008684184116253}
2023-01-05 09:31:08,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:31:08,246 INFO:     Epoch: 72
2023-01-05 09:31:10,379 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.40493934551874794, 'Total loss': 0.40493934551874794} | train loss {'Reaction outcome loss': 0.3144319037728828, 'Total loss': 0.3144319037728828}
2023-01-05 09:31:10,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:31:10,380 INFO:     Epoch: 73
2023-01-05 09:31:12,492 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4235704441865285, 'Total loss': 0.4235704441865285} | train loss {'Reaction outcome loss': 0.298058686783749, 'Total loss': 0.298058686783749}
2023-01-05 09:31:12,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:31:12,493 INFO:     Epoch: 74
2023-01-05 09:31:14,594 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.40212534070014955, 'Total loss': 0.40212534070014955} | train loss {'Reaction outcome loss': 0.29999554081861285, 'Total loss': 0.29999554081861285}
2023-01-05 09:31:14,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:31:14,594 INFO:     Epoch: 75
2023-01-05 09:31:16,728 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4047861417134603, 'Total loss': 0.4047861417134603} | train loss {'Reaction outcome loss': 0.30165517821602617, 'Total loss': 0.30165517821602617}
2023-01-05 09:31:16,728 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:31:16,728 INFO:     Epoch: 76
2023-01-05 09:31:18,891 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.39194006423155464, 'Total loss': 0.39194006423155464} | train loss {'Reaction outcome loss': 0.30377680381787, 'Total loss': 0.30377680381787}
2023-01-05 09:31:18,891 INFO:     Found new best model at epoch 76
2023-01-05 09:31:18,892 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:31:18,892 INFO:     Epoch: 77
2023-01-05 09:31:21,046 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3891842722892761, 'Total loss': 0.3891842722892761} | train loss {'Reaction outcome loss': 0.29655556585909665, 'Total loss': 0.29655556585909665}
2023-01-05 09:31:21,046 INFO:     Found new best model at epoch 77
2023-01-05 09:31:21,047 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:31:21,047 INFO:     Epoch: 78
2023-01-05 09:31:23,162 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4036678572495778, 'Total loss': 0.4036678572495778} | train loss {'Reaction outcome loss': 0.2991504075909978, 'Total loss': 0.2991504075909978}
2023-01-05 09:31:23,162 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:31:23,163 INFO:     Epoch: 79
2023-01-05 09:31:25,270 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4123886798818906, 'Total loss': 0.4123886798818906} | train loss {'Reaction outcome loss': 0.3032227767820376, 'Total loss': 0.3032227767820376}
2023-01-05 09:31:25,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:31:25,271 INFO:     Epoch: 80
2023-01-05 09:31:27,402 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.41153767158587773, 'Total loss': 0.41153767158587773} | train loss {'Reaction outcome loss': 0.3026648107696783, 'Total loss': 0.3026648107696783}
2023-01-05 09:31:27,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:31:27,403 INFO:     Epoch: 81
2023-01-05 09:31:29,539 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3906330555677414, 'Total loss': 0.3906330555677414} | train loss {'Reaction outcome loss': 0.2887171667956653, 'Total loss': 0.2887171667956653}
2023-01-05 09:31:29,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:31:29,539 INFO:     Epoch: 82
2023-01-05 09:31:31,715 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44233016967773436, 'Total loss': 0.44233016967773436} | train loss {'Reaction outcome loss': 0.2856724178899363, 'Total loss': 0.2856724178899363}
2023-01-05 09:31:31,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:31:31,715 INFO:     Epoch: 83
2023-01-05 09:31:33,879 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40641272788246474, 'Total loss': 0.40641272788246474} | train loss {'Reaction outcome loss': 0.2911967695087525, 'Total loss': 0.2911967695087525}
2023-01-05 09:31:33,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:31:33,880 INFO:     Epoch: 84
2023-01-05 09:31:36,012 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4156039357185364, 'Total loss': 0.4156039357185364} | train loss {'Reaction outcome loss': 0.2849252571514639, 'Total loss': 0.2849252571514639}
2023-01-05 09:31:36,012 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:31:36,012 INFO:     Epoch: 85
2023-01-05 09:31:38,159 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3951159546772639, 'Total loss': 0.3951159546772639} | train loss {'Reaction outcome loss': 0.28489497741279396, 'Total loss': 0.28489497741279396}
2023-01-05 09:31:38,159 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:31:38,159 INFO:     Epoch: 86
2023-01-05 09:31:40,310 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38815039992332456, 'Total loss': 0.38815039992332456} | train loss {'Reaction outcome loss': 0.2879520236932929, 'Total loss': 0.2879520236932929}
2023-01-05 09:31:40,311 INFO:     Found new best model at epoch 86
2023-01-05 09:31:40,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:31:40,312 INFO:     Epoch: 87
2023-01-05 09:31:42,489 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.40956392685572307, 'Total loss': 0.40956392685572307} | train loss {'Reaction outcome loss': 0.3125773871357998, 'Total loss': 0.3125773871357998}
2023-01-05 09:31:42,490 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:31:42,490 INFO:     Epoch: 88
2023-01-05 09:31:44,655 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.42714476138353347, 'Total loss': 0.42714476138353347} | train loss {'Reaction outcome loss': 0.29494924727402144, 'Total loss': 0.29494924727402144}
2023-01-05 09:31:44,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:31:44,655 INFO:     Epoch: 89
2023-01-05 09:31:46,812 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4047363596657912, 'Total loss': 0.4047363596657912} | train loss {'Reaction outcome loss': 0.2779380573226355, 'Total loss': 0.2779380573226355}
2023-01-05 09:31:46,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:31:46,812 INFO:     Epoch: 90
2023-01-05 09:31:48,996 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4186401536067327, 'Total loss': 0.4186401536067327} | train loss {'Reaction outcome loss': 0.27325584150393284, 'Total loss': 0.27325584150393284}
2023-01-05 09:31:48,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:31:48,996 INFO:     Epoch: 91
2023-01-05 09:31:51,106 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4029793878396352, 'Total loss': 0.4029793878396352} | train loss {'Reaction outcome loss': 0.2791246040577842, 'Total loss': 0.2791246040577842}
2023-01-05 09:31:51,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:31:51,107 INFO:     Epoch: 92
2023-01-05 09:31:53,227 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4138933062553406, 'Total loss': 0.4138933062553406} | train loss {'Reaction outcome loss': 0.27413283519706677, 'Total loss': 0.27413283519706677}
2023-01-05 09:31:53,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:31:53,227 INFO:     Epoch: 93
2023-01-05 09:31:55,349 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.38796355624993645, 'Total loss': 0.38796355624993645} | train loss {'Reaction outcome loss': 0.26744146398066176, 'Total loss': 0.26744146398066176}
2023-01-05 09:31:55,349 INFO:     Found new best model at epoch 93
2023-01-05 09:31:55,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:31:55,350 INFO:     Epoch: 94
2023-01-05 09:31:57,496 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4126922647158305, 'Total loss': 0.4126922647158305} | train loss {'Reaction outcome loss': 0.2756040515342265, 'Total loss': 0.2756040515342265}
2023-01-05 09:31:57,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:31:57,497 INFO:     Epoch: 95
2023-01-05 09:31:59,634 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3997621645530065, 'Total loss': 0.3997621645530065} | train loss {'Reaction outcome loss': 0.2897697130110169, 'Total loss': 0.2897697130110169}
2023-01-05 09:31:59,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:31:59,634 INFO:     Epoch: 96
2023-01-05 09:32:01,763 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4328287353118261, 'Total loss': 0.4328287353118261} | train loss {'Reaction outcome loss': 0.2847210009720689, 'Total loss': 0.2847210009720689}
2023-01-05 09:32:01,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:32:01,763 INFO:     Epoch: 97
2023-01-05 09:32:03,892 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4074908643960953, 'Total loss': 0.4074908643960953} | train loss {'Reaction outcome loss': 0.27300425592145167, 'Total loss': 0.27300425592145167}
2023-01-05 09:32:03,893 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:32:03,893 INFO:     Epoch: 98
2023-01-05 09:32:06,057 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.39370027085145315, 'Total loss': 0.39370027085145315} | train loss {'Reaction outcome loss': 0.2694705013555126, 'Total loss': 0.2694705013555126}
2023-01-05 09:32:06,058 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:32:06,058 INFO:     Epoch: 99
2023-01-05 09:32:08,240 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.40785030523935956, 'Total loss': 0.40785030523935956} | train loss {'Reaction outcome loss': 0.26486791129510506, 'Total loss': 0.26486791129510506}
2023-01-05 09:32:08,240 INFO:     Best model found after epoch 94 of 100.
2023-01-05 09:32:08,240 INFO:   Done with stage: TRAINING
2023-01-05 09:32:08,240 INFO:   Starting stage: EVALUATION
2023-01-05 09:32:08,371 INFO:   Done with stage: EVALUATION
2023-01-05 09:32:08,371 INFO:   Leaving out SEQ value Fold_1
2023-01-05 09:32:08,384 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 09:32:08,384 INFO:   Starting stage: FEATURE SCALING
2023-01-05 09:32:09,035 INFO:   Done with stage: FEATURE SCALING
2023-01-05 09:32:09,035 INFO:   Starting stage: SCALING TARGETS
2023-01-05 09:32:09,105 INFO:   Done with stage: SCALING TARGETS
2023-01-05 09:32:09,105 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:32:09,105 INFO:     No hyperparam tuning for this model
2023-01-05 09:32:09,105 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:32:09,105 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 09:32:09,106 INFO:     None feature selector for col prot
2023-01-05 09:32:09,106 INFO:     None feature selector for col prot
2023-01-05 09:32:09,106 INFO:     None feature selector for col prot
2023-01-05 09:32:09,107 INFO:     None feature selector for col chem
2023-01-05 09:32:09,107 INFO:     None feature selector for col chem
2023-01-05 09:32:09,107 INFO:     None feature selector for col chem
2023-01-05 09:32:09,107 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 09:32:09,107 INFO:   Starting stage: BUILD MODEL
2023-01-05 09:32:09,108 INFO:     Number of params in model 72901
2023-01-05 09:32:09,112 INFO:   Done with stage: BUILD MODEL
2023-01-05 09:32:09,112 INFO:   Starting stage: TRAINING
2023-01-05 09:32:09,171 INFO:     Val loss before train {'Reaction outcome loss': 0.9581736048062642, 'Total loss': 0.9581736048062642}
2023-01-05 09:32:09,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:32:09,171 INFO:     Epoch: 0
2023-01-05 09:32:11,322 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8103238383928935, 'Total loss': 0.8103238383928935} | train loss {'Reaction outcome loss': 0.8983451573826049, 'Total loss': 0.8983451573826049}
2023-01-05 09:32:11,322 INFO:     Found new best model at epoch 0
2023-01-05 09:32:11,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:32:11,324 INFO:     Epoch: 1
2023-01-05 09:32:13,483 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6279580811659495, 'Total loss': 0.6279580811659495} | train loss {'Reaction outcome loss': 0.6800518730736297, 'Total loss': 0.6800518730736297}
2023-01-05 09:32:13,483 INFO:     Found new best model at epoch 1
2023-01-05 09:32:13,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:32:13,484 INFO:     Epoch: 2
2023-01-05 09:32:15,621 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5346241335074107, 'Total loss': 0.5346241335074107} | train loss {'Reaction outcome loss': 0.5562725576767833, 'Total loss': 0.5562725576767833}
2023-01-05 09:32:15,621 INFO:     Found new best model at epoch 2
2023-01-05 09:32:15,622 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:32:15,622 INFO:     Epoch: 3
2023-01-05 09:32:17,762 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5264872173468272, 'Total loss': 0.5264872173468272} | train loss {'Reaction outcome loss': 0.5199188430823847, 'Total loss': 0.5199188430823847}
2023-01-05 09:32:17,763 INFO:     Found new best model at epoch 3
2023-01-05 09:32:17,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:32:17,764 INFO:     Epoch: 4
2023-01-05 09:32:19,882 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5481771310170491, 'Total loss': 0.5481771310170491} | train loss {'Reaction outcome loss': 0.5054524176200663, 'Total loss': 0.5054524176200663}
2023-01-05 09:32:19,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:32:19,883 INFO:     Epoch: 5
2023-01-05 09:32:22,003 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.5423168023427327, 'Total loss': 0.5423168023427327} | train loss {'Reaction outcome loss': 0.49962902561600314, 'Total loss': 0.49962902561600314}
2023-01-05 09:32:22,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:32:22,003 INFO:     Epoch: 6
2023-01-05 09:32:24,124 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5429896533489227, 'Total loss': 0.5429896533489227} | train loss {'Reaction outcome loss': 0.49489949978348136, 'Total loss': 0.49489949978348136}
2023-01-05 09:32:24,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:32:24,125 INFO:     Epoch: 7
2023-01-05 09:32:26,234 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5326821128527324, 'Total loss': 0.5326821128527324} | train loss {'Reaction outcome loss': 0.4821800081551993, 'Total loss': 0.4821800081551993}
2023-01-05 09:32:26,234 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:32:26,234 INFO:     Epoch: 8
2023-01-05 09:32:28,388 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5225913504759471, 'Total loss': 0.5225913504759471} | train loss {'Reaction outcome loss': 0.4668347493920853, 'Total loss': 0.4668347493920853}
2023-01-05 09:32:28,388 INFO:     Found new best model at epoch 8
2023-01-05 09:32:28,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:32:28,390 INFO:     Epoch: 9
2023-01-05 09:32:30,533 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.5339387545982996, 'Total loss': 0.5339387545982996} | train loss {'Reaction outcome loss': 0.46930164739867486, 'Total loss': 0.46930164739867486}
2023-01-05 09:32:30,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:32:30,533 INFO:     Epoch: 10
2023-01-05 09:32:32,690 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.5160364349683125, 'Total loss': 0.5160364349683125} | train loss {'Reaction outcome loss': 0.46137289971491136, 'Total loss': 0.46137289971491136}
2023-01-05 09:32:32,690 INFO:     Found new best model at epoch 10
2023-01-05 09:32:32,692 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:32:32,692 INFO:     Epoch: 11
2023-01-05 09:32:34,836 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49443300465742746, 'Total loss': 0.49443300465742746} | train loss {'Reaction outcome loss': 0.4551080678036247, 'Total loss': 0.4551080678036247}
2023-01-05 09:32:34,837 INFO:     Found new best model at epoch 11
2023-01-05 09:32:34,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:32:34,839 INFO:     Epoch: 12
2023-01-05 09:32:36,979 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4986144463221232, 'Total loss': 0.4986144463221232} | train loss {'Reaction outcome loss': 0.4557326789532005, 'Total loss': 0.4557326789532005}
2023-01-05 09:32:36,979 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:32:36,979 INFO:     Epoch: 13
2023-01-05 09:32:39,134 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.5247795701026916, 'Total loss': 0.5247795701026916} | train loss {'Reaction outcome loss': 0.4468270451154398, 'Total loss': 0.4468270451154398}
2023-01-05 09:32:39,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:32:39,135 INFO:     Epoch: 14
2023-01-05 09:32:41,299 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.5259939024845759, 'Total loss': 0.5259939024845759} | train loss {'Reaction outcome loss': 0.4645877011336278, 'Total loss': 0.4645877011336278}
2023-01-05 09:32:41,300 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:32:41,300 INFO:     Epoch: 15
2023-01-05 09:32:43,461 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.5008679032325745, 'Total loss': 0.5008679032325745} | train loss {'Reaction outcome loss': 0.45942815829049866, 'Total loss': 0.45942815829049866}
2023-01-05 09:32:43,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:32:43,462 INFO:     Epoch: 16
2023-01-05 09:32:45,564 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4927893877029419, 'Total loss': 0.4927893877029419} | train loss {'Reaction outcome loss': 0.43576254250407487, 'Total loss': 0.43576254250407487}
2023-01-05 09:32:45,564 INFO:     Found new best model at epoch 16
2023-01-05 09:32:45,566 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:32:45,566 INFO:     Epoch: 17
2023-01-05 09:32:47,696 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.5170024037361145, 'Total loss': 0.5170024037361145} | train loss {'Reaction outcome loss': 0.45622250902048056, 'Total loss': 0.45622250902048056}
2023-01-05 09:32:47,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:32:47,696 INFO:     Epoch: 18
2023-01-05 09:32:49,801 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.5233403384685517, 'Total loss': 0.5233403384685517} | train loss {'Reaction outcome loss': 0.4215019397113634, 'Total loss': 0.4215019397113634}
2023-01-05 09:32:49,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:32:49,801 INFO:     Epoch: 19
2023-01-05 09:32:51,936 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.5051371653874716, 'Total loss': 0.5051371653874716} | train loss {'Reaction outcome loss': 0.42680282300452876, 'Total loss': 0.42680282300452876}
2023-01-05 09:32:51,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:32:51,936 INFO:     Epoch: 20
2023-01-05 09:32:54,085 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.507800884048144, 'Total loss': 0.507800884048144} | train loss {'Reaction outcome loss': 0.42257976080915227, 'Total loss': 0.42257976080915227}
2023-01-05 09:32:54,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:32:54,086 INFO:     Epoch: 21
2023-01-05 09:32:56,223 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.5262267371018727, 'Total loss': 0.5262267371018727} | train loss {'Reaction outcome loss': 0.417138643414322, 'Total loss': 0.417138643414322}
2023-01-05 09:32:56,223 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:32:56,224 INFO:     Epoch: 22
2023-01-05 09:32:58,350 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.5203900694847107, 'Total loss': 0.5203900694847107} | train loss {'Reaction outcome loss': 0.4141548687648669, 'Total loss': 0.4141548687648669}
2023-01-05 09:32:58,350 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:32:58,351 INFO:     Epoch: 23
2023-01-05 09:33:00,487 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.515833834807078, 'Total loss': 0.515833834807078} | train loss {'Reaction outcome loss': 0.4103549914189911, 'Total loss': 0.4103549914189911}
2023-01-05 09:33:00,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:33:00,487 INFO:     Epoch: 24
2023-01-05 09:33:02,590 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.5156960527102152, 'Total loss': 0.5156960527102152} | train loss {'Reaction outcome loss': 0.40937651036833617, 'Total loss': 0.40937651036833617}
2023-01-05 09:33:02,590 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:33:02,590 INFO:     Epoch: 25
2023-01-05 09:33:04,740 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.5439341346422831, 'Total loss': 0.5439341346422831} | train loss {'Reaction outcome loss': 0.40108495173246966, 'Total loss': 0.40108495173246966}
2023-01-05 09:33:04,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:33:04,742 INFO:     Epoch: 26
2023-01-05 09:33:06,879 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4889708419640859, 'Total loss': 0.4889708419640859} | train loss {'Reaction outcome loss': 0.41519540449118486, 'Total loss': 0.41519540449118486}
2023-01-05 09:33:06,879 INFO:     Found new best model at epoch 26
2023-01-05 09:33:06,880 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:33:06,881 INFO:     Epoch: 27
2023-01-05 09:33:08,995 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.515960834423701, 'Total loss': 0.515960834423701} | train loss {'Reaction outcome loss': 0.3986885107929677, 'Total loss': 0.3986885107929677}
2023-01-05 09:33:08,995 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:33:08,995 INFO:     Epoch: 28
2023-01-05 09:33:11,113 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.47812700768311817, 'Total loss': 0.47812700768311817} | train loss {'Reaction outcome loss': 0.39265503272738145, 'Total loss': 0.39265503272738145}
2023-01-05 09:33:11,114 INFO:     Found new best model at epoch 28
2023-01-05 09:33:11,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:33:11,115 INFO:     Epoch: 29
2023-01-05 09:33:13,224 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47816975017388663, 'Total loss': 0.47816975017388663} | train loss {'Reaction outcome loss': 0.41253394352785056, 'Total loss': 0.41253394352785056}
2023-01-05 09:33:13,224 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:33:13,224 INFO:     Epoch: 30
2023-01-05 09:33:15,343 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.5216599712769191, 'Total loss': 0.5216599712769191} | train loss {'Reaction outcome loss': 0.41836892896284605, 'Total loss': 0.41836892896284605}
2023-01-05 09:33:15,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:33:15,343 INFO:     Epoch: 31
2023-01-05 09:33:17,460 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.48004134694735207, 'Total loss': 0.48004134694735207} | train loss {'Reaction outcome loss': 0.38519364428045094, 'Total loss': 0.38519364428045094}
2023-01-05 09:33:17,460 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:33:17,461 INFO:     Epoch: 32
2023-01-05 09:33:19,587 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4698168208201726, 'Total loss': 0.4698168208201726} | train loss {'Reaction outcome loss': 0.3940357082941826, 'Total loss': 0.3940357082941826}
2023-01-05 09:33:19,587 INFO:     Found new best model at epoch 32
2023-01-05 09:33:19,589 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:33:19,589 INFO:     Epoch: 33
2023-01-05 09:33:21,709 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.49616774717966716, 'Total loss': 0.49616774717966716} | train loss {'Reaction outcome loss': 0.39514369059108395, 'Total loss': 0.39514369059108395}
2023-01-05 09:33:21,709 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:33:21,709 INFO:     Epoch: 34
2023-01-05 09:33:23,852 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4885797460873922, 'Total loss': 0.4885797460873922} | train loss {'Reaction outcome loss': 0.3697472527693616, 'Total loss': 0.3697472527693616}
2023-01-05 09:33:23,853 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:33:23,853 INFO:     Epoch: 35
2023-01-05 09:33:25,967 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.49828774531682335, 'Total loss': 0.49828774531682335} | train loss {'Reaction outcome loss': 0.36712103945952235, 'Total loss': 0.36712103945952235}
2023-01-05 09:33:25,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:33:25,968 INFO:     Epoch: 36
2023-01-05 09:33:28,078 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4711988886197408, 'Total loss': 0.4711988886197408} | train loss {'Reaction outcome loss': 0.3880622595872568, 'Total loss': 0.3880622595872568}
2023-01-05 09:33:28,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:33:28,078 INFO:     Epoch: 37
2023-01-05 09:33:30,196 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4995152711868286, 'Total loss': 0.4995152711868286} | train loss {'Reaction outcome loss': 0.3650378154023834, 'Total loss': 0.3650378154023834}
2023-01-05 09:33:30,196 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:33:30,196 INFO:     Epoch: 38
2023-01-05 09:33:32,323 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.48410277962684634, 'Total loss': 0.48410277962684634} | train loss {'Reaction outcome loss': 0.3719319961790995, 'Total loss': 0.3719319961790995}
2023-01-05 09:33:32,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:33:32,323 INFO:     Epoch: 39
2023-01-05 09:33:34,439 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.49291612605253854, 'Total loss': 0.49291612605253854} | train loss {'Reaction outcome loss': 0.362276351894252, 'Total loss': 0.362276351894252}
2023-01-05 09:33:34,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:33:34,440 INFO:     Epoch: 40
2023-01-05 09:33:36,561 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47386332750320437, 'Total loss': 0.47386332750320437} | train loss {'Reaction outcome loss': 0.3681359376920306, 'Total loss': 0.3681359376920306}
2023-01-05 09:33:36,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:33:36,561 INFO:     Epoch: 41
2023-01-05 09:33:38,683 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4718782673279444, 'Total loss': 0.4718782673279444} | train loss {'Reaction outcome loss': 0.3920005552632653, 'Total loss': 0.3920005552632653}
2023-01-05 09:33:38,683 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:33:38,683 INFO:     Epoch: 42
2023-01-05 09:33:40,813 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.49005365173021953, 'Total loss': 0.49005365173021953} | train loss {'Reaction outcome loss': 0.3586020637954209, 'Total loss': 0.3586020637954209}
2023-01-05 09:33:40,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:33:40,815 INFO:     Epoch: 43
2023-01-05 09:33:42,952 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4882385094960531, 'Total loss': 0.4882385094960531} | train loss {'Reaction outcome loss': 0.3506515719776001, 'Total loss': 0.3506515719776001}
2023-01-05 09:33:42,952 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:33:42,952 INFO:     Epoch: 44
2023-01-05 09:33:45,083 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.5307601690292358, 'Total loss': 0.5307601690292358} | train loss {'Reaction outcome loss': 0.3445139833535338, 'Total loss': 0.3445139833535338}
2023-01-05 09:33:45,083 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:33:45,083 INFO:     Epoch: 45
2023-01-05 09:33:47,211 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4586872388919195, 'Total loss': 0.4586872388919195} | train loss {'Reaction outcome loss': 0.34701959295215196, 'Total loss': 0.34701959295215196}
2023-01-05 09:33:47,212 INFO:     Found new best model at epoch 45
2023-01-05 09:33:47,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:33:47,213 INFO:     Epoch: 46
2023-01-05 09:33:49,347 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.5079457283020019, 'Total loss': 0.5079457283020019} | train loss {'Reaction outcome loss': 0.34196397389346006, 'Total loss': 0.34196397389346006}
2023-01-05 09:33:49,347 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:33:49,347 INFO:     Epoch: 47
2023-01-05 09:33:51,541 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.49026044011116027, 'Total loss': 0.49026044011116027} | train loss {'Reaction outcome loss': 0.340136492030992, 'Total loss': 0.340136492030992}
2023-01-05 09:33:51,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:33:51,541 INFO:     Epoch: 48
2023-01-05 09:33:53,723 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4589335098862648, 'Total loss': 0.4589335098862648} | train loss {'Reaction outcome loss': 0.33908330195560626, 'Total loss': 0.33908330195560626}
2023-01-05 09:33:53,723 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:33:53,724 INFO:     Epoch: 49
2023-01-05 09:33:55,839 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.45572030246257783, 'Total loss': 0.45572030246257783} | train loss {'Reaction outcome loss': 0.3388746112140707, 'Total loss': 0.3388746112140707}
2023-01-05 09:33:55,840 INFO:     Found new best model at epoch 49
2023-01-05 09:33:55,841 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:33:55,841 INFO:     Epoch: 50
2023-01-05 09:33:57,961 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4685657978057861, 'Total loss': 0.4685657978057861} | train loss {'Reaction outcome loss': 0.32851693537373067, 'Total loss': 0.32851693537373067}
2023-01-05 09:33:57,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:33:57,962 INFO:     Epoch: 51
2023-01-05 09:34:00,091 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.5110648810863495, 'Total loss': 0.5110648810863495} | train loss {'Reaction outcome loss': 0.33412566398770205, 'Total loss': 0.33412566398770205}
2023-01-05 09:34:00,092 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:34:00,092 INFO:     Epoch: 52
2023-01-05 09:34:02,027 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4731347421805064, 'Total loss': 0.4731347421805064} | train loss {'Reaction outcome loss': 0.32151531351163337, 'Total loss': 0.32151531351163337}
2023-01-05 09:34:02,027 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:34:02,027 INFO:     Epoch: 53
2023-01-05 09:34:04,164 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.5153310139973958, 'Total loss': 0.5153310139973958} | train loss {'Reaction outcome loss': 0.3297182283338085, 'Total loss': 0.3297182283338085}
2023-01-05 09:34:04,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:34:04,164 INFO:     Epoch: 54
2023-01-05 09:34:06,275 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4476293742656708, 'Total loss': 0.4476293742656708} | train loss {'Reaction outcome loss': 0.3237212775140137, 'Total loss': 0.3237212775140137}
2023-01-05 09:34:06,276 INFO:     Found new best model at epoch 54
2023-01-05 09:34:06,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:34:06,277 INFO:     Epoch: 55
2023-01-05 09:34:08,388 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5625533759593964, 'Total loss': 0.5625533759593964} | train loss {'Reaction outcome loss': 0.31769653261922626, 'Total loss': 0.31769653261922626}
2023-01-05 09:34:08,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:34:08,388 INFO:     Epoch: 56
2023-01-05 09:34:10,534 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.49428010880947115, 'Total loss': 0.49428010880947115} | train loss {'Reaction outcome loss': 0.3176728961044464, 'Total loss': 0.3176728961044464}
2023-01-05 09:34:10,535 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:34:10,535 INFO:     Epoch: 57
2023-01-05 09:34:12,654 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4836064676443736, 'Total loss': 0.4836064676443736} | train loss {'Reaction outcome loss': 0.31097972358714987, 'Total loss': 0.31097972358714987}
2023-01-05 09:34:12,654 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:34:12,654 INFO:     Epoch: 58
2023-01-05 09:34:14,769 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.45510183374087015, 'Total loss': 0.45510183374087015} | train loss {'Reaction outcome loss': 0.3113610936241035, 'Total loss': 0.3113610936241035}
2023-01-05 09:34:14,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:34:14,770 INFO:     Epoch: 59
2023-01-05 09:34:16,898 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.5150498181581498, 'Total loss': 0.5150498181581498} | train loss {'Reaction outcome loss': 0.306660735039496, 'Total loss': 0.306660735039496}
2023-01-05 09:34:16,899 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:34:16,899 INFO:     Epoch: 60
2023-01-05 09:34:19,006 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.5120108157396317, 'Total loss': 0.5120108157396317} | train loss {'Reaction outcome loss': 0.3057355263314304, 'Total loss': 0.3057355263314304}
2023-01-05 09:34:19,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:34:19,007 INFO:     Epoch: 61
2023-01-05 09:34:21,122 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.48196126421292623, 'Total loss': 0.48196126421292623} | train loss {'Reaction outcome loss': 0.30865743437754933, 'Total loss': 0.30865743437754933}
2023-01-05 09:34:21,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:34:21,122 INFO:     Epoch: 62
2023-01-05 09:34:23,273 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.47515865763028464, 'Total loss': 0.47515865763028464} | train loss {'Reaction outcome loss': 0.303883250185248, 'Total loss': 0.303883250185248}
2023-01-05 09:34:23,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:34:23,273 INFO:     Epoch: 63
2023-01-05 09:34:25,383 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4881394093235334, 'Total loss': 0.4881394093235334} | train loss {'Reaction outcome loss': 0.3207079542233892, 'Total loss': 0.3207079542233892}
2023-01-05 09:34:25,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:34:25,383 INFO:     Epoch: 64
2023-01-05 09:34:27,529 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4905285954475403, 'Total loss': 0.4905285954475403} | train loss {'Reaction outcome loss': 0.34294280860964477, 'Total loss': 0.34294280860964477}
2023-01-05 09:34:27,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:34:27,529 INFO:     Epoch: 65
2023-01-05 09:34:29,659 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.5667344808578492, 'Total loss': 0.5667344808578492} | train loss {'Reaction outcome loss': 0.3048309480450437, 'Total loss': 0.3048309480450437}
2023-01-05 09:34:29,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:34:29,660 INFO:     Epoch: 66
2023-01-05 09:34:31,842 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.46468429068724315, 'Total loss': 0.46468429068724315} | train loss {'Reaction outcome loss': 0.2991540723338021, 'Total loss': 0.2991540723338021}
2023-01-05 09:34:31,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:34:31,842 INFO:     Epoch: 67
2023-01-05 09:34:34,015 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4781826039155324, 'Total loss': 0.4781826039155324} | train loss {'Reaction outcome loss': 0.2976078196328329, 'Total loss': 0.2976078196328329}
2023-01-05 09:34:34,015 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:34:34,015 INFO:     Epoch: 68
2023-01-05 09:34:36,136 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.48438788652420045, 'Total loss': 0.48438788652420045} | train loss {'Reaction outcome loss': 0.294982389924437, 'Total loss': 0.294982389924437}
2023-01-05 09:34:36,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:34:36,137 INFO:     Epoch: 69
2023-01-05 09:34:38,266 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.46717716157436373, 'Total loss': 0.46717716157436373} | train loss {'Reaction outcome loss': 0.2900869422254787, 'Total loss': 0.2900869422254787}
2023-01-05 09:34:38,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:34:38,267 INFO:     Epoch: 70
2023-01-05 09:34:40,400 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4852201054493586, 'Total loss': 0.4852201054493586} | train loss {'Reaction outcome loss': 0.2904199102515544, 'Total loss': 0.2904199102515544}
2023-01-05 09:34:40,400 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:34:40,400 INFO:     Epoch: 71
2023-01-05 09:34:42,527 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.510903513431549, 'Total loss': 0.510903513431549} | train loss {'Reaction outcome loss': 0.29058503949411296, 'Total loss': 0.29058503949411296}
2023-01-05 09:34:42,528 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:34:42,528 INFO:     Epoch: 72
2023-01-05 09:34:44,658 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4782365401585897, 'Total loss': 0.4782365401585897} | train loss {'Reaction outcome loss': 0.28747380002544337, 'Total loss': 0.28747380002544337}
2023-01-05 09:34:44,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:34:44,659 INFO:     Epoch: 73
2023-01-05 09:34:46,798 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4606206009785334, 'Total loss': 0.4606206009785334} | train loss {'Reaction outcome loss': 0.289395937750089, 'Total loss': 0.289395937750089}
2023-01-05 09:34:46,799 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:34:46,799 INFO:     Epoch: 74
2023-01-05 09:34:48,934 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4831451634565989, 'Total loss': 0.4831451634565989} | train loss {'Reaction outcome loss': 0.27900363784536475, 'Total loss': 0.27900363784536475}
2023-01-05 09:34:48,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:34:48,935 INFO:     Epoch: 75
2023-01-05 09:34:51,039 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4413754383722941, 'Total loss': 0.4413754383722941} | train loss {'Reaction outcome loss': 0.2734676899761299, 'Total loss': 0.2734676899761299}
2023-01-05 09:34:51,039 INFO:     Found new best model at epoch 75
2023-01-05 09:34:51,040 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:34:51,040 INFO:     Epoch: 76
2023-01-05 09:34:53,167 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.5035979310671489, 'Total loss': 0.5035979310671489} | train loss {'Reaction outcome loss': 0.2834563317499461, 'Total loss': 0.2834563317499461}
2023-01-05 09:34:53,167 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:34:53,167 INFO:     Epoch: 77
2023-01-05 09:34:55,323 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.5093158344427745, 'Total loss': 0.5093158344427745} | train loss {'Reaction outcome loss': 0.2805488529109794, 'Total loss': 0.2805488529109794}
2023-01-05 09:34:55,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:34:55,323 INFO:     Epoch: 78
2023-01-05 09:34:57,476 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.5116330911715825, 'Total loss': 0.5116330911715825} | train loss {'Reaction outcome loss': 0.27996199571169733, 'Total loss': 0.27996199571169733}
2023-01-05 09:34:57,476 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:34:57,476 INFO:     Epoch: 79
2023-01-05 09:34:59,619 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.49811912377675377, 'Total loss': 0.49811912377675377} | train loss {'Reaction outcome loss': 0.26998693711610267, 'Total loss': 0.26998693711610267}
2023-01-05 09:34:59,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:34:59,619 INFO:     Epoch: 80
2023-01-05 09:35:01,760 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.5177111168702443, 'Total loss': 0.5177111168702443} | train loss {'Reaction outcome loss': 0.2623612141709916, 'Total loss': 0.2623612141709916}
2023-01-05 09:35:01,760 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:35:01,760 INFO:     Epoch: 81
2023-01-05 09:35:03,882 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4751218756039937, 'Total loss': 0.4751218756039937} | train loss {'Reaction outcome loss': 0.2724525958141042, 'Total loss': 0.2724525958141042}
2023-01-05 09:35:03,882 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:35:03,882 INFO:     Epoch: 82
2023-01-05 09:35:06,027 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.49726949334144593, 'Total loss': 0.49726949334144593} | train loss {'Reaction outcome loss': 0.26942773256239994, 'Total loss': 0.26942773256239994}
2023-01-05 09:35:06,028 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:35:06,028 INFO:     Epoch: 83
2023-01-05 09:35:08,176 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.4773086051146189, 'Total loss': 0.4773086051146189} | train loss {'Reaction outcome loss': 0.272306834469023, 'Total loss': 0.272306834469023}
2023-01-05 09:35:08,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:35:08,176 INFO:     Epoch: 84
2023-01-05 09:35:10,333 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.5227429986000061, 'Total loss': 0.5227429986000061} | train loss {'Reaction outcome loss': 0.26567701340156974, 'Total loss': 0.26567701340156974}
2023-01-05 09:35:10,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:35:10,333 INFO:     Epoch: 85
2023-01-05 09:35:12,482 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.5101027448972066, 'Total loss': 0.5101027448972066} | train loss {'Reaction outcome loss': 0.27635787418363783, 'Total loss': 0.27635787418363783}
2023-01-05 09:35:12,482 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:35:12,482 INFO:     Epoch: 86
2023-01-05 09:35:14,638 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4850780884424845, 'Total loss': 0.4850780884424845} | train loss {'Reaction outcome loss': 0.2630768869181549, 'Total loss': 0.2630768869181549}
2023-01-05 09:35:14,638 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:35:14,638 INFO:     Epoch: 87
2023-01-05 09:35:16,761 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5307913477222125, 'Total loss': 0.5307913477222125} | train loss {'Reaction outcome loss': 0.26404652829489145, 'Total loss': 0.26404652829489145}
2023-01-05 09:35:16,761 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:35:16,761 INFO:     Epoch: 88
2023-01-05 09:35:18,878 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.48969244956970215, 'Total loss': 0.48969244956970215} | train loss {'Reaction outcome loss': 0.26809397128501744, 'Total loss': 0.26809397128501744}
2023-01-05 09:35:18,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:35:18,878 INFO:     Epoch: 89
2023-01-05 09:35:20,993 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4587192237377167, 'Total loss': 0.4587192237377167} | train loss {'Reaction outcome loss': 0.25497683787556447, 'Total loss': 0.25497683787556447}
2023-01-05 09:35:20,993 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:35:20,993 INFO:     Epoch: 90
2023-01-05 09:35:23,121 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.46287836929162346, 'Total loss': 0.46287836929162346} | train loss {'Reaction outcome loss': 0.2567846594763029, 'Total loss': 0.2567846594763029}
2023-01-05 09:35:23,122 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:35:23,122 INFO:     Epoch: 91
2023-01-05 09:35:25,259 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.5409383058547974, 'Total loss': 0.5409383058547974} | train loss {'Reaction outcome loss': 0.2776003690989877, 'Total loss': 0.2776003690989877}
2023-01-05 09:35:25,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:35:25,259 INFO:     Epoch: 92
2023-01-05 09:35:27,372 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.488635915517807, 'Total loss': 0.488635915517807} | train loss {'Reaction outcome loss': 0.2627034469160076, 'Total loss': 0.2627034469160076}
2023-01-05 09:35:27,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:35:27,373 INFO:     Epoch: 93
2023-01-05 09:35:29,487 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46991152862707775, 'Total loss': 0.46991152862707775} | train loss {'Reaction outcome loss': 0.254207635498012, 'Total loss': 0.254207635498012}
2023-01-05 09:35:29,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:35:29,488 INFO:     Epoch: 94
2023-01-05 09:35:31,593 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4905581772327423, 'Total loss': 0.4905581772327423} | train loss {'Reaction outcome loss': 0.25747564702548853, 'Total loss': 0.25747564702548853}
2023-01-05 09:35:31,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:35:31,593 INFO:     Epoch: 95
2023-01-05 09:35:33,707 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4838707019885381, 'Total loss': 0.4838707019885381} | train loss {'Reaction outcome loss': 0.25502585223538504, 'Total loss': 0.25502585223538504}
2023-01-05 09:35:33,708 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:35:33,708 INFO:     Epoch: 96
2023-01-05 09:35:35,825 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4813294097781181, 'Total loss': 0.4813294097781181} | train loss {'Reaction outcome loss': 0.24841903993164768, 'Total loss': 0.24841903993164768}
2023-01-05 09:35:35,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:35:35,825 INFO:     Epoch: 97
2023-01-05 09:35:37,960 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.5159223695596059, 'Total loss': 0.5159223695596059} | train loss {'Reaction outcome loss': 0.25114904769082164, 'Total loss': 0.25114904769082164}
2023-01-05 09:35:37,960 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:35:37,960 INFO:     Epoch: 98
2023-01-05 09:35:40,104 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4867562671502431, 'Total loss': 0.4867562671502431} | train loss {'Reaction outcome loss': 0.2483477065256591, 'Total loss': 0.2483477065256591}
2023-01-05 09:35:40,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:35:40,104 INFO:     Epoch: 99
2023-01-05 09:35:42,232 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.5135653997461002, 'Total loss': 0.5135653997461002} | train loss {'Reaction outcome loss': 0.25281713481240004, 'Total loss': 0.25281713481240004}
2023-01-05 09:35:42,233 INFO:     Best model found after epoch 76 of 100.
2023-01-05 09:35:42,233 INFO:   Done with stage: TRAINING
2023-01-05 09:35:42,233 INFO:   Starting stage: EVALUATION
2023-01-05 09:35:42,365 INFO:   Done with stage: EVALUATION
2023-01-05 09:35:42,365 INFO:   Leaving out SEQ value Fold_2
2023-01-05 09:35:42,378 INFO:   examples: 20,544| examples in train: 17,236 | examples in val: 908| examples in test: 2,400
2023-01-05 09:35:42,378 INFO:   Starting stage: FEATURE SCALING
2023-01-05 09:35:43,016 INFO:   Done with stage: FEATURE SCALING
2023-01-05 09:35:43,016 INFO:   Starting stage: SCALING TARGETS
2023-01-05 09:35:43,083 INFO:   Done with stage: SCALING TARGETS
2023-01-05 09:35:43,083 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:35:43,083 INFO:     No hyperparam tuning for this model
2023-01-05 09:35:43,083 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:35:43,084 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 09:35:43,084 INFO:     None feature selector for col prot
2023-01-05 09:35:43,084 INFO:     None feature selector for col prot
2023-01-05 09:35:43,084 INFO:     None feature selector for col prot
2023-01-05 09:35:43,085 INFO:     None feature selector for col chem
2023-01-05 09:35:43,085 INFO:     None feature selector for col chem
2023-01-05 09:35:43,085 INFO:     None feature selector for col chem
2023-01-05 09:35:43,085 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 09:35:43,085 INFO:   Starting stage: BUILD MODEL
2023-01-05 09:35:43,087 INFO:     Number of params in model 72901
2023-01-05 09:35:43,090 INFO:   Done with stage: BUILD MODEL
2023-01-05 09:35:43,090 INFO:   Starting stage: TRAINING
2023-01-05 09:35:43,149 INFO:     Val loss before train {'Reaction outcome loss': 1.072773410876592, 'Total loss': 1.072773410876592}
2023-01-05 09:35:43,149 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:35:43,149 INFO:     Epoch: 0
2023-01-05 09:35:45,243 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7834251602490743, 'Total loss': 0.7834251602490743} | train loss {'Reaction outcome loss': 0.8959480851888657, 'Total loss': 0.8959480851888657}
2023-01-05 09:35:45,243 INFO:     Found new best model at epoch 0
2023-01-05 09:35:45,244 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:35:45,244 INFO:     Epoch: 1
2023-01-05 09:35:47,328 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5662492195765177, 'Total loss': 0.5662492195765177} | train loss {'Reaction outcome loss': 0.719453356994523, 'Total loss': 0.719453356994523}
2023-01-05 09:35:47,328 INFO:     Found new best model at epoch 1
2023-01-05 09:35:47,329 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:35:47,329 INFO:     Epoch: 2
2023-01-05 09:35:49,403 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5449594259262085, 'Total loss': 0.5449594259262085} | train loss {'Reaction outcome loss': 0.5684846528702312, 'Total loss': 0.5684846528702312}
2023-01-05 09:35:49,403 INFO:     Found new best model at epoch 2
2023-01-05 09:35:49,404 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:35:49,404 INFO:     Epoch: 3
2023-01-05 09:35:51,496 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5316548188527425, 'Total loss': 0.5316548188527425} | train loss {'Reaction outcome loss': 0.5218533227841059, 'Total loss': 0.5218533227841059}
2023-01-05 09:35:51,496 INFO:     Found new best model at epoch 3
2023-01-05 09:35:51,497 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:35:51,498 INFO:     Epoch: 4
2023-01-05 09:35:53,599 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4689595619837443, 'Total loss': 0.4689595619837443} | train loss {'Reaction outcome loss': 0.49871007852532245, 'Total loss': 0.49871007852532245}
2023-01-05 09:35:53,600 INFO:     Found new best model at epoch 4
2023-01-05 09:35:53,601 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:35:53,602 INFO:     Epoch: 5
2023-01-05 09:35:55,696 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.504129018386205, 'Total loss': 0.504129018386205} | train loss {'Reaction outcome loss': 0.4852511458374836, 'Total loss': 0.4852511458374836}
2023-01-05 09:35:55,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:35:55,696 INFO:     Epoch: 6
2023-01-05 09:35:57,796 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4569134175777435, 'Total loss': 0.4569134175777435} | train loss {'Reaction outcome loss': 0.4745477628652696, 'Total loss': 0.4745477628652696}
2023-01-05 09:35:57,796 INFO:     Found new best model at epoch 6
2023-01-05 09:35:57,797 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:35:57,797 INFO:     Epoch: 7
2023-01-05 09:35:59,905 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4292610377073288, 'Total loss': 0.4292610377073288} | train loss {'Reaction outcome loss': 0.46897706559134855, 'Total loss': 0.46897706559134855}
2023-01-05 09:35:59,905 INFO:     Found new best model at epoch 7
2023-01-05 09:35:59,907 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:35:59,907 INFO:     Epoch: 8
2023-01-05 09:36:02,000 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4879979074001312, 'Total loss': 0.4879979074001312} | train loss {'Reaction outcome loss': 0.4617230288684368, 'Total loss': 0.4617230288684368}
2023-01-05 09:36:02,000 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:36:02,000 INFO:     Epoch: 9
2023-01-05 09:36:04,089 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.47396905620892843, 'Total loss': 0.47396905620892843} | train loss {'Reaction outcome loss': 0.4610876405956569, 'Total loss': 0.4610876405956569}
2023-01-05 09:36:04,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:36:04,089 INFO:     Epoch: 10
2023-01-05 09:36:06,198 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4553528914848963, 'Total loss': 0.4553528914848963} | train loss {'Reaction outcome loss': 0.4479773278865549, 'Total loss': 0.4479773278865549}
2023-01-05 09:36:06,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:36:06,198 INFO:     Epoch: 11
2023-01-05 09:36:08,297 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.43359388212362926, 'Total loss': 0.43359388212362926} | train loss {'Reaction outcome loss': 0.44573132994550246, 'Total loss': 0.44573132994550246}
2023-01-05 09:36:08,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:36:08,297 INFO:     Epoch: 12
2023-01-05 09:36:10,387 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.49427652756373086, 'Total loss': 0.49427652756373086} | train loss {'Reaction outcome loss': 0.4407703997636283, 'Total loss': 0.4407703997636283}
2023-01-05 09:36:10,387 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:36:10,387 INFO:     Epoch: 13
2023-01-05 09:36:12,511 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4239800937473774, 'Total loss': 0.4239800937473774} | train loss {'Reaction outcome loss': 0.43851416113751907, 'Total loss': 0.43851416113751907}
2023-01-05 09:36:12,512 INFO:     Found new best model at epoch 13
2023-01-05 09:36:12,513 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:36:12,513 INFO:     Epoch: 14
2023-01-05 09:36:14,618 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.46731555263201396, 'Total loss': 0.46731555263201396} | train loss {'Reaction outcome loss': 0.4336151901494574, 'Total loss': 0.4336151901494574}
2023-01-05 09:36:14,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:36:14,619 INFO:     Epoch: 15
2023-01-05 09:36:16,726 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.43372023304303486, 'Total loss': 0.43372023304303486} | train loss {'Reaction outcome loss': 0.4292992996672789, 'Total loss': 0.4292992996672789}
2023-01-05 09:36:16,726 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:36:16,726 INFO:     Epoch: 16
2023-01-05 09:36:18,814 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44576127926508585, 'Total loss': 0.44576127926508585} | train loss {'Reaction outcome loss': 0.4251065438268361, 'Total loss': 0.4251065438268361}
2023-01-05 09:36:18,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:36:18,814 INFO:     Epoch: 17
2023-01-05 09:36:20,897 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4317355404297511, 'Total loss': 0.4317355404297511} | train loss {'Reaction outcome loss': 0.41535030887634666, 'Total loss': 0.41535030887634666}
2023-01-05 09:36:20,897 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:36:20,897 INFO:     Epoch: 18
2023-01-05 09:36:22,994 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.44978099763393403, 'Total loss': 0.44978099763393403} | train loss {'Reaction outcome loss': 0.4149405935020358, 'Total loss': 0.4149405935020358}
2023-01-05 09:36:22,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:36:22,994 INFO:     Epoch: 19
2023-01-05 09:36:25,055 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4622790311773618, 'Total loss': 0.4622790311773618} | train loss {'Reaction outcome loss': 0.4176459433303939, 'Total loss': 0.4176459433303939}
2023-01-05 09:36:25,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:36:25,055 INFO:     Epoch: 20
2023-01-05 09:36:27,154 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.419800728559494, 'Total loss': 0.419800728559494} | train loss {'Reaction outcome loss': 0.4021414126786921, 'Total loss': 0.4021414126786921}
2023-01-05 09:36:27,154 INFO:     Found new best model at epoch 20
2023-01-05 09:36:27,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:36:27,155 INFO:     Epoch: 21
2023-01-05 09:36:29,292 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.405410398542881, 'Total loss': 0.405410398542881} | train loss {'Reaction outcome loss': 0.40242374589045843, 'Total loss': 0.40242374589045843}
2023-01-05 09:36:29,294 INFO:     Found new best model at epoch 21
2023-01-05 09:36:29,295 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:36:29,295 INFO:     Epoch: 22
2023-01-05 09:36:31,407 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4278608649969101, 'Total loss': 0.4278608649969101} | train loss {'Reaction outcome loss': 0.39366410269781393, 'Total loss': 0.39366410269781393}
2023-01-05 09:36:31,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:36:31,408 INFO:     Epoch: 23
2023-01-05 09:36:33,521 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4023806283871333, 'Total loss': 0.4023806283871333} | train loss {'Reaction outcome loss': 0.39401789600098575, 'Total loss': 0.39401789600098575}
2023-01-05 09:36:33,521 INFO:     Found new best model at epoch 23
2023-01-05 09:36:33,522 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:36:33,522 INFO:     Epoch: 24
2023-01-05 09:36:35,607 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4342681854963303, 'Total loss': 0.4342681854963303} | train loss {'Reaction outcome loss': 0.3911157906745319, 'Total loss': 0.3911157906745319}
2023-01-05 09:36:35,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:36:35,608 INFO:     Epoch: 25
2023-01-05 09:36:37,707 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.46642580231030784, 'Total loss': 0.46642580231030784} | train loss {'Reaction outcome loss': 0.38621867579166536, 'Total loss': 0.38621867579166536}
2023-01-05 09:36:37,707 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:36:37,707 INFO:     Epoch: 26
2023-01-05 09:36:39,811 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.47622082034746804, 'Total loss': 0.47622082034746804} | train loss {'Reaction outcome loss': 0.37820396025975545, 'Total loss': 0.37820396025975545}
2023-01-05 09:36:39,811 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:36:39,811 INFO:     Epoch: 27
2023-01-05 09:36:41,929 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4077884316444397, 'Total loss': 0.4077884316444397} | train loss {'Reaction outcome loss': 0.37908323354743145, 'Total loss': 0.37908323354743145}
2023-01-05 09:36:41,929 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:36:41,929 INFO:     Epoch: 28
2023-01-05 09:36:44,060 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4678336262702942, 'Total loss': 0.4678336262702942} | train loss {'Reaction outcome loss': 0.37112704634114546, 'Total loss': 0.37112704634114546}
2023-01-05 09:36:44,060 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:36:44,060 INFO:     Epoch: 29
2023-01-05 09:36:46,251 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4298681596914927, 'Total loss': 0.4298681596914927} | train loss {'Reaction outcome loss': 0.3719687563125734, 'Total loss': 0.3719687563125734}
2023-01-05 09:36:46,251 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:36:46,252 INFO:     Epoch: 30
2023-01-05 09:36:48,362 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.41151985228061677, 'Total loss': 0.41151985228061677} | train loss {'Reaction outcome loss': 0.3596787678146804, 'Total loss': 0.3596787678146804}
2023-01-05 09:36:48,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:36:48,363 INFO:     Epoch: 31
2023-01-05 09:36:50,479 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3971445828676224, 'Total loss': 0.3971445828676224} | train loss {'Reaction outcome loss': 0.3614324715126444, 'Total loss': 0.3614324715126444}
2023-01-05 09:36:50,479 INFO:     Found new best model at epoch 31
2023-01-05 09:36:50,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:36:50,480 INFO:     Epoch: 32
2023-01-05 09:36:52,595 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.425442773103714, 'Total loss': 0.425442773103714} | train loss {'Reaction outcome loss': 0.35978054028970224, 'Total loss': 0.35978054028970224}
2023-01-05 09:36:52,595 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:36:52,595 INFO:     Epoch: 33
2023-01-05 09:36:54,713 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.39322852436453104, 'Total loss': 0.39322852436453104} | train loss {'Reaction outcome loss': 0.3599855321700926, 'Total loss': 0.3599855321700926}
2023-01-05 09:36:54,713 INFO:     Found new best model at epoch 33
2023-01-05 09:36:54,714 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:36:54,714 INFO:     Epoch: 34
2023-01-05 09:36:56,801 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.456867545346419, 'Total loss': 0.456867545346419} | train loss {'Reaction outcome loss': 0.3546651837174539, 'Total loss': 0.3546651837174539}
2023-01-05 09:36:56,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:36:56,802 INFO:     Epoch: 35
2023-01-05 09:36:58,864 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3834911361336708, 'Total loss': 0.3834911361336708} | train loss {'Reaction outcome loss': 0.3448372295609227, 'Total loss': 0.3448372295609227}
2023-01-05 09:36:58,865 INFO:     Found new best model at epoch 35
2023-01-05 09:36:58,866 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:36:58,866 INFO:     Epoch: 36
2023-01-05 09:37:00,950 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.429864889383316, 'Total loss': 0.429864889383316} | train loss {'Reaction outcome loss': 0.34290255820033727, 'Total loss': 0.34290255820033727}
2023-01-05 09:37:00,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:37:00,951 INFO:     Epoch: 37
2023-01-05 09:37:03,001 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.42827593684196474, 'Total loss': 0.42827593684196474} | train loss {'Reaction outcome loss': 0.3435272690736585, 'Total loss': 0.3435272690736585}
2023-01-05 09:37:03,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:37:03,002 INFO:     Epoch: 38
2023-01-05 09:37:05,075 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40940411885579425, 'Total loss': 0.40940411885579425} | train loss {'Reaction outcome loss': 0.33925647260966124, 'Total loss': 0.33925647260966124}
2023-01-05 09:37:05,076 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:37:05,076 INFO:     Epoch: 39
2023-01-05 09:37:07,142 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4086545745531718, 'Total loss': 0.4086545745531718} | train loss {'Reaction outcome loss': 0.33885101976769944, 'Total loss': 0.33885101976769944}
2023-01-05 09:37:07,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:37:07,142 INFO:     Epoch: 40
2023-01-05 09:37:09,361 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.37689295783638954, 'Total loss': 0.37689295783638954} | train loss {'Reaction outcome loss': 0.33372852424228633, 'Total loss': 0.33372852424228633}
2023-01-05 09:37:09,361 INFO:     Found new best model at epoch 40
2023-01-05 09:37:09,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:37:09,363 INFO:     Epoch: 41
2023-01-05 09:37:11,606 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.39717977344989774, 'Total loss': 0.39717977344989774} | train loss {'Reaction outcome loss': 0.3301319259460326, 'Total loss': 0.3301319259460326}
2023-01-05 09:37:11,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:37:11,607 INFO:     Epoch: 42
2023-01-05 09:37:13,822 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.40465412934621176, 'Total loss': 0.40465412934621176} | train loss {'Reaction outcome loss': 0.32844282334877384, 'Total loss': 0.32844282334877384}
2023-01-05 09:37:13,823 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:37:13,823 INFO:     Epoch: 43
2023-01-05 09:37:16,034 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39753771672646204, 'Total loss': 0.39753771672646204} | train loss {'Reaction outcome loss': 0.32537871517792893, 'Total loss': 0.32537871517792893}
2023-01-05 09:37:16,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:37:16,034 INFO:     Epoch: 44
2023-01-05 09:37:18,188 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3803998872637749, 'Total loss': 0.3803998872637749} | train loss {'Reaction outcome loss': 0.3130098070259447, 'Total loss': 0.3130098070259447}
2023-01-05 09:37:18,188 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:37:18,188 INFO:     Epoch: 45
2023-01-05 09:37:20,318 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40671090185642245, 'Total loss': 0.40671090185642245} | train loss {'Reaction outcome loss': 0.3136142235387255, 'Total loss': 0.3136142235387255}
2023-01-05 09:37:20,318 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:37:20,319 INFO:     Epoch: 46
2023-01-05 09:37:22,426 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4093746115763982, 'Total loss': 0.4093746115763982} | train loss {'Reaction outcome loss': 0.315841095259896, 'Total loss': 0.315841095259896}
2023-01-05 09:37:22,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:37:22,426 INFO:     Epoch: 47
2023-01-05 09:37:24,515 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.38062322040398916, 'Total loss': 0.38062322040398916} | train loss {'Reaction outcome loss': 0.3136447534241058, 'Total loss': 0.3136447534241058}
2023-01-05 09:37:24,516 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:37:24,516 INFO:     Epoch: 48
2023-01-05 09:37:26,594 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.38474301745494205, 'Total loss': 0.38474301745494205} | train loss {'Reaction outcome loss': 0.3093728676714279, 'Total loss': 0.3093728676714279}
2023-01-05 09:37:26,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:37:26,594 INFO:     Epoch: 49
2023-01-05 09:37:28,688 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42403942545255024, 'Total loss': 0.42403942545255024} | train loss {'Reaction outcome loss': 0.3093091284925187, 'Total loss': 0.3093091284925187}
2023-01-05 09:37:28,688 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:37:28,688 INFO:     Epoch: 50
2023-01-05 09:37:30,767 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4071817249059677, 'Total loss': 0.4071817249059677} | train loss {'Reaction outcome loss': 0.3094386062964245, 'Total loss': 0.3094386062964245}
2023-01-05 09:37:30,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:37:30,767 INFO:     Epoch: 51
2023-01-05 09:37:32,831 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41895601550738015, 'Total loss': 0.41895601550738015} | train loss {'Reaction outcome loss': 0.3025349729039051, 'Total loss': 0.3025349729039051}
2023-01-05 09:37:32,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:37:32,831 INFO:     Epoch: 52
2023-01-05 09:37:34,908 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3993591447671255, 'Total loss': 0.3993591447671255} | train loss {'Reaction outcome loss': 0.2986128364034273, 'Total loss': 0.2986128364034273}
2023-01-05 09:37:34,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:37:34,908 INFO:     Epoch: 53
2023-01-05 09:37:36,971 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.3930937965710958, 'Total loss': 0.3930937965710958} | train loss {'Reaction outcome loss': 0.2991864882409573, 'Total loss': 0.2991864882409573}
2023-01-05 09:37:36,971 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:37:36,971 INFO:     Epoch: 54
2023-01-05 09:37:39,039 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.400937494635582, 'Total loss': 0.400937494635582} | train loss {'Reaction outcome loss': 0.304741791608157, 'Total loss': 0.304741791608157}
2023-01-05 09:37:39,039 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:37:39,039 INFO:     Epoch: 55
2023-01-05 09:37:41,104 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.4026913603146871, 'Total loss': 0.4026913603146871} | train loss {'Reaction outcome loss': 0.29655478569092575, 'Total loss': 0.29655478569092575}
2023-01-05 09:37:41,105 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:37:41,106 INFO:     Epoch: 56
2023-01-05 09:37:43,271 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4250197509924571, 'Total loss': 0.4250197509924571} | train loss {'Reaction outcome loss': 0.2971415958746716, 'Total loss': 0.2971415958746716}
2023-01-05 09:37:43,271 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:37:43,272 INFO:     Epoch: 57
2023-01-05 09:37:45,392 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.43270568251609803, 'Total loss': 0.43270568251609803} | train loss {'Reaction outcome loss': 0.2997559750245677, 'Total loss': 0.2997559750245677}
2023-01-05 09:37:45,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:37:45,392 INFO:     Epoch: 58
2023-01-05 09:37:47,486 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.35971585256047545, 'Total loss': 0.35971585256047545} | train loss {'Reaction outcome loss': 0.2933004041616287, 'Total loss': 0.2933004041616287}
2023-01-05 09:37:47,487 INFO:     Found new best model at epoch 58
2023-01-05 09:37:47,488 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:37:47,489 INFO:     Epoch: 59
2023-01-05 09:37:49,567 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.43760025103886924, 'Total loss': 0.43760025103886924} | train loss {'Reaction outcome loss': 0.2893932766384549, 'Total loss': 0.2893932766384549}
2023-01-05 09:37:49,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:37:49,568 INFO:     Epoch: 60
2023-01-05 09:37:51,671 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.36913055976231895, 'Total loss': 0.36913055976231895} | train loss {'Reaction outcome loss': 0.28208717760388496, 'Total loss': 0.28208717760388496}
2023-01-05 09:37:51,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:37:51,672 INFO:     Epoch: 61
2023-01-05 09:37:53,768 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4349942535161972, 'Total loss': 0.4349942535161972} | train loss {'Reaction outcome loss': 0.2865954016921697, 'Total loss': 0.2865954016921697}
2023-01-05 09:37:53,768 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:37:53,768 INFO:     Epoch: 62
2023-01-05 09:37:55,831 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.3887814665834109, 'Total loss': 0.3887814665834109} | train loss {'Reaction outcome loss': 0.2820338881953999, 'Total loss': 0.2820338881953999}
2023-01-05 09:37:55,831 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:37:55,832 INFO:     Epoch: 63
2023-01-05 09:37:57,903 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.430672279993693, 'Total loss': 0.430672279993693} | train loss {'Reaction outcome loss': 0.27739424815884345, 'Total loss': 0.27739424815884345}
2023-01-05 09:37:57,903 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:37:57,903 INFO:     Epoch: 64
2023-01-05 09:38:00,012 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3965167239308357, 'Total loss': 0.3965167239308357} | train loss {'Reaction outcome loss': 0.2827175667992345, 'Total loss': 0.2827175667992345}
2023-01-05 09:38:00,013 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:38:00,013 INFO:     Epoch: 65
2023-01-05 09:38:02,107 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.429620128373305, 'Total loss': 0.429620128373305} | train loss {'Reaction outcome loss': 0.2755604444692532, 'Total loss': 0.2755604444692532}
2023-01-05 09:38:02,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:38:02,107 INFO:     Epoch: 66
2023-01-05 09:38:04,018 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.38120062574744223, 'Total loss': 0.38120062574744223} | train loss {'Reaction outcome loss': 0.28101251100500424, 'Total loss': 0.28101251100500424}
2023-01-05 09:38:04,018 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:38:04,019 INFO:     Epoch: 67
2023-01-05 09:38:06,091 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.39042449196179707, 'Total loss': 0.39042449196179707} | train loss {'Reaction outcome loss': 0.27150903443495433, 'Total loss': 0.27150903443495433}
2023-01-05 09:38:06,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:38:06,092 INFO:     Epoch: 68
2023-01-05 09:38:08,171 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4387107213338216, 'Total loss': 0.4387107213338216} | train loss {'Reaction outcome loss': 0.2724210402065957, 'Total loss': 0.2724210402065957}
2023-01-05 09:38:08,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:38:08,171 INFO:     Epoch: 69
2023-01-05 09:38:10,248 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.39770094156265257, 'Total loss': 0.39770094156265257} | train loss {'Reaction outcome loss': 0.26742396236707766, 'Total loss': 0.26742396236707766}
2023-01-05 09:38:10,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:38:10,248 INFO:     Epoch: 70
2023-01-05 09:38:12,352 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.37135739078124363, 'Total loss': 0.37135739078124363} | train loss {'Reaction outcome loss': 0.26807345787270204, 'Total loss': 0.26807345787270204}
2023-01-05 09:38:12,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:38:12,352 INFO:     Epoch: 71
2023-01-05 09:38:14,444 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3762527068456014, 'Total loss': 0.3762527068456014} | train loss {'Reaction outcome loss': 0.27205277765514674, 'Total loss': 0.27205277765514674}
2023-01-05 09:38:14,444 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:38:14,445 INFO:     Epoch: 72
2023-01-05 09:38:16,525 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3918124427398046, 'Total loss': 0.3918124427398046} | train loss {'Reaction outcome loss': 0.2668412661800782, 'Total loss': 0.2668412661800782}
2023-01-05 09:38:16,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:38:16,526 INFO:     Epoch: 73
2023-01-05 09:38:18,611 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.41538613140583036, 'Total loss': 0.41538613140583036} | train loss {'Reaction outcome loss': 0.2677172425513466, 'Total loss': 0.2677172425513466}
2023-01-05 09:38:18,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:38:18,611 INFO:     Epoch: 74
2023-01-05 09:38:20,699 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3860887439921498, 'Total loss': 0.3860887439921498} | train loss {'Reaction outcome loss': 0.26947060072863543, 'Total loss': 0.26947060072863543}
2023-01-05 09:38:20,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:38:20,699 INFO:     Epoch: 75
2023-01-05 09:38:22,807 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.36740031333950657, 'Total loss': 0.36740031333950657} | train loss {'Reaction outcome loss': 0.2649244748400869, 'Total loss': 0.2649244748400869}
2023-01-05 09:38:22,808 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:38:22,808 INFO:     Epoch: 76
2023-01-05 09:38:24,920 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4149707357088725, 'Total loss': 0.4149707357088725} | train loss {'Reaction outcome loss': 0.2572246340034461, 'Total loss': 0.2572246340034461}
2023-01-05 09:38:24,920 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:38:24,920 INFO:     Epoch: 77
2023-01-05 09:38:27,003 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.38642511566480003, 'Total loss': 0.38642511566480003} | train loss {'Reaction outcome loss': 0.2568710313902961, 'Total loss': 0.2568710313902961}
2023-01-05 09:38:27,004 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:38:27,004 INFO:     Epoch: 78
2023-01-05 09:38:29,086 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3544612308343252, 'Total loss': 0.3544612308343252} | train loss {'Reaction outcome loss': 0.25329567890752247, 'Total loss': 0.25329567890752247}
2023-01-05 09:38:29,086 INFO:     Found new best model at epoch 78
2023-01-05 09:38:29,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:38:29,087 INFO:     Epoch: 79
2023-01-05 09:38:31,174 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.42778628766536714, 'Total loss': 0.42778628766536714} | train loss {'Reaction outcome loss': 0.25554517887670686, 'Total loss': 0.25554517887670686}
2023-01-05 09:38:31,174 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:38:31,174 INFO:     Epoch: 80
2023-01-05 09:38:33,263 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3609704050545891, 'Total loss': 0.3609704050545891} | train loss {'Reaction outcome loss': 0.2601909134812929, 'Total loss': 0.2601909134812929}
2023-01-05 09:38:33,263 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:38:33,263 INFO:     Epoch: 81
2023-01-05 09:38:35,342 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3743382821480433, 'Total loss': 0.3743382821480433} | train loss {'Reaction outcome loss': 0.25567444925782856, 'Total loss': 0.25567444925782856}
2023-01-05 09:38:35,343 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:38:35,343 INFO:     Epoch: 82
2023-01-05 09:38:37,423 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3811724374691645, 'Total loss': 0.3811724374691645} | train loss {'Reaction outcome loss': 0.2555770602077246, 'Total loss': 0.2555770602077246}
2023-01-05 09:38:37,423 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:38:37,423 INFO:     Epoch: 83
2023-01-05 09:38:39,499 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.36628689519905794, 'Total loss': 0.36628689519905794} | train loss {'Reaction outcome loss': 0.2582887144828284, 'Total loss': 0.2582887144828284}
2023-01-05 09:38:39,499 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:38:39,500 INFO:     Epoch: 84
2023-01-05 09:38:41,584 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.36885540882746376, 'Total loss': 0.36885540882746376} | train loss {'Reaction outcome loss': 0.25062502564310474, 'Total loss': 0.25062502564310474}
2023-01-05 09:38:41,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:38:41,585 INFO:     Epoch: 85
2023-01-05 09:38:43,658 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3946969896554947, 'Total loss': 0.3946969896554947} | train loss {'Reaction outcome loss': 0.24963179336929764, 'Total loss': 0.24963179336929764}
2023-01-05 09:38:43,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:38:43,658 INFO:     Epoch: 86
2023-01-05 09:38:45,749 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.31303425030782817, 'Total loss': 0.31303425030782817} | train loss {'Reaction outcome loss': 0.2485823104571965, 'Total loss': 0.2485823104571965}
2023-01-05 09:38:45,749 INFO:     Found new best model at epoch 86
2023-01-05 09:38:45,751 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:38:45,751 INFO:     Epoch: 87
2023-01-05 09:38:47,830 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.4106697996457418, 'Total loss': 0.4106697996457418} | train loss {'Reaction outcome loss': 0.24159648817170548, 'Total loss': 0.24159648817170548}
2023-01-05 09:38:47,830 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:38:47,830 INFO:     Epoch: 88
2023-01-05 09:38:49,927 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3874512096246084, 'Total loss': 0.3874512096246084} | train loss {'Reaction outcome loss': 0.23731970383475223, 'Total loss': 0.23731970383475223}
2023-01-05 09:38:49,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:38:49,927 INFO:     Epoch: 89
2023-01-05 09:38:51,986 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.39860230187575024, 'Total loss': 0.39860230187575024} | train loss {'Reaction outcome loss': 0.24805081723499353, 'Total loss': 0.24805081723499353}
2023-01-05 09:38:51,987 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:38:51,987 INFO:     Epoch: 90
2023-01-05 09:38:54,082 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.41782362560431163, 'Total loss': 0.41782362560431163} | train loss {'Reaction outcome loss': 0.23689612666903823, 'Total loss': 0.23689612666903823}
2023-01-05 09:38:54,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:38:54,082 INFO:     Epoch: 91
2023-01-05 09:38:56,154 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3928413430849711, 'Total loss': 0.3928413430849711} | train loss {'Reaction outcome loss': 0.23924688901062366, 'Total loss': 0.23924688901062366}
2023-01-05 09:38:56,154 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:38:56,154 INFO:     Epoch: 92
2023-01-05 09:38:58,230 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4387065569559733, 'Total loss': 0.4387065569559733} | train loss {'Reaction outcome loss': 0.2418692141495369, 'Total loss': 0.2418692141495369}
2023-01-05 09:38:58,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:38:58,231 INFO:     Epoch: 93
2023-01-05 09:39:00,322 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.36184685627619423, 'Total loss': 0.36184685627619423} | train loss {'Reaction outcome loss': 0.2406648111546895, 'Total loss': 0.2406648111546895}
2023-01-05 09:39:00,322 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:39:00,322 INFO:     Epoch: 94
2023-01-05 09:39:02,413 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.42343406279881796, 'Total loss': 0.42343406279881796} | train loss {'Reaction outcome loss': 0.24370918179758722, 'Total loss': 0.24370918179758722}
2023-01-05 09:39:02,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:39:02,414 INFO:     Epoch: 95
2023-01-05 09:39:04,494 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.36224436859289805, 'Total loss': 0.36224436859289805} | train loss {'Reaction outcome loss': 0.23949974714605896, 'Total loss': 0.23949974714605896}
2023-01-05 09:39:04,494 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:39:04,494 INFO:     Epoch: 96
2023-01-05 09:39:06,583 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.42977002263069153, 'Total loss': 0.42977002263069153} | train loss {'Reaction outcome loss': 0.23271834294277208, 'Total loss': 0.23271834294277208}
2023-01-05 09:39:06,583 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:39:06,583 INFO:     Epoch: 97
2023-01-05 09:39:08,658 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.37019105156262716, 'Total loss': 0.37019105156262716} | train loss {'Reaction outcome loss': 0.23638196072230735, 'Total loss': 0.23638196072230735}
2023-01-05 09:39:08,658 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:39:08,658 INFO:     Epoch: 98
2023-01-05 09:39:10,749 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4660784065723419, 'Total loss': 0.4660784065723419} | train loss {'Reaction outcome loss': 0.2358738797682303, 'Total loss': 0.2358738797682303}
2023-01-05 09:39:10,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:39:10,750 INFO:     Epoch: 99
2023-01-05 09:39:12,845 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3444664764761304, 'Total loss': 0.3444664764761304} | train loss {'Reaction outcome loss': 0.23309437254512752, 'Total loss': 0.23309437254512752}
2023-01-05 09:39:12,846 INFO:     Best model found after epoch 87 of 100.
2023-01-05 09:39:12,846 INFO:   Done with stage: TRAINING
2023-01-05 09:39:12,846 INFO:   Starting stage: EVALUATION
2023-01-05 09:39:13,002 INFO:   Done with stage: EVALUATION
2023-01-05 09:39:13,003 INFO:   Leaving out SEQ value Fold_3
2023-01-05 09:39:13,015 INFO:   examples: 20,544| examples in train: 17,419 | examples in val: 917| examples in test: 2,208
2023-01-05 09:39:13,015 INFO:   Starting stage: FEATURE SCALING
2023-01-05 09:39:13,658 INFO:   Done with stage: FEATURE SCALING
2023-01-05 09:39:13,658 INFO:   Starting stage: SCALING TARGETS
2023-01-05 09:39:13,726 INFO:   Done with stage: SCALING TARGETS
2023-01-05 09:39:13,726 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:39:13,726 INFO:     No hyperparam tuning for this model
2023-01-05 09:39:13,726 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:39:13,726 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 09:39:13,727 INFO:     None feature selector for col prot
2023-01-05 09:39:13,727 INFO:     None feature selector for col prot
2023-01-05 09:39:13,727 INFO:     None feature selector for col prot
2023-01-05 09:39:13,727 INFO:     None feature selector for col chem
2023-01-05 09:39:13,728 INFO:     None feature selector for col chem
2023-01-05 09:39:13,728 INFO:     None feature selector for col chem
2023-01-05 09:39:13,728 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 09:39:13,728 INFO:   Starting stage: BUILD MODEL
2023-01-05 09:39:13,729 INFO:     Number of params in model 72901
2023-01-05 09:39:13,732 INFO:   Done with stage: BUILD MODEL
2023-01-05 09:39:13,732 INFO:   Starting stage: TRAINING
2023-01-05 09:39:13,792 INFO:     Val loss before train {'Reaction outcome loss': 1.0199561357498168, 'Total loss': 1.0199561357498168}
2023-01-05 09:39:13,792 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:39:13,792 INFO:     Epoch: 0
2023-01-05 09:39:15,903 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8667242844899495, 'Total loss': 0.8667242844899495} | train loss {'Reaction outcome loss': 0.9355258739693261, 'Total loss': 0.9355258739693261}
2023-01-05 09:39:15,903 INFO:     Found new best model at epoch 0
2023-01-05 09:39:15,905 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:39:15,905 INFO:     Epoch: 1
2023-01-05 09:39:18,004 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6777954777081807, 'Total loss': 0.6777954777081807} | train loss {'Reaction outcome loss': 0.7577430873345106, 'Total loss': 0.7577430873345106}
2023-01-05 09:39:18,004 INFO:     Found new best model at epoch 1
2023-01-05 09:39:18,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:39:18,006 INFO:     Epoch: 2
2023-01-05 09:39:20,109 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5581506808598836, 'Total loss': 0.5581506808598836} | train loss {'Reaction outcome loss': 0.6166461043250866, 'Total loss': 0.6166461043250866}
2023-01-05 09:39:20,109 INFO:     Found new best model at epoch 2
2023-01-05 09:39:20,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:39:20,111 INFO:     Epoch: 3
2023-01-05 09:39:22,219 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5196184158325196, 'Total loss': 0.5196184158325196} | train loss {'Reaction outcome loss': 0.5455821577882592, 'Total loss': 0.5455821577882592}
2023-01-05 09:39:22,219 INFO:     Found new best model at epoch 3
2023-01-05 09:39:22,220 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:39:22,221 INFO:     Epoch: 4
2023-01-05 09:39:24,342 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4943484753370285, 'Total loss': 0.4943484753370285} | train loss {'Reaction outcome loss': 0.522595267756518, 'Total loss': 0.522595267756518}
2023-01-05 09:39:24,342 INFO:     Found new best model at epoch 4
2023-01-05 09:39:24,344 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:39:24,344 INFO:     Epoch: 5
2023-01-05 09:39:26,453 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48710838754971825, 'Total loss': 0.48710838754971825} | train loss {'Reaction outcome loss': 0.5043614215248233, 'Total loss': 0.5043614215248233}
2023-01-05 09:39:26,453 INFO:     Found new best model at epoch 5
2023-01-05 09:39:26,454 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:39:26,454 INFO:     Epoch: 6
2023-01-05 09:39:28,538 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5067018399635951, 'Total loss': 0.5067018399635951} | train loss {'Reaction outcome loss': 0.5013373887145912, 'Total loss': 0.5013373887145912}
2023-01-05 09:39:28,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:39:28,539 INFO:     Epoch: 7
2023-01-05 09:39:30,663 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.5495504061381022, 'Total loss': 0.5495504061381022} | train loss {'Reaction outcome loss': 0.49023659701967415, 'Total loss': 0.49023659701967415}
2023-01-05 09:39:30,663 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:39:30,663 INFO:     Epoch: 8
2023-01-05 09:39:32,764 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.49238746662934624, 'Total loss': 0.49238746662934624} | train loss {'Reaction outcome loss': 0.48344029862802107, 'Total loss': 0.48344029862802107}
2023-01-05 09:39:32,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:39:32,764 INFO:     Epoch: 9
2023-01-05 09:39:34,883 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.451219113667806, 'Total loss': 0.451219113667806} | train loss {'Reaction outcome loss': 0.4761668930014411, 'Total loss': 0.4761668930014411}
2023-01-05 09:39:34,884 INFO:     Found new best model at epoch 9
2023-01-05 09:39:34,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:39:34,885 INFO:     Epoch: 10
2023-01-05 09:39:37,009 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.47807146509488424, 'Total loss': 0.47807146509488424} | train loss {'Reaction outcome loss': 0.46804771327410205, 'Total loss': 0.46804771327410205}
2023-01-05 09:39:37,009 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:39:37,009 INFO:     Epoch: 11
2023-01-05 09:39:39,126 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.49076449672381084, 'Total loss': 0.49076449672381084} | train loss {'Reaction outcome loss': 0.4635873850121166, 'Total loss': 0.4635873850121166}
2023-01-05 09:39:39,127 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:39:39,127 INFO:     Epoch: 12
2023-01-05 09:39:41,244 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44850245614846546, 'Total loss': 0.44850245614846546} | train loss {'Reaction outcome loss': 0.45682912562792993, 'Total loss': 0.45682912562792993}
2023-01-05 09:39:41,244 INFO:     Found new best model at epoch 12
2023-01-05 09:39:41,246 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:39:41,246 INFO:     Epoch: 13
2023-01-05 09:39:43,361 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47638323505719504, 'Total loss': 0.47638323505719504} | train loss {'Reaction outcome loss': 0.4565175553927055, 'Total loss': 0.4565175553927055}
2023-01-05 09:39:43,361 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:39:43,361 INFO:     Epoch: 14
2023-01-05 09:39:45,479 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45706709623336794, 'Total loss': 0.45706709623336794} | train loss {'Reaction outcome loss': 0.4423938484200628, 'Total loss': 0.4423938484200628}
2023-01-05 09:39:45,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:39:45,480 INFO:     Epoch: 15
2023-01-05 09:39:47,595 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.45471130808194477, 'Total loss': 0.45471130808194477} | train loss {'Reaction outcome loss': 0.4500878916664438, 'Total loss': 0.4500878916664438}
2023-01-05 09:39:47,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:39:47,596 INFO:     Epoch: 16
2023-01-05 09:39:49,710 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4515371024608612, 'Total loss': 0.4515371024608612} | train loss {'Reaction outcome loss': 0.44125742778768795, 'Total loss': 0.44125742778768795}
2023-01-05 09:39:49,710 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:39:49,710 INFO:     Epoch: 17
2023-01-05 09:39:51,829 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4670082072416941, 'Total loss': 0.4670082072416941} | train loss {'Reaction outcome loss': 0.4337956726332724, 'Total loss': 0.4337956726332724}
2023-01-05 09:39:51,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:39:51,829 INFO:     Epoch: 18
2023-01-05 09:39:53,933 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4570038288831711, 'Total loss': 0.4570038288831711} | train loss {'Reaction outcome loss': 0.42946899564929936, 'Total loss': 0.42946899564929936}
2023-01-05 09:39:53,933 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:39:53,933 INFO:     Epoch: 19
2023-01-05 09:39:56,053 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.456413663427035, 'Total loss': 0.456413663427035} | train loss {'Reaction outcome loss': 0.42618398122735074, 'Total loss': 0.42618398122735074}
2023-01-05 09:39:56,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:39:56,053 INFO:     Epoch: 20
2023-01-05 09:39:58,167 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43086938659350077, 'Total loss': 0.43086938659350077} | train loss {'Reaction outcome loss': 0.41932686399190855, 'Total loss': 0.41932686399190855}
2023-01-05 09:39:58,168 INFO:     Found new best model at epoch 20
2023-01-05 09:39:58,169 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:39:58,169 INFO:     Epoch: 21
2023-01-05 09:40:00,305 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43932961026827494, 'Total loss': 0.43932961026827494} | train loss {'Reaction outcome loss': 0.4197605222245276, 'Total loss': 0.4197605222245276}
2023-01-05 09:40:00,306 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:40:00,306 INFO:     Epoch: 22
2023-01-05 09:40:02,430 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4502255618572235, 'Total loss': 0.4502255618572235} | train loss {'Reaction outcome loss': 0.41496778623415875, 'Total loss': 0.41496778623415875}
2023-01-05 09:40:02,430 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:40:02,430 INFO:     Epoch: 23
2023-01-05 09:40:04,547 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4845860203107198, 'Total loss': 0.4845860203107198} | train loss {'Reaction outcome loss': 0.4140168848164352, 'Total loss': 0.4140168848164352}
2023-01-05 09:40:04,548 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:40:04,549 INFO:     Epoch: 24
2023-01-05 09:40:06,655 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4389050910870234, 'Total loss': 0.4389050910870234} | train loss {'Reaction outcome loss': 0.4065300973452928, 'Total loss': 0.4065300973452928}
2023-01-05 09:40:06,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:40:06,655 INFO:     Epoch: 25
2023-01-05 09:40:08,766 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.41679556518793104, 'Total loss': 0.41679556518793104} | train loss {'Reaction outcome loss': 0.40028582647060734, 'Total loss': 0.40028582647060734}
2023-01-05 09:40:08,766 INFO:     Found new best model at epoch 25
2023-01-05 09:40:08,767 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:40:08,767 INFO:     Epoch: 26
2023-01-05 09:40:10,886 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4393989771604538, 'Total loss': 0.4393989771604538} | train loss {'Reaction outcome loss': 0.40109052842025794, 'Total loss': 0.40109052842025794}
2023-01-05 09:40:10,887 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:40:10,887 INFO:     Epoch: 27
2023-01-05 09:40:13,002 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.5079152554273605, 'Total loss': 0.5079152554273605} | train loss {'Reaction outcome loss': 0.39546185931115796, 'Total loss': 0.39546185931115796}
2023-01-05 09:40:13,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:40:13,002 INFO:     Epoch: 28
2023-01-05 09:40:15,107 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.43095326821009317, 'Total loss': 0.43095326821009317} | train loss {'Reaction outcome loss': 0.3853657995879432, 'Total loss': 0.3853657995879432}
2023-01-05 09:40:15,107 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:40:15,107 INFO:     Epoch: 29
2023-01-05 09:40:17,213 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4299678772687912, 'Total loss': 0.4299678772687912} | train loss {'Reaction outcome loss': 0.38744920123736937, 'Total loss': 0.38744920123736937}
2023-01-05 09:40:17,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:40:17,213 INFO:     Epoch: 30
2023-01-05 09:40:19,296 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.4437924395004908, 'Total loss': 0.4437924395004908} | train loss {'Reaction outcome loss': 0.38759017498283593, 'Total loss': 0.38759017498283593}
2023-01-05 09:40:19,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:40:19,297 INFO:     Epoch: 31
2023-01-05 09:40:21,413 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.41258635073900224, 'Total loss': 0.41258635073900224} | train loss {'Reaction outcome loss': 0.38126213395551883, 'Total loss': 0.38126213395551883}
2023-01-05 09:40:21,413 INFO:     Found new best model at epoch 31
2023-01-05 09:40:21,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:40:21,414 INFO:     Epoch: 32
2023-01-05 09:40:23,520 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.42708840370178225, 'Total loss': 0.42708840370178225} | train loss {'Reaction outcome loss': 0.3791416341459358, 'Total loss': 0.3791416341459358}
2023-01-05 09:40:23,521 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:40:23,521 INFO:     Epoch: 33
2023-01-05 09:40:25,614 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4318098564942678, 'Total loss': 0.4318098564942678} | train loss {'Reaction outcome loss': 0.3724678344069383, 'Total loss': 0.3724678344069383}
2023-01-05 09:40:25,614 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:40:25,614 INFO:     Epoch: 34
2023-01-05 09:40:27,699 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4214138925075531, 'Total loss': 0.4214138925075531} | train loss {'Reaction outcome loss': 0.3651848768494723, 'Total loss': 0.3651848768494723}
2023-01-05 09:40:27,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:40:27,700 INFO:     Epoch: 35
2023-01-05 09:40:29,814 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4216885363062223, 'Total loss': 0.4216885363062223} | train loss {'Reaction outcome loss': 0.3638101585564159, 'Total loss': 0.3638101585564159}
2023-01-05 09:40:29,814 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:40:29,814 INFO:     Epoch: 36
2023-01-05 09:40:31,955 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4172421097755432, 'Total loss': 0.4172421097755432} | train loss {'Reaction outcome loss': 0.3688944747378101, 'Total loss': 0.3688944747378101}
2023-01-05 09:40:31,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:40:31,956 INFO:     Epoch: 37
2023-01-05 09:40:34,054 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43587926824887596, 'Total loss': 0.43587926824887596} | train loss {'Reaction outcome loss': 0.35754691858540527, 'Total loss': 0.35754691858540527}
2023-01-05 09:40:34,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:40:34,054 INFO:     Epoch: 38
2023-01-05 09:40:36,161 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.46239777505397794, 'Total loss': 0.46239777505397794} | train loss {'Reaction outcome loss': 0.36166539048646396, 'Total loss': 0.36166539048646396}
2023-01-05 09:40:36,161 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:40:36,161 INFO:     Epoch: 39
2023-01-05 09:40:38,262 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4824198772509893, 'Total loss': 0.4824198772509893} | train loss {'Reaction outcome loss': 0.35002783103249013, 'Total loss': 0.35002783103249013}
2023-01-05 09:40:38,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:40:38,262 INFO:     Epoch: 40
2023-01-05 09:40:40,356 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4324309060970942, 'Total loss': 0.4324309060970942} | train loss {'Reaction outcome loss': 0.3575507303897714, 'Total loss': 0.3575507303897714}
2023-01-05 09:40:40,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:40:40,357 INFO:     Epoch: 41
2023-01-05 09:40:42,477 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4190235460797946, 'Total loss': 0.4190235460797946} | train loss {'Reaction outcome loss': 0.3491570098059518, 'Total loss': 0.3491570098059518}
2023-01-05 09:40:42,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:40:42,477 INFO:     Epoch: 42
2023-01-05 09:40:44,579 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4166158284371098, 'Total loss': 0.4166158284371098} | train loss {'Reaction outcome loss': 0.3439340643011607, 'Total loss': 0.3439340643011607}
2023-01-05 09:40:44,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:40:44,579 INFO:     Epoch: 43
2023-01-05 09:40:46,691 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.42232609788576764, 'Total loss': 0.42232609788576764} | train loss {'Reaction outcome loss': 0.3424083945706432, 'Total loss': 0.3424083945706432}
2023-01-05 09:40:46,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:40:46,692 INFO:     Epoch: 44
2023-01-05 09:40:48,820 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42655277748902637, 'Total loss': 0.42655277748902637} | train loss {'Reaction outcome loss': 0.3351840613539511, 'Total loss': 0.3351840613539511}
2023-01-05 09:40:48,820 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:40:48,820 INFO:     Epoch: 45
2023-01-05 09:40:50,925 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4220222463210424, 'Total loss': 0.4220222463210424} | train loss {'Reaction outcome loss': 0.3421667386596893, 'Total loss': 0.3421667386596893}
2023-01-05 09:40:50,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:40:50,926 INFO:     Epoch: 46
2023-01-05 09:40:53,029 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.44264084498087564, 'Total loss': 0.44264084498087564} | train loss {'Reaction outcome loss': 0.33657161925574797, 'Total loss': 0.33657161925574797}
2023-01-05 09:40:53,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:40:53,030 INFO:     Epoch: 47
2023-01-05 09:40:55,145 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4232115705808004, 'Total loss': 0.4232115705808004} | train loss {'Reaction outcome loss': 0.33310817753821065, 'Total loss': 0.33310817753821065}
2023-01-05 09:40:55,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:40:55,145 INFO:     Epoch: 48
2023-01-05 09:40:57,243 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.42213149070739747, 'Total loss': 0.42213149070739747} | train loss {'Reaction outcome loss': 0.3354734194229592, 'Total loss': 0.3354734194229592}
2023-01-05 09:40:57,243 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:40:57,243 INFO:     Epoch: 49
2023-01-05 09:40:59,327 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.42275146146615344, 'Total loss': 0.42275146146615344} | train loss {'Reaction outcome loss': 0.33242300701337857, 'Total loss': 0.33242300701337857}
2023-01-05 09:40:59,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:40:59,328 INFO:     Epoch: 50
2023-01-05 09:41:01,451 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4209607750177383, 'Total loss': 0.4209607750177383} | train loss {'Reaction outcome loss': 0.33760838955640793, 'Total loss': 0.33760838955640793}
2023-01-05 09:41:01,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:41:01,452 INFO:     Epoch: 51
2023-01-05 09:41:03,553 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.43348923524220784, 'Total loss': 0.43348923524220784} | train loss {'Reaction outcome loss': 0.32373602579146515, 'Total loss': 0.32373602579146515}
2023-01-05 09:41:03,553 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:41:03,553 INFO:     Epoch: 52
2023-01-05 09:41:05,665 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.4283955762783686, 'Total loss': 0.4283955762783686} | train loss {'Reaction outcome loss': 0.31910919518152, 'Total loss': 0.31910919518152}
2023-01-05 09:41:05,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:41:05,665 INFO:     Epoch: 53
2023-01-05 09:41:07,781 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4373187243938446, 'Total loss': 0.4373187243938446} | train loss {'Reaction outcome loss': 0.3176865816498414, 'Total loss': 0.3176865816498414}
2023-01-05 09:41:07,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:41:07,781 INFO:     Epoch: 54
2023-01-05 09:41:09,908 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4383655826250712, 'Total loss': 0.4383655826250712} | train loss {'Reaction outcome loss': 0.31266586326963297, 'Total loss': 0.31266586326963297}
2023-01-05 09:41:09,908 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:41:09,908 INFO:     Epoch: 55
2023-01-05 09:41:11,992 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.43695948521296185, 'Total loss': 0.43695948521296185} | train loss {'Reaction outcome loss': 0.3148095807190234, 'Total loss': 0.3148095807190234}
2023-01-05 09:41:11,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:41:11,992 INFO:     Epoch: 56
2023-01-05 09:41:14,092 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4716823697090149, 'Total loss': 0.4716823697090149} | train loss {'Reaction outcome loss': 0.3091757902841428, 'Total loss': 0.3091757902841428}
2023-01-05 09:41:14,093 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:41:14,093 INFO:     Epoch: 57
2023-01-05 09:41:16,199 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.44684777160485584, 'Total loss': 0.44684777160485584} | train loss {'Reaction outcome loss': 0.3074178919196129, 'Total loss': 0.3074178919196129}
2023-01-05 09:41:16,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:41:16,201 INFO:     Epoch: 58
2023-01-05 09:41:18,295 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4057998945315679, 'Total loss': 0.4057998945315679} | train loss {'Reaction outcome loss': 0.31336209126117026, 'Total loss': 0.31336209126117026}
2023-01-05 09:41:18,295 INFO:     Found new best model at epoch 58
2023-01-05 09:41:18,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:41:18,296 INFO:     Epoch: 59
2023-01-05 09:41:20,413 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4237480918566386, 'Total loss': 0.4237480918566386} | train loss {'Reaction outcome loss': 0.3113996709113593, 'Total loss': 0.3113996709113593}
2023-01-05 09:41:20,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:41:20,414 INFO:     Epoch: 60
2023-01-05 09:41:22,501 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4429675797621409, 'Total loss': 0.4429675797621409} | train loss {'Reaction outcome loss': 0.29835219853199446, 'Total loss': 0.29835219853199446}
2023-01-05 09:41:22,502 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:41:22,502 INFO:     Epoch: 61
2023-01-05 09:41:24,587 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.44944496055444083, 'Total loss': 0.44944496055444083} | train loss {'Reaction outcome loss': 0.2980234485320856, 'Total loss': 0.2980234485320856}
2023-01-05 09:41:24,588 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:41:24,588 INFO:     Epoch: 62
2023-01-05 09:41:26,697 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4549425701300303, 'Total loss': 0.4549425701300303} | train loss {'Reaction outcome loss': 0.29578425967895283, 'Total loss': 0.29578425967895283}
2023-01-05 09:41:26,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:41:26,697 INFO:     Epoch: 63
2023-01-05 09:41:28,842 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.42510029872258503, 'Total loss': 0.42510029872258503} | train loss {'Reaction outcome loss': 0.29669786266464016, 'Total loss': 0.29669786266464016}
2023-01-05 09:41:28,842 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:41:28,842 INFO:     Epoch: 64
2023-01-05 09:41:30,940 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43065574765205383, 'Total loss': 0.43065574765205383} | train loss {'Reaction outcome loss': 0.29761291288296543, 'Total loss': 0.29761291288296543}
2023-01-05 09:41:30,940 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:41:30,940 INFO:     Epoch: 65
2023-01-05 09:41:33,041 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41616415878136953, 'Total loss': 0.41616415878136953} | train loss {'Reaction outcome loss': 0.2938436637786064, 'Total loss': 0.2938436637786064}
2023-01-05 09:41:33,041 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:41:33,041 INFO:     Epoch: 66
2023-01-05 09:41:35,142 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.45199795862038933, 'Total loss': 0.45199795862038933} | train loss {'Reaction outcome loss': 0.28993125981736534, 'Total loss': 0.28993125981736534}
2023-01-05 09:41:35,143 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:41:35,143 INFO:     Epoch: 67
2023-01-05 09:41:37,209 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4163450906674067, 'Total loss': 0.4163450906674067} | train loss {'Reaction outcome loss': 0.295856733243544, 'Total loss': 0.295856733243544}
2023-01-05 09:41:37,209 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:41:37,209 INFO:     Epoch: 68
2023-01-05 09:41:39,298 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4532232811053594, 'Total loss': 0.4532232811053594} | train loss {'Reaction outcome loss': 0.29097775132446496, 'Total loss': 0.29097775132446496}
2023-01-05 09:41:39,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:41:39,298 INFO:     Epoch: 69
2023-01-05 09:41:41,415 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.45744568705558775, 'Total loss': 0.45744568705558775} | train loss {'Reaction outcome loss': 0.28678093954320355, 'Total loss': 0.28678093954320355}
2023-01-05 09:41:41,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:41:41,415 INFO:     Epoch: 70
2023-01-05 09:41:43,534 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.42366628448168436, 'Total loss': 0.42366628448168436} | train loss {'Reaction outcome loss': 0.28785285063006066, 'Total loss': 0.28785285063006066}
2023-01-05 09:41:43,534 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:41:43,534 INFO:     Epoch: 71
2023-01-05 09:41:45,627 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.4535749802986781, 'Total loss': 0.4535749802986781} | train loss {'Reaction outcome loss': 0.2743604356020471, 'Total loss': 0.2743604356020471}
2023-01-05 09:41:45,627 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:41:45,627 INFO:     Epoch: 72
2023-01-05 09:41:47,742 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44004085461298625, 'Total loss': 0.44004085461298625} | train loss {'Reaction outcome loss': 0.2820453301495139, 'Total loss': 0.2820453301495139}
2023-01-05 09:41:47,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:41:47,743 INFO:     Epoch: 73
2023-01-05 09:41:49,643 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.42344953020413717, 'Total loss': 0.42344953020413717} | train loss {'Reaction outcome loss': 0.28022850107319736, 'Total loss': 0.28022850107319736}
2023-01-05 09:41:49,644 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:41:49,644 INFO:     Epoch: 74
2023-01-05 09:41:51,387 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4546826352675756, 'Total loss': 0.4546826352675756} | train loss {'Reaction outcome loss': 0.27552200423983425, 'Total loss': 0.27552200423983425}
2023-01-05 09:41:51,388 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:41:51,388 INFO:     Epoch: 75
2023-01-05 09:41:53,166 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4568520615498225, 'Total loss': 0.4568520615498225} | train loss {'Reaction outcome loss': 0.275204174220562, 'Total loss': 0.275204174220562}
2023-01-05 09:41:53,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:41:53,166 INFO:     Epoch: 76
2023-01-05 09:41:55,279 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.44722263763348263, 'Total loss': 0.44722263763348263} | train loss {'Reaction outcome loss': 0.2727625922678591, 'Total loss': 0.2727625922678591}
2023-01-05 09:41:55,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:41:55,280 INFO:     Epoch: 77
2023-01-05 09:41:57,372 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4697447657585144, 'Total loss': 0.4697447657585144} | train loss {'Reaction outcome loss': 0.28023284935689236, 'Total loss': 0.28023284935689236}
2023-01-05 09:41:57,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:41:57,373 INFO:     Epoch: 78
2023-01-05 09:41:59,514 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.45433021982510885, 'Total loss': 0.45433021982510885} | train loss {'Reaction outcome loss': 0.27218778760278184, 'Total loss': 0.27218778760278184}
2023-01-05 09:41:59,515 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:41:59,515 INFO:     Epoch: 79
2023-01-05 09:42:01,592 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4406283967196941, 'Total loss': 0.4406283967196941} | train loss {'Reaction outcome loss': 0.278271277677336, 'Total loss': 0.278271277677336}
2023-01-05 09:42:01,593 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:42:01,593 INFO:     Epoch: 80
2023-01-05 09:42:03,526 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4192438278968135, 'Total loss': 0.4192438278968135} | train loss {'Reaction outcome loss': 0.2720287930793487, 'Total loss': 0.2720287930793487}
2023-01-05 09:42:03,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:42:03,526 INFO:     Epoch: 81
2023-01-05 09:42:05,586 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4437435338894526, 'Total loss': 0.4437435338894526} | train loss {'Reaction outcome loss': 0.26630308674204917, 'Total loss': 0.26630308674204917}
2023-01-05 09:42:05,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:42:05,586 INFO:     Epoch: 82
2023-01-05 09:42:07,690 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4219611903031667, 'Total loss': 0.4219611903031667} | train loss {'Reaction outcome loss': 0.2690844116084305, 'Total loss': 0.2690844116084305}
2023-01-05 09:42:07,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:42:07,691 INFO:     Epoch: 83
2023-01-05 09:42:09,785 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.44024420380592344, 'Total loss': 0.44024420380592344} | train loss {'Reaction outcome loss': 0.26635623084476745, 'Total loss': 0.26635623084476745}
2023-01-05 09:42:09,785 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:42:09,785 INFO:     Epoch: 84
2023-01-05 09:42:11,877 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.41875154078006743, 'Total loss': 0.41875154078006743} | train loss {'Reaction outcome loss': 0.26848291244098554, 'Total loss': 0.26848291244098554}
2023-01-05 09:42:11,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:42:11,878 INFO:     Epoch: 85
2023-01-05 09:42:13,984 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4362453361352285, 'Total loss': 0.4362453361352285} | train loss {'Reaction outcome loss': 0.2617951940485846, 'Total loss': 0.2617951940485846}
2023-01-05 09:42:13,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:42:13,984 INFO:     Epoch: 86
2023-01-05 09:42:16,082 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.44164841634531815, 'Total loss': 0.44164841634531815} | train loss {'Reaction outcome loss': 0.25941872947777694, 'Total loss': 0.25941872947777694}
2023-01-05 09:42:16,082 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:42:16,083 INFO:     Epoch: 87
2023-01-05 09:42:18,202 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.45212584137916567, 'Total loss': 0.45212584137916567} | train loss {'Reaction outcome loss': 0.2606428671532717, 'Total loss': 0.2606428671532717}
2023-01-05 09:42:18,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:42:18,203 INFO:     Epoch: 88
2023-01-05 09:42:20,315 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.43530836204687756, 'Total loss': 0.43530836204687756} | train loss {'Reaction outcome loss': 0.2626091873566637, 'Total loss': 0.2626091873566637}
2023-01-05 09:42:20,315 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:42:20,315 INFO:     Epoch: 89
2023-01-05 09:42:22,414 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.47310580909252165, 'Total loss': 0.47310580909252165} | train loss {'Reaction outcome loss': 0.2535305668773887, 'Total loss': 0.2535305668773887}
2023-01-05 09:42:22,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:42:22,414 INFO:     Epoch: 90
2023-01-05 09:42:24,531 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.43967873851458233, 'Total loss': 0.43967873851458233} | train loss {'Reaction outcome loss': 0.25630732552035823, 'Total loss': 0.25630732552035823}
2023-01-05 09:42:24,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:42:24,531 INFO:     Epoch: 91
2023-01-05 09:42:26,634 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4389273852109909, 'Total loss': 0.4389273852109909} | train loss {'Reaction outcome loss': 0.26574724417984924, 'Total loss': 0.26574724417984924}
2023-01-05 09:42:26,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:42:26,634 INFO:     Epoch: 92
2023-01-05 09:42:28,724 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4332037687301636, 'Total loss': 0.4332037687301636} | train loss {'Reaction outcome loss': 0.24702363977065453, 'Total loss': 0.24702363977065453}
2023-01-05 09:42:28,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:42:28,726 INFO:     Epoch: 93
2023-01-05 09:42:30,842 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4277815786500772, 'Total loss': 0.4277815786500772} | train loss {'Reaction outcome loss': 0.2600449301479828, 'Total loss': 0.2600449301479828}
2023-01-05 09:42:30,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:42:30,843 INFO:     Epoch: 94
2023-01-05 09:42:32,939 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.47317568560441337, 'Total loss': 0.47317568560441337} | train loss {'Reaction outcome loss': 0.25621432803431354, 'Total loss': 0.25621432803431354}
2023-01-05 09:42:32,939 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:42:32,940 INFO:     Epoch: 95
2023-01-05 09:42:35,034 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.44134738290061554, 'Total loss': 0.44134738290061554} | train loss {'Reaction outcome loss': 0.25306156379999695, 'Total loss': 0.25306156379999695}
2023-01-05 09:42:35,035 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:42:35,035 INFO:     Epoch: 96
2023-01-05 09:42:37,137 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.43686008354028066, 'Total loss': 0.43686008354028066} | train loss {'Reaction outcome loss': 0.2463933978734654, 'Total loss': 0.2463933978734654}
2023-01-05 09:42:37,137 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:42:37,138 INFO:     Epoch: 97
2023-01-05 09:42:39,260 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.45061560968557995, 'Total loss': 0.45061560968557995} | train loss {'Reaction outcome loss': 0.25462001102938975, 'Total loss': 0.25462001102938975}
2023-01-05 09:42:39,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:42:39,260 INFO:     Epoch: 98
2023-01-05 09:42:41,370 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4747067004442215, 'Total loss': 0.4747067004442215} | train loss {'Reaction outcome loss': 0.2480189875655231, 'Total loss': 0.2480189875655231}
2023-01-05 09:42:41,370 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:42:41,370 INFO:     Epoch: 99
2023-01-05 09:42:43,493 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.48431703050931296, 'Total loss': 0.48431703050931296} | train loss {'Reaction outcome loss': 0.25213374428266844, 'Total loss': 0.25213374428266844}
2023-01-05 09:42:43,493 INFO:     Best model found after epoch 59 of 100.
2023-01-05 09:42:43,493 INFO:   Done with stage: TRAINING
2023-01-05 09:42:43,493 INFO:   Starting stage: EVALUATION
2023-01-05 09:42:43,638 INFO:   Done with stage: EVALUATION
2023-01-05 09:42:43,638 INFO:   Leaving out SEQ value Fold_4
2023-01-05 09:42:43,650 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 09:42:43,650 INFO:   Starting stage: FEATURE SCALING
2023-01-05 09:42:44,296 INFO:   Done with stage: FEATURE SCALING
2023-01-05 09:42:44,296 INFO:   Starting stage: SCALING TARGETS
2023-01-05 09:42:44,363 INFO:   Done with stage: SCALING TARGETS
2023-01-05 09:42:44,364 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:42:44,364 INFO:     No hyperparam tuning for this model
2023-01-05 09:42:44,364 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:42:44,364 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 09:42:44,364 INFO:     None feature selector for col prot
2023-01-05 09:42:44,365 INFO:     None feature selector for col prot
2023-01-05 09:42:44,365 INFO:     None feature selector for col prot
2023-01-05 09:42:44,365 INFO:     None feature selector for col chem
2023-01-05 09:42:44,365 INFO:     None feature selector for col chem
2023-01-05 09:42:44,365 INFO:     None feature selector for col chem
2023-01-05 09:42:44,365 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 09:42:44,365 INFO:   Starting stage: BUILD MODEL
2023-01-05 09:42:44,367 INFO:     Number of params in model 72901
2023-01-05 09:42:44,370 INFO:   Done with stage: BUILD MODEL
2023-01-05 09:42:44,370 INFO:   Starting stage: TRAINING
2023-01-05 09:42:44,431 INFO:     Val loss before train {'Reaction outcome loss': 0.9716841101646423, 'Total loss': 0.9716841101646423}
2023-01-05 09:42:44,431 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:42:44,431 INFO:     Epoch: 0
2023-01-05 09:42:46,560 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7287461161613464, 'Total loss': 0.7287461161613464} | train loss {'Reaction outcome loss': 0.9210630877861294, 'Total loss': 0.9210630877861294}
2023-01-05 09:42:46,560 INFO:     Found new best model at epoch 0
2023-01-05 09:42:46,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:42:46,562 INFO:     Epoch: 1
2023-01-05 09:42:48,702 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.5742873509724935, 'Total loss': 0.5742873509724935} | train loss {'Reaction outcome loss': 0.7179354224868618, 'Total loss': 0.7179354224868618}
2023-01-05 09:42:48,702 INFO:     Found new best model at epoch 1
2023-01-05 09:42:48,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:42:48,704 INFO:     Epoch: 2
2023-01-05 09:42:50,857 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5260028431812922, 'Total loss': 0.5260028431812922} | train loss {'Reaction outcome loss': 0.5747359457520255, 'Total loss': 0.5747359457520255}
2023-01-05 09:42:50,857 INFO:     Found new best model at epoch 2
2023-01-05 09:42:50,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:42:50,858 INFO:     Epoch: 3
2023-01-05 09:42:52,993 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5099177817503612, 'Total loss': 0.5099177817503612} | train loss {'Reaction outcome loss': 0.5251908811240329, 'Total loss': 0.5251908811240329}
2023-01-05 09:42:52,993 INFO:     Found new best model at epoch 3
2023-01-05 09:42:52,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:42:52,994 INFO:     Epoch: 4
2023-01-05 09:42:55,121 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.48233158787091573, 'Total loss': 0.48233158787091573} | train loss {'Reaction outcome loss': 0.5088429921062029, 'Total loss': 0.5088429921062029}
2023-01-05 09:42:55,121 INFO:     Found new best model at epoch 4
2023-01-05 09:42:55,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:42:55,123 INFO:     Epoch: 5
2023-01-05 09:42:57,198 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.4633999516566594, 'Total loss': 0.4633999516566594} | train loss {'Reaction outcome loss': 0.4870999946353444, 'Total loss': 0.4870999946353444}
2023-01-05 09:42:57,198 INFO:     Found new best model at epoch 5
2023-01-05 09:42:57,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:42:57,200 INFO:     Epoch: 6
2023-01-05 09:42:58,954 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5130366245905559, 'Total loss': 0.5130366245905559} | train loss {'Reaction outcome loss': 0.4810878884695146, 'Total loss': 0.4810878884695146}
2023-01-05 09:42:58,954 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:42:58,954 INFO:     Epoch: 7
2023-01-05 09:43:00,690 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4711078425248464, 'Total loss': 0.4711078425248464} | train loss {'Reaction outcome loss': 0.4720106630704612, 'Total loss': 0.4720106630704612}
2023-01-05 09:43:00,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:43:00,691 INFO:     Epoch: 8
2023-01-05 09:43:02,742 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.5020350257555644, 'Total loss': 0.5020350257555644} | train loss {'Reaction outcome loss': 0.46125328064848925, 'Total loss': 0.46125328064848925}
2023-01-05 09:43:02,743 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:43:02,743 INFO:     Epoch: 9
2023-01-05 09:43:04,900 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.45858825941880543, 'Total loss': 0.45858825941880543} | train loss {'Reaction outcome loss': 0.46239396288697404, 'Total loss': 0.46239396288697404}
2023-01-05 09:43:04,900 INFO:     Found new best model at epoch 9
2023-01-05 09:43:04,901 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:43:04,902 INFO:     Epoch: 10
2023-01-05 09:43:07,060 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45295327305793764, 'Total loss': 0.45295327305793764} | train loss {'Reaction outcome loss': 0.47146619494626485, 'Total loss': 0.47146619494626485}
2023-01-05 09:43:07,060 INFO:     Found new best model at epoch 10
2023-01-05 09:43:07,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:43:07,062 INFO:     Epoch: 11
2023-01-05 09:43:09,209 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.4507981866598129, 'Total loss': 0.4507981866598129} | train loss {'Reaction outcome loss': 0.48093037729731936, 'Total loss': 0.48093037729731936}
2023-01-05 09:43:09,209 INFO:     Found new best model at epoch 11
2023-01-05 09:43:09,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:43:09,211 INFO:     Epoch: 12
2023-01-05 09:43:11,371 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.44765656093756356, 'Total loss': 0.44765656093756356} | train loss {'Reaction outcome loss': 0.45244233478603046, 'Total loss': 0.45244233478603046}
2023-01-05 09:43:11,372 INFO:     Found new best model at epoch 12
2023-01-05 09:43:11,373 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:43:11,373 INFO:     Epoch: 13
2023-01-05 09:43:13,562 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4552610655625661, 'Total loss': 0.4552610655625661} | train loss {'Reaction outcome loss': 0.4480029215388324, 'Total loss': 0.4480029215388324}
2023-01-05 09:43:13,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:43:13,562 INFO:     Epoch: 14
2023-01-05 09:43:15,735 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.45645478268464407, 'Total loss': 0.45645478268464407} | train loss {'Reaction outcome loss': 0.43974240373253176, 'Total loss': 0.43974240373253176}
2023-01-05 09:43:15,735 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:43:15,736 INFO:     Epoch: 15
2023-01-05 09:43:17,896 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4383574684460958, 'Total loss': 0.4383574684460958} | train loss {'Reaction outcome loss': 0.42995998916634615, 'Total loss': 0.42995998916634615}
2023-01-05 09:43:17,896 INFO:     Found new best model at epoch 15
2023-01-05 09:43:17,898 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:43:17,898 INFO:     Epoch: 16
2023-01-05 09:43:20,021 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.44471270640691124, 'Total loss': 0.44471270640691124} | train loss {'Reaction outcome loss': 0.4235995552737512, 'Total loss': 0.4235995552737512}
2023-01-05 09:43:20,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:43:20,022 INFO:     Epoch: 17
2023-01-05 09:43:22,171 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.46385858158270515, 'Total loss': 0.46385858158270515} | train loss {'Reaction outcome loss': 0.45387810792611993, 'Total loss': 0.45387810792611993}
2023-01-05 09:43:22,172 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:43:22,172 INFO:     Epoch: 18
2023-01-05 09:43:24,324 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.45956381360689796, 'Total loss': 0.45956381360689796} | train loss {'Reaction outcome loss': 0.4232546305511673, 'Total loss': 0.4232546305511673}
2023-01-05 09:43:24,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:43:24,324 INFO:     Epoch: 19
2023-01-05 09:43:26,412 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.41920707722504935, 'Total loss': 0.41920707722504935} | train loss {'Reaction outcome loss': 0.4151190923150642, 'Total loss': 0.4151190923150642}
2023-01-05 09:43:26,412 INFO:     Found new best model at epoch 19
2023-01-05 09:43:26,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:43:26,413 INFO:     Epoch: 20
2023-01-05 09:43:28,554 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4381258765856425, 'Total loss': 0.4381258765856425} | train loss {'Reaction outcome loss': 0.4109374149276477, 'Total loss': 0.4109374149276477}
2023-01-05 09:43:28,554 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:43:28,554 INFO:     Epoch: 21
2023-01-05 09:43:30,697 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4191103458404541, 'Total loss': 0.4191103458404541} | train loss {'Reaction outcome loss': 0.40658280445158185, 'Total loss': 0.40658280445158185}
2023-01-05 09:43:30,697 INFO:     Found new best model at epoch 21
2023-01-05 09:43:30,698 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:43:30,699 INFO:     Epoch: 22
2023-01-05 09:43:32,848 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4150084316730499, 'Total loss': 0.4150084316730499} | train loss {'Reaction outcome loss': 0.40438954807494, 'Total loss': 0.40438954807494}
2023-01-05 09:43:32,848 INFO:     Found new best model at epoch 22
2023-01-05 09:43:32,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:43:32,850 INFO:     Epoch: 23
2023-01-05 09:43:34,949 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.41985032161076863, 'Total loss': 0.41985032161076863} | train loss {'Reaction outcome loss': 0.40345688142965164, 'Total loss': 0.40345688142965164}
2023-01-05 09:43:34,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:43:34,949 INFO:     Epoch: 24
2023-01-05 09:43:37,083 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4035742938518524, 'Total loss': 0.4035742938518524} | train loss {'Reaction outcome loss': 0.39894861231247586, 'Total loss': 0.39894861231247586}
2023-01-05 09:43:37,083 INFO:     Found new best model at epoch 24
2023-01-05 09:43:37,085 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:43:37,085 INFO:     Epoch: 25
2023-01-05 09:43:39,212 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42904048363367714, 'Total loss': 0.42904048363367714} | train loss {'Reaction outcome loss': 0.4005217222307903, 'Total loss': 0.4005217222307903}
2023-01-05 09:43:39,214 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:43:39,214 INFO:     Epoch: 26
2023-01-05 09:43:41,360 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4210602422555288, 'Total loss': 0.4210602422555288} | train loss {'Reaction outcome loss': 0.3892909629520137, 'Total loss': 0.3892909629520137}
2023-01-05 09:43:41,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:43:41,360 INFO:     Epoch: 27
2023-01-05 09:43:43,507 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.456514436006546, 'Total loss': 0.456514436006546} | train loss {'Reaction outcome loss': 0.37816966516708117, 'Total loss': 0.37816966516708117}
2023-01-05 09:43:43,507 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:43:43,507 INFO:     Epoch: 28
2023-01-05 09:43:45,659 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.41098888019720714, 'Total loss': 0.41098888019720714} | train loss {'Reaction outcome loss': 0.4109135555589329, 'Total loss': 0.4109135555589329}
2023-01-05 09:43:45,660 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:43:45,660 INFO:     Epoch: 29
2023-01-05 09:43:47,776 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.44812594453493754, 'Total loss': 0.44812594453493754} | train loss {'Reaction outcome loss': 0.3890498439349081, 'Total loss': 0.3890498439349081}
2023-01-05 09:43:47,776 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:43:47,776 INFO:     Epoch: 30
2023-01-05 09:43:49,909 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.42723177472750345, 'Total loss': 0.42723177472750345} | train loss {'Reaction outcome loss': 0.37204063608162646, 'Total loss': 0.37204063608162646}
2023-01-05 09:43:49,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:43:49,909 INFO:     Epoch: 31
2023-01-05 09:43:52,021 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40716261019309363, 'Total loss': 0.40716261019309363} | train loss {'Reaction outcome loss': 0.36772054695672746, 'Total loss': 0.36772054695672746}
2023-01-05 09:43:52,021 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:43:52,021 INFO:     Epoch: 32
2023-01-05 09:43:54,147 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3938487221797307, 'Total loss': 0.3938487221797307} | train loss {'Reaction outcome loss': 0.3635350755699303, 'Total loss': 0.3635350755699303}
2023-01-05 09:43:54,147 INFO:     Found new best model at epoch 32
2023-01-05 09:43:54,148 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:43:54,148 INFO:     Epoch: 33
2023-01-05 09:43:56,280 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.41117175022761027, 'Total loss': 0.41117175022761027} | train loss {'Reaction outcome loss': 0.36202545018539345, 'Total loss': 0.36202545018539345}
2023-01-05 09:43:56,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:43:56,280 INFO:     Epoch: 34
2023-01-05 09:43:58,378 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42467254400253296, 'Total loss': 0.42467254400253296} | train loss {'Reaction outcome loss': 0.35934497944106336, 'Total loss': 0.35934497944106336}
2023-01-05 09:43:58,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:43:58,379 INFO:     Epoch: 35
2023-01-05 09:44:00,506 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3901064082980156, 'Total loss': 0.3901064082980156} | train loss {'Reaction outcome loss': 0.35385645286220574, 'Total loss': 0.35385645286220574}
2023-01-05 09:44:00,506 INFO:     Found new best model at epoch 35
2023-01-05 09:44:00,508 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:44:00,508 INFO:     Epoch: 36
2023-01-05 09:44:02,611 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4272385428349177, 'Total loss': 0.4272385428349177} | train loss {'Reaction outcome loss': 0.3501242201720901, 'Total loss': 0.3501242201720901}
2023-01-05 09:44:02,611 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:44:02,612 INFO:     Epoch: 37
2023-01-05 09:44:04,722 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.39969855149586997, 'Total loss': 0.39969855149586997} | train loss {'Reaction outcome loss': 0.34401850255064503, 'Total loss': 0.34401850255064503}
2023-01-05 09:44:04,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:44:04,722 INFO:     Epoch: 38
2023-01-05 09:44:06,847 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42312217156092324, 'Total loss': 0.42312217156092324} | train loss {'Reaction outcome loss': 0.345679937608783, 'Total loss': 0.345679937608783}
2023-01-05 09:44:06,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:44:06,848 INFO:     Epoch: 39
2023-01-05 09:44:08,973 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.4226196318864822, 'Total loss': 0.4226196318864822} | train loss {'Reaction outcome loss': 0.33982093550530146, 'Total loss': 0.33982093550530146}
2023-01-05 09:44:08,973 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:44:08,973 INFO:     Epoch: 40
2023-01-05 09:44:11,111 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4037419373790423, 'Total loss': 0.4037419373790423} | train loss {'Reaction outcome loss': 0.33034955639664404, 'Total loss': 0.33034955639664404}
2023-01-05 09:44:11,111 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:44:11,112 INFO:     Epoch: 41
2023-01-05 09:44:13,258 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45853279531002045, 'Total loss': 0.45853279531002045} | train loss {'Reaction outcome loss': 0.3246283061967731, 'Total loss': 0.3246283061967731}
2023-01-05 09:44:13,259 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:44:13,259 INFO:     Epoch: 42
2023-01-05 09:44:15,387 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.38073436667521793, 'Total loss': 0.38073436667521793} | train loss {'Reaction outcome loss': 0.3276506555055781, 'Total loss': 0.3276506555055781}
2023-01-05 09:44:15,388 INFO:     Found new best model at epoch 42
2023-01-05 09:44:15,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:44:15,390 INFO:     Epoch: 43
2023-01-05 09:44:17,544 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.39371584405501686, 'Total loss': 0.39371584405501686} | train loss {'Reaction outcome loss': 0.32936448176, 'Total loss': 0.32936448176}
2023-01-05 09:44:17,544 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:44:17,544 INFO:     Epoch: 44
2023-01-05 09:44:19,699 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.4282610555489858, 'Total loss': 0.4282610555489858} | train loss {'Reaction outcome loss': 0.3347452605780943, 'Total loss': 0.3347452605780943}
2023-01-05 09:44:19,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:44:19,699 INFO:     Epoch: 45
2023-01-05 09:44:21,838 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4345921625693639, 'Total loss': 0.4345921625693639} | train loss {'Reaction outcome loss': 0.3171990098101863, 'Total loss': 0.3171990098101863}
2023-01-05 09:44:21,839 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:44:21,839 INFO:     Epoch: 46
2023-01-05 09:44:23,980 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.4126725574334463, 'Total loss': 0.4126725574334463} | train loss {'Reaction outcome loss': 0.31712603523308225, 'Total loss': 0.31712603523308225}
2023-01-05 09:44:23,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:44:23,980 INFO:     Epoch: 47
2023-01-05 09:44:26,126 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.40511841475963595, 'Total loss': 0.40511841475963595} | train loss {'Reaction outcome loss': 0.31138259579640126, 'Total loss': 0.31138259579640126}
2023-01-05 09:44:26,126 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:44:26,126 INFO:     Epoch: 48
2023-01-05 09:44:28,265 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4060132622718811, 'Total loss': 0.4060132622718811} | train loss {'Reaction outcome loss': 0.3133143300824947, 'Total loss': 0.3133143300824947}
2023-01-05 09:44:28,265 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:44:28,266 INFO:     Epoch: 49
2023-01-05 09:44:30,398 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4264290491739909, 'Total loss': 0.4264290491739909} | train loss {'Reaction outcome loss': 0.3096232193360186, 'Total loss': 0.3096232193360186}
2023-01-05 09:44:30,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:44:30,398 INFO:     Epoch: 50
2023-01-05 09:44:32,556 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4045841852823893, 'Total loss': 0.4045841852823893} | train loss {'Reaction outcome loss': 0.32373447736503347, 'Total loss': 0.32373447736503347}
2023-01-05 09:44:32,556 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:44:32,556 INFO:     Epoch: 51
2023-01-05 09:44:34,693 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4282506932814916, 'Total loss': 0.4282506932814916} | train loss {'Reaction outcome loss': 0.3059198984532934, 'Total loss': 0.3059198984532934}
2023-01-05 09:44:34,694 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:44:34,694 INFO:     Epoch: 52
2023-01-05 09:44:36,834 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3858102709054947, 'Total loss': 0.3858102709054947} | train loss {'Reaction outcome loss': 0.3013233864153533, 'Total loss': 0.3013233864153533}
2023-01-05 09:44:36,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:44:36,834 INFO:     Epoch: 53
2023-01-05 09:44:38,975 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.39105374217033384, 'Total loss': 0.39105374217033384} | train loss {'Reaction outcome loss': 0.3024581406949648, 'Total loss': 0.3024581406949648}
2023-01-05 09:44:38,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:44:38,975 INFO:     Epoch: 54
2023-01-05 09:44:41,134 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.3993392219146093, 'Total loss': 0.3993392219146093} | train loss {'Reaction outcome loss': 0.2965133573583233, 'Total loss': 0.2965133573583233}
2023-01-05 09:44:41,134 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:44:41,135 INFO:     Epoch: 55
2023-01-05 09:44:43,324 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.40380841890970864, 'Total loss': 0.40380841890970864} | train loss {'Reaction outcome loss': 0.2996556063864272, 'Total loss': 0.2996556063864272}
2023-01-05 09:44:43,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:44:43,324 INFO:     Epoch: 56
2023-01-05 09:44:45,480 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.42661069631576537, 'Total loss': 0.42661069631576537} | train loss {'Reaction outcome loss': 0.29653115687213594, 'Total loss': 0.29653115687213594}
2023-01-05 09:44:45,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:44:45,480 INFO:     Epoch: 57
2023-01-05 09:44:47,597 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4219267110029856, 'Total loss': 0.4219267110029856} | train loss {'Reaction outcome loss': 0.2936667947679002, 'Total loss': 0.2936667947679002}
2023-01-05 09:44:47,598 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:44:47,598 INFO:     Epoch: 58
2023-01-05 09:44:49,712 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4019383539756139, 'Total loss': 0.4019383539756139} | train loss {'Reaction outcome loss': 0.29399796796755306, 'Total loss': 0.29399796796755306}
2023-01-05 09:44:49,712 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:44:49,713 INFO:     Epoch: 59
2023-01-05 09:44:51,853 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4103935221831004, 'Total loss': 0.4103935221831004} | train loss {'Reaction outcome loss': 0.289794339062781, 'Total loss': 0.289794339062781}
2023-01-05 09:44:51,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:44:51,855 INFO:     Epoch: 60
2023-01-05 09:44:53,984 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4160571028788885, 'Total loss': 0.4160571028788885} | train loss {'Reaction outcome loss': 0.3783374852568343, 'Total loss': 0.3783374852568343}
2023-01-05 09:44:53,984 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:44:53,984 INFO:     Epoch: 61
2023-01-05 09:44:56,090 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4177295098702113, 'Total loss': 0.4177295098702113} | train loss {'Reaction outcome loss': 0.3563294429288784, 'Total loss': 0.3563294429288784}
2023-01-05 09:44:56,090 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:44:56,090 INFO:     Epoch: 62
2023-01-05 09:44:58,215 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4076826194922129, 'Total loss': 0.4076826194922129} | train loss {'Reaction outcome loss': 0.2967067477917569, 'Total loss': 0.2967067477917569}
2023-01-05 09:44:58,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:44:58,216 INFO:     Epoch: 63
2023-01-05 09:45:00,335 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.38981096347173055, 'Total loss': 0.38981096347173055} | train loss {'Reaction outcome loss': 0.2896104351184089, 'Total loss': 0.2896104351184089}
2023-01-05 09:45:00,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:45:00,335 INFO:     Epoch: 64
2023-01-05 09:45:02,475 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.39359694917996724, 'Total loss': 0.39359694917996724} | train loss {'Reaction outcome loss': 0.28513931645589974, 'Total loss': 0.28513931645589974}
2023-01-05 09:45:02,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:45:02,475 INFO:     Epoch: 65
2023-01-05 09:45:04,616 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3983603318532308, 'Total loss': 0.3983603318532308} | train loss {'Reaction outcome loss': 0.2819229862121258, 'Total loss': 0.2819229862121258}
2023-01-05 09:45:04,616 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:45:04,616 INFO:     Epoch: 66
2023-01-05 09:45:06,752 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.41124333490928017, 'Total loss': 0.41124333490928017} | train loss {'Reaction outcome loss': 0.28031399005187163, 'Total loss': 0.28031399005187163}
2023-01-05 09:45:06,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:45:06,753 INFO:     Epoch: 67
2023-01-05 09:45:08,879 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4258268713951111, 'Total loss': 0.4258268713951111} | train loss {'Reaction outcome loss': 0.27340444372426986, 'Total loss': 0.27340444372426986}
2023-01-05 09:45:08,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:45:08,879 INFO:     Epoch: 68
2023-01-05 09:45:10,990 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3924292251467705, 'Total loss': 0.3924292251467705} | train loss {'Reaction outcome loss': 0.2880568598140625, 'Total loss': 0.2880568598140625}
2023-01-05 09:45:10,991 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:45:10,991 INFO:     Epoch: 69
2023-01-05 09:45:13,121 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4434299031893412, 'Total loss': 0.4434299031893412} | train loss {'Reaction outcome loss': 0.3642713153680813, 'Total loss': 0.3642713153680813}
2023-01-05 09:45:13,121 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:45:13,121 INFO:     Epoch: 70
2023-01-05 09:45:15,283 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.40338216920693715, 'Total loss': 0.40338216920693715} | train loss {'Reaction outcome loss': 0.38124836229057424, 'Total loss': 0.38124836229057424}
2023-01-05 09:45:15,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:45:15,283 INFO:     Epoch: 71
2023-01-05 09:45:17,445 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3775380050142606, 'Total loss': 0.3775380050142606} | train loss {'Reaction outcome loss': 0.3279284044013669, 'Total loss': 0.3279284044013669}
2023-01-05 09:45:17,445 INFO:     Found new best model at epoch 71
2023-01-05 09:45:17,446 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:45:17,446 INFO:     Epoch: 72
2023-01-05 09:45:19,610 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.4003339131673177, 'Total loss': 0.4003339131673177} | train loss {'Reaction outcome loss': 0.3074673705842292, 'Total loss': 0.3074673705842292}
2023-01-05 09:45:19,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:45:19,611 INFO:     Epoch: 73
2023-01-05 09:45:21,769 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.40868113736311595, 'Total loss': 0.40868113736311595} | train loss {'Reaction outcome loss': 0.2955869746097512, 'Total loss': 0.2955869746097512}
2023-01-05 09:45:21,770 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:45:21,770 INFO:     Epoch: 74
2023-01-05 09:45:23,915 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4248557279507319, 'Total loss': 0.4248557279507319} | train loss {'Reaction outcome loss': 0.30465418397300487, 'Total loss': 0.30465418397300487}
2023-01-05 09:45:23,915 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:45:23,916 INFO:     Epoch: 75
2023-01-05 09:45:26,028 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4099316323796908, 'Total loss': 0.4099316323796908} | train loss {'Reaction outcome loss': 0.3726267028141065, 'Total loss': 0.3726267028141065}
2023-01-05 09:45:26,029 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:45:26,029 INFO:     Epoch: 76
2023-01-05 09:45:28,164 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.38493722478548686, 'Total loss': 0.38493722478548686} | train loss {'Reaction outcome loss': 0.3084255691644722, 'Total loss': 0.3084255691644722}
2023-01-05 09:45:28,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:45:28,164 INFO:     Epoch: 77
2023-01-05 09:45:30,296 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.40627179741859437, 'Total loss': 0.40627179741859437} | train loss {'Reaction outcome loss': 0.29469105929973116, 'Total loss': 0.29469105929973116}
2023-01-05 09:45:30,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:45:30,297 INFO:     Epoch: 78
2023-01-05 09:45:32,441 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3536754747231801, 'Total loss': 0.3536754747231801} | train loss {'Reaction outcome loss': 0.2796782023362829, 'Total loss': 0.2796782023362829}
2023-01-05 09:45:32,442 INFO:     Found new best model at epoch 78
2023-01-05 09:45:32,443 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:45:32,443 INFO:     Epoch: 79
2023-01-05 09:45:34,596 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.38517740567525227, 'Total loss': 0.38517740567525227} | train loss {'Reaction outcome loss': 0.28036279922125157, 'Total loss': 0.28036279922125157}
2023-01-05 09:45:34,596 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:45:34,596 INFO:     Epoch: 80
2023-01-05 09:45:36,738 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.3936665326356888, 'Total loss': 0.3936665326356888} | train loss {'Reaction outcome loss': 0.27808690683889215, 'Total loss': 0.27808690683889215}
2023-01-05 09:45:36,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:45:36,738 INFO:     Epoch: 81
2023-01-05 09:45:38,894 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.40342736144860586, 'Total loss': 0.40342736144860586} | train loss {'Reaction outcome loss': 0.27979697070448944, 'Total loss': 0.27979697070448944}
2023-01-05 09:45:38,894 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:45:38,895 INFO:     Epoch: 82
2023-01-05 09:45:41,055 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.41780822823445, 'Total loss': 0.41780822823445} | train loss {'Reaction outcome loss': 0.265740463012438, 'Total loss': 0.265740463012438}
2023-01-05 09:45:41,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:45:41,056 INFO:     Epoch: 83
2023-01-05 09:45:43,182 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.40066108653942745, 'Total loss': 0.40066108653942745} | train loss {'Reaction outcome loss': 0.2731618515799578, 'Total loss': 0.2731618515799578}
2023-01-05 09:45:43,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:45:43,182 INFO:     Epoch: 84
2023-01-05 09:45:45,312 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.42512184878190357, 'Total loss': 0.42512184878190357} | train loss {'Reaction outcome loss': 0.27909066317859443, 'Total loss': 0.27909066317859443}
2023-01-05 09:45:45,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:45:45,312 INFO:     Epoch: 85
2023-01-05 09:45:47,484 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4200322429339091, 'Total loss': 0.4200322429339091} | train loss {'Reaction outcome loss': 0.31350026675499976, 'Total loss': 0.31350026675499976}
2023-01-05 09:45:47,484 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:45:47,485 INFO:     Epoch: 86
2023-01-05 09:45:49,659 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.40709163149197897, 'Total loss': 0.40709163149197897} | train loss {'Reaction outcome loss': 0.28091348395210464, 'Total loss': 0.28091348395210464}
2023-01-05 09:45:49,659 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:45:49,659 INFO:     Epoch: 87
2023-01-05 09:45:51,819 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.3877330243587494, 'Total loss': 0.3877330243587494} | train loss {'Reaction outcome loss': 0.2678482326851024, 'Total loss': 0.2678482326851024}
2023-01-05 09:45:51,819 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:45:51,819 INFO:     Epoch: 88
2023-01-05 09:45:53,980 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.37486640761295953, 'Total loss': 0.37486640761295953} | train loss {'Reaction outcome loss': 0.26752001827159233, 'Total loss': 0.26752001827159233}
2023-01-05 09:45:53,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:45:53,980 INFO:     Epoch: 89
2023-01-05 09:45:56,123 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.37383458813031517, 'Total loss': 0.37383458813031517} | train loss {'Reaction outcome loss': 0.2659415863538701, 'Total loss': 0.2659415863538701}
2023-01-05 09:45:56,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:45:56,123 INFO:     Epoch: 90
2023-01-05 09:45:58,276 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.3990933060646057, 'Total loss': 0.3990933060646057} | train loss {'Reaction outcome loss': 0.26075513009656814, 'Total loss': 0.26075513009656814}
2023-01-05 09:45:58,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:45:58,278 INFO:     Epoch: 91
2023-01-05 09:46:00,461 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.41575095256169636, 'Total loss': 0.41575095256169636} | train loss {'Reaction outcome loss': 0.2679355731978422, 'Total loss': 0.2679355731978422}
2023-01-05 09:46:00,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:46:00,461 INFO:     Epoch: 92
2023-01-05 09:46:02,633 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3809909631808599, 'Total loss': 0.3809909631808599} | train loss {'Reaction outcome loss': 0.2535080976507532, 'Total loss': 0.2535080976507532}
2023-01-05 09:46:02,634 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:46:02,634 INFO:     Epoch: 93
2023-01-05 09:46:04,586 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.45144527951876323, 'Total loss': 0.45144527951876323} | train loss {'Reaction outcome loss': 0.25841355107579567, 'Total loss': 0.25841355107579567}
2023-01-05 09:46:04,587 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:46:04,587 INFO:     Epoch: 94
2023-01-05 09:46:06,759 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.38722710410753886, 'Total loss': 0.38722710410753886} | train loss {'Reaction outcome loss': 0.2621682305698809, 'Total loss': 0.2621682305698809}
2023-01-05 09:46:06,759 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:46:06,760 INFO:     Epoch: 95
2023-01-05 09:46:08,885 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4078528354565302, 'Total loss': 0.4078528354565302} | train loss {'Reaction outcome loss': 0.26242097340429504, 'Total loss': 0.26242097340429504}
2023-01-05 09:46:08,885 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:46:08,885 INFO:     Epoch: 96
2023-01-05 09:46:11,008 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.38864215165376664, 'Total loss': 0.38864215165376664} | train loss {'Reaction outcome loss': 0.26093493508127774, 'Total loss': 0.26093493508127774}
2023-01-05 09:46:11,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:46:11,008 INFO:     Epoch: 97
2023-01-05 09:46:13,164 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.38988473316033684, 'Total loss': 0.38988473316033684} | train loss {'Reaction outcome loss': 0.2567299132326456, 'Total loss': 0.2567299132326456}
2023-01-05 09:46:13,164 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:46:13,164 INFO:     Epoch: 98
2023-01-05 09:46:15,297 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.44914568265279137, 'Total loss': 0.44914568265279137} | train loss {'Reaction outcome loss': 0.258291847131593, 'Total loss': 0.258291847131593}
2023-01-05 09:46:15,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:46:15,297 INFO:     Epoch: 99
2023-01-05 09:46:17,445 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.4057726015647252, 'Total loss': 0.4057726015647252} | train loss {'Reaction outcome loss': 0.25257627046675474, 'Total loss': 0.25257627046675474}
2023-01-05 09:46:17,446 INFO:     Best model found after epoch 79 of 100.
2023-01-05 09:46:17,446 INFO:   Done with stage: TRAINING
2023-01-05 09:46:17,446 INFO:   Starting stage: EVALUATION
2023-01-05 09:46:17,579 INFO:   Done with stage: EVALUATION
2023-01-05 09:46:17,579 INFO:   Leaving out SEQ value Fold_5
2023-01-05 09:46:17,592 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 09:46:17,592 INFO:   Starting stage: FEATURE SCALING
2023-01-05 09:46:18,244 INFO:   Done with stage: FEATURE SCALING
2023-01-05 09:46:18,244 INFO:   Starting stage: SCALING TARGETS
2023-01-05 09:46:18,313 INFO:   Done with stage: SCALING TARGETS
2023-01-05 09:46:18,313 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:46:18,314 INFO:     No hyperparam tuning for this model
2023-01-05 09:46:18,314 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:46:18,314 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 09:46:18,314 INFO:     None feature selector for col prot
2023-01-05 09:46:18,315 INFO:     None feature selector for col prot
2023-01-05 09:46:18,315 INFO:     None feature selector for col prot
2023-01-05 09:46:18,315 INFO:     None feature selector for col chem
2023-01-05 09:46:18,315 INFO:     None feature selector for col chem
2023-01-05 09:46:18,315 INFO:     None feature selector for col chem
2023-01-05 09:46:18,315 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 09:46:18,315 INFO:   Starting stage: BUILD MODEL
2023-01-05 09:46:18,317 INFO:     Number of params in model 72901
2023-01-05 09:46:18,320 INFO:   Done with stage: BUILD MODEL
2023-01-05 09:46:18,320 INFO:   Starting stage: TRAINING
2023-01-05 09:46:18,379 INFO:     Val loss before train {'Reaction outcome loss': 1.0175646702448526, 'Total loss': 1.0175646702448526}
2023-01-05 09:46:18,379 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:46:18,379 INFO:     Epoch: 0
2023-01-05 09:46:20,518 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.7975017388661703, 'Total loss': 0.7975017388661703} | train loss {'Reaction outcome loss': 0.9423080621206242, 'Total loss': 0.9423080621206242}
2023-01-05 09:46:20,518 INFO:     Found new best model at epoch 0
2023-01-05 09:46:20,520 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:46:20,520 INFO:     Epoch: 1
2023-01-05 09:46:22,674 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6271580318609874, 'Total loss': 0.6271580318609874} | train loss {'Reaction outcome loss': 0.7338661816025126, 'Total loss': 0.7338661816025126}
2023-01-05 09:46:22,674 INFO:     Found new best model at epoch 1
2023-01-05 09:46:22,675 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:46:22,675 INFO:     Epoch: 2
2023-01-05 09:46:24,830 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5696037898461024, 'Total loss': 0.5696037898461024} | train loss {'Reaction outcome loss': 0.5851146471762056, 'Total loss': 0.5851146471762056}
2023-01-05 09:46:24,831 INFO:     Found new best model at epoch 2
2023-01-05 09:46:24,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:46:24,832 INFO:     Epoch: 3
2023-01-05 09:46:26,991 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.568192841609319, 'Total loss': 0.568192841609319} | train loss {'Reaction outcome loss': 0.5396673760336378, 'Total loss': 0.5396673760336378}
2023-01-05 09:46:26,991 INFO:     Found new best model at epoch 3
2023-01-05 09:46:26,992 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:46:26,992 INFO:     Epoch: 4
2023-01-05 09:46:29,127 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5147677878538768, 'Total loss': 0.5147677878538768} | train loss {'Reaction outcome loss': 0.5129053436263559, 'Total loss': 0.5129053436263559}
2023-01-05 09:46:29,128 INFO:     Found new best model at epoch 4
2023-01-05 09:46:29,130 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:46:29,130 INFO:     Epoch: 5
2023-01-05 09:46:31,262 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.525068857272466, 'Total loss': 0.525068857272466} | train loss {'Reaction outcome loss': 0.5028111519480961, 'Total loss': 0.5028111519480961}
2023-01-05 09:46:31,262 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:46:31,262 INFO:     Epoch: 6
2023-01-05 09:46:33,389 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.5196239640315373, 'Total loss': 0.5196239640315373} | train loss {'Reaction outcome loss': 0.4941005224422754, 'Total loss': 0.4941005224422754}
2023-01-05 09:46:33,389 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:46:33,390 INFO:     Epoch: 7
2023-01-05 09:46:35,536 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.504271403948466, 'Total loss': 0.504271403948466} | train loss {'Reaction outcome loss': 0.48664188459920493, 'Total loss': 0.48664188459920493}
2023-01-05 09:46:35,537 INFO:     Found new best model at epoch 7
2023-01-05 09:46:35,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:46:35,538 INFO:     Epoch: 8
2023-01-05 09:46:37,690 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.503056134780248, 'Total loss': 0.503056134780248} | train loss {'Reaction outcome loss': 0.4818199852353259, 'Total loss': 0.4818199852353259}
2023-01-05 09:46:37,690 INFO:     Found new best model at epoch 8
2023-01-05 09:46:37,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:46:37,691 INFO:     Epoch: 9
2023-01-05 09:46:39,814 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4746485024690628, 'Total loss': 0.4746485024690628} | train loss {'Reaction outcome loss': 0.47412090790727973, 'Total loss': 0.47412090790727973}
2023-01-05 09:46:39,814 INFO:     Found new best model at epoch 9
2023-01-05 09:46:39,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:46:39,816 INFO:     Epoch: 10
2023-01-05 09:46:41,933 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.467962916692098, 'Total loss': 0.467962916692098} | train loss {'Reaction outcome loss': 0.46925412679927936, 'Total loss': 0.46925412679927936}
2023-01-05 09:46:41,933 INFO:     Found new best model at epoch 10
2023-01-05 09:46:41,934 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:46:41,934 INFO:     Epoch: 11
2023-01-05 09:46:44,080 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.5063460350036622, 'Total loss': 0.5063460350036622} | train loss {'Reaction outcome loss': 0.46949472019205923, 'Total loss': 0.46949472019205923}
2023-01-05 09:46:44,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:46:44,080 INFO:     Epoch: 12
2023-01-05 09:46:46,248 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4794428547223409, 'Total loss': 0.4794428547223409} | train loss {'Reaction outcome loss': 0.4619669843789028, 'Total loss': 0.4619669843789028}
2023-01-05 09:46:46,248 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:46:46,248 INFO:     Epoch: 13
2023-01-05 09:46:48,397 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.47866602142651876, 'Total loss': 0.47866602142651876} | train loss {'Reaction outcome loss': 0.4582947389917799, 'Total loss': 0.4582947389917799}
2023-01-05 09:46:48,398 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:46:48,398 INFO:     Epoch: 14
2023-01-05 09:46:50,541 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4756761282682419, 'Total loss': 0.4756761282682419} | train loss {'Reaction outcome loss': 0.45254310878985765, 'Total loss': 0.45254310878985765}
2023-01-05 09:46:50,541 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:46:50,541 INFO:     Epoch: 15
2023-01-05 09:46:52,647 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.49848995606104535, 'Total loss': 0.49848995606104535} | train loss {'Reaction outcome loss': 0.4485027973651481, 'Total loss': 0.4485027973651481}
2023-01-05 09:46:52,647 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:46:52,647 INFO:     Epoch: 16
2023-01-05 09:46:54,774 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5089331159989039, 'Total loss': 0.5089331159989039} | train loss {'Reaction outcome loss': 0.44766198322126316, 'Total loss': 0.44766198322126316}
2023-01-05 09:46:54,774 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:46:54,774 INFO:     Epoch: 17
2023-01-05 09:46:56,908 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4636195143063863, 'Total loss': 0.4636195143063863} | train loss {'Reaction outcome loss': 0.44374045152284636, 'Total loss': 0.44374045152284636}
2023-01-05 09:46:56,908 INFO:     Found new best model at epoch 17
2023-01-05 09:46:56,909 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:46:56,910 INFO:     Epoch: 18
2023-01-05 09:46:59,050 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.47076817353566486, 'Total loss': 0.47076817353566486} | train loss {'Reaction outcome loss': 0.43444430153560487, 'Total loss': 0.43444430153560487}
2023-01-05 09:46:59,051 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:46:59,052 INFO:     Epoch: 19
2023-01-05 09:47:01,198 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.482452725370725, 'Total loss': 0.482452725370725} | train loss {'Reaction outcome loss': 0.43462813203560485, 'Total loss': 0.43462813203560485}
2023-01-05 09:47:01,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:47:01,199 INFO:     Epoch: 20
2023-01-05 09:47:03,355 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.44192962944507597, 'Total loss': 0.44192962944507597} | train loss {'Reaction outcome loss': 0.4324129329626516, 'Total loss': 0.4324129329626516}
2023-01-05 09:47:03,356 INFO:     Found new best model at epoch 20
2023-01-05 09:47:03,357 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:47:03,357 INFO:     Epoch: 21
2023-01-05 09:47:05,509 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45736649533112844, 'Total loss': 0.45736649533112844} | train loss {'Reaction outcome loss': 0.4278425590035614, 'Total loss': 0.4278425590035614}
2023-01-05 09:47:05,510 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:47:05,510 INFO:     Epoch: 22
2023-01-05 09:47:07,662 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.47387375235557555, 'Total loss': 0.47387375235557555} | train loss {'Reaction outcome loss': 0.4235160085625704, 'Total loss': 0.4235160085625704}
2023-01-05 09:47:07,662 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:47:07,662 INFO:     Epoch: 23
2023-01-05 09:47:09,812 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4748948574066162, 'Total loss': 0.4748948574066162} | train loss {'Reaction outcome loss': 0.42237710723165417, 'Total loss': 0.42237710723165417}
2023-01-05 09:47:09,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:47:09,812 INFO:     Epoch: 24
2023-01-05 09:47:11,981 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4930766334136327, 'Total loss': 0.4930766334136327} | train loss {'Reaction outcome loss': 0.42043941342727403, 'Total loss': 0.42043941342727403}
2023-01-05 09:47:11,981 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:47:11,981 INFO:     Epoch: 25
2023-01-05 09:47:14,141 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.44948739210764566, 'Total loss': 0.44948739210764566} | train loss {'Reaction outcome loss': 0.4124260986952678, 'Total loss': 0.4124260986952678}
2023-01-05 09:47:14,141 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:47:14,141 INFO:     Epoch: 26
2023-01-05 09:47:16,303 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4975394427776337, 'Total loss': 0.4975394427776337} | train loss {'Reaction outcome loss': 0.42146770934155886, 'Total loss': 0.42146770934155886}
2023-01-05 09:47:16,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:47:16,303 INFO:     Epoch: 27
2023-01-05 09:47:18,465 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4590334008137385, 'Total loss': 0.4590334008137385} | train loss {'Reaction outcome loss': 0.42061955842444254, 'Total loss': 0.42061955842444254}
2023-01-05 09:47:18,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:47:18,466 INFO:     Epoch: 28
2023-01-05 09:47:20,622 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4600526531537374, 'Total loss': 0.4600526531537374} | train loss {'Reaction outcome loss': 0.40136512209732167, 'Total loss': 0.40136512209732167}
2023-01-05 09:47:20,623 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:47:20,623 INFO:     Epoch: 29
2023-01-05 09:47:22,787 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.47955092787742615, 'Total loss': 0.47955092787742615} | train loss {'Reaction outcome loss': 0.3964402046370104, 'Total loss': 0.3964402046370104}
2023-01-05 09:47:22,787 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:47:22,787 INFO:     Epoch: 30
2023-01-05 09:47:24,948 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.45453258951505027, 'Total loss': 0.45453258951505027} | train loss {'Reaction outcome loss': 0.39908039621144964, 'Total loss': 0.39908039621144964}
2023-01-05 09:47:24,949 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:47:24,949 INFO:     Epoch: 31
2023-01-05 09:47:27,109 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.4652452131112417, 'Total loss': 0.4652452131112417} | train loss {'Reaction outcome loss': 0.39720048301893734, 'Total loss': 0.39720048301893734}
2023-01-05 09:47:27,109 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:47:27,110 INFO:     Epoch: 32
2023-01-05 09:47:29,249 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4596542755762736, 'Total loss': 0.4596542755762736} | train loss {'Reaction outcome loss': 0.3955301259058081, 'Total loss': 0.3955301259058081}
2023-01-05 09:47:29,250 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:47:29,250 INFO:     Epoch: 33
2023-01-05 09:47:31,413 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4580042650302251, 'Total loss': 0.4580042650302251} | train loss {'Reaction outcome loss': 0.3878671015282845, 'Total loss': 0.3878671015282845}
2023-01-05 09:47:31,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:47:31,414 INFO:     Epoch: 34
2023-01-05 09:47:33,567 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.45659909546375277, 'Total loss': 0.45659909546375277} | train loss {'Reaction outcome loss': 0.3855055772633616, 'Total loss': 0.3855055772633616}
2023-01-05 09:47:33,567 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:47:33,567 INFO:     Epoch: 35
2023-01-05 09:47:35,725 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.4246777720128497, 'Total loss': 0.4246777720128497} | train loss {'Reaction outcome loss': 0.381552836979213, 'Total loss': 0.381552836979213}
2023-01-05 09:47:35,726 INFO:     Found new best model at epoch 35
2023-01-05 09:47:35,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:47:35,727 INFO:     Epoch: 36
2023-01-05 09:47:37,883 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.47006543974081677, 'Total loss': 0.47006543974081677} | train loss {'Reaction outcome loss': 0.3825088599612396, 'Total loss': 0.3825088599612396}
2023-01-05 09:47:37,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:47:37,884 INFO:     Epoch: 37
2023-01-05 09:47:40,033 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.43115594138701757, 'Total loss': 0.43115594138701757} | train loss {'Reaction outcome loss': 0.37454248395195044, 'Total loss': 0.37454248395195044}
2023-01-05 09:47:40,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:47:40,033 INFO:     Epoch: 38
2023-01-05 09:47:42,198 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.42568984230359397, 'Total loss': 0.42568984230359397} | train loss {'Reaction outcome loss': 0.37768517195212736, 'Total loss': 0.37768517195212736}
2023-01-05 09:47:42,199 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:47:42,199 INFO:     Epoch: 39
2023-01-05 09:47:44,335 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.44809974332650504, 'Total loss': 0.44809974332650504} | train loss {'Reaction outcome loss': 0.3706470380935386, 'Total loss': 0.3706470380935386}
2023-01-05 09:47:44,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:47:44,335 INFO:     Epoch: 40
2023-01-05 09:47:46,475 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.4504369020462036, 'Total loss': 0.4504369020462036} | train loss {'Reaction outcome loss': 0.37489632004197093, 'Total loss': 0.37489632004197093}
2023-01-05 09:47:46,475 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:47:46,475 INFO:     Epoch: 41
2023-01-05 09:47:48,605 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.45506854852040607, 'Total loss': 0.45506854852040607} | train loss {'Reaction outcome loss': 0.4318788971050062, 'Total loss': 0.4318788971050062}
2023-01-05 09:47:48,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:47:48,605 INFO:     Epoch: 42
2023-01-05 09:47:50,737 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.41540299405654274, 'Total loss': 0.41540299405654274} | train loss {'Reaction outcome loss': 0.39286612349383504, 'Total loss': 0.39286612349383504}
2023-01-05 09:47:50,737 INFO:     Found new best model at epoch 42
2023-01-05 09:47:50,738 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:47:50,738 INFO:     Epoch: 43
2023-01-05 09:47:52,859 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4261516402165095, 'Total loss': 0.4261516402165095} | train loss {'Reaction outcome loss': 0.3714076208787552, 'Total loss': 0.3714076208787552}
2023-01-05 09:47:52,859 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:47:52,859 INFO:     Epoch: 44
2023-01-05 09:47:54,947 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.43200079202651975, 'Total loss': 0.43200079202651975} | train loss {'Reaction outcome loss': 0.3892254769410668, 'Total loss': 0.3892254769410668}
2023-01-05 09:47:54,948 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:47:54,948 INFO:     Epoch: 45
2023-01-05 09:47:57,078 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.41373349030812584, 'Total loss': 0.41373349030812584} | train loss {'Reaction outcome loss': 0.37120551314285916, 'Total loss': 0.37120551314285916}
2023-01-05 09:47:57,078 INFO:     Found new best model at epoch 45
2023-01-05 09:47:57,080 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:47:57,080 INFO:     Epoch: 46
2023-01-05 09:47:59,212 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.38750291218360267, 'Total loss': 0.38750291218360267} | train loss {'Reaction outcome loss': 0.35555779853861613, 'Total loss': 0.35555779853861613}
2023-01-05 09:47:59,212 INFO:     Found new best model at epoch 46
2023-01-05 09:47:59,213 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:47:59,213 INFO:     Epoch: 47
2023-01-05 09:48:01,363 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.42293317516644796, 'Total loss': 0.42293317516644796} | train loss {'Reaction outcome loss': 0.3542312958940085, 'Total loss': 0.3542312958940085}
2023-01-05 09:48:01,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:48:01,363 INFO:     Epoch: 48
2023-01-05 09:48:03,486 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.41255805442730586, 'Total loss': 0.41255805442730586} | train loss {'Reaction outcome loss': 0.34845486471591436, 'Total loss': 0.34845486471591436}
2023-01-05 09:48:03,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:48:03,486 INFO:     Epoch: 49
2023-01-05 09:48:05,611 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4261895418167114, 'Total loss': 0.4261895418167114} | train loss {'Reaction outcome loss': 0.3485118347290562, 'Total loss': 0.3485118347290562}
2023-01-05 09:48:05,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:48:05,612 INFO:     Epoch: 50
2023-01-05 09:48:07,713 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.41282836347818375, 'Total loss': 0.41282836347818375} | train loss {'Reaction outcome loss': 0.3482367291952065, 'Total loss': 0.3482367291952065}
2023-01-05 09:48:07,713 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:48:07,713 INFO:     Epoch: 51
2023-01-05 09:48:09,843 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.41665440797805786, 'Total loss': 0.41665440797805786} | train loss {'Reaction outcome loss': 0.34199066583338816, 'Total loss': 0.34199066583338816}
2023-01-05 09:48:09,843 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:48:09,843 INFO:     Epoch: 52
2023-01-05 09:48:11,980 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44548685749371847, 'Total loss': 0.44548685749371847} | train loss {'Reaction outcome loss': 0.33908003470708575, 'Total loss': 0.33908003470708575}
2023-01-05 09:48:11,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:48:11,980 INFO:     Epoch: 53
2023-01-05 09:48:14,115 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.42288513481616974, 'Total loss': 0.42288513481616974} | train loss {'Reaction outcome loss': 0.3339365820375742, 'Total loss': 0.3339365820375742}
2023-01-05 09:48:14,116 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:48:14,116 INFO:     Epoch: 54
2023-01-05 09:48:16,230 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.4393520087003708, 'Total loss': 0.4393520087003708} | train loss {'Reaction outcome loss': 0.33254626023193373, 'Total loss': 0.33254626023193373}
2023-01-05 09:48:16,230 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:48:16,230 INFO:     Epoch: 55
2023-01-05 09:48:18,367 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.44247812827428185, 'Total loss': 0.44247812827428185} | train loss {'Reaction outcome loss': 0.33310933060188225, 'Total loss': 0.33310933060188225}
2023-01-05 09:48:18,368 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:48:18,368 INFO:     Epoch: 56
2023-01-05 09:48:20,492 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4561576426029205, 'Total loss': 0.4561576426029205} | train loss {'Reaction outcome loss': 0.33673231359490025, 'Total loss': 0.33673231359490025}
2023-01-05 09:48:20,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:48:20,493 INFO:     Epoch: 57
2023-01-05 09:48:22,624 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4107280721267064, 'Total loss': 0.4107280721267064} | train loss {'Reaction outcome loss': 0.32646465966836724, 'Total loss': 0.32646465966836724}
2023-01-05 09:48:22,624 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:48:22,625 INFO:     Epoch: 58
2023-01-05 09:48:24,740 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4291982799768448, 'Total loss': 0.4291982799768448} | train loss {'Reaction outcome loss': 0.32724884850229474, 'Total loss': 0.32724884850229474}
2023-01-05 09:48:24,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:48:24,741 INFO:     Epoch: 59
2023-01-05 09:48:26,827 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4128558744986852, 'Total loss': 0.4128558744986852} | train loss {'Reaction outcome loss': 0.3309089786118315, 'Total loss': 0.3309089786118315}
2023-01-05 09:48:26,827 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:48:26,827 INFO:     Epoch: 60
2023-01-05 09:48:28,942 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.45065924525260925, 'Total loss': 0.45065924525260925} | train loss {'Reaction outcome loss': 0.31762737627866666, 'Total loss': 0.31762737627866666}
2023-01-05 09:48:28,943 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:48:28,943 INFO:     Epoch: 61
2023-01-05 09:48:31,053 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.40650693078835803, 'Total loss': 0.40650693078835803} | train loss {'Reaction outcome loss': 0.32590542552803736, 'Total loss': 0.32590542552803736}
2023-01-05 09:48:31,053 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:48:31,053 INFO:     Epoch: 62
2023-01-05 09:48:33,205 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.42378108700116474, 'Total loss': 0.42378108700116474} | train loss {'Reaction outcome loss': 0.3198997009548939, 'Total loss': 0.3198997009548939}
2023-01-05 09:48:33,205 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:48:33,206 INFO:     Epoch: 63
2023-01-05 09:48:35,354 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.409897181391716, 'Total loss': 0.409897181391716} | train loss {'Reaction outcome loss': 0.31028843254097266, 'Total loss': 0.31028843254097266}
2023-01-05 09:48:35,354 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:48:35,354 INFO:     Epoch: 64
2023-01-05 09:48:37,468 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.43955460786819456, 'Total loss': 0.43955460786819456} | train loss {'Reaction outcome loss': 0.31079706089856673, 'Total loss': 0.31079706089856673}
2023-01-05 09:48:37,468 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:48:37,468 INFO:     Epoch: 65
2023-01-05 09:48:39,584 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.41723381479581195, 'Total loss': 0.41723381479581195} | train loss {'Reaction outcome loss': 0.3145045076372048, 'Total loss': 0.3145045076372048}
2023-01-05 09:48:39,585 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:48:39,585 INFO:     Epoch: 66
2023-01-05 09:48:41,714 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.42506515284379326, 'Total loss': 0.42506515284379326} | train loss {'Reaction outcome loss': 0.30770476381176326, 'Total loss': 0.30770476381176326}
2023-01-05 09:48:41,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:48:41,715 INFO:     Epoch: 67
2023-01-05 09:48:43,848 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.4530813713868459, 'Total loss': 0.4530813713868459} | train loss {'Reaction outcome loss': 0.3088823404345337, 'Total loss': 0.3088823404345337}
2023-01-05 09:48:43,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:48:43,848 INFO:     Epoch: 68
2023-01-05 09:48:46,006 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4470363517602285, 'Total loss': 0.4470363517602285} | train loss {'Reaction outcome loss': 0.3060188337779213, 'Total loss': 0.3060188337779213}
2023-01-05 09:48:46,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:48:46,006 INFO:     Epoch: 69
2023-01-05 09:48:48,156 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4304051522165537, 'Total loss': 0.4304051522165537} | train loss {'Reaction outcome loss': 0.30275890737370437, 'Total loss': 0.30275890737370437}
2023-01-05 09:48:48,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:48:48,157 INFO:     Epoch: 70
2023-01-05 09:48:50,297 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.399464362859726, 'Total loss': 0.399464362859726} | train loss {'Reaction outcome loss': 0.30028366014712315, 'Total loss': 0.30028366014712315}
2023-01-05 09:48:50,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:48:50,298 INFO:     Epoch: 71
2023-01-05 09:48:52,442 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.40311080515384673, 'Total loss': 0.40311080515384673} | train loss {'Reaction outcome loss': 0.3010306220768025, 'Total loss': 0.3010306220768025}
2023-01-05 09:48:52,442 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:48:52,442 INFO:     Epoch: 72
2023-01-05 09:48:54,576 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.43248936931292215, 'Total loss': 0.43248936931292215} | train loss {'Reaction outcome loss': 0.2977024102718502, 'Total loss': 0.2977024102718502}
2023-01-05 09:48:54,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:48:54,576 INFO:     Epoch: 73
2023-01-05 09:48:56,702 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.37604313616951307, 'Total loss': 0.37604313616951307} | train loss {'Reaction outcome loss': 0.292906798133829, 'Total loss': 0.292906798133829}
2023-01-05 09:48:56,703 INFO:     Found new best model at epoch 73
2023-01-05 09:48:56,704 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:48:56,704 INFO:     Epoch: 74
2023-01-05 09:48:58,846 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4508825108408928, 'Total loss': 0.4508825108408928} | train loss {'Reaction outcome loss': 0.29168953047390433, 'Total loss': 0.29168953047390433}
2023-01-05 09:48:58,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:48:58,846 INFO:     Epoch: 75
2023-01-05 09:49:00,977 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.48998647133509315, 'Total loss': 0.48998647133509315} | train loss {'Reaction outcome loss': 0.30089330668578035, 'Total loss': 0.30089330668578035}
2023-01-05 09:49:00,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:49:00,978 INFO:     Epoch: 76
2023-01-05 09:49:03,100 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.40226162870724996, 'Total loss': 0.40226162870724996} | train loss {'Reaction outcome loss': 0.2939418492487807, 'Total loss': 0.2939418492487807}
2023-01-05 09:49:03,100 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:49:03,100 INFO:     Epoch: 77
2023-01-05 09:49:05,235 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4025276318192482, 'Total loss': 0.4025276318192482} | train loss {'Reaction outcome loss': 0.2896425830034971, 'Total loss': 0.2896425830034971}
2023-01-05 09:49:05,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:49:05,235 INFO:     Epoch: 78
2023-01-05 09:49:07,363 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.4157491018374761, 'Total loss': 0.4157491018374761} | train loss {'Reaction outcome loss': 0.28690868751078413, 'Total loss': 0.28690868751078413}
2023-01-05 09:49:07,363 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:49:07,363 INFO:     Epoch: 79
2023-01-05 09:49:09,504 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.44076884984970094, 'Total loss': 0.44076884984970094} | train loss {'Reaction outcome loss': 0.30629984897869406, 'Total loss': 0.30629984897869406}
2023-01-05 09:49:09,504 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:49:09,504 INFO:     Epoch: 80
2023-01-05 09:49:11,641 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.42724528213342033, 'Total loss': 0.42724528213342033} | train loss {'Reaction outcome loss': 0.2886344516644359, 'Total loss': 0.2886344516644359}
2023-01-05 09:49:11,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:49:11,642 INFO:     Epoch: 81
2023-01-05 09:49:13,777 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.4554190933704376, 'Total loss': 0.4554190933704376} | train loss {'Reaction outcome loss': 0.28019128370120283, 'Total loss': 0.28019128370120283}
2023-01-05 09:49:13,777 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:49:13,777 INFO:     Epoch: 82
2023-01-05 09:49:15,911 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.4476916293303172, 'Total loss': 0.4476916293303172} | train loss {'Reaction outcome loss': 0.28217837156821124, 'Total loss': 0.28217837156821124}
2023-01-05 09:49:15,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:49:15,911 INFO:     Epoch: 83
2023-01-05 09:49:18,032 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3957383046547572, 'Total loss': 0.3957383046547572} | train loss {'Reaction outcome loss': 0.2776558578597347, 'Total loss': 0.2776558578597347}
2023-01-05 09:49:18,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:49:18,034 INFO:     Epoch: 84
2023-01-05 09:49:20,176 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4016509473323822, 'Total loss': 0.4016509473323822} | train loss {'Reaction outcome loss': 0.27764080356905324, 'Total loss': 0.27764080356905324}
2023-01-05 09:49:20,176 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:49:20,176 INFO:     Epoch: 85
2023-01-05 09:49:22,323 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.42065339585145317, 'Total loss': 0.42065339585145317} | train loss {'Reaction outcome loss': 0.2783397057083557, 'Total loss': 0.2783397057083557}
2023-01-05 09:49:22,323 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:49:22,323 INFO:     Epoch: 86
2023-01-05 09:49:24,446 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.45336365203062695, 'Total loss': 0.45336365203062695} | train loss {'Reaction outcome loss': 0.27534195867643785, 'Total loss': 0.27534195867643785}
2023-01-05 09:49:24,447 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:49:24,447 INFO:     Epoch: 87
2023-01-05 09:49:26,579 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.41454347092658284, 'Total loss': 0.41454347092658284} | train loss {'Reaction outcome loss': 0.27415760722795024, 'Total loss': 0.27415760722795024}
2023-01-05 09:49:26,579 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:49:26,580 INFO:     Epoch: 88
2023-01-05 09:49:28,721 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.38351127207279206, 'Total loss': 0.38351127207279206} | train loss {'Reaction outcome loss': 0.2708811855510525, 'Total loss': 0.2708811855510525}
2023-01-05 09:49:28,721 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:49:28,721 INFO:     Epoch: 89
2023-01-05 09:49:30,848 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4159053772687912, 'Total loss': 0.4159053772687912} | train loss {'Reaction outcome loss': 0.27941525240506354, 'Total loss': 0.27941525240506354}
2023-01-05 09:49:30,848 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:49:30,849 INFO:     Epoch: 90
2023-01-05 09:49:32,999 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4501246720552444, 'Total loss': 0.4501246720552444} | train loss {'Reaction outcome loss': 0.2710399757619387, 'Total loss': 0.2710399757619387}
2023-01-05 09:49:32,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:49:32,999 INFO:     Epoch: 91
2023-01-05 09:49:35,139 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4415188878774643, 'Total loss': 0.4415188878774643} | train loss {'Reaction outcome loss': 0.2758990344726413, 'Total loss': 0.2758990344726413}
2023-01-05 09:49:35,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:49:35,140 INFO:     Epoch: 92
2023-01-05 09:49:37,277 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.39763564070065816, 'Total loss': 0.39763564070065816} | train loss {'Reaction outcome loss': 0.2691173094372325, 'Total loss': 0.2691173094372325}
2023-01-05 09:49:37,278 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:49:37,278 INFO:     Epoch: 93
2023-01-05 09:49:39,427 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.4263446132342021, 'Total loss': 0.4263446132342021} | train loss {'Reaction outcome loss': 0.26933476641990134, 'Total loss': 0.26933476641990134}
2023-01-05 09:49:39,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:49:39,428 INFO:     Epoch: 94
2023-01-05 09:49:41,561 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.44010141094525657, 'Total loss': 0.44010141094525657} | train loss {'Reaction outcome loss': 0.2650931926968885, 'Total loss': 0.2650931926968885}
2023-01-05 09:49:41,561 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:49:41,561 INFO:     Epoch: 95
2023-01-05 09:49:43,700 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4293843984603882, 'Total loss': 0.4293843984603882} | train loss {'Reaction outcome loss': 0.26078122575073276, 'Total loss': 0.26078122575073276}
2023-01-05 09:49:43,700 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:49:43,700 INFO:     Epoch: 96
2023-01-05 09:49:45,850 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.4151189605394999, 'Total loss': 0.4151189605394999} | train loss {'Reaction outcome loss': 0.26233780719137384, 'Total loss': 0.26233780719137384}
2023-01-05 09:49:45,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:49:45,850 INFO:     Epoch: 97
2023-01-05 09:49:47,988 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4362063298622767, 'Total loss': 0.4362063298622767} | train loss {'Reaction outcome loss': 0.2654575513104224, 'Total loss': 0.2654575513104224}
2023-01-05 09:49:47,989 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:49:47,989 INFO:     Epoch: 98
2023-01-05 09:49:50,120 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.41427302956581114, 'Total loss': 0.41427302956581114} | train loss {'Reaction outcome loss': 0.2646775875666366, 'Total loss': 0.2646775875666366}
2023-01-05 09:49:50,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:49:50,120 INFO:     Epoch: 99
2023-01-05 09:49:52,260 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44961515863736473, 'Total loss': 0.44961515863736473} | train loss {'Reaction outcome loss': 0.2712458365569836, 'Total loss': 0.2712458365569836}
2023-01-05 09:49:52,260 INFO:     Best model found after epoch 74 of 100.
2023-01-05 09:49:52,260 INFO:   Done with stage: TRAINING
2023-01-05 09:49:52,260 INFO:   Starting stage: EVALUATION
2023-01-05 09:49:52,392 INFO:   Done with stage: EVALUATION
2023-01-05 09:49:52,392 INFO:   Leaving out SEQ value Fold_6
2023-01-05 09:49:52,404 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 09:49:52,404 INFO:   Starting stage: FEATURE SCALING
2023-01-05 09:49:53,051 INFO:   Done with stage: FEATURE SCALING
2023-01-05 09:49:53,051 INFO:   Starting stage: SCALING TARGETS
2023-01-05 09:49:53,118 INFO:   Done with stage: SCALING TARGETS
2023-01-05 09:49:53,118 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:49:53,118 INFO:     No hyperparam tuning for this model
2023-01-05 09:49:53,118 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:49:53,118 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 09:49:53,119 INFO:     None feature selector for col prot
2023-01-05 09:49:53,119 INFO:     None feature selector for col prot
2023-01-05 09:49:53,119 INFO:     None feature selector for col prot
2023-01-05 09:49:53,120 INFO:     None feature selector for col chem
2023-01-05 09:49:53,120 INFO:     None feature selector for col chem
2023-01-05 09:49:53,120 INFO:     None feature selector for col chem
2023-01-05 09:49:53,120 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 09:49:53,120 INFO:   Starting stage: BUILD MODEL
2023-01-05 09:49:53,121 INFO:     Number of params in model 72901
2023-01-05 09:49:53,124 INFO:   Done with stage: BUILD MODEL
2023-01-05 09:49:53,125 INFO:   Starting stage: TRAINING
2023-01-05 09:49:53,183 INFO:     Val loss before train {'Reaction outcome loss': 1.0302716493606567, 'Total loss': 1.0302716493606567}
2023-01-05 09:49:53,183 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:49:53,184 INFO:     Epoch: 0
2023-01-05 09:49:55,324 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8271087805430094, 'Total loss': 0.8271087805430094} | train loss {'Reaction outcome loss': 0.920420147937493, 'Total loss': 0.920420147937493}
2023-01-05 09:49:55,325 INFO:     Found new best model at epoch 0
2023-01-05 09:49:55,326 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:49:55,326 INFO:     Epoch: 1
2023-01-05 09:49:57,460 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6490060269832612, 'Total loss': 0.6490060269832612} | train loss {'Reaction outcome loss': 0.7332906349514867, 'Total loss': 0.7332906349514867}
2023-01-05 09:49:57,460 INFO:     Found new best model at epoch 1
2023-01-05 09:49:57,461 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:49:57,461 INFO:     Epoch: 2
2023-01-05 09:49:59,581 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.536905703941981, 'Total loss': 0.536905703941981} | train loss {'Reaction outcome loss': 0.5899560288382708, 'Total loss': 0.5899560288382708}
2023-01-05 09:49:59,581 INFO:     Found new best model at epoch 2
2023-01-05 09:49:59,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:49:59,582 INFO:     Epoch: 3
2023-01-05 09:50:01,724 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.48177350759506227, 'Total loss': 0.48177350759506227} | train loss {'Reaction outcome loss': 0.5306520808650099, 'Total loss': 0.5306520808650099}
2023-01-05 09:50:01,724 INFO:     Found new best model at epoch 3
2023-01-05 09:50:01,725 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:50:01,725 INFO:     Epoch: 4
2023-01-05 09:50:03,849 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5172423193852107, 'Total loss': 0.5172423193852107} | train loss {'Reaction outcome loss': 0.5185862793452174, 'Total loss': 0.5185862793452174}
2023-01-05 09:50:03,849 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:50:03,849 INFO:     Epoch: 5
2023-01-05 09:50:05,976 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48209513823191324, 'Total loss': 0.48209513823191324} | train loss {'Reaction outcome loss': 0.495858864837235, 'Total loss': 0.495858864837235}
2023-01-05 09:50:05,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:50:05,977 INFO:     Epoch: 6
2023-01-05 09:50:07,904 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4964826246102651, 'Total loss': 0.4964826246102651} | train loss {'Reaction outcome loss': 0.48617863520116045, 'Total loss': 0.48617863520116045}
2023-01-05 09:50:07,904 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:50:07,905 INFO:     Epoch: 7
2023-01-05 09:50:10,032 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.47180024286111194, 'Total loss': 0.47180024286111194} | train loss {'Reaction outcome loss': 0.4809899215135005, 'Total loss': 0.4809899215135005}
2023-01-05 09:50:10,032 INFO:     Found new best model at epoch 7
2023-01-05 09:50:10,033 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:50:10,033 INFO:     Epoch: 8
2023-01-05 09:50:12,140 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.48161258101463317, 'Total loss': 0.48161258101463317} | train loss {'Reaction outcome loss': 0.474843091884606, 'Total loss': 0.474843091884606}
2023-01-05 09:50:12,140 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:50:12,140 INFO:     Epoch: 9
2023-01-05 09:50:14,268 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4700780938069026, 'Total loss': 0.4700780938069026} | train loss {'Reaction outcome loss': 0.46501260902395175, 'Total loss': 0.46501260902395175}
2023-01-05 09:50:14,268 INFO:     Found new best model at epoch 9
2023-01-05 09:50:14,269 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:50:14,269 INFO:     Epoch: 10
2023-01-05 09:50:16,401 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.45347592582305274, 'Total loss': 0.45347592582305274} | train loss {'Reaction outcome loss': 0.46198221344325313, 'Total loss': 0.46198221344325313}
2023-01-05 09:50:16,401 INFO:     Found new best model at epoch 10
2023-01-05 09:50:16,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:50:16,402 INFO:     Epoch: 11
2023-01-05 09:50:18,538 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.44766776959101356, 'Total loss': 0.44766776959101356} | train loss {'Reaction outcome loss': 0.4545844671505409, 'Total loss': 0.4545844671505409}
2023-01-05 09:50:18,538 INFO:     Found new best model at epoch 11
2023-01-05 09:50:18,539 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:50:18,540 INFO:     Epoch: 12
2023-01-05 09:50:20,663 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.43770904739697775, 'Total loss': 0.43770904739697775} | train loss {'Reaction outcome loss': 0.4559063485864064, 'Total loss': 0.4559063485864064}
2023-01-05 09:50:20,664 INFO:     Found new best model at epoch 12
2023-01-05 09:50:20,665 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:50:20,665 INFO:     Epoch: 13
2023-01-05 09:50:22,793 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.44018480281035105, 'Total loss': 0.44018480281035105} | train loss {'Reaction outcome loss': 0.4544910831187946, 'Total loss': 0.4544910831187946}
2023-01-05 09:50:22,793 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:50:22,793 INFO:     Epoch: 14
2023-01-05 09:50:24,923 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4601639986038208, 'Total loss': 0.4601639986038208} | train loss {'Reaction outcome loss': 0.46480736470160383, 'Total loss': 0.46480736470160383}
2023-01-05 09:50:24,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:50:24,924 INFO:     Epoch: 15
2023-01-05 09:50:27,054 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4499125391244888, 'Total loss': 0.4499125391244888} | train loss {'Reaction outcome loss': 0.44399032282872475, 'Total loss': 0.44399032282872475}
2023-01-05 09:50:27,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:50:27,054 INFO:     Epoch: 16
2023-01-05 09:50:29,166 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4414606352647146, 'Total loss': 0.4414606352647146} | train loss {'Reaction outcome loss': 0.4470204068550273, 'Total loss': 0.4470204068550273}
2023-01-05 09:50:29,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:50:29,166 INFO:     Epoch: 17
2023-01-05 09:50:31,296 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4421052227417628, 'Total loss': 0.4421052227417628} | train loss {'Reaction outcome loss': 0.43527117171797197, 'Total loss': 0.43527117171797197}
2023-01-05 09:50:31,297 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:50:31,297 INFO:     Epoch: 18
2023-01-05 09:50:33,424 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4253042300542196, 'Total loss': 0.4253042300542196} | train loss {'Reaction outcome loss': 0.4317514914749325, 'Total loss': 0.4317514914749325}
2023-01-05 09:50:33,424 INFO:     Found new best model at epoch 18
2023-01-05 09:50:33,426 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:50:33,426 INFO:     Epoch: 19
2023-01-05 09:50:35,558 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4153569241364797, 'Total loss': 0.4153569241364797} | train loss {'Reaction outcome loss': 0.44962216578963876, 'Total loss': 0.44962216578963876}
2023-01-05 09:50:35,558 INFO:     Found new best model at epoch 19
2023-01-05 09:50:35,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:50:35,559 INFO:     Epoch: 20
2023-01-05 09:50:37,687 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4206257263819377, 'Total loss': 0.4206257263819377} | train loss {'Reaction outcome loss': 0.43109822284052335, 'Total loss': 0.43109822284052335}
2023-01-05 09:50:37,687 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:50:37,687 INFO:     Epoch: 21
2023-01-05 09:50:39,802 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.43488953560590743, 'Total loss': 0.43488953560590743} | train loss {'Reaction outcome loss': 0.4252524023767615, 'Total loss': 0.4252524023767615}
2023-01-05 09:50:39,802 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:50:39,802 INFO:     Epoch: 22
2023-01-05 09:50:41,935 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42330381174882253, 'Total loss': 0.42330381174882253} | train loss {'Reaction outcome loss': 0.4211712722815033, 'Total loss': 0.4211712722815033}
2023-01-05 09:50:41,935 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:50:41,935 INFO:     Epoch: 23
2023-01-05 09:50:44,060 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4176495393117269, 'Total loss': 0.4176495393117269} | train loss {'Reaction outcome loss': 0.4117386484193022, 'Total loss': 0.4117386484193022}
2023-01-05 09:50:44,061 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:50:44,061 INFO:     Epoch: 24
2023-01-05 09:50:46,177 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4388147830963135, 'Total loss': 0.4388147830963135} | train loss {'Reaction outcome loss': 0.41212760941472376, 'Total loss': 0.41212760941472376}
2023-01-05 09:50:46,177 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:50:46,177 INFO:     Epoch: 25
2023-01-05 09:50:48,302 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4567620764176051, 'Total loss': 0.4567620764176051} | train loss {'Reaction outcome loss': 0.4060383244144285, 'Total loss': 0.4060383244144285}
2023-01-05 09:50:48,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:50:48,302 INFO:     Epoch: 26
2023-01-05 09:50:50,421 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.408735466003418, 'Total loss': 0.408735466003418} | train loss {'Reaction outcome loss': 0.4016870967065241, 'Total loss': 0.4016870967065241}
2023-01-05 09:50:50,421 INFO:     Found new best model at epoch 26
2023-01-05 09:50:50,422 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:50:50,422 INFO:     Epoch: 27
2023-01-05 09:50:52,530 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4076349159081777, 'Total loss': 0.4076349159081777} | train loss {'Reaction outcome loss': 0.4055636834785126, 'Total loss': 0.4055636834785126}
2023-01-05 09:50:52,531 INFO:     Found new best model at epoch 27
2023-01-05 09:50:52,532 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:50:52,532 INFO:     Epoch: 28
2023-01-05 09:50:54,671 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.42092864712079364, 'Total loss': 0.42092864712079364} | train loss {'Reaction outcome loss': 0.4246385096423868, 'Total loss': 0.4246385096423868}
2023-01-05 09:50:54,672 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:50:54,672 INFO:     Epoch: 29
2023-01-05 09:50:56,772 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.39406967759132383, 'Total loss': 0.39406967759132383} | train loss {'Reaction outcome loss': 0.4085456341828989, 'Total loss': 0.4085456341828989}
2023-01-05 09:50:56,772 INFO:     Found new best model at epoch 29
2023-01-05 09:50:56,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:50:56,774 INFO:     Epoch: 30
2023-01-05 09:50:58,926 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.40862912237644194, 'Total loss': 0.40862912237644194} | train loss {'Reaction outcome loss': 0.40085481455468613, 'Total loss': 0.40085481455468613}
2023-01-05 09:50:58,927 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:50:58,927 INFO:     Epoch: 31
2023-01-05 09:51:01,102 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3969046801328659, 'Total loss': 0.3969046801328659} | train loss {'Reaction outcome loss': 0.3885285241639645, 'Total loss': 0.3885285241639645}
2023-01-05 09:51:01,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:51:01,102 INFO:     Epoch: 32
2023-01-05 09:51:03,228 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4055359383424123, 'Total loss': 0.4055359383424123} | train loss {'Reaction outcome loss': 0.388997566350567, 'Total loss': 0.388997566350567}
2023-01-05 09:51:03,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:51:03,229 INFO:     Epoch: 33
2023-01-05 09:51:05,351 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.40919073224067687, 'Total loss': 0.40919073224067687} | train loss {'Reaction outcome loss': 0.3825770230774862, 'Total loss': 0.3825770230774862}
2023-01-05 09:51:05,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:51:05,352 INFO:     Epoch: 34
2023-01-05 09:51:07,491 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.4310484528541565, 'Total loss': 0.4310484528541565} | train loss {'Reaction outcome loss': 0.38179540366367737, 'Total loss': 0.38179540366367737}
2023-01-05 09:51:07,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:51:07,491 INFO:     Epoch: 35
2023-01-05 09:51:09,618 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.405307791630427, 'Total loss': 0.405307791630427} | train loss {'Reaction outcome loss': 0.37810456977620005, 'Total loss': 0.37810456977620005}
2023-01-05 09:51:09,619 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:51:09,619 INFO:     Epoch: 36
2023-01-05 09:51:11,742 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.41182177265485126, 'Total loss': 0.41182177265485126} | train loss {'Reaction outcome loss': 0.3667660237565608, 'Total loss': 0.3667660237565608}
2023-01-05 09:51:11,742 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:51:11,742 INFO:     Epoch: 37
2023-01-05 09:51:13,870 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.41622276802857716, 'Total loss': 0.41622276802857716} | train loss {'Reaction outcome loss': 0.36997879285490193, 'Total loss': 0.36997879285490193}
2023-01-05 09:51:13,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:51:13,871 INFO:     Epoch: 38
2023-01-05 09:51:15,998 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.3760573585828145, 'Total loss': 0.3760573585828145} | train loss {'Reaction outcome loss': 0.3677453605215187, 'Total loss': 0.3677453605215187}
2023-01-05 09:51:15,998 INFO:     Found new best model at epoch 38
2023-01-05 09:51:15,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:51:15,999 INFO:     Epoch: 39
2023-01-05 09:51:18,119 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40257432162761686, 'Total loss': 0.40257432162761686} | train loss {'Reaction outcome loss': 0.36803574698801705, 'Total loss': 0.36803574698801705}
2023-01-05 09:51:18,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:51:18,119 INFO:     Epoch: 40
2023-01-05 09:51:20,272 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.38035691281159717, 'Total loss': 0.38035691281159717} | train loss {'Reaction outcome loss': 0.3615418395054513, 'Total loss': 0.3615418395054513}
2023-01-05 09:51:20,273 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:51:20,273 INFO:     Epoch: 41
2023-01-05 09:51:22,440 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4125282014409701, 'Total loss': 0.4125282014409701} | train loss {'Reaction outcome loss': 0.3591244218641541, 'Total loss': 0.3591244218641541}
2023-01-05 09:51:22,440 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:51:22,440 INFO:     Epoch: 42
2023-01-05 09:51:24,609 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4149713203310966, 'Total loss': 0.4149713203310966} | train loss {'Reaction outcome loss': 0.36045240467765194, 'Total loss': 0.36045240467765194}
2023-01-05 09:51:24,609 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:51:24,610 INFO:     Epoch: 43
2023-01-05 09:51:26,758 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.40605485439300537, 'Total loss': 0.40605485439300537} | train loss {'Reaction outcome loss': 0.3505159171915654, 'Total loss': 0.3505159171915654}
2023-01-05 09:51:26,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:51:26,758 INFO:     Epoch: 44
2023-01-05 09:51:28,925 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.40318255722522733, 'Total loss': 0.40318255722522733} | train loss {'Reaction outcome loss': 0.3486006640781905, 'Total loss': 0.3486006640781905}
2023-01-05 09:51:28,925 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:51:28,925 INFO:     Epoch: 45
2023-01-05 09:51:31,054 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.40193724234898887, 'Total loss': 0.40193724234898887} | train loss {'Reaction outcome loss': 0.342630963438474, 'Total loss': 0.342630963438474}
2023-01-05 09:51:31,054 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:51:31,054 INFO:     Epoch: 46
2023-01-05 09:51:33,208 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41047676602999367, 'Total loss': 0.41047676602999367} | train loss {'Reaction outcome loss': 0.34305738227566757, 'Total loss': 0.34305738227566757}
2023-01-05 09:51:33,208 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:51:33,209 INFO:     Epoch: 47
2023-01-05 09:51:35,346 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.3902345071236292, 'Total loss': 0.3902345071236292} | train loss {'Reaction outcome loss': 0.33717843776811723, 'Total loss': 0.33717843776811723}
2023-01-05 09:51:35,348 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:51:35,348 INFO:     Epoch: 48
2023-01-05 09:51:37,480 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.39657047142585117, 'Total loss': 0.39657047142585117} | train loss {'Reaction outcome loss': 0.3359112792067986, 'Total loss': 0.3359112792067986}
2023-01-05 09:51:37,480 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:51:37,480 INFO:     Epoch: 49
2023-01-05 09:51:39,613 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.39095323781172436, 'Total loss': 0.39095323781172436} | train loss {'Reaction outcome loss': 0.3433745797669542, 'Total loss': 0.3433745797669542}
2023-01-05 09:51:39,613 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:51:39,613 INFO:     Epoch: 50
2023-01-05 09:51:41,746 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.42982565859953564, 'Total loss': 0.42982565859953564} | train loss {'Reaction outcome loss': 0.35360911821413354, 'Total loss': 0.35360911821413354}
2023-01-05 09:51:41,747 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:51:41,747 INFO:     Epoch: 51
2023-01-05 09:51:44,003 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4084746564428012, 'Total loss': 0.4084746564428012} | train loss {'Reaction outcome loss': 0.3310967930162366, 'Total loss': 0.3310967930162366}
2023-01-05 09:51:44,003 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:51:44,003 INFO:     Epoch: 52
2023-01-05 09:51:46,157 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.39092616240183514, 'Total loss': 0.39092616240183514} | train loss {'Reaction outcome loss': 0.3298439399889279, 'Total loss': 0.3298439399889279}
2023-01-05 09:51:46,157 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:51:46,157 INFO:     Epoch: 53
2023-01-05 09:51:48,312 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.418471626440684, 'Total loss': 0.418471626440684} | train loss {'Reaction outcome loss': 0.32121443340851774, 'Total loss': 0.32121443340851774}
2023-01-05 09:51:48,312 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:51:48,312 INFO:     Epoch: 54
2023-01-05 09:51:50,451 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.41072131594022115, 'Total loss': 0.41072131594022115} | train loss {'Reaction outcome loss': 0.32412071749884874, 'Total loss': 0.32412071749884874}
2023-01-05 09:51:50,451 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:51:50,451 INFO:     Epoch: 55
2023-01-05 09:51:52,599 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.39091447194417317, 'Total loss': 0.39091447194417317} | train loss {'Reaction outcome loss': 0.31779037271115923, 'Total loss': 0.31779037271115923}
2023-01-05 09:51:52,599 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:51:52,599 INFO:     Epoch: 56
2023-01-05 09:51:54,738 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.3953117936849594, 'Total loss': 0.3953117936849594} | train loss {'Reaction outcome loss': 0.3213705734790141, 'Total loss': 0.3213705734790141}
2023-01-05 09:51:54,739 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:51:54,739 INFO:     Epoch: 57
2023-01-05 09:51:56,890 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.395876141389211, 'Total loss': 0.395876141389211} | train loss {'Reaction outcome loss': 0.31772760790941457, 'Total loss': 0.31772760790941457}
2023-01-05 09:51:56,890 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:51:56,890 INFO:     Epoch: 58
2023-01-05 09:51:59,031 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.3840295930703481, 'Total loss': 0.3840295930703481} | train loss {'Reaction outcome loss': 0.3140304338429933, 'Total loss': 0.3140304338429933}
2023-01-05 09:51:59,031 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:51:59,031 INFO:     Epoch: 59
2023-01-05 09:52:01,182 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.4105362395445506, 'Total loss': 0.4105362395445506} | train loss {'Reaction outcome loss': 0.3143667481009565, 'Total loss': 0.3143667481009565}
2023-01-05 09:52:01,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:52:01,182 INFO:     Epoch: 60
2023-01-05 09:52:03,337 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.3927135248978933, 'Total loss': 0.3927135248978933} | train loss {'Reaction outcome loss': 0.31275811179311597, 'Total loss': 0.31275811179311597}
2023-01-05 09:52:03,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:52:03,337 INFO:     Epoch: 61
2023-01-05 09:52:05,466 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38984197477499644, 'Total loss': 0.38984197477499644} | train loss {'Reaction outcome loss': 0.30889662631544407, 'Total loss': 0.30889662631544407}
2023-01-05 09:52:05,467 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:52:05,467 INFO:     Epoch: 62
2023-01-05 09:52:07,607 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.41273189584414166, 'Total loss': 0.41273189584414166} | train loss {'Reaction outcome loss': 0.30804918694967337, 'Total loss': 0.30804918694967337}
2023-01-05 09:52:07,608 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:52:07,608 INFO:     Epoch: 63
2023-01-05 09:52:09,741 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3785194506247838, 'Total loss': 0.3785194506247838} | train loss {'Reaction outcome loss': 0.3060860999427952, 'Total loss': 0.3060860999427952}
2023-01-05 09:52:09,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:52:09,741 INFO:     Epoch: 64
2023-01-05 09:52:11,872 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.3707398240764936, 'Total loss': 0.3707398240764936} | train loss {'Reaction outcome loss': 0.30431447358990926, 'Total loss': 0.30431447358990926}
2023-01-05 09:52:11,873 INFO:     Found new best model at epoch 64
2023-01-05 09:52:11,874 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:52:11,874 INFO:     Epoch: 65
2023-01-05 09:52:13,998 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.4014075418313344, 'Total loss': 0.4014075418313344} | train loss {'Reaction outcome loss': 0.3047053258953805, 'Total loss': 0.3047053258953805}
2023-01-05 09:52:13,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:52:13,998 INFO:     Epoch: 66
2023-01-05 09:52:16,146 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.44110970497131347, 'Total loss': 0.44110970497131347} | train loss {'Reaction outcome loss': 0.2998758679360448, 'Total loss': 0.2998758679360448}
2023-01-05 09:52:16,146 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:52:16,146 INFO:     Epoch: 67
2023-01-05 09:52:18,266 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3871872256199519, 'Total loss': 0.3871872256199519} | train loss {'Reaction outcome loss': 0.3019683773804834, 'Total loss': 0.3019683773804834}
2023-01-05 09:52:18,267 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:52:18,267 INFO:     Epoch: 68
2023-01-05 09:52:20,420 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3796466539303462, 'Total loss': 0.3796466539303462} | train loss {'Reaction outcome loss': 0.30801357123266865, 'Total loss': 0.30801357123266865}
2023-01-05 09:52:20,420 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:52:20,421 INFO:     Epoch: 69
2023-01-05 09:52:22,575 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3692996084690094, 'Total loss': 0.3692996084690094} | train loss {'Reaction outcome loss': 0.2953119667500436, 'Total loss': 0.2953119667500436}
2023-01-05 09:52:22,575 INFO:     Found new best model at epoch 69
2023-01-05 09:52:22,576 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:52:22,576 INFO:     Epoch: 70
2023-01-05 09:52:24,734 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.3775247593720754, 'Total loss': 0.3775247593720754} | train loss {'Reaction outcome loss': 0.28815077872560074, 'Total loss': 0.28815077872560074}
2023-01-05 09:52:24,734 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:52:24,734 INFO:     Epoch: 71
2023-01-05 09:52:26,858 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.3761786152919134, 'Total loss': 0.3761786152919134} | train loss {'Reaction outcome loss': 0.2832141820910982, 'Total loss': 0.2832141820910982}
2023-01-05 09:52:26,858 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:52:26,858 INFO:     Epoch: 72
2023-01-05 09:52:28,998 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3796337415774663, 'Total loss': 0.3796337415774663} | train loss {'Reaction outcome loss': 0.28354277015171025, 'Total loss': 0.28354277015171025}
2023-01-05 09:52:28,999 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:52:28,999 INFO:     Epoch: 73
2023-01-05 09:52:31,131 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.4128348489602407, 'Total loss': 0.4128348489602407} | train loss {'Reaction outcome loss': 0.2881525354594856, 'Total loss': 0.2881525354594856}
2023-01-05 09:52:31,132 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:52:31,132 INFO:     Epoch: 74
2023-01-05 09:52:33,260 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.3819266950090726, 'Total loss': 0.3819266950090726} | train loss {'Reaction outcome loss': 0.28906367361407215, 'Total loss': 0.28906367361407215}
2023-01-05 09:52:33,260 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:52:33,260 INFO:     Epoch: 75
2023-01-05 09:52:35,408 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3998960057894389, 'Total loss': 0.3998960057894389} | train loss {'Reaction outcome loss': 0.2838198443085117, 'Total loss': 0.2838198443085117}
2023-01-05 09:52:35,408 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:52:35,408 INFO:     Epoch: 76
2023-01-05 09:52:37,529 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.34589107185602186, 'Total loss': 0.34589107185602186} | train loss {'Reaction outcome loss': 0.2807958865625973, 'Total loss': 0.2807958865625973}
2023-01-05 09:52:37,529 INFO:     Found new best model at epoch 76
2023-01-05 09:52:37,531 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:52:37,531 INFO:     Epoch: 77
2023-01-05 09:52:39,669 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3998493005832036, 'Total loss': 0.3998493005832036} | train loss {'Reaction outcome loss': 0.2773342363829927, 'Total loss': 0.2773342363829927}
2023-01-05 09:52:39,669 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:52:39,669 INFO:     Epoch: 78
2023-01-05 09:52:41,785 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.391656427582105, 'Total loss': 0.391656427582105} | train loss {'Reaction outcome loss': 0.2779735845979303, 'Total loss': 0.2779735845979303}
2023-01-05 09:52:41,786 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:52:41,786 INFO:     Epoch: 79
2023-01-05 09:52:43,930 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.38716547389825184, 'Total loss': 0.38716547389825184} | train loss {'Reaction outcome loss': 0.2739266756503323, 'Total loss': 0.2739266756503323}
2023-01-05 09:52:43,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:52:43,930 INFO:     Epoch: 80
2023-01-05 09:52:46,061 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4079378421107928, 'Total loss': 0.4079378421107928} | train loss {'Reaction outcome loss': 0.2900195394548169, 'Total loss': 0.2900195394548169}
2023-01-05 09:52:46,062 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:52:46,062 INFO:     Epoch: 81
2023-01-05 09:52:48,186 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.39372984170913694, 'Total loss': 0.39372984170913694} | train loss {'Reaction outcome loss': 0.30042331031290814, 'Total loss': 0.30042331031290814}
2023-01-05 09:52:48,187 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:52:48,187 INFO:     Epoch: 82
2023-01-05 09:52:50,296 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.39802975753943126, 'Total loss': 0.39802975753943126} | train loss {'Reaction outcome loss': 0.27179904124004417, 'Total loss': 0.27179904124004417}
2023-01-05 09:52:50,296 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:52:50,296 INFO:     Epoch: 83
2023-01-05 09:52:52,407 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.3869565347830454, 'Total loss': 0.3869565347830454} | train loss {'Reaction outcome loss': 0.2720927914057899, 'Total loss': 0.2720927914057899}
2023-01-05 09:52:52,407 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:52:52,407 INFO:     Epoch: 84
2023-01-05 09:52:54,518 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.40074247047305106, 'Total loss': 0.40074247047305106} | train loss {'Reaction outcome loss': 0.27332620568230975, 'Total loss': 0.27332620568230975}
2023-01-05 09:52:54,519 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:52:54,519 INFO:     Epoch: 85
2023-01-05 09:52:56,652 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3754274109999339, 'Total loss': 0.3754274109999339} | train loss {'Reaction outcome loss': 0.26320582748377236, 'Total loss': 0.26320582748377236}
2023-01-05 09:52:56,652 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:52:56,652 INFO:     Epoch: 86
2023-01-05 09:52:58,789 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.3569175720214844, 'Total loss': 0.3569175720214844} | train loss {'Reaction outcome loss': 0.2678346201127684, 'Total loss': 0.2678346201127684}
2023-01-05 09:52:58,789 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:52:58,789 INFO:     Epoch: 87
2023-01-05 09:53:00,929 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.39165046165386835, 'Total loss': 0.39165046165386835} | train loss {'Reaction outcome loss': 0.26840108259500045, 'Total loss': 0.26840108259500045}
2023-01-05 09:53:00,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:53:00,930 INFO:     Epoch: 88
2023-01-05 09:53:03,072 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.395682130753994, 'Total loss': 0.395682130753994} | train loss {'Reaction outcome loss': 0.26523180398267554, 'Total loss': 0.26523180398267554}
2023-01-05 09:53:03,072 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:53:03,072 INFO:     Epoch: 89
2023-01-05 09:53:05,200 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3678985133767128, 'Total loss': 0.3678985133767128} | train loss {'Reaction outcome loss': 0.2634356013716082, 'Total loss': 0.2634356013716082}
2023-01-05 09:53:05,200 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:53:05,200 INFO:     Epoch: 90
2023-01-05 09:53:07,372 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.42368711133797965, 'Total loss': 0.42368711133797965} | train loss {'Reaction outcome loss': 0.2884771997594963, 'Total loss': 0.2884771997594963}
2023-01-05 09:53:07,372 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:53:07,373 INFO:     Epoch: 91
2023-01-05 09:53:09,529 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4167590528726578, 'Total loss': 0.4167590528726578} | train loss {'Reaction outcome loss': 0.26539041099612654, 'Total loss': 0.26539041099612654}
2023-01-05 09:53:09,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:53:09,529 INFO:     Epoch: 92
2023-01-05 09:53:11,625 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4091386104623477, 'Total loss': 0.4091386104623477} | train loss {'Reaction outcome loss': 0.26040893063547654, 'Total loss': 0.26040893063547654}
2023-01-05 09:53:11,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:53:11,626 INFO:     Epoch: 93
2023-01-05 09:53:13,753 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.40435764292875925, 'Total loss': 0.40435764292875925} | train loss {'Reaction outcome loss': 0.26301301326028614, 'Total loss': 0.26301301326028614}
2023-01-05 09:53:13,753 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:53:13,753 INFO:     Epoch: 94
2023-01-05 09:53:15,871 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.4146430976688862, 'Total loss': 0.4146430976688862} | train loss {'Reaction outcome loss': 0.2622642281705761, 'Total loss': 0.2622642281705761}
2023-01-05 09:53:15,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:53:15,871 INFO:     Epoch: 95
2023-01-05 09:53:17,989 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.4229130208492279, 'Total loss': 0.4229130208492279} | train loss {'Reaction outcome loss': 0.26185175467390515, 'Total loss': 0.26185175467390515}
2023-01-05 09:53:17,990 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:53:17,991 INFO:     Epoch: 96
2023-01-05 09:53:20,087 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.37421285758415856, 'Total loss': 0.37421285758415856} | train loss {'Reaction outcome loss': 0.2614655538219149, 'Total loss': 0.2614655538219149}
2023-01-05 09:53:20,087 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:53:20,087 INFO:     Epoch: 97
2023-01-05 09:53:22,226 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3690311392148336, 'Total loss': 0.3690311392148336} | train loss {'Reaction outcome loss': 0.25410476847268315, 'Total loss': 0.25410476847268315}
2023-01-05 09:53:22,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:53:22,227 INFO:     Epoch: 98
2023-01-05 09:53:24,391 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.4038854718208313, 'Total loss': 0.4038854718208313} | train loss {'Reaction outcome loss': 0.259726995879791, 'Total loss': 0.259726995879791}
2023-01-05 09:53:24,392 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:53:24,392 INFO:     Epoch: 99
2023-01-05 09:53:26,484 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.43945072442293165, 'Total loss': 0.43945072442293165} | train loss {'Reaction outcome loss': 0.25070823448291724, 'Total loss': 0.25070823448291724}
2023-01-05 09:53:26,484 INFO:     Best model found after epoch 77 of 100.
2023-01-05 09:53:26,485 INFO:   Done with stage: TRAINING
2023-01-05 09:53:26,485 INFO:   Starting stage: EVALUATION
2023-01-05 09:53:26,615 INFO:   Done with stage: EVALUATION
2023-01-05 09:53:26,615 INFO:   Leaving out SEQ value Fold_7
2023-01-05 09:53:26,628 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 09:53:26,628 INFO:   Starting stage: FEATURE SCALING
2023-01-05 09:53:27,277 INFO:   Done with stage: FEATURE SCALING
2023-01-05 09:53:27,277 INFO:   Starting stage: SCALING TARGETS
2023-01-05 09:53:27,346 INFO:   Done with stage: SCALING TARGETS
2023-01-05 09:53:27,346 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:53:27,346 INFO:     No hyperparam tuning for this model
2023-01-05 09:53:27,346 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:53:27,346 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 09:53:27,347 INFO:     None feature selector for col prot
2023-01-05 09:53:27,347 INFO:     None feature selector for col prot
2023-01-05 09:53:27,347 INFO:     None feature selector for col prot
2023-01-05 09:53:27,347 INFO:     None feature selector for col chem
2023-01-05 09:53:27,348 INFO:     None feature selector for col chem
2023-01-05 09:53:27,348 INFO:     None feature selector for col chem
2023-01-05 09:53:27,348 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 09:53:27,348 INFO:   Starting stage: BUILD MODEL
2023-01-05 09:53:27,349 INFO:     Number of params in model 72901
2023-01-05 09:53:27,352 INFO:   Done with stage: BUILD MODEL
2023-01-05 09:53:27,353 INFO:   Starting stage: TRAINING
2023-01-05 09:53:27,411 INFO:     Val loss before train {'Reaction outcome loss': 0.9515080134073893, 'Total loss': 0.9515080134073893}
2023-01-05 09:53:27,411 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:53:27,411 INFO:     Epoch: 0
2023-01-05 09:53:29,528 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8222822109858196, 'Total loss': 0.8222822109858196} | train loss {'Reaction outcome loss': 0.9193213300154097, 'Total loss': 0.9193213300154097}
2023-01-05 09:53:29,528 INFO:     Found new best model at epoch 0
2023-01-05 09:53:29,529 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:53:29,529 INFO:     Epoch: 1
2023-01-05 09:53:31,680 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6259599447250366, 'Total loss': 0.6259599447250366} | train loss {'Reaction outcome loss': 0.7291810736329116, 'Total loss': 0.7291810736329116}
2023-01-05 09:53:31,680 INFO:     Found new best model at epoch 1
2023-01-05 09:53:31,681 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:53:31,681 INFO:     Epoch: 2
2023-01-05 09:53:33,823 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5041097482045491, 'Total loss': 0.5041097482045491} | train loss {'Reaction outcome loss': 0.5775079707268773, 'Total loss': 0.5775079707268773}
2023-01-05 09:53:33,823 INFO:     Found new best model at epoch 2
2023-01-05 09:53:33,824 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:53:33,824 INFO:     Epoch: 3
2023-01-05 09:53:35,954 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.4988162130117416, 'Total loss': 0.4988162130117416} | train loss {'Reaction outcome loss': 0.5292716127440387, 'Total loss': 0.5292716127440387}
2023-01-05 09:53:35,954 INFO:     Found new best model at epoch 3
2023-01-05 09:53:35,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:53:35,955 INFO:     Epoch: 4
2023-01-05 09:53:38,084 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.4965373744567235, 'Total loss': 0.4965373744567235} | train loss {'Reaction outcome loss': 0.5096547934445234, 'Total loss': 0.5096547934445234}
2023-01-05 09:53:38,085 INFO:     Found new best model at epoch 4
2023-01-05 09:53:38,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:53:38,086 INFO:     Epoch: 5
2023-01-05 09:53:40,213 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.48831290801366173, 'Total loss': 0.48831290801366173} | train loss {'Reaction outcome loss': 0.48823749045387504, 'Total loss': 0.48823749045387504}
2023-01-05 09:53:40,213 INFO:     Found new best model at epoch 5
2023-01-05 09:53:40,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:53:40,215 INFO:     Epoch: 6
2023-01-05 09:53:42,323 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4692794362703959, 'Total loss': 0.4692794362703959} | train loss {'Reaction outcome loss': 0.4861062018987504, 'Total loss': 0.4861062018987504}
2023-01-05 09:53:42,323 INFO:     Found new best model at epoch 6
2023-01-05 09:53:42,324 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:53:42,325 INFO:     Epoch: 7
2023-01-05 09:53:44,496 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4589117795228958, 'Total loss': 0.4589117795228958} | train loss {'Reaction outcome loss': 0.4770593796503673, 'Total loss': 0.4770593796503673}
2023-01-05 09:53:44,496 INFO:     Found new best model at epoch 7
2023-01-05 09:53:44,498 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:53:44,498 INFO:     Epoch: 8
2023-01-05 09:53:46,691 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4663655360539754, 'Total loss': 0.4663655360539754} | train loss {'Reaction outcome loss': 0.4651301235283325, 'Total loss': 0.4651301235283325}
2023-01-05 09:53:46,691 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:53:46,691 INFO:     Epoch: 9
2023-01-05 09:53:48,836 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4915365715821584, 'Total loss': 0.4915365715821584} | train loss {'Reaction outcome loss': 0.46158071244236365, 'Total loss': 0.46158071244236365}
2023-01-05 09:53:48,836 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:53:48,836 INFO:     Epoch: 10
2023-01-05 09:53:50,967 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.42513328890005747, 'Total loss': 0.42513328890005747} | train loss {'Reaction outcome loss': 0.4608834965779893, 'Total loss': 0.4608834965779893}
2023-01-05 09:53:50,967 INFO:     Found new best model at epoch 10
2023-01-05 09:53:50,968 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:53:50,968 INFO:     Epoch: 11
2023-01-05 09:53:53,085 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45243556598822277, 'Total loss': 0.45243556598822277} | train loss {'Reaction outcome loss': 0.45275876162714906, 'Total loss': 0.45275876162714906}
2023-01-05 09:53:53,086 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:53:53,086 INFO:     Epoch: 12
2023-01-05 09:53:55,229 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.4681376839677493, 'Total loss': 0.4681376839677493} | train loss {'Reaction outcome loss': 0.45047402597076197, 'Total loss': 0.45047402597076197}
2023-01-05 09:53:55,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:53:55,229 INFO:     Epoch: 13
2023-01-05 09:53:57,403 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4645150323708852, 'Total loss': 0.4645150323708852} | train loss {'Reaction outcome loss': 0.44590377404156145, 'Total loss': 0.44590377404156145}
2023-01-05 09:53:57,403 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:53:57,403 INFO:     Epoch: 14
2023-01-05 09:53:59,558 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4697931448618571, 'Total loss': 0.4697931448618571} | train loss {'Reaction outcome loss': 0.4391976520957069, 'Total loss': 0.4391976520957069}
2023-01-05 09:53:59,559 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:53:59,559 INFO:     Epoch: 15
2023-01-05 09:54:01,724 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4786899030208588, 'Total loss': 0.4786899030208588} | train loss {'Reaction outcome loss': 0.43066505372309083, 'Total loss': 0.43066505372309083}
2023-01-05 09:54:01,724 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:54:01,724 INFO:     Epoch: 16
2023-01-05 09:54:03,879 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.4597826143105825, 'Total loss': 0.4597826143105825} | train loss {'Reaction outcome loss': 0.4356170498668502, 'Total loss': 0.4356170498668502}
2023-01-05 09:54:03,879 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:54:03,879 INFO:     Epoch: 17
2023-01-05 09:54:05,998 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.4518070052067439, 'Total loss': 0.4518070052067439} | train loss {'Reaction outcome loss': 0.430926563103922, 'Total loss': 0.430926563103922}
2023-01-05 09:54:05,998 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:54:05,998 INFO:     Epoch: 18
2023-01-05 09:54:08,184 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.46256876985232037, 'Total loss': 0.46256876985232037} | train loss {'Reaction outcome loss': 0.42657335758854764, 'Total loss': 0.42657335758854764}
2023-01-05 09:54:08,185 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:54:08,185 INFO:     Epoch: 19
2023-01-05 09:54:10,152 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.45268747210502625, 'Total loss': 0.45268747210502625} | train loss {'Reaction outcome loss': 0.4249399103735328, 'Total loss': 0.4249399103735328}
2023-01-05 09:54:10,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:54:10,152 INFO:     Epoch: 20
2023-01-05 09:54:12,301 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.4394540687402089, 'Total loss': 0.4394540687402089} | train loss {'Reaction outcome loss': 0.41906964749313, 'Total loss': 0.41906964749313}
2023-01-05 09:54:12,302 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:54:12,302 INFO:     Epoch: 21
2023-01-05 09:54:14,438 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.4327666769425074, 'Total loss': 0.4327666769425074} | train loss {'Reaction outcome loss': 0.41443900571672065, 'Total loss': 0.41443900571672065}
2023-01-05 09:54:14,438 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:54:14,438 INFO:     Epoch: 22
2023-01-05 09:54:16,585 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.4463614602883657, 'Total loss': 0.4463614602883657} | train loss {'Reaction outcome loss': 0.40992940803619926, 'Total loss': 0.40992940803619926}
2023-01-05 09:54:16,586 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:54:16,586 INFO:     Epoch: 23
2023-01-05 09:54:18,697 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.4689758062362671, 'Total loss': 0.4689758062362671} | train loss {'Reaction outcome loss': 0.4073379100014587, 'Total loss': 0.4073379100014587}
2023-01-05 09:54:18,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:54:18,697 INFO:     Epoch: 24
2023-01-05 09:54:20,840 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4469544639190038, 'Total loss': 0.4469544639190038} | train loss {'Reaction outcome loss': 0.4044082312969094, 'Total loss': 0.4044082312969094}
2023-01-05 09:54:20,840 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:54:20,840 INFO:     Epoch: 25
2023-01-05 09:54:22,982 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.4347036421298981, 'Total loss': 0.4347036421298981} | train loss {'Reaction outcome loss': 0.4033877213993227, 'Total loss': 0.4033877213993227}
2023-01-05 09:54:22,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:54:22,982 INFO:     Epoch: 26
2023-01-05 09:54:25,117 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4583561172087987, 'Total loss': 0.4583561172087987} | train loss {'Reaction outcome loss': 0.3944493156424068, 'Total loss': 0.3944493156424068}
2023-01-05 09:54:25,117 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:54:25,117 INFO:     Epoch: 27
2023-01-05 09:54:27,229 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4857404480377833, 'Total loss': 0.4857404480377833} | train loss {'Reaction outcome loss': 0.39646284551181515, 'Total loss': 0.39646284551181515}
2023-01-05 09:54:27,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:54:27,229 INFO:     Epoch: 28
2023-01-05 09:54:29,359 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.44629147549470266, 'Total loss': 0.44629147549470266} | train loss {'Reaction outcome loss': 0.3921710544598662, 'Total loss': 0.3921710544598662}
2023-01-05 09:54:29,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:54:29,360 INFO:     Epoch: 29
2023-01-05 09:54:31,570 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4757135490576426, 'Total loss': 0.4757135490576426} | train loss {'Reaction outcome loss': 0.3807301014217982, 'Total loss': 0.3807301014217982}
2023-01-05 09:54:31,571 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:54:31,571 INFO:     Epoch: 30
2023-01-05 09:54:33,758 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.429837159315745, 'Total loss': 0.429837159315745} | train loss {'Reaction outcome loss': 0.38358723486534957, 'Total loss': 0.38358723486534957}
2023-01-05 09:54:33,758 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:54:33,758 INFO:     Epoch: 31
2023-01-05 09:54:35,965 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.43009436726570127, 'Total loss': 0.43009436726570127} | train loss {'Reaction outcome loss': 0.3789963021282685, 'Total loss': 0.3789963021282685}
2023-01-05 09:54:35,966 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:54:35,966 INFO:     Epoch: 32
2023-01-05 09:54:38,151 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.43847769498825073, 'Total loss': 0.43847769498825073} | train loss {'Reaction outcome loss': 0.3702750441345928, 'Total loss': 0.3702750441345928}
2023-01-05 09:54:38,151 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:54:38,152 INFO:     Epoch: 33
2023-01-05 09:54:40,368 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4613530973593394, 'Total loss': 0.4613530973593394} | train loss {'Reaction outcome loss': 0.37413627258922216, 'Total loss': 0.37413627258922216}
2023-01-05 09:54:40,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:54:40,369 INFO:     Epoch: 34
2023-01-05 09:54:42,594 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.47052075862884524, 'Total loss': 0.47052075862884524} | train loss {'Reaction outcome loss': 0.3708332154079465, 'Total loss': 0.3708332154079465}
2023-01-05 09:54:42,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:54:42,594 INFO:     Epoch: 35
2023-01-05 09:54:44,706 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.42523409575223925, 'Total loss': 0.42523409575223925} | train loss {'Reaction outcome loss': 0.36303381234515014, 'Total loss': 0.36303381234515014}
2023-01-05 09:54:44,706 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:54:44,706 INFO:     Epoch: 36
2023-01-05 09:54:46,811 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.42171141505241394, 'Total loss': 0.42171141505241394} | train loss {'Reaction outcome loss': 0.3646941543539939, 'Total loss': 0.3646941543539939}
2023-01-05 09:54:46,811 INFO:     Found new best model at epoch 36
2023-01-05 09:54:46,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:54:46,812 INFO:     Epoch: 37
2023-01-05 09:54:48,920 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.46284273862838743, 'Total loss': 0.46284273862838743} | train loss {'Reaction outcome loss': 0.3561126851217841, 'Total loss': 0.3561126851217841}
2023-01-05 09:54:48,921 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:54:48,921 INFO:     Epoch: 38
2023-01-05 09:54:51,070 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.47804712479313216, 'Total loss': 0.47804712479313216} | train loss {'Reaction outcome loss': 0.35706660686739944, 'Total loss': 0.35706660686739944}
2023-01-05 09:54:51,070 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:54:51,070 INFO:     Epoch: 39
2023-01-05 09:54:53,215 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.45791787703831993, 'Total loss': 0.45791787703831993} | train loss {'Reaction outcome loss': 0.35404292547853417, 'Total loss': 0.35404292547853417}
2023-01-05 09:54:53,215 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:54:53,215 INFO:     Epoch: 40
2023-01-05 09:54:55,360 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.47333473960558575, 'Total loss': 0.47333473960558575} | train loss {'Reaction outcome loss': 0.34958754664132313, 'Total loss': 0.34958754664132313}
2023-01-05 09:54:55,360 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:54:55,360 INFO:     Epoch: 41
2023-01-05 09:54:57,483 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.4408805201450984, 'Total loss': 0.4408805201450984} | train loss {'Reaction outcome loss': 0.3411331014835447, 'Total loss': 0.3411331014835447}
2023-01-05 09:54:57,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:54:57,483 INFO:     Epoch: 42
2023-01-05 09:54:59,610 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.46417609055836995, 'Total loss': 0.46417609055836995} | train loss {'Reaction outcome loss': 0.3413428351794124, 'Total loss': 0.3413428351794124}
2023-01-05 09:54:59,610 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:54:59,610 INFO:     Epoch: 43
2023-01-05 09:55:01,773 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.4801256666580836, 'Total loss': 0.4801256666580836} | train loss {'Reaction outcome loss': 0.3445574888683829, 'Total loss': 0.3445574888683829}
2023-01-05 09:55:01,773 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:55:01,773 INFO:     Epoch: 44
2023-01-05 09:55:03,941 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.42992383340994517, 'Total loss': 0.42992383340994517} | train loss {'Reaction outcome loss': 0.33549928768716136, 'Total loss': 0.33549928768716136}
2023-01-05 09:55:03,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:55:03,942 INFO:     Epoch: 45
2023-01-05 09:55:06,054 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.4423669636249542, 'Total loss': 0.4423669636249542} | train loss {'Reaction outcome loss': 0.3296494540701274, 'Total loss': 0.3296494540701274}
2023-01-05 09:55:06,055 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:55:06,055 INFO:     Epoch: 46
2023-01-05 09:55:08,165 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.41690511008103687, 'Total loss': 0.41690511008103687} | train loss {'Reaction outcome loss': 0.32713846722449635, 'Total loss': 0.32713846722449635}
2023-01-05 09:55:08,165 INFO:     Found new best model at epoch 46
2023-01-05 09:55:08,166 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:55:08,166 INFO:     Epoch: 47
2023-01-05 09:55:10,280 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.4222838352123896, 'Total loss': 0.4222838352123896} | train loss {'Reaction outcome loss': 0.3259185183833652, 'Total loss': 0.3259185183833652}
2023-01-05 09:55:10,280 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:55:10,281 INFO:     Epoch: 48
2023-01-05 09:55:12,491 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.4691630134979884, 'Total loss': 0.4691630134979884} | train loss {'Reaction outcome loss': 0.32383994147558076, 'Total loss': 0.32383994147558076}
2023-01-05 09:55:12,492 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:55:12,492 INFO:     Epoch: 49
2023-01-05 09:55:14,655 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.4253479089587927, 'Total loss': 0.4253479089587927} | train loss {'Reaction outcome loss': 0.3232102529128966, 'Total loss': 0.3232102529128966}
2023-01-05 09:55:14,655 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:55:14,655 INFO:     Epoch: 50
2023-01-05 09:55:16,790 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4252383291721344, 'Total loss': 0.4252383291721344} | train loss {'Reaction outcome loss': 0.3158263646281368, 'Total loss': 0.3158263646281368}
2023-01-05 09:55:16,790 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:55:16,790 INFO:     Epoch: 51
2023-01-05 09:55:18,924 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.4713268518447876, 'Total loss': 0.4713268518447876} | train loss {'Reaction outcome loss': 0.30879658258886544, 'Total loss': 0.30879658258886544}
2023-01-05 09:55:18,924 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:55:18,925 INFO:     Epoch: 52
2023-01-05 09:55:21,066 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.44237193862597146, 'Total loss': 0.44237193862597146} | train loss {'Reaction outcome loss': 0.31070447573270177, 'Total loss': 0.31070447573270177}
2023-01-05 09:55:21,067 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:55:21,067 INFO:     Epoch: 53
2023-01-05 09:55:23,215 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.4075106014808019, 'Total loss': 0.4075106014808019} | train loss {'Reaction outcome loss': 0.3089885534416037, 'Total loss': 0.3089885534416037}
2023-01-05 09:55:23,215 INFO:     Found new best model at epoch 53
2023-01-05 09:55:23,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:55:23,216 INFO:     Epoch: 54
2023-01-05 09:55:25,401 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.48538424968719485, 'Total loss': 0.48538424968719485} | train loss {'Reaction outcome loss': 0.30848015242320104, 'Total loss': 0.30848015242320104}
2023-01-05 09:55:25,402 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:55:25,402 INFO:     Epoch: 55
2023-01-05 09:55:27,599 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.5090318058927854, 'Total loss': 0.5090318058927854} | train loss {'Reaction outcome loss': 0.3030760691094377, 'Total loss': 0.3030760691094377}
2023-01-05 09:55:27,600 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:55:27,600 INFO:     Epoch: 56
2023-01-05 09:55:29,736 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4405480414628983, 'Total loss': 0.4405480414628983} | train loss {'Reaction outcome loss': 0.296956470807752, 'Total loss': 0.296956470807752}
2023-01-05 09:55:29,736 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:55:29,736 INFO:     Epoch: 57
2023-01-05 09:55:31,871 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.4587255984544754, 'Total loss': 0.4587255984544754} | train loss {'Reaction outcome loss': 0.2954340424482788, 'Total loss': 0.2954340424482788}
2023-01-05 09:55:31,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:55:31,871 INFO:     Epoch: 58
2023-01-05 09:55:34,005 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.4657480557759603, 'Total loss': 0.4657480557759603} | train loss {'Reaction outcome loss': 0.29347782933728145, 'Total loss': 0.29347782933728145}
2023-01-05 09:55:34,006 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:55:34,006 INFO:     Epoch: 59
2023-01-05 09:55:36,151 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.45161584417025247, 'Total loss': 0.45161584417025247} | train loss {'Reaction outcome loss': 0.2954300201434091, 'Total loss': 0.2954300201434091}
2023-01-05 09:55:36,152 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:55:36,153 INFO:     Epoch: 60
2023-01-05 09:55:38,298 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.4237598220507304, 'Total loss': 0.4237598220507304} | train loss {'Reaction outcome loss': 0.2903453022752643, 'Total loss': 0.2903453022752643}
2023-01-05 09:55:38,298 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:55:38,298 INFO:     Epoch: 61
2023-01-05 09:55:40,439 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.4096106114486853, 'Total loss': 0.4096106114486853} | train loss {'Reaction outcome loss': 0.2868552055841964, 'Total loss': 0.2868552055841964}
2023-01-05 09:55:40,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:55:40,439 INFO:     Epoch: 62
2023-01-05 09:55:42,580 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4495774428049723, 'Total loss': 0.4495774428049723} | train loss {'Reaction outcome loss': 0.2888597891723152, 'Total loss': 0.2888597891723152}
2023-01-05 09:55:42,581 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:55:42,581 INFO:     Epoch: 63
2023-01-05 09:55:44,727 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.4635044872760773, 'Total loss': 0.4635044872760773} | train loss {'Reaction outcome loss': 0.28118266216361565, 'Total loss': 0.28118266216361565}
2023-01-05 09:55:44,727 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:55:44,727 INFO:     Epoch: 64
2023-01-05 09:55:46,851 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.4320655256509781, 'Total loss': 0.4320655256509781} | train loss {'Reaction outcome loss': 0.28444653843606854, 'Total loss': 0.28444653843606854}
2023-01-05 09:55:46,851 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:55:46,851 INFO:     Epoch: 65
2023-01-05 09:55:48,985 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.44658900797367096, 'Total loss': 0.44658900797367096} | train loss {'Reaction outcome loss': 0.28035873244600606, 'Total loss': 0.28035873244600606}
2023-01-05 09:55:48,986 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:55:48,986 INFO:     Epoch: 66
2023-01-05 09:55:51,139 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.48576967815558114, 'Total loss': 0.48576967815558114} | train loss {'Reaction outcome loss': 0.2798336757084738, 'Total loss': 0.2798336757084738}
2023-01-05 09:55:51,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:55:51,139 INFO:     Epoch: 67
2023-01-05 09:55:53,283 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.457112056016922, 'Total loss': 0.457112056016922} | train loss {'Reaction outcome loss': 0.2734025199275585, 'Total loss': 0.2734025199275585}
2023-01-05 09:55:53,283 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:55:53,283 INFO:     Epoch: 68
2023-01-05 09:55:55,433 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.4388283332188924, 'Total loss': 0.4388283332188924} | train loss {'Reaction outcome loss': 0.27166557656298473, 'Total loss': 0.27166557656298473}
2023-01-05 09:55:55,434 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:55:55,434 INFO:     Epoch: 69
2023-01-05 09:55:57,569 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.4465305258830388, 'Total loss': 0.4465305258830388} | train loss {'Reaction outcome loss': 0.26938910133437344, 'Total loss': 0.26938910133437344}
2023-01-05 09:55:57,569 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:55:57,570 INFO:     Epoch: 70
2023-01-05 09:55:59,695 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4401216934124629, 'Total loss': 0.4401216934124629} | train loss {'Reaction outcome loss': 0.2708650208498597, 'Total loss': 0.2708650208498597}
2023-01-05 09:55:59,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:55:59,696 INFO:     Epoch: 71
2023-01-05 09:56:01,805 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.5138003488381704, 'Total loss': 0.5138003488381704} | train loss {'Reaction outcome loss': 0.2713970992552782, 'Total loss': 0.2713970992552782}
2023-01-05 09:56:01,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:56:01,806 INFO:     Epoch: 72
2023-01-05 09:56:03,928 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.44141387144724525, 'Total loss': 0.44141387144724525} | train loss {'Reaction outcome loss': 0.26590601426115534, 'Total loss': 0.26590601426115534}
2023-01-05 09:56:03,928 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:56:03,928 INFO:     Epoch: 73
2023-01-05 09:56:06,033 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.44263164003690086, 'Total loss': 0.44263164003690086} | train loss {'Reaction outcome loss': 0.2625716551331406, 'Total loss': 0.2625716551331406}
2023-01-05 09:56:06,034 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:56:06,034 INFO:     Epoch: 74
2023-01-05 09:56:08,145 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.4489904910326004, 'Total loss': 0.4489904910326004} | train loss {'Reaction outcome loss': 0.2703737350120226, 'Total loss': 0.2703737350120226}
2023-01-05 09:56:08,145 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:56:08,145 INFO:     Epoch: 75
2023-01-05 09:56:10,257 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.4264325035115083, 'Total loss': 0.4264325035115083} | train loss {'Reaction outcome loss': 0.2589029964288219, 'Total loss': 0.2589029964288219}
2023-01-05 09:56:10,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:56:10,257 INFO:     Epoch: 76
2023-01-05 09:56:12,358 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4491669888297717, 'Total loss': 0.4491669888297717} | train loss {'Reaction outcome loss': 0.26650360289167624, 'Total loss': 0.26650360289167624}
2023-01-05 09:56:12,359 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:56:12,359 INFO:     Epoch: 77
2023-01-05 09:56:14,523 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.4522252211968104, 'Total loss': 0.4522252211968104} | train loss {'Reaction outcome loss': 0.2622557800626281, 'Total loss': 0.2622557800626281}
2023-01-05 09:56:14,523 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:56:14,523 INFO:     Epoch: 78
2023-01-05 09:56:16,678 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.40881930689016976, 'Total loss': 0.40881930689016976} | train loss {'Reaction outcome loss': 0.2581193321838383, 'Total loss': 0.2581193321838383}
2023-01-05 09:56:16,678 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:56:16,678 INFO:     Epoch: 79
2023-01-05 09:56:18,828 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.4250270326932271, 'Total loss': 0.4250270326932271} | train loss {'Reaction outcome loss': 0.25599367965671777, 'Total loss': 0.25599367965671777}
2023-01-05 09:56:18,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:56:18,829 INFO:     Epoch: 80
2023-01-05 09:56:20,955 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4673687020937602, 'Total loss': 0.4673687020937602} | train loss {'Reaction outcome loss': 0.25333768770179377, 'Total loss': 0.25333768770179377}
2023-01-05 09:56:20,955 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:56:20,955 INFO:     Epoch: 81
2023-01-05 09:56:23,119 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.44667903780937196, 'Total loss': 0.44667903780937196} | train loss {'Reaction outcome loss': 0.2464849015677664, 'Total loss': 0.2464849015677664}
2023-01-05 09:56:23,119 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:56:23,119 INFO:     Epoch: 82
2023-01-05 09:56:25,257 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.44510959287484486, 'Total loss': 0.44510959287484486} | train loss {'Reaction outcome loss': 0.25190491725216596, 'Total loss': 0.25190491725216596}
2023-01-05 09:56:25,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:56:25,257 INFO:     Epoch: 83
2023-01-05 09:56:27,414 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.41292261282602943, 'Total loss': 0.41292261282602943} | train loss {'Reaction outcome loss': 0.25537103758822277, 'Total loss': 0.25537103758822277}
2023-01-05 09:56:27,414 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:56:27,414 INFO:     Epoch: 84
2023-01-05 09:56:29,573 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.4267362962166468, 'Total loss': 0.4267362962166468} | train loss {'Reaction outcome loss': 0.24459955402875205, 'Total loss': 0.24459955402875205}
2023-01-05 09:56:29,574 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:56:29,574 INFO:     Epoch: 85
2023-01-05 09:56:31,729 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.4592405299345652, 'Total loss': 0.4592405299345652} | train loss {'Reaction outcome loss': 0.2516324839719474, 'Total loss': 0.2516324839719474}
2023-01-05 09:56:31,730 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:56:31,730 INFO:     Epoch: 86
2023-01-05 09:56:33,852 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.4023031731446584, 'Total loss': 0.4023031731446584} | train loss {'Reaction outcome loss': 0.2543681015189912, 'Total loss': 0.2543681015189912}
2023-01-05 09:56:33,852 INFO:     Found new best model at epoch 86
2023-01-05 09:56:33,854 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:56:33,854 INFO:     Epoch: 87
2023-01-05 09:56:35,980 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.5010183970133464, 'Total loss': 0.5010183970133464} | train loss {'Reaction outcome loss': 0.24415979017957454, 'Total loss': 0.24415979017957454}
2023-01-05 09:56:35,980 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:56:35,980 INFO:     Epoch: 88
2023-01-05 09:56:38,113 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.5082823564608892, 'Total loss': 0.5082823564608892} | train loss {'Reaction outcome loss': 0.24443457773230998, 'Total loss': 0.24443457773230998}
2023-01-05 09:56:38,113 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:56:38,113 INFO:     Epoch: 89
2023-01-05 09:56:40,257 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.4811287472645442, 'Total loss': 0.4811287472645442} | train loss {'Reaction outcome loss': 0.24623985588886785, 'Total loss': 0.24623985588886785}
2023-01-05 09:56:40,257 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:56:40,257 INFO:     Epoch: 90
2023-01-05 09:56:42,412 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.4744805842638016, 'Total loss': 0.4744805842638016} | train loss {'Reaction outcome loss': 0.24502304431710004, 'Total loss': 0.24502304431710004}
2023-01-05 09:56:42,413 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:56:42,413 INFO:     Epoch: 91
2023-01-05 09:56:44,538 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.4369738223652045, 'Total loss': 0.4369738223652045} | train loss {'Reaction outcome loss': 0.24181967097862425, 'Total loss': 0.24181967097862425}
2023-01-05 09:56:44,538 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:56:44,538 INFO:     Epoch: 92
2023-01-05 09:56:46,695 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.4657094339529673, 'Total loss': 0.4657094339529673} | train loss {'Reaction outcome loss': 0.23864717161894813, 'Total loss': 0.23864717161894813}
2023-01-05 09:56:46,695 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:56:46,696 INFO:     Epoch: 93
2023-01-05 09:56:48,821 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.46091244320074715, 'Total loss': 0.46091244320074715} | train loss {'Reaction outcome loss': 0.24263108642738218, 'Total loss': 0.24263108642738218}
2023-01-05 09:56:48,822 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:56:48,822 INFO:     Epoch: 94
2023-01-05 09:56:50,951 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.48647318681081136, 'Total loss': 0.48647318681081136} | train loss {'Reaction outcome loss': 0.2402025170368731, 'Total loss': 0.2402025170368731}
2023-01-05 09:56:50,951 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:56:50,952 INFO:     Epoch: 95
2023-01-05 09:56:53,123 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.48107692301273347, 'Total loss': 0.48107692301273347} | train loss {'Reaction outcome loss': 0.24352463738932292, 'Total loss': 0.24352463738932292}
2023-01-05 09:56:53,123 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:56:53,123 INFO:     Epoch: 96
2023-01-05 09:56:55,237 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.47463745176792144, 'Total loss': 0.47463745176792144} | train loss {'Reaction outcome loss': 0.23855027973161008, 'Total loss': 0.23855027973161008}
2023-01-05 09:56:55,237 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:56:55,237 INFO:     Epoch: 97
2023-01-05 09:56:57,378 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.4906802197297414, 'Total loss': 0.4906802197297414} | train loss {'Reaction outcome loss': 0.23795809549034072, 'Total loss': 0.23795809549034072}
2023-01-05 09:56:57,378 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:56:57,379 INFO:     Epoch: 98
2023-01-05 09:56:59,540 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.48792065382003785, 'Total loss': 0.48792065382003785} | train loss {'Reaction outcome loss': 0.2319349779777686, 'Total loss': 0.2319349779777686}
2023-01-05 09:56:59,540 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:56:59,540 INFO:     Epoch: 99
2023-01-05 09:57:01,690 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.44465150833129885, 'Total loss': 0.44465150833129885} | train loss {'Reaction outcome loss': 0.23957974027290888, 'Total loss': 0.23957974027290888}
2023-01-05 09:57:01,691 INFO:     Best model found after epoch 87 of 100.
2023-01-05 09:57:01,691 INFO:   Done with stage: TRAINING
2023-01-05 09:57:01,691 INFO:   Starting stage: EVALUATION
2023-01-05 09:57:01,817 INFO:   Done with stage: EVALUATION
2023-01-05 09:57:01,817 INFO:   Leaving out SEQ value Fold_8
2023-01-05 09:57:01,830 INFO:   examples: 20,544| examples in train: 17,692 | examples in val: 932| examples in test: 1,920
2023-01-05 09:57:01,830 INFO:   Starting stage: FEATURE SCALING
2023-01-05 09:57:02,484 INFO:   Done with stage: FEATURE SCALING
2023-01-05 09:57:02,484 INFO:   Starting stage: SCALING TARGETS
2023-01-05 09:57:02,552 INFO:   Done with stage: SCALING TARGETS
2023-01-05 09:57:02,552 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:57:02,552 INFO:     No hyperparam tuning for this model
2023-01-05 09:57:02,552 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 09:57:02,552 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 09:57:02,553 INFO:     None feature selector for col prot
2023-01-05 09:57:02,553 INFO:     None feature selector for col prot
2023-01-05 09:57:02,553 INFO:     None feature selector for col prot
2023-01-05 09:57:02,554 INFO:     None feature selector for col chem
2023-01-05 09:57:02,554 INFO:     None feature selector for col chem
2023-01-05 09:57:02,554 INFO:     None feature selector for col chem
2023-01-05 09:57:02,554 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 09:57:02,554 INFO:   Starting stage: BUILD MODEL
2023-01-05 09:57:02,556 INFO:     Number of params in model 72901
2023-01-05 09:57:02,559 INFO:   Done with stage: BUILD MODEL
2023-01-05 09:57:02,559 INFO:   Starting stage: TRAINING
2023-01-05 09:57:02,618 INFO:     Val loss before train {'Reaction outcome loss': 0.9409766972064972, 'Total loss': 0.9409766972064972}
2023-01-05 09:57:02,618 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:57:02,619 INFO:     Epoch: 0
2023-01-05 09:57:04,738 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8270360549290975, 'Total loss': 0.8270360549290975} | train loss {'Reaction outcome loss': 0.9365236981896287, 'Total loss': 0.9365236981896287}
2023-01-05 09:57:04,739 INFO:     Found new best model at epoch 0
2023-01-05 09:57:04,740 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:57:04,740 INFO:     Epoch: 1
2023-01-05 09:57:06,882 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.6130137105782827, 'Total loss': 0.6130137105782827} | train loss {'Reaction outcome loss': 0.7613112555298994, 'Total loss': 0.7613112555298994}
2023-01-05 09:57:06,882 INFO:     Found new best model at epoch 1
2023-01-05 09:57:06,883 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:57:06,883 INFO:     Epoch: 2
2023-01-05 09:57:09,054 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.5176095287005107, 'Total loss': 0.5176095287005107} | train loss {'Reaction outcome loss': 0.6006448225854536, 'Total loss': 0.6006448225854536}
2023-01-05 09:57:09,054 INFO:     Found new best model at epoch 2
2023-01-05 09:57:09,056 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:57:09,056 INFO:     Epoch: 3
2023-01-05 09:57:11,227 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.5235063393910726, 'Total loss': 0.5235063393910726} | train loss {'Reaction outcome loss': 0.5400444478442092, 'Total loss': 0.5400444478442092}
2023-01-05 09:57:11,227 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:57:11,227 INFO:     Epoch: 4
2023-01-05 09:57:13,365 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.5148984134197235, 'Total loss': 0.5148984134197235} | train loss {'Reaction outcome loss': 0.512196401396383, 'Total loss': 0.512196401396383}
2023-01-05 09:57:13,365 INFO:     Found new best model at epoch 4
2023-01-05 09:57:13,366 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:57:13,366 INFO:     Epoch: 5
2023-01-05 09:57:15,483 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.47462382515271506, 'Total loss': 0.47462382515271506} | train loss {'Reaction outcome loss': 0.5046529692432941, 'Total loss': 0.5046529692432941}
2023-01-05 09:57:15,483 INFO:     Found new best model at epoch 5
2023-01-05 09:57:15,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:57:15,485 INFO:     Epoch: 6
2023-01-05 09:57:17,612 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.49058531721433, 'Total loss': 0.49058531721433} | train loss {'Reaction outcome loss': 0.4963019650012577, 'Total loss': 0.4963019650012577}
2023-01-05 09:57:17,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:57:17,612 INFO:     Epoch: 7
2023-01-05 09:57:19,747 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.4895027607679367, 'Total loss': 0.4895027607679367} | train loss {'Reaction outcome loss': 0.4898061445150995, 'Total loss': 0.4898061445150995}
2023-01-05 09:57:19,748 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:57:19,749 INFO:     Epoch: 8
2023-01-05 09:57:21,878 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4763661672671636, 'Total loss': 0.4763661672671636} | train loss {'Reaction outcome loss': 0.47834223250619773, 'Total loss': 0.47834223250619773}
2023-01-05 09:57:21,878 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:57:21,878 INFO:     Epoch: 9
2023-01-05 09:57:24,001 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4626144806543986, 'Total loss': 0.4626144806543986} | train loss {'Reaction outcome loss': 0.47484450257426997, 'Total loss': 0.47484450257426997}
2023-01-05 09:57:24,001 INFO:     Found new best model at epoch 9
2023-01-05 09:57:24,002 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:57:24,002 INFO:     Epoch: 10
2023-01-05 09:57:26,118 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.4532056927680969, 'Total loss': 0.4532056927680969} | train loss {'Reaction outcome loss': 0.4716279852314977, 'Total loss': 0.4716279852314977}
2023-01-05 09:57:26,119 INFO:     Found new best model at epoch 10
2023-01-05 09:57:26,120 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:57:26,120 INFO:     Epoch: 11
2023-01-05 09:57:28,259 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.45144268969694773, 'Total loss': 0.45144268969694773} | train loss {'Reaction outcome loss': 0.46783978623818834, 'Total loss': 0.46783978623818834}
2023-01-05 09:57:28,260 INFO:     Found new best model at epoch 11
2023-01-05 09:57:28,261 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:57:28,261 INFO:     Epoch: 12
2023-01-05 09:57:30,377 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.5064082622528077, 'Total loss': 0.5064082622528077} | train loss {'Reaction outcome loss': 0.4604918970474267, 'Total loss': 0.4604918970474267}
2023-01-05 09:57:30,377 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:57:30,377 INFO:     Epoch: 13
2023-01-05 09:57:32,549 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4659101565678914, 'Total loss': 0.4659101565678914} | train loss {'Reaction outcome loss': 0.45930454850412017, 'Total loss': 0.45930454850412017}
2023-01-05 09:57:32,549 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:57:32,549 INFO:     Epoch: 14
2023-01-05 09:57:34,695 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.4294215033451716, 'Total loss': 0.4294215033451716} | train loss {'Reaction outcome loss': 0.4555088804516982, 'Total loss': 0.4555088804516982}
2023-01-05 09:57:34,695 INFO:     Found new best model at epoch 14
2023-01-05 09:57:34,696 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:57:34,696 INFO:     Epoch: 15
2023-01-05 09:57:36,811 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.4517025887966156, 'Total loss': 0.4517025887966156} | train loss {'Reaction outcome loss': 0.44495326662536994, 'Total loss': 0.44495326662536994}
2023-01-05 09:57:36,812 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:57:36,812 INFO:     Epoch: 16
2023-01-05 09:57:38,975 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.5118020753065745, 'Total loss': 0.5118020753065745} | train loss {'Reaction outcome loss': 0.45055789831312987, 'Total loss': 0.45055789831312987}
2023-01-05 09:57:38,975 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:57:38,976 INFO:     Epoch: 17
2023-01-05 09:57:41,125 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.43024809956550597, 'Total loss': 0.43024809956550597} | train loss {'Reaction outcome loss': 0.43873480672440374, 'Total loss': 0.43873480672440374}
2023-01-05 09:57:41,125 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:57:41,125 INFO:     Epoch: 18
2023-01-05 09:57:43,253 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.4397950490315755, 'Total loss': 0.4397950490315755} | train loss {'Reaction outcome loss': 0.44319425184373823, 'Total loss': 0.44319425184373823}
2023-01-05 09:57:43,253 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:57:43,253 INFO:     Epoch: 19
2023-01-05 09:57:45,369 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.4474771519502004, 'Total loss': 0.4474771519502004} | train loss {'Reaction outcome loss': 0.438878412227338, 'Total loss': 0.438878412227338}
2023-01-05 09:57:45,369 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:57:45,369 INFO:     Epoch: 20
2023-01-05 09:57:47,485 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.43542782167593636, 'Total loss': 0.43542782167593636} | train loss {'Reaction outcome loss': 0.43234387583465783, 'Total loss': 0.43234387583465783}
2023-01-05 09:57:47,485 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:57:47,485 INFO:     Epoch: 21
2023-01-05 09:57:49,611 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.45227312445640566, 'Total loss': 0.45227312445640566} | train loss {'Reaction outcome loss': 0.42574659689238786, 'Total loss': 0.42574659689238786}
2023-01-05 09:57:49,612 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:57:49,612 INFO:     Epoch: 22
2023-01-05 09:57:51,763 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.42693197230498, 'Total loss': 0.42693197230498} | train loss {'Reaction outcome loss': 0.42855193630022265, 'Total loss': 0.42855193630022265}
2023-01-05 09:57:51,763 INFO:     Found new best model at epoch 22
2023-01-05 09:57:51,764 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:57:51,764 INFO:     Epoch: 23
2023-01-05 09:57:53,860 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.439008828997612, 'Total loss': 0.439008828997612} | train loss {'Reaction outcome loss': 0.4231555797025185, 'Total loss': 0.4231555797025185}
2023-01-05 09:57:53,862 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:57:53,862 INFO:     Epoch: 24
2023-01-05 09:57:56,015 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.4203628977139791, 'Total loss': 0.4203628977139791} | train loss {'Reaction outcome loss': 0.418476002848966, 'Total loss': 0.418476002848966}
2023-01-05 09:57:56,015 INFO:     Found new best model at epoch 24
2023-01-05 09:57:56,017 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:57:56,017 INFO:     Epoch: 25
2023-01-05 09:57:58,164 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.42365213433901466, 'Total loss': 0.42365213433901466} | train loss {'Reaction outcome loss': 0.41822687625239474, 'Total loss': 0.41822687625239474}
2023-01-05 09:57:58,165 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:57:58,165 INFO:     Epoch: 26
2023-01-05 09:58:00,275 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.4278348207473755, 'Total loss': 0.4278348207473755} | train loss {'Reaction outcome loss': 0.4118271134390297, 'Total loss': 0.4118271134390297}
2023-01-05 09:58:00,276 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:58:00,276 INFO:     Epoch: 27
2023-01-05 09:58:02,438 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.4105618052184582, 'Total loss': 0.4105618052184582} | train loss {'Reaction outcome loss': 0.40779810334263294, 'Total loss': 0.40779810334263294}
2023-01-05 09:58:02,438 INFO:     Found new best model at epoch 27
2023-01-05 09:58:02,439 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:58:02,439 INFO:     Epoch: 28
2023-01-05 09:58:04,582 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.4249655534823736, 'Total loss': 0.4249655534823736} | train loss {'Reaction outcome loss': 0.4099989988528434, 'Total loss': 0.4099989988528434}
2023-01-05 09:58:04,582 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:58:04,582 INFO:     Epoch: 29
2023-01-05 09:58:06,728 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.4056369910637538, 'Total loss': 0.4056369910637538} | train loss {'Reaction outcome loss': 0.4024257164730922, 'Total loss': 0.4024257164730922}
2023-01-05 09:58:06,728 INFO:     Found new best model at epoch 29
2023-01-05 09:58:06,729 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:58:06,729 INFO:     Epoch: 30
2023-01-05 09:58:08,685 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.43514201839764916, 'Total loss': 0.43514201839764916} | train loss {'Reaction outcome loss': 0.3997563061838976, 'Total loss': 0.3997563061838976}
2023-01-05 09:58:08,685 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:58:08,686 INFO:     Epoch: 31
2023-01-05 09:58:10,834 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.40775979856650035, 'Total loss': 0.40775979856650035} | train loss {'Reaction outcome loss': 0.3985152217401494, 'Total loss': 0.3985152217401494}
2023-01-05 09:58:10,834 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:58:10,834 INFO:     Epoch: 32
2023-01-05 09:58:12,974 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.4015094329913457, 'Total loss': 0.4015094329913457} | train loss {'Reaction outcome loss': 0.3913760278575687, 'Total loss': 0.3913760278575687}
2023-01-05 09:58:12,975 INFO:     Found new best model at epoch 32
2023-01-05 09:58:12,976 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:58:12,976 INFO:     Epoch: 33
2023-01-05 09:58:15,139 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.4304454743862152, 'Total loss': 0.4304454743862152} | train loss {'Reaction outcome loss': 0.3870312057516205, 'Total loss': 0.3870312057516205}
2023-01-05 09:58:15,139 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:58:15,139 INFO:     Epoch: 34
2023-01-05 09:58:17,274 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.42682275573412576, 'Total loss': 0.42682275573412576} | train loss {'Reaction outcome loss': 0.38303741535662744, 'Total loss': 0.38303741535662744}
2023-01-05 09:58:17,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:58:17,275 INFO:     Epoch: 35
2023-01-05 09:58:19,435 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.429056058327357, 'Total loss': 0.429056058327357} | train loss {'Reaction outcome loss': 0.3842021810018629, 'Total loss': 0.3842021810018629}
2023-01-05 09:58:19,435 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:58:19,435 INFO:     Epoch: 36
2023-01-05 09:58:21,584 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.4099149117867152, 'Total loss': 0.4099149117867152} | train loss {'Reaction outcome loss': 0.37939784541349547, 'Total loss': 0.37939784541349547}
2023-01-05 09:58:21,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:58:21,584 INFO:     Epoch: 37
2023-01-05 09:58:23,741 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.4179720322291056, 'Total loss': 0.4179720322291056} | train loss {'Reaction outcome loss': 0.37643435444104545, 'Total loss': 0.37643435444104545}
2023-01-05 09:58:23,741 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:58:23,742 INFO:     Epoch: 38
2023-01-05 09:58:25,884 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.40305395424366, 'Total loss': 0.40305395424366} | train loss {'Reaction outcome loss': 0.36755791279598266, 'Total loss': 0.36755791279598266}
2023-01-05 09:58:25,884 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:58:25,884 INFO:     Epoch: 39
2023-01-05 09:58:27,982 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.40961796243985493, 'Total loss': 0.40961796243985493} | train loss {'Reaction outcome loss': 0.36486627753245704, 'Total loss': 0.36486627753245704}
2023-01-05 09:58:27,982 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:58:27,982 INFO:     Epoch: 40
2023-01-05 09:58:30,129 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.42158631881078085, 'Total loss': 0.42158631881078085} | train loss {'Reaction outcome loss': 0.3666848855005705, 'Total loss': 0.3666848855005705}
2023-01-05 09:58:30,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:58:30,131 INFO:     Epoch: 41
2023-01-05 09:58:32,263 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.38353771617015203, 'Total loss': 0.38353771617015203} | train loss {'Reaction outcome loss': 0.362382225880554, 'Total loss': 0.362382225880554}
2023-01-05 09:58:32,263 INFO:     Found new best model at epoch 41
2023-01-05 09:58:32,264 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:58:32,265 INFO:     Epoch: 42
2023-01-05 09:58:34,412 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.4273612260818481, 'Total loss': 0.4273612260818481} | train loss {'Reaction outcome loss': 0.3580964704444262, 'Total loss': 0.3580964704444262}
2023-01-05 09:58:34,412 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:58:34,412 INFO:     Epoch: 43
2023-01-05 09:58:36,545 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.41118556062380474, 'Total loss': 0.41118556062380474} | train loss {'Reaction outcome loss': 0.35477789636661, 'Total loss': 0.35477789636661}
2023-01-05 09:58:36,546 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:58:36,546 INFO:     Epoch: 44
2023-01-05 09:58:38,661 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.3905075261990229, 'Total loss': 0.3905075261990229} | train loss {'Reaction outcome loss': 0.352158155588144, 'Total loss': 0.352158155588144}
2023-01-05 09:58:38,661 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:58:38,661 INFO:     Epoch: 45
2023-01-05 09:58:40,779 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3764294455448786, 'Total loss': 0.3764294455448786} | train loss {'Reaction outcome loss': 0.3561059072317845, 'Total loss': 0.3561059072317845}
2023-01-05 09:58:40,779 INFO:     Found new best model at epoch 45
2023-01-05 09:58:40,781 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:58:40,781 INFO:     Epoch: 46
2023-01-05 09:58:42,922 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3985837697982788, 'Total loss': 0.3985837697982788} | train loss {'Reaction outcome loss': 0.34571345063054176, 'Total loss': 0.34571345063054176}
2023-01-05 09:58:42,922 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:58:42,923 INFO:     Epoch: 47
2023-01-05 09:58:45,077 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.402530230085055, 'Total loss': 0.402530230085055} | train loss {'Reaction outcome loss': 0.34587678757062457, 'Total loss': 0.34587678757062457}
2023-01-05 09:58:45,078 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:58:45,078 INFO:     Epoch: 48
2023-01-05 09:58:47,211 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.411345315972964, 'Total loss': 0.411345315972964} | train loss {'Reaction outcome loss': 0.3412392933042686, 'Total loss': 0.3412392933042686}
2023-01-05 09:58:47,211 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:58:47,212 INFO:     Epoch: 49
2023-01-05 09:58:49,370 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.38877881268660225, 'Total loss': 0.38877881268660225} | train loss {'Reaction outcome loss': 0.34586375265883196, 'Total loss': 0.34586375265883196}
2023-01-05 09:58:49,371 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:58:49,371 INFO:     Epoch: 50
2023-01-05 09:58:51,526 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.4111921737591426, 'Total loss': 0.4111921737591426} | train loss {'Reaction outcome loss': 0.3362137852539224, 'Total loss': 0.3362137852539224}
2023-01-05 09:58:51,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:58:51,526 INFO:     Epoch: 51
2023-01-05 09:58:53,697 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.3769815524419149, 'Total loss': 0.3769815524419149} | train loss {'Reaction outcome loss': 0.33791753993998364, 'Total loss': 0.33791753993998364}
2023-01-05 09:58:53,697 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:58:53,697 INFO:     Epoch: 52
2023-01-05 09:58:55,850 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.41280424197514853, 'Total loss': 0.41280424197514853} | train loss {'Reaction outcome loss': 0.32946950315568424, 'Total loss': 0.32946950315568424}
2023-01-05 09:58:55,850 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:58:55,851 INFO:     Epoch: 53
2023-01-05 09:58:57,993 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.372311007976532, 'Total loss': 0.372311007976532} | train loss {'Reaction outcome loss': 0.32427240173846805, 'Total loss': 0.32427240173846805}
2023-01-05 09:58:57,993 INFO:     Found new best model at epoch 53
2023-01-05 09:58:57,994 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:58:57,994 INFO:     Epoch: 54
2023-01-05 09:59:00,142 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.40446481903394066, 'Total loss': 0.40446481903394066} | train loss {'Reaction outcome loss': 0.32888864930248435, 'Total loss': 0.32888864930248435}
2023-01-05 09:59:00,142 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:59:00,143 INFO:     Epoch: 55
2023-01-05 09:59:02,266 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.37696869174639386, 'Total loss': 0.37696869174639386} | train loss {'Reaction outcome loss': 0.32571199240452114, 'Total loss': 0.32571199240452114}
2023-01-05 09:59:02,266 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:59:02,266 INFO:     Epoch: 56
2023-01-05 09:59:04,393 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.4080093850692113, 'Total loss': 0.4080093850692113} | train loss {'Reaction outcome loss': 0.31839877964142, 'Total loss': 0.31839877964142}
2023-01-05 09:59:04,393 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:59:04,393 INFO:     Epoch: 57
2023-01-05 09:59:06,532 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.38911632895469667, 'Total loss': 0.38911632895469667} | train loss {'Reaction outcome loss': 0.31187656535245883, 'Total loss': 0.31187656535245883}
2023-01-05 09:59:06,533 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:59:06,533 INFO:     Epoch: 58
2023-01-05 09:59:08,682 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.38568772077560426, 'Total loss': 0.38568772077560426} | train loss {'Reaction outcome loss': 0.3122618174187113, 'Total loss': 0.3122618174187113}
2023-01-05 09:59:08,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:59:08,682 INFO:     Epoch: 59
2023-01-05 09:59:10,829 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3914017488559087, 'Total loss': 0.3914017488559087} | train loss {'Reaction outcome loss': 0.316369791256284, 'Total loss': 0.316369791256284}
2023-01-05 09:59:10,829 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:59:10,829 INFO:     Epoch: 60
2023-01-05 09:59:12,978 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.40505268772443137, 'Total loss': 0.40505268772443137} | train loss {'Reaction outcome loss': 0.3094800380646967, 'Total loss': 0.3094800380646967}
2023-01-05 09:59:12,978 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:59:12,978 INFO:     Epoch: 61
2023-01-05 09:59:15,101 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.38321726222832997, 'Total loss': 0.38321726222832997} | train loss {'Reaction outcome loss': 0.3190718716824098, 'Total loss': 0.3190718716824098}
2023-01-05 09:59:15,101 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:59:15,101 INFO:     Epoch: 62
2023-01-05 09:59:17,238 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.4125644365946452, 'Total loss': 0.4125644365946452} | train loss {'Reaction outcome loss': 0.30780939673097124, 'Total loss': 0.30780939673097124}
2023-01-05 09:59:17,238 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:59:17,238 INFO:     Epoch: 63
2023-01-05 09:59:19,380 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.3994586169719696, 'Total loss': 0.3994586169719696} | train loss {'Reaction outcome loss': 0.31249296413700933, 'Total loss': 0.31249296413700933}
2023-01-05 09:59:19,381 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:59:19,381 INFO:     Epoch: 64
2023-01-05 09:59:21,525 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.36595267554124195, 'Total loss': 0.36595267554124195} | train loss {'Reaction outcome loss': 0.30443356909691643, 'Total loss': 0.30443356909691643}
2023-01-05 09:59:21,525 INFO:     Found new best model at epoch 64
2023-01-05 09:59:21,526 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:59:21,526 INFO:     Epoch: 65
2023-01-05 09:59:23,669 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.36592718462149304, 'Total loss': 0.36592718462149304} | train loss {'Reaction outcome loss': 0.30485711034239416, 'Total loss': 0.30485711034239416}
2023-01-05 09:59:23,670 INFO:     Found new best model at epoch 65
2023-01-05 09:59:23,671 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:59:23,671 INFO:     Epoch: 66
2023-01-05 09:59:25,800 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.4065132558345795, 'Total loss': 0.4065132558345795} | train loss {'Reaction outcome loss': 0.30470682817783595, 'Total loss': 0.30470682817783595}
2023-01-05 09:59:25,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:59:25,801 INFO:     Epoch: 67
2023-01-05 09:59:27,938 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.38051012754440305, 'Total loss': 0.38051012754440305} | train loss {'Reaction outcome loss': 0.30071737322727693, 'Total loss': 0.30071737322727693}
2023-01-05 09:59:27,938 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:59:27,938 INFO:     Epoch: 68
2023-01-05 09:59:30,097 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.3967384378115336, 'Total loss': 0.3967384378115336} | train loss {'Reaction outcome loss': 0.30273532890294436, 'Total loss': 0.30273532890294436}
2023-01-05 09:59:30,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:59:30,097 INFO:     Epoch: 69
2023-01-05 09:59:32,268 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.3888523757457733, 'Total loss': 0.3888523757457733} | train loss {'Reaction outcome loss': 0.2960023141536687, 'Total loss': 0.2960023141536687}
2023-01-05 09:59:32,268 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:59:32,268 INFO:     Epoch: 70
2023-01-05 09:59:34,416 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.4187500347693761, 'Total loss': 0.4187500347693761} | train loss {'Reaction outcome loss': 0.29660067883478175, 'Total loss': 0.29660067883478175}
2023-01-05 09:59:34,416 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:59:34,416 INFO:     Epoch: 71
2023-01-05 09:59:36,571 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.39088062246640526, 'Total loss': 0.39088062246640526} | train loss {'Reaction outcome loss': 0.2941403792572581, 'Total loss': 0.2941403792572581}
2023-01-05 09:59:36,573 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:59:36,573 INFO:     Epoch: 72
2023-01-05 09:59:38,689 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3766171634197235, 'Total loss': 0.3766171634197235} | train loss {'Reaction outcome loss': 0.2885318223373554, 'Total loss': 0.2885318223373554}
2023-01-05 09:59:38,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:59:38,689 INFO:     Epoch: 73
2023-01-05 09:59:40,825 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.38884848952293394, 'Total loss': 0.38884848952293394} | train loss {'Reaction outcome loss': 0.2964723082763624, 'Total loss': 0.2964723082763624}
2023-01-05 09:59:40,825 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:59:40,826 INFO:     Epoch: 74
2023-01-05 09:59:42,976 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.392738893131415, 'Total loss': 0.392738893131415} | train loss {'Reaction outcome loss': 0.28456228460430666, 'Total loss': 0.28456228460430666}
2023-01-05 09:59:42,977 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:59:42,977 INFO:     Epoch: 75
2023-01-05 09:59:45,114 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.35004443873961766, 'Total loss': 0.35004443873961766} | train loss {'Reaction outcome loss': 0.28823373887674475, 'Total loss': 0.28823373887674475}
2023-01-05 09:59:45,114 INFO:     Found new best model at epoch 75
2023-01-05 09:59:45,115 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:59:45,115 INFO:     Epoch: 76
2023-01-05 09:59:47,277 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.4087003658215205, 'Total loss': 0.4087003658215205} | train loss {'Reaction outcome loss': 0.288701647119294, 'Total loss': 0.288701647119294}
2023-01-05 09:59:47,277 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:59:47,277 INFO:     Epoch: 77
2023-01-05 09:59:49,427 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.3779685805241267, 'Total loss': 0.3779685805241267} | train loss {'Reaction outcome loss': 0.2866830551687507, 'Total loss': 0.2866830551687507}
2023-01-05 09:59:49,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:59:49,427 INFO:     Epoch: 78
2023-01-05 09:59:51,597 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3789505138993263, 'Total loss': 0.3789505138993263} | train loss {'Reaction outcome loss': 0.2837935442555467, 'Total loss': 0.2837935442555467}
2023-01-05 09:59:51,597 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:59:51,597 INFO:     Epoch: 79
2023-01-05 09:59:53,761 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.3482517977555593, 'Total loss': 0.3482517977555593} | train loss {'Reaction outcome loss': 0.28584687688828375, 'Total loss': 0.28584687688828375}
2023-01-05 09:59:53,761 INFO:     Found new best model at epoch 79
2023-01-05 09:59:53,763 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:59:53,763 INFO:     Epoch: 80
2023-01-05 09:59:55,910 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.4118816783030828, 'Total loss': 0.4118816783030828} | train loss {'Reaction outcome loss': 0.27853281323929124, 'Total loss': 0.27853281323929124}
2023-01-05 09:59:55,911 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:59:55,911 INFO:     Epoch: 81
2023-01-05 09:59:58,042 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.3891668736934662, 'Total loss': 0.3891668736934662} | train loss {'Reaction outcome loss': 0.2909077324699409, 'Total loss': 0.2909077324699409}
2023-01-05 09:59:58,042 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 09:59:58,042 INFO:     Epoch: 82
2023-01-05 10:00:00,182 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.3824459065993627, 'Total loss': 0.3824459065993627} | train loss {'Reaction outcome loss': 0.2812193849053409, 'Total loss': 0.2812193849053409}
2023-01-05 10:00:00,182 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:00:00,182 INFO:     Epoch: 83
2023-01-05 10:00:02,326 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.37959905763467156, 'Total loss': 0.37959905763467156} | train loss {'Reaction outcome loss': 0.2727294051246415, 'Total loss': 0.2727294051246415}
2023-01-05 10:00:02,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:00:02,327 INFO:     Epoch: 84
2023-01-05 10:00:04,476 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.3667094945907593, 'Total loss': 0.3667094945907593} | train loss {'Reaction outcome loss': 0.2772833548136567, 'Total loss': 0.2772833548136567}
2023-01-05 10:00:04,477 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:00:04,477 INFO:     Epoch: 85
2023-01-05 10:00:06,621 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.3620430005093416, 'Total loss': 0.3620430005093416} | train loss {'Reaction outcome loss': 0.27316818713119745, 'Total loss': 0.27316818713119745}
2023-01-05 10:00:06,621 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:00:06,622 INFO:     Epoch: 86
2023-01-05 10:00:08,772 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.38547004759311676, 'Total loss': 0.38547004759311676} | train loss {'Reaction outcome loss': 0.27222193000226247, 'Total loss': 0.27222193000226247}
2023-01-05 10:00:08,772 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:00:08,772 INFO:     Epoch: 87
2023-01-05 10:00:10,926 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.35192855894565583, 'Total loss': 0.35192855894565583} | train loss {'Reaction outcome loss': 0.2695831562718545, 'Total loss': 0.2695831562718545}
2023-01-05 10:00:10,926 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:00:10,926 INFO:     Epoch: 88
2023-01-05 10:00:13,044 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.3591817999879519, 'Total loss': 0.3591817999879519} | train loss {'Reaction outcome loss': 0.27098864505222126, 'Total loss': 0.27098864505222126}
2023-01-05 10:00:13,045 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:00:13,045 INFO:     Epoch: 89
2023-01-05 10:00:15,197 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.3513588587443034, 'Total loss': 0.3513588587443034} | train loss {'Reaction outcome loss': 0.26841119336576236, 'Total loss': 0.26841119336576236}
2023-01-05 10:00:15,198 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:00:15,198 INFO:     Epoch: 90
2023-01-05 10:00:17,335 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.37030819853146874, 'Total loss': 0.37030819853146874} | train loss {'Reaction outcome loss': 0.27056725664797243, 'Total loss': 0.27056725664797243}
2023-01-05 10:00:17,335 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:00:17,335 INFO:     Epoch: 91
2023-01-05 10:00:19,490 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3876504093408585, 'Total loss': 0.3876504093408585} | train loss {'Reaction outcome loss': 0.26618228500392893, 'Total loss': 0.26618228500392893}
2023-01-05 10:00:19,491 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:00:19,491 INFO:     Epoch: 92
2023-01-05 10:00:21,657 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.37124851942062376, 'Total loss': 0.37124851942062376} | train loss {'Reaction outcome loss': 0.2620874782721596, 'Total loss': 0.2620874782721596}
2023-01-05 10:00:21,657 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:00:21,657 INFO:     Epoch: 93
2023-01-05 10:00:23,787 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.34686606427033745, 'Total loss': 0.34686606427033745} | train loss {'Reaction outcome loss': 0.26468629777996333, 'Total loss': 0.26468629777996333}
2023-01-05 10:00:23,787 INFO:     Found new best model at epoch 93
2023-01-05 10:00:23,788 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:00:23,788 INFO:     Epoch: 94
2023-01-05 10:00:25,936 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.37982603510220847, 'Total loss': 0.37982603510220847} | train loss {'Reaction outcome loss': 0.2731706587604452, 'Total loss': 0.2731706587604452}
2023-01-05 10:00:25,936 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:00:25,936 INFO:     Epoch: 95
2023-01-05 10:00:28,108 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.35735842287540437, 'Total loss': 0.35735842287540437} | train loss {'Reaction outcome loss': 0.2666805702991219, 'Total loss': 0.2666805702991219}
2023-01-05 10:00:28,108 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:00:28,109 INFO:     Epoch: 96
2023-01-05 10:00:30,325 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.3397618469161292, 'Total loss': 0.3397618469161292} | train loss {'Reaction outcome loss': 0.26758642602268107, 'Total loss': 0.26758642602268107}
2023-01-05 10:00:30,326 INFO:     Found new best model at epoch 96
2023-01-05 10:00:30,327 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:00:30,327 INFO:     Epoch: 97
2023-01-05 10:00:32,561 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.3416323309143384, 'Total loss': 0.3416323309143384} | train loss {'Reaction outcome loss': 0.2566280316843883, 'Total loss': 0.2566280316843883}
2023-01-05 10:00:32,562 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:00:32,562 INFO:     Epoch: 98
2023-01-05 10:00:34,805 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.3590657492478689, 'Total loss': 0.3590657492478689} | train loss {'Reaction outcome loss': 0.2602548910580602, 'Total loss': 0.2602548910580602}
2023-01-05 10:00:34,805 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:00:34,805 INFO:     Epoch: 99
2023-01-05 10:00:37,033 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.3932042598724365, 'Total loss': 0.3932042598724365} | train loss {'Reaction outcome loss': 0.2662572628794917, 'Total loss': 0.2662572628794917}
2023-01-05 10:00:37,033 INFO:     Best model found after epoch 97 of 100.
2023-01-05 10:00:37,033 INFO:   Done with stage: TRAINING
2023-01-05 10:00:37,033 INFO:   Starting stage: EVALUATION
2023-01-05 10:00:37,177 INFO:   Done with stage: EVALUATION
2023-01-05 10:00:37,177 INFO:   Leaving out SEQ value Fold_9
2023-01-05 10:00:37,191 INFO:   examples: 20,544| examples in train: 17,601 | examples in val: 927| examples in test: 2,016
2023-01-05 10:00:37,191 INFO:   Starting stage: FEATURE SCALING
2023-01-05 10:00:37,863 INFO:   Done with stage: FEATURE SCALING
2023-01-05 10:00:37,863 INFO:   Starting stage: SCALING TARGETS
2023-01-05 10:00:37,931 INFO:   Done with stage: SCALING TARGETS
2023-01-05 10:00:37,931 INFO:   Starting stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:00:37,931 INFO:     No hyperparam tuning for this model
2023-01-05 10:00:37,931 INFO:   Done with stage: HYPERPARAM OPTIMIZATION
2023-01-05 10:00:37,931 INFO:   Starting stage: FEATURE SELECTION
2023-01-05 10:00:37,932 INFO:     None feature selector for col prot
2023-01-05 10:00:37,932 INFO:     None feature selector for col prot
2023-01-05 10:00:37,932 INFO:     None feature selector for col prot
2023-01-05 10:00:37,933 INFO:     None feature selector for col chem
2023-01-05 10:00:37,933 INFO:     None feature selector for col chem
2023-01-05 10:00:37,933 INFO:     None feature selector for col chem
2023-01-05 10:00:37,933 INFO:   Done with stage: FEATURE SELECTION
2023-01-05 10:00:37,933 INFO:   Starting stage: BUILD MODEL
2023-01-05 10:00:37,934 INFO:     Number of params in model 72901
2023-01-05 10:00:37,937 INFO:   Done with stage: BUILD MODEL
2023-01-05 10:00:37,938 INFO:   Starting stage: TRAINING
2023-01-05 10:00:37,996 INFO:     Val loss before train {'Reaction outcome loss': 0.9751239120960236, 'Total loss': 0.9751239120960236}
2023-01-05 10:00:37,996 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:00:37,996 INFO:     Epoch: 0
2023-01-05 10:00:40,098 INFO:     After epoch 0, val loss {'Reaction outcome loss': 0.8069100340207418, 'Total loss': 0.8069100340207418} | train loss {'Reaction outcome loss': 0.9346809536623566, 'Total loss': 0.9346809536623566}
2023-01-05 10:00:40,098 INFO:     Found new best model at epoch 0
2023-01-05 10:00:40,099 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:00:40,099 INFO:     Epoch: 1
2023-01-05 10:00:42,234 INFO:     After epoch 1, val loss {'Reaction outcome loss': 0.619819720586141, 'Total loss': 0.619819720586141} | train loss {'Reaction outcome loss': 0.794142264170923, 'Total loss': 0.794142264170923}
2023-01-05 10:00:42,234 INFO:     Found new best model at epoch 1
2023-01-05 10:00:42,235 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:00:42,235 INFO:     Epoch: 2
2023-01-05 10:00:44,335 INFO:     After epoch 2, val loss {'Reaction outcome loss': 0.49666197299957277, 'Total loss': 0.49666197299957277} | train loss {'Reaction outcome loss': 0.6470132203151783, 'Total loss': 0.6470132203151783}
2023-01-05 10:00:44,336 INFO:     Found new best model at epoch 2
2023-01-05 10:00:44,337 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:00:44,337 INFO:     Epoch: 3
2023-01-05 10:00:46,477 INFO:     After epoch 3, val loss {'Reaction outcome loss': 0.43284326444069543, 'Total loss': 0.43284326444069543} | train loss {'Reaction outcome loss': 0.5588432574708797, 'Total loss': 0.5588432574708797}
2023-01-05 10:00:46,477 INFO:     Found new best model at epoch 3
2023-01-05 10:00:46,478 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:00:46,478 INFO:     Epoch: 4
2023-01-05 10:00:48,594 INFO:     After epoch 4, val loss {'Reaction outcome loss': 0.44779753784338633, 'Total loss': 0.44779753784338633} | train loss {'Reaction outcome loss': 0.5296852587704527, 'Total loss': 0.5296852587704527}
2023-01-05 10:00:48,594 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:00:48,594 INFO:     Epoch: 5
2023-01-05 10:00:50,698 INFO:     After epoch 5, val loss {'Reaction outcome loss': 0.43551331559816997, 'Total loss': 0.43551331559816997} | train loss {'Reaction outcome loss': 0.5159785088961117, 'Total loss': 0.5159785088961117}
2023-01-05 10:00:50,699 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:00:50,699 INFO:     Epoch: 6
2023-01-05 10:00:52,801 INFO:     After epoch 6, val loss {'Reaction outcome loss': 0.4401564339796702, 'Total loss': 0.4401564339796702} | train loss {'Reaction outcome loss': 0.5043491844249808, 'Total loss': 0.5043491844249808}
2023-01-05 10:00:52,801 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:00:52,801 INFO:     Epoch: 7
2023-01-05 10:00:54,911 INFO:     After epoch 7, val loss {'Reaction outcome loss': 0.41260764996210736, 'Total loss': 0.41260764996210736} | train loss {'Reaction outcome loss': 0.5202983922284582, 'Total loss': 0.5202983922284582}
2023-01-05 10:00:54,912 INFO:     Found new best model at epoch 7
2023-01-05 10:00:54,913 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:00:54,913 INFO:     Epoch: 8
2023-01-05 10:00:57,038 INFO:     After epoch 8, val loss {'Reaction outcome loss': 0.4234153817097346, 'Total loss': 0.4234153817097346} | train loss {'Reaction outcome loss': 0.49406488960527856, 'Total loss': 0.49406488960527856}
2023-01-05 10:00:57,038 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:00:57,039 INFO:     Epoch: 9
2023-01-05 10:00:59,154 INFO:     After epoch 9, val loss {'Reaction outcome loss': 0.4081093490123749, 'Total loss': 0.4081093490123749} | train loss {'Reaction outcome loss': 0.4803876899410966, 'Total loss': 0.4803876899410966}
2023-01-05 10:00:59,154 INFO:     Found new best model at epoch 9
2023-01-05 10:00:59,155 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:00:59,156 INFO:     Epoch: 10
2023-01-05 10:01:01,275 INFO:     After epoch 10, val loss {'Reaction outcome loss': 0.41619953513145447, 'Total loss': 0.41619953513145447} | train loss {'Reaction outcome loss': 0.4756278331944908, 'Total loss': 0.4756278331944908}
2023-01-05 10:01:01,275 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:01:01,275 INFO:     Epoch: 11
2023-01-05 10:01:03,417 INFO:     After epoch 11, val loss {'Reaction outcome loss': 0.41117302725712457, 'Total loss': 0.41117302725712457} | train loss {'Reaction outcome loss': 0.46783971178946016, 'Total loss': 0.46783971178946016}
2023-01-05 10:01:03,418 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:01:03,418 INFO:     Epoch: 12
2023-01-05 10:01:05,546 INFO:     After epoch 12, val loss {'Reaction outcome loss': 0.39091072579224906, 'Total loss': 0.39091072579224906} | train loss {'Reaction outcome loss': 0.46643087173773284, 'Total loss': 0.46643087173773284}
2023-01-05 10:01:05,546 INFO:     Found new best model at epoch 12
2023-01-05 10:01:05,547 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:01:05,548 INFO:     Epoch: 13
2023-01-05 10:01:07,689 INFO:     After epoch 13, val loss {'Reaction outcome loss': 0.4081157883008321, 'Total loss': 0.4081157883008321} | train loss {'Reaction outcome loss': 0.4621348598351081, 'Total loss': 0.4621348598351081}
2023-01-05 10:01:07,689 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:01:07,689 INFO:     Epoch: 14
2023-01-05 10:01:09,813 INFO:     After epoch 14, val loss {'Reaction outcome loss': 0.388089719414711, 'Total loss': 0.388089719414711} | train loss {'Reaction outcome loss': 0.461129078614539, 'Total loss': 0.461129078614539}
2023-01-05 10:01:09,813 INFO:     Found new best model at epoch 14
2023-01-05 10:01:09,815 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:01:09,815 INFO:     Epoch: 15
2023-01-05 10:01:11,961 INFO:     After epoch 15, val loss {'Reaction outcome loss': 0.378598228096962, 'Total loss': 0.378598228096962} | train loss {'Reaction outcome loss': 0.4963111725266334, 'Total loss': 0.4963111725266334}
2023-01-05 10:01:11,961 INFO:     Found new best model at epoch 15
2023-01-05 10:01:11,962 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:01:11,962 INFO:     Epoch: 16
2023-01-05 10:01:14,087 INFO:     After epoch 16, val loss {'Reaction outcome loss': 0.3657653361558914, 'Total loss': 0.3657653361558914} | train loss {'Reaction outcome loss': 0.4454174664519403, 'Total loss': 0.4454174664519403}
2023-01-05 10:01:14,088 INFO:     Found new best model at epoch 16
2023-01-05 10:01:14,089 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:01:14,089 INFO:     Epoch: 17
2023-01-05 10:01:16,229 INFO:     After epoch 17, val loss {'Reaction outcome loss': 0.39490795930226646, 'Total loss': 0.39490795930226646} | train loss {'Reaction outcome loss': 0.44557377366700035, 'Total loss': 0.44557377366700035}
2023-01-05 10:01:16,229 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:01:16,229 INFO:     Epoch: 18
2023-01-05 10:01:18,356 INFO:     After epoch 18, val loss {'Reaction outcome loss': 0.3777953584988912, 'Total loss': 0.3777953584988912} | train loss {'Reaction outcome loss': 0.4422157249696877, 'Total loss': 0.4422157249696877}
2023-01-05 10:01:18,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:01:18,356 INFO:     Epoch: 19
2023-01-05 10:01:20,449 INFO:     After epoch 19, val loss {'Reaction outcome loss': 0.40145703256130216, 'Total loss': 0.40145703256130216} | train loss {'Reaction outcome loss': 0.4389800400611526, 'Total loss': 0.4389800400611526}
2023-01-05 10:01:20,450 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:01:20,450 INFO:     Epoch: 20
2023-01-05 10:01:22,603 INFO:     After epoch 20, val loss {'Reaction outcome loss': 0.3564852500955264, 'Total loss': 0.3564852500955264} | train loss {'Reaction outcome loss': 0.4329582606273555, 'Total loss': 0.4329582606273555}
2023-01-05 10:01:22,604 INFO:     Found new best model at epoch 20
2023-01-05 10:01:22,605 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:01:22,605 INFO:     Epoch: 21
2023-01-05 10:01:24,667 INFO:     After epoch 21, val loss {'Reaction outcome loss': 0.3843694642186165, 'Total loss': 0.3843694642186165} | train loss {'Reaction outcome loss': 0.43176410419679695, 'Total loss': 0.43176410419679695}
2023-01-05 10:01:24,667 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:01:24,667 INFO:     Epoch: 22
2023-01-05 10:01:26,383 INFO:     After epoch 22, val loss {'Reaction outcome loss': 0.38143154184023537, 'Total loss': 0.38143154184023537} | train loss {'Reaction outcome loss': 0.4253247526568779, 'Total loss': 0.4253247526568779}
2023-01-05 10:01:26,383 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:01:26,383 INFO:     Epoch: 23
2023-01-05 10:01:28,102 INFO:     After epoch 23, val loss {'Reaction outcome loss': 0.35934899548689525, 'Total loss': 0.35934899548689525} | train loss {'Reaction outcome loss': 0.42613454202259216, 'Total loss': 0.42613454202259216}
2023-01-05 10:01:28,102 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:01:28,102 INFO:     Epoch: 24
2023-01-05 10:01:30,216 INFO:     After epoch 24, val loss {'Reaction outcome loss': 0.3633134613434474, 'Total loss': 0.3633134613434474} | train loss {'Reaction outcome loss': 0.41874732407133863, 'Total loss': 0.41874732407133863}
2023-01-05 10:01:30,216 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:01:30,216 INFO:     Epoch: 25
2023-01-05 10:01:32,426 INFO:     After epoch 25, val loss {'Reaction outcome loss': 0.3476795087258021, 'Total loss': 0.3476795087258021} | train loss {'Reaction outcome loss': 0.41406029845403164, 'Total loss': 0.41406029845403164}
2023-01-05 10:01:32,426 INFO:     Found new best model at epoch 25
2023-01-05 10:01:32,427 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:01:32,428 INFO:     Epoch: 26
2023-01-05 10:01:34,641 INFO:     After epoch 26, val loss {'Reaction outcome loss': 0.3519344617923101, 'Total loss': 0.3519344617923101} | train loss {'Reaction outcome loss': 0.408343200966213, 'Total loss': 0.408343200966213}
2023-01-05 10:01:34,642 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:01:34,642 INFO:     Epoch: 27
2023-01-05 10:01:36,870 INFO:     After epoch 27, val loss {'Reaction outcome loss': 0.34287637869517007, 'Total loss': 0.34287637869517007} | train loss {'Reaction outcome loss': 0.40399088667692157, 'Total loss': 0.40399088667692157}
2023-01-05 10:01:36,870 INFO:     Found new best model at epoch 27
2023-01-05 10:01:36,871 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:01:36,871 INFO:     Epoch: 28
2023-01-05 10:01:39,102 INFO:     After epoch 28, val loss {'Reaction outcome loss': 0.3272747337818146, 'Total loss': 0.3272747337818146} | train loss {'Reaction outcome loss': 0.40310030118005513, 'Total loss': 0.40310030118005513}
2023-01-05 10:01:39,102 INFO:     Found new best model at epoch 28
2023-01-05 10:01:39,104 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:01:39,104 INFO:     Epoch: 29
2023-01-05 10:01:41,302 INFO:     After epoch 29, val loss {'Reaction outcome loss': 0.3415255477031072, 'Total loss': 0.3415255477031072} | train loss {'Reaction outcome loss': 0.39913320685066184, 'Total loss': 0.39913320685066184}
2023-01-05 10:01:41,303 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:01:41,303 INFO:     Epoch: 30
2023-01-05 10:01:43,414 INFO:     After epoch 30, val loss {'Reaction outcome loss': 0.3470324233174324, 'Total loss': 0.3470324233174324} | train loss {'Reaction outcome loss': 0.39925133115679456, 'Total loss': 0.39925133115679456}
2023-01-05 10:01:43,415 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:01:43,415 INFO:     Epoch: 31
2023-01-05 10:01:45,536 INFO:     After epoch 31, val loss {'Reaction outcome loss': 0.3587048550446828, 'Total loss': 0.3587048550446828} | train loss {'Reaction outcome loss': 0.396027246298837, 'Total loss': 0.396027246298837}
2023-01-05 10:01:45,536 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:01:45,536 INFO:     Epoch: 32
2023-01-05 10:01:47,680 INFO:     After epoch 32, val loss {'Reaction outcome loss': 0.3269041935602824, 'Total loss': 0.3269041935602824} | train loss {'Reaction outcome loss': 0.39379073488795996, 'Total loss': 0.39379073488795996}
2023-01-05 10:01:47,681 INFO:     Found new best model at epoch 32
2023-01-05 10:01:47,682 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:01:47,682 INFO:     Epoch: 33
2023-01-05 10:01:49,817 INFO:     After epoch 33, val loss {'Reaction outcome loss': 0.34082886079947156, 'Total loss': 0.34082886079947156} | train loss {'Reaction outcome loss': 0.39384795142256696, 'Total loss': 0.39384795142256696}
2023-01-05 10:01:49,818 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:01:49,818 INFO:     Epoch: 34
2023-01-05 10:01:51,964 INFO:     After epoch 34, val loss {'Reaction outcome loss': 0.3160080740849177, 'Total loss': 0.3160080740849177} | train loss {'Reaction outcome loss': 0.390241060314862, 'Total loss': 0.390241060314862}
2023-01-05 10:01:51,964 INFO:     Found new best model at epoch 34
2023-01-05 10:01:51,965 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:01:51,965 INFO:     Epoch: 35
2023-01-05 10:01:54,097 INFO:     After epoch 35, val loss {'Reaction outcome loss': 0.3372951686382294, 'Total loss': 0.3372951686382294} | train loss {'Reaction outcome loss': 0.380531746306983, 'Total loss': 0.380531746306983}
2023-01-05 10:01:54,097 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:01:54,098 INFO:     Epoch: 36
2023-01-05 10:01:56,217 INFO:     After epoch 36, val loss {'Reaction outcome loss': 0.31154433637857437, 'Total loss': 0.31154433637857437} | train loss {'Reaction outcome loss': 0.3824373690168495, 'Total loss': 0.3824373690168495}
2023-01-05 10:01:56,218 INFO:     Found new best model at epoch 36
2023-01-05 10:01:56,219 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:01:56,219 INFO:     Epoch: 37
2023-01-05 10:01:58,351 INFO:     After epoch 37, val loss {'Reaction outcome loss': 0.3786043132344882, 'Total loss': 0.3786043132344882} | train loss {'Reaction outcome loss': 0.3789903922681359, 'Total loss': 0.3789903922681359}
2023-01-05 10:01:58,352 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:01:58,352 INFO:     Epoch: 38
2023-01-05 10:02:00,486 INFO:     After epoch 38, val loss {'Reaction outcome loss': 0.34650492171446484, 'Total loss': 0.34650492171446484} | train loss {'Reaction outcome loss': 0.375281858192993, 'Total loss': 0.375281858192993}
2023-01-05 10:02:00,486 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:02:00,486 INFO:     Epoch: 39
2023-01-05 10:02:02,625 INFO:     After epoch 39, val loss {'Reaction outcome loss': 0.3213250279426575, 'Total loss': 0.3213250279426575} | train loss {'Reaction outcome loss': 0.36914137611334363, 'Total loss': 0.36914137611334363}
2023-01-05 10:02:02,626 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:02:02,626 INFO:     Epoch: 40
2023-01-05 10:02:04,750 INFO:     After epoch 40, val loss {'Reaction outcome loss': 0.33300193150838214, 'Total loss': 0.33300193150838214} | train loss {'Reaction outcome loss': 0.36458172015947005, 'Total loss': 0.36458172015947005}
2023-01-05 10:02:04,750 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:02:04,750 INFO:     Epoch: 41
2023-01-05 10:02:06,870 INFO:     After epoch 41, val loss {'Reaction outcome loss': 0.3175610254208247, 'Total loss': 0.3175610254208247} | train loss {'Reaction outcome loss': 0.36429348902996594, 'Total loss': 0.36429348902996594}
2023-01-05 10:02:06,870 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:02:06,870 INFO:     Epoch: 42
2023-01-05 10:02:08,802 INFO:     After epoch 42, val loss {'Reaction outcome loss': 0.31168025533358257, 'Total loss': 0.31168025533358257} | train loss {'Reaction outcome loss': 0.3616587753151206, 'Total loss': 0.3616587753151206}
2023-01-05 10:02:08,803 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:02:08,803 INFO:     Epoch: 43
2023-01-05 10:02:10,946 INFO:     After epoch 43, val loss {'Reaction outcome loss': 0.346971129377683, 'Total loss': 0.346971129377683} | train loss {'Reaction outcome loss': 0.3809948085471252, 'Total loss': 0.3809948085471252}
2023-01-05 10:02:10,946 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:02:10,947 INFO:     Epoch: 44
2023-01-05 10:02:13,088 INFO:     After epoch 44, val loss {'Reaction outcome loss': 0.31201477150122325, 'Total loss': 0.31201477150122325} | train loss {'Reaction outcome loss': 0.3514466510336522, 'Total loss': 0.3514466510336522}
2023-01-05 10:02:13,088 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:02:13,088 INFO:     Epoch: 45
2023-01-05 10:02:15,228 INFO:     After epoch 45, val loss {'Reaction outcome loss': 0.3431902249654134, 'Total loss': 0.3431902249654134} | train loss {'Reaction outcome loss': 0.352693491237427, 'Total loss': 0.352693491237427}
2023-01-05 10:02:15,228 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:02:15,228 INFO:     Epoch: 46
2023-01-05 10:02:17,349 INFO:     After epoch 46, val loss {'Reaction outcome loss': 0.3045954058567683, 'Total loss': 0.3045954058567683} | train loss {'Reaction outcome loss': 0.34750252803753656, 'Total loss': 0.34750252803753656}
2023-01-05 10:02:17,349 INFO:     Found new best model at epoch 46
2023-01-05 10:02:17,351 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:02:17,351 INFO:     Epoch: 47
2023-01-05 10:02:19,203 INFO:     After epoch 47, val loss {'Reaction outcome loss': 0.32183018922805784, 'Total loss': 0.32183018922805784} | train loss {'Reaction outcome loss': 0.34492770736139483, 'Total loss': 0.34492770736139483}
2023-01-05 10:02:19,203 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:02:19,203 INFO:     Epoch: 48
2023-01-05 10:02:20,960 INFO:     After epoch 48, val loss {'Reaction outcome loss': 0.3003266250093778, 'Total loss': 0.3003266250093778} | train loss {'Reaction outcome loss': 0.3409435048693474, 'Total loss': 0.3409435048693474}
2023-01-05 10:02:20,960 INFO:     Found new best model at epoch 48
2023-01-05 10:02:20,961 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:02:20,961 INFO:     Epoch: 49
2023-01-05 10:02:22,845 INFO:     After epoch 49, val loss {'Reaction outcome loss': 0.3405157595872879, 'Total loss': 0.3405157595872879} | train loss {'Reaction outcome loss': 0.3413978536947347, 'Total loss': 0.3413978536947347}
2023-01-05 10:02:22,846 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:02:22,846 INFO:     Epoch: 50
2023-01-05 10:02:25,007 INFO:     After epoch 50, val loss {'Reaction outcome loss': 0.3103328118721644, 'Total loss': 0.3103328118721644} | train loss {'Reaction outcome loss': 0.3331006435004436, 'Total loss': 0.3331006435004436}
2023-01-05 10:02:25,008 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:02:25,008 INFO:     Epoch: 51
2023-01-05 10:02:27,131 INFO:     After epoch 51, val loss {'Reaction outcome loss': 0.33332616289456685, 'Total loss': 0.33332616289456685} | train loss {'Reaction outcome loss': 0.3325941166722391, 'Total loss': 0.3325941166722391}
2023-01-05 10:02:27,131 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:02:27,131 INFO:     Epoch: 52
2023-01-05 10:02:29,258 INFO:     After epoch 52, val loss {'Reaction outcome loss': 0.3129212593038877, 'Total loss': 0.3129212593038877} | train loss {'Reaction outcome loss': 0.3322663496558865, 'Total loss': 0.3322663496558865}
2023-01-05 10:02:29,258 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:02:29,258 INFO:     Epoch: 53
2023-01-05 10:02:31,388 INFO:     After epoch 53, val loss {'Reaction outcome loss': 0.2798412357767423, 'Total loss': 0.2798412357767423} | train loss {'Reaction outcome loss': 0.34266670702862134, 'Total loss': 0.34266670702862134}
2023-01-05 10:02:31,389 INFO:     Found new best model at epoch 53
2023-01-05 10:02:31,390 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:02:31,390 INFO:     Epoch: 54
2023-01-05 10:02:33,523 INFO:     After epoch 54, val loss {'Reaction outcome loss': 0.31444288194179537, 'Total loss': 0.31444288194179537} | train loss {'Reaction outcome loss': 0.3505053529206568, 'Total loss': 0.3505053529206568}
2023-01-05 10:02:33,524 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:02:33,524 INFO:     Epoch: 55
2023-01-05 10:02:35,653 INFO:     After epoch 55, val loss {'Reaction outcome loss': 0.3146477237343788, 'Total loss': 0.3146477237343788} | train loss {'Reaction outcome loss': 0.3347669978351062, 'Total loss': 0.3347669978351062}
2023-01-05 10:02:35,653 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:02:35,653 INFO:     Epoch: 56
2023-01-05 10:02:37,794 INFO:     After epoch 56, val loss {'Reaction outcome loss': 0.32520720014969506, 'Total loss': 0.32520720014969506} | train loss {'Reaction outcome loss': 0.32944235831973195, 'Total loss': 0.32944235831973195}
2023-01-05 10:02:37,794 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:02:37,794 INFO:     Epoch: 57
2023-01-05 10:02:39,930 INFO:     After epoch 57, val loss {'Reaction outcome loss': 0.3148559699455897, 'Total loss': 0.3148559699455897} | train loss {'Reaction outcome loss': 0.3208427255909107, 'Total loss': 0.3208427255909107}
2023-01-05 10:02:39,930 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:02:39,930 INFO:     Epoch: 58
2023-01-05 10:02:42,066 INFO:     After epoch 58, val loss {'Reaction outcome loss': 0.2965895431737105, 'Total loss': 0.2965895431737105} | train loss {'Reaction outcome loss': 0.31202681736091187, 'Total loss': 0.31202681736091187}
2023-01-05 10:02:42,066 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:02:42,066 INFO:     Epoch: 59
2023-01-05 10:02:44,206 INFO:     After epoch 59, val loss {'Reaction outcome loss': 0.3156645745038986, 'Total loss': 0.3156645745038986} | train loss {'Reaction outcome loss': 0.31545319001399574, 'Total loss': 0.31545319001399574}
2023-01-05 10:02:44,207 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:02:44,207 INFO:     Epoch: 60
2023-01-05 10:02:46,335 INFO:     After epoch 60, val loss {'Reaction outcome loss': 0.2791367689768473, 'Total loss': 0.2791367689768473} | train loss {'Reaction outcome loss': 0.3066790321153467, 'Total loss': 0.3066790321153467}
2023-01-05 10:02:46,335 INFO:     Found new best model at epoch 60
2023-01-05 10:02:46,336 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:02:46,336 INFO:     Epoch: 61
2023-01-05 10:02:48,483 INFO:     After epoch 61, val loss {'Reaction outcome loss': 0.3488744636376699, 'Total loss': 0.3488744636376699} | train loss {'Reaction outcome loss': 0.3029580715422829, 'Total loss': 0.3029580715422829}
2023-01-05 10:02:48,483 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:02:48,483 INFO:     Epoch: 62
2023-01-05 10:02:50,584 INFO:     After epoch 62, val loss {'Reaction outcome loss': 0.31346281121174496, 'Total loss': 0.31346281121174496} | train loss {'Reaction outcome loss': 0.3135705105521703, 'Total loss': 0.3135705105521703}
2023-01-05 10:02:50,584 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:02:50,584 INFO:     Epoch: 63
2023-01-05 10:02:52,715 INFO:     After epoch 63, val loss {'Reaction outcome loss': 0.29549067666133244, 'Total loss': 0.29549067666133244} | train loss {'Reaction outcome loss': 0.3072523317920665, 'Total loss': 0.3072523317920665}
2023-01-05 10:02:52,715 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:02:52,716 INFO:     Epoch: 64
2023-01-05 10:02:54,832 INFO:     After epoch 64, val loss {'Reaction outcome loss': 0.31091166138648985, 'Total loss': 0.31091166138648985} | train loss {'Reaction outcome loss': 0.3161454704603639, 'Total loss': 0.3161454704603639}
2023-01-05 10:02:54,832 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:02:54,832 INFO:     Epoch: 65
2023-01-05 10:02:56,941 INFO:     After epoch 65, val loss {'Reaction outcome loss': 0.3242675801118215, 'Total loss': 0.3242675801118215} | train loss {'Reaction outcome loss': 0.32772360556755564, 'Total loss': 0.32772360556755564}
2023-01-05 10:02:56,941 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:02:56,942 INFO:     Epoch: 66
2023-01-05 10:02:59,069 INFO:     After epoch 66, val loss {'Reaction outcome loss': 0.36592056453227995, 'Total loss': 0.36592056453227995} | train loss {'Reaction outcome loss': 0.3147322708281918, 'Total loss': 0.3147322708281918}
2023-01-05 10:02:59,069 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:02:59,069 INFO:     Epoch: 67
2023-01-05 10:03:01,201 INFO:     After epoch 67, val loss {'Reaction outcome loss': 0.3169231191277504, 'Total loss': 0.3169231191277504} | train loss {'Reaction outcome loss': 0.3046738954557889, 'Total loss': 0.3046738954557889}
2023-01-05 10:03:01,202 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:03:01,203 INFO:     Epoch: 68
2023-01-05 10:03:03,333 INFO:     After epoch 68, val loss {'Reaction outcome loss': 0.31262014011542, 'Total loss': 0.31262014011542} | train loss {'Reaction outcome loss': 0.2950649943229729, 'Total loss': 0.2950649943229729}
2023-01-05 10:03:03,333 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:03:03,333 INFO:     Epoch: 69
2023-01-05 10:03:05,466 INFO:     After epoch 69, val loss {'Reaction outcome loss': 0.30646016001701354, 'Total loss': 0.30646016001701354} | train loss {'Reaction outcome loss': 0.29723196732474194, 'Total loss': 0.29723196732474194}
2023-01-05 10:03:05,466 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:03:05,466 INFO:     Epoch: 70
2023-01-05 10:03:07,607 INFO:     After epoch 70, val loss {'Reaction outcome loss': 0.2924425592025121, 'Total loss': 0.2924425592025121} | train loss {'Reaction outcome loss': 0.288068787058127, 'Total loss': 0.288068787058127}
2023-01-05 10:03:07,607 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:03:07,607 INFO:     Epoch: 71
2023-01-05 10:03:09,722 INFO:     After epoch 71, val loss {'Reaction outcome loss': 0.2794246584177017, 'Total loss': 0.2794246584177017} | train loss {'Reaction outcome loss': 0.29352695563389664, 'Total loss': 0.29352695563389664}
2023-01-05 10:03:09,722 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:03:09,723 INFO:     Epoch: 72
2023-01-05 10:03:11,856 INFO:     After epoch 72, val loss {'Reaction outcome loss': 0.3157956977685293, 'Total loss': 0.3157956977685293} | train loss {'Reaction outcome loss': 0.2902085364987505, 'Total loss': 0.2902085364987505}
2023-01-05 10:03:11,856 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:03:11,856 INFO:     Epoch: 73
2023-01-05 10:03:13,970 INFO:     After epoch 73, val loss {'Reaction outcome loss': 0.28936543464660647, 'Total loss': 0.28936543464660647} | train loss {'Reaction outcome loss': 0.282706159242203, 'Total loss': 0.282706159242203}
2023-01-05 10:03:13,970 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:03:13,970 INFO:     Epoch: 74
2023-01-05 10:03:16,084 INFO:     After epoch 74, val loss {'Reaction outcome loss': 0.2964731802543004, 'Total loss': 0.2964731802543004} | train loss {'Reaction outcome loss': 0.2871806893322239, 'Total loss': 0.2871806893322239}
2023-01-05 10:03:16,084 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:03:16,085 INFO:     Epoch: 75
2023-01-05 10:03:18,210 INFO:     After epoch 75, val loss {'Reaction outcome loss': 0.3159292449553808, 'Total loss': 0.3159292449553808} | train loss {'Reaction outcome loss': 0.2891940955626036, 'Total loss': 0.2891940955626036}
2023-01-05 10:03:18,210 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:03:18,210 INFO:     Epoch: 76
2023-01-05 10:03:20,333 INFO:     After epoch 76, val loss {'Reaction outcome loss': 0.3104314332207044, 'Total loss': 0.3104314332207044} | train loss {'Reaction outcome loss': 0.28847782060915633, 'Total loss': 0.28847782060915633}
2023-01-05 10:03:20,334 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:03:20,334 INFO:     Epoch: 77
2023-01-05 10:03:22,452 INFO:     After epoch 77, val loss {'Reaction outcome loss': 0.26513184010982516, 'Total loss': 0.26513184010982516} | train loss {'Reaction outcome loss': 0.2793180222713314, 'Total loss': 0.2793180222713314}
2023-01-05 10:03:22,452 INFO:     Found new best model at epoch 77
2023-01-05 10:03:22,453 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:03:22,453 INFO:     Epoch: 78
2023-01-05 10:03:24,591 INFO:     After epoch 78, val loss {'Reaction outcome loss': 0.3026725927988688, 'Total loss': 0.3026725927988688} | train loss {'Reaction outcome loss': 0.28123630019473383, 'Total loss': 0.28123630019473383}
2023-01-05 10:03:24,591 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:03:24,591 INFO:     Epoch: 79
2023-01-05 10:03:26,718 INFO:     After epoch 79, val loss {'Reaction outcome loss': 0.2872104302048683, 'Total loss': 0.2872104302048683} | train loss {'Reaction outcome loss': 0.2745825792527825, 'Total loss': 0.2745825792527825}
2023-01-05 10:03:26,720 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:03:26,720 INFO:     Epoch: 80
2023-01-05 10:03:28,845 INFO:     After epoch 80, val loss {'Reaction outcome loss': 0.31331026802460354, 'Total loss': 0.31331026802460354} | train loss {'Reaction outcome loss': 0.2841645805388723, 'Total loss': 0.2841645805388723}
2023-01-05 10:03:28,845 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:03:28,845 INFO:     Epoch: 81
2023-01-05 10:03:30,974 INFO:     After epoch 81, val loss {'Reaction outcome loss': 0.2695047547419866, 'Total loss': 0.2695047547419866} | train loss {'Reaction outcome loss': 0.2763909042907366, 'Total loss': 0.2763909042907366}
2023-01-05 10:03:30,974 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:03:30,974 INFO:     Epoch: 82
2023-01-05 10:03:33,090 INFO:     After epoch 82, val loss {'Reaction outcome loss': 0.2907766034205755, 'Total loss': 0.2907766034205755} | train loss {'Reaction outcome loss': 0.2660042358718625, 'Total loss': 0.2660042358718625}
2023-01-05 10:03:33,091 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:03:33,091 INFO:     Epoch: 83
2023-01-05 10:03:35,197 INFO:     After epoch 83, val loss {'Reaction outcome loss': 0.2977991089224815, 'Total loss': 0.2977991089224815} | train loss {'Reaction outcome loss': 0.27791572008372634, 'Total loss': 0.27791572008372634}
2023-01-05 10:03:35,197 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:03:35,197 INFO:     Epoch: 84
2023-01-05 10:03:37,325 INFO:     After epoch 84, val loss {'Reaction outcome loss': 0.33251108825206754, 'Total loss': 0.33251108825206754} | train loss {'Reaction outcome loss': 0.27487043122190685, 'Total loss': 0.27487043122190685}
2023-01-05 10:03:37,325 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:03:37,325 INFO:     Epoch: 85
2023-01-05 10:03:39,485 INFO:     After epoch 85, val loss {'Reaction outcome loss': 0.27877022673686347, 'Total loss': 0.27877022673686347} | train loss {'Reaction outcome loss': 0.2789713731488756, 'Total loss': 0.2789713731488756}
2023-01-05 10:03:39,487 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:03:39,487 INFO:     Epoch: 86
2023-01-05 10:03:41,674 INFO:     After epoch 86, val loss {'Reaction outcome loss': 0.35091152787208557, 'Total loss': 0.35091152787208557} | train loss {'Reaction outcome loss': 0.27164686736595933, 'Total loss': 0.27164686736595933}
2023-01-05 10:03:41,674 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:03:41,674 INFO:     Epoch: 87
2023-01-05 10:03:43,855 INFO:     After epoch 87, val loss {'Reaction outcome loss': 0.320805498957634, 'Total loss': 0.320805498957634} | train loss {'Reaction outcome loss': 0.27519856152070715, 'Total loss': 0.27519856152070715}
2023-01-05 10:03:43,855 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:03:43,855 INFO:     Epoch: 88
2023-01-05 10:03:46,031 INFO:     After epoch 88, val loss {'Reaction outcome loss': 0.29451647301514944, 'Total loss': 0.29451647301514944} | train loss {'Reaction outcome loss': 0.26581893281452695, 'Total loss': 0.26581893281452695}
2023-01-05 10:03:46,032 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:03:46,032 INFO:     Epoch: 89
2023-01-05 10:03:48,206 INFO:     After epoch 89, val loss {'Reaction outcome loss': 0.33711354980866115, 'Total loss': 0.33711354980866115} | train loss {'Reaction outcome loss': 0.26652487783238926, 'Total loss': 0.26652487783238926}
2023-01-05 10:03:48,206 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:03:48,206 INFO:     Epoch: 90
2023-01-05 10:03:50,355 INFO:     After epoch 90, val loss {'Reaction outcome loss': 0.2871650372942289, 'Total loss': 0.2871650372942289} | train loss {'Reaction outcome loss': 0.26098523633170745, 'Total loss': 0.26098523633170745}
2023-01-05 10:03:50,356 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:03:50,356 INFO:     Epoch: 91
2023-01-05 10:03:52,493 INFO:     After epoch 91, val loss {'Reaction outcome loss': 0.3235486276447773, 'Total loss': 0.3235486276447773} | train loss {'Reaction outcome loss': 0.2637626181746347, 'Total loss': 0.2637626181746347}
2023-01-05 10:03:52,493 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:03:52,493 INFO:     Epoch: 92
2023-01-05 10:03:54,649 INFO:     After epoch 92, val loss {'Reaction outcome loss': 0.3015745212634405, 'Total loss': 0.3015745212634405} | train loss {'Reaction outcome loss': 0.25615103825196234, 'Total loss': 0.25615103825196234}
2023-01-05 10:03:54,650 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:03:54,650 INFO:     Epoch: 93
2023-01-05 10:03:56,777 INFO:     After epoch 93, val loss {'Reaction outcome loss': 0.31630452647805213, 'Total loss': 0.31630452647805213} | train loss {'Reaction outcome loss': 0.25911408483617654, 'Total loss': 0.25911408483617654}
2023-01-05 10:03:56,778 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:03:56,778 INFO:     Epoch: 94
2023-01-05 10:03:58,902 INFO:     After epoch 94, val loss {'Reaction outcome loss': 0.29108458360036216, 'Total loss': 0.29108458360036216} | train loss {'Reaction outcome loss': 0.25543967348968855, 'Total loss': 0.25543967348968855}
2023-01-05 10:03:58,902 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:03:58,902 INFO:     Epoch: 95
2023-01-05 10:04:01,029 INFO:     After epoch 95, val loss {'Reaction outcome loss': 0.3232549394170443, 'Total loss': 0.3232549394170443} | train loss {'Reaction outcome loss': 0.2573680363384483, 'Total loss': 0.2573680363384483}
2023-01-05 10:04:01,030 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:04:01,030 INFO:     Epoch: 96
2023-01-05 10:04:03,170 INFO:     After epoch 96, val loss {'Reaction outcome loss': 0.288742725054423, 'Total loss': 0.288742725054423} | train loss {'Reaction outcome loss': 0.2560368606355041, 'Total loss': 0.2560368606355041}
2023-01-05 10:04:03,171 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:04:03,171 INFO:     Epoch: 97
2023-01-05 10:04:05,304 INFO:     After epoch 97, val loss {'Reaction outcome loss': 0.30941961258649825, 'Total loss': 0.30941961258649825} | train loss {'Reaction outcome loss': 0.2529956380085028, 'Total loss': 0.2529956380085028}
2023-01-05 10:04:05,304 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:04:05,304 INFO:     Epoch: 98
2023-01-05 10:04:07,420 INFO:     After epoch 98, val loss {'Reaction outcome loss': 0.2948620945215225, 'Total loss': 0.2948620945215225} | train loss {'Reaction outcome loss': 0.2568013674663498, 'Total loss': 0.2568013674663498}
2023-01-05 10:04:07,421 INFO:     Current learning rate [0.00015553873022161447]
2023-01-05 10:04:07,422 INFO:     Epoch: 99
2023-01-05 10:04:09,550 INFO:     After epoch 99, val loss {'Reaction outcome loss': 0.33352330376704536, 'Total loss': 0.33352330376704536} | train loss {'Reaction outcome loss': 0.25390086900037917, 'Total loss': 0.25390086900037917}
2023-01-05 10:04:09,551 INFO:     Best model found after epoch 78 of 100.
2023-01-05 10:04:09,551 INFO:   Done with stage: TRAINING
2023-01-05 10:04:09,551 INFO:   Starting stage: EVALUATION
2023-01-05 10:04:09,682 INFO:   Done with stage: EVALUATION
2023-01-05 10:04:09,682 INFO: Done with stage: RUNNING SPLITS
2023-01-05 10:04:09,682 INFO: Starting stage: COMPUTE METRICS
2023-01-05 10:04:10,855 INFO: Done with stage: COMPUTE METRICS
2023-01-05 10:04:10,855 INFO: Starting stage: EXPORT RESULTS
2023-01-05 10:04:10,873 INFO:   Final results averaged over 50 folds: 
2023-01-05 10:04:10,876 INFO:   
                     mae  neg-spearman      rmse  spearman
dataset_split                                            
test           0.182831           NaN  0.348267       NaN
2023-01-05 10:04:12,506 DEBUG:   matplotlib data path: /opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data
2023-01-05 10:04:12,512 DEBUG:   CONFIGDIR=/root/.config/matplotlib
2023-01-05 10:04:12,513 DEBUG:   interactive is False
2023-01-05 10:04:12,513 DEBUG:   platform is linux
2023-01-05 10:04:12,513 DEBUG:   loaded modules: ['sys', 'builtins', '_frozen_importlib', '_imp', '_thread', '_warnings', '_weakref', 'zipimport', '_frozen_importlib_external', '_io', 'marshal', 'posix', 'encodings', 'codecs', '_codecs', 'encodings.aliases', 'encodings.utf_8', '_signal', '__main__', 'encodings.latin_1', 'io', 'abc', '_abc', 'site', 'os', 'stat', '_stat', '_collections_abc', 'posixpath', 'genericpath', 'os.path', '_sitebuiltins', '_bootlocale', '_locale', '_distutils_hack', 'types', 'importlib', 'importlib._bootstrap', 'importlib._bootstrap_external', 'warnings', 'importlib.util', 'importlib.abc', 'importlib.machinery', 'contextlib', 'collections', 'operator', '_operator', 'keyword', 'heapq', '_heapq', 'itertools', 'reprlib', '_collections', 'functools', '_functools', 'mpl_toolkits', 'google', 'encodings.cp437', 'enzpred', 'enzpred.train_dense', 'copy', 'weakref', '_weakrefset', 'copyreg', 'logging', 'time', 'traceback', 'linecache', 'tokenize', 're', 'enum', 'sre_compile', '_sre', 'sre_parse', 'sre_constants', 'token', 'collections.abc', 'string', '_string', 'threading', 'atexit', 'random', 'math', 'hashlib', '_hashlib', '_blake2', '_sha3', 'bisect', '_bisect', '_random', 'json', 'json.decoder', 'json.scanner', '_json', 'json.encoder', 'pandas', 'numpy', 'numpy._globals', 'numpy.__config__', 'numpy.version', 'numpy._distributor_init', 'mkl', 'ctypes', '_ctypes', 'struct', '_struct', 'ctypes._endian', 'mkl._mklinit', 'mkl._py_mkl_service', 'cython_runtime', 'six', '__future__', 'numpy.core', 'numpy.core.multiarray', 'numpy.core.overrides', 'textwrap', 'datetime', '_datetime', 'numpy.core._multiarray_umath', 'numpy.compat', 'numpy.compat._inspect', 'numpy.compat.py3k', 'pathlib', 'fnmatch', 'ntpath', 'errno', 'urllib', 'urllib.parse', 'pickle', '_compat_pickle', '_pickle', 'numpy.core.umath', 'numpy.core.numerictypes', 'numbers', 'numpy.core._string_helpers', 'numpy.core._type_aliases', 'numpy.core._dtype', 'numpy.core.numeric', 'numpy.core.shape_base', 'numpy.core._asarray', 'numpy.core.fromnumeric', 'numpy.core._methods', 'numpy.core._exceptions', 'numpy.core._ufunc_config', 'numpy.core.arrayprint', 'numpy.core.defchararray', 'numpy.core.records', 'numpy.core.memmap', 'numpy.core.function_base', 'numpy.core.machar', 'numpy.core.getlimits', 'numpy.core.einsumfunc', 'numpy.core._add_newdocs', 'numpy.core._multiarray_tests', 'numpy.core._dtype_ctypes', 'numpy.core._internal', 'ast', '_ast', 'platform', 'subprocess', 'signal', '_posixsubprocess', 'select', 'selectors', 'numpy._pytesttester', 'numpy.lib', 'numpy.lib.mixins', 'numpy.lib.scimath', 'numpy.lib.type_check', 'numpy.lib.ufunclike', 'numpy.lib.index_tricks', 'numpy.matrixlib', 'numpy.matrixlib.defmatrix', 'numpy.linalg', 'numpy.linalg.linalg', 'numpy.lib.twodim_base', 'numpy.linalg.lapack_lite', 'numpy.linalg._umath_linalg', 'numpy.lib.function_base', 'numpy.lib.histograms', 'numpy.lib.stride_tricks', 'numpy.lib.nanfunctions', 'numpy.lib.shape_base', 'numpy.lib.polynomial', 'numpy.lib.utils', 'numpy.lib.arraysetops', 'numpy.lib.npyio', 'numpy.lib.format', 'numpy.lib._datasource', 'shutil', 'zlib', 'bz2', '_compression', '_bz2', 'lzma', '_lzma', 'pwd', 'grp', 'numpy.lib._iotools', 'numpy.lib.financial', 'decimal', '_decimal', 'numpy.lib.arrayterator', 'numpy.lib.arraypad', 'numpy.lib._version', 'numpy.fft', 'numpy.fft._pocketfft', 'numpy.fft._pocketfft_internal', 'numpy.fft.helper', 'numpy.polynomial', 'numpy.polynomial.polynomial', 'numpy.polynomial.polyutils', 'numpy.polynomial._polybase', 'numpy.polynomial.chebyshev', 'numpy.polynomial.legendre', 'numpy.polynomial.hermite', 'numpy.polynomial.hermite_e', 'numpy.polynomial.laguerre', 'numpy.random', 'numpy.random._pickle', 'numpy.random.mtrand', 'numpy.random.bit_generator', '_cython_0_29_21', 'numpy.random._common', 'secrets', 'base64', 'binascii', 'hmac', 'numpy.random._bounded_integers', 'numpy.random._mt19937', 'numpy.random._philox', 'numpy.random._pcg64', 'numpy.random._sfc64', 'numpy.random._generator', 'numpy.ctypeslib', 'numpy.ma', 'numpy.ma.core', 'numpy.ma.extras', 'pytz', 'pytz.exceptions', 'pytz.lazy', 'pytz.tzinfo', 'pytz.tzfile', 'dateutil', 'dateutil._version', 'pandas.compat', 'pandas._typing', 'mmap', 'typing', 'typing.io', 'typing.re', 'pandas.compat.numpy', 'pandas.util', 'pandas.util._decorators', 'inspect', 'dis', 'opcode', '_opcode', 'pandas._libs', 'pandas._libs.interval', '_cython_0_29_25', 'pandas._libs.hashtable', 'pandas._libs.missing', 'pandas._libs.tslibs', 'pandas._libs.tslibs.dtypes', 'pandas._libs.tslibs.conversion', 'pandas._libs.tslibs.base', 'pandas._libs.tslibs.nattype', 'pandas._libs.tslibs.np_datetime', 'pandas._libs.tslibs.timezones', 'dateutil.tz', 'dateutil.tz.tz', 'six.moves', 'dateutil.tz._common', 'dateutil.tz._factories', 'dateutil.zoneinfo', 'tarfile', 'pkgutil', 'gzip', 'pandas._libs.tslibs.tzconversion', 'pandas._libs.tslibs.ccalendar', 'pandas._libs.tslibs.parsing', 'pandas._libs.tslibs.offsets', 'pandas._libs.tslibs.timedeltas', 'pandas._libs.tslibs.fields', 'locale', 'pandas._config', 'pandas._config.config', 'pandas._config.dates', 'pandas._config.display', 'pandas._config.localization', 'pandas._libs.tslibs.strptime', 'calendar', 'pandas._libs.tslibs.timestamps', 'dateutil.easter', 'dateutil.relativedelta', 'dateutil._common', 'pandas._libs.properties', 'dateutil.parser', 'dateutil.parser._parser', 'dateutil.parser.isoparser', 'pandas._libs.tslibs.period', 'pandas._libs.tslibs.vectorized', 'pandas._libs.ops_dispatch', 'pandas._libs.algos', 'pandas.core', 'pandas.core.util', 'pandas.core.util.hashing', 'pandas._libs.lib', 'pandas._libs.tslib', 'pandas._libs.hashing', 'pandas.core.dtypes', 'pandas.core.dtypes.common', 'pandas.core.dtypes.base', 'pandas.errors', 'pandas.core.dtypes.generic', 'pandas.core.dtypes.dtypes', 'pandas.core.dtypes.inference', 'pandas.util.version', 'pandas.compat.pyarrow', 'pandas.core.config_init', 'pandas.core.api', 'pandas.core.dtypes.missing', 'pandas.core.algorithms', 'pandas.core.dtypes.cast', 'pandas.util._exceptions', 'pandas.util._validators', 'pandas.core.array_algos', 'pandas.core.array_algos.take', 'pandas.core.construction', 'pandas.core.common', 'pandas.core.indexers', 'pandas.core.arrays', 'pandas.core.arrays.base', 'pandas.compat.numpy.function', 'pandas.core.missing', 'pandas.compat._optional', 'pandas.core.ops', 'pandas.core.roperator', 'pandas.core.ops.array_ops', 'pandas._libs.ops', 'pandas.core.computation', 'pandas.core.computation.expressions', 'pandas.core.computation.check', 'numexpr', 'numexpr.__config__', 'numexpr.interpreter', 'numexpr.expressions', 'setuptools', '_distutils_hack.override', 'setuptools._distutils', 'distutils', 'distutils.core', 'distutils.debug', 'distutils.errors', 'distutils.dist', 'email', 'distutils.fancy_getopt', 'getopt', 'gettext', 'distutils.util', 'sysconfig', 'distutils.dep_util', 'distutils.spawn', 'distutils.log', 'distutils.cmd', 'distutils.dir_util', 'distutils.file_util', 'distutils.archive_util', 'zipfile', 'distutils.config', 'configparser', 'distutils.extension', 'setuptools._deprecation_warning', 'setuptools.version', 'pkg_resources', 'plistlib', 'xml', 'xml.parsers', 'xml.parsers.expat', 'pyexpat.errors', 'pyexpat.model', 'pyexpat', 'xml.parsers.expat.model', 'xml.parsers.expat.errors', 'email.parser', 'email.feedparser', 'email.errors', 'email._policybase', 'email.header', 'email.quoprimime', 'email.base64mime', 'email.charset', 'email.encoders', 'quopri', 'email.utils', 'socket', '_socket', 'email._parseaddr', 'tempfile', 'pkg_resources.extern', 'pkg_resources._vendor', 'pkg_resources._vendor.jaraco', 'pkg_resources.extern.jaraco', 'pkg_resources.extern.jaraco.text', 'importlib.resources', 'pkg_resources._vendor.importlib_resources', 'pkg_resources._vendor.importlib_resources._common', 'pkg_resources._vendor.importlib_resources.abc', 'pkg_resources._vendor.importlib_resources._compat', 'pkg_resources._vendor.zipp', 'pkg_resources._vendor.importlib_resources._legacy', 'pkg_resources.extern.importlib_resources', 'pkg_resources.extern.jaraco.functools', 'pkg_resources._vendor.more_itertools', 'pkg_resources._vendor.more_itertools.more', 'queue', '_queue', 'pkg_resources._vendor.more_itertools.recipes', 'pkg_resources.extern.more_itertools', 'pkg_resources.extern.jaraco.context', 'pkg_resources._vendor.appdirs', 'pkg_resources.extern.appdirs', 'pkg_resources._vendor.packaging', 'pkg_resources._vendor.packaging.__about__', 'pkg_resources.extern.packaging', 'pkg_resources.extern.packaging.version', 'pkg_resources.extern.packaging._structures', 'pkg_resources.extern.packaging.specifiers', 'pkg_resources.extern.packaging.utils', 'pkg_resources.extern.packaging.tags', 'pkg_resources._vendor.packaging._manylinux', 'pkg_resources._vendor.packaging._musllinux', 'pkg_resources.extern.packaging.requirements', 'pkg_resources._vendor.pyparsing', 'pkg_resources._vendor.pyparsing.util', 'pkg_resources._vendor.pyparsing.exceptions', 'pkg_resources._vendor.pyparsing.unicode', 'pkg_resources._vendor.pyparsing.actions', 'pkg_resources._vendor.pyparsing.core', 'pkg_resources._vendor.pyparsing.results', 'pprint', 'pkg_resources._vendor.pyparsing.helpers', 'html', 'html.entities', 'pkg_resources._vendor.pyparsing.testing', 'pkg_resources._vendor.pyparsing.common', 'pkg_resources.extern.pyparsing', 'pkg_resources.extern.packaging.markers', 'setuptools.extension', 'setuptools.monkey', 'distutils.filelist', 'setuptools.dist', 'distutils.command', 'glob', 'setuptools.extern', 'setuptools._vendor', 'setuptools._vendor.packaging', 'setuptools._vendor.packaging.__about__', 'setuptools.extern.packaging', 'setuptools._vendor.ordered_set', 'setuptools.extern.ordered_set', 'setuptools._vendor.more_itertools', 'setuptools._vendor.more_itertools.more', 'setuptools._vendor.more_itertools.recipes', 'setuptools.extern.more_itertools', 'setuptools._importlib', 'setuptools._vendor.importlib_metadata', 'csv', '_csv', 'setuptools._vendor.zipp', 'setuptools._vendor.importlib_metadata._adapters', 'email.message', 'uu', 'email._encoded_words', 'email.iterators', 'setuptools._vendor.importlib_metadata._text', 'setuptools._vendor.importlib_metadata._functools', 'setuptools._vendor.importlib_metadata._meta', 'setuptools._vendor.importlib_metadata._compat', 'setuptools._vendor.typing_extensions', 'setuptools._vendor.importlib_metadata._collections', 'setuptools._vendor.importlib_metadata._itertools', 'setuptools.extern.importlib_metadata', 'importlib_metadata', 'zipp', 'importlib_metadata._adapters', 'importlib_metadata._text', 'importlib_metadata._functools', 'importlib_metadata._meta', 'importlib_metadata._compat', 'typing_extensions', 'importlib_metadata._collections', 'importlib_metadata._itertools', 'setuptools._vendor.importlib_resources', 'setuptools._vendor.importlib_resources._common', 'setuptools._vendor.importlib_resources.abc', 'setuptools._vendor.importlib_resources._compat', 'setuptools._vendor.importlib_resources._legacy', 'setuptools.extern.importlib_resources', 'setuptools.command', 'distutils.command.bdist', 'setuptools.windows_support', 'setuptools.config', 'setuptools.config.setupcfg', 'setuptools.extern.packaging.requirements', 'setuptools._vendor.pyparsing', 'setuptools._vendor.pyparsing.util', 'setuptools._vendor.pyparsing.exceptions', 'setuptools._vendor.pyparsing.unicode', 'setuptools._vendor.pyparsing.actions', 'setuptools._vendor.pyparsing.core', 'setuptools._vendor.pyparsing.results', 'setuptools._vendor.pyparsing.helpers', 'setuptools._vendor.pyparsing.testing', 'setuptools._vendor.pyparsing.common', 'setuptools.extern.pyparsing', 'setuptools.extern.packaging.markers', 'setuptools.extern.packaging.specifiers', 'setuptools.extern.packaging.utils', 'setuptools.extern.packaging.tags', 'setuptools._vendor.packaging._manylinux', 'setuptools._vendor.packaging._musllinux', 'setuptools.extern.packaging.version', 'setuptools.extern.packaging._structures', 'setuptools.config.expand', 'setuptools._path', 'setuptools.config.pyprojecttoml', 'setuptools.errors', 'setuptools.config._apply_pyprojecttoml', 'email.headerregistry', 'email._header_value_parser', 'setuptools.discovery', 'setuptools._reqs', 'setuptools._vendor.jaraco', 'setuptools.extern.jaraco', 'setuptools.extern.jaraco.text', 'setuptools.extern.jaraco.functools', 'setuptools.extern.jaraco.context', 'setuptools._entry_points', 'setuptools._itertools', 'setuptools.depends', 'setuptools._imp', 'setuptools.py34compat', 'setuptools.logging', 'setuptools.msvc', 'distutils.version', 'numexpr.necompiler', 'numexpr.utils', 'numexpr.version', 'pandas.core.ops.missing', 'pandas.core.ops.dispatch', 'pandas.core.ops.invalid', 'pandas.core.ops.common', 'pandas.core.ops.docstrings', 'pandas.core.ops.mask_ops', 'pandas.core.ops.methods', 'pandas.core.sorting', 'pandas.core.arrays.boolean', 'pandas.core.arrays.masked', 'pandas.core.nanops', 'bottleneck', 'bottleneck.benchmark', 'bottleneck.benchmark.bench', 'bottleneck.benchmark.autotimeit', 'timeit', 'gc', 'bottleneck.benchmark.bench_detailed', 'bottleneck.tests', 'bottleneck.tests.util', 'bottleneck.slow', 'bottleneck.slow.reduce', 'bottleneck.slow.nonreduce', 'bottleneck.slow.nonreduce_axis', 'bottleneck.slow.move', 'bottleneck._pytesttester', 'bottleneck.move', 'bottleneck.nonreduce', 'bottleneck.nonreduce_axis', 'bottleneck.reduce', 'bottleneck._version', 'pandas.core.array_algos.masked_reductions', 'pandas.core.arraylike', 'pandas.core.arrays.categorical', 'pandas._libs.arrays', 'pandas.core.accessor', 'pandas.core.arrays._mixins', 'pandas.core.array_algos.transforms', 'pandas.core.base', 'pandas.core.strings', 'pandas.core.strings.accessor', 'pandas.core.strings.base', 'pandas.core.strings.object_array', 'unicodedata', 'pandas.io', 'pandas.io.formats', 'pandas.io.formats.console', 'pandas.core.arrays.datetimes', 'pandas.core.arrays.datetimelike', 'pandas.tseries', 'pandas.tseries.frequencies', 'pandas.core.arrays._ranges', 'pandas.core.arrays.integer', 'pandas.core.arrays.numeric', 'pandas.core.tools', 'pandas.core.tools.numeric', 'pandas.tseries.offsets', 'pandas.core.arrays.floating', 'pandas.core.arrays.interval', 'pandas.core.indexes', 'pandas.core.indexes.base', 'pandas._libs.index', 'pandas._libs.join', 'pandas.core.dtypes.concat', 'pandas.core.arrays.sparse', 'pandas.core.arrays.sparse.accessor', 'pandas.core.arrays.sparse.array', 'pandas._libs.sparse', 'pandas.core.arrays.sparse.dtype', 'pandas.io.formats.printing', 'pandas.core.array_algos.putmask', 'pandas.core.indexes.frozen', 'pandas.core.arrays.numpy_', 'pandas.core.arrays.period', 'pandas.core.arrays.string_', 'pandas.core.arrays.string_arrow', 'pandas.core.arrays.timedeltas', 'pandas.core.flags', 'pandas.core.groupby', 'pandas.core.groupby.generic', 'pandas._libs.reduction', 'pandas.core.aggregation', 'pandas.core.indexes.api', 'pandas.core.indexes.category', 'pandas.core.indexes.extension', 'pandas.core.indexes.datetimes', 'pandas.core.indexes.datetimelike', 'pandas.core.indexes.numeric', 'pandas.core.tools.timedeltas', 'pandas.core.tools.times', 'pandas.core.indexes.interval', 'pandas.core.indexes.multi', 'pandas.core.indexes.timedeltas', 'pandas.core.indexes.period', 'pandas.core.indexes.range', 'pandas.core.apply', 'pandas.core.frame', 'pandas.core.generic', 'pandas.core.indexing', 'pandas._libs.indexing', 'pandas.core.describe', 'pandas.core.reshape', 'pandas.core.reshape.concat', 'pandas.core.internals', 'pandas.core.internals.api', 'pandas._libs.internals', 'pandas.core.internals.blocks', 'pandas._libs.writers', 'pandas.core.array_algos.quantile', 'pandas.core.array_algos.replace', 'pandas.core.internals.array_manager', 'pandas.core.internals.base', 'pandas.core.internals.concat', 'pandas.core.internals.managers', 'pandas.core.internals.ops', 'pandas.io.formats.format', 'pandas.io.common', 'dataclasses', 'pandas.core.internals.construction', 'pandas.core.shared_docs', 'pandas.core.window', 'pandas.core.window.ewm', 'pandas._libs.window', 'pandas._libs.window.aggregations', 'pandas.core.util.numba_', 'pandas.core.window.common', 'pandas.core.window.doc', 'pandas.core.window.indexers', 'pandas._libs.window.indexers', 'pandas.core.window.numba_', 'pandas.core.window.online', 'pandas.core.window.rolling', 'pandas.core.window.expanding', 'pandas.core.reshape.melt', 'pandas.core.reshape.util', 'pandas.core.series', 'pandas._libs.reshape', 'pandas.core.indexes.accessors', 'pandas.core.tools.datetimes', 'pandas.arrays', 'pandas.plotting', 'pandas.plotting._core', 'pandas.plotting._misc', 'pandas.io.formats.info', 'pandas.core.groupby.base', 'pandas.core.groupby.groupby', 'pandas._libs.groupby', 'pandas.core.groupby.numba_', 'pandas.core.groupby.ops', 'pandas.core.groupby.grouper', 'pandas.core.groupby.categorical', 'pandas.tseries.api', 'pandas.core.computation.api', 'pandas.core.computation.eval', 'pandas.core.computation.engines', 'pandas.core.computation.align', 'pandas.core.computation.common', 'pandas.core.computation.expr', 'pandas.core.computation.ops', 'pandas.core.computation.scope', 'pandas.compat.chainmap', 'pandas.core.computation.parsing', 'pandas.core.reshape.api', 'pandas.core.reshape.merge', 'pandas.core.reshape.pivot', 'pandas.core.reshape.reshape', 'pandas.core.reshape.tile', 'pandas.api', 'pandas.api.extensions', 'pandas.api.indexers', 'pandas.api.types', 'pandas.core.dtypes.api', 'pandas.util._print_versions', 'pandas.io.api', 'pandas.io.clipboards', 'pandas.io.excel', 'pandas.io.excel._base', 'pandas._libs.parsers', 'pandas.io.excel._util', 'pandas.io.parsers', 'pandas.io.parsers.readers', 'pandas.io.parsers.base_parser', 'pandas.io.date_converters', 'pandas.io.parsers.c_parser_wrapper', 'pandas.io.parsers.python_parser', 'pandas.io.excel._odfreader', 'pandas.io.excel._openpyxl', 'pandas.io.excel._pyxlsb', 'pandas.io.excel._xlrd', 'pandas.io.excel._odswriter', 'pandas._libs.json', 'pandas.io.formats.excel', 'pandas.io.formats._color_data', 'pandas.io.formats.css', 'pandas.io.excel._xlsxwriter', 'pandas.io.excel._xlwt', 'pandas.io.feather_format', 'pandas.io.gbq', 'pandas.io.html', 'pandas.io.json', 'pandas.io.json._json', 'pandas.io.json._normalize', 'pandas.io.json._table_schema', 'pandas.io.orc', 'pandas.io.parquet', 'pandas.io.pickle', 'pandas.compat.pickle_compat', 'pandas.io.pytables', 'pandas.core.computation.pytables', 'pandas.io.sas', 'pandas.io.sas.sasreader', 'pandas.io.spss', 'pandas.io.sql', 'pandas.io.stata', 'pandas.io.xml', 'pandas.util._tester', 'pandas.testing', 'pandas._testing', 'pandas._testing._io', 'pandas._testing._random', 'pandas._testing.contexts', 'pandas._testing._warnings', 'pandas._testing.asserters', 'pandas._libs.testing', 'cmath', 'pandas._testing.compat', 'pandas._version', 'torch', 'torch._utils', 'torch._utils_internal', 'torch.version', 'torch._six', 'torch._C._onnx', 'torch._C._jit_tree_views', 'torch._C.cpp', 'torch._C.cpp.nn', 'torch._C', 'torch.random', 'torch.serialization', 'difflib', 'torch._tensor_str', 'torch.tensor', 'torch._namedtensor_internals', 'torch.utils', 'torch.utils.throughput_benchmark', 'torch.utils.hooks', 'torch.storage', 'torch.cuda', 'torch.cuda._utils', 'torch.cuda.memory', 'torch.cuda.random', 'torch.cuda.sparse', 'torch.cuda.profiler', 'torch.cuda.nvtx', 'torch.cuda.streams', 'torch.sparse', 'torch.functional', 'torch.nn', 'torch.nn.modules', 'torch.nn.modules.module', 'torch.nn.parameter', 'torch.nn.modules.linear', 'torch.nn.functional', 'torch.nn._reduction', 'torch.nn.modules.utils', 'torch.nn.grad', 'torch.nn._VF', 'torch._jit_internal', 'torch.nn.init', 'torch.nn.modules.conv', 'torch.nn.modules.activation', 'torch.nn.modules.loss', 'torch.nn.modules.container', 'torch.nn.modules.pooling', 'torch.nn.modules.batchnorm', 'torch.nn.modules._functions', 'torch.autograd', 'torch.autograd.variable', 'torch.autograd.function', 'torch.autograd.gradcheck', 'torch.testing', 'torch.autograd.grad_mode', 'torch.autograd.anomaly_mode', 'torch.autograd.profiler', 'torch.nn.modules.instancenorm', 'torch.nn.modules.normalization', 'torch.nn.modules.dropout', 'torch.nn.modules.padding', 'torch.nn.modules.sparse', 'torch.nn.modules.rnn', 'torch.nn.utils', 'torch.nn.utils.rnn', 'torch.nn.utils.clip_grad', 'torch.nn.utils.weight_norm', 'torch.nn.utils.convert_parameters', 'torch.nn.utils.spectral_norm', 'torch.nn.utils.fusion', 'torch.nn.modules.pixelshuffle', 'torch.nn.modules.upsampling', 'torch.nn.modules.distance', 'torch.nn.modules.fold', 'torch.nn.modules.adaptive', 'torch.nn.modules.transformer', 'torch.nn.modules.flatten', 'torch.nn.parallel', 'torch.nn.parallel.parallel_apply', 'torch.nn.parallel.replicate', 'torch.cuda.comm', 'torch.cuda.nccl', 'torch.nn.parallel.data_parallel', 'torch.nn.parallel.scatter_gather', 'torch.nn.parallel._functions', 'torch.nn.parallel.distributed', 'torch.distributed', 'torch.distributed.distributed_c10d', 'torch.distributed.rendezvous', 'torch.nn.intrinsic', 'torch.nn.intrinsic.modules', 'torch.nn.intrinsic.modules.fused', 'torch.nn.quantized', 'torch.nn.quantized.modules', 'torch.nn.quantized.modules.activation', 'torch.nn.quantized.functional', 'torch.nn.quantized.modules.conv', 'torch.nn.intrinsic.qat', 'torch.nn.intrinsic.qat.modules', 'torch.nn.intrinsic.qat.modules.linear_relu', 'torch.nn.qat', 'torch.nn.qat.modules', 'torch.nn.qat.modules.linear', 'torch.nn.qat.modules.conv', 'torch.nn.intrinsic.qat.modules.conv_fused', 'torch._ops', 'torch.jit', 'torch.backends', 'torch.backends.cudnn', 'torch.jit.annotations', 'torch.jit._recursive', 'torch.jit.frontend', 'torch.nn.quantized.modules.utils', 'torch.nn.quantized.modules.linear', 'torch.nn.quantized.modules.functional_modules', 'torch.optim', 'torch.optim.adadelta', 'torch.optim.optimizer', 'torch.optim.adagrad', 'torch.optim.adam', 'torch.optim.adamw', 'torch.optim.sparse_adam', 'torch.optim.adamax', 'torch.optim.asgd', 'torch.optim.sgd', 'torch.optim.rprop', 'torch.optim.rmsprop', 'torch.optim.lbfgs', 'torch.optim.lr_scheduler', 'torch.multiprocessing', 'torch.multiprocessing.reductions', 'multiprocessing', 'multiprocessing.context', 'multiprocessing.process', 'multiprocessing.reduction', 'array', '__mp_main__', 'multiprocessing.util', 'multiprocessing.resource_sharer', 'torch.multiprocessing.spawn', 'multiprocessing.connection', '_multiprocessing', 'torch.utils.backcompat', 'torch.onnx', 'torch.hub', 'urllib.request', 'http', 'http.client', 'ssl', '_ssl', 'urllib.error', 'urllib.response', 'tqdm', 'tqdm._monitor', 'tqdm._tqdm_pandas', 'tqdm.cli', 'tqdm.std', 'tqdm.utils', 'tqdm.version', 'tqdm._dist_ver', 'tqdm.gui', 'tqdm.auto', 'tqdm.autonotebook', 'tqdm.asyncio', 'asyncio', 'asyncio.base_events', 'concurrent', 'concurrent.futures', 'concurrent.futures._base', 'asyncio.constants', 'asyncio.coroutines', 'asyncio.base_futures', 'asyncio.format_helpers', 'asyncio.log', 'asyncio.events', 'contextvars', '_contextvars', 'asyncio.base_tasks', '_asyncio', 'asyncio.futures', 'asyncio.protocols', 'asyncio.sslproto', 'asyncio.transports', 'asyncio.tasks', 'asyncio.locks', 'asyncio.runners', 'asyncio.queues', 'asyncio.streams', 'asyncio.subprocess', 'asyncio.unix_events', 'asyncio.base_subprocess', 'asyncio.selector_events', 'torch.distributions', 'torch.distributions.bernoulli', 'torch.distributions.constraints', 'torch.distributions.exp_family', 'torch.distributions.distribution', 'torch.distributions.utils', 'torch.distributions.beta', 'torch.distributions.dirichlet', 'torch.distributions.binomial', 'torch.distributions.categorical', 'torch.distributions.cauchy', 'torch.distributions.chi2', 'torch.distributions.gamma', 'torch.distributions.constraint_registry', 'torch.distributions.transforms', 'torch.distributions.exponential', 'torch.distributions.fishersnedecor', 'torch.distributions.geometric', 'torch.distributions.gumbel', 'torch.distributions.uniform', 'torch.distributions.transformed_distribution', 'torch.distributions.half_cauchy', 'torch.distributions.half_normal', 'torch.distributions.normal', 'torch.distributions.independent', 'torch.distributions.kl', 'torch.distributions.laplace', 'torch.distributions.lowrank_multivariate_normal', 'torch.distributions.multivariate_normal', 'torch.distributions.one_hot_categorical', 'torch.distributions.pareto', 'torch.distributions.poisson', 'torch.distributions.log_normal', 'torch.distributions.logistic_normal', 'torch.distributions.multinomial', 'torch.distributions.negative_binomial', 'torch.distributions.relaxed_bernoulli', 'torch.distributions.relaxed_categorical', 'torch.distributions.studentT', 'torch.distributions.weibull', 'torch.backends.cuda', 'torch.backends.mkl', 'torch.backends.openmp', 'torch.backends.quantized', 'torch.quantization', 'torch.quantization.quantize', 'torch.quantization.default_mappings', 'torch.nn.intrinsic.quantized', 'torch.nn.intrinsic.quantized.modules', 'torch.nn.intrinsic.quantized.modules.linear_relu', 'torch.nn.intrinsic.quantized.modules.conv_relu', 'torch.nn.quantized.dynamic', 'torch.nn.quantized.dynamic.modules', 'torch.nn.quantized.dynamic.modules.linear', 'torch.nn.quantized.dynamic.modules.rnn', 'torch.quantization.stubs', 'torch.quantization.qconfig', 'torch.quantization.observer', 'torch.quantization.fake_quantize', 'torch.quantization.fuse_modules', 'torch.utils.data', 'torch.utils.data.sampler', 'torch.utils.data.distributed', 'torch.utils.data.dataset', 'torch.utils.data.dataloader', 'torch.utils.data._utils', 'torch.utils.data._utils.worker', 'torch.utils.data._utils.signal_handling', 'torch.utils.data._utils.pin_memory', 'torch.utils.data._utils.collate', 'torch.utils.data._utils.fetch', 'torch.__config__', 'torch.__future__', 'torch._torch_docs', 'torch._tensor_docs', 'torch._storage_docs', 'torch._classes', 'torch.quasirandom', 'imp', 'optuna', 'optuna.distributions', 'optuna.type_checking', 'optuna.exceptions', 'optuna.importance', 'optuna._experimental', 'optuna.importance._base', 'optuna.samplers', 'optuna.samplers._search_space', 'optuna.study', 'joblib', 'joblib.memory', 'pydoc', '_sysconfigdata_m_linux_x86_64-linux-gnu', 'joblib.hashing', 'joblib.func_inspect', 'joblib.logger', 'joblib.disk', 'joblib._store_backends', 'joblib.backports', 'joblib.numpy_pickle', 'joblib.compressor', 'joblib.numpy_pickle_utils', 'joblib.numpy_pickle_compat', 'joblib.parallel', 'uuid', 'joblib._multiprocessing_helpers', 'joblib._parallel_backends', 'joblib.my_exceptions', 'joblib._deprecated_my_exceptions', 'joblib.pool', 'joblib._memmapping_reducer', 'joblib.externals', 'joblib.externals.loky', 'joblib.externals.loky._base', 'joblib.externals.loky.backend', 'joblib.externals.loky.backend.context', 'joblib.externals.loky.backend.process', 'joblib.externals.loky.backend.compat', 'joblib.externals.loky.backend.compat_posix', 'multiprocessing.synchronize', 'joblib.externals.loky.backend.reduction', 'joblib.externals.loky.backend._posix_reduction', 'joblib.externals.cloudpickle', 'joblib.externals.cloudpickle.cloudpickle', 'joblib.externals.cloudpickle.compat', 'joblib.externals.cloudpickle.cloudpickle_fast', 'joblib.externals.loky.reusable_executor', 'joblib.externals.loky.process_executor', 'joblib.externals.loky.backend.queues', 'multiprocessing.queues', 'joblib.externals.loky.backend.utils', 'joblib.externals.loky.initializers', 'concurrent.futures.process', 'joblib.externals.loky.cloudpickle_wrapper', 'joblib.externals.loky.backend.resource_tracker', 'joblib.externals.loky.backend.spawn', 'runpy', 'multiprocessing.pool', 'joblib.executor', 'joblib._utils', 'optuna._study_direction', 'optuna._study_summary', 'optuna.logging', 'colorlog', 'colorlog.colorlog', 'colorlog.escape_codes', 'colorlog.logging', 'optuna.trial', 'optuna.trial._base', 'optuna.trial._fixed', 'optuna.trial._frozen', 'optuna.trial._state', 'optuna.trial._trial', 'optuna.pruners', 'optuna.pruners.base', 'optuna.pruners.hyperband', 'optuna.pruners.successive_halving', 'optuna.pruners.median', 'optuna.pruners.percentile', 'optuna.pruners.nop', 'optuna.pruners.threshold', 'optuna.progress_bar', 'optuna.storages', 'optuna.storages.base', 'optuna.storages.cached_storage', 'optuna.storages.rdb', 'optuna.storages.rdb.storage', 'alembic', 'alembic.context', 'alembic.runtime', 'alembic.runtime.environment', 'alembic.runtime.migration', 'sqlalchemy', 'sqlalchemy.util', 'sqlalchemy.util._collections', 'sqlalchemy.util.compat', 'sqlalchemy.cimmutabledict', 'sqlalchemy.util._preloaded', 'sqlalchemy.util.concurrency', 'greenlet', 'greenlet._greenlet', 'sqlalchemy.util._concurrency_py3k', 'sqlalchemy.util.langhelpers', 'sqlalchemy.exc', 'sqlalchemy.util._compat_py3k', 'sqlalchemy.util.deprecations', 'sqlalchemy.engine', 'sqlalchemy.engine.events', 'sqlalchemy.engine.base', 'sqlalchemy.engine.interfaces', 'sqlalchemy.sql', 'sqlalchemy.sql.base', 'sqlalchemy.sql.roles', 'sqlalchemy.sql.visitors', 'sqlalchemy.sql.traversals', 'sqlalchemy.sql.operators', 'sqlalchemy.inspection', 'sqlalchemy.sql.compiler', 'sqlalchemy.sql.coercions', 'sqlalchemy.sql.crud', 'sqlalchemy.sql.dml', 'sqlalchemy.types', 'sqlalchemy.sql.sqltypes', 'sqlalchemy.sql.elements', 'sqlalchemy.sql.type_api', 'sqlalchemy.sql.annotation', 'sqlalchemy.event', 'sqlalchemy.event.api', 'sqlalchemy.event.base', 'sqlalchemy.event.attr', 'sqlalchemy.event.legacy', 'sqlalchemy.event.registry', 'sqlalchemy.processors', 'sqlalchemy.cprocessors', 'sqlalchemy.sql.util', 'sqlalchemy.sql.ddl', 'sqlalchemy.util.topological', 'sqlalchemy.sql.schema', 'sqlalchemy.sql.selectable', 'sqlalchemy.sql.functions', 'sqlalchemy.sql.expression', 'sqlalchemy.sql.lambdas', 'sqlalchemy.sql.events', 'sqlalchemy.sql.naming', 'sqlalchemy.sql.default_comparator', 'sqlalchemy.engine.util', 'sqlalchemy.log', 'sqlalchemy.engine.create', 'sqlalchemy.engine.url', 'sqlalchemy.dialects', 'sqlalchemy.engine.mock', 'sqlalchemy.pool', 'sqlalchemy.pool.events', 'sqlalchemy.pool.base', 'sqlalchemy.pool.dbapi_proxy', 'sqlalchemy.pool.impl', 'sqlalchemy.util.queue', 'sqlalchemy.engine.cursor', 'sqlalchemy.engine.result', 'sqlalchemy.engine.row', 'sqlalchemy.cresultproxy', 'sqlalchemy.engine.reflection', 'sqlalchemy.schema', 'sqlalchemy.events', 'sqlalchemy.engine.default', 'sqlalchemy.engine.characteristics', 'sqlalchemy.engine.strategies', 'alembic.ddl', 'alembic.ddl.mssql', 'sqlalchemy.ext', 'sqlalchemy.ext.compiler', 'alembic.ddl.base', 'alembic.util', 'alembic.util.editor', 'alembic.util.compat', 'importlib_resources', 'importlib_resources._common', 'importlib_resources.abc', 'importlib_resources._compat', 'importlib_resources._legacy', 'alembic.util.exc', 'alembic.util.langhelpers', 'alembic.util.messaging', 'alembic.util.sqla_compat', 'fcntl', 'termios', 'alembic.util.pyfiles', 'mako', 'mako.exceptions', 'mako.compat', 'mako.util', 'mako.ext', 'mako.ext.pygmentplugin', 'pygments', 'pygments.formatters', 'pygments.formatters._mapping', 'pygments.plugin', 'pygments.util', 'pygments.formatters.html', 'pygments.formatter', 'pygments.styles', 'pygments.token', 'pygments.lexer', 'pygments.filter', 'pygments.filters', 'pygments.regexopt', 'pygments.lexers', 'pygments.lexers._mapping', 'pygments.modeline', 'pygments.lexers.agile', 'pygments.lexers.lisp', 'pygments.lexers.python', 'pygments.unistring', 'pygments.lexers.jvm', 'pygments.lexers.ruby', 'pygments.lexers.perl', 'pygments.lexers.d', 'pygments.lexers.iolang', 'pygments.lexers.tcl', 'pygments.lexers.factor', 'pygments.lexers.scripting', 'pygments.lexers.web', 'pygments.lexers.html', 'pygments.lexers.javascript', 'pygments.lexers.css', 'pygments.lexers.actionscript', 'pygments.lexers.php', 'pygments.lexers.webmisc', 'pygments.lexers.data', 'pygments.styles.default', 'pygments.style', 'mako.template', 'mako.cache', 'mako.codegen', 'mako.ast', 'mako.pyparser', 'mako._ast_util', 'mako.filters', 'markupsafe', 'markupsafe._speedups', 'mako.parsetree', 'mako.pygen', 'mako.runtime', 'mako.lexer', 'alembic.ddl.impl', 'alembic.ddl.mysql', 'alembic.autogenerate', 'alembic.autogenerate.api', 'alembic.autogenerate.compare', 'alembic.autogenerate.render', 'alembic.operations', 'alembic.operations.toimpl', 'alembic.operations.ops', 'alembic.operations.schemaobj', 'alembic.operations.base', 'alembic.operations.batch', 'alembic.autogenerate.rewriter', 'alembic.ddl.oracle', 'alembic.ddl.postgresql', 'sqlalchemy.dialects.postgresql', 'sqlalchemy.dialects.postgresql.base', 'sqlalchemy.dialects.postgresql.array', 'sqlalchemy.dialects.postgresql.dml', 'sqlalchemy.dialects.postgresql.ext', 'sqlalchemy.dialects.postgresql.hstore', 'sqlalchemy.dialects.postgresql.json', 'sqlalchemy.dialects.postgresql.ranges', 'sqlalchemy.dialects.postgresql.pg8000', 'sqlalchemy.dialects.postgresql.psycopg2', 'sqlalchemy.dialects.postgresql.psycopg2cffi', 'sqlalchemy.dialects.postgresql.pygresql', 'sqlalchemy.dialects.postgresql.pypostgresql', 'sqlalchemy.dialects.postgresql.asyncpg', 'alembic.ddl.sqlite', 'alembic.op', 'alembic.command', 'alembic.script', 'alembic.script.base', 'alembic.script.revision', 'alembic.script.write_hooks', 'shlex', 'alembic.config', 'argparse', 'alembic.migration', 'sqlalchemy.orm', 'sqlalchemy.orm.exc', 'sqlalchemy.orm.mapper', 'sqlalchemy.orm.attributes', 'sqlalchemy.orm.collections', 'sqlalchemy.orm.base', 'sqlalchemy.orm.interfaces', 'sqlalchemy.orm.path_registry', 'sqlalchemy.orm.instrumentation', 'sqlalchemy.orm.state', 'sqlalchemy.orm.loading', 'sqlalchemy.orm.strategy_options', 'sqlalchemy.orm.util', 'sqlalchemy.future', 'sqlalchemy.future.engine', 'sqlalchemy.orm.properties', 'sqlalchemy.orm.descriptor_props', 'sqlalchemy.orm.relationships', 'sqlalchemy.orm.context', 'sqlalchemy.orm.decl_api', 'sqlalchemy.orm.clsregistry', 'sqlalchemy.orm.decl_base', 'sqlalchemy.orm.identity', 'sqlalchemy.orm.query', 'sqlalchemy.orm.scoping', 'sqlalchemy.orm.session', 'sqlalchemy.orm.persistence', 'sqlalchemy.orm.evaluator', 'sqlalchemy.orm.sync', 'sqlalchemy.orm.unitofwork', 'sqlalchemy.orm.events', 'sqlalchemy.orm.dynamic', 'sqlalchemy.orm.strategies', 'sqlalchemy.orm.dependency', 'optuna.storages.rdb.models', 'sqlalchemy.ext.declarative', 'sqlalchemy.ext.declarative.extensions', 'optuna.version', 'optuna.storages.in_memory', 'optuna.storages.redis', 'optuna.samplers.base', 'optuna.samplers.cmaes', 'cmaes', 'cmaes._cma', 'cmaes._sepcma', 'cmaes._warm_start', 'cmaes._cmawm', 'scipy', 'scipy._lib', 'scipy._lib._testutils', 'scipy._lib.deprecation', 'scipy.__config__', 'scipy.version', 'scipy._distributor_init', 'scipy._lib._pep440', 'scipy._lib._ccallback', 'scipy._lib._ccallback_c', 'scipy.stats', 'scipy.stats.stats', 'scipy.spatial', 'scipy.spatial.kdtree', 'scipy.spatial.ckdtree', '_cython_0_29_22', 'scipy.sparse', 'scipy.sparse.base', 'scipy.sparse.sputils', 'scipy._lib._util', 'scipy.sparse.csr', 'scipy.sparse._sparsetools', 'scipy.sparse.compressed', 'scipy.sparse.data', 'scipy.sparse.dia', 'scipy.sparse._index', 'scipy.sparse.csc', 'scipy.sparse.lil', 'scipy.sparse._csparsetools', 'scipy.sparse.dok', 'scipy.sparse.coo', 'scipy.sparse.bsr', 'scipy.sparse.construct', 'scipy.sparse.extract', 'scipy.sparse._matrix_io', 'scipy.sparse.csgraph', 'scipy.sparse.csgraph._laplacian', 'scipy.sparse.csgraph._shortest_path', 'scipy.sparse.csgraph._validation', 'scipy.sparse.csgraph._tools', 'scipy.sparse.csgraph._traversal', 'scipy.sparse.csgraph._min_spanning_tree', 'scipy.sparse.csgraph._flow', 'scipy.sparse.csgraph._matching', 'scipy.sparse.csgraph._reordering', 'scipy.spatial.qhull', 'scipy._lib.messagestream', 'scipy.spatial._spherical_voronoi', 'scipy.spatial._voronoi', 'scipy.spatial._plotutils', 'scipy._lib.decorator', 'scipy.spatial._procrustes', 'scipy.linalg', 'scipy.linalg.misc', 'scipy.linalg.blas', 'scipy.linalg._fblas', 'scipy.linalg.lapack', 'scipy.linalg._flapack', 'scipy.linalg.basic', 'scipy.linalg.flinalg', 'scipy.linalg._flinalg', 'scipy.linalg.decomp', 'scipy.linalg.decomp_svd', 'scipy.linalg._solve_toeplitz', 'scipy.linalg.decomp_lu', 'scipy.linalg._decomp_ldl', 'scipy.linalg.decomp_cholesky', 'scipy.linalg.decomp_qr', 'scipy.linalg._decomp_qz', 'scipy.linalg.decomp_schur', 'scipy.linalg._decomp_polar', 'scipy.linalg.matfuncs', 'scipy.linalg.special_matrices', 'scipy.linalg._expm_frechet', 'scipy.linalg._matfuncs_sqrtm', 'scipy.linalg._matfuncs_sqrtm_triu', 'scipy.linalg._solvers', 'scipy.linalg._procrustes', 'scipy.linalg._decomp_update', 'scipy.linalg.cython_blas', 'scipy.linalg.cython_lapack', 'scipy.linalg._sketches', 'scipy.linalg._decomp_cossin', 'scipy.spatial._geometric_slerp', 'scipy.spatial.distance', 'scipy.spatial._distance_wrap', 'scipy.spatial._hausdorff', 'scipy.special', 'scipy.special.sf_error', 'scipy.special._ufuncs', 'scipy.special._ufuncs_cxx', 'scipy.special._basic', 'scipy.special.specfun', 'scipy.special.orthogonal', 'scipy.special._comb', 'scipy.special._logsumexp', 'scipy.special.spfun_stats', 'scipy.special._ellip_harm', 'scipy.special._ellip_harm_2', 'scipy.special._lambertw', 'scipy.special._spherical_bessel', 'scipy.spatial.transform', 'scipy.spatial.transform.rotation', 'scipy.spatial.transform._rotation_groups', 'scipy.constants', 'scipy.constants.codata', 'scipy.constants.constants', 'scipy.spatial.transform._rotation_spline', 'scipy.ndimage', 'scipy.ndimage.filters', 'scipy.ndimage._ni_support', 'scipy.ndimage._nd_image', 'scipy.ndimage._ni_docstrings', 'scipy._lib.doccer', 'scipy.ndimage.fourier', 'scipy.ndimage.interpolation', 'scipy.ndimage.measurements', 'scipy.ndimage._ni_label', '_ni_label', 'scipy.ndimage.morphology', 'scipy.stats.distributions', 'scipy.stats._distn_infrastructure', 'scipy.stats._distr_params', 'scipy.optimize', 'scipy.optimize.optimize', 'scipy.optimize.linesearch', 'scipy.optimize.minpack2', 'scipy.optimize._numdiff', 'scipy.sparse.linalg', 'scipy.sparse.linalg.isolve', 'scipy.sparse.linalg.isolve.iterative', 'scipy.sparse.linalg.isolve._iterative', 'scipy.sparse.linalg.interface', 'scipy.sparse.linalg.isolve.utils', 'scipy._lib._threadsafety', 'scipy.sparse.linalg.isolve.minres', 'scipy.sparse.linalg.isolve.lgmres', 'scipy.sparse.linalg.isolve._gcrotmk', 'scipy.sparse.linalg.isolve.lsqr', 'scipy.sparse.linalg.isolve.lsmr', 'scipy.sparse.linalg.dsolve', 'scipy.sparse.linalg.dsolve.linsolve', 'scipy.sparse.linalg.dsolve._superlu', 'scipy.sparse.linalg.dsolve._add_newdocs', 'scipy.sparse.linalg.eigen', 'scipy.sparse.linalg.eigen.arpack', 'scipy.sparse.linalg.eigen.arpack.arpack', 'scipy.sparse.linalg.eigen.arpack._arpack', 'scipy.sparse.linalg.eigen.lobpcg', 'scipy.sparse.linalg.eigen.lobpcg.lobpcg', 'scipy.sparse.linalg.matfuncs', 'scipy.sparse.linalg._expm_multiply', 'scipy.sparse.linalg._onenormest', 'scipy.sparse.linalg._norm', 'scipy.optimize._group_columns', 'scipy.optimize._differentiable_functions', 'scipy.optimize._hessian_update_strategy', 'scipy.optimize._minimize', 'scipy.optimize._trustregion_dogleg', 'scipy.optimize._trustregion', 'scipy.optimize._trustregion_ncg', 'scipy.optimize._trustregion_krylov', 'scipy.optimize._trlib', 'scipy.optimize._trlib._trlib', 'scipy.optimize._trustregion_exact', 'scipy.optimize._trustregion_constr', 'scipy.optimize._trustregion_constr.minimize_trustregion_constr', 'scipy.optimize._constraints', 'numpy.testing', 'unittest', 'unittest.result', 'unittest.util', 'unittest.case', 'unittest.suite', 'unittest.loader', 'unittest.main', 'unittest.runner', 'unittest.signals', 'numpy.testing._private', 'numpy.testing._private.utils', 'numpy.testing._private.decorators', 'numpy.testing._private.nosetester', 'scipy.optimize._trustregion_constr.equality_constrained_sqp', 'scipy.optimize._trustregion_constr.projections', 'scipy.optimize._trustregion_constr.qp_subproblem', 'scipy.optimize._trustregion_constr.canonical_constraint', 'scipy.optimize._trustregion_constr.tr_interior_point', 'scipy.optimize._trustregion_constr.report', 'scipy.optimize.lbfgsb', 'scipy.optimize._lbfgsb', 'scipy.optimize.tnc', 'scipy.optimize.moduleTNC', 'scipy.optimize.cobyla', 'scipy.optimize._cobyla', 'scipy.optimize.slsqp', 'scipy.optimize._slsqp', 'scipy.optimize._root', 'scipy.optimize.minpack', 'scipy.optimize._minpack', 'scipy.optimize._lsq', 'scipy.optimize._lsq.least_squares', 'scipy.optimize._lsq.trf', 'scipy.optimize._lsq.common', 'scipy.optimize._lsq.dogbox', 'scipy.optimize._lsq.lsq_linear', 'scipy.optimize._lsq.trf_linear', 'scipy.optimize._lsq.givens_elimination', 'scipy.optimize._lsq.bvls', 'scipy.optimize._spectral', 'scipy.optimize.nonlin', 'scipy.optimize._root_scalar', 'scipy.optimize.zeros', 'scipy.optimize._zeros', 'scipy.optimize._nnls', 'scipy.optimize.__nnls', 'scipy.optimize._basinhopping', 'scipy.optimize._linprog', 'scipy.optimize._linprog_highs', 'scipy.optimize._highs', 'scipy.optimize._highs._highs_wrapper', 'scipy.optimize._highs.cython.src._highs_wrapper', 'scipy.optimize._highs._highs_constants', 'scipy.optimize._highs.cython.src._highs_constants', 'scipy.optimize._linprog_ip', 'scipy.optimize._linprog_util', 'scipy.optimize._remove_redundancy', 'scipy.linalg.interpolative', 'scipy.linalg._interpolative_backend', 'scipy.linalg._interpolative', 'scipy.optimize._linprog_simplex', 'scipy.optimize._linprog_rs', 'scipy.optimize._bglu_dense', 'scipy.optimize._linprog_doc', 'scipy.optimize._lsap', 'scipy.optimize._lsap_module', 'scipy.optimize._differentialevolution', 'scipy.optimize._shgo', 'scipy.optimize._shgo_lib', 'scipy.optimize._shgo_lib.sobol_seq', 'scipy.optimize._shgo_lib.triangulation', 'scipy.optimize._dual_annealing', 'scipy.optimize._qap', 'scipy.integrate', 'scipy.integrate._quadrature', 'scipy.integrate.odepack', 'scipy.integrate._odepack', 'scipy.integrate.quadpack', 'scipy.integrate._quadpack', 'scipy.integrate._ode', 'scipy.integrate.vode', 'scipy.integrate._dop', 'scipy.integrate.lsoda', 'scipy.integrate._bvp', 'scipy.integrate._ivp', 'scipy.integrate._ivp.ivp', 'scipy.integrate._ivp.bdf', 'scipy.integrate._ivp.common', 'scipy.integrate._ivp.base', 'scipy.integrate._ivp.radau', 'scipy.integrate._ivp.rk', 'scipy.integrate._ivp.dop853_coefficients', 'scipy.integrate._ivp.lsoda', 'scipy.integrate._quad_vec', 'scipy.misc', 'scipy.misc.doccer', 'scipy.misc.common', 'scipy.stats._constants', 'scipy.stats._continuous_distns', 'scipy.interpolate', 'scipy.interpolate.interpolate', 'scipy.interpolate.fitpack', 'scipy.interpolate._fitpack_impl', 'scipy.interpolate._fitpack', 'scipy.interpolate.dfitpack', 'scipy.interpolate._bsplines', 'scipy.interpolate._bspl', 'scipy.interpolate.polyint', 'scipy.interpolate._ppoly', 'scipy.interpolate.fitpack2', 'scipy.interpolate.interpnd', 'scipy.interpolate.rbf', 'scipy.interpolate._cubic', 'scipy.interpolate.ndgriddata', 'scipy.interpolate._pade', 'scipy.stats._stats', 'scipy.special.cython_special', 'scipy.stats._rvs_sampling', 'scipy.stats._tukeylambda_stats', 'scipy.stats._ksstats', 'scipy.stats._discrete_distns', 'scipy.stats.mstats_basic', 'scipy.stats._stats_mstats_common', 'scipy._lib._bunch', 'scipy.stats._hypotests', 'scipy.stats._wilcoxon_data', 'scipy.stats.morestats', 'scipy.stats.statlib', 'scipy.stats.contingency', 'scipy.stats._binned_statistic', 'scipy.stats.kde', 'scipy.stats.mvn', 'scipy.stats.mstats', 'scipy.stats.mstats_extras', 'scipy.stats._multivariate', 'optuna.samplers.grid', 'optuna.samplers.random', 'optuna.samplers.tpe', 'optuna.samplers.tpe.sampler', 'optuna.samplers.tpe.parzen_estimator', 'optuna.importance._fanova', 'optuna.importance._mean_decrease_impurity', 'sklearn', 'sklearn._config', 'sklearn._distributor_init', 'sklearn.__check_build', 'sklearn.__check_build._check_build', 'sklearn.base', 'sklearn.utils', 'sklearn.utils.murmurhash', 'sklearn.utils.class_weight', 'sklearn.utils._joblib', 'sklearn.exceptions', 'sklearn.utils.deprecation', 'sklearn.utils.fixes', 'sklearn.externals', 'sklearn.externals._scipy_linalg', 'sklearn.utils.validation', 'sklearn.utils._show_versions', 'sklearn.utils._openmp_helpers', 'sklearn.compose', 'sklearn.compose._column_transformer', 'sklearn.pipeline', 'sklearn.utils.metaestimators', 'sklearn.preprocessing', 'sklearn.preprocessing._function_transformer', 'sklearn.preprocessing._data', 'sklearn.utils.extmath', 'sklearn.utils._logistic_sigmoid', 'sklearn.utils.sparsefuncs_fast', '_cython_0_29_14', 'sklearn.utils.sparsefuncs', 'sklearn.preprocessing._csr_polynomial_expansion', 'sklearn.preprocessing._encoders', 'sklearn.preprocessing._label', 'sklearn.utils.multiclass', 'sklearn.preprocessing._discretization', 'sklearn.compose._target', 'sklearn.ensemble', 'sklearn.ensemble._base', 'sklearn.ensemble._forest', 'sklearn.metrics', 'sklearn.metrics._ranking', 'sklearn.metrics._base', 'sklearn.metrics._classification', 'sklearn.metrics.cluster', 'sklearn.metrics.cluster._supervised', 'sklearn.metrics.cluster._expected_mutual_info_fast', 'sklearn.metrics.cluster._unsupervised', 'sklearn.metrics.pairwise', 'sklearn.utils._mask', 'sklearn.metrics._pairwise_fast', 'sklearn.metrics.cluster._bicluster', 'sklearn.metrics._regression', 'sklearn.metrics._scorer', 'sklearn.metrics._plot', 'sklearn.metrics._plot.roc_curve', 'sklearn.metrics._plot.base', 'sklearn.metrics._plot.precision_recall_curve', 'sklearn.metrics._plot.confusion_matrix', 'sklearn.tree', 'sklearn.tree._classes', 'sklearn.tree._criterion', 'sklearn.tree._splitter', 'sklearn.tree._tree', 'sklearn.neighbors', 'sklearn.neighbors._ball_tree', 'sklearn.neighbors._dist_metrics', 'sklearn.neighbors._typedefs', 'sklearn.neighbors._kd_tree', 'sklearn.neighbors._graph', 'sklearn.neighbors._base', 'sklearn.neighbors._unsupervised', 'sklearn.neighbors._classification', 'sklearn.neighbors._regression', 'sklearn.neighbors._nearest_centroid', 'sklearn.neighbors._kde', 'sklearn.neighbors._lof', 'sklearn.neighbors._nca', 'sklearn.decomposition', 'sklearn.decomposition.dict_learning', 'sklearn.decomposition._dict_learning', 'sklearn.linear_model', 'sklearn.linear_model._base', 'sklearn.utils._seq_dataset', 'sklearn.utils._random', 'sklearn.linear_model._bayes', 'sklearn.linear_model._least_angle', 'sklearn.utils.arrayfuncs', 'sklearn.utils._cython_blas', 'sklearn.model_selection', 'sklearn.model_selection._split', 'sklearn.model_selection._validation', 'sklearn.model_selection._search', 'sklearn.utils.random', 'sklearn.linear_model._coordinate_descent', 'sklearn.linear_model._cd_fast', 'sklearn.linear_model._huber', 'sklearn.utils.optimize', 'sklearn.linear_model._sgd_fast', 'sklearn.utils._weight_vector', 'sklearn.linear_model._stochastic_gradient', 'sklearn.linear_model._ridge', 'sklearn.linear_model._sag', 'sklearn.linear_model._sag_fast', 'sklearn.linear_model._logistic', 'sklearn.svm', 'sklearn.svm._classes', 'sklearn.svm._base', 'sklearn.svm._libsvm', 'sklearn.svm._liblinear', 'sklearn.svm._libsvm_sparse', 'sklearn.svm._bounds', 'sklearn.linear_model._omp', 'sklearn.linear_model._passive_aggressive', 'sklearn.linear_model._perceptron', 'sklearn.linear_model._ransac', 'sklearn.linear_model._theil_sen', 'sklearn.externals._pep562', 'sklearn.decomposition._nmf', 'sklearn.decomposition._cdnmf_fast', 'sklearn.decomposition._pca', 'sklearn.decomposition._base', 'sklearn.decomposition._incremental_pca', 'sklearn.decomposition._kernel_pca', 'sklearn.decomposition._sparse_pca', 'sklearn.decomposition._truncated_svd', 'sklearn.decomposition._fastica', 'sklearn.decomposition._factor_analysis', 'sklearn.decomposition._lda', 'sklearn.decomposition._online_lda_fast', 'sklearn.neighbors._quad_tree', 'sklearn.tree._utils', 'sklearn.tree._export', 'sklearn.tree._reingold_tilford', 'sklearn.ensemble._bagging', 'sklearn.ensemble._iforest', 'sklearn.ensemble._weight_boosting', 'sklearn.ensemble._gb', 'sklearn.ensemble._gradient_boosting', 'sklearn.ensemble._gb_losses', 'sklearn.utils.stats', 'sklearn.dummy', 'sklearn.ensemble._voting', 'sklearn.ensemble._stacking', 'sklearn.ensemble.partial_dependence', 'optuna.integration', 'optuna.multi_objective', 'optuna.multi_objective.samplers', 'optuna.multi_objective.samplers._adapter', 'optuna.multi_objective.samplers._base', 'optuna.multi_objective.samplers._nsga2', 'optuna.multi_objective.samplers._random', 'optuna.multi_objective.study', 'optuna.multi_objective.trial', 'optuna.visualization', 'optuna.visualization.contour', 'optuna.visualization.utils', 'optuna.visualization.plotly_imports', 'optuna.visualization.intermediate_values', 'optuna.visualization.optimization_history', 'optuna.visualization.parallel_coordinate', 'optuna.visualization.slice', 'enzpred.features', 'enzpred.features.build_features', 'rdkit', 'rdkit.rdBase', 'rdkit.Chem', 'rdkit.RDConfig', 'rdkit.RDPaths', 'sqlite3', 'sqlite3.dbapi2', '_sqlite3', 'rdkit.DataStructs', 'rdkit.DataStructs.cDataStructs', 'rdkit.Geometry', 'rdkit.Geometry.rdGeometry', 'rdkit.Chem.rdchem', 'rdkit.Chem.rdmolfiles', 'rdkit.Chem.rdmolops', 'rdkit.Chem.rdCIPLabeler', 'rdkit.Chem.inchi', 'rdkit.Chem.rdinchi', 'rdkit.RDLogger', 'rdkit.Chem.rdMolInterchange', 'rdkit.Chem.rdCoordGen', 'rdkit.Chem.AllChem', 'rdkit.ForceField', 'rdkit.ForceField.rdForceField', 'rdkit.Chem.ChemicalFeatures', 'rdkit.Chem.rdChemicalFeatures', 'rdkit.Chem.rdMolChemicalFeatures', 'rdkit.Chem.rdChemReactions', 'rdkit.Chem.rdDepictor', 'rdkit.Chem.rdDistGeom', 'rdkit.Chem.rdForceFieldHelpers', 'rdkit.Chem.rdMolAlign', 'rdkit.Chem.rdMolDescriptors', 'rdkit.Chem.rdMolTransforms', 'rdkit.Chem.rdPartialCharges', 'rdkit.Chem.rdReducedGraphs', 'rdkit.Chem.rdShapeHelpers', 'rdkit.Chem.rdqueries', 'rdkit.Chem.rdMolEnumerator', 'rdkit.Chem.EnumerateStereoisomers', 'rdkit.Chem.rdSLNParse', 'sklearn.feature_extraction', 'sklearn.feature_extraction._dict_vectorizer', 'sklearn.feature_extraction._hash', 'sklearn.feature_extraction._hashing_fast', 'sklearn.feature_extraction.image', 'sklearn.feature_extraction.text', 'sklearn.feature_extraction._stop_words', 'bepler_embedding', 'bepler_embedding.embed_utils', 'bepler_embedding.alphabets', 'bepler_embedding.utils', 'bepler_embedding.models', 'bepler_embedding.models.multitask', 'bepler_embedding.models.comparison', 'bepler_embedding.models.embedding', 'bepler_embedding.models.sequence', 'tape', 'tape.datasets', 'lmdb', 'lmdb.cpython', 'tape.tokenizers', 'tape.registry', 'tape.models', 'tape.models.modeling_utils', 'tape.models.file_utils', 'boto3', 'boto3.compat', 'boto3.exceptions', 'botocore', 'botocore.exceptions', 'botocore.vendored', 'botocore.vendored.requests', 'botocore.vendored.requests.exceptions', 'botocore.vendored.requests.packages', 'botocore.vendored.requests.packages.urllib3', 'botocore.vendored.requests.packages.urllib3.exceptions', 'boto3.session', 'botocore.session', 'botocore.client', 'botocore.waiter', 'jmespath', 'jmespath.parser', 'jmespath.lexer', 'jmespath.exceptions', 'jmespath.compat', 'jmespath.ast', 'jmespath.visitor', 'jmespath.functions', 'botocore.docs', 'botocore.docs.service', 'botocore.docs.bcdoc', 'botocore.docs.bcdoc.restdoc', 'botocore.compat', 'botocore.vendored.six', 'urllib3', 'urllib3.exceptions', 'urllib3.packages', 'urllib3.packages.six', 'urllib3.packages.six.moves', 'urllib3.packages.six.moves.http_client', 'urllib3._version', 'urllib3.connectionpool', 'urllib3.connection', 'urllib3.util', 'urllib3.util.connection', 'urllib3.contrib', 'urllib3.contrib._appengine_environ', 'urllib3.util.wait', 'urllib3.util.request', 'brotli', 'brotli.brotli', '_cffi_backend', '_brotli.lib', '_brotli', 'brotli._brotli', 'urllib3.util.response', 'urllib3.util.retry', 'urllib3.util.ssl_', 'urllib3.util.url', 'urllib3.util.ssltransport', 'urllib3.util.timeout', 'urllib3.util.proxy', 'urllib3._collections', 'urllib3.util.ssl_match_hostname', 'ipaddress', 'urllib3.request', 'urllib3.filepost', 'urllib3.fields', 'mimetypes', 'urllib3.packages.six.moves.urllib', 'urllib3.packages.six.moves.urllib.parse', 'urllib3.response', 'urllib3.util.queue', 'urllib3.poolmanager', 'botocore.vendored.six.moves', 'xml.etree', 'xml.etree.cElementTree', 'xml.etree.ElementTree', 'xml.etree.ElementPath', '_elementtree', 'botocore.docs.bcdoc.docstringparser', 'html.parser', '_markupbase', 'botocore.docs.bcdoc.style', 'botocore.docs.client', 'botocore.docs.example', 'botocore.docs.shape', 'botocore.utils', 'cgi', 'botocore.awsrequest', 'botocore.httpsession', 'urllib3.contrib.pyopenssl', 'OpenSSL', 'OpenSSL.crypto', 'cryptography', 'cryptography.__about__', 'cryptography.utils', 'cryptography.x509', 'cryptography.x509.certificate_transparency', 'cryptography.hazmat', 'cryptography.hazmat.bindings', 'cryptography.hazmat.bindings._rust', 'cryptography.hazmat.primitives', 'cryptography.hazmat.primitives.hashes', 'cryptography.exceptions', 'cryptography.x509.base', 'cryptography.hazmat.primitives.serialization', 'cryptography.hazmat.primitives._serialization', 'cryptography.hazmat.primitives.serialization.base', 'cryptography.hazmat.primitives.asymmetric', 'cryptography.hazmat.primitives.asymmetric.dh', 'cryptography.hazmat.primitives.asymmetric.types', 'cryptography.hazmat.primitives.asymmetric.dsa', 'cryptography.hazmat.primitives.asymmetric.utils', 'cryptography.hazmat.primitives.asymmetric.ec', 'cryptography.hazmat._oid', 'cryptography.hazmat.primitives.asymmetric.ed25519', 'cryptography.hazmat.primitives.asymmetric.ed448', 'cryptography.hazmat.primitives.asymmetric.rsa', 'cryptography.hazmat.primitives._asymmetric', 'cryptography.hazmat.primitives.asymmetric.x25519', 'cryptography.hazmat.primitives.asymmetric.x448', 'cryptography.hazmat.primitives.serialization.ssh', 'cryptography.hazmat.primitives.ciphers', 'cryptography.hazmat.primitives._cipheralgorithm', 'cryptography.hazmat.primitives.ciphers.base', 'cryptography.hazmat.primitives.ciphers.modes', 'cryptography.hazmat.primitives.ciphers.algorithms', 'cryptography.x509.extensions', 'cryptography.hazmat.primitives.constant_time', 'cryptography.x509.general_name', 'cryptography.x509.name', 'cryptography.x509.oid', 'OpenSSL._util', 'cryptography.hazmat.bindings.openssl', 'cryptography.hazmat.bindings.openssl.binding', 'cryptography.hazmat.bindings._openssl.lib', 'cryptography.hazmat.bindings._openssl', 'cryptography.hazmat.bindings.openssl._conditional', 'OpenSSL.SSL', 'OpenSSL.version', 'cryptography.hazmat.backends', 'cryptography.hazmat.backends.openssl', 'cryptography.hazmat.backends.openssl.backend', 'cryptography.hazmat.backends.openssl.aead', 'cryptography.hazmat.backends.openssl.ciphers', 'cryptography.hazmat.backends.openssl.cmac', 'cryptography.hazmat.backends.openssl.dh', 'cryptography.hazmat.backends.openssl.dsa', 'cryptography.hazmat.backends.openssl.utils', 'cryptography.hazmat.backends.openssl.ec', 'cryptography.hazmat.backends.openssl.ed25519', 'cryptography.hazmat.backends.openssl.ed448', 'cryptography.hazmat.backends.openssl.hashes', 'cryptography.hazmat.backends.openssl.hmac', 'cryptography.hazmat.backends.openssl.poly1305', 'cryptography.hazmat.backends.openssl.rsa', 'cryptography.hazmat.primitives.asymmetric.padding', 'cryptography.hazmat.backends.openssl.x25519', 'cryptography.hazmat.backends.openssl.x448', 'cryptography.hazmat.primitives.kdf', 'cryptography.hazmat.primitives.kdf.scrypt', 'cryptography.hazmat.primitives.serialization.pkcs7', 'cryptography.hazmat.primitives.serialization.pkcs12', 'cryptography.hazmat.backends.openssl.x509', 'urllib3.packages.backports', 'urllib3.packages.backports.makefile', 'botocore.vendored.six.moves.urllib_parse', 'certifi', 'certifi.core', 'botocore.vendored.six.moves.urllib', 'botocore.vendored.six.moves.urllib.request', 'botocore.docs.utils', 'botocore.docs.method', 'botocore.docs.params', 'botocore.docs.sharedexample', 'botocore.docs.paginator', 'botocore.docs.waiter', 'botocore.docs.docstring', 'botocore.args', 'botocore.parsers', 'botocore.eventstream', 'botocore.serialize', 'botocore.validate', 'botocore.config', 'botocore.endpoint', 'botocore.history', 'botocore.hooks', 'botocore.httpchecksum', 'botocore.response', 'botocore.regions', 'botocore.auth', 'botocore.crt', 'botocore.endpoint_provider', 'botocore.signers', 'botocore.discovery', 'botocore.model', 'botocore.paginate', 'botocore.retries', 'botocore.retries.adaptive', 'botocore.retries.bucket', 'botocore.retries.standard', 'botocore.retries.quota', 'botocore.retries.special', 'botocore.retries.base', 'botocore.retries.throttling', 'botocore.configloader', 'botocore.credentials', 'getpass', 'botocore.tokens', 'botocore.handlers', 'botocore.retryhandler', 'botocore.translate', 'botocore.monitoring', 'botocore.configprovider', 'botocore.errorfactory', 'botocore.loaders', 'boto3.utils', 'boto3.resources', 'boto3.resources.factory', 'boto3.docs', 'boto3.docs.service', 'boto3.docs.client', 'boto3.docs.resource', 'boto3.docs.action', 'boto3.docs.base', 'boto3.docs.method', 'boto3.docs.utils', 'boto3.docs.attr', 'boto3.docs.collection', 'boto3.docs.subresource', 'boto3.docs.waiter', 'boto3.docs.docstring', 'boto3.resources.action', 'boto3.resources.model', 'boto3.resources.params', 'boto3.resources.response', 'boto3.resources.base', 'boto3.resources.collection', 'requests', 'requests.exceptions', 'requests.compat', 'charset_normalizer', 'charset_normalizer.api', 'charset_normalizer.constant', 'charset_normalizer.md', 'charset_normalizer.utils', '_multibytecodec', 'charset_normalizer.models', 'charset_normalizer.cd', 'charset_normalizer.assets', 'charset_normalizer.legacy', 'charset_normalizer.version', 'http.cookiejar', 'http.cookies', 'requests.packages', 'requests.packages.urllib3', 'requests.packages.urllib3.exceptions', 'requests.packages.urllib3.packages', 'requests.packages.urllib3.packages.six', 'requests.packages.urllib3.packages.six.moves', 'requests.packages.urllib3.packages.six.moves.http_client', 'requests.packages.urllib3._version', 'requests.packages.urllib3.connectionpool', 'requests.packages.urllib3.connection', 'requests.packages.urllib3.util', 'requests.packages.urllib3.util.connection', 'requests.packages.urllib3.contrib', 'requests.packages.urllib3.contrib._appengine_environ', 'requests.packages.urllib3.util.wait', 'requests.packages.urllib3.util.request', 'requests.packages.urllib3.util.response', 'requests.packages.urllib3.util.retry', 'requests.packages.urllib3.util.ssl_', 'requests.packages.urllib3.util.url', 'requests.packages.urllib3.util.ssltransport', 'requests.packages.urllib3.util.timeout', 'requests.packages.urllib3.util.proxy', 'requests.packages.urllib3._collections', 'requests.packages.urllib3.util.ssl_match_hostname', 'requests.packages.urllib3.request', 'requests.packages.urllib3.filepost', 'requests.packages.urllib3.fields', 'requests.packages.urllib3.packages.six.moves.urllib', 'requests.packages.urllib3.packages.six.moves.urllib.parse', 'requests.packages.urllib3.response', 'requests.packages.urllib3.util.queue', 'requests.packages.urllib3.poolmanager', 'requests.packages.urllib3.contrib.pyopenssl', 'requests.packages.urllib3.packages.backports', 'requests.packages.urllib3.packages.backports.makefile', 'idna', 'idna.package_data', 'idna.core', 'idna.idnadata', 'idna.intranges', 'requests.packages.idna', 'requests.packages.idna.package_data', 'requests.packages.idna.core', 'requests.packages.idna.idnadata', 'requests.packages.idna.intranges', 'requests.packages.chardet', 'requests.utils', 'requests.certs', 'requests.__version__', 'requests._internal_utils', 'requests.cookies', 'requests.structures', 'requests.api', 'requests.sessions', 'requests.adapters', 'requests.auth', 'requests.models', 'encodings.idna', 'stringprep', 'requests.hooks', 'requests.status_codes', 'urllib3.contrib.socks', 'socks', 'tape.metrics', 'tape.models.modeling_bert', 'torch.utils.checkpoint', 'tape.models.modeling_lstm', 'tape.models.modeling_onehot', 'tape.models.modeling_resnet', 'tape.models.modeling_trrosetta', 'tape.models.modeling_unirep', 'enzpred.features.alphabet', 'enzpred.utils', 'enzpred.utils.file_utils', 'enzpred.utils.parse_utils', 'enzpred.utils.ssa_utils', 'enzpred.features.feature_selection', 'sklearn.feature_selection', 'sklearn.feature_selection._univariate_selection', 'sklearn.feature_selection._base', 'sklearn.feature_selection._variance_threshold', 'sklearn.feature_selection._rfe', 'sklearn.feature_selection._from_model', 'sklearn.feature_selection._mutual_info', 'enzpred.models', 'enzpred.models.dense_models', 'enzpred.models.sklearn_models', 'sklearn.gaussian_process', 'sklearn.gaussian_process._gpr', 'sklearn.gaussian_process.kernels', 'sklearn.gaussian_process._gpc', 'sklearn.multiclass', 'enzpred.models.torch_models', 'enzpred.dataset', 'enzpred.dataset.dataloader', 'enzpred.models.distance', 'pathos', 'pathos.info', 'pathos.core', 'pathos.hosts', 'pathos.server', 'pathos.selector', 'pathos.connection', 'pathos.util', 'pathos.pools', 'pathos.helpers', 'pathos.helpers.pp_helper', 'multiprocess', 'multiprocess.__info__', 'multiprocess.context', 'multiprocess.process', 'multiprocess.reduction', 'dill', 'dill.__info__', 'dill._dill', 'dill.logger', '_pyio', 'dill._shims', 'dill.settings', 'dill.session', 'dill.detect', 'dill.pointers', 'dill.source', 'dill.temp', 'dill.objtypes', 'multiprocess.pool', 'multiprocess.util', 'pp', 'ppft', 'ppft.__info__', 'ppft._pp', 'ppft.transport', 'ppft.common', 'ppft.auto', 'ppft.worker', 'ppft.__main__', 'pathos.helpers.mp_helper', 'multiprocess.dummy', 'multiprocess.dummy.connection', 'pathos.multiprocessing', 'pathos.abstract_launcher', 'pathos.threading', 'pathos.parallel', 'pathos.serial', 'pathos.secure', 'pathos.secure.connection', 'pathos.secure.copier', 'pathos.secure.tunnel', 'Levenshtein', 'Levenshtein._levenshtein', 'Bio', 'Bio.Blast', 'Bio.Blast.Applications', 'Bio.Application', 'Bio.Blast.NCBIXML', 'Bio.Blast.Record', 'Bio.Seq', 'Bio.Data', 'Bio.Data.CodonTable', 'Bio.Data.IUPACData', 'Bio.SeqRecord', 'Bio.Align', 'Bio.Align._aligners', 'Bio.Align.substitution_matrices', 'xml.sax', 'xml.sax.xmlreader', 'xml.sax.handler', 'xml.sax._exceptions', 'enzpred.dataset.splitter', 'enzpred.parsing', 'enzpred.evaluation', 'enzpred.evaluation.metrics', 'pandas.io.formats.string', 'pandas.io.formats.csvs', 'matplotlib', 'packaging', 'packaging.__about__', 'packaging.version', 'packaging._structures', 'matplotlib._api', 'matplotlib._api.deprecation', 'matplotlib._version', 'matplotlib.cbook', 'matplotlib._c_internal_utils', 'matplotlib.docstring', 'matplotlib.rcsetup', 'matplotlib.colors', 'PIL', 'PIL._version', 'PIL.Image', 'PIL.ImageMode', 'PIL.TiffTags', 'PIL._binary', 'PIL._deprecate', 'PIL._util', 'PIL._imaging', 'cffi', 'cffi.api', 'cffi.lock', 'cffi.error', 'cffi.model', 'PIL.PngImagePlugin', 'PIL.ImageChops', 'PIL.ImageFile', 'PIL.ImagePalette', 'PIL.GimpGradientFile', 'PIL.GimpPaletteFile', 'PIL.ImageColor', 'PIL.PaletteFile', 'PIL.ImageSequence', 'matplotlib.scale', 'matplotlib.ticker', 'matplotlib.transforms', 'matplotlib._path', 'matplotlib.path', 'matplotlib.bezier', 'matplotlib._color_data', 'matplotlib.fontconfig_pattern', 'pyparsing', 'pyparsing.util', 'pyparsing.exceptions', 'pyparsing.unicode', 'pyparsing.actions', 'pyparsing.core', 'pyparsing.results', 'pyparsing.helpers', 'pyparsing.testing', 'pyparsing.common', 'matplotlib._enums', 'cycler', 'matplotlib.ft2font', 'kiwisolver', 'kiwisolver._cext']
2023-01-05 10:04:12,685 DEBUG:   CACHEDIR=/root/.cache/matplotlib
2023-01-05 10:04:12,687 DEBUG:   Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json
2023-01-05 10:04:13,122 DEBUG:   Loaded backend agg version unknown.
2023-01-05 10:04:13,124 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-01-05 10:04:13,124 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 10:04:13,125 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,125 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,125 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 10:04:13,125 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 10:04:13,125 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 10:04:13,125 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 10:04:13,125 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 10:04:13,125 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,125 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,125 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 10:04:13,125 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 10:04:13,125 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,125 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,125 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,126 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 10:04:13,126 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,126 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 10:04:13,126 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,126 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,126 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-05 10:04:13,126 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 10:04:13,126 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 10:04:13,126 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,126 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,126 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,126 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 10:04:13,126 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,126 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 10:04:13,126 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 10:04:13,127 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,127 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 10:04:13,127 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-05 10:04:13,127 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,127 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,127 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 10:04:13,127 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,127 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 10:04:13,127 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 10:04:13,127 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,127 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 10:04:13,127 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,127 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 10:04:13,127 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 10:04:13,127 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-05 10:04:13,164 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.
2023-01-05 10:04:13,164 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 10:04:13,164 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,164 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,164 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 10:04:13,165 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 10:04:13,165 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 10:04:13,165 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 10:04:13,165 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 10:04:13,165 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,165 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,165 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 10:04:13,165 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 10:04:13,165 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,165 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,165 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,165 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 10:04:13,165 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,165 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 10:04:13,165 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,166 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,166 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-05 10:04:13,166 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 10:04:13,166 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 10:04:13,166 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,166 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,166 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,166 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 10:04:13,166 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,166 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 10:04:13,166 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 10:04:13,166 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,166 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 10:04:13,166 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-05 10:04:13,166 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,167 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,167 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 10:04:13,167 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,167 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 10:04:13,167 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 10:04:13,167 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,167 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 10:04:13,167 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,167 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 10:04:13,167 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 10:04:13,167 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-05 10:04:13,176 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0.
2023-01-05 10:04:13,176 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBol.ttf', name='STIXGeneral', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 10:04:13,176 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmtt10.ttf', name='cmtt10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,176 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmex10.ttf', name='cmex10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,176 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-BoldItalic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 10:04:13,176 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralItalic.ttf', name='STIXGeneral', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 10:04:13,176 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 10:04:13,176 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymBol.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 10:04:13,176 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBol.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 10:04:13,176 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneral.ttf', name='STIXGeneral', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmb10.ttf', name='cmb10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 10:04:13,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 10:04:13,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymReg.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymReg.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizOneSymReg.ttf', name='STIXSizeOneSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-BoldOblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 10:04:13,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmmi10.ttf', name='cmmi10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXGeneralBolIta.ttf', name='STIXGeneral', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 10:04:13,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmr10.ttf', name='cmr10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmss10.ttf', name='cmss10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-BoldOblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=700, stretch='normal', size='scalable')) = 1.335
2023-01-05 10:04:13,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Oblique.ttf', name='DejaVu Sans Mono', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 10:04:13,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUniBolIta.ttf', name='STIXNonUnicode', style='italic', variant='normal', weight=700, stretch='normal', size='scalable')) = 11.335
2023-01-05 10:04:13,177 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFiveSymReg.ttf', name='STIXSizeFiveSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,178 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,178 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,178 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 10:04:13,178 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymReg.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,178 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizThreeSymBol.ttf', name='STIXSizeThreeSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 10:04:13,178 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 10:04:13,178 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/cmsy10.ttf', name='cmsy10', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,178 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizFourSymBol.ttf', name='STIXSizeFourSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 10:04:13,178 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans-Oblique.ttf', name='DejaVu Sans', style='oblique', variant='normal', weight=400, stretch='normal', size='scalable')) = 1.05
2023-01-05 10:04:13,178 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXNonUni.ttf', name='STIXNonUnicode', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,178 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSansDisplay.ttf', name='DejaVu Sans Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,178 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/STIXSizTwoSymBol.ttf', name='STIXSizeTwoSym', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 10:04:13,178 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerifDisplay.ttf', name='DejaVu Serif Display', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,178 DEBUG:   findfont: score(FontEntry(fname='/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSerif-Italic.ttf', name='DejaVu Serif', style='italic', variant='normal', weight=400, stretch='normal', size='scalable')) = 11.05
2023-01-05 10:04:13,178 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 0.05
2023-01-05 10:04:13,179 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,179 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSansMono-Bold.ttf', name='DejaVu Sans Mono', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 10:04:13,179 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=400, stretch='normal', size='scalable')) = 10.05
2023-01-05 10:04:13,179 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf', name='DejaVu Sans', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 0.33499999999999996
2023-01-05 10:04:13,179 DEBUG:   findfont: score(FontEntry(fname='/usr/share/fonts/truetype/dejavu/DejaVuSerif-Bold.ttf', name='DejaVu Serif', style='normal', variant='normal', weight=700, stretch='normal', size='scalable')) = 10.335
2023-01-05 10:04:13,179 DEBUG:   findfont: Matching sans\-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/opt/conda/envs/enzpred/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.
2023-01-05 10:04:13,622 INFO: Done with stage: EXPORT RESULTS
2023-01-05 10:04:13,623 INFO: Starting stage: SAVE MODEL
2023-01-05 10:04:13,677 INFO: Done with stage: SAVE MODEL
2023-01-05 10:04:13,677 INFO: Wall time for program:  10753.41 seconds
